[
    {
        "paper_id": 1112.1607,
        "authors": "Claudio Albanese, Damiano Brigo, Frank Oertel",
        "title": "Restructuring Counterparty Credit Risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce an innovative theoretical framework to model derivative\ntransactions between defaultable entities based on the principle of arbitrage\nfreedom. Our framework extends the traditional formulations based on Credit and\nDebit Valuation Adjustments (CVA and DVA). Depending on how the default\ncontingency is accounted for, we list a total of ten different structuring\nstyles. These include bipartite structures between a bank and a counterparty,\ntri-partite structures with one margin lender in addition, quadri-partite\nstructures with two margin lenders and, most importantly, configurations where\nall derivative transactions are cleared through a Central Counterparty (CCP).\nWe compare the various structuring styles under a number of criteria including\nconsistency from an accounting standpoint, counterparty risk hedgeability,\nnumerical complexity, transaction portability upon default, induced behaviour\nand macro-economic impact of the implied wealth allocation.\n"
    },
    {
        "paper_id": 1112.1652,
        "authors": "Cyril Grunspan",
        "title": "Asymptotic Expansions of the Lognormal Implied Volatility : A Model Free\n  Approach",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We invert the Black-Scholes formula. We consider the cases low strike, large\nstrike, short maturity and large maturity. We give explicitly the first 5 terms\nof the expansions. A method to compute all the terms by induction is also\ngiven. At the money, we have a closed form formula for implied lognormal\nvolatility in terms of a power series in call price.\n"
    },
    {
        "paper_id": 1112.1763,
        "authors": "Masaaki Fujii, Akihiko Takahashi",
        "title": "Clean Valuation Framework for the USD Silo",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the forthcoming ISDA Standard Credit Support Annex (SCSA), the trades\ndenominated in non-G5 currencies as well as those include multiple currencies\nare expected to be allocated to the USD silo, where the contracts are\ncollateralized by USD cash, or a different currency with an appropriate\ninterest rate overlay to achieve the same economic effects. In this paper, we\nhave presented a simple generic valuation framework for the clean price under\nthe USD silo with the the detailed procedures for the initial term structure\nconstruction. We have also shown that Cross Currency Swap (CCS) basis spread\ncan be expressed as a difference between two swap rates.\n"
    },
    {
        "paper_id": 1112.1782,
        "authors": "Cyril Grunspan",
        "title": "A Note on the Equivalence between the Normal and the Lognormal Implied\n  Volatility : A Model Free Approach",
        "comments": "10 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  First, we show that implied normal volatility is intimately linked with the\nincomplete Gamma function. Then, we deduce an expansion on implied normal\nvolatility in terms of the time-value of a European call option. Then, we\nformulate an equivalence between the implied normal volatility and the\nlognormal implied volatility with any strike and any model. This generalizes a\nknown result for the SABR model. Finally, we adress the issue of the \"breakeven\nmove\" of a delta-hedged portfolio.\n"
    },
    {
        "paper_id": 1112.1838,
        "authors": "E. Bacry, K. Dayri and J. F. Muzy",
        "title": "Non-parametric kernel estimation for symmetric Hawkes processes.\n  Application to high frequency financial data",
        "comments": "6 figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2012-21005-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We define a numerical method that provides a non-parametric estimation of the\nkernel shape in symmetric multivariate Hawkes processes. This method relies on\nsecond order statistical properties of Hawkes processes that relate the\ncovariance matrix of the process to the kernel matrix. The square root of the\ncorrelation function is computed using a minimal phase recovering method. We\nillustrate our method on some examples and provide an empirical study of the\nestimation errors. Within this framework, we analyze high frequency financial\nprice data modeled as 1D or 2D Hawkes processes. We find slowly decaying\n(power-law) kernel shapes suggesting a long memory nature of self-excitation\nphenomena at the microstructure level of price dynamics.\n"
    },
    {
        "paper_id": 1112.2059,
        "authors": "Andrea Macrina, Priyanka A. Parbhoo",
        "title": "Randomised Mixture Models for Pricing Kernels",
        "comments": "34 pages, 19 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Numerous kinds of uncertainties may affect an economy, e.g. economic,\npolitical, and environmental ones. We model the aggregate impact by the\nuncertainties on an economy and its associated financial market by randomised\nmixtures of L\\'evy processes. We assume that market participants observe the\nrandomised mixtures only through best estimates based on noisy market\ninformation. The concept of incomplete information introduces an element of\nstochastic filtering theory in constructing what we term \"filtered Esscher\nmartingales\". We make use of this family of martingales to develop pricing\nkernel models. Examples of bond price models are examined, and we show that the\nchoice of the random mixture has a significant effect on the model dynamics and\nthe types of movements observed in the associated yield curves. Parameter\nsensitivity is analysed and option price processes are derived. We extend the\nclass of pricing kernel models by considering a weighted heat kernel approach,\nand develop models driven by mixtures of Markov processes.\n"
    },
    {
        "paper_id": 1112.2168,
        "authors": "Anindya S. Chakrabarti",
        "title": "Firm dynamics in a closed, conserved economy: A model of size\n  distribution of employment and related statistics",
        "comments": "25 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We address the issue of the distribution of firm size. To this end we propose\na model of firms in a closed, conserved economy populated with\nzero-intelligence agents who continuously move from one firm to another. We\nthen analyze the size distribution and related statistics obtained from the\nmodel. Our ultimate goal is to reproduce the well known statistical features\nobtained from the panel study of the firms i.e., the power law in size (in\nterms of income and/or employment), the Laplace distribution in the growth\nrates and the slowly declining standard deviation of the growth rates\nconditional on the firm size. First, we show that the model generalizes the\nusual kinetic exchange models with binary interaction to interactions between\nan arbitrary number of agents. When the number of interacting agents is in the\norder of the system itself, it is possible to decouple the model. We provide\nsome exact results on the distributions. Our model easily reproduces the power\nlaw. The fluctuations in the growth rate falls with increasing size following a\npower law (with an exponent 1 whereas the data suggests that the exponent is\naround 1/6). However, the distribution of the difference of the firm-size in\nthis model has Laplace distribution whereas the real data suggests that the\ndifference of the log sizes has the same distribution.\n"
    },
    {
        "paper_id": 1112.2379,
        "authors": "B. Dupoyet, H. R. Fiebig, D. P. Musgrove",
        "title": "Arbitrage-free Self-organizing Markets with GARCH Properties: Generating\n  them in the Lab with a Lattice Model",
        "comments": "19 pages, 11 figures compiled from 33 eps files",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend our studies of a quantum field model defined on a lattice having\nthe dilation group as a local gauge symmetry. The model is relevant in the\ncross-disciplinary area of econophysics. A corresponding proposal by Ilinski\naimed at gauge modeling in non-equilibrium pricing is realized as a numerical\nsimulation of the one-asset version. The gauge field background enforces\nminimal arbitrage, yet allows for statistical fluctuations. The new feature\nadded to the model is an updating prescription for the simulation that drives\nthe model market into a self-organized critical state. Taking advantage of some\nflexibility of the updating prescription, stylized features and dynamical\nbehaviors of real-world markets are reproduced in some detail.\n"
    },
    {
        "paper_id": 1112.2397,
        "authors": "Sophie Laruelle (LPMA), Charles-Albert Lehalle, Gilles Pag\\`es (LPMA)",
        "title": "Optimal posting price of limit orders: learning by trading",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Considering that a trader or a trading algorithm interacting with markets\nduring continuous auctions can be modeled by an iterating procedure adjusting\nthe price at which he posts orders at a given rhythm, this paper proposes a\nprocedure minimizing his costs. We prove the a.s. convergence of the algorithm\nunder assumptions on the cost function and give some practical criteria on\nmodel parameters to ensure that the conditions to use the algorithm are\nfulfilled (using notably the co-monotony principle). We illustrate our results\nwith numerical experiments on both simulated data and using a financial market\ndataset.\n"
    },
    {
        "paper_id": 1112.2406,
        "authors": "Dmitry B. Rokhlin",
        "title": "On the game interpretation of a shadow price process in utility\n  maximization problems under transaction costs",
        "comments": "19 pages, minor corrections, Example 5 is added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To any utility maximization problem under transaction costs one can assign a\nfrictionless model with a price process $S^*$, lying in the bid/ask price\ninterval $[\\underline S, \\bar{S}]$. Such process $S^*$ is called a \\emph{shadow\nprice} if it provides the same optimal utility value as in the original model\nwith bid-ask spread.\n  We call $S^*$ a \\emph{generalized shadow price} if the above property is true\nfor the \\emph{relaxed} utility function in the frictionless model. This\nrelaxation is defined as the lower semicontinuous envelope of the original\nutility, considered as a function on the set $[\\underline S, \\bar{S}]$,\nequipped with some natural weak topology. We prove the existence of a\ngeneralized shadow price under rather weak assumptions and mark its relation to\na saddle point of the trader/market zero-sum game, determined by the relaxed\nutility function. The relation of the notion of a shadow price to its\ngeneralization is illustrated by several examples. Also, we briefly discuss the\ninterpretation of shadow prices via Lagrange duality.\n"
    },
    {
        "paper_id": 1112.2638,
        "authors": "Christian Bender, John Schoenmakers, Jianing Zhang",
        "title": "Dual representations for general multiple stopping problems",
        "comments": "This is an updated version of WIAS preprint 1665, 23 November 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the dual representation for generalized multiple\nstopping problems, hence the pricing problem of general multiple exercise\noptions. We derive a dual representation which allows for cashflows which are\nsubject to volume constraints modeled by integer valued adapted processes and\nrefraction periods modeled by stopping times. As such, this extends the works\nby Schoenmakers (2010), Bender (2011a), Bender (2011b), Aleksandrov and Hambly\n(2010), and Meinshausen and Hambly (2004) on multiple exercise options, which\neither take into consideration a refraction period or volume constraints, but\nnot both simultaneously. We also allow more flexible cashflow structures than\nthe additive structure in the above references. For example some exponential\nutility problems are covered by our setting. We supplement the theoretical\nresults with an explicit Monte Carlo algorithm for constructing confidence\nintervals for the price of multiple exercise options and exemplify it by a\nnumerical study on the pricing of a swing option in an electricity market.\n"
    },
    {
        "paper_id": 1112.2749,
        "authors": "Maxim Bichuch",
        "title": "Asymptotic Analysis for Optimal Investment in Finite Time with\n  Transaction Costs",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an agent who invests in a stock and a money market account with\nthe goal of maximizing the utility of his investment at the final time T in the\npresence of a proportional transaction cost. The utility function considered is\npower utility. We provide a heuristic and a rigorous derivation of the\nasymptotic expansion of the value function in powers of transaction cost\nparameter. We also obtain a \"nearly optimal\" strategy, whose utility\nasymptotically matches the leading terms in the value function.\n"
    },
    {
        "paper_id": 1112.2867,
        "authors": "Marco Duenas and Giorgio Fagiolo",
        "title": "Modeling the International-Trade Network: A Gravity Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates whether the gravity model (GM) can explain the\nstatistical properties of the International Trade Network (ITN). We fit data on\ninternational-trade flows with a GM specification using alternative fitting\ntechniques and we employ GM estimates to build a weighted predicted ITN, whose\ntopological properties are compared to observed ones. Furthermore, we propose\nan estimation strategy to predict the binary ITN with a GM. We find that the GM\nsuccessfully replicates the weighted-network structure of the ITN, only if one\nfixes its binary architecture equal to the observed one. Conversely, the GM\nperforms very badly when asked to predict the presence of a link, or the level\nof the trade flow it carries, whenever the binary structure must be\nsimultaneously estimated.\n"
    },
    {
        "paper_id": 1112.2889,
        "authors": "I. Garcia and J. Jimenez",
        "title": "Estimating financial risk using piecewise Gaussian processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a computational method for measuring financial risk by estimating\nthe Value at Risk and Expected Shortfall from financial series. We have made\ntwo assumptions: First, that the predictive distributions of the values of an\nasset are conditioned by information on the way in which the variable evolves\nfrom similar conditions, and secondly, that the underlying random processes can\nbe described using piecewise Gaussian processes. The performance of the method\nwas evaluated by using it to estimate VaR and ES for a daily data series taken\nfrom the S&P500 index and applying a backtesting procedure recommended by the\nBasel Committee on Banking Supervision. The results indicated a satisfactory\nperformance.\n"
    },
    {
        "paper_id": 1112.2895,
        "authors": "Giorgio Fagiolo, Tiziano Squartini, Diego Garlaschelli",
        "title": "Null Models of Economic Networks: The Case of the World Trade Web",
        "comments": "39 pages, 46 figures, 2 tables",
        "journal-ref": "J. Econ. Interac. Coord. 8 (1), pp. 75-107 (2012)",
        "doi": "10.1007/s11403-012-0104-7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In all empirical-network studies, the observed properties of economic\nnetworks are informative only if compared with a well-defined null model that\ncan quantitatively predict the behavior of such properties in constrained\ngraphs. However, predictions of the available null-model methods can be derived\nanalytically only under assumptions (e.g., sparseness of the network) that are\nunrealistic for most economic networks like the World Trade Web (WTW). In this\npaper we study the evolution of the WTW using a recently-proposed family of\nnull network models. The method allows to analytically obtain the expected\nvalue of any network statistic across the ensemble of networks that preserve on\naverage some local properties, and are otherwise fully random. We compare\nexpected and observed properties of the WTW in the period 1950-2000, when\neither the expected number of trade partners or total country trade is kept\nfixed and equal to observed quantities. We show that, in the binary WTW,\nnode-degree sequences are sufficient to explain higher-order network properties\nsuch as disassortativity and clustering-degree correlation, especially in the\nlast part of the sample. Conversely, in the weighted WTW, the observed sequence\nof total country imports and exports are not sufficient to predict higher-order\npatterns of the WTW. We discuss some important implications of these findings\nfor international-trade models.\n"
    },
    {
        "paper_id": 1112.2939,
        "authors": "Xiang Yu",
        "title": "An Explicit Example Of Optimal Portfolio-Consumption Choices With Habit\n  Formation And Partial Observations",
        "comments": "Key words: Consumption habit formation, Kalman-Bucy filtering,\n  Path-dependent stochastic control, Verification theorem",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a model of optimal investment and consumption with both habit\nformation and partial observations in incomplete It\\^{o} processes market. The\ninvestor chooses his consumption under the addictive habits constraint while\nonly observing the market stock prices but not the instantaneous rate of\nreturn. Applying the Kalman-Bucy filtering theorem and the Dynamic Programming\narguments, we solve the associated Hamilton-Jacobi-Bellman (HJB) equation\nexplicitly for the path dependent stochastic control problem in the case of\npower utilities. We provide the optimal investment and consumption policies in\nexplicit feedback forms using rigorous verification arguments.\n"
    },
    {
        "paper_id": 1112.294,
        "authors": "Xiang Yu",
        "title": "Utility maximization with addictive consumption habit formation in\n  incomplete semimartingale markets",
        "comments": "Published at http://dx.doi.org/10.1214/14-AAP1026 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 3, 1383-1419",
        "doi": "10.1214/14-AAP1026",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the continuous time utility maximization problem on\nconsumption with addictive habit formation in incomplete semimartingale\nmarkets. Introducing the set of auxiliary state processes and the modified dual\nspace, we embed our original problem into a time-separable utility maximization\nproblem with a shadow random endowment on the product space\n$\\mathbb{L}_+^0(\\Omega\\times [0,T],\\mathcal{O},\\overline{\\mathbb{P}})$.\nExistence and uniqueness of the optimal solution are established using convex\nduality approach, where the primal value function is defined on two variables,\nthat is, the initial wealth and the initial standard of living. We also provide\nsufficient conditions on the stochastic discounting processes and on the\nutility function for the well-posedness of the original optimization problem.\nUnder the same assumptions, classical proofs in the approach of convex duality\nanalysis can be modified when the auxiliary dual process is not necessarily\nintegrable.\n"
    },
    {
        "paper_id": 1112.2952,
        "authors": "Lijun Bo, Ying Jiao (LPMA), Xuewei Yang",
        "title": "Credit derivatives pricing with default density term structure modelled\n  by L\\'evy random fields",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We model the term structure of the forward default intensity and the default\ndensity by using L\\'evy random fields, which allow us to consider the credit\nderivatives with an after-default recovery payment. As applications, we study\nthe pricing of a defaultable bond and represent the pricing kernel as the\nunique solution of a parabolic integro-differential equation. Finally, we\nillustrate by numerical examples the impact of the contagious jump risks on the\ndefaultable bond price in our model.\n"
    },
    {
        "paper_id": 1112.2984,
        "authors": "Peter Klimek, Ricardo Hausmann, Stefan Thurner",
        "title": "Empirical confirmation of creative destruction from world trade data",
        "comments": "16 pages (main text), 6 figures",
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0038924",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that world trade network datasets contain empirical evidence that the\ndynamics of innovation in the world economy follows indeed the concept of\ncreative destruction, as proposed by J.A. Schumpeter more than half a century\nago. National economies can be viewed as complex, evolving systems, driven by a\nstream of appearance and disappearance of goods and services. Products appear\nin bursts of creative cascades. We find that products systematically tend to\nco-appear, and that product appearances lead to massive disappearance events of\nexisting products in the following years. The opposite - disappearances\nfollowed by periods of appearances - is not observed. This is an empirical\nvalidation of the dominance of cascading competitive replacement events on the\nscale of national economies, i.e. creative destruction. We find a tendency that\nmore complex products drive out less complex ones, i.e. progress has a\ndirection. Finally we show that the growth trajectory of a country's product\noutput diversity can be understood by a recently proposed evolutionary model of\nSchumpeterian economic dynamics.\n"
    },
    {
        "paper_id": 1112.3012,
        "authors": "Maxim Bichuch",
        "title": "Pricing a Contingent Claim Liability with Transaction Costs Using\n  Asymptotic Analysis for Optimal Investment",
        "comments": "24 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We price a contingent claim liability using the utility indifference\nargument. We consider an agent with exponential utility, who invests in a stock\nand a money market account with the goal of maximizing the utility of his\ninvestment at the final time T in the presence of positive proportional\ntransaction cost in two cases with and without a contingent claim liability.\nUsing the computations from the heuristic argument in Whalley & Wilmott we\nprovide a rigorous derivation of the asymptotic expansion of the value function\nin powers of the transaction cost parameter around the known value function for\nthe case of zero transaction cost in both cases with and without a contingent\nclaim liability. Additionally, using utility indifference method we derive an\nasymptotic expansion of the price of the contingent claim liability. In both\ncases, we also obtain a \"nearly optimal\" strategy, whose expected utility\nasymptotically matches the leading terms of the value function.\n"
    },
    {
        "paper_id": 1112.3095,
        "authors": "Vedant Misra, Marco Lagi, and Yaneer Bar-Yam",
        "title": "Evidence of market manipulation in the financial crisis",
        "comments": "21 pages, 5 figures, Addendum",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide direct evidence of market manipulation at the beginning of the\nfinancial crisis in November 2007. The type of manipulation, a \"bear raid,\"\nwould have been prevented by a regulation that was repealed by the Securities\nand Exchange Commission in July 2007. The regulation, the uptick rule, was\ndesigned to prevent manipulation and promote stability and was in force from\n1938 as a key part of the government response to the 1929 market crash and its\naftermath. On November 1, 2007, Citigroup experienced an unusual increase in\ntrading volume and decrease in price. Our analysis of financial industry data\nshows that this decline coincided with an anomalous increase in borrowed\nshares, the selling of which would be a large fraction of the total trading\nvolume. The selling of borrowed shares cannot be explained by news events as\nthere is no corresponding increase in selling by share owners. A similar number\nof shares were returned on a single day six days later. The magnitude and\ncoincidence of borrowing and returning of shares is evidence of a concerted\neffort to drive down Citigroup's stock price and achieve a profit, i.e., a bear\nraid. Interpretations and analyses of financial markets should consider the\npossibility that the intentional actions of individual actors or coordinated\ngroups can impact market behavior. Markets are not sufficiently transparent to\nreveal even major market manipulation events. Our results point to the need for\nregulations that prevent intentional actions that cause markets to deviate from\nequilibrium and contribute to crashes. Enforcement actions cannot reverse\nsevere damage to the economic system. The current \"alternative\" uptick rule\nwhich is only in effect for stocks dropping by over 10% in a single day is\ninsufficient. Prevention may be achieved through improved availability of\nmarket data and the original uptick rule or other transaction limitations.\n"
    },
    {
        "paper_id": 1112.3111,
        "authors": "Jos\\'e E. Figueroa-L\\'opez, Ruoting Gong, and Christian Houdr\\'e",
        "title": "High-order short-time expansions for ATM option prices under the CGMY\n  model",
        "comments": "Corrects Proposition 4.5 (former Proposition 4.3) as well as other\n  typos; For a generalization of this manuscript, see arXiv:1208.5520v1\n  [q-fin.PR]",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The short-time asymptotic behavior of option prices for a variety of models\nwith jumps has received much attention in recent years. In the present work, a\nnovel second-order approximation for ATM option prices under the CGMY L\\'evy\nmodel is derived, and then extended to a model with an additional independent\nBrownian component. Our results shed light on the connection between both the\nvolatility of the continuous component and the jump parameters and the behavior\nof ATM option prices near expiration. In case of an additional Brownian\ncomponent, the second-order term, in time-t, is of the form $ d_{2}\nt^{(3-Y)/2}$, with the coefficient $d_{2}$ depending only on the overall jump\nintensity parameter C and the tail-heaviness parameter Y. This extends the\nknown result that the leading term is $(\\sigma/\\sqrt{2\\pi})t^{1/2}$, where\n$\\sigma$ is the volatility of the continuous component. In contrast, under a\npure-jump CGMY model, the dependence on the two parameters C and Y is already\nreflected in the leading term, which is of the form $d_{1} t^{1/Y}$.\nInformation on the relative frequency of negative and positive jumps appears\nonly in the second-order term, which is shown to be of the form $d_{2} t$ and\nwhose order of decay turns out to be independent of Y. The third-order\nasymptotic behavior of the option prices as well as the asymptotic behavior of\nthe corresponding Black-Scholes implied volatilities are also addressed. Our\nnumerical results show that in most cases the second-order term significantly\noutperform the first-order approximation.\n"
    },
    {
        "paper_id": 1112.3217,
        "authors": "T. K. Jana and P. Roy",
        "title": "Pseudo Hermitian formulation of Black-Scholes equation",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.12.012",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that the non Hermitian Black-Scholes Hamiltonian and its various\ngeneralizations are eta-pseudo Hermitian. The metric operator eta is explicitly\nconstructed for this class of Hamitonians. It is also shown that the effective\nBlack-Scholes Hamiltonian and its partner form a pseudo supersymmetric system.\n"
    },
    {
        "paper_id": 1112.3868,
        "authors": "Vladimir Filimonov, Didier Sornette",
        "title": "Spurious trend switching phenomena in financial markets",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1140/epjb/e2012-21060-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The observation of power laws in the time to extrema of volatility, volume\nand intertrade times, from milliseconds to years, are shown to result\nstraightforwardly from the selection of biased statistical subsets of\nrealizations in otherwise featureless processes such as random walks. The bias\nstems from the selection of price peaks that imposes a condition on the\nstatistics of price change and of trade volumes that skew their distributions.\nFor the intertrade times, the extrema and power laws results from the format of\ntransaction data.\n"
    },
    {
        "paper_id": 1112.3908,
        "authors": "Andre Cardoso Barato, Iacopo Mastromatteo, Marco Bardoscia and Matteo\n  Marsili",
        "title": "Impact of meta-order in the Minority Game",
        "comments": "18 pages, 4 figures",
        "journal-ref": "Quantitative Finance 13-9 (2013), pp. 1343-1352",
        "doi": "10.1080/14697688.2012.756146",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the market impact of a meta-order in the framework of the Minority\nGame. This amounts to studying the response of the market when introducing a\ntrader who buys or sells a fixed amount h for a finite time T. This\nperturbation introduces statistical arbitrages that traders exploit by adapting\ntheir trading strategies. The market impact depends on the nature of the\nstationary state: We find that the permanent impact is zero in the\nunpredictable (information efficient) phase, while in the predictable phase it\nis non-zero and grows linearly with the size of the meta-order. This\nestablishes a quantitative link between information efficiency and trading\nefficiency (i.e. market impact). By using statistical mechanics methods for\ndisordered systems, we are able to fully characterize the response in the\npredictable phase, to relate execution cost to response functions and obtain\nexact results for the permanent impact.\n"
    },
    {
        "paper_id": 1112.4005,
        "authors": "Shangzhen Luo and Michael Taksar",
        "title": "Minimal Cost of a Brownian Risk without Ruin",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study a risk process modeled by a Brownian motion with\ndrift (the diffusion approximation model). The insurance entity can purchase\nreinsurance to lower its risk and receive cash injections at discrete times to\navoid ruin. Proportional reinsurance and excess-of-loss reinsurance are\nconsidered. The objective is to find the optimal reinsurance and cash injection\nstrategy that minimizes the total cost to keep the company's surplus process\nnon-negative, i.e. without ruin, where the cost function is defined as the\ntotal discounted value of the injections. The optimal solution is found\nexplicitly by solving the according quasi-variational inequalities (QVIs).\n"
    },
    {
        "paper_id": 1112.4007,
        "authors": "Tatiana Belkina, Christian Hipp, Shangzhen Luo, Michael Taksar",
        "title": "Optimal Constrained Investment in the Cramer-Lundberg model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an insurance company whose surplus is represented by the\nclassical Cramer-Lundberg process. The company can invest its surplus in a risk\nfree asset and in a risky asset, governed by the Black-Scholes equation. There\nis a constraint that the insurance company can only invest in the risky asset\nat a limited leveraging level; more precisely, when purchasing, the ratio of\nthe investment amount in the risky asset to the surplus level is no more than\na; and when shortselling, the proportion of the proceeds from the short-selling\nto the surplus level is no more than b. The objective is to find an optimal\ninvestment policy that minimizes the probability of ruin. The minimal ruin\nprobability as a function of the initial surplus is characterized by a\nclassical solution to the corresponding Hamilton-Jacobi-Bellman (HJB) equation.\nWe study the optimal control policy and its properties. The interrelation\nbetween the parameters of the model plays a crucial role in the qualitative\nbehavior of the optimal policy. E.g., for some ratios between a and b, quite\nunusual and at first ostensibly counterintuitive policies may appear, like\nshort-selling a stock with a higher rate of return to earn lower interest, or\nborrowing at a higher rate to invest in a stock with lower rate of return. This\nis in sharp contrast with the unrestricted case, first studied in Hipp and Plum\n(2000), or with the case of no shortselling and no borrowing studied in Azcue\nand Muler (2009).\n"
    },
    {
        "paper_id": 1112.4027,
        "authors": "Chang-Shuai Li",
        "title": "Analysis of hedging based on co-persistence theory",
        "comments": "There are some mistakes in our estimation",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article analyzes the relationship between co-persistence and hedging\nwhich indicates co-persistence ratio is just the long-term hedging ratio. The\nnew method of exhaustive search algorithm for deriving co-persistence ratio is\nderived in the article. And we also develop a new hedging strategy of combining\nco-persistence with dynamic hedging which can enhance the hedging effectiveness\nand reduce the persistence of the hedged portfolio. Finally our strategy is\nillustrated to study the hedge of JIASHI300 index and HS300 stock index future .\n"
    },
    {
        "paper_id": 1112.4351,
        "authors": "Lajos Gergely Gyurko, Ben Hambly, Jan Hendrik Witte",
        "title": "Monte Carlo methods via a dual approach for some discrete time\n  stochastic control problems",
        "comments": "24 Pages, 6 Figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a class of discrete time stochastic control problems motivated by\nsome financial applications. We use a pathwise stochastic control approach to\nprovide a dual formulation of the problem. This enables us to develop a\nnumerical technique for obtaining an estimate of the value function which\nimproves on purely regression based methods. We demonstrate the competitiveness\nof the method on the example of a gas storage valuation problem.\n"
    },
    {
        "paper_id": 1112.4385,
        "authors": "Attila Herczegh, Vilmos Prokaj",
        "title": "Shadow price in the power utility case",
        "comments": "Published at http://dx.doi.org/10.1214/14-AAP1058 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 5, 2671-2707",
        "doi": "10.1214/14-AAP1058",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of maximizing expected power utility from consumption\nover an infinite horizon in the Black-Scholes model with proportional\ntransaction costs, as studied in Shreve and Soner [Ann. Appl. Probab. 4 (1994)\n609-692]. Similar to Kallsen and Muhle-Karbe [Ann. Appl. Probab. 20 (2010)\n1341-1358], we derive a shadow price, that is, a frictionless price process\nwith values in the bid-ask spread which leads to the same optimal policy.\n"
    },
    {
        "paper_id": 1112.4534,
        "authors": "Cristin Buescu, Michael Taksar and Fatoumata J. Kon\\'e",
        "title": "An application of the method of moments to volatility estimation using\n  daily high, low, opening and closing prices",
        "comments": "19 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use the expectation of the range of an arithmetic Brownian motion and the\nmethod of moments on the daily high, low, opening and closing prices to\nestimate the volatility of the stock price. The daily price jump at the opening\nis considered to be the result of the unobserved evolution of an after-hours\nvirtual trading day.The annualized volatility is used to calculate\nBlack-Scholes prices for European options, and a trading strategy is devised to\nprofit when these prices differ flagrantly from the market prices.\n"
    },
    {
        "paper_id": 1112.474,
        "authors": "Adrien Nguyen Huu (CEREMADE, FiME)",
        "title": "A note on super-hedging for investor-producers",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the situation of an agent who can trade on a financial market and\ncan also transform some assets into others by means of a production system, in\norder to price and hedge derivatives on produced goods. This framework is\nmotivated by the case of an electricity producer who wants to hedge a position\non the electricity spot price and can trade commodities which are inputs for\nhis system. This extends the essential results of Bouchard & Nguyen Huu (2011)\nto continuous time markets. We introduce the generic concept of conditional\nsure profit along the idea of the no sure profit condition of R\\`asonyi (2009).\nThe condition allows one to provide a closedness property for the set of\nsuper-hedgeable claims in a very general financial setting. Using standard\nseparation arguments, we then deduce a dual characterization of the latter and\nprovide an application to power futures pricing.\n"
    },
    {
        "paper_id": 1112.4824,
        "authors": "Paul M. N. Feehan and Camelia Pop",
        "title": "A Schauder approach to degenerate-parabolic partial differential\n  equations with unbounded coefficients",
        "comments": "42 pages; corresponds to Part 1 of our previous article\n  [arxiv.org:1112.4824v1]. Incorporates final galley proof corrections\n  corresponding to published version",
        "journal-ref": "Journal of Differential Equations 254 (2013), 4401-4445",
        "doi": "10.1016/j.jde.2013.03.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by applications to probability and mathematical finance, we\nconsider a parabolic partial differential equation on a half-space whose\ncoefficients are suitably Holder continuous and allowed to grow linearly in the\nspatial variable and which become degenerate along the boundary of the\nhalf-space. We establish existence and uniqueness of solutions in weighted\nHolder spaces which incorporate both the degeneracy at the boundary and the\nunboundedness of the coefficients. In our companion article [arXiv:1211.4636],\nwe apply the main result of this article to show that the martingale problem\nassociated with a degenerate-elliptic partial differential operator is\nwell-posed in the sense of Stroock and Varadhan.\n"
    },
    {
        "paper_id": 1112.533,
        "authors": "Philipp Doersek and Josef Teichmann",
        "title": "Efficient simulation and calibration of general HJM models by splitting\n  schemes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce efficient numerical methods for generic HJM equations of\ninterest rate theory by means of high-order weak approximation schemes. These\nschemes allow for QMC implementations due to the relatively low dimensional\nintegration space. The complexity of the resulting algorithm is considerably\nlower than the complexity of multi-level MC algorithms as long as the optimal\norder of QMC-convergence is guaranteed. In order to make the methods applicable\nto real world problems, we introduce and use the setting of weighted function\nspaces, such that unbounded payoffs and unbounded characteristics of the\nequations in question are still allowed. We also provide an implementation,\nwhere we efficiently calibrate an HJM equation to caplet data.\n"
    },
    {
        "paper_id": 1112.534,
        "authors": "Winslow Strong",
        "title": "Fundamental theorems of asset pricing for piecewise semimartingales of\n  stochastic dimension",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this paper is two-fold. First is to extend the notions of an\nn-dimensional semimartingale and its stochastic integral to a piecewise\nsemimartingale of stochastic dimension. The properties of the former carry over\nlargely intact to the latter, avoiding some of the pitfalls of\ninfinite-dimensional stochastic integration. Second is to extend two\nfundamental theorems of asset pricing (FTAPs): the equivalence of no free lunch\nwith vanishing risk to the existence of an equivalent sigma-martingale measure\nfor the price process, and the equivalence of no arbitrage of the first kind to\nthe existence of an equivalent local martingale deflator for the set of\nnonnegative wealth processes.\n"
    },
    {
        "paper_id": 1112.555,
        "authors": "Dirk Tasche",
        "title": "Bayesian estimation of probabilities of default for low default\n  portfolios",
        "comments": "29 pages, 1 figure, 4 tables, minor corrections",
        "journal-ref": "Journal of Risk Management in Financial Institutions 6 (3),\n  302-326, 2013",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The estimation of probabilities of default (PDs) for low default portfolios\nby means of upper confidence bounds is a well established procedure in many\nfinancial institutions. However, there are often discussions within the\ninstitutions or between institutions and supervisors about which confidence\nlevel to use for the estimation. The Bayesian estimator for the PD based on the\nuninformed, uniform prior distribution is an obvious alternative that avoids\nthe choice of a confidence level. In this paper, we demonstrate that in the\ncase of independent default events the upper confidence bounds can be\nrepresented as quantiles of a Bayesian posterior distribution based on a prior\nthat is slightly more conservative than the uninformed prior. We then describe\nhow to implement the uninformed and conservative Bayesian estimators in the\ndependent one- and multi-period default data cases and compare their estimates\nto the upper confidence bound estimates. The comparison leads us to suggest a\nconstrained version of the uninformed (neutral) Bayesian estimator as an\nalternative to the upper confidence bound estimators.\n"
    },
    {
        "paper_id": 1112.5687,
        "authors": "Hamed Amini, Rama Cont, Andreea Minca",
        "title": "Resilience to Contagion in Financial Networks",
        "comments": "40 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1111/mafi.12051",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Propagation of balance-sheet or cash-flow insolvency across financial\ninstitutions may be modeled as a cascade process on a network representing\ntheir mutual exposures. We derive rigorous asymptotic results for the magnitude\nof contagion in a large financial network and give an analytical expression for\nthe asymptotic fraction of defaults, in terms of network characteristics. Our\nresults extend previous studies on contagion in random graphs to inhomogeneous\ndirected graphs with a given degree sequence and arbitrary distribution of\nweights. We introduce a criterion for the resilience of a large financial\nnetwork to the insolvency of a small group of financial institutions and\nquantify how contagion amplifies small shocks to the network. Our results\nemphasize the role played by \"contagious links\" and show that institutions\nwhich contribute most to network instability in case of default have both large\nconnectivity and a large fraction of contagious links. The asymptotic results\nshow good agreement with simulations for networks with realistic sizes.\n"
    },
    {
        "paper_id": 1112.5711,
        "authors": "Alessandro Spelta and Tanya Ara\\'ujo",
        "title": "The topology of cross-border exposures: beyond the minimal spanning tree\n  approach",
        "comments": "22 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.05.071",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The recent financial crisis has stressed the need to understand financial\nsystems as networks of interdependent countries, where cross-border financial\nlinkages play the fundamental role. It has also been emphasized that the\nrelevance of these networks relies on the representation of changes follow-on\nthe occurrence of stress events. Adopting a topological approach we are able to\naddress the role that network structures play in the spread of shocks and\nconversely, the effectiveness of stress events and its impact on the structure\nof the networks. Here, from series of interbank liabilities and claims over\ndifferent time periods, we have developed networks of positions (net claims)\nbetween countries. Besides the Minimal Spanning Tree analysis of the\ntime-constrained networks, a coefficient of residuality is defined to capture\nthe structural evolution of the network of cross-border financial linkages.\nBecause some structural changes seem to be related to the role that countries\nplay in the financial context, networks of debtor and creditor countries are\nalso developed. Empirical results allows to relate the network structure that\nemerges in the last years to the globally turbulent period that has\ncharacterized financial systems since the latest nineties. The residuality\ncoefficient highlights an important modification acting in the financial\nlinkages across countries in the period 1997-2011, and situates the recent\nfinancial crises as replica of a larger structural change going on since 1997.\n"
    },
    {
        "paper_id": 1112.5766,
        "authors": "Pavel V. Shevchenko and Xiaolin Luo",
        "title": "Dependent default and recovery: MCMC study of downturn LGD credit risk\n  model",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1011.2827",
        "journal-ref": "ANZIAM Journal 53, pp. C185-C202, 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There is empirical evidence that recovery rates tend to go down just when the\nnumber of defaults goes up in economic downturns. This has to be taken into\naccount in estimation of the capital against credit risk required by Basel II\nto cover losses during the adverse economic downturns; the so-called \"downturn\nLGD\" requirement. This paper presents estimation of the LGD credit risk model\nwith default and recovery dependent via the latent systematic risk factor using\nBayesian inference approach and Markov chain Monte Carlo method. This approach\nallows joint estimation of all model parameters and latent systematic factor,\nand all relevant uncertainties. Results using Moody's annual default and\nrecovery rates for corporate bonds for the period 1982-2010 show that the\nimpact of parameter uncertainty on economic capital can be very significant and\nshould be assessed by practitioners.\n"
    },
    {
        "paper_id": 1112.585,
        "authors": "Rod Cross, Victor Kozyakin, Brian O'Callaghan, Alexei Pokrovskii,\n  Alexey Pokrovskiy",
        "title": "Periodic Sequences of Arbitrage: A Tale of Four Currencies",
        "comments": "35 pages, 48 bibliography references, submitted to Metroeconomica",
        "journal-ref": "Metroeconomica 63:2 (2012), pp. 250-294",
        "doi": "10.1111/j.1467-999X.2011.04140.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates arbitrage chains involving four currencies and four\nforeign exchange trader-arbitrageurs. In contrast with the three-currency case,\nwe find that arbitrage operations when four currencies are present may appear\nperiodic in nature, and not involve smooth convergence to a \"balanced\" ensemble\nof exchange rates in which the law of one price holds. The goal of this article\nis to understand some interesting features of sequences of arbitrage\noperations, features which might well be relevant in other contexts in finance\nand economics.\n"
    },
    {
        "paper_id": 1112.6024,
        "authors": "Zal\\'an Forr\\'o, Peter Cauwels and Didier Sornette",
        "title": "Valuation of Zynga",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  On December 16, Zynga, the well-known social game developing company went\npublic. This event is following other recent IPOs in the world of social\nnetworking companies, such as Groupon, Linkedin or Pandora to cite a few. With\na valuation close to 7 billion USD at the time when it went public, Zynga has\nbecome the biggest web IPO since Google. This recent enthusiasm for social\nnetworking companies, and in particular Zynga, brings up the question whether\nor not they are overvalued. The common denominator of all these IPOs is that a\nlot of estimates about their valuation have been circulating, without any\nspecifics given about the methodology or assumptions used to obtain those\nnumbers. To bring more substance to the debate, we propose a two-tiered\napproach. First, we introduce a new model to forecast the global user base of\nZynga, based on the analysis of the individual dynamics of its major games.\nNext, we model the revenues per user using a logistic growth function, a\nstandard model for growth in competition. This leads to bracket the valuation\nof Zynga using three different scenarios (base one, optimistic and very\noptimistic): 4.17 billion USD in the base case, 5.16 billion in the high growth\nand 7.02 billion in the extreme growth scenario respectively. Thus, only the\nunlikely extreme growth scenario could potentially justify today's 6.6 billion\nUSD valuation of Zynga. This suggests that Zynga at its IPO has been\noverpriced.\n"
    },
    {
        "paper_id": 1112.6085,
        "authors": "Gao-Feng Gu (ECUST), Xiong Xiong (TJU), Fei Ren (ECUST), Wei-Xing Zhou\n  (ECUST), Wei Zhang (TJU)",
        "title": "The position profiles of order cancellations in an emerging stock market",
        "comments": "17 pages, 6 figures and 6 tables",
        "journal-ref": "The Journal of Statistical Mechanics: Theory and Experiment\n  (JSTAT), 2013, P04027",
        "doi": "10.1088/1742-5468/2013/04/P04027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Order submission and cancellation are two constituent actions of stock\ntrading behaviors in order-driven markets. Order submission dynamics has been\nextensively studied for different markets, while order cancellation dynamics is\nless understood. There are two positions associated with a cancellation, that\nis, the price level in the limit-order book (LOB) and the position in the queue\nat each price level. We study the profiles of these two order cancellation\npositions through rebuilding the limit-order book using the order flow data of\n23 liquid stocks traded on the Shenzhen Stock Exchange in the year 2003. We\nfind that the profiles of relative price levels where cancellations occur obey\na log-normal distribution. After normalizing the relative price level by\nremoving the factor of order numbers stored at the price level, we find that\nthe profiles exhibit a power-law scaling behavior on the right tails for both\nbuy and sell orders. When focusing on the order cancellation positions in the\nqueue at each price level, we find that the profiles increase rapidly in the\nfront of the queue, and then fluctuate around a constant value till the end of\nthe queue. These profiles are similar for different stocks. In addition, the\nprofiles of cancellation positions can be fitted by an exponent function for\nboth buy and sell orders. These two kinds of cancellation profiles seem\nuniversal for different stocks investigated and exhibit minor asymmetry between\nbuy and sell orders. Our empirical findings shed new light on the order\ncancellation dynamics and pose constraints on the construction of order-driven\nstock market models.\n"
    },
    {
        "paper_id": 1112.6169,
        "authors": "Alexandros Gabrielsen, Massimiliano Marzo, Paolo Zagaglia",
        "title": "Measuring market liquidity: An introductory survey",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Asset liquidity in modern financial markets is a key but elusive concept. A\nmarket is often said to be liquid when the prevailing structure of transactions\nprovides a prompt and secure link between the demand and supply of assets, thus\ndelivering low costs of transaction. Providing a rigorous and empirically\nrelevant definition of market liquidity has, however, provided to be a\ndifficult task. This paper provides a critical review of the frameworks\ncurrently available for modelling and estimating the market liquidity of\nassets. We consider definitions that stress the role of the bid-ask spread and\nthe estimation of its components that arise from alternative sources of market\nfriction. In this case, intra-daily measures of liquidity appear relevant for\ncapturing the core features of a market, and for their ability to describe the\narrival of new information to market participants.\n"
    },
    {
        "paper_id": 1112.639,
        "authors": "Reason Lesego Machete",
        "title": "Early Warning with Calibrated and Sharper Probabilistic Forecasts",
        "comments": "23 pages, 3 figures. Accepted for publication in Journal of\n  Forecasting",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Given a nonlinear model, a probabilistic forecast may be obtained by Monte\nCarlo simulations. At a given forecast horizon, Monte Carlo simulations yield\nsets of discrete forecasts, which can be converted to density forecasts. The\nresulting density forecasts will inevitably be downgraded by model\nmis-specification. In order to enhance the quality of the density forecasts,\none can mix them with the unconditional density. This paper examines the value\nof combining conditional density forecasts with the unconditional density. The\nfindings have positive implications for issuing early warnings in different\ndisciplines including economics and meteorology, but UK inflation forecasts are\nconsidered as an example.\n"
    },
    {
        "paper_id": 1201.0075,
        "authors": "Xiaoshan Chen, Qingshuo Song, Fahuai Yi, George Yin",
        "title": "Indifference Pricing of American Option Underlying Illiquid Stock under\n  Exponential Forward Performance",
        "comments": "23 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work focuses on the indifference pricing of American call option\nunderlying a non-traded stock, which may be partially hedgeable by another\ntraded stock. Under the exponential forward measure, the indifference price is\nformulated as a stochastic singular control problem. The value function is\ncharacterized as the unique solution of a partial differential equation in a\nSobolev space. Together with some regularities and estimates of the value\nfunction, the existence of the optimal strategy is also obtained. The\napplications of the characterization result includes a derivation of a dual\nrepresentation and the indifference pricing on employee stock option. As a\nbyproduct, a generalized Ito's formula is obtained for functions in a Sobolev\nspace.\n"
    },
    {
        "paper_id": 1201.0106,
        "authors": "Richard J Martin",
        "title": "Saddlepoint methods in portfolio theory",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the use of saddlepoint methods in the analysis of portfolios, with\nparticular reference to credit portfolios. The objective is to proceed from a\nmodel of the loss distribution, given through probabilities, correlations and\nthe like, to an analytical approximation of the distribution. Once this is done\nwe show how to derive the so-called risk contributions which are the\nderivatives of risk measures, such as a given quantile (VaR) or expected\nshortfall, to the allocations in the underlying assets. These show, informally,\nwhere the risk is coming from, and also indicate how to go about optimising the\nportfolio.\n"
    },
    {
        "paper_id": 1201.0111,
        "authors": "Richard J Martin",
        "title": "A CDS Option Miscellany",
        "comments": "Minor corrections from 2017 version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  CDS options allow investors to express a view on spread volatility and obtain\na wider range of payoffs than are possible with vanilla CDS. We give a detailed\nexposition of different types of single-name CDS option, including options with\nupfront protection payment, recovery options and recovery swaps, and also\npresents a new formula for the index option. The emphasis is on using the\nBlack-76 formula where possible and ensuring consistency within asset classes.\nIn the framework shown here the `armageddon event' does not require special\nattention.\n"
    },
    {
        "paper_id": 1201.0433,
        "authors": "W.-X. Zhou (ECUST), G.-H. Mu (ECUST), J. Kert\\'esz (BME)",
        "title": "Random matrix approach to the dynamics of stock inventory variations",
        "comments": "10 REVTEX pages including 7 figures",
        "journal-ref": "New Journal of Physics 14 (9), 093025 (2012)",
        "doi": "10.1088/1367-2630/14/9/093025",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the cross-correlation matrix $C_{ij}$ of inventory variations of the\nmost active individual and institutional investors in an emerging market to\nunderstand the dynamics of inventory variations. We find that the distribution\nof cross-correlation coefficient $C_{ij}$ has a power-law form in the bulk\nfollowed by exponential tails and there are more positive coefficients than\nnegative ones. In addition, it is more possible that two individuals or two\ninstitutions have stronger inventory variation correlation than one individual\nand one institution. We find that the largest and the second largest\neigenvalues ($\\lambda_1$ and $\\lambda_2$) of the correlation matrix cannot be\nexplained by the random matrix theory and the projection of inventory\nvariations on the first eigenvector $u(\\lambda_1)$ are linearly correlated with\nstock returns, where individual investors play a dominating role. The investors\nare classified into three categories based on the cross-correlation\ncoefficients $C_{VR}$ between inventory variations and stock returns. Half\nindividuals are reversing investors who exhibit evident buy and sell herding\nbehaviors, while 6% individuals are trending investors. For institutions, only\n10% and 8% investors are trending and reversing investors. A strong Granger\ncausality is unveiled from stock returns to inventory variations, which means\nthat a large proportion of individuals hold the reversing trading strategy and\na small part of individuals hold the trending strategy. Comparing with the case\nof Spanish market, Chinese investors exhibit common and market-specific\nbehaviors. Our empirical findings have scientific significance in the\nunderstanding of investors' trading behaviors and in the construction of\nagent-based models for stock markets.\n"
    },
    {
        "paper_id": 1201.0625,
        "authors": "Leonidas Sandoval Junior, Adriana Bruscato, Maria Kelly Venezuela",
        "title": "Building portfolios of stocks in the S\\~ao Paulo Stock Exchange using\n  Random Matrix Theory",
        "comments": "23 pages",
        "journal-ref": "Physica A 410 (2013) 94-109",
        "doi": "10.1016/j.physa.2014.05.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By using Random Matrix Theory, we build covariance matrices between stocks of\nthe BM&F-Bovespa (Bolsa de Valores, Mercadorias e Futuros de S\\~ao Paulo) which\nare cleaned of some of the noise due to the complex interactions between the\nmany stocks and the finiteness of available data. We also use a regression\nmodel in order to remove the market effect due to the common movement of all\nstocks. These two procedures are then used to build stock portfolios based on\nMarkowitz's theory, trying to obtain better predictions of future risk based on\npast data. This is done for years of both low and high volatility of the\nBrazilian stock market, from 2004 to 2010. The results show that the use of\nregression to subtract the market effect on returns greatly increases the\naccuracy of the prediction of risk, and that, although the cleaning of the\ncorrelation matrix often leads to portfolios that better predict risks, in\nperiods of high volatility of the market this procedure may fail to do so.\n"
    },
    {
        "paper_id": 1201.0769,
        "authors": "Anis Matoussi, Dylan Possama\\\"i, Chao Zhou",
        "title": "Robust utility maximization in non-dominated models with 2BSDEs",
        "comments": "31 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of robust utility maximization in an incomplete market with\nvolatility uncertainty is considered, in the sense that the volatility of the\nmarket is only assumed to lie between two given bounds. The set of all possible\nmodels (probability measures) considered here is non-dominated. We propose\nstudying this problem in the framework of second-order backward stochastic\ndifferential equations (2BSDEs for short) with quadratic growth generators. We\nshow for exponential, power and logarithmic utilities that the value function\nof the problem can be written as the initial value of a particular 2BSDE and\nprove existence of an optimal strategy. Finally several examples which shed\nmore light on the problem and its links with the classical utility maximization\none are provided. In particular, we show that in some cases, the upper bound of\nthe volatility interval plays a central role, exactly as in the option pricing\nproblem with uncertain volatility models of [2].\n"
    },
    {
        "paper_id": 1201.0967,
        "authors": "Daniel Kapp and Marco Vega",
        "title": "Real Output Costs of Financial Crises: A Loss Distribution Approach",
        "comments": "31 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study cross-country GDP losses due to financial crises in terms of\nfrequency (number of loss events per period) and severity (loss per\noccurrence). We perform the Loss Distribution Approach (LDA) to estimate a\nmulti-country aggregate GDP loss probability density function and the\npercentiles associated to extreme events due to financial crises.\n  We find that output losses arising from financial crises are strongly\nheterogeneous and that currency crises lead to smaller output losses than debt\nand banking crises.\n  Extreme global financial crises episodes, occurring with a one percent\nprobability every five years, lead to losses between 2.95% and 4.54% of world\nGDP.\n"
    },
    {
        "paper_id": 1201.1151,
        "authors": "Fred Espen Benth, Claudia Kl\\\"uppelberg, Gernot M\\\"uller, Linda Vos",
        "title": "Futures pricing in electricity markets based on stable CARMA spot models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new model for the electricity spot price dynamics, which is able\nto capture seasonality, low-frequency dynamics and the extreme spikes in the\nmarket. Instead of the usual purely deterministic trend we introduce a\nnon-stationary independent increments process for the low-frequency dynamics,\nand model the large fluctuations by a non-Gaussian stable CARMA process. The\nmodel allows for analytic futures prices, and we apply these to model and\nestimate the whole market consistently. Besides standard parameter estimation,\nan estimation procedure is suggested, where we fit the non-stationary trend\nusing futures data with long time until delivery, and a robust $L^1$-filter to\nfind the states of the CARMA process. The procedure also involves the empirical\nand theoretical risk premiums which -- as a by-product -- are also estimated.\nWe apply this procedure to data from the German electricity exchange EEX, where\nwe split the empirical analysis into base load and peak load prices. We find an\noverall negative risk premium for the base load futures contracts, except for\ncontracts close to delivery, where a small positive risk premium is detected.\nThe peak load contracts, on the other hand, show a clear positive risk premium,\nwhen they are close to delivery, while the contracts in the longer end also\nhave a negative premium.\n"
    },
    {
        "paper_id": 1201.1215,
        "authors": "Tiziano Squartini, Diego Garlaschelli",
        "title": "Triadic motifs and dyadic self-organization in the World Trade Network",
        "comments": "12 pages, 3 figures; Best Paper Award at the 6th International\n  Conference on Self-Organizing Systems, Delft, The Netherlands, 15-16/03/2012",
        "journal-ref": "in Self-Organizing Systems (series: Lec. Notes Comp. Science\n  7166/2012), chapter 3, pp. 24-35, Springer (edited by F. A. Kuipers and P. E.\n  Heegaard) (2012)",
        "doi": "10.1007/978-3-642-28583-7_3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In self-organizing networks, topology and dynamics coevolve in a continuous\nfeedback, without exogenous driving. The World Trade Network (WTN) is one of\nthe few empirically well documented examples of self-organizing networks: its\ntopology strongly depends on the GDP of world countries, which in turn depends\non the structure of trade. Therefore, understanding which are the key\ntopological properties of the WTN that deviate from randomness provides direct\nempirical information about the structural effects of self-organization. Here,\nusing an analytical pattern-detection method that we have recently proposed, we\nstudy the occurrence of triadic \"motifs\" (subgraphs of three vertices) in the\nWTN between 1950 and 2000. We find that, unlike other properties, motifs are\nnot explained by only the in- and out-degree sequences. By contrast, they are\ncompletely explained if also the numbers of reciprocal edges are taken into\naccount. This implies that the self-organization process underlying the\nevolution of the WTN is almost completely encoded into the dyadic structure,\nwhich strongly depends on reciprocity.\n"
    },
    {
        "paper_id": 1201.1437,
        "authors": "Carmelo Vaccaro",
        "title": "Heat kernel methods in finance: the SABR model",
        "comments": "59 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The SABR model is a stochastic volatility model not admitting a closed form\nsolution. Hagan, Kumar, Leniewski and Woodward have obtained an approximate\nsolution by means of perturbative techniques. A more precise approximation was\nfound by Henry-Labord\\`ere with the heat kernel expansion method. The latter\nrelies on deep and hard theorems from Riemannian geometry which are almost\ntotally unknown to the professionals of finance, who however are those\nprimarily interested in these results.\n  The goal of this report is to fill this gap and to make these topics\nunderstandable with a basic knowledge of calculus and linear algebra.\n"
    },
    {
        "paper_id": 1201.1483,
        "authors": "Zachary Feinstein, Birgit Rudloff",
        "title": "Time consistency of dynamic risk measures in markets with transaction\n  costs",
        "comments": null,
        "journal-ref": "Quantitative Finance 13 (9), 1473-1489, (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper concerns primal and dual representations as well as time\nconsistency of set-valued dynamic risk measures. Set-valued risk measures\nappear naturally when markets with transaction costs are considered and capital\nrequirements can be made in a basket of currencies or assets. Time consistency\nof scalar risk measures can be generalized to set-valued risk measures in\ndifferent ways. The most intuitive generalization is called time consistency.\nWe will show that the equivalence between a recursive form of the risk measure\nand time consistency, which is a central result in the scalar case, does not\nhold in the set-valued framework. Instead, we propose an alternative\ngeneralization, which we will call multi-portfolio time consistency and show in\nthe main result of the paper that this property is indeed equivalent to the\nrecursive form as well as to an additive property for the acceptance sets.\nMulti-portfolio time consistency is a stronger property than time consistency.\nIn the scalar case, both notions coincide.\n"
    },
    {
        "paper_id": 1201.1535,
        "authors": "Jozef Barunik, Tomaso Aste, Tiziana Di Matteo, Ruipeng Liu",
        "title": "Understanding the source of multifractality in financial markets",
        "comments": null,
        "journal-ref": "Physica A, 391 (17), pp. 4234-4251 (2012)",
        "doi": "10.1016/j.physa.2012.03.037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we use the generalized Hurst exponent approach to study the\nmulti- scaling behavior of different financial time series. We show that this\napproach is robust and powerful in detecting different types of multiscaling.\nWe observe a puzzling phenomenon where an apparent increase in multifractality\nis measured in time series generated from shuffled returns, where all\ntime-correlations are destroyed, while the return distributions are conserved.\nThis effect is robust and it is reproduced in several real financial data\nincluding stock market indices, exchange rates and interest rates. In order to\nunderstand the origin of this effect we investigate different simulated time\nseries by means of the Markov switching multifractal (MSM) model,\nautoregressive fractionally integrated moving average (ARFIMA) processes with\nstable innovations, fractional Brownian motion and Levy flights. Overall we\nconclude that the multifractality observed in financial time series is mainly a\nconsequence of the characteristic fat-tailed distribution of the returns and\ntime-correlations have the effect to decrease the measured multifractality.\n"
    },
    {
        "paper_id": 1201.1604,
        "authors": "Amy Poh Ai Ling, Mohamad Nasir Saludin, Masao Mukaidono",
        "title": "Deriving consensus rankings via multicriteria decision making\n  methodology",
        "comments": null,
        "journal-ref": "Business Strategy Series, Vol. 13 Iss: 1, pp.3 - 12 2012",
        "doi": "10.1108/17515631211194571",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Purpose - This paper seeks to take a cautionary stance to the impact of the\nmarketing mix on customer satisfaction, via a case study deriving consensus\nrankings for benchmarking on selected retail stores in Malaysia.\n  Design/methodology/approach - The ELECTRE I model is used in deriving\nconsensus rankings via multicriteria decision making method for benchmarking\nbase on the marketing mix model 4P's. Descriptive analysis is used to analyze\nbest practice among the four marketing tactics.\n  Findings - Outranking methods in consequence constitute a strong base on\nwhich to found the entire structure of the behavioral theory of benchmarking\napplied to development of marketing strategy.\n  Research limitations/implications - This study looks only at a limited part\nof the puzzle of how consumer satisfaction translates into behavioral outcomes.\n  Practical implications - The study provides managers with guidance on how to\ngenerate a rough outline of potential marketing activities that can be used to\ntake advantage of capabilities and convert weaknesses and threats.\n  Originality/value - The paper interestingly portrays the effective usage of\nmulticriteria decision-making and ranking method to help marketing managers\npredict their marketing trends.\n"
    },
    {
        "paper_id": 1201.1623,
        "authors": "Sergio Gomez, Justo Montiel, David Torres, Alberto Fernandez",
        "title": "MultiDendrograms: Variable-Group Agglomerative Hierarchical Clusterings",
        "comments": "Article upgraded to MultiDendrograms 3.0. Software available at\n  http://deim.urv.cat/~sgomez/multidendrograms.php",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  MultiDendrograms is a Java-written application that computes agglomerative\nhierarchical clusterings of data. Starting from a distances (or weights)\nmatrix, MultiDendrograms is able to calculate its dendrograms using the most\ncommon agglomerative hierarchical clustering methods. The application\nimplements a variable-group algorithm that solves the non-uniqueness problem\nfound in the standard pair-group algorithm. This problem arises when two or\nmore minimum distances between different clusters are equal during the\nagglomerative process, because then different output clusterings are possible\ndepending on the criterion used to break ties between distances.\nMultiDendrograms solves this problem implementing a variable-group algorithm\nthat groups more than two clusters at the same time when ties occur.\n"
    },
    {
        "paper_id": 1201.1782,
        "authors": "Alvise De Col (1), Alessandro Gnoatto (4) and Martino Grasselli (2,3)\n  ((1) UBS AG, (2) Universit\\`a degli Studi di Padova - Dipartimento di\n  Matematica, (3) D\\'epartement Math\\'ematiques et Ing\\'enierie Financi\\`ere,\n  ESILV, Paris La D\\'efense (France), (4) Mathematisches Institut, LMU\n  M\\\"unchen (Germany))",
        "title": "Smiles all around: FX joint calibration in a multi-Heston model",
        "comments": "Journal of Banking and Finance. Accepted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a novel multi-factor Heston-based stochastic volatility model,\nwhich is able to reproduce consistently typical multi-dimensional FX vanilla\nmarkets, while retaining the (semi)-analytical tractability typical of affine\nmodels and relying on a reasonable number of parameters. A successful joint\ncalibration to real market data is presented together with various in- and\nout-of-sample calibration exercises to highlight the robustness of the\nparameters estimation. The proposed model preserves the natural inversion and\ntriangulation symmetries of FX spot rates and its functional form, irrespective\nof choice of the risk-free currency. That is, all currencies are treated in the\nsame way.\n"
    },
    {
        "paper_id": 1201.1783,
        "authors": "Davide La Torre and Marco Maggis",
        "title": "A Goal Programming Model with Satisfaction Function for Risk Management\n  and Optimal Portfolio Diversification",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend the classical risk minimization model with scalar risk measures to\nthe general case of set-valued risk measures. The problem we obtain is a\nset-valued optimization model and we propose a goal programming-based approach\nwith satisfaction function to obtain a solution which represents the best\ncompromise between goals and the achievement levels. Numerical examples are\nprovided to illustrate how the method works in practical situations.\n"
    },
    {
        "paper_id": 1201.1788,
        "authors": "Marco Frittelli and Marco Maggis",
        "title": "Complete duality for quasiconvex dynamic risk measures on modules of the\n  $L^{p}$-type",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the conditional setting we provide a complete duality between quasiconvex\nrisk measures defined on $L^{0}$ modules of the $L^{p}$ type and the\nappropriate class of dual functions. This is based on a general result which\nextends the usual Penot-Volle representation for quasiconvex real valued maps.\n"
    },
    {
        "paper_id": 1201.184,
        "authors": "Ulrich Horst, Michael Kupper, Andrea Macrina, Christoph Mainberger",
        "title": "Continuous Equilibrium in Affine and Information-Based Capital Asset\n  Pricing Models",
        "comments": "24 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a class of generalized capital asset pricing models in continuous\ntime with a finite number of agents and tradable securities. The securities may\nnot be sufficient to span all sources of uncertainty. If the agents have\nexponential utility functions and the individual endowments are spanned by the\nsecurities, an equilibrium exists and the agents' optimal trading strategies\nare constant. Affine processes, and the theory of information-based asset\npricing are used to model the endogenous asset price dynamics and the terminal\npayoff. The derived semi-explicit pricing formulae are applied to numerically\nanalyze the impact of the agents' risk aversion on the implied volatility of\nsimultaneously-traded European-style options.\n"
    },
    {
        "paper_id": 1201.2024,
        "authors": "Pau Erola, Albert Diaz-Guilera, Sergio Gomez, Alex Arenas",
        "title": "Modeling international crisis synchronization in the World Trade Web",
        "comments": null,
        "journal-ref": "Networks and Heterogeneous Media 7 (2012) 385-397",
        "doi": "10.3934/nhm.2012.7.385",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Trade is a fundamental pillar of economy and a form of social organization.\nIts empirical characterization at the worldwide scale is represented by the\nWorld Trade Web (WTW), the network built upon the trade relationships between\nthe different countries. Several scientific studies have focused on the\nstructural characterization of this network, as well as its dynamical\nproperties, since we have registry of the structure of the network at different\ntimes in history. In this paper we study an abstract scenario for the\ndevelopment of global crises on top of the structure of connections of the WTW.\nAssuming a cyclic dynamics of national economies and the interaction of\ndifferent countries according to the import-export balances, we are able to\ninvestigate, using a simple model of pulse-coupled oscillators, the\nsynchronization phenomenon of crises at the worldwide scale. We focus on the\nlevel of synchronization measured by an order parameter at two different\nscales, one for the global system and another one for the mesoscales defined\nthrough the topology. We use the WTW network structure to simulate a network of\nIntegrate-and-Fire oscillators for six different snapshots between years 1950\nand 2000. The results reinforce the idea that globalization accelerates the\nglobal synchronization process, and the analysis at a mesoscopic level shows\nthat this synchronization is different before and after globalization periods:\nafter globalization, the effect of communities is almost inexistent.\n"
    },
    {
        "paper_id": 1201.2257,
        "authors": "Marco Frittelli, Marco Maggis and Ilaria Peri",
        "title": "Risk Measures on $\\mathcal{P}(\\mathbb{R})$ and Value At Risk with\n  Probability/Loss function",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a generalization of the classical notion of the $V@R_{\\lambda}$\nthat takes into account not only the probability of the losses, but the balance\nbetween such probability and the amount of the loss. This is obtained by\ndefining a new class of law invariant risk measures based on an appropriate\nfamily of acceptance sets. The $V@R_{\\lambda}$ and other known law invariant\nrisk measures turn out to be special cases of our proposal. We further prove\nthe dual representation of Risk Measures on $\\mathcal{P}(% \\mathbb{R}).$\n"
    },
    {
        "paper_id": 1201.2616,
        "authors": "C. Neri (Lloyds Banking Group, London, UK), L. Schneider (EMLYON\n  Business School, Lyon, France)",
        "title": "The Impact of the Prior Density on a Minimum Relative Entropy Density: A\n  Case Study with SPX Option Data",
        "comments": "24 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the problem of finding probability densities that match given\nEuropean call option prices. To allow prior information about such a density to\nbe taken into account, we generalise the algorithm presented in Neri and\nSchneider (2011) to find the maximum entropy density of an asset price to the\nrelative entropy case. This is applied to study the impact the choice of prior\ndensity has in two market scenarios. In the first scenario, call option prices\nare prescribed at only a small number of strikes, and we see that the choice of\nprior, or indeed its omission, yields notably different densities. The second\nscenario is given by CBOE option price data for S&P500 index options at a large\nnumber of strikes. Prior information is now considered to be given by\ncalibrated Heston, Schoebel-Zhu or Variance Gamma models. We find that the\nresulting digital option prices are essentially the same as those given by the\n(non-relative) Buchen-Kelly density itself. In other words, in a sufficiently\nliquid market the influence of the prior density seems to vanish almost\ncompletely. Finally, we study variance swaps and derive a simple formula\nrelating the fair variance swap rate to entropy. Then we show, again, that the\nprior loses its influence on the fair variance swap rate as the number of\nstrikes increases.\n"
    },
    {
        "paper_id": 1201.2756,
        "authors": "Aur\\'elien Alfonsi (CERMICS), Alexander Schied",
        "title": "Capacitary measures for completely monotone kernels via singular control",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give a singular control approach to the problem of minimizing an energy\nfunctional for measures with given total mass on a compact real interval, when\nenergy is defined in terms of a completely monotone kernel. This problem occurs\nboth in potential theory and when looking for optimal financial order execution\nstrategies under transient price impact. In our setup, measures or order\nexecution strategies are interpreted as singular controls, and the capacitary\nmeasure is the unique optimal control. The minimal energy, or equivalently the\ncapacity of the underlying interval, is characterized by means of a nonstandard\ninfinite-dimensional Riccati differential equation, which is analyzed in some\ndetail. We then show that the capacitary measure has two Dirac components at\nthe endpoints of the interval and a continuous Lebesgue density in between.\nThis density can be obtained as the solution of a certain Volterra integral\nequation of the second kind.\n"
    },
    {
        "paper_id": 1201.2817,
        "authors": "Mario Filiasi, Giacomo Livan, Matteo Marsili, Maria Peressi, Erik\n  Vesselli, Elia Zarinelli",
        "title": "On the concentration of large deviations for fat tailed distributions,\n  with application to financial data",
        "comments": "38 pages, 12 figures",
        "journal-ref": null,
        "doi": "10.1088/1742-5468/2014/09/P09030",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Large deviations for fat tailed distributions, i.e. those that decay slower\nthan exponential, are not only relatively likely, but they also occur in a\nrather peculiar way where a finite fraction of the whole sample deviation is\nconcentrated on a single variable. The regime of large deviations is separated\nfrom the regime of typical fluctuations by a phase transition where the\nsymmetry between the points in the sample is spontaneously broken. For\nstochastic processes with a fat tailed microscopic noise, this implies that\nwhile typical realizations are well described by a diffusion process with\ncontinuous sample paths, large deviation paths are typically discontinuous. For\neigenvalues of random matrices with fat tailed distributed elements, a large\ndeviation where the trace of the matrix is anomalously large concentrates on\njust a single eigenvalue, whereas in the thin tailed world the large deviation\naffects the whole distribution. These results find a natural application to\nfinance. Since the price dynamics of financial stocks is characterized by fat\ntailed increments, large fluctuations of stock prices are expected to be\nrealized by discrete jumps. Interestingly, we find that large excursions of\nprices are more likely realized by continuous drifts rather than by\ndiscontinuous jumps. Indeed, auto-correlations suppress the concentration of\nlarge deviations. Financial covariance matrices also exhibit an anomalously\nlarge eigenvalue, the market mode, as compared to the prediction of random\nmatrix theory. We show that this is explained by a large deviation with excess\ncovariance rather than by one with excess volatility.\n"
    },
    {
        "paper_id": 1201.2825,
        "authors": "Hao Meng (ECUST), Fei Ren (ECUST), Gao-Feng Gu (ECUST), Xiong Xiong\n  (TJU), Yong-Jie Zhang (TJU), Wei-Xing Zhou (ECUST), Wei Zhang (TJU)",
        "title": "Effects of long memory in the order submission process on the properties\n  of recurrence intervals of large price fluctuations",
        "comments": "6 EPL pages including 6 figures",
        "journal-ref": "EPL 98 (3), 38003 (2012)",
        "doi": "10.1209/0295-5075/98/38003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Understanding the statistical properties of recurrence intervals of extreme\nevents is crucial to risk assessment and management of complex systems. The\nprobability distributions and correlations of recurrence intervals for many\nsystems have been extensively investigated. However, the impacts of microscopic\nrules of a complex system on the macroscopic properties of its recurrence\nintervals are less studied. In this Letter, we adopt an order-driven stock\nmarket model to address this issue for stock returns. We find that the\ndistributions of the scaled recurrence intervals of simulated returns have a\npower law scaling with stretched exponential cutoff and the intervals possess\nmultifractal nature, which are consistent with empirical results. We further\ninvestigate the effects of long memory in the directions (or signs) and\nrelative prices of the order flow on the characteristic quantities of these\nproperties. It is found that the long memory in the order directions (Hurst\nindex $H_s$) has a negligible effect on the interval distributions and the\nmultifractal nature. In contrast, the power-law exponent of the interval\ndistribution increases linearly with respect to the Hurst index $H_x$ of the\nrelative prices, and the singularity width of the multifractal nature\nfluctuates around a constant value when $H_x<0.7$ and then increases with\n$H_x$. No evident effects of $H_s$ and $H_x$ are found on the long memory of\nthe recurrence intervals. Our results indicate that the nontrivial properties\nof the recurrence intervals of returns are mainly caused by traders' behaviors\nof persistently placing new orders around the best bid and ask prices.\n"
    },
    {
        "paper_id": 1201.2899,
        "authors": "Steven Kou and Tony Sit and Zhiliang Ying",
        "title": "Parameter Estimation using Empirical Likelihood combined with Market\n  Information",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  During the last decade Levy processes with jumps have received increasing\npopularity for modelling market behaviour for both derviative pricing and risk\nmanagement purposes. Chan et al. (2009) introduced the use of empirical\nlikelihood methods to estimate the parameters of various diffusion processes\nvia their characteristic functions which are readily avaiable in most cases.\nReturn series from the market are used for estimation. In addition to the\nreturn series, there are many derivatives actively traded in the market whose\nprices also contain information about parameters of the underlying process.\nThis observation motivates us, in this paper, to combine the return series and\nthe associated derivative prices observed at the market so as to provide a more\nreflective estimation with respect to the market movement and achieve a gain of\neffciency. The usual asymptotic properties, including consistency and\nasymptotic normality, are established under suitable regularity conditions.\nSimulation and case studies are performed to demonstrate the feasibility and\neffectiveness of the proposed method.\n"
    },
    {
        "paper_id": 1201.3083,
        "authors": "Vygintas Gontis, Aleksejus Kononovicius, Stefan Reimann",
        "title": "The class of nonlinear stochastic models as a background for the bursty\n  behavior in financial markets",
        "comments": "9 pages, 5 figures",
        "journal-ref": "Advances in Complex Systems 15 (1), 2012, 1250071",
        "doi": "10.1142/S0219525912500713",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate large changes, bursts, of the continuous stochastic signals,\nwhen the exponent of multiplicativity is higher than one. Earlier we have\nproposed a general nonlinear stochastic model which can be transformed into\nBessel process with known first hitting (first passage) time statistics. Using\nthese results we derive PDF of burst duration for the proposed model. We\nconfirm analytical expressions by numerical evaluation and discuss bursty\nbehavior of return in financial markets in the framework of modeling by\nnonlinear SDE.\n"
    },
    {
        "paper_id": 1201.3432,
        "authors": "Tariq Ahmad Mir",
        "title": "The leading digit distribution of the worldwide Illicit Financial Flows",
        "comments": "13 pages, 10 figures, 6 tables, additional data analyis",
        "journal-ref": "Quality & Quantity, 50 (2016) 271-281",
        "doi": "10.1007/s11135-014-0147-z",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Benford's law states that in data sets from different phenomena leading\ndigits tend to be distributed logarithmically such that the numbers beginning\nwith smaller digits occur more often than those with larger ones. Particularly,\nthe law is known to hold for different types of financial data. The Illicit\nFinancial Flows (IFFs) exiting the developing countries are frequently\ndiscussed as hidden resources which could have been otherwise properly utilized\nfor their development. We investigate here the distribution of the leading\ndigits in the recent data on estimates of IFFs to look for the existence of a\npattern as predicted by Benford's law and establish that the frequency of\noccurrence of the leading digits in these estimates does closely follow the\nlaw.\n"
    },
    {
        "paper_id": 1201.3473,
        "authors": "Ladislav Kristoufek",
        "title": "Multifractal Height Cross-Correlation Analysis: A New Method for\n  Analyzing Long-Range Cross-Correlations",
        "comments": "6 pages, 4 figures",
        "journal-ref": "EPL 95, 68001, 2011",
        "doi": "10.1209/0295-5075/95/68001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new method for detection of long-range cross-correlations and\nmultifractality - multifractal height cross-correlation analysis (MF-HXA) -\nbased on scaling of qth order covariances. MF-HXA is a bivariate generalization\nof the height-height correlation analysis of Barabasi & Vicsek [Barabasi, A.L.,\nVicsek, T.: Multifractality of self-affine fractals, Physical Review A 44(4),\n1991]. The method can be used to analyze long-range cross-correlations and\nmultifractality between two simultaneously recorded series. We illustrate a\npower of the method on both simulated and real-world time series.\n"
    },
    {
        "paper_id": 1201.3511,
        "authors": "Ladislav Kristoufek",
        "title": "How are rescaled range analyses affected by different memory and\n  distributional properties? A Monte Carlo study",
        "comments": "15 pages, 6 tables",
        "journal-ref": "Physica A 391(17), pp. 4252-4260, 2012",
        "doi": "10.1016/j.physa.2012.04.018",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present the results of Monte Carlo simulations for two\npopular techniques of long-range correlations detection - classical and\nmodified rescaled range analyses. A focus is put on an effect of different\ndistributional properties on an ability of the methods to efficiently\ndistinguish between short and long-term memory. To do so, we analyze the\nbehavior of the estimators for independent, short-range dependent, and\nlong-range dependent processes with innovations from 8 different distributions.\nWe find that apart from a combination of very high levels of kurtosis and\nskewness, both estimators are quite robust to distributional properties.\nImportantly, we show that R/S is biased upwards (yet not strongly) for\nshort-range dependent processes, while M-R/S is strongly biased downwards for\nlong-range dependent processes regardless of the distribution of innovations.\n"
    },
    {
        "paper_id": 1201.3572,
        "authors": "Vladimir Filimonov, Didier Sornette",
        "title": "Quantifying reflexivity in financial markets: towards a prediction of\n  flash crashes",
        "comments": null,
        "journal-ref": "Phys. Rev. E 85 (5), 056108 (2012)",
        "doi": "10.1103/PhysRevE.85.056108",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new measure of activity of financial markets that provides a\ndirect access to their level of endogeneity. This measure quantifies how much\nof price changes are due to endogenous feedback processes, as opposed to\nexogenous news. For this, we calibrate the self-excited conditional Poisson\nHawkes model, which combines in a natural and parsimonious way exogenous\ninfluences with self-excited dynamics, to the E-mini S&P 500 futures contracts\ntraded in the Chicago Mercantile Exchange from 1998 to 2010. We find that the\nlevel of endogeneity has increased significantly from 1998 to 2010, with only\n70% in 1998 to less than 30% since 2007 of the price changes resulting from\nsome revealed exogenous information. Analogous to nuclear plant safety\nconcerned with avoiding \"criticality\", our measure provides a direct\nquantification of the distance of the financial market to a critical state\ndefined precisely as the limit of diverging trading activity in absence of any\nexternal driving.\n"
    },
    {
        "paper_id": 1201.358,
        "authors": "Reginald D. Smith",
        "title": "A drift formulation of Gresham's Law",
        "comments": "6 pages, 7 figures",
        "journal-ref": "Hyperion international journal of econophysics & new economy,\n  volume 5, issue 1, 2012, p. 71-84",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we analyze Gresham's Law, in particular, how the rate of inflow\nor outflow of currencies is affected by the demand elasticity of arbitrage and\nthe difference in face value ratios inside and outside of a country under a\nbimetallic system. We find that these equations are very similar to those used\nto describe drift in systems of free charged particles. In addition, we look at\nhow Gresham's Law would play out with multiple currencies and multiple\ncountries under a variety of connecting topologies.\n"
    },
    {
        "paper_id": 1201.3584,
        "authors": "Leonardo Ermann and Dima L. Shepelyansky",
        "title": "Ecological analysis of world trade",
        "comments": "5 pages, 6 figures (6 extra figures in Supporting Information)",
        "journal-ref": "Phys. Lett. A 377, 250-256 (2013)",
        "doi": "10.1016/j.physleta.2012.10.056",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Ecological systems have a high level of complexity combined with stability\nand rich biodiversity. Recently, the analysis of their properties and evolution\nhas been pushed forward on a basis of concept of mutualistic networks that\nprovides a detailed understanding of their features being linked to a high\nnestedness of these networks. It was shown that the nestedness architecture of\nmutualistic networks of plants and their pollinators minimizes competition and\nincreases biodiversity. Here, using the United Nations COMTRADE database for\nyears 1962 - 2009, we show that a similar ecological analysis gives a valuable\ndescription of the world trade. In fact the countries and trade products are\nanalogous to plants and pollinators, and the whole trade network is\ncharacterized by a low nestedness temperature which is typical for the\necological networks. This approach provides new mutualistic features of the\nworld trade highlighting new significance of countries and trade products for\nthe world trade.\n"
    },
    {
        "paper_id": 1201.3798,
        "authors": "Tiago P. Peixoto, Stefan Bornholdt",
        "title": "No need for conspiracy: Self-organized cartel formation in a modified\n  trust game",
        "comments": "5 pages, 5 figures [fixes a typo in the text]",
        "journal-ref": "Phys. Rev. Lett. 108, 218702 (2012)",
        "doi": "10.1103/PhysRevLett.108.218702",
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  We investigate the dynamics of a trust game on a mixed population where\nindividuals with the role of buyers are forced to play against a predetermined\nnumber of sellers, whom they choose dynamically. Agents with the role of\nsellers are also allowed to adapt the level of value for money of their\nproducts, based on payoff. The dynamics undergoes a transition at a specific\nvalue of the strategy update rate, above which an emergent cartel organization\nis observed, where sellers have similar values of below optimal value for\nmoney. This cartel organization is not due to an explicit collusion among\nagents; instead it arises spontaneously from the maximization of the individual\npayoffs. This dynamics is marked by large fluctuations and a high degree of\nunpredictability for most of the parameter space, and serves as a plausible\nqualitative explanation for observed elevated levels and fluctuations of\ncertain commodity prices.\n"
    },
    {
        "paper_id": 1201.3851,
        "authors": "Jinli Hu",
        "title": "Combinatorial Modelling and Learning with Prediction Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Combining models in appropriate ways to achieve high performance is commonly\nseen in machine learning fields today. Although a large amount of combinatorial\nmodels have been created, little attention is drawn to the commons in different\nmodels and their connections. A general modelling technique is thus worth\nstudying to understand model combination deeply and shed light on creating new\nmodels. Prediction markets show a promise of becoming such a generic, flexible\ncombinatorial model. By reviewing on several popular combinatorial models and\nprediction market models, this paper aims to show how the market models can\ngeneralise different combinatorial stuctures and how they implement these\npopular combinatorial models in specific conditions. Besides, we will see among\ndifferent market models, Storkey's \\emph{Machine Learning Markets} provide more\nfundamental, generic modelling mechanisms than the others, and it has a\nsignificant appeal for both theoretical study and application.\n"
    },
    {
        "paper_id": 1201.449,
        "authors": "Leonidas Sandoval Junior",
        "title": "Survivability and centrality measures for networks of financial market\n  indices",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using data from 92 indices of stock exchanges worldwide, I analize the\ncluster formation and evolution from 2007 to 2010, which includes the Subprime\nMortgage Crisis of 2008, using asset graphs based on distance thresholds. I\nalso study the survivability of connections and of clusters through time and\nthe influence of noise in centrality measures applied to the networks of\nfinancial indices.\n"
    },
    {
        "paper_id": 1201.4551,
        "authors": "Hazuki Ishida",
        "title": "Fossil fuel consumption and economic growth: causality relationship in\n  the world",
        "comments": "This paper has been withdrawn by the author",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper has been withdrawn by the author due to some inaccurate\ndescriptions in the section of INTRODUCTION and CONCLUSIONS.\n"
    },
    {
        "paper_id": 1201.458,
        "authors": "N. Vvedenskaya, Y. Suhov, V. Belitsky",
        "title": "A non-linear model of trading mechanism on a financial market",
        "comments": "15 pages, 1 figure",
        "journal-ref": "Markov Processes and Related Fields, Vol. 19 (2013), 83--98",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a prototype model in an attempt to capture some aspects of\nmarket dynamics simulating a trading mechanism. The model description starts\nwith a discrete-space, continuous-time Markov process describing arrival and\nmovement of orders with different prices. We then perform a re-scaling\nprocedure leading to a deterministic dynamical system controlled by non-linear\nordinary differential equations (ODEs). This allows us to introduce\napproximations for the equilibrium distribution of the model represented by\nfixed points of deterministic dynamics.\n"
    },
    {
        "paper_id": 1201.4586,
        "authors": "Leonidas Sandoval Junior",
        "title": "To lag or not to lag? How to compare indices of stock markets that\n  operate at different times",
        "comments": null,
        "journal-ref": "Physica A 403 (2014) 227-243",
        "doi": "10.1016/j.physa.2014.02.039",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets worldwide do not have the same working hours. As a\nconsequence, the study of correlation or causality between financial market\nindices becomes dependent on wether we should consider in computations of\ncorrelation matrices all indices in the same day or lagged indices. The answer\nthis article proposes is that we should consider both. In this work, we use 79\nindices of a diversity of stock markets across the world in order to study\ntheir correlation structure, and discover that representing in the same network\noriginal and lagged indices, we obtain a better understanding of how indices\nthat operate at different hours relate to each other.\n"
    },
    {
        "paper_id": 1201.4776,
        "authors": "Lukas Vacha, Jozef Barunik",
        "title": "Co-movement of energy commodities revisited: Evidence from wavelet\n  coherence analysis",
        "comments": null,
        "journal-ref": "Energy Economics 34(1), pp. 241--247 (2012)",
        "doi": "10.1016/j.eneco.2011.10.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we contribute to the literature on energy market co-movement\nby studying its dynamics in the time-frequency domain. The novelty of our\napproach lies in the application of wavelet tools to commodity market data. A\nmajor part of economic time series analysis is done in the time or frequency\ndomain separately. Wavelet analysis combines these two fundamental approaches\nallowing study of the time series in the time- frequency domain. Using this\nframework, we propose a new, model-free way of estimating time-varying cor-\nrelations. In the empirical analysis, we connect our approach to the dynamic\nconditional correlation approach of Engle (2002) on the main components of the\nenergy sector. Namely, we use crude oil, gasoline, heating oil, and natural gas\non a nearest-future basis over a period of approximately 16 and 1/2 years\nbeginning on November 1, 1993 and ending on July 21, 2010. Using wavelet\ncoherence, we uncover interesting dynamics of correlations between energy\ncommodities in the time-frequency space.\n"
    },
    {
        "paper_id": 1201.4781,
        "authors": "Jozef Barunik, Lukas Vacha",
        "title": "Monte Carlo-based tail exponent estimator",
        "comments": null,
        "journal-ref": "Physica A: Statistical Mechanics and its Applications (2010), 389\n  (21), pp. 4863-4874",
        "doi": "10.1016/j.physa.2010.06.054",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a new approach to estimation of the tail exponent in\nfinancial stock markets. We begin the study with the finite sample behavior of\nthe Hill estimator under {\\alpha}-stable distributions. Using large Monte Carlo\nsimulations, we show that the Hill estimator overestimates the true tail\nexponent and can hardly be used on samples with small length. Utilizing our\nresults, we introduce a Monte Carlo-based method of estimation for the tail\nexponent. Our proposed method is not sensitive to the choice of tail size and\nworks well also on small data samples. The new estimator also gives unbiased\nresults with symmetrical confidence intervals. Finally, we demonstrate the\npower of our estimator on the international world stock market indices. On the\ntwo separate periods of 2002-2005 and 2006-2009, we estimate the tail exponent.\n"
    },
    {
        "paper_id": 1201.4786,
        "authors": "Jozef Barunik, Ladislav Kristoufek",
        "title": "On Hurst exponent estimation under heavy-tailed distributions",
        "comments": null,
        "journal-ref": "Physica A: Statistical Mechanics and its Applications (2010), 389\n  (18), pp. 3844-3855",
        "doi": "10.1016/j.physa.2010.05.025",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we show how the sampling properties of the Hurst exponent\nmethods of estimation change with the presence of heavy tails. We run extensive\nMonte Carlo simulations to find out how rescaled range analysis (R/S),\nmultifractal detrended fluctuation analysis (MF-DFA), detrending moving average\n(DMA) and generalized Hurst exponent approach (GHE) estimate Hurst exponent on\nindependent series with different heavy tails. For this purpose, we generate\nindependent random series from stable distribution with stability exponent\n{\\alpha} changing from 1.1 (heaviest tails) to 2 (Gaussian normal distribution)\nand we estimate the Hurst exponent using the different methods. R/S and GHE\nprove to be robust to heavy tails in the underlying process. GHE provides the\nlowest variance and bias in comparison to the other methods regardless the\npresence of heavy tails in data and sample size. Utilizing this result, we\napply a novel approach of the intraday time-dependent Hurst exponent and we\nestimate the Hurst exponent on high frequency data for each trading day\nseparately. We obtain Hurst exponents for S&P500 index for the period beginning\nwith year 1983 and ending by November 2009 and we discuss the surprising result\nwhich uncovers how the market's behavior changed over this long period.\n"
    },
    {
        "paper_id": 1201.4841,
        "authors": "Marcel R. Ausloos",
        "title": "Econophysics of a religious cult: the Antoinists in Belgium [1920-2000]",
        "comments": "20 pages, 6 figures, 2 tables, 51 references; prepared for Physica A;\n  now including title, author, address and abstract",
        "journal-ref": "Physica A 391 (2012) 3190-97",
        "doi": "10.1016/j.physa.2012.01.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the framework of applying econophysics ideas in religious topics, the\nfinances of the Antoinist religious movement organized in Belgium between 1920\nand 2000 are studied. The interest of investigating financial aspects of such\na, sometimes called, sect stems in finding characteristics of conditions and\nmechanisms under which definitely growth AND decay features of communities can\nbe understood. The legally reported yearly income and expenses between 1920 and\n2000 are studied. A three wave asymmetric regime is observed over a trend among\nmarked fluctuations at time of crises. The data analysis leads to propose a\ngeneral mechanistic model taking into account an average GDP growth, an\noscillatory monetary inflation and a logistic population drift.\n"
    },
    {
        "paper_id": 1201.5132,
        "authors": "Thorsten Rheinl\\\"ander and Michael Schmutz",
        "title": "Quasi self-dual exponential L\\'evy processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The important application of semi-static hedging in financial markets\nnaturally leads to the notion of quasi self-dual processes. The focus of our\nstudy is to give new characterizations of quasi self-duality for exponential\nL\\'evy processes such that the resulting market does not admit arbitrage\nopportunities. We derive a set of equivalent conditions for the stochastic\nlogarithm of quasi self-dual martingale models and derive a further\ncharacterization of these models not depending on the L\\'evy-Khintchine\nparametrization. Since for non-vanishing order parameter two martingale\nproperties have to be satisfied simultaneously, there is a non-trivial relation\nbetween the order and shift parameter representing carrying costs in financial\napplications. This leads to an equation containing an integral term which has\nto be inverted in applications. We first discuss several important properties\nof this equation and, for some well-known models, we derive a family of\nclosed-form inversion formulae leading to parameterizations of sets of possible\ncombinations in the corresponding parameter spaces of well-known L\\'evy driven\nmodels.\n"
    },
    {
        "paper_id": 1201.5448,
        "authors": "Wei-Xing Zhou (ECUST)",
        "title": "Determinants of immediate price impacts at the trade level in an\n  emerging order-driven market",
        "comments": "21 IOP tex pages including 5 figures and 5 tables. Accepted for\n  publication in New Journal of Physics",
        "journal-ref": "New Journal of Physics 14 (2), 023055 (2012)",
        "doi": "10.1088/1367-2630/14/2/023055",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The common wisdom argues that, in general, large trades cause large price\nchanges, while small trades cause small price changes. However, for extremely\nlarge price changes, the trade size and news play a minor role, while the\nliquidity (especially price gaps on the limit order book) is a more influencing\nfactor. Hence, there might be other influencing factors of immediate price\nimpacts of trades. In this paper, through mechanical analysis of price\nvariations before and after a trade of arbitrary size, we identify that the\ntrade size, the bid-ask spread, the price gaps and the outstanding volumes at\nthe bid and ask sides of the limit order book have impacts on the changes of\nprices. We propose two regression models to investigate the influences of these\nmicroscopic factors on the price impact of buyer-initiated partially filled\ntrades, seller-initiated partially filled trades, buyer-initiated filled\ntrades, and seller-initiated filled trades. We find that they have\nquantitatively similar explanation powers and these factors can account for up\nto 44% of the price impacts. Large trade sizes, wide bid-ask spreads, high\nliquidity at the same side and low liquidity at the opposite side will cause a\nlarge price impact. We also find that the liquidity at the opposite side has a\nmore influencing impact than the liquidity at the same side. Our results shed\nnew lights on the determinants of immediate price impacts.\n"
    },
    {
        "paper_id": 1201.569,
        "authors": "Jongwook Kim and Gabjin Oh",
        "title": "Heavy-tail driven by memory",
        "comments": "This paper was withdrawn by the authors because of the change in\n  authorship. The work is replaced by the new one with considerable improvement\n  which is available at arXiv",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a stochastic process driven by memory effect with novel\ndistributions including both exponential and leptokurtic heavy-tailed\ndistributions. A class of distribution is analytically derived from the\ncontinuum limit of the discrete binary process with the renormalized\nauto-correlation and the closed form moment generating function is obtained,\nthus the cumulants are calculated and shown to be convergent. The other class\nof distributions are numerically investigated. The concoction of the two\nstochastic processes of the different signs of memory under regime switching\nmechanism does incarnate power-law decay behavior, which strongly implies that\nmemory is the alternative origin of heavy-tail.\n"
    },
    {
        "paper_id": 1201.613,
        "authors": "Peter Kratz, Torsten Sch\\\"oneborn",
        "title": "Portfolio liquidation in dark pools in continuous time",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an illiquid financial market where a risk averse investor has to\nliquidate a portfolio within a finite time horizon [0,T] and can trade\ncontinuously at a traditional exchange (the \"primary venue\") and in a dark\npool. At the primary venue, trading yields a linear price impact. In the dark\npool, no price impact costs arise but order execution is uncertain, modeled by\na multi-dimensional Poisson process. We characterize the costs of trading by a\nlinear-quadratic functional which incorporates both the price impact costs of\ntrading at the primary exchange and the market risk of the position. The\nliquidation constraint implies a singularity of the value function of the\nresulting minimization problem at the terminal time T. Via the HJB equation and\na quadratic ansatz, we obtain a candidate for the value function which is the\nlimit of a sequence of solutions of initial value problems for a matrix\ndifferential equation. We show that this limit exists by using an appropriate\nmatrix inequality and a comparison result for Riccati matrix equations.\nAdditionally, we obtain upper and lower bounds of the solutions of the initial\nvalue problems, which allow us to prove a verification theorem. If a single\nasset position is to be liquidated, the investor slowly trades out of her\nposition at the primary venue, with the remainder being placed in the dark pool\nat any point in time. For multi-asset liquidations this is generally not the\ncase; it can, e.g., be optimal to oversize orders in the dark pool in order to\nturn a poorly balanced portfolio into a portfolio bearing less risk.\n"
    },
    {
        "paper_id": 1201.6137,
        "authors": "Martin Rypdal and Ola L{\\o}vsletten",
        "title": "Modeling electricity spot prices using mean-reverting multifractal\n  processes",
        "comments": "13 pages, 4 figures, 2 tables",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.08.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss stochastic modeling of volatility persistence and\nanti-correlations in electricity spot prices, and for this purpose we present\ntwo mean-reverting versions of the multifractal random walk (MRW). In the first\nmodel the anti-correlations are modeled in the same way as in an\nOrnstein-Uhlenbeck process, i.e. via a drift (damping) term, and in the second\nmodel the anti-correlations are included by letting the innovations in the MRW\nmodel be fractional Gaussian noise with H < 1/2. For both models we present\napproximate maximum likelihood methods, and we apply these methods to estimate\nthe parameters for the spot prices in the Nordic electricity market. The\nmaximum likelihood estimates show that electricity spot prices are\ncharacterized by scaling exponents that are significantly different from the\ncorresponding exponents in stock markets, confirming the exceptional nature of\nthe electricity market. In order to compare the damped MRW model with the\nfractional MRW model we use ensemble simulations and wavelet-based variograms,\nand we observe that certain features of the spot prices are better described by\nthe damped MRW model. The characteristic correlation time is estimated to\napproximately half a year.\n"
    },
    {
        "paper_id": 1201.634,
        "authors": "Martin Gremm and Mark B. Wise",
        "title": "Mathematical Constraints on Financially Viable Public Policy",
        "comments": "11 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Social Security and other public policies can be viewed as a series of cash\nin and outflows that depend on parameters such as the age distribution of the\npopulation and the retirement age. Given forecasts of these parameters,\npolicies can be designed to be financially stable, i.e., to terminate with a\nzero balance. If reality deviates from the forecasts, policies normally\nterminate with a surplus or a deficit. We derive constraints on the cash flows\nof robust policies that terminate with zero balance even in the presence of\nforecasting errors. Social Security and most similar policies are not robust.\nWe show that non-trivial robust policies exist and provide a recipe for\nconstructing robust extensions of non-robust policies. An example illustrates\nour results.\n"
    },
    {
        "paper_id": 1201.6418,
        "authors": "X.F. Jiang and B. Zheng",
        "title": "Anti-correlation and subsector structure in financial systems",
        "comments": "6 pages, 2 figures, 4 tables",
        "journal-ref": "EPL, 97 (2012) 48006",
        "doi": "10.1209/0295-5075/97/48006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With the random matrix theory, we study the spatial structure of the Chinese\nstock market, American stock market and global market indices. After taking\ninto account the signs of the components in the eigenvectors of the\ncross-correlation matrix, we detect the subsector structure of the financial\nsystems. The positive and negative subsectors are anti-correlated each other in\nthe corresponding eigenmode. The subsector structure is strong in the Chinese\nstock market, while somewhat weaker in the American stock market and global\nmarket indices. Characteristics of the subsector structures in different\nmarkets are revealed.\n"
    },
    {
        "paper_id": 1201.6516,
        "authors": "Thorsten Rheinl\\\"ander, Michael Schmutz",
        "title": "Self-dual continuous processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The important application of semi-static hedging in financial markets\nnaturally leads to the notion of quasi self-dual processes which is, for\ncontinuous semimartingales, related to symmetry properties of both their\nordinary as well as their stochastic logarithms. We provide a structure result\nfor continuous quasi self-dual processes. Moreover, we give a characterisation\nof continuous Ocone martingales via a strong version of self-duality.\n"
    },
    {
        "paper_id": 1201.6535,
        "authors": "Giacomo Livan, Luca Rebecchi",
        "title": "Asymmetric correlation matrices: an analysis of financial data",
        "comments": "Revised version; 11 pages, 13 figures",
        "journal-ref": "Eur. Phys. J. B 85, 213 (2012)",
        "doi": "10.1140/epjb/e2012-30085-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the spectral properties of correlation matrices between distinct\nstatistical systems. Such matrices are intrinsically non symmetric, and lend\nthemselves to extend the spectral analyses usually performed on standard\nPearson correlation matrices to the realm of complex eigenvalues. We employ\nsome recent random matrix theory results on the average eigenvalue density of\nthis type of matrices to distinguish between noise and non trivial correlation\nstructures, and we focus on financial data as a case study. Namely, we employ\ndaily prices of stocks belonging to the American and British stock exchanges,\nand look for the emergence of correlations between two such markets in the\neigenvalue spectrum of their non symmetric correlation matrix. We find several\nnon trivial results, also when considering time-lagged correlations over short\nlags, and we corroborate our findings by additionally studying the asymmetric\ncorrelation matrix of the principal components of our datasets.\n"
    },
    {
        "paper_id": 1201.6544,
        "authors": "Ma{\\l}gorzata Snarska",
        "title": "A Random Matrix Approach to Dynamic Factors in macroeconomic data",
        "comments": "arXiv admin note: text overlap with arXiv:physics/0512090 by other\n  authors",
        "journal-ref": "ACTA PHYSICA POLONICA A Vol. 121 B (2012) 110-120",
        "doi": "10.12693/APhysPolA.121.B-110",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show how random matrix theory can be applied to develop new algorithms to\nextract dynamic factors from macroeconomic time series. In particular, we\nconsider a limit where the number of random variables N and the number of\nconsecutive time measurements T are large but the ratio N / T is fixed. In this\nregime the underlying random matrices are asymptotically equivalent to Free\nRandom Variables (FRV).Application of these methods for macroeconomic\nindicators for Poland economy is also presented.\n"
    },
    {
        "paper_id": 1201.6655,
        "authors": "Alina Beygelzimer, John Langford, David Pennock",
        "title": "Learning Performance of Prediction Markets with Kelly Bettors",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In evaluating prediction markets (and other crowd-prediction mechanisms),\ninvestigators have repeatedly observed a so-called \"wisdom of crowds\" effect,\nwhich roughly says that the average of participants performs much better than\nthe average participant. The market price---an average or at least aggregate of\ntraders' beliefs---offers a better estimate than most any individual trader's\nopinion. In this paper, we ask a stronger question: how does the market price\ncompare to the best trader's belief, not just the average trader. We measure\nthe market's worst-case log regret, a notion common in machine learning theory.\nTo arrive at a meaningful answer, we need to assume something about how traders\nbehave. We suppose that every trader optimizes according to the Kelly criteria,\na strategy that provably maximizes the compound growth of wealth over an\n(infinite) sequence of market interactions. We show several consequences.\nFirst, the market prediction is a wealth-weighted average of the individual\nparticipants' beliefs. Second, the market learns at the optimal rate, the\nmarket price reacts exactly as if updating according to Bayes' Law, and the\nmarket prediction has low worst-case log regret to the best individual\nparticipant. We simulate a sequence of markets where an underlying true\nprobability exists, showing that the market converges to the true objective\nfrequency as if updating a Beta distribution, as the theory predicts. If agents\nadopt a fractional Kelly criteria, a common practical variant, we show that\nagents behave like full-Kelly agents with beliefs weighted between their own\nand the market's, and that the market price converges to a time-discounted\nfrequency. Our analysis provides a new justification for fractional Kelly\nbetting, a strategy widely used in practice for ad-hoc reasons. Finally, we\npropose a method for an agent to learn her own optimal Kelly fraction.\n"
    },
    {
        "paper_id": 1202.01,
        "authors": "Mikio Ito and Akihiko Noda and Tatsuma Wada",
        "title": "The Evolution of Stock Market Efficiency in the US: A Non-Bayesian\n  Time-Varying Model Approach",
        "comments": "28 pages, 7 figures, 2 tables in Applied Economics, 2015",
        "journal-ref": "Applied Economics 48 (2016) 621-635",
        "doi": "10.1080/00036846.2015.1083532",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A non-Bayesian time-varying model is developed by introducing the concept of\nthe degree of market efficiency that varies over time. This model may be seen\nas a reflection of the idea that continuous technological progress alters the\ntrading environment over time. With new methodologies and a new measure of the\ndegree of market efficiency, we examine whether the US stock market evolves\nover time. In particular, a time-varying autoregressive (TV-AR) model is\nemployed. Our main findings are: (i) the US stock market has evolved over time\nand the degree of market efficiency has cyclical fluctuations with a\nconsiderably long periodicity, from 30 to 40 years; and (ii) the US stock\nmarket has been efficient with the exception of four times in our sample\nperiod: during the long-recession of 1873-1879; the recession of 1902-1904; the\nNew Deal era; and the recession of 1957-1958 and soon after it. It is then\nshown that our results are partly consistent with the view of behavioral\nfinance.\n"
    },
    {
        "paper_id": 1202.0142,
        "authors": "Jo\\~ao P. da Cruz, Pedro G. Lind",
        "title": "Heavy-tails in economic data: fundamental assumptions, modelling and\n  analysis",
        "comments": "23 pages, 10 figures; to appear as chapter of a book on heavy-tails",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The study of heavy-tailed distributions in economic and financial systems has\nbeen widely addressed since financial time series has become a research\nsubject.After the eighties, several \"highly improbable\" market drops were\nobserved (e.g. the 1987 stock market drop known as \"Black Monday\" and on even\nmore recent ones, already in the 21st century) that produce heavy losses that\nwere unexplainable in a GN environment. The losses incurred in these large\nmarket drop events did not change significantly the market practices or the way\nregulation is done but drove some attention back to the study of heavy-tails\nand their underlying mechanisms. Some recent findings in these context is the\nscope of this manuscript.\n"
    },
    {
        "paper_id": 1202.0175,
        "authors": "Andreas Kunz",
        "title": "Robust Hedging of Withdrawal Guarantees (Extended Version)",
        "comments": "Static hedging, model selection problem, local volatility models,\n  stochastic volatility models, Levy process models, variable annuities,\n  guaranteed minimun withdrawal benefit (GMWB) products, (29 pages, 8 figures)",
        "journal-ref": "Risk Magazine 3 (2013) 64-68",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Withdrawal guarantees ensure the periodical deduction of a constant\ndollar-amount from a fund investment for a fixed number of periods. If the fund\ndepletes before the last withdrawal, the guarantor has to finance the\noutstanding withdrawals. We derive a robust hedging strategy which leads to\nclosed form solutions for the guarantee value.\n"
    },
    {
        "paper_id": 1202.0342,
        "authors": "J. Shen and B. Zheng",
        "title": "On return-volatility correlation in financial dynamics",
        "comments": "6 pages, 4 figures",
        "journal-ref": "published in EPL (Europhysics Letters), Volume 88, Issue 2, pp.\n  28003 (2009)",
        "doi": "10.1209/0295-5075/88/28003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With the daily and minutely data of the German DAX and Chinese indices, we\ninvestigate how the return-volatility correlation originates in financial\ndynamics. Based on a retarded volatility model, we may eliminate or generate\nthe return-volatility correlation of the time series, while other\ncharacteristics, such as the probability distribution of returns and long-range\ntime-correlation of volatilities etc., remain essentially unchanged. This\nsuggests that the leverage effect or anti-leverage effect in financial markets\narises from a kind of feedback return-volatility interactions, rather than the\nlong-range time-correlation of volatilities and asymmetric probability\ndistribution of returns. Further, we show that large volatilities dominate the\nreturn-volatility correlation in financial dynamics.\n"
    },
    {
        "paper_id": 1202.0344,
        "authors": "J. Shen and B. Zheng",
        "title": "Cross-correlation in financial dynamics",
        "comments": "6 pages, 3 figures",
        "journal-ref": "published in EPL (Europhysics Letters), Volume 86, Issue 4, pp.\n  48005 (2009)",
        "doi": "10.1209/0295-5075/86/48005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To investigate the universal structure of interactions in financial dynamics,\nwe analyze the cross-correlation matrix C of price returns of the Chinese stock\nmarket, in comparison with those of the American and Indian stock markets. As\nan important emerging market, the Chinese market exhibits much stronger\ncorrelations than the developed markets. In the Chinese market, the\ninteractions between the stocks in a same business sector are weak, while extra\ninteractions in unusual sectors are detected. Using a variation of the\ntwo-factor model, we simulate the interactions in financial markets.\n"
    },
    {
        "paper_id": 1202.0409,
        "authors": "Sunil Kumar and Nivedita Deo",
        "title": "Correlation, Network and Multifractal Analysis of Global Financial\n  Indices",
        "comments": "32 pages, 25 figures, 1 table",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.86.026101",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We apply RMT, Network and MF-DFA methods to investigate correlation, network\nand multifractal properties of 20 global financial indices. We compare results\nbefore and during the financial crisis of 2008 respectively. We find that the\nnetwork method gives more useful information about the formation of clusters as\ncompared to results obtained from eigenvectors corresponding to second largest\neigenvalue and these sectors are formed on the basis of geographical location\nof indices. At threshold 0.6, indices corresponding to Americas, Europe and\nAsia/Pacific disconnect and form different clusters before the crisis but\nduring the crisis, indices corresponding to Americas and Europe are combined\ntogether to form a cluster while the Asia/Pacific indices forms another\ncluster. By further increasing the value of threshold to 0.9, European\ncountries France, Germany and UK constitute the most tightly linked markets. We\nstudy multifractal properties of global financial indices and find that\nfinancial indices corresponding to Americas and Europe almost lie in the same\nrange of degree of multifractality as compared to other indices. India, South\nKorea, Hong Kong are found to be near the degree of multifractality of indices\ncorresponding to Americas and Europe. A large variation in the degree of\nmultifractality in Egypt, Indonesia, Malaysia, Taiwan and Singapore may be a\nreason that when we increase the threshold in financial network these countries\nfirst start getting disconnected at low threshold from the correlation network\nof financial indices. We fit Binomial Multifractal Model (BMFM) to these\nfinancial markets.\n"
    },
    {
        "paper_id": 1202.0447,
        "authors": "B. Acciaio, M. Beiglb\\\"ock, F. Penkner, W. Schachermayer, J. Temme",
        "title": "A trajectorial interpretation of Doob's martingale inequalities",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP878 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 4, 1494-1505",
        "doi": "10.1214/12-AAP878",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a unified approach to Doob's $L^p$ maximal inequalities for $1\\leq\np<\\infty$. The novelty of our method is that these martingale inequalities are\nobtained as consequences of elementary deterministic counterparts. The latter\nhave a natural interpretation in terms of robust hedging. Moreover, our\ndeterministic inequalities lead to new versions of Doob's maximal inequalities.\nThese are best possible in the sense that equality is attained by properly\nchosen martingales.\n"
    },
    {
        "paper_id": 1202.0587,
        "authors": "Zorana Grbac, Antonis Papapantoleon",
        "title": "A tractable LIBOR model with default risk",
        "comments": "26 pages. Forthcoming in Mathematics and Financial Economics",
        "journal-ref": "Mathematics and Financial Economics 2013, Vol 7, No 2, 203-227",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a model for the dynamic evolution of default-free and defaultable\ninterest rates in a LIBOR framework. Utilizing the class of affine processes,\nthis model produces positive LIBOR rates and spreads, while the dynamics are\nanalytically tractable under defaultable forward measures. This leads to\nexplicit formulas for CDS spreads, while semi-analytical formulas are derived\nfor other credit derivatives. Finally, we give an application to counterparty\nrisk.\n"
    },
    {
        "paper_id": 1202.0606,
        "authors": "Ribin Lye and James Peng Lung Tan and Siew Ann Cheong",
        "title": "Understanding agent-based models of financial markets: a bottom-up\n  approach based on order parameters and phase diagrams",
        "comments": "elsarticle.cls, 22 pages, 10 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.06.014",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We describe a bottom-up framework, based on the identification of appropriate\norder parameters and determination of phase diagrams, for understanding\nprogressively refined agent-based models and simulations of financial markets.\nWe illustrate this framework by starting with a deterministic toy model,\nwhereby $N$ independent traders buy and sell $M$ stocks through an order book\nthat acts as a clearing house. The price of a stock increases whenever it is\nbought and decreases whenever it is sold. Price changes are updated by the\norder book before the next transaction takes place. In this deterministic\nmodel, all traders based their buy decisions on a call utility function, and\nall their sell decisions on a put utility function. We then make the\nagent-based model more realistic, by either having a fraction $f_b$ of traders\nbuy a random stock on offer, or a fraction $f_s$ of traders sell a random stock\nin their portfolio. Based on our simulations, we find that it is possible to\nidentify useful order parameters from the steady-state price distributions of\nall three models. Using these order parameters as a guide, we find three\nphases: (i) the dead market; (ii) the boom market; and (iii) the jammed market\nin the the phase diagram of the deterministic model. Comparing the phase\ndiagrams of the stochastic models against that of the deterministic model, we\nrealize that the primary effect of stochasticity is to eliminate the dead\nmarket phase.\n"
    },
    {
        "paper_id": 1202.0608,
        "authors": "Masaaki Fujii, Akihiko Takahashi",
        "title": "Perturbative Expansion of FBSDE in an Incomplete Market with Stochastic\n  Volatility",
        "comments": "Accepted version for Quarterly Journal of Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we apply our newly proposed perturbative expansion technique to\na quadratic growth FBSDE appearing in an incomplete market with stochastic\nvolatility that is not perfectly hedgeable. By combining standard asymptotic\nexpansion technique for the underlying volatility process, we derive explicit\nexpression for the solution of the FBSDE up to the third order of\nvolatility-of-volatility, which can be directly translated into the optimal\ninvestment strategy. We compare our approximation with the exact solution,\nwhich is known to be derived by the Cole-Hopf transformation in this popular\nsetup. The result is very encouraging and shows good accuracy of the\napproximation up to quite long maturities. Since our new methodology can be\nextended straightforwardly to multi-dimensional setups, we expect it will open\nreal possibilities to obtain explicit optimal portfolios or hedging strategies\nunder realistic assumptions.\n"
    },
    {
        "paper_id": 1202.0628,
        "authors": "Miklos Rasonyi and Andrea M. Rodrigues",
        "title": "Optimal Portfolio Choice for a Behavioural Investor in Continuous-Time\n  Markets",
        "comments": "An error corrected (Proposition 3.4 and the ensuing unnumbered\n  Remark)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this work consists in the study of the optimal investment strategy\nfor a behavioural investor, whose preference towards risk is described by both\na probability distortion and an S-shaped utility function. Within a\ncontinuous-time financial market framework and assuming that asset prices are\nmodelled by semimartingales, we derive sufficient and necessary conditions for\nthe well-posedness of the optimisation problem in the case of piecewise-power\nprobability distortion and utility functions. Finally, under straightforwardly\nverifiable conditions, we further demonstrate the existence of an optimal\nstrategy.\n"
    },
    {
        "paper_id": 1202.0996,
        "authors": "Anca Gheorghiu and Ion Spanulescu",
        "title": "An Econophysics Model for the Migration Phenomena",
        "comments": "13 pages, 6 figures, ENEC 2011 Conference, vol 4, no 2, 2011,\n  http://journal.universitateahyperion.ro/archive.html; ISSN: 2069-3508",
        "journal-ref": "Hyperion International for Econophysics and New Economy, vol 4,\n  issue 2, 2011 pp. 272-284",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Knowing and modelling the migration phenomena and especially the social and\neconomic consequences have a theoretical and practical importance, being\nrelated to their consequences for development, economic progress (or as\nappropriate, regression), environmental influences etc. One of the causes of\nmigration, especially of the interregional and why not intercontinental, is\nthat resources are unevenly distributed, and from the human perspective there\nare differences in culture, education, mentality, collective aspirations etc.\nThis study proposes a new econophysics model for the migration phenomena.\n"
    },
    {
        "paper_id": 1202.1302,
        "authors": "Amel Bentata, Rama Cont",
        "title": "Short-time asymptotics for marginal distributions of semimartingales",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the short-time asymptotics of conditional expectations of smooth and\nnon-smooth functions of a (discontinuous) Ito semimartingale; we compute the\nleading term in the asymptotics in terms of the local characteristics of the\nsemimartingale. We derive in particular the asymptotic behavior of call options\nwith short maturity in a semimartingale model: whereas the behavior of\n\\textit{out-of-the-money} options is found to be linear in time, the short time\nasymptotics of \\textit{at-the-money} options is shown to depend on the fine\nstructure of the semimartingale.\n"
    },
    {
        "paper_id": 1202.1374,
        "authors": "Anita Mehta",
        "title": "Predatory trading and risk minimisation: how to (b)eat the competition",
        "comments": "19 pages, 13 figures, written for the Proceedings of the\n  International Workshop on the \"Econophysics of systemic risk and network\n  dynamics\" (Springer Verlag Italia)",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-2553-0_10",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a model of predatory traders interacting with each other in the\npresence of a central reserve (which dissipates their wealth through say,\ntaxation), as well as inflation. This model is examined on a network for the\npurposes of correlating complexity of interactions with systemic risk. We\nsuggest the use of selective networking to enhance the survival rates of\narbitrarily chosen traders. Our conclusions show that networking with 'doomed'\ntraders is the most risk-free scenario, and that if a trader is to network with\npeers, it is far better to do so with those who have less intrinsic wealth than\nhimself to ensure individual, and perhaps systemic stability.\n"
    },
    {
        "paper_id": 1202.1448,
        "authors": "Neil Johnson, Guannan Zhao, Eric Hunsader, Jing Meng, Amith Ravindar,\n  Spencer Carran and Brian Tivnan",
        "title": "Financial black swans driven by ultrafast machine ecology",
        "comments": "Working paper. Scientific comments and feedback welcome",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Society's drive toward ever faster socio-technical systems, means that there\nis an urgent need to understand the threat from 'black swan' extreme events\nthat might emerge. On 6 May 2010, it took just five minutes for a spontaneous\nmix of human and machine interactions in the global trading cyberspace to\ngenerate an unprecedented system-wide Flash Crash. However, little is known\nabout what lies ahead in the crucial sub-second regime where humans become\nunable to respond or intervene sufficiently quickly. Here we analyze a set of\n18,520 ultrafast black swan events that we have uncovered in stock-price\nmovements between 2006 and 2011. We provide empirical evidence for, and an\naccompanying theory of, an abrupt system-wide transition from a mixed\nhuman-machine phase to a new all-machine phase characterized by frequent black\nswan events with ultrafast durations (<650ms for crashes, <950ms for spikes).\nOur theory quantifies the systemic fluctuations in these two distinct phases in\nterms of the diversity of the system's internal ecology and the amount of\nglobal information being processed. Our finding that the ten most susceptible\nentities are major international banks, hints at a hidden relationship between\nthese ultrafast 'fractures' and the slow 'breaking' of the global financial\nsystem post-2006. More generally, our work provides tools to help predict and\nmitigate the systemic risk developing in any complex socio-technical system\nthat attempts to operate at, or beyond, the limits of human response times.\n"
    },
    {
        "paper_id": 1202.1623,
        "authors": "Michael C. M\\\"unnix, Takashi Shimada, Rudi Sch\\\"afer, Francois Leyvraz\n  Thomas H. Seligman, Thomas Guhr, H. E. Stanley",
        "title": "Identifying States of a Financial Market",
        "comments": "9 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The understanding of complex systems has become a central issue because\ncomplex systems exist in a wide range of scientific disciplines. Time series\nare typical experimental results we have about complex systems. In the analysis\nof such time series, stationary situations have been extensively studied and\ncorrelations have been found to be a very powerful tool. Yet most natural\nprocesses are non-stationary. In particular, in times of crisis, accident or\ntrouble, stationarity is lost. As examples we may think of financial markets,\nbiological systems, reactors or the weather. In non-stationary situations\nanalysis becomes very difficult and noise is a severe problem. Following a\nnatural urge to search for order in the system, we endeavor to define states\nthrough which systems pass and in which they remain for short times. Success in\nthis respect would allow to get a better understanding of the system and might\neven lead to methods for controlling the system in more efficient ways.\n  We here concentrate on financial markets because of the easy access we have\nto good data and because of the strong non-stationary effects recently seen. We\nanalyze the S&P 500 stocks in the 19-year period 1992-2010. Here, we propose\nsuch an above mentioned definition of state for a financial market and use it\nto identify points of drastic change in the correlation structure. These points\nare mapped to occurrences of financial crises. We find that a wide variety of\ncharacteristic correlation structure patterns exist in the observation time\nwindow, and that these characteristic correlation structure patterns can be\nclassified into several typical \"market states\". Using this classification we\nrecognize transitions between different market states. A similarity measure we\ndevelop thus affords means of understanding changes in states and of\nrecognizing developments not previously seen.\n"
    },
    {
        "paper_id": 1202.1854,
        "authors": "Jozef Barunik, Lukas Vacha",
        "title": "Realized wavelet-based estimation of integrated variance and jumps in\n  the presence of noise",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce wavelet-based methodology for estimation of realized variance\nallowing its measurement in the time-frequency domain. Using smooth wavelets\nand Maximum Overlap Discrete Wavelet Transform, we allow for the decomposition\nof the realized variance into several investment horizons and jumps. Basing our\nestimator in the two-scale realized variance framework, we are able to utilize\nall available data and get feasible estimator in the presence of microstructure\nnoise as well. The estimator is tested in a large numerical study of the finite\nsample performance and is compared to other popular realized variation\nestimators. We use different simulation settings with changing noise as well as\njump level in different price processes including long memory fractional\nstochastic volatility model. The results reveal that our wavelet-based\nestimator is able to estimate and forecast the realized measures with the\ngreatest precision. Our time-frequency estimators not only produce feasible\nestimates, but also decompose the realized variation into arbitrarily chosen\ninvestment horizons. We apply it to study the volatility of forex futures\nduring the recent crisis at several investment horizons and obtain the results\nwhich provide us with better understanding of the volatility dynamics.\n"
    },
    {
        "paper_id": 1202.1949,
        "authors": "Jean-Claude Juhel (CRIFP)",
        "title": "Choix strat\\'egiques de la firme et contr\\^ole financier",
        "comments": "arXiv admin note: significant text overlap with arXiv:1004.0682",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Observation of the workings of productive organizations shows that the\ncharacteristics of a trade, backed by nature given to a technological\nenvironment, determine the productive combination implemented by the decision\nmaker, and the structure of the operating cycle which is related. The choice of\nthe production function and the choice of the ring structure strain the\noperating conditions under which the firm's cash flow will evolve. New tools\nfor financial control - leverage cash and operating cash surplus - provide the\nentrepreneur the information relevant to the efficiency of the strategic\nchoices of the firm.\n"
    },
    {
        "paper_id": 1202.2076,
        "authors": "Henri Pag\\`es and Dylan Possama\\\"i",
        "title": "A mathematical treatment of bank monitoring incentives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we take up the analysis of a principal/agent model with moral\nhazard introduced in [17], with optimal contracting between competitive\ninvestors and an impatient bank monitoring a pool of long-term loans subject to\nMarkovian contagion. We provide here a comprehensive mathematical formulation\nof the model and show using martingale arguments in the spirit of Sannikov [18]\nhow the maximization problem with implicit constraints faced by investors can\nbe reduced to a classical stochastic control problem. The approach has the\nadvantage of avoiding the more general techniques based on forward-backward\nstochastic differential equations described in [6] and leads to a simple\nrecursive system of Hamilton-Jacobi-Bellman equations. We provide a solution to\nour problem by a verification argument and give an explicit description of both\nthe value function and the optimal contract. Finally, we study the limit case\nwhere the bank is no longer impatient.\n"
    },
    {
        "paper_id": 1202.208,
        "authors": "Carlos Pedro Gon\\c{c}alves",
        "title": "Quantum Financial Economics of Games of Strategy and Financial Decisions",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A quantum financial approach to finite games of strategy is addressed, with\nan extension of Nash's theorem to the quantum financial setting, allowing for\nan entanglement of games of strategy with two-period financial allocation\nproblems that are expressed in terms of: the consumption plans' optimization\nproblem in pure exchange economies and the finite-state securities market\noptimization problem, thus addressing, within the financial setting, the\ninterplay between companies' business games and financial agents' behavior.\n  A complete set of quantum Arrow-Debreu prices, resulting from the game of\nstrategy's quantum Nash equilibrium, is shown to hold, even in the absence of\nsecurities' market completeness, such that Pareto optimal results are obtained\nwithout having to assume the completeness condition that the rank of the\nsecurities' payoff matrix is equal to the number of alternative lottery states.\n"
    },
    {
        "paper_id": 1202.2447,
        "authors": "Fulvio Baldovin, Francesco Camana, Massimiliano Caporin, Michele\n  Caraglio, Attilio L. Stella",
        "title": "Ensemble properties of high frequency data and intraday trading rules",
        "comments": "21 pages, 10 figures. Throughout revision and correction of the first\n  version. Extension of the trading strategy to the whole day",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Regarding the intraday sequence of high frequency returns of the S&P index as\ndaily realizations of a given stochastic process, we first demonstrate that the\nscaling properties of the aggregated return distribution can be employed to\ndefine a martingale stochastic model which consistently replicates conditioned\nexpectations of the S&P 500 high frequency data in the morning of each trading\nday. Then, a more general formulation of the above scaling properties allows to\nextend the model to the afternoon trading session. We finally outline an\napplication in which conditioned forecasting is used to implement a\ntrend-following trading strategy capable of exploiting linear correlations\npresent in the S&P dataset and absent in the model. Trading signals are\nmodel-based and not derived from chartist criteria. In-sample and out-of-sample\ntests indicate that the model-based trading strategy performs better than a\nbenchmark one established on an asymmetric GARCH process, and show the\nexistence of small arbitrage opportunities. We remark that in the absence of\nlinear correlations the trading profit would vanish and discuss why the trading\nstrategy is potentially interesting to hedge volatility risk for S&P\nindex-based products.\n"
    },
    {
        "paper_id": 1202.2532,
        "authors": "Marco Bardoscia, Roberto Bellotti",
        "title": "A Dynamical Approach to Operational Risk Measurement",
        "comments": "19 pages, 2 figures",
        "journal-ref": "Journal of Operational Risk 6-1 (2011), pp. 3-19",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a dynamical model for the estimation of Operational Risk in\nbanking institutions. Operational Risk is the risk that a financial loss occurs\nas the result of failed processes. Examples of operational losses are the ones\ngenerated by internal frauds, human errors or failed transactions. In order to\nencompass the most heterogeneous set of processes, in our approach the losses\nof each process are generated by the interplay among random noise, interactions\nwith other processes and the efforts the bank makes to avoid losses. We show\nhow some relevant parameters of the model can be estimated from a database of\nhistorical operational losses, validate the estimation procedure and test the\nforecasting power of the model. Some advantages of our approach over the\ntraditional statistical techniques are that it allows to follow the whole time\nevolution of the losses and to take into account different-time correlations\namong the processes.\n"
    },
    {
        "paper_id": 1202.2559,
        "authors": "Salima El Kolei",
        "title": "Parametric estimation of hidden stochastic model by contrast\n  minimization and deconvolution: application to the Stochastic Volatility\n  Model",
        "comments": "46 pages",
        "journal-ref": "Metrika, journal 184 article 430, 2013",
        "doi": "10.1007/s00184-013-0430-3.",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a new parametric approach for particular hidden stochastic models\nsuch as the Stochastic Volatility model. This method is based on contrast\nminimization and deconvolution. After proving consistency and asymptotic\nnormality of the estimation leading to asymptotic confidence intervals, we\nprovide a thorough numerical study, which compares most of the classical\nmethods that are used in practice (Quasi Maximum Likelihood estimator,\nSimulated Expectation Maximization Likelihood estimator and Bayesian\nestimators). We prove that our estimator clearly outperforms the Maximum\nLikelihood Estimator in term of computing time, but also most of the other\nmethods. We also show that this contrast method is the most robust with respect\nto non Gaussianity of the error and also does not need any tuning parameter.\n"
    },
    {
        "paper_id": 1202.2585,
        "authors": "Jacob Abernethy, Rafael M. Frongillo, and Andre Wibisono",
        "title": "Minimax Option Pricing Meets Black-Scholes in the Limit",
        "comments": "19 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Option contracts are a type of financial derivative that allow investors to\nhedge risk and speculate on the variation of an asset's future market price. In\nshort, an option has a particular payout that is based on the market price for\nan asset on a given date in the future. In 1973, Black and Scholes proposed a\nvaluation model for options that essentially estimates the tail risk of the\nasset price under the assumption that the price will fluctuate according to\ngeometric Brownian motion. More recently, DeMarzo et al., among others, have\nproposed more robust valuation schemes, where we can even assume an adversary\nchooses the price fluctuations. This framework can be considered as a\nsequential two-player zero-sum game between the investor and Nature. We analyze\nthe value of this game in the limit, where the investor can trade at smaller\nand smaller time intervals. Under weak assumptions on the actions of Nature (an\nadversary), we show that the minimax option price asymptotically approaches\nexactly the Black-Scholes valuation. The key piece of our analysis is showing\nthat Nature's minimax optimal dual strategy converges to geometric Brownian\nmotion in the limit.\n"
    },
    {
        "paper_id": 1202.298,
        "authors": "Luciano Campi, Umut \\c{C}etin and Albina Danilova",
        "title": "Dynamic Markov bridges motivated by models of insider trading",
        "comments": null,
        "journal-ref": "Stochastic processes and their applications, 2011, 121 (3). pp.\n  534-567",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Given a Markovian Brownian martingale $Z$, we build a process $X$ which is a\nmartingale in its own filtration and satisfies $X_1 = Z_1$. We call $X$ a\ndynamic bridge, because its terminal value $Z_1$ is not known in advance. We\ncompute explicitly its semimartingale decomposition under both its own\nfiltration $\\cF^X$ and the filtration $\\cF^{X,Z}$ jointly generated by $X$ and\n$Z$. Our construction is heavily based on parabolic PDE's and filtering\ntechniques. As an application, we explicitly solve an equilibrium model with\ninsider trading, that can be viewed as a non-Gaussian generalization of Back\nand Pedersen's \\cite{BP}, where insider's additional information evolves over\ntime.\n"
    },
    {
        "paper_id": 1202.2999,
        "authors": "Daniel Fernholz, Ioannis Karatzas",
        "title": "Optimal arbitrage under model uncertainty",
        "comments": "Published in at http://dx.doi.org/10.1214/10-AAP755 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2011, Vol. 21, No. 6, 2191-2225",
        "doi": "10.1214/10-AAP755",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an equity market model with \"Knightian\" uncertainty regarding the relative\nrisk and covariance structure of its assets, we characterize in several ways\nthe highest return relative to the market that can be achieved using\nnonanticipative investment rules over a given time horizon, and under any\nadmissible configuration of model parameters that might materialize. One\ncharacterization is in terms of the smallest positive supersolution to a fully\nnonlinear parabolic partial differential equation of the\nHamilton--Jacobi--Bellman type. Under appropriate conditions, this smallest\nsupersolution is the value function of an associated stochastic control\nproblem, namely, the maximal probability with which an auxiliary\nmultidimensional diffusion process, controlled in a manner which affects both\nits drift and covariance structures, stays in the interior of the positive\northant through the end of the time-horizon. This value function is also\ncharacterized in terms of a stochastic game, and can be used to generate an\ninvestment rule that realizes such best possible outperformance of the market.\n"
    },
    {
        "paper_id": 1202.3002,
        "authors": "Takashi Kato, Akihiko Takahashi and Toshihiro Yamada",
        "title": "A Semi-group Expansion for Pricing Barrier Options",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": "10.1155/2014/268086",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a new asymptotic expansion method for pricing\ncontinuously monitoring barrier options. In particular, we develops a\nsemi-group expansion scheme for the Cauchy-Dirichlet problem in the\nsecond-order parabolic partial differential equations (PDEs) arising in barrier\noption pricing. As an application, we propose a concrete approximation formula\nunder a stochastic volatility model and demonstrate its validity by some\nnumerical experiments.\n"
    },
    {
        "paper_id": 1202.3025,
        "authors": "Sebastian Heise and Reimer Kuehn",
        "title": "Derivatives and Credit Contagion in Interconnected Networks",
        "comments": "26 pages, 7 multi-part figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2012-20740-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The importance of adequately modeling credit risk has once again been\nhighlighted in the recent financial crisis. Defaults tend to cluster around\ntimes of economic stress due to poor macro-economic conditions, {\\em but also}\nby directly triggering each other through contagion. Although credit default\nswaps have radically altered the dynamics of contagion for more than a decade,\nmodels quantifying their impact on systemic risk are still missing. Here, we\nexamine contagion through credit default swaps in a stylized economic network\nof corporates and financial institutions. We analyse such a system using a\nstochastic setting, which allows us to exploit limit theorems to exactly solve\nthe contagion dynamics for the entire system. Our analysis shows that, by\ncreating additional contagion channels, CDS can actually lead to greater\ninstability of the entire network in times of economic stress. This is\nparticularly pronounced when CDS are used by banks to expand their loan books\n(arguing that CDS would offload the additional risks from their balance\nsheets). Thus, even with complete hedging through CDS, a significant loan book\nexpansion can lead to considerably enhanced probabilities for the occurrence of\nvery large losses and very high default rates in the system. Our approach adds\na new dimension to research on credit contagion, and could feed into a rational\nunderpinning of an improved regulatory framework for credit derivatives.\n"
    },
    {
        "paper_id": 1202.3182,
        "authors": "Andrey Sokolov, Rachel Webster, Andrew Melatos, Tien Kieu",
        "title": "Loan and nonloan flows in the Australian interbank network",
        "comments": null,
        "journal-ref": "Physica A 391 (2012) 2867-2882",
        "doi": "10.1016/j.physa.2011.12.036",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  High-value transactions between Australian banks are settled in the Reserve\nBank Information and Transfer System (RITS) administered by the Reserve Bank of\nAustralia. RITS operates on a real-time gross settlement (RTGS) basis and\nsettles payments sourced from the SWIFT, the Austraclear, and the interbank\ntransactions entered directly into RITS. In this paper, we analyse a dataset\nreceived from the Reserve Bank of Australia that includes all interbank\ntransactions settled in RITS on an RTGS basis during five consecutive weekdays\nfrom 19 February 2007 inclusive, a week of relatively quiescent market\nconditions. The source, destination, and value of each transaction are known,\nwhich allows us to separate overnight loans from other transactions (nonloans)\nand reconstruct monetary flows between banks for every day in our sample. We\nconduct a novel analysis of the flow stability and examine the connection\nbetween loan and nonloan flows. Our aim is to understand the underlying causal\nmechanism connecting loan and nonloan flows. We find that the imbalances in the\nbanks' exchange settlement funds resulting from the daily flows of nonloan\ntransactions are almost exactly counterbalanced by the flows of overnight\nloans. The correlation coefficient between loan and nonloan imbalances is about\n-0.9 on most days. Some flows that persist over two consecutive days can be\nhighly variable, but overall the flows are moderately stable in value. The\nnonloan network is characterised by a large fraction of persistent flows,\nwhereas only half of the flows persist over any two consecutive days in the\nloan network. Moreover, we observe an unusual degree of coherence between\npersistent loan flow values on Tuesday and Wednesday. We probe static\ntopological properties of the Australian interbank network and find them\nconsistent with those observed in other countries.\n"
    },
    {
        "paper_id": 1202.3217,
        "authors": "Jan Baldeaux and Dale Roberts",
        "title": "Quasi-Monte Carlo methods for the Heston model",
        "comments": "20 pages. Submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we discuss the application of quasi-Monte Carlo methods to the\nHeston model. We base our algorithms on the Broadie-Kaya algorithm, an exact\nsimulation scheme for the Heston model. As the joint transition densities are\nnot available in closed-form, the Linear Transformation method due to Imai and\nTan, a popular and widely applicable method to improve the effectiveness of\nquasi-Monte Carlo methods, cannot be employed in the context of path-dependent\noptions when the underlying price process follows the Heston model.\nConsequently, we tailor quasi-Monte Carlo methods directly to the Heston model.\nThe contributions of the paper are threefold: We firstly show how to apply\nquasi-Monte Carlo methods in the context of the Heston model and the SVJ model,\nsecondly that quasi-Monte Carlo methods improve on Monte Carlo methods, and\nthirdly how to improve the effectiveness of quasi-Monte Carlo methods by using\nbridge constructions tailored to the Heston and SVJ models. Finally, we provide\nsome extensions for computing greeks, barrier options, multidimensional and\nmulti-asset pricing, and the 3/2 model.\n"
    },
    {
        "paper_id": 1202.3533,
        "authors": "Aleksejus Kononovicius, Vygintas Gontis, Valentas Daniunas",
        "title": "Agent-based Versus Macroscopic Modeling of Competition and Business\n  Processes in Economics and Finance",
        "comments": "20 pages, 8 figures",
        "journal-ref": "International Journal On Advances in Intelligent Systems, volume\n  5, pages 111-126, 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present examples of agent-based and stochastic models of competition and\nbusiness processes in economics and finance. We start from as simple as\npossible models, which have microscopic, agent-based, versions and macroscopic\ntreatment in behavior. Microscopic and macroscopic versions of herding model\nproposed by Kirman and Bass diffusion of new products are considered in this\ncontribution as two basic ideas. Further we demonstrate that general herding\nbehavior can be considered as a background of nonlinear stochastic model of\nfinancial fluctuations.\n"
    },
    {
        "paper_id": 1202.3755,
        "authors": "Takayuki Osogami",
        "title": "Iterated risk measures for risk-sensitive Markov decision processes with\n  discounted cost",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We demonstrate a limitation of discounted expected utility, a standard\napproach for representing the preference to risk when future cost is\ndiscounted. Specifically, we provide an example of the preference of a decision\nmaker that appears to be rational but cannot be represented with any discounted\nexpected utility. A straightforward modification to discounted expected utility\nleads to inconsistent decision making over time. We will show that an iterated\nrisk measure can represent the preference that cannot be represented by any\ndiscounted expected utility and that the decisions based on the iterated risk\nmeasure are consistent over time.\n"
    },
    {
        "paper_id": 1202.3915,
        "authors": "A. Saichev and D. Sornette",
        "title": "A simple microstructure return model explaining microstructure noise and\n  Epps effects",
        "comments": "31 pages + 19 figures",
        "journal-ref": "International Journal of Modern Physics C 25 (6),1450012 (36\n  pages) (2014)",
        "doi": "10.1142/S0129183114500120",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a simple microstructure model of financial returns that combines\n(i) the well-known ARFIMA process applied to tick-by-tick returns, (ii) the\nbid-ask bounce effect, (iii) the fat tail structure of the distribution of\nreturns and (iv) the non-Poissonian statistics of inter-trade intervals. This\nmodel allows us to explain both qualitatively and quantitatively important\nstylized facts observed in the statistics of microstructure returns, including\nthe short-ranged correlation of returns, the long-ranged correlations of\nabsolute returns, the microstructure noise and Epps effects. According to the\nmicrostructure noise effect, volatility is a decreasing function of the time\nscale used to estimate it. Paradoxically, the Epps effect states that cross\ncorrelations between asset returns are increasing functions of the time scale\nat which the returns are estimated. The microstructure noise is explained as\nthe result of the negative return correlations inherent in the definition of\nthe bid-ask bounce component (ii). In the presence of a genuine correlation\nbetween the returns of two assets, the Epps effect is due to an average\nstatistical overlap of the momentum of the returns of the two assets defined\nover a finite time scale in the presence of the long memory process (i).\n"
    },
    {
        "paper_id": 1202.4007,
        "authors": "Scott Robertson",
        "title": "Pricing for Large Positions in Contingent Claims",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Approximations to utility indifference prices are provided for a contingent\nclaim in the large position size limit. Results are valid for general utility\nfunctions on the real line and semi-martingale models. It is shown that as the\nposition size approaches infinity, the utility function's decay rate for large\nnegative wealths is the primary driver of prices. For utilities with\nexponential decay, one may price like an exponential investor. For utilities\nwith a power decay, one may price like a power investor after a suitable\nadjustment to the rate at which the position size becomes large. In a sizable\nclass of diffusion models, limiting indifference prices are explicitly computed\nfor an exponential investor. Furthermore, the large claim limit is seen to\nendogenously arise as the hedging error for the claim vanishes.\n"
    },
    {
        "paper_id": 1202.4311,
        "authors": "Alexander Saichev and Svetlana Lapinova",
        "title": "Comparative statistics of Garman-Klass, Parkinson, Roger-Satchell and\n  bridge estimators",
        "comments": "18 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  Comparative statistical properties of Parkinson, Garman-Klass, Roger-Satchell\nand bridge oscillation estimators are discussed. Point and interval\nestimations, related with mentioned estimators are considered\n"
    },
    {
        "paper_id": 1202.4332,
        "authors": "Enrico Scalas, Mauro Politi",
        "title": "A parsimonious model for intraday European option pricing",
        "comments": "Submitted to Economics E-Journal:\n  http://www.economics-ejournal.org/economics/discussionpapers/2012-14",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A stochastic model for pure-jump diffusion (the compound renewal process) can\nbe used as a zero-order approximation and as a phenomenological description of\ntick-by-tick price fluctuations. This leads to an exact and explicit general\nformula for the martingale price of a European call option. A complete\nderivation of this result is presented by means of elementary probabilistic\ntools.\n"
    },
    {
        "paper_id": 1202.4877,
        "authors": "Martin Rypdal, Espen Sirnes, Ola L{\\o}vsletten, Kristoffer Rypdal",
        "title": "Assessing market uncertainty by means of a time-varying intermittency\n  parameter for asset price fluctuations",
        "comments": "8 pages, 4 figures, 2 tables",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.02.010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Maximum likelihood estimation applied to high-frequency data allows us to\nquantify intermittency in the fluctu- ations of asset prices. From time records\nas short as one month these methods permit extraction of a meaningful\nintermittency parameter {\\lambda} characterising the degree of volatility\nclustering of asset prices. We can therefore study the time evolution of\nvolatility clustering and test the statistical significance of this\nvariability. By analysing data from the Oslo Stock Exchange, and comparing the\nresults with the investment grade spread, we find that the estimates of\n{\\lambda} are lower at times of high market uncertainty.\n"
    },
    {
        "paper_id": 1202.4913,
        "authors": "Guanghui Huang, Wenting Xin, Weiqing Gu",
        "title": "Active margin system for margin loans and its application in Chinese\n  market: using cash and randomly selected stock as collateral",
        "comments": "16 pages,5 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An active margin system for margin loans is proposed for Chinese margin\nlending market, which uses cash and randomly selected stock as collateral. The\nconditional probability of negative return(CPNR) after a forced sale of\nsecurities from under-margined account in a falling market is used to measure\nthe risk faced by the brokers, and the margin system is chosen under the\nconstraint of the risk measure. In order to calculate CPNR, a recursive\nalgorithm is proposed under a Markov chain model, which is constructed by\nsample learning method. The resulted margin system is an active system, which\nis able to adjust actively with respect to the changes of stock prices and the\nchanges of different collateral. The resulted margin system is applied to\n30,000 margin loans of 150 stocks listed on Shanghai Stock Exchange. The\nempirical results show the number of margin calls and the average costs of the\nloans under the proposed margin system are less than their counterparts under\nthe system required by SSE and SZSE.\n"
    },
    {
        "paper_id": 1202.4918,
        "authors": "V.I. Yukalov and D. Sornette",
        "title": "Quantum decision making by social agents",
        "comments": "This paper has been withdrawn by the authors because a much extended\n  and improved version has been submitted as arXiv:1510.02686 under the new\n  title \"Role of information in decision making of social agents\"",
        "journal-ref": "International Journal of Information Technology & Decision Making\n  13 (2014) (pages 1-38)",
        "doi": "10.1142/S0219622014500564",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The influence of additional information on the decision making of agents, who\nare interacting members of a society, is analyzed within the mathematical\nframework based on the use of quantum probabilities. The introduction of social\ninteractions, which influence the decisions of individual agents, leads to a\ngeneralization of the quantum decision theory developed earlier by the authors\nfor separate individuals. The generalized approach is free of the standard\nparadoxes of classical decision theory. This approach also explains the\nerror-attenuation effects observed for the paradoxes occurring when decision\nmakers, who are members of a society, consult with each other, increasing in\nthis way the available mutual information. A precise correspondence between\nquantum decision theory and classical utility theory is formulated via the\nintroduction of an intermediate probabilistic version of utility theory of a\nnovel form, which obeys the requirement that zero-utility prospects should have\nzero probability weights.\n"
    },
    {
        "paper_id": 1202.518,
        "authors": "Guanghui Huang, Weiqing Gu, Wenting Xing, Hongyu Li",
        "title": "Active margin system for margin loans using cash and stock as collateral\n  and its application in Chinese market",
        "comments": "16 pages, 5 tables. arXiv admin note: significant text overlap with\n  arXiv:1101.3974",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Margin system for margin loans using cash and stock as collateral is\nconsidered in this paper, which is the line of defence for brokers against risk\nassociated with margin trading. The conditional probability of negative return\nis used as risk measure, and a recursive algorithm is proposed to realize this\nmeasure under a Markov chain model. Optimal margin system is chosen from those\nsystems which satisfy the constraint of the risk measure. The resulted margin\nsystem is able to adjust actively with respect to the changes of stock prices.\nThe margin system required by the Shanghai Stock Exchange is compared with the\nproposed system, where 25,200 margin loans of 126 stocks listed on the SSE are\ninvestigated. It is found that the number of margin calls under the proposed\nmargin system is significantly less than its counterpart under the required\nsystem for the same level of risk, and the average costs of the loans are\nsimilar under the two types of margin systems.\n"
    },
    {
        "paper_id": 1202.5251,
        "authors": "Alain B\\'elanger and Gaston Giroux",
        "title": "Information Percolation: Some General Cases with an Application to\n  Econophysics",
        "comments": "13 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We describe, at the microscopic level, the dynamics of N interacting\ncomponents where the probability is very small when N is large that a given\ncomponent interact more than once, directly or indirectly, up to time t, with\nany other component. Due to this fact, we can consider, at the macroscopic\nlevel, the quadratic system of differential equations associated with the\ninteraction and establish an explicit formula for the solution of this system.\nWe moreover apply our results to some models of Econophysics.\n"
    },
    {
        "paper_id": 1202.5376,
        "authors": "Ola L{\\o}vsletten and Martin Rypdal",
        "title": "A multifractal approach towards inference in finance",
        "comments": "8 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce tools for inference in the multifractal random walk introduced\nby Bacry et al. (2001). These tools include formulas for smoothing, filtering\nand volatility forecasting. In addition, we present methods for computing\nconditional densities for one- and multi-step returns. The inference techniques\npresented in this paper, including maximum likelihood estimation, are applied\nto data from the Oslo Stock Exchange, and it is observed that the volatility\nforecasts based on the multifractal random walk have a much richer structure\nthan the forecasts obtained from a basic stochastic volatility model.\n"
    },
    {
        "paper_id": 1202.5574,
        "authors": "John A. D. Appleby, John A. Daniels, Katja Krol",
        "title": "A Black--Scholes Model with Long Memory",
        "comments": "John Appleby and John Daniels were partially funded by the Science\n  Foundation Ireland grant 07/MI/008 \"Edgeworth Centre for Financial\n  Mathematics\". John Daniels was also partially funded by The Embark Initiative\n  operated by the Irish Research Council for Science, Engineering and\n  Technology (IRCSET) under the project \"Volatility Models in Inefficient\n  Markets\". Katja Krol was supported by the Deutsche Telekom Stiftung",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This note develops a stochastic model of asset volatility. The volatility\nobeys a continuous-time autoregressive equation. Conditions under which the\nprocess is asymptotically stationary and possesses long memory are\ncharacterised. Connections with the class of ARCH($\\infty$) processes are\nsketched.\n"
    },
    {
        "paper_id": 1202.5702,
        "authors": "Andreas H. Hamel, Birgit Rudloff, Mihaela Yankova",
        "title": "Set-valued average value at risk and its computation",
        "comments": "16 pages",
        "journal-ref": "Mathematics and Financial Economics 7 (2), 229-246, (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  New versions of the set-valued average value at risk for multivariate risks\nare introduced by generalizing the well-known certainty equivalent\nrepresentation to the set-valued case. The first \"regulator\" version is\nindependent from any market model whereas the second version, called the market\nextension, takes trading opportunities into account. Essential properties of\nboth versions are proven and an algorithmic approach is provided which admits\nto compute the values of both version over finite probability spaces. Several\nexamples illustrate various features of the theoretical constructions.\n"
    },
    {
        "paper_id": 1202.5926,
        "authors": "Eric Kemp-Benedict",
        "title": "Second-order Price Dynamics: Approach to Equilibrium with Perpetual\n  Arbitrage",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The notion that economies should normally be in equilibrium is by now\nwell-established; equally well-established is that economies are almost never\nprecisely in equilibrium. Using a very general formulation, we show that under\ndynamics that are second-order in time a price system can remain away from\nequilibrium with permanent and repeating opportunities for arbitrage, even when\na damping term drives the system towards equilibrium. We also argue that\nsecond-order dynamic equations emerge naturally when there are heterogeneous\neconomic actors, some behaving as active and knowledgeable arbitrageurs, and\nothers using heuristics. The essential mechanism is that active arbitrageurs\nare able to repeatedly benefit from the suboptimal heuristics that govern most\neconomic behavior.\n"
    },
    {
        "paper_id": 1202.5983,
        "authors": "Jakob S\\\"ohl and Mathias Trabs",
        "title": "Option calibration of exponential L\\'evy models: Confidence intervals\n  and empirical results",
        "comments": "to appear in Journal of Computational Finance",
        "journal-ref": "J. Comput. Finance 18(2) (2014) 91-119",
        "doi": "10.21314/JCF.2014.275",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Observing prices of European put and call options, we calibrate exponential\nL\\'evy models nonparametrically. We discuss the efficient implementation of the\nspectral estimation procedures for L\\'evy models of finite jump activity as\nwell as for self-decomposable L\\'evy models. Based on finite sample variances,\nconfidence intervals are constructed for the volatility, for the drift and,\npointwise, for the jump density. As demonstrated by simulations, these\nintervals perform well in terms of size and coverage probabilities. We compare\nthe performance of the procedures for finite and infinite jump activity based\non options on the German DAX index and find that both methods achieve good\ncalibration results. The stability of the finite activity model is studied when\nthe option prices are observed in a sequence of trading days.\n"
    },
    {
        "paper_id": 1202.6131,
        "authors": "H. Mete Soner and Nizar Touzi",
        "title": "Homogenization and asymptotics for small transaction costs",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the classical Merton problem of lifetime consumption-portfolio\noptimization problem with small proportional transaction costs. The first order\nterm in the asymptotic expansion is explicitly calculated through a singular\nergodic control problem which can be solved in closed form in the\none-dimensional case. Unlike the existing literature, we consider a general\nutility function and general dynamics for the underlying assets. Our arguments\nare based on ideas from the homogenization theory and use the convergence tools\nfrom the theory of viscosity solutions. The multidimensional case is studied in\nour accompanying paper using the same approach.\n"
    },
    {
        "paper_id": 1202.6187,
        "authors": "Peter Carr, Travis Fisher, Johannes Ruf",
        "title": "Why are quadratic normal volatility models analytically tractable?",
        "comments": null,
        "journal-ref": "SIAM Journal on Financial Mathematics, 2013 4:1, 185-202",
        "doi": "10.1137/120871973",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the class of \"Quadratic Normal Volatility\" models, which have\ndrawn much attention in the financial industry due to their analytic\ntractability and flexibility. We characterize these models as the ones that can\nbe obtained from stopped Brownian motion by a simple transformation and a\nchange of measure that only depends on the terminal value of the stopped\nBrownian motion. This explains the existence of explicit analytic formulas for\noption prices within Quadratic Normal Volatility models in the academic\nliterature.\n"
    },
    {
        "paper_id": 1202.6188,
        "authors": "Peter Carr, Travis Fisher, Johannes Ruf",
        "title": "On the Hedging of Options On Exploding Exchange Rates",
        "comments": "Major revision. Accepted by Finance and Stochastics. The original\n  publication is available at http://link.springer.com",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a novel pricing operator for complete, local martingale models. The\nnew pricing operator guarantees put-call parity to hold for model prices and\nthe value of a forward contract to match the buy-and-hold strategy, even if the\nunderlying follows strict local martingale dynamics. More precisely, we discuss\na change of num\\'eraire (change of currency) technique when the underlying is\nonly a local martingale modelling for example an exchange rate. The new pricing\noperator assigns prices to contingent claims according to the minimal cost for\nsuperreplication strategies that succeed with probability one for both\ncurrencies as num\\'eraire. Within this context, we interpret the lack of the\nmartingale property of an exchange-rate as a reflection of the possibility that\nthe num\\'eraire currency may devalue completely against the asset currency\n(hyperinflation).\n"
    },
    {
        "paper_id": 1202.6283,
        "authors": "Michael B. Giles, Lukasz Szpruch",
        "title": "Antithetic multilevel Monte Carlo estimation for multi-dimensional SDEs\n  without L\\'{e}vy area simulation",
        "comments": "Published in at http://dx.doi.org/10.1214/13-AAP957 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 4, 1585-1620",
        "doi": "10.1214/13-AAP957",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce a new multilevel Monte Carlo (MLMC) estimator for\nmulti-dimensional SDEs driven by Brownian motions. Giles has previously shown\nthat if we combine a numerical approximation with strong order of convergence\n$O(\\Delta t)$ with MLMC we can reduce the computational complexity to estimate\nexpected values of functionals of SDE solutions with a root-mean-square error\nof $\\epsilon$ from $O(\\epsilon^{-3})$ to $O(\\epsilon^{-2})$. However, in\ngeneral, to obtain a rate of strong convergence higher than $O(\\Delta t^{1/2})$\nrequires simulation, or approximation, of L\\'{e}vy areas. In this paper,\nthrough the construction of a suitable antithetic multilevel correction\nestimator, we are able to avoid the simulation of L\\'{e}vy areas and still\nachieve an $O(\\Delta t^2)$ multilevel correction variance for smooth payoffs,\nand almost an $O(\\Delta t^{3/2})$ variance for piecewise smooth payoffs, even\nthough there is only $O(\\Delta t^{1/2})$ strong convergence. This results in an\n$O(\\epsilon^{-2})$ complexity for estimating the value of European and Asian\nput and call options.\n"
    },
    {
        "paper_id": 1202.6412,
        "authors": "Rama Cont and Adrien De Larrard",
        "title": "Order book dynamics in liquid markets: limit theorems and diffusion\n  approximations",
        "comments": "40 pages, 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a model for the dynamics of a limit order book in a liquid market\nwhere buy and sell orders are submitted at high frequency. We derive a\nfunctional central limit theorem for the joint dynamics of the bid and ask\nqueues and show that, when the frequency of order arrivals is large, the\nintraday dynamics of the limit order book may be approximated by a Markovian\njump-diffusion process in the positive orthant, whose characteristics are\nexplicitly described in terms of the statistical properties of the underlying\norder flow. This result allows to obtain tractable analytical approximations\nfor various quantities of interest, such as the probability of a price increase\nor the distribution of the duration until the next price move, conditional on\nthe state of the order book. Our results allow for a wide range of\ndistributional assumptions and temporal dependence in the order flow and apply\nto a wide class of stochastic models proposed for order book dynamics,\nincluding models based on Poisson point processes, self-exciting point\nprocesses and models of the ACD-GARCH family.\n"
    },
    {
        "paper_id": 1202.6611,
        "authors": "Jakob S\\\"ohl",
        "title": "Confidence sets in nonparametric calibration of exponential L\\'evy\n  models",
        "comments": "to appear in Finance and Stochastics",
        "journal-ref": "Finance Stoch. 18 (2014) 617-649",
        "doi": "10.1007/s00780-014-0228-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Confidence intervals and joint confidence sets are constructed for the\nnonparametric calibration of exponential L\\'evy models based on prices of\nEuropean options. To this end, we show joint asymptotic normality in the\nspectral calibration method for the estimators of the volatility, the drift,\nthe jump intensity and the L\\'evy density at finitely many points.\n"
    },
    {
        "paper_id": 1202.6632,
        "authors": "Patrick Bei{\\ss}ner",
        "title": "Coherent Price Systems and Uncertainty-Neutral Valuation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider fundamental questions of arbitrage pricing arising when the\nuncertainty model is given by a set of possible mutually singular probability\nmeasures. With a single probability model, essential equivalence between the\nabsence of arbitrage and the existence of an equivalent martingale measure is a\nfolk theorem, see Harrison and Kreps (1979). We establish a microeconomic\nfoundation of sublinear price systems and present an extension result. In this\ncontext we introduce a prior dependent notion of marketed spaces and viable\nprice systems. We associate this extension with a canonically altered concept\nof equivalent symmetric martingale measure sets, in a dynamic trading framework\nunder absence of prior depending arbitrage. We prove the existence of such sets\nwhen volatility uncertainty is modeled by a stochastic differential equation,\ndriven by Peng's G-Brownian motions.\n"
    },
    {
        "paper_id": 1202.6647,
        "authors": "Carlos Pedro Gon\\c{c}alves",
        "title": "Chaos and Nonlinear Dynamics in a Quantum Artificial Economy",
        "comments": "16 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Chaos and nonlinear economic dynamics are addressed for a quantum coupled map\nlattice model of an artificial economy, with quantized supply and demand\nequilibrium conditions. The measure theoretic properties and the patterns that\nemerge in both the economic business volume dynamics' diagrams as well as in\nthe quantum mean field averages are addressed and conclusions are drawn in\nregards to the application of quantum chaos theory to address signatures of\nchaotic dynamics in relevant discrete economic state variables.\n"
    },
    {
        "paper_id": 1203.0163,
        "authors": "Cesar A. Hidalgo",
        "title": "Discovering East Africa's Industrial Opportunities",
        "comments": "Journal Version has a few corrections with respect to the pre-print;\n  German Marshall Fund Economic Policy Series, (2011)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  What are East Africa's industrial opportunities? In this article we explore\nthis question by using the Product Space to study the productive structure of\nfive south-east African countries: Kenya, Mozambique, Rwanda, Tanzania and\nZambia. The Product Space is a network connecting products that tend to be\nexported by the same sets of countries. Since countries are more likely to\ndevelop products that are close by in the Product Space to the ones that they\nalready produce, the Product Space can be used to help anticipate a country's\nindustrial opportunities.\n  Our results suggest that the most natural avenue for future product\ndiversification for these five south-east African nations resides in the\nagricultural sector, since all of these nations appear to have productive\nstructures that are pre-adapted to the production of many agricultural products\nthat none of them are currently exporting.\n  We conclude this paper by exploring the potential benefits of further\nregional economic integration by doing an exercise in which we pull together\nthe productive structures of these five countries. This exercise shows that the\nproducts that become more accessible in the combined economy are once again\npredominantly agricultural. These results suggest that while diversification\ninto all sectors should remain an important long-term goal of the region, the\npath towards increased diversification in the near future may well lie in a\nmore empowered and diverse agricultural sector.\n"
    },
    {
        "paper_id": 1203.0599,
        "authors": "Jingwei Liu, Xing Chen",
        "title": "Implied volatility formula of European Power Option Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive the implied volatility estimation formula in European power call\noptions pricing, where the payoff functions are in the form of\n$V=(S^{\\alpha}_T-K)^{+}$ and $V=(S^{\\alpha}_T-K^{\\alpha})^{+}$\n($\\alpha>0$)respectively. Using quadratic Taylor approximations, We develop the\ncomputing formula of implied volatility in European power call option and\nextend the traditional implied volatility formula of Charles J.Corrado, et al\n(1996) to general power option pricing. And the Monte-Carlo simulations are\nalso given.\n"
    },
    {
        "paper_id": 1203.0643,
        "authors": "Santanu Dey and Sandeep Juneja",
        "title": "Incorporating fat tails in financial models using entropic divergence\n  measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the existing financial literature, entropy based ideas have been proposed\nin portfolio optimization, in model calibration for options pricing as well as\nin ascertaining a pricing measure in incomplete markets. The abstracted problem\ncorresponds to finding a probability measure that minimizes the relative\nentropy (also called $I$-divergence) with respect to a known measure while it\nsatisfies certain moment constraints on functions of underlying assets. In this\npaper, we show that under $I$-divergence, the optimal solution may not exist\nwhen the underlying assets have fat tailed distributions, ubiquitous in\nfinancial practice. We note that this drawback may be corrected if\n`polynomial-divergence' is used. This divergence can be seen to be equivalent\nto the well known (relative) Tsallis or (relative) Renyi entropy. We discuss\nexistence and uniqueness issues related to this new optimization problem as\nwell as the nature of the optimal solution under different objectives. We also\nidentify the optimal solution structure under $I$-divergence as well as\npolynomial-divergence when the associated constraints include those on marginal\ndistribution of functions of underlying assets. These results are applied to a\nsimple problem of model calibration to options prices as well as to portfolio\nmodeling in Markowitz framework, where we note that a reasonable view that a\nparticular portfolio of assets has heavy tailed losses may lead to fatter and\nmore reasonable tail distributions of all assets.\n"
    },
    {
        "paper_id": 1203.1191,
        "authors": "Thomas Knispel",
        "title": "Asymptotics of robust utility maximization",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP764 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 1, 172-212",
        "doi": "10.1214/11-AAP764",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a stochastic factor model we maximize the long-term growth rate of robust\nexpected power utility with parameter $\\lambda\\in(0,1)$. Using duality methods\nthe problem is reformulated as an infinite time horizon, risk-sensitive control\nproblem. Our results characterize the optimal growth rate, an optimal long-term\ntrading strategy and an asymptotic worst-case model in terms of an ergodic\nBellman equation. With these results we propose a duality approach to a \"robust\nlarge deviations\" criterion for optimal long-term investment.\n"
    },
    {
        "paper_id": 1203.1311,
        "authors": "Ian Wilkinson (The University of Sydney)",
        "title": "The evolvability of business and the role of antitrust",
        "comments": "37 pages, 1 table, 1 Figure",
        "journal-ref": "Ian Wilkinson \"The Evolvability of Business and the Role of\n  Antitrust\" Antitrust Bulletin 51 (1) 2006, 111-141",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, based on theories of complex adaptive systems, I argue that\nthe main case for antitrust policy should be extended to include the criteria\nof \"evolvability.\" To date, the main case focuses on economizing, including\nmarket power as a key filter for identifying suspect cases. Both production and\ntransaction costs are considered as part of economizing and other factors are\nuse to consider the benefits of different industry structures. CAS analysis\nfocuses attention on dynamics, evolution and networks. As I will show, the\ncriteria of evolvability requires us to consider various types of direct and\nindirect network impacts in business that go beyond the traditional focus on\nproduction and transaction costs. These network impacts stem from the\nconnections between transactions and relations over time and place, including\nhow business arrangements at one time, limit or enable arrangements in the\nfuture. An assessment of the impacts, I argue, can and should be included in\nthe rules of antitrust and in the processes of antitrust case analysis and\ndecision making.\n"
    },
    {
        "paper_id": 1203.1313,
        "authors": "Marco Lagi, Yavni Bar-Yam, Karla Z. Bertrand and Yaneer Bar-Yam",
        "title": "UPDATE February 2012 - The Food Crises: Predictive validation of a\n  quantitative model of food prices including speculators and ethanol\n  conversion",
        "comments": "5 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Increases in global food prices have led to widespread hunger and social\nunrest---and an imperative to understand their causes. In a previous paper\npublished in September 2011, we constructed for the first time a dynamic model\nthat quantitatively agreed with food prices. Specifically, the model fit the\nFAO Food Price Index time series from January 2004 to March 2011, inclusive.\nThe results showed that the dominant causes of price increases during this\nperiod were investor speculation and ethanol conversion. The model included\ninvestor trend following as well as shifting between commodities, equities and\nbonds to take advantage of increased expected returns. Here, we extend the food\nprices model to January 2012, without modifying the model but simply continuing\nits dynamics. The agreement is still precise, validating both the descriptive\nand predictive abilities of the analysis. Policy actions are needed to avoid a\nthird speculative bubble that would cause prices to rise above recent peaks by\nthe end of 2012.\n"
    },
    {
        "paper_id": 1203.1399,
        "authors": "Paolo Guasoni, Scott Robertson",
        "title": "Portfolios and risk premia for the long run",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP767 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 1, 239-284",
        "doi": "10.1214/11-AAP767",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper develops a method to derive optimal portfolios and risk premia\nexplicitly in a general diffusion model for an investor with power utility and\na long horizon. The market has several risky assets and is potentially\nincomplete. Investment opportunities are driven by, and partially correlated\nwith, state variables which follow an autonomous diffusion. The framework nests\nmodels of stochastic interest rates, return predictability, stochastic\nvolatility and correlation risk. In models with several assets and a single\nstate variable, long-run portfolios and risk premia admit explicit formulas up\nthe solution of an ordinary differential equation which characterizes the\nprincipal eigenvalue of an elliptic operator. Multiple state variables lead to\na quasilinear partial differential equation which is solvable for many models\nof interest. The paper derives the long-run optimal portfolio and the long-run\noptimal pricing measures depending on relative risk aversion, as well as their\nfinite-horizon performance.\n"
    },
    {
        "paper_id": 1203.188,
        "authors": "N. Derzsy, Z. Neda, M.A. Santos",
        "title": "Income distribution patterns from a complete social security database",
        "comments": "10 pages, 7 Figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.06.027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the income distribution of employees for 9 consecutive years\n(2001-2009) using a complete social security database for an economically\nimportant district of Romania. The database contains detailed information on\nmore than half million taxpayers, including their monthly salaries from all\nemployers where they worked. Besides studying the characteristic distribution\nfunctions in the high and low/medium income limits, the database allows us a\ndetailed dynamical study by following the time-evolution of the taxpayers\nincome. To our knowledge, this is the first extensive study of this kind (a\nprevious japanese taxpayers survey was limited to two years). In the high\nincome limit we prove once again the validity of Pareto's law, obtaining a\nperfect scaling on four orders of magnitude in the rank for all the studied\nyears. The obtained Pareto exponents are quite stable with values around\n$\\alpha \\approx 2.5$, in spite of the fact that during this period the economy\ndeveloped rapidly and also a financial-economic crisis hit Romania in\n2007-2008. For the low and medium income category we confirmed the\nexponential-type income distribution. Following the income of employees in\ntime, we have found that the top limit of the income distribution is a highly\ndynamical region with strong fluctuations in the rank. In this region, the\nobserved dynamics is consistent with a multiplicative random growth hypothesis.\nContrarily with previous results obtained for the japanese employees, we find\nthat the logarithmic growth-rate is not independent of the income.\n"
    },
    {
        "paper_id": 1203.2017,
        "authors": "Josef Teichmann and Mario V. W\\\"uthrich",
        "title": "Consistent Long-Term Yield Curve Prediction",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an arbitrage-free non-parametric yield curve prediction model\nwhich takes the full (discretized) yield curve as state variable. We believe\nthat absence of arbitrage is an important model feature in case of highly\ncorrelated data, as it is the case for interest rates. Furthermore, the model\nstructure allows to separate clearly the tasks of estimating the volatility\nstructure and of calibrating market prices of risk. The empirical part includes\ntests on modeling assumptions, back testing and a comparison with the\nVasi\\v{c}ek short rate model.\n"
    },
    {
        "paper_id": 1203.225,
        "authors": "Valeriy Zakamulin",
        "title": "Low-Frequency Waves and the Medium to Long-Term US Stock Market Outlook",
        "comments": "There is an updated version of the paper on the http://www.ssrn.com",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we provide compelling evidence of cyclical mean reversion and\nmultiperiod stock return predictability over horizons of about 30 years with a\nhalf-life of about 15 years. This implies that the US stock market follows a\nlong-term rhythm where a period of above average returns tends to be followed\nby a period of below average returns. We demonstrate that this long-term stock\nmarket rhythm moves in lockstep with corresponding long-term economic, social,\nand political rhythms in the US. Assuming that the past relationship between\nthese rhythms will hold unaltered in the future, we provide the medium to\nlong-term stock market outlook.\n"
    },
    {
        "paper_id": 1203.2287,
        "authors": "Dirk Tasche",
        "title": "Bounds for rating override rates",
        "comments": "23 pages, 3 figures, 3 tables",
        "journal-ref": "Journal of Credit Risk 8(4), 3-29, 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Overrides of credit ratings are important correctives of ratings that are\ndetermined by statistical rating models. Financial institutions and banking\nregulators agree on this because on the one hand errors with ratings of\ncorporates or banks can have fatal consequences for the lending institutions\nand on the other hand errors by statistical methods can be minimised but not\ncompletely avoided. Nonetheless, rating overrides can be misused in order to\nconceal the real riskiness of borrowers or even entire portfolios. That is why\nrating overrides usually are strictly governed and carefully recorded. It is\nnot clear, however, which frequency of overrides is appropriate for a given\nrating model within a predefined time period. This paper argues that there is a\nnatural error rate associated with a statistical rating model that may be used\nto inform assessment of whether or not an observed override rate is adequate.\nThe natural error rate is closely related to the rating model's discriminatory\npower and can readily be calculated.\n"
    },
    {
        "paper_id": 1203.2355,
        "authors": "Jos\\'e E. Figueroa-L\\'opez, Peter Tankov",
        "title": "Small-time asymptotics of stopped L\\'evy bridges and simulation schemes\n  with controlled bias",
        "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ517 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1126-1164",
        "doi": "10.3150/13-BEJ517",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We characterize the small-time asymptotic behavior of the exit probability of\na L\\'evy process out of a two-sided interval and of the law of its overshoot,\nconditionally on the terminal value of the process. The asymptotic expansions\nare given in the form of a first-order term and a precise computable error\nbound. As an important application of these formulas, we develop a novel\nadaptive discretization scheme for the Monte Carlo computation of functionals\nof killed L\\'evy processes with controlled bias. The considered functionals\nappear in several domains of mathematical finance (e.g., structural credit risk\nmodels, pricing of barrier options, and contingent convertible bonds) as well\nas in natural sciences. The proposed algorithm works by adding discretization\npoints sampled from the L\\'evy bridge density to the skeleton of the process\nuntil the overall error for a given trajectory becomes smaller than the maximum\ntolerance given by the user.\n"
    },
    {
        "paper_id": 1203.2369,
        "authors": "Pierre Henry-Labordere (SOCIETE GENERALE)",
        "title": "Counterparty Risk Valuation: A Marked Branching Diffusion Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this paper is to design an algorithm for the computation of\nthe counterparty risk which is competitive in regards of a brute force\n\"Monte-Carlo of Monte-Carlo\" method (with nested simulations). This is achieved\nusing marked branching diffusions describing a Galton-Watson random tree. Such\nan algorithm leads at the same time to a computation of the (bilateral)\ncounterparty risk when we use the default-risky or counterparty-riskless option\nvalues as mark-to-market. Our method is illustrated by various numerical\nexamples.\n"
    },
    {
        "paper_id": 1203.2564,
        "authors": "Lorenzo Hern\\'andez, Jorge Tejero, Alberto Su\\'arez and Santiago\n  Carrillo-Men\\'endez",
        "title": "Percentiles of sums of heavy-tailed random variables: Beyond the\n  single-loss approximation",
        "comments": "18 pages, 20 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A perturbative approach is used to derive approximations of arbitrary order\nto estimate high percentiles of sums of positive independent random variables\nthat exhibit heavy tails. Closed-form expressions for the successive\napproximations are obtained both when the number of terms in the sum is\ndeterministic and when it is random. The zeroth order approximation is the\npercentile of the maximum term in the sum. Higher orders in the perturbative\nseries involve the right-truncated moments of the individual random variables\nthat appear in the sum. These censored moments are always finite. As a result,\nand in contrast to previous approximations proposed in the literature, the\nperturbative series has the same form regardless of whether these random\nvariables have a finite mean or not. The accuracy of the approximations is\nillustrated for a variety of distributions and a wide range of parameters. The\nquality of the estimate improves as more terms are included in the perturbative\nseries, specially for higher percentiles and heavier tails.\n"
    },
    {
        "paper_id": 1203.3031,
        "authors": "Phaiboon Jhongpita, Sukree Sinthupinyo and Thitivadee Chaiyawat",
        "title": "Using Decision Tree Learner to Classify Solvency Position for Thai\n  Non-life Insurance Companies",
        "comments": null,
        "journal-ref": "International Journal of the Computer, the Internet and Management\n  Vol. 19. No.3 (September-December, 2011) pp 41 -46",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper introduces a Decision Tree Learner as an early warning system for\nclassification of the non-life insurance companies according to their financial\nsolid as strong, moderate, weak, or insolvency. In this study, we ran several\nexperiments to show that the proposed model can achieve a good result using\nstandard 10 fold crossvalidation, split train and test data set, and separated\ntest set. The results show that the method is effective and can accurately\nclassify the solvency position.\n"
    },
    {
        "paper_id": 1203.3188,
        "authors": "Alexander Becker and Alexander F. R. Koivusalo and Rudi Sch\\\"afer",
        "title": "Empirical Evidence for the Structural Recovery Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  While defaults are rare events, losses can be substantial even for credit\nportfolios with a large number of contracts. Therefore, not only a good\nevaluation of the probability of default is crucial, but also the severity of\nlosses needs to be estimated. The recovery rate is often modeled independently\nwith regard to the default probability, whereas the Merton model yields a\nfunctional dependence of both variables. We use Moody's Default and Recovery\nDatabase in order to investigate the relationship of default probability and\nrecovery rate for senior secured bonds. The assumptions in the Merton model do\nnot seem justified by the empirical situation. Yet the empirical dependence of\ndefault probability and recovery rate is well described by the functional\ndependence found in the Merton model.\n"
    },
    {
        "paper_id": 1203.3757,
        "authors": "Maria B. Chiarolla, Giorgio Ferrari and Frank Riedel",
        "title": "Generalized Kuhn-Tucker Conditions for N-Firm Stochastic Irreversible\n  Investment under Limited Resources",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study a continuous time, optimal stochastic investment\nproblem under limited resources in a market with N firms. The investment\nprocesses are subject to a time-dependent stochastic constraint. Rather than\nusing a dynamic programming approach, we exploit the concavity of the profit\nfunctional to derive some necessary and sufficient first order conditions for\nthe corresponding Social Planner optimal policy. Our conditions are a\nstochastic infinite-dimensional generalization of the Kuhn-Tucker Theorem. The\nLagrange multiplier takes the form of a nonnegative optional random measure on\n[0,T] which is flat off the set of times for which the constraint is binding,\ni.e. when all the fuel is spent. As a subproduct we obtain an enlightening\ninterpretation of the first order conditions for a single firm in Bank (2005).\nIn the infinite-horizon case, with operating profit functions of Cobb-Douglas\ntype, our method allows the explicit calculation of the optimal policy in terms\nof the `base capacity' process, i.e. the unique solution of the Bank and El\nKaroui representation problem (2004).\n"
    },
    {
        "paper_id": 1203.3869,
        "authors": "Dapeng Cai and Takashi Gyoshin Nitta",
        "title": "Transversality Conditions for Stochastic Higher-Order Optimality:\n  Continuous and Discrete Time Problems",
        "comments": "28 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Higher-order optimization problems naturally appear when investigating the\neffects of a patent with finite length, as in the pioneering work of Futagami\nand Iwaisako (2007). In this paper, we establish the Euler equations and\ntransversality conditions necessary for analyzing such higher-order\noptimization problems. We develop our results for stochastic general\nreduced-form models and consider cases of both continuous and discrete time. We\nemploy our results to establish the Euler equations and transversality\nconditions for the simplified household maximization problem in Futagami and\nIwaisako (2007).\n"
    },
    {
        "paper_id": 1203.4153,
        "authors": "Sait Tunc, Mehmet A. Donmez, Suleyman S. Kozat",
        "title": "Optimal Investment Under Transaction Costs",
        "comments": "Submitted to IEEE Transactions on Signal Processing, 12 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate how and when to diversify capital over assets, i.e., the\nportfolio selection problem, from a signal processing perspective. To this end,\nwe first construct portfolios that achieve the optimal expected growth in\ni.i.d. discrete-time two-asset markets under proportional transaction costs. We\nthen extend our analysis to cover markets having more than two stocks. The\nmarket is modeled by a sequence of price relative vectors with arbitrary\ndiscrete distributions, which can also be used to approximate a wide class of\ncontinuous distributions. To achieve the optimal growth, we use threshold\nportfolios, where we introduce a recursive update to calculate the expected\nwealth. We then demonstrate that under the threshold rebalancing framework, the\nachievable set of portfolios elegantly form an irreducible Markov chain under\nmild technical conditions. We evaluate the corresponding stationary\ndistribution of this Markov chain, which provides a natural and efficient\nmethod to calculate the cumulative expected wealth. Subsequently, the\ncorresponding parameters are optimized yielding the growth optimal portfolio\nunder proportional transaction costs in i.i.d. discrete-time two-asset markets.\nAs a widely known financial problem, we next solve optimal portfolio selection\nin discrete-time markets constructed by sampling continuous-time Brownian\nmarkets. For the case that the underlying discrete distributions of the price\nrelative vectors are unknown, we provide a maximum likelihood estimator that is\nalso incorporated in the optimization framework in our simulations.\n"
    },
    {
        "paper_id": 1203.4156,
        "authors": "Sait Tunc and Suleyman S. Kozat",
        "title": "Optimal Investment Under Transaction Costs: A Threshold Rebalanced\n  Portfolio Approach",
        "comments": "Submitted to IEEE Transactions on Signal Processing",
        "journal-ref": null,
        "doi": "10.1109/TSP.2013.2258339",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study optimal investment in a financial market having a finite number of\nassets from a signal processing perspective. We investigate how an investor\nshould distribute capital over these assets and when he should reallocate the\ndistribution of the funds over these assets to maximize the cumulative wealth\nover any investment period. In particular, we introduce a portfolio selection\nalgorithm that maximizes the expected cumulative wealth in i.i.d. two-asset\ndiscrete-time markets where the market levies proportional transaction costs in\nbuying and selling stocks. We achieve this using \"threshold rebalanced\nportfolios\", where trading occurs only if the portfolio breaches certain\nthresholds. Under the assumption that the relative price sequences have\nlog-normal distribution from the Black-Scholes model, we evaluate the expected\nwealth under proportional transaction costs and find the threshold rebalanced\nportfolio that achieves the maximal expected cumulative wealth over any\ninvestment period. Our derivations can be readily extended to markets having\nmore than two stocks, where these extensions are pointed out in the paper. As\npredicted from our derivations, we significantly improve the achieved wealth\nover portfolio selection algorithms from the literature on historical data\nsets.\n"
    },
    {
        "paper_id": 1203.461,
        "authors": "Walter Farkas, Pablo Koch-Medina, and Cosimo Munari",
        "title": "Capital requirements with defaultable securities",
        "comments": null,
        "journal-ref": "Insurance: Mathematics and Economics, 55, 58-67 (2014)",
        "doi": "10.1016/j.insmatheco.2013.11.009",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study capital requirements for bounded financial positions defined as the\nminimum amount of capital to invest in a chosen eligible asset targeting a\npre-specified acceptability test. We allow for general acceptance sets and\ngeneral eligible assets, including defaultable bonds. Since the payoff of these\nassets is not necessarily bounded away from zero the resulting risk measures\ncannot be transformed into cash-additive risk measures by a change of\nnumeraire. However, extending the range of eligible assets is important\nbecause, as exemplified by the recent financial crisis, assuming the existence\nof default-free bonds may be unrealistic. We focus on finiteness and continuity\nproperties of these general risk measures. As an application, we discuss\ncapital requirements based on Value-at-Risk and Tail-Value-at-Risk\nacceptability, the two most important acceptability criteria in practice.\nFinally, we prove that there is no optimal choice of the eligible asset. Our\nresults and our examples show that a theory of capital requirements allowing\nfor general eligible assets is richer than the standard theory of cash-additive\nrisk measures.\n"
    },
    {
        "paper_id": 1203.4786,
        "authors": "Jos\\'e Da Fonseca and Alessandro Gnoatto and Martino Grasselli",
        "title": "A flexible matrix Libor model with smiles",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a flexible approach for the valuation of interest rate derivatives\nbased on Affine Processes. We extend the methodology proposed in Keller-Ressel\net al. (2009) by changing the choice of the state space. We provide\nsemi-closed-form solutions for the pricing of caps and floors. We then show\nthat it is possible to price swaptions in a multifactor setting with a good\ndegree of analytical tractability. This is done via the Edgeworth expansion\napproach developed in Collin-Dufresne and Goldstein (2002). A numerical\nexercise illustrates the flexibility of Wishart Libor model in describing the\nmovements of the implied volatility surface.\n"
    },
    {
        "paper_id": 1203.4979,
        "authors": "Ladislav Kristoufek",
        "title": "Fractal Markets Hypothesis and the Global Financial Crisis: Scaling,\n  Investment Horizons and Liquidity",
        "comments": "11 pages, 3 figures",
        "journal-ref": "Advances in Complex Systems 2012, Vol. 15(6), art. 1250065",
        "doi": "10.1142/S0219525912500658",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate whether fractal markets hypothesis and its focus on liquidity\nand invest- ment horizons give reasonable predictions about dynamics of the\nfinancial markets during the turbulences such as the Global Financial Crisis of\nlate 2000s. Compared to the mainstream efficient markets hypothesis, fractal\nmarkets hypothesis considers financial markets as com- plex systems consisting\nof many heterogenous agents, which are distinguishable mainly with respect to\ntheir investment horizon. In the paper, several novel measures of trading\nactivity at different investment horizons are introduced through scaling of\nvariance of the underlying processes. On the three most liquid US indices -\nDJI, NASDAQ and S&P500 - we show that predictions of fractal markets hypothesis\nactually fit the observed behavior quite well.\n"
    },
    {
        "paper_id": 1203.502,
        "authors": "Antoine Jacquier, Aleksandar Mijatovic",
        "title": "Large deviations for the extended Heston model: the large-time case",
        "comments": "21 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study here the large-time behaviour of all continuous affine stochastic\nvolatility models (in the sense of Keller-Ressel) and deduce a closed-form\nformula for the large-maturity implied volatility smile. Based on refinements\nof the Gartner-Ellis theorem on the real line, our proof reveals pathological\nbehaviours of the asymptotic smile. In particular, we show that the condition\nassumed in Gatheral and Jacquier under which the Heston implied volatility\nconverges to the SVI parameterisation is necessary and sufficient.\n"
    },
    {
        "paper_id": 1203.5176,
        "authors": "Mikio Ito and Akihiko Noda and Tatsuma Wada",
        "title": "International Stock Market Efficiency: A Non-Bayesian Time-Varying Model\n  Approach",
        "comments": "21 pages, 2 tables, 6 figures",
        "journal-ref": "Applied Economics 46 (2014) 2744-2754",
        "doi": "10.1080/00036846.2014.909579",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper develops a non-Bayesian methodology to analyze the time-varying\nstructure of international linkages and market efficiency in G7 countries. We\nconsider a non-Bayesian time-varying vector autoregressive (TV-VAR) model, and\napply it to estimate the joint degree of market efficiency in the sense of Fama\n(1970, 1991). Our empirical results provide a new perspective that the\ninternational linkages and market efficiency change over time and that their\nbehaviors correspond well to historical events of the international financial\nsystem.\n"
    },
    {
        "paper_id": 1203.5298,
        "authors": "R\\'emi Lemoy, Eric Bertin",
        "title": "Dynamical fluctuations in a simple housing market model",
        "comments": "12 pages, 5 figures, to appear in J. Stat. Mech",
        "journal-ref": "J. Stat. Mech. P12007 (2012)",
        "doi": "10.1088/1742-5468/2012/12/P12007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a simple stochastic model of a urban rental housing market, in\nwhich the interaction of tenants and landlords induces rent fluctuations. We\nsimulate the model numerically and measure the equilibrium rent distribution,\nwhich is found to be close to a lognormal law. We also study the influence of\nthe density of agents (or equivalently, the vacancy rate) on the rent\ndistribution. A simplified version of the model, amenable to analytical\ntreatment, is studied and leads to a lognormal distribution of rents. The\npredicted equilibrium value agrees quantitatively with numerical simulations,\nwhile a qualitative agreement is obtained for the standard deviation. The\nconnection with non-equilibrium statistical physics models like ratchets is\nalso emphasized.\n"
    },
    {
        "paper_id": 1203.5442,
        "authors": "Joanna Janczura",
        "title": "Pricing electricity derivatives within a Markov regime-switching model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper analytic formulas for electricity derivatives are calculated.\nTo this end, we assume that electricity spot prices follow a 3-regime Markov\nregime-switching model with independent spikes and drops and periodic\ntransition matrix. Since the classical derivatives pricing methodology cannot\nbe used in case of non-storable commodities, we employ the concept of the risk\npremium. The obtained theoretical results are then used for the European Energy\nExchange (EEX) market data. The 3-regime model is calibrated to the spot\nelectricity prices. Next, the risk premium is derived and used to calculate\nprices of European options written on spot, as well as, forward prices.\n"
    },
    {
        "paper_id": 1203.5513,
        "authors": "Alessandro Gnoatto",
        "title": "The Wishart short rate model",
        "comments": null,
        "journal-ref": "International Journal on Theoretical and Applied Finance (15)08,\n  2012",
        "doi": "10.1142/S0219024912500562",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a short rate model, driven by a stochastic process on the cone of\npositive semidefinite matrices. We derive sufficient conditions ensuring that\nthe model replicates normal, inverse or humped yield curves.\n"
    },
    {
        "paper_id": 1203.5581,
        "authors": "Jongwook Kim and Teppei Okumura",
        "title": "Heavy-Tail Distribution from Correlation of Discrete Stochastic Process",
        "comments": "4 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a stochastic process driven by the memory effect with novel\ndistributions which include both exponential and leptokurtic heavy-tailed\ndistributions. A class of the distributions is analytically derived from the\ncontinuum limit of the discrete binary process with the renormalized\nauto-correlation. The moment generating function with a closed form is\nobtained, thus the cumulants are calculated and shown to be convergent. The\nother class of the distributions is numerically investigated. The combination\nof the two stochastic processes of memory with different signs under regime\nswitching mechanism does result in behaviors of power-law decay. Therefore we\nclaim that memory is the alternative origin of heavy-tail.\n"
    },
    {
        "paper_id": 1203.5664,
        "authors": "Simone Scotti (LPMA)",
        "title": "Asset Pricing under uncertainty",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1001.5202",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the effect of parameter uncertainty on a stochastic diffusion model,\nin particular the impact on the pricing of contingent claims, using methods\nfrom the theory of Dirichlet forms. We apply these techniques to hedging\nprocedures in order to compute the sensitivity of SDE trajectories with respect\nto parameter perturbations. We show that this analysis can justify endogenously\nthe presence of a bid-ask spread on the option prices. We also prove that if\nthe stochastic differential equation admits a closed form representation then\nthe sensitivities have closed form representations. We examine the case of\nlog-normal diffusion and we show that this framework leads to a smiled implied\nvolatility surface coherent with historical data.\n"
    },
    {
        "paper_id": 1203.5703,
        "authors": "L. De Leo, V. Vargas, S. Ciliberti, J.-P. Bouchaud",
        "title": "We've walked a million miles for one of these smiles",
        "comments": "Submitted to \"Risk Magazine\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive a new, exact and transparent expansion for option smiles, which\nlends itself both to analytical approximation and, perhaps more importantly, to\ncongenial numerical treatments. We show that the skew and the curvature of the\nsmile can be computed as exotic options, for which the Hedged Monte Carlo\nmethod is particularly well suited. When applied to options on the S&P index,\nwe find that the skew and the curvature of the smile are very poorly reproduced\nby the standard Edgeworth (cumulant) expansion. Most notably, the relation\nbetween the skew and the skewness is inverted at small and large vols, a\nfeature that none of the model studied so far is able to reproduce.\nFurthermore, the around-the-money curvature of the smile is found to be very\nsmall, in stark contrast with the highly kurtic nature of the returns.\n"
    },
    {
        "paper_id": 1203.5729,
        "authors": "Asad Munir, William Shaw",
        "title": "Quantile Mechanics 3: Series Representations and Approximation of some\n  Quantile Functions appearing in Finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It has long been agreed by academics that the inversion method is the method\nof choice for generating random variates, given the availability of the\nquantile function. However for several probability distributions arising in\npractice a satisfactory method of approximating these functions is not\navailable. The main focus of this paper will be to develop Taylor and\nasymptotic series expansions for the quantile functions belonging to the\nfollowing probability distributions; Variance Gamma, Generalized Inverse\nGaussian, Hyperbolic and alpha-Stable. As a secondary matter, based on these\nanalytic expressions we briefly investigate the problem of approximating the\nquantile function.\n"
    },
    {
        "paper_id": 1203.5893,
        "authors": "Fulvio Baldovin, Francesco Camana, Michele Caraglio, Attilio L.\n  Stella, Marco Zamparo",
        "title": "Aftershock prediction for high-frequency financial markets' dynamics",
        "comments": "Contribution to the proceedings of the Econophysics Kolkata VI\n  International Workshop, 12 pages, 4 figures. Added references and minor\n  corrections",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-2553-0_4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The occurrence of aftershocks following a major financial crash manifests the\ncritical dynamical response of financial markets. Aftershocks put additional\nstress on markets, with conceivable dramatic consequences. Such a phenomenon\nhas been shown to be common to most financial assets, both at high and low\nfrequency. Its present-day description relies on an empirical characterization\nproposed by Omori at the end of 1800 for seismic earthquakes. We point out the\nlimited predictive power in this phenomenological approach and present a\nstochastic model, based on the scaling symmetry of financial assets, which is\npotentially capable to predict aftershocks occurrence, given the main shock\nmagnitude. Comparisons with S&P high-frequency data confirm this predictive\npotential.\n"
    },
    {
        "paper_id": 1203.5903,
        "authors": "Jan Baldeaux and Alexander Badran",
        "title": "Consistent Modeling of VIX and Equity Derivatives Using a 3/2 plus Jumps\n  Model",
        "comments": "15 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper demonstrates that a pure-diffusion 3/2 model is able to capture the\nobserved upward-sloping implied volatility skew in VIX options. This\nobservation contradicts a common perception in the literature that jumps are\nrequired for the consistent modelling of equity and VIX derivatives. The\npure-diffusion model, however, struggles to reproduce the smile in the implied\nvolatilities of short-term index options. One remedy to this problem is to\naugment the model by introducing jumps in the index. The resulting 3/2 plus\njumps model turns out to be as tractable as its pure-diffusion counterpart when\nit comes to pricing equity, realized variance and VIX derivatives, but\naccurately captures the smile in implied volatilities of short-term index\noptions.\n"
    },
    {
        "paper_id": 1203.5957,
        "authors": "Joachim de Lataillade, Cyril Deremble, Marc Potters and Jean-Philippe\n  Bouchaud",
        "title": "Optimal Trading with Linear Costs",
        "comments": "Submitted to Journal of Investment Strategies",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of the optimal trading strategy in the presence of\nlinear costs, and with a strict cap on the allowed position in the market.\nUsing Bellman's backward recursion method, we show that the optimal strategy is\nto switch between the maximum allowed long position and the maximum allowed\nshort position, whenever the predictor exceeds a threshold value, for which we\nestablish an exact equation. This equation can be solved explicitely in the\ncase of a discrete Ornstein-Uhlenbeck predictor. We discuss in detail the\ndependence of this threshold value on the transaction costs. Finally, we\nestablish a strong connection between our problem and the case of a quadratic\nrisk penalty, where our threshold becomes the size of the optimal non-trading\nband.\n"
    },
    {
        "paper_id": 1203.6021,
        "authors": "Frank W. K. Firk",
        "title": "From Nuclear Reactions to High-Frequency Trading: an R-function Approach",
        "comments": "18 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The R-function theory of Thomas is used to model neutron inelastic scattering\nand the fine, intermediate, and gross structure observed in the Dow Jones\nIndustrial Average on a typical trading day.\n"
    },
    {
        "paper_id": 1203.6228,
        "authors": "Romain Allez and Jean-Philippe Bouchaud",
        "title": "Eigenvector dynamics: general theory and some applications",
        "comments": "40 pages; 12 figures",
        "journal-ref": "Phys. Rev. E 86, 046202 (2012)",
        "doi": "10.1103/PhysRevE.86.046202",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a general framework to study the stability of the subspace spanned\nby $P$ consecutive eigenvectors of a generic symmetric matrix ${\\bf H}_0$, when\na small perturbation is added. This problem is relevant in various contexts,\nincluding quantum dissipation (${\\bf H}_0$ is then the Hamiltonian) and\nfinancial risk control (in which case ${\\bf H}_0$ is the assets return\ncovariance matrix). We argue that the problem can be formulated in terms of the\nsingular values of an overlap matrix, that allows one to define a \"fidelity\"\ndistance. We specialize our results for the case of a Gaussian Orthogonal ${\\bf\nH}_0$, for which the full spectrum of singular values can be explicitly\ncomputed. We also consider the case when ${\\bf H}_0$ is a covariance matrix and\nillustrate the usefulness of our results using financial data. The special case\nwhere the top eigenvalue is much larger than all the other ones can be\ninvestigated in full detail. In particular, the dynamics of the angle made by\nthe top eigenvector and its true direction defines an interesting new class of\nrandom processes.\n"
    },
    {
        "paper_id": 1203.6424,
        "authors": "Phaiboon Jhonpita, Sukree Sinthupinyo and Thitivadee Chaiyawat",
        "title": "Ordinal Classification Method for the Evaluation Of Thai Non-life\n  Insurance Companies",
        "comments": null,
        "journal-ref": "IJCSI Volume 9, Issue 1, January 2012\n  http://www.ijcsi.org/articles/Ordinal-classification-method-for-the-evaluation-of-thai-nonlife-insurance-companies.php",
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  This paper proposes a use of an ordinal classifier to evaluate the financial\nsolidity of non-life insurance companies as strong, moderate, weak, and\ninsolvency. This study constructed an efficient classification model that can\nbe used by regulators to evaluate the financial solidity and to determine the\npriority of further examination as an early warning system. The proposed model\nis beneficial to policy-makers to create guidelines for the solvency\nregulations and roles of the government in protecting the public against\ninsolvency.\n"
    },
    {
        "paper_id": 1203.6507,
        "authors": "Joachim Kaldasch",
        "title": "Evolutionary Model of the Personal Income Distribution",
        "comments": null,
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, 391 (2012)\n  5628-5642",
        "doi": "10.1016/j.physa.2012.06.048",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this work is to establish the personal income distribution from\nthe elementary constituents of a free market; products of a representative good\nand agents forming the economic network. The economy is treated as a\nself-organized system. Based on the idea that the dynamics of an economy is\ngoverned by slow modes, the model suggests that for short time intervals a\nfixed ratio of total labour income (capital income) to net income exists\n(Cobb-Douglas relation). Explicitly derived is Gibrat's law from an\nevolutionary market dynamics of short term fluctuations. The total private\nincome distribution is shown to consist of four main parts. From capital income\nof private firms the income distribution contains a lognormal distribution for\nsmall and a Pareto tail for large incomes. Labour income contributes an\nexponential distribution. Also included is the income from a social insurance\nsystem, approximated by a Gaussian peak. The evolutionary model is able to\nreproduce the stylized facts of the income distribution, shown by a comparison\nwith empirical data of a high resolution income distribution. The theory\nsuggests that in a free market competition between products is ultimately the\norigin of the uneven income distribution.\n"
    },
    {
        "paper_id": 1203.6631,
        "authors": "Carlos Fuertes and Andrew Papanicolaou",
        "title": "Implied Filtering Densities on Volatility's Hidden State",
        "comments": null,
        "journal-ref": "Applied Mathematical Finance, Vol. 21, No. 6, (2014) pp. 483-522",
        "doi": "10.1080/1350486X.2014.891357",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We formulate and analyze an inverse problem using derivatives prices to\nobtain an implied filtering density on volatility's hidden state. Stochastic\nvolatility is the unobserved state in a hidden Markov model (HMM) and can be\ntracked using Bayesian filtering. However, derivative data can be considered as\nconditional expectations that are already observed in the market, and which can\nbe used as input to an inverse problem whose solution is an implied conditional\ndensity on volatility. Our analysis relies on a specification of the martingale\nchange of measure, which we refer to as \\textit{separability}. This\nspecification has a multiplicative component that behaves like a risk premium\non volatility uncertainty in the market. When applied to SPX options data, the\nestimated model and implied densities produce variance-swap rates that are\nconsistent with the VIX volatility index. The implied densities are relatively\nstable over time and pick up some of the monthly effects that occur due to the\noptions' expiration, indicating that the volatility-uncertainty premium could\nexperience cyclic effects due to the maturity date of the options.\n"
    },
    {
        "paper_id": 1203.6723,
        "authors": "Sara Cecchetti and Antonio Di Cesare",
        "title": "The Mathematics of the Relationship between the Default Risk and\n  Yield-to-Maturity of Coupon Bonds",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper analyzes the mathematics of the relationship between the default\nrisk and yield-to-maturity of a coupon bond. It is shown that the\nyield-to-maturity is driven not only by the default probability and recovery\nrate of the bond but also by other contractual characteristics of the bond that\nare not commonly associated with default risk, such as the maturity and coupon\nrate of the bond. In particular, for given default probability and recovery\nrate, both the level and slope of the yield-to-maturity term structure depend\non the coupon rate, as the higher the coupon rate the higher the\nyield-to-maturity term structure. In addition, the yield-to-maturity term\nstructure is upward or downward sloping depending on whether the coupon rate is\nhigh or low enough. Similar qualitative results also holds for CDS spreads.\nConsequently, the yield-to-maturity is an indicator that must be used\ncautiously as a proxy for default risk.\n"
    },
    {
        "paper_id": 1203.6778,
        "authors": "Igor Tsatskis (Financial Services Authority, London)",
        "title": "Systemic losses in banking networks: indirect interaction of nodes via\n  asset prices",
        "comments": "6 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A simple banking network model is proposed which features multiple waves of\nbank defaults and is analytically solvable in the limiting case of an\ninfinitely large homogeneous network. The model is a collection of nodes\nrepresenting individual banks; associated with each node is a balance sheet\nconsisting of assets and liabilities. Initial node failures are triggered by\nexternal correlated shocks applied to the asset sides of the balance sheets.\nThese defaults lead to further reductions in asset values of all nodes which in\nturn produce additional failures, and so on. This mechanism induces indirect\ninteractions between the nodes and leads to a cascade of defaults. There are no\ninterbank links, and therefore no direct interactions, between the nodes. The\nresulting probability distribution for the total (direct plus systemic) network\nloss can be viewed as a modification of the well-known Vasicek distribution.\n"
    },
    {
        "paper_id": 1203.6877,
        "authors": "Pierre Henry-Labord\\`ere, Jan Ob{\\l}\\'oj, Peter Spoida, Nizar Touzi",
        "title": "The maximum maximum of a martingale with given $n$ marginals",
        "comments": "Published at http://dx.doi.org/10.1214/14-AAP1084 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2016, Vol. 26, No. 1, 1-44",
        "doi": "10.1214/14-AAP1084",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We obtain bounds on the distribution of the maximum of a martingale with\nfixed marginals at finitely many intermediate times. The bounds are sharp and\nattained by a solution to $n$-marginal Skorokhod embedding problem in\nOb{\\l}\\'oj and Spoida [An iterated Az\\'ema-Yor type embedding for finitely many\nmarginals (2013) Preprint]. It follows that their embedding maximizes the\nmaximum among all other embeddings. Our motivating problem is superhedging\nlookback options under volatility uncertainty for an investor allowed to\ndynamically trade the underlying asset and statically trade European call\noptions for all possible strikes and finitely-many maturities. We derive a\npathwise inequality which induces the cheapest superhedging value, which\nextends the two-marginals pathwise inequality of Brown, Hobson and Rogers\n[Probab. Theory Related Fields 119 (2001) 558-578]. This inequality, proved by\nelementary arguments, is derived by following the stochastic control approach\nof Galichon, Henry-Labord\\`ere and Touzi [Ann. Appl. Probab. 24 (2014)\n312-336].\n"
    },
    {
        "paper_id": 1203.6899,
        "authors": "Martijn Pistorius and Johannes Stolte",
        "title": "Fast computation of vanilla prices in time-changed models and implied\n  volatilities using rational approximations",
        "comments": "To appear in International Journal of Theoretical and Applied Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new numerical method to price vanilla options quickly in\ntime-changed Brownian motion models. The method is based on rational function\napproximations of the Black-Scholes formula. Detailed numerical results are\ngiven for a number of widely used models. In particular, we use the\nvariance-gamma model, the CGMY model and the Heston model without correlation\nto illustrate our results. Comparison to the standard fast Fourier transform\nmethod with respect to accuracy and speed appears to favour the newly developed\nmethod in the cases considered. We present error estimates for the option\nprices. Additionally, we use this method to derive a procedure to compute, for\na given set of arbitrage-free European call option prices, the corresponding\nBlack-Scholes implied volatility surface. To achieve this, rational function\napproximations of the inverse of the Black-Scholes formula are used. We are\nthus able to work out implied volatilities more efficiently than one can by the\nuse of other common methods. Error estimates are presented for a wide range of\nparameters.\n"
    },
    {
        "paper_id": 1204.0148,
        "authors": "Olivier Gu\\'eant, Charles-Albert Lehalle",
        "title": "General Intensity Shapes in Optimal Liquidation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The classical literature on optimal liquidation, rooted in Almgren-Chriss\nmodels, tackles the optimal liquidation problem using a trade-off between\nmarket impact and price risk. Therefore, it only answers the general question\nof the optimal liquidation rhythm. The very question of the actual way to\nproceed with liquidation is then rarely dealt with. Our model, that\nincorporates both price risk and non-execution risk, is an attempt to tackle\nthis question using limit orders. The very general framework we propose to\nmodel liquidation generalizes the existing literature on optimal posting of\nlimit orders. We consider a risk-adverse agent whereas the model of Bayraktar\nand Ludkovski only tackles the case of a risk-neutral one. We consider very\ngeneral functional forms for the execution process intensity, whereas Gu\\'eant\net al. is restricted to exponential intensity. Eventually, we link the\nexecution cost function of Almgren-Chriss models to the intensity function in\nour model, providing then a way to see Almgren-Chriss models as a limit of\nours.\n"
    },
    {
        "paper_id": 1204.0305,
        "authors": "Jin Hyuk Choi, Mihai Sirbu, Gordan Zitkovic",
        "title": "Shadow prices and well-posedness in the problem of optimal investment\n  and consumption with transaction costs",
        "comments": "31 pages, 20 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit the optimal investment and consumption model of Davis and Norman\n(1990) and Shreve and Soner (1994), following a shadow-price approach similar\nto that of Kallsen and Muhle-Karbe (2010). Making use of the completeness of\nthe model without transaction costs, we reformulate and reduce the\nHamilton-Jacobi-Bellman equation for this singular stochastic control problem\nto a non-standard free-boundary problem for a first-order ODE with an integral\nconstraint. Having shown that the free boundary problem has a smooth solution,\nwe use it to construct the solution of the original optimal\ninvestment/consumption problem in a self-contained manner and without any\nrecourse to the dynamic programming principle. Furthermore, we provide an\nexplicit characterization of model parameters for which the value function is\nfinite.\n"
    },
    {
        "paper_id": 1204.035,
        "authors": "Zal\\'an Forr\\'o, Peter Cauwels and Didier Sornette",
        "title": "When games meet reality: is Zynga overvalued?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  On December 16th, 2011, Zynga, the well-known social game developing company\nwent public. This event followed other recent IPOs in the world of social\nnetworking companies, such as Groupon or Linkedin among others. With a\nvaluation close to 7 billion USD at the time when it went public, Zynga became\none of the biggest web IPOs since Google. This recent enthusiasm for social\nnetworking companies raises the question whether they are overvalued. Indeed,\nduring the few months since its IPO, Zynga showed significant variability, its\nmarket capitalization going from 5.6 to 10.2 billion USD, hinting at a possible\nirrational behavior from the market. To bring substance to the debate, we\npropose a two-tiered approach to compute the intrinsic value of Zynga. First,\nwe introduce a new model to forecast its user base, based on the individual\ndynamics of its major games. Next, we model the revenues per user using a\nlogistic function, a standard model for growth in competition. This allows us\nto bracket the valuation of Zynga using three different scenarios: 3.4, 4.0 and\n4.8 billion USD in the base case, high growth and extreme growth scenario\nrespectively. This suggests that Zynga has been overpriced ever since its IPO.\nFinally, we propose an investment strategy (dated April 19th, 2012 on the\narXive), which is based on our diagnostic of a bubble for Zynga and how this\nherding / bubbly sentiment can be expected to play together with two important\ncoming events (the quarterly financial result announcement around April 26th,\n2012 followed by the end of a first lock-up period around April 30th, 2012). On\nthe long term, our analysis indicates that Zynga's price should decrease\nsignificantly. The paper ends with a post-mortem analysis added on May 24th,\n2012, just before going to press, showing that we have successfully predicted\nthe downward trend of Zynga. Since April 27th, 2012, Zynga dropped 25%.\n"
    },
    {
        "paper_id": 1204.0426,
        "authors": "Aki-Hiro Sato, Takaki Hayashi, and Janusz A. Ho{\\l}yst",
        "title": "Comprehensive Analysis of Market Conditions in the Foreign Exchange\n  Market: Fluctuation Scaling and Variance-Covariance Matrix",
        "comments": "13 pages, 10 figures",
        "journal-ref": null,
        "doi": "10.1007/s11403-012-0089-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate quotation and transaction activities in the foreign exchange\nmarket for every week during the period of June 2007 to December 2010. A\nscaling relationship between the mean values of number of quotations (or number\nof transactions) for various currency pairs and the corresponding standard\ndeviations holds for a majority of the weeks. However, the scaling breaks in\nsome time intervals, which is related to the emergence of market shocks. There\nis a monotonous relationship between values of scaling indices and global\naverages of currency pair cross-correlations when both quantities are observed\nfor various window lengths $\\Delta t$.\n"
    },
    {
        "paper_id": 1204.0453,
        "authors": "Griselda Deelstra and Gr\\'egory Ray\\'ee",
        "title": "Pricing Variable Annuity Guarantees in a Local Volatility framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the price of Variable Annuity Guarantees, especially\nof Guaranteed Annuity Options (GAO) and Guaranteed Minimum Income Benefit\n(GMIB), and this in the settings of a derivative pricing model where the\nunderlying spot (the fund) is locally governed by a geometric Brownian motion\nwith local volatility, while interest rates follow a Hull-White one-factor\nGaussian model. Notwithstanding the fact that in this framework, the local\nvolatility depends on a particularly complicated expectation where no\nclosed-form expression exists and it is neither directly related to European\ncall prices or other liquid products, we present in this contribution different\nmethods to calibrate the local volatility model. We further compare Variable\nAnnuity Guarantee prices obtained in three different settings, namely the local\nvolatility, the stochastic volatility and the constant volatility models all\ncombined with stochastic interest rates and show that an appropriate volatility\nmodelling is important for these long-dated derivatives. More precisely, we\ncompare prices of GAO, GMIB Rider and barrier types GAO obtained by using local\nvolatility, stochastic volatility and constant volatility models.\n"
    },
    {
        "paper_id": 1204.0633,
        "authors": "Griselda Deelstra and Gr\\'egory Ray\\'ee",
        "title": "Local Volatility Pricing Models for Long-dated FX Derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the local volatility function in the Foreign Exchange market where\nboth domestic and foreign interest rates are stochastic. This model is suitable\nto price long-dated FX derivatives. We derive the local volatility function and\nobtain several results that can be used for the calibration of this local\nvolatility on the FX option's market. Then, we study an extension to obtain a\nmore general volatility model and propose a calibration method for the local\nvolatility associated to this model.\n"
    },
    {
        "paper_id": 1204.0637,
        "authors": "Masaaki Fukasawa",
        "title": "Efficient Discretization of Stochastic Integrals",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Sharp asymptotic lower bounds of the expected quadratic variation of\ndiscretization error in stochastic integration are given. The theory relies on\ninequalities for the kurtosis and skewness of a general random variable which\nare themselves seemingly new. Asymptotically efficient schemes which attain the\nlower bounds are constructed explicitly. The result is directly applicable to\npractical hedging problem in mathematical finance; it gives an asymptotically\noptimal way to choose rebalancing dates and portofolios with respect to\ntransaction costs. The asymptotically efficient strategies in fact reflect the\nstructure of transaction costs. In particular a specific biased rebalancing\nscheme is shown to be superior to unbiased schemes if transaction costs follow\na convex model. The problem is discussed also in terms of the exponential\nutility maximization.\n"
    },
    {
        "paper_id": 1204.0646,
        "authors": "Jim Gatheral, Antoine Jacquier",
        "title": "Arbitrage-free SVI volatility surfaces",
        "comments": "25 pages, 6 figures Corrected some typos. Extended bibliography.\n  Paper restructured, Main theorem (Theorem 4.1) improved. Proof of Theorem 4.3\n  amended",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we show how to calibrate the widely-used SVI\nparameterization of the implied volatility surface in such a way as to\nguarantee the absence of static arbitrage. In particular, we exhibit a large\nclass of arbitrage-free SVI volatility surfaces with a simple closed-form\nrepresentation. We demonstrate the high quality of typical SVI fits with a\nnumerical example using recent SPX options data.\n"
    },
    {
        "paper_id": 1204.0915,
        "authors": "Dan Pirjol",
        "title": "Equivalence of interest rate models and lattice gases",
        "comments": "7 pages, 1 figure",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.85.046116",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the class of short rate interest rate models for which the short\nrate is proportional to the exponential of a Gaussian Markov process x(t) in\nthe terminal measure r(t) = a(t) exp(x(t)). These models include the Black,\nDerman, Toy and Black, Karasinski models in the terminal measure. We show that\nsuch interest rate models are equivalent with lattice gases with attractive\ntwo-body interaction V(t1,t2)= -Cov(x(t1),x(t2)). We consider in some detail\nthe Black, Karasinski model with x(t) an Ornstein, Uhlenbeck process, and show\nthat it is similar with a lattice gas model considered by Kac and Helfand, with\nattractive long-range two-body interactions V(x,y) = -\\alpha (e^{-\\gamma |x -\ny|} - e^{-\\gamma (x + y)}). An explicit solution for the model is given as a\nsum over the states of the lattice gas, which is used to show that the model\nhas a phase transition similar to that found previously in the Black, Derman,\nToy model in the terminal measure.\n"
    },
    {
        "paper_id": 1204.0922,
        "authors": "Fabio Caccioli, Jean-Philippe Bouchaud, J. Doyne Farmer",
        "title": "A proposal for impact-adjusted valuation: Critical leverage and\n  execution risk",
        "comments": "19 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The practice of valuation by marking-to-market with current trading prices is\nseriously flawed. Under leverage the problem is particularly dramatic: due to\nthe concave form of market impact, selling always initially causes the expected\nleverage to increase. There is a critical leverage above which it is impossible\nto exit a portfolio without leverage going to infinity and bankruptcy becoming\nlikely. Standard risk-management methods give no warning of this problem, which\neasily occurs for aggressively leveraged positions in illiquid markets. We\npropose an alternative accounting procedure based on the estimated market\nimpact of liquidation that removes the illusion of profit. This should curb the\nleverage cycle and contribute to an enhanced stability of financial markets.\n"
    },
    {
        "paper_id": 1204.1126,
        "authors": "Jan Baldeaux and Eckhard Platen",
        "title": "Computing Functionals of Multidimensional Diffusions via Monte Carlo\n  Methods",
        "comments": "19 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss suitable classes of diffusion processes, for which functionals\nrelevant to finance can be computed via Monte Carlo methods. In particular, we\nconstruct exact simulation schemes for processes from this class. However,\nshould the finance problem under consideration require e.g. continuous\nmonitoring of the processes, the simulation algorithm can easily be embedded in\na multilevel Monte Carlo scheme. We choose to introduce the finance problems\nunder the benchmark approach, and find that this approach allows us to exploit\nconveniently the analytical tractability of these diffusion processes.\n"
    },
    {
        "paper_id": 1204.1381,
        "authors": "Ban Zheng, Eric Moulines, Fr\\'ed\\'eric Abergel",
        "title": "Price Jump Prediction in Limit Order Book",
        "comments": "16 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A limit order book provides information on available limit order prices and\ntheir volumes. Based on these quantities, we give an empirical result on the\nrelationship between the bid-ask liquidity balance and trade sign and we show\nthat liquidity balance on best bid/best ask is quite informative for predicting\nthe future market order's direction. Moreover, we define price jump as a sell\n(buy) market order arrival which is executed at a price which is smaller\n(larger) than the best bid (best ask) price at the moment just after the\nprecedent market order arrival. Features are then extracted related to limit\norder volumes, limit order price gaps, market order information and limit order\nevent information. Logistic regression is applied to predict the price jump\nfrom the limit order book's feature. LASSO logistic regression is introduced to\nhelp us make variable selection from which we are capable to highlight the\nimportance of different features in predicting the future price jump. In order\nto get rid of the intraday data seasonality, the analysis is based on two\nseparated datasets: morning dataset and afternoon dataset. Based on an analysis\non forty largest French stocks of CAC40, we find that trade sign and market\norder size as well as the liquidity on the best bid (best ask) are consistently\ninformative for predicting the incoming price jump.\n"
    },
    {
        "paper_id": 1204.141,
        "authors": "Peter Lerner",
        "title": "Patience vs. Impatience of Stock Traders",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An ability to postpone one's execution without penalty provides an important\nstrategic advantage in high-frequency trading. To elucidate competition between\ntraders one has to formulate to a quantitative theory of formation of the\nexecution price from market expectations and quotes. This theory was provided\nin 2005 by Foucault, Kadan and Kandel. I derive asymptotic distribution of the\nbids/offers as a function of the ratio of patient and impatient traders using\nthe dynamic version of the Foucault, Kadan and Kandel dynamic Limit Order Book\n(LOB) model.\n  Dynamic version of the LOB model allows stylized but sufficiently realistic\nrepresentation of the trading markets. In particular, dynamic LOB allows\nsimulation of the distribution of execution times and spreads from\nhigh-frequency quotes. Significant analytic progress is made towards\nunderstanding of trading as competition for immediacy of execution between\ntraders. The results are qualitatively compared with empirical volume-at-price\ndistribution of highly liquid stocks.\n"
    },
    {
        "paper_id": 1204.1442,
        "authors": "Michael B. Giles and Christoph Reisinger",
        "title": "Stochastic finite differences and multilevel Monte Carlo for a class of\n  SPDEs in finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we propose a Milstein finite difference scheme for a\nstochastic partial differential equation (SPDE) describing a large particle\nsystem. We show, by means of Fourier analysis, that the discretisation on an\nunbounded domain is convergent of first order in the timestep and second order\nin the spatial grid size, and that the discretisation is stable with respect to\nboundary data. Numerical experiments clearly indicate that the same convergence\norder also holds for boundary-value problems. Multilevel path simulation,\npreviously used for SDEs, is shown to give substantial complexity gains\ncompared to a standard discretisation of the SPDE or direct simulation of the\nparticle system. We derive complexity bounds and illustrate the results by an\napplication to basket credit derivatives.\n"
    },
    {
        "paper_id": 1204.1452,
        "authors": "Jozef Barunik and Tomas Krehlik and Lukas Vacha",
        "title": "Modeling and forecasting exchange rate volatility in time-frequency\n  domain",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes an enhanced approach to modeling and forecasting\nvolatility using high frequency data. Using a forecasting model based on\nRealized GARCH with multiple time-frequency decomposed realized volatility\nmeasures, we study the influence of different timescales on volatility\nforecasts. The decomposition of volatility into several timescales approximates\nthe behaviour of traders at corresponding investment horizons. The proposed\nmethodology is moreover able to account for impact of jumps due to a recently\nproposed jump wavelet two scale realized volatility estimator. We propose a\nrealized Jump-GARCH models estimated in two versions using maximum likelihood\nas well as observation-driven estimation framework of generalized\nautoregressive score. We compare forecasts using several popular realized\nvolatility measures on foreign exchange rate futures data covering the recent\nfinancial crisis. Our results indicate that disentangling jump variation from\nthe integrated variation is important for forecasting performance. An\ninteresting insight into the volatility process is also provided by its\nmultiscale decomposition. We find that most of the information for future\nvolatility comes from high frequency part of the spectra representing very\nshort investment horizons. Our newly proposed models outperform statistically\nthe popular as well conventional models in both one-day and multi-period-ahead\nforecasting.\n"
    },
    {
        "paper_id": 1204.1561,
        "authors": "Peter Sasvari",
        "title": "The macroeconomic effect of the information and communication technology\n  in Hungary",
        "comments": "7 pages, 3 figures",
        "journal-ref": "International Journal of Advanced Computer Science and\n  Applications (IJACSA), Vol. 2, No. 12, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It was not until the beginning of the 1990s that the effects of information\nand communication technology on economic growth as well as on the profitability\nof enterprises raised the interest of researchers. After giving a general\ndescription on the relationship between a more intense use of ICT devices and\ndynamic economic growth, the author identified and explained those four\nchannels that had a robust influence on economic growth and productivity. When\ncomparing the use of information technonology devices in developed as well as\nin developing countries, the author highlighted the importance of the available\nadditional human capital and the elimination of organizational inflexibilities\nin the attempt of narrowing the productivity gap between the developed and\ndeveloping nations. By processing a large quantitiy of information gained from\nHungarian enterprises operating in several economic sectors, the author made an\nattempt to find a strong correlation between the development level of using ICT\ndevices and profitability together with total factor productivity. Although the\nimpact of using ICT devices cannot be measured unequivocally at the\nmicroeconomic level because of certain statistical and methodological\nimperfections, by applying such analytical methods as cluster analysis and\ncorrelation and regression calculation, the author managed to prove that both\nthe correlation coefficient and the gradient of the regression trend line\nshowed a positive relationship between the extensive use of information and\ncommunication technology and the profitability of enterprises.\n"
    },
    {
        "paper_id": 1204.1583,
        "authors": "Jacky Mallett",
        "title": "Description of the Operational Mechanics of a Basel Regulated Banking\n  System",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a description of the mechanical operations of banking as\nused in modern banking systems regulated under the Basel Accords, in order to\nprovide support for a verifiable and complete description of the banking system\nsuitable for computer simulation. Feedback is requested on the contents of this\ndocument, both with respect to the operations described here, and any known\nnational, regional or local variations in their structure and practice.\n"
    },
    {
        "paper_id": 1204.1903,
        "authors": "Johannes Ruf",
        "title": "Negative Call Prices",
        "comments": "minor changes. Accepted for publication in Annals of Finance",
        "journal-ref": null,
        "doi": "10.1007/s10436-012-0221-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that the existence of an equivalent local martingale measure for\nasset prices does not prevent negative prices for European calls written on\npositive stock prices. In particular, we illustrate that many standard\nno-arbitrage arguments implicitly rely on conditions stronger than the No Free\nLunch With Vanishing Risk (NFLVR) assumption. The discrepancy between\nreplicating prices and market prices for a contingent claim may be observed in\na model satisfying NFLVR since certain trading strategies of buying one\nportfolio and selling another one are often excluded by standard admissibility\nconstraints.\n"
    },
    {
        "paper_id": 1204.2065,
        "authors": "Iryna Banakh, Taras Banakh, Pavel Trisch and Myroslava Vovk",
        "title": "Toehold Purchase Problem: A comparative analysis of two strategies",
        "comments": "10 pages",
        "journal-ref": "Econotechmod. 4:1 (2015) 3-10",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Toehold purchase, defined here as purchase of one share in a firm by an\ninvestor preparing a tender offer to acquire majority of shares in it, reduces\nby one the number of shares this investor needs for majority. In the paper we\nconstruct mathematical models for the toehold and no-toehold strategies and\ncompare the expected profits of the investor and the probabilities of takeover\nthe firm in both strategies. It turns out that the expected profits of the\ninvestor in both strategies coincide. On the other hand, the probability of\ntakeover the firm using the toehold strategy is considerably higher comparing\nto the no-toehold strategy. In the analysis of the models we apply the\napparatus of incomplete Beta functions and some refined bounds for central\nbinomial coefficients.\n"
    },
    {
        "paper_id": 1204.209,
        "authors": "Damiano Brigo, Kyriakos Chourdakis",
        "title": "Consistent single- and multi-step sampling of multivariate arrival\n  times: A characterization of self-chaining copulas",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with dependence across marginally exponentially distributed\narrival times, such as default times in financial modeling or inter-failure\ntimes in reliability theory. We explore the relationship between dependence and\nthe possibility to sample final multivariate survival in a long time-interval\nas a sequence of iterations of local multivariate survivals along a partition\nof the total time interval. We find that this is possible under a form of\nmultivariate lack of memory that is linked to a property of the survival times\ncopula. This property defines a \"self-chaining-copula\", and we show that this\ncoincides with the extreme value copulas characterization. The self-chaining\ncondition is satisfied by the Gumbel-Hougaard copula, a full characterization\nof self chaining copulas in the Archimedean family, and by the Marshall-Olkin\ncopula. The result has important practical implications for consistent\nsingle-step and multi-step simulation of multivariate arrival times in a way\nthat does not destroy dependency through iterations, as happens when\ninconsistently iterating a Gaussian copula.\n"
    },
    {
        "paper_id": 1204.2251,
        "authors": "Jean-David Fermanian (CREST-ENSAE) and Olivier Vigneron (JP-Morgan)",
        "title": "On break-even correlation: the way to price structured credit\n  derivatives by replication",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the pricing of European-style structured credit payoff in a\nstatic framework, where the underlying default times are independent given a\ncommon factor. A practical application would consist of the pricing of\nnth-to-default baskets under the Gaussian copula model (GCM). We provide\nnecessary and sufficient conditions so that the corresponding asset prices are\nmartingales and introduce the concept of \"break-even\" correlation matrix. When\nno sudden jump-to-default events occur, we show that the perfect replication of\nthese payoffs under the GCM is obtained if and only if the underlying single\nname credit spreads follow a particular family of dynamics. We calculate the\ncorresponding break-even correlations and we exhibit a class of Merton-style\nmodels that are consistent with this result. We explain why the GCM does not\nhave a lot of competitors among the class of one-period static models, except\nperhaps the Clayton copula.\n"
    },
    {
        "paper_id": 1204.2458,
        "authors": "Volker Kr\\\"atschmer, Alexander Schied, Henryk Z\\\"ahle",
        "title": "Comparative and qualitative robustness for law-invariant risk measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  When estimating the risk of a P&L from historical data or Monte Carlo\nsimulation, the robustness of the estimate is important. We argue here that\nHampel's classical notion of qualitative robustness is not suitable for risk\nmeasurement and we propose and analyze a refined notion of robustness that\napplies to tail-dependent law-invariant convex risk measures on Orlicz space.\nThis concept of robustness captures the tradeoff between robustness and\nsensitivity and can be quantified by an index of qualitative robustness. By\nmeans of this index, we can compare various risk measures, such as distortion\nrisk measures, in regard to their degree of robustness. Our analysis also\nyields results that are of independent interest such as continuity properties\nand consistency of estimators for risk measures, or a Skorohod representation\ntheorem for {\\psi}-weak convergence.\n"
    },
    {
        "paper_id": 1204.2638,
        "authors": "Masaaki Fujii, Akihiko Takahashi",
        "title": "Perturbative Expansion Technique for Non-linear FBSDEs with Interacting\n  Particle Method",
        "comments": "20 pages, 3 figures, references added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we propose an efficient Monte Carlo implementation of\nnon-linear FBSDEs as a system of interacting particles inspired by the ideas of\nbranching diffusion method. It will be particularly useful to investigate large\nand complex systems, and hence it is a good complement of our previous work\npresenting an analytical perturbation procedure for generic non-linear FBSDEs.\nThere appear multiple species of particles, where the first one follows the\ndiffusion of the original underlying state, and the others the Malliavin\nderivatives with a grading structure. The number of branching points are capped\nby the order of perturbation, which is expected to make the scheme less\nnumerically intensive. The proposed method can be applied to semi-linear\nproblems, such as American and Bermudan options, Credit Value Adjustment (CVA),\nand even fully non-linear issues, such as the optimal portfolio problems in\nincomplete and/or constrained markets, feedbacks from large investors, and also\nthe analysis of various risk measures.\n"
    },
    {
        "paper_id": 1204.2667,
        "authors": "Fred Espen Benth and Jukka Lempa",
        "title": "Optimal portfolios in commodity futures markets",
        "comments": "21 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider portfolio optimization in futures markets. We model the entire\nfutures price curve at once as a solution of a stochastic partial differential\nequation. The agents objective is to maximize her utility from the final wealth\nwhen investing in futures contracts. We study a class of futures price curve\nmodels which admit a finite-dimensional realization. Using this, we recast the\nportfolio optimization problem as a finite-dimensional control problem and\nstudy its solvability.\n"
    },
    {
        "paper_id": 1204.2716,
        "authors": "Christopher Lorenz, Alexander Schied",
        "title": "Drift dependence of optimal trade execution strategies under transient\n  price impact",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give a complete solution to the problem of minimizing the expected\nliquidity costs in presence of a general drift when the underlying market\nimpact model has linear transient price impact with exponential resilience. It\nturns out that this problem is well-posed only if the drift is absolutely\ncontinuous. Optimal strategies often do not exist, and when they do, they\ndepend strongly on the derivative of the drift. Our approach uses elements from\nsingular stochastic control, even though the problem is essentially\nnon-Markovian due to the transience of price impact and the lack in Markovian\nstructure of the underlying price process. As a corollary, we give a complete\nsolution to the minimization of a certain cost-risk criterion in our setting.\n"
    },
    {
        "paper_id": 1204.2717,
        "authors": "Alexander Schied",
        "title": "Robust Strategies for Optimal Order Execution in the Almgren-Chriss\n  Framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Assuming geometric Brownian motion as unaffected price process $S^0$,\nGatheral & Schied (2011) derived a strategy for optimal order execution that\nreacts in a sensible manner on market changes but can still be computed in\nclosed form. Here we will investigate the robustness of this strategy with\nrespect to misspecification of the law of $S^0$. We prove the surprising result\nthat the strategy remains optimal whenever $S^0$ is a square-integrable\nmartingale. We then analyze the optimization criterion of Gatheral & Schied\n(2011) in the case in which $S^0$ is any square-integrable semimartingale and\nwe give a closed-form solution to this problem. As a corollary, we find an\nexplicit solution to the problem of minimizing the expected liquidation costs\nwhen the unaffected price process is a square-integrable semimartingale. The\nsolutions to our problems are found by stochastically solving a finite-fuel\ncontrol problem without assumptions of Markovianity.\n"
    },
    {
        "paper_id": 1204.2736,
        "authors": "Aur\\'elien Alfonsi (CERMICS), Jos\\'e Infante Acevedo (CERMICS)",
        "title": "Optimal execution and price manipulations in time-varying limit order\n  books",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper focuses on an extension of the Limit Order Book (LOB) model with\ngeneral shape introduced by Alfonsi, Fruth and Schied. Here, the additional\nfeature allows a time-varying LOB depth. We solve the optimal execution problem\nin this framework for both discrete and continuous time strategies. This gives\nin particular sufficient conditions to exclude Price Manipulations in the sense\nof Huberman and Stanzl or Transaction-Triggered Price Manipulations (see\nAlfonsi, Schied and Slynko). These conditions give interesting qualitative\ninsights on how market makers may create or not price manipulations.\n"
    },
    {
        "paper_id": 1204.3136,
        "authors": "Eder Lucio Fonseca, Fernando F. Ferreira, Paulsamy Muruganandam and\n  Hilda A. Cerdeira",
        "title": "Identifying financial crises in real time",
        "comments": "8 pages, 6 figures",
        "journal-ref": "Physica A 392, 1386-1392 (2013)",
        "doi": "10.1016/j.physa.2012.11.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Following the thermodynamic formulation of multifractal measure that was\nshown to be capable of detecting large fluctuations at an early stage, here we\npropose a new index which permits us to distinguish events like financial\ncrisis in real time . We calculate the partition function from where we obtain\nthermodynamic quantities analogous to free energy and specific heat. The index\nis defined as the normalized energy variation and it can be used to study the\nbehavior of stochastic time series, such as financial market daily data. Famous\nfinancial market crashes - Black Thursday (1929), Black Monday (1987) and\nSubprime crisis (2008) - are identified with clear and robust results. The\nmethod is also applied to the market fluctuations of 2011. From these results\nit appears as if the apparent crisis of 2011 is of a different nature from the\nother three. We also show that the analysis has forecasting capabilities.\n"
    },
    {
        "paper_id": 1204.3156,
        "authors": "Eric Kemp-Benedict",
        "title": "Price and Quantity Trajectories: Second-order Dynamics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In two previous papers the author developed a second-order price adjustment\n(t\\^atonnement) process. This paper extends the approach to include both\nquantity and price adjustments. We demonstrate three results: a analogue to\nphysical energy, called \"activity\" arises naturally in the model, and is not\nconserved in general; price and quantity trajectories must either end at a\nlocal minimum of a scalar potential or circulate endlessly; and disturbances\ninto a subspace of substitutable commodities decay over time. From this we\nargue, although we do not prove, that the model features global stability,\ncombined with local instability, a characteristic of many real markets.\nFollowing these observations and a brief survey of empirical results for\nprice-setting and consumption behavior in markets for \"real\" goods (as opposed\nto financial markets), we conjecture that Stigler and Becker's well-known\ntheory of consumer preference opens the possibility of substantial degeneracy\nin commodity space, and therefore that price and quantity trajectories could\nlie on a relatively low-dimensional subspace within the full commodity space.\n"
    },
    {
        "paper_id": 1204.3422,
        "authors": "Rod Cross, Victor Kozyakin",
        "title": "Double Exponential Instability of Triangular Arbitrage Systems",
        "comments": "22 pages, 22 bibliography references, expanded Introduction and\n  Conclusion, added bibliohraphy references",
        "journal-ref": "Discrete and Continuous Dynamical Systems Series B, Vol. 18, No.\n  2, 2013, pp. 349-376",
        "doi": "10.3934/dcdsb.2013.18.349",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  If financial markets displayed the informational efficiency postulated in the\nefficient markets hypothesis (EMH), arbitrage operations would be\nself-extinguishing. The present paper considers arbitrage sequences in foreign\nexchange (FX) markets, in which trading platforms and information are\nfragmented. In Kozyakin et al. (2010) and Cross et al. (2012) it was shown that\nsequences of triangular arbitrage operations in FX markets containing 4\ncurrencies and trader-arbitrageurs tend to display periodicity or grow\nexponentially rather than being self-extinguishing. This paper extends the\nanalysis to 5 or higher-order currency worlds. The key findings are that in a\n5-currency world arbitrage sequences may also follow an exponential law as well\nas display periodicity, but that in higher-order currency worlds a double\nexponential law may additionally apply. There is an \"inheritance of\ninstability\" in the higher-order currency worlds. Profitable arbitrage\noperations are thus endemic rather that displaying the self-extinguishing\nproperties implied by the EMH.\n"
    },
    {
        "paper_id": 1204.3452,
        "authors": "Adi Ben-Meir, Jeremy Schiff",
        "title": "The Variance of Standard Option Returns",
        "comments": "14 pages, 5 color figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The vast majority of works on option pricing operate on the assumption of\nrisk neutral valuation, and consequently focus on the expected value of option\nreturns, and do not consider risk parameters, such as variance. We show that it\nis possible to give explicit formulae for the variance of European option\nreturns (vanilla calls and puts, as well as barrier options), and that for\nAmerican options the variance can be computed using a PDE approach, involving a\nmodified Black-Scholes PDE. We show how the need to consider risk parameters,\nsuch as the variance, and also the probability of expiring worthless (PEW),\narises naturally for individual investors in options. Furthermore, we show that\na volatility smile arises in a simple model of risk-seeking option pricing.\n"
    },
    {
        "paper_id": 1204.3457,
        "authors": "Ivo Blohm, Christoph Riedl, Johann F\\\"uller, Orhan K\\\"oroglu, Jan\n  Marco Leimeister, Helmut Krcmar",
        "title": "The Effects of Prediction Market Design and Price Elasticity on Trading\n  Performance of Users: An Experimental Analysis",
        "comments": "Presented at Collective Intelligence conference, 2012\n  (arXiv:1204.2991)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We employ a 2x3 factorial experiment to study two central factors in the\ndesign of prediction markets (PMs) for idea evaluation: the overall design of\nthe PM, and the elasticity of market prices set by a market maker. The results\nshow that 'multi-market designs' on which each contract is traded on a separate\nPM lead to significantly higher trading performance than 'single-markets' that\nhandle all contracts one on PM. Price elasticity has no direct effect on\ntrading performance, but a significant interaction effect with market design\nimplies that the performance difference between the market designs is highest\nin settings of moderate price elasticity. We contribute to the emerging\nresearch stream of PM design through an unprecedented experiment which compares\ncurrent market designs.\n"
    },
    {
        "paper_id": 1204.3496,
        "authors": "Masayuki Kumon and Jing Li and Akimichi Takemura and Kei Takeuchi",
        "title": "Bayesian logistic betting strategy against probability forecasting",
        "comments": null,
        "journal-ref": "Stochastic Analysis and Applications 31 (2013) 214-234",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a betting strategy based on Bayesian logistic regression modeling\nfor the probability forecasting game in the framework of game-theoretic\nprobability by Shafer and Vovk (2001). We prove some results concerning the\nstrong law of large numbers in the probability forecasting game with side\ninformation based on our strategy. We also apply our strategy for assessing the\nquality of probability forecasting by the Japan Meteorological Agency. We find\nthat our strategy beats the agency by exploiting its tendency of avoiding\nclear-cut forecasts.\n"
    },
    {
        "paper_id": 1204.3536,
        "authors": "Josselin Garnier and George Papanicolaou and Tzu-Wei Yang",
        "title": "Large deviations for a mean field model of systemic risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a system of diffusion processes that interact through their\nempirical mean and have a stabilizing force acting on each of them,\ncorresponding to a bistable potential. There are three parameters that\ncharacterize the system: the strength of the intrinsic stabilization, the\nstrength of the external random perturbations, and the degree of cooperation or\ninteraction between them. The latter is the rate of mean reversion of each\ncomponent to the empirical mean of the system. We interpret this model in the\ncontext of systemic risk and analyze in detail the effect of cooperation\nbetween the components, that is, the rate of mean reversion. We show that in a\ncertain regime of parameters increasing cooperation tends to increase the\nstability of the individual agents but it also increases the overall or\nsystemic risk. We use the theory of large deviations of diffusions interacting\nthrough their mean field.\n"
    },
    {
        "paper_id": 1204.3556,
        "authors": "Jordi Camprodon and Josep Perell\\'o",
        "title": "Maximum likelihood approach for several stochastic volatility models",
        "comments": "26 pages, 15 figures",
        "journal-ref": "J. Stat. Mech. (2012) P08016",
        "doi": "10.1088/1742-5468/2012/08/P08016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Volatility measures the amplitude of price fluctuations. Despite it is one of\nthe most important quantities in finance, volatility is not directly\nobservable. Here we apply a maximum likelihood method which assumes that price\nand volatility follow a two-dimensional diffusion process where volatility is\nthe stochastic diffusion coefficient of the log-price dynamics. We apply this\nmethod to the simplest versions of the expOU, the OU and the Heston stochastic\nvolatility models and we study their performance in terms of the log-price\nprobability, the volatility probability, and its Mean First-Passage Time. The\napproach has some predictive power on the future returns amplitude by only\nknowing current volatility. The assumed models do not consider long-range\nvolatility auto-correlation and the asymmetric return-volatility\ncross-correlation but the method still arises very naturally these two\nimportant stylized facts. We apply the method to different market indexes and\nwith a good performance in all cases.\n"
    },
    {
        "paper_id": 1204.3679,
        "authors": "Lingfei Li and Vadim Linetsky",
        "title": "Time-Changed Ornstein-Uhlenbeck Processes And Their Applications In\n  Commodity Derivative Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies subordinate Ornstein-Uhlenbeck (OU) processes, i.e., OU\ndiffusions time changed by L\\'{e}vy subordinators. We construct their sample\npath decomposition, show that they possess mean-reverting jumps, study their\nequivalent measure transformations, and the spectral representation of their\ntransition semigroups in terms of Hermite expansions. As an application, we\npropose a new class of commodity models with mean-reverting jumps based on\nsubordinate OU process. Further time changing by the integral of a CIR process\nplus a deterministic function of time, we induce stochastic volatility and time\ninhomogeneity, such as seasonality, in the models. We obtain analytical\nsolutions for commodity futures options in terms of Hermite expansions. The\nmodels are consistent with the initial futures curve, exhibit Samuelson's\nmaturity effect, and are flexible enough to capture a variety of implied\nvolatility smile patterns observed in commodities futures options.\n"
    },
    {
        "paper_id": 1204.3786,
        "authors": "Fabio Bellini, Franco Pellerey, Carlo Sgarra and Salimeh Yasaei Sekeh",
        "title": "Comparison results for Garch processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of stochastic comparison of general Garch-like\nprocesses, for different parameters and different distributions of the\ninnovations. We identify several stochastic orders that are propagated from the\ninnovations to the Garch process itself, and discuss their interpretations. We\nfocus on the convex order and show that in the case of symmetric innovations it\nis also propagated to the cumulated sums of the Garch process. More generally,\nwe discuss multivariate comparison results related to the multivariate convex\nand supermodular order. Finally we discuss ordering with respect to the\nparameters in the Garch (1,1) case. Key words: Garch, Convex Order, Peakedness,\nKurtosis, Supermodularity.\n"
    },
    {
        "paper_id": 1204.4025,
        "authors": "Jia-Wen Gu, Wai-Ki Ching, Tak-Kuen Siu and Harry Zheng",
        "title": "On Pricing Basket Credit Default Swaps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a simple and efficient method to compute the ordered\ndefault time distributions in both the homogeneous case and the two-group\nheterogeneous case under the interacting intensity default contagion model. We\ngive the analytical expressions for the ordered default time distributions with\nrecursive formulas for the coefficients, which makes the calculation fast and\nefficient in finding rates of basket CDSs. In the homogeneous case, we explore\nthe ordered default time in limiting case and further include the exponential\ndecay and the multistate stochastic intensity process. The numerical study\nindicates that, in the valuation of the swap rates and their sensitivities with\nrespect to underlying parameters, our proposed model outperforms the Monte\nCarlo method.\n"
    },
    {
        "paper_id": 1204.4122,
        "authors": "James McNerney, Brian D. Fath, and Gerald Silverberg",
        "title": "Network structure of inter-industry flows",
        "comments": "14 pages, 7 figures",
        "journal-ref": "Physica A 392, (2013) 6427-6441",
        "doi": "10.1016/j.physa.2013.07.063",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the structure of inter-industry relationships using networks of\nmoney flows between industries in 20 national economies. We find these networks\nvary around a typical structure characterized by a Weibull link weight\ndistribution, exponential industry size distribution, and a common community\nstructure. The community structure is hierarchical, with the top level of the\nhierarchy comprising five industry communities: food industries, chemical\nindustries, manufacturing industries, service industries, and extraction\nindustries.\n"
    },
    {
        "paper_id": 1204.4614,
        "authors": "Liviu-Adrian Cotfas",
        "title": "A finite-dimensional quantum model for the stock market",
        "comments": "Same results in a simpler mathematical formalism",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications 392 (2013)\n  371-380",
        "doi": "10.1016/j.physa.2012.09.010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a finite-dimensional version of the quantum model for the stock\nmarket proposed in [C. Zhang and L. Huang, A quantum model for the stock\nmarket, Physica A 389(2010) 5769]. Our approach is an attempt to make this\nmodel consistent with the discrete nature of the stock price and is based on\nthe mathematical formalism used in the case of the quantum systems with\nfinite-dimensional Hilbert space. The rate of return is a discrete variable\ncorresponding to the coordinate in the case of quantum systems, and the\noperator of the conjugate variable describing the trend of the stock return is\ndefined in terms of the finite Fourier transform. The stock return in\nequilibrium is described by a finite Gaussian function, and the time evolution\nof the stock price, directly related to the rate of return, is obtained by\nnumerically solving a Schrodinger type equation.\n"
    },
    {
        "paper_id": 1204.4631,
        "authors": "Didier Kouokap Youmbi",
        "title": "Yield to maturity modelling and a Monte Carlo Technique for pricing\n  Derivatives on Constant Maturity Treasury (CMT) and Derivatives on forward\n  Bonds",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes a Monte Carlo technique for pricing the forward yield to\nmaturity, when the volatility of the zero-coupon bond is known. We make the\nassumption of deterministic default intensity (Hazard Rate Function). We make\nno assumption on the volatility of the yield. We actually calculate the initial\nvalue of the forward yield, we calculate the volatility of the yield, and we\nwrite the diffusion of the yield. As direct application we price options on\nConstant Maturity Treasury (CMT) in the Hull and White Model for the short\ninterest rate. Tests results with Caps and Floors on 10 years constant maturity\ntreasury (CMT10) are satisfactory. This work can also be used for pricing\noptions on bonds or forward bonds.\n"
    },
    {
        "paper_id": 1204.4877,
        "authors": "Arturo Kohatsu-Higa, Salvador Ortiz-Latorre and Peter Tankov",
        "title": "Optimal simulation schemes for L\\'evy driven stochastic differential\n  equations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a general class of high order weak approximation schemes for\nstochastic differential equations driven by L\\'evy processes with infinite\nactivity. These schemes combine a compound Poisson approximation for the jump\npart of the L\\'evy process with a high order scheme for the Brownian driven\ncomponent, applied between the jump times. The overall approximation is\nanalyzed using a stochastic splitting argument. The resulting error bound\ninvolves separate contributions of the compound Poisson approximation and of\nthe discretization scheme for the Brownian part, and allows, on one hand, to\nbalance the two contributions in order to minimize the computational time, and\non the other hand, to study the optimal design of the approximating compound\nPoisson process. For driving processes whose L\\'evy measure explodes near zero\nin a regularly varying way, this procedure allows to construct discretization\nschemes with arbitrary order of convergence.\n"
    },
    {
        "paper_id": 1204.5039,
        "authors": "Gregor Wergen, Satya N. Majumdar, Gregory Schehr",
        "title": "Record Statistics for Multiple Random Walks",
        "comments": "25 pages, 8 figures",
        "journal-ref": "Phys. Rev. E 86, 011119 (2012)",
        "doi": "10.1103/PhysRevE.86.011119",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the statistics of the number of records R_{n,N} for N identical and\nindependent symmetric discrete-time random walks of n steps in one dimension,\nall starting at the origin at step 0. At each time step, each walker jumps by a\nrandom length drawn independently from a symmetric and continuous distribution.\nWe consider two cases: (I) when the variance \\sigma^2 of the jump distribution\nis finite and (II) when \\sigma^2 is divergent as in the case of L\\'evy flights\nwith index 0 < \\mu < 2. In both cases we find that the mean record number\n<R_{n,N}> grows universally as \\sim \\alpha_N \\sqrt{n} for large n, but with a\nvery different behavior of the amplitude \\alpha_N for N > 1 in the two cases.\nWe find that for large N, \\alpha_N \\approx 2 \\sqrt{\\log N} independently of\n\\sigma^2 in case I. In contrast, in case II, the amplitude approaches to an\nN-independent constant for large N, \\alpha_N \\approx 4/\\sqrt{\\pi},\nindependently of 0<\\mu<2. For finite \\sigma^2 we argue, and this is confirmed\nby our numerical simulations, that the full distribution of (R_{n,N}/\\sqrt{n} -\n2 \\sqrt{\\log N}) \\sqrt{\\log N} converges to a Gumbel law as n \\to \\infty and N\n\\to \\infty. In case II, our numerical simulations indicate that the\ndistribution of R_{n,N}/\\sqrt{n} converges, for n \\to \\infty and N \\to \\infty,\nto a universal nontrivial distribution, independently of \\mu. We discuss the\napplications of our results to the study of the record statistics of 366 daily\nstock prices from the Standard & Poors 500 index.\n"
    },
    {
        "paper_id": 1204.5055,
        "authors": "Natascia Angelini, Giacomo Bormetti, Stefano Marmi and Franco Nardini",
        "title": "Value matters: Predictability of Stock Index Returns",
        "comments": "27 pages, 3 figures, 2 tables; an entirely new econometric section\n  about predictive regressions added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a simple dynamical model of stock index returns which is grounded\non the ability of the Cyclically Adjusted Price Earning (CAPE) valuation ratio\ndevised by Robert Shiller to predict long-horizon performances of the market.\nMore precisely, we discuss a discrete time dynamics in which the return growth\ndepends on three components: i) a momentum component, naturally justified in\nterms of agents' belief that expected returns are higher in bullish markets\nthan in bearish ones, ii) a fundamental component proportional to the\nlogarithmic CAPE at time zero. The initial value of the ratio determines the\nreference growth level, from which the actual stock price may deviate as an\neffect of random external disturbances, and iii) a driving component which\nensures the diffusive behaviour of stock prices. Under these assumptions, we\nprove that for a sufficiently large horizon the expected rate of return and the\nexpected gross return are linear in the initial logarithmic CAPE, and their\nvariance goes to zero with a rate of convergence consistent with the diffusive\nbehaviour. Eventually this means that the momentum component may generate\nbubbles and crashes in the short and medium run, nevertheless the valuation\nratio remains a good reference point of future long-run returns.\n"
    },
    {
        "paper_id": 1204.5103,
        "authors": "Gayatri Tilak, Tamas Szell, Remy Chicheportiche and Anirban\n  Chakraborti",
        "title": "Study of statistical correlations in intraday and daily financial return\n  time series",
        "comments": "22 pages, 11 figures, Springer-Verlag format. To appear in the\n  conference proceedings of Econophys-Kolkata VI: \"Econophysics of systemic\n  risk and network dynamics\", Eds. F. Abergel, B.K. Chakrabarti, A. Chakraborti\n  and A. Ghosh, to be published by Springer-Verlag (Italia), Milan (2012)",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-2553-0_6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this article is to briefly review and make new studies of\ncorrelations and co-movements of stocks, so as to understand the\n\"seasonalities\" and market evolution. Using the intraday data of the CAC40, we\nbegin by reasserting the findings of Allez and Bouchaud [New J. Phys. 13,\n025010 (2011)]: the average correlation between stocks increases throughout the\nday. We then use multidimensional scaling (MDS) in generating maps and\nvisualizing the dynamic evolution of the stock market during the day. We do not\nfind any marked difference in the structure of the market during a day. Another\naim is to use daily data for MDS studies, and visualize or detect specific\nsectors in a market and periods of crisis. We suggest that this type of\nvisualization may be used in identifying potential pairs of stocks for \"pairs\ntrade\".\n"
    },
    {
        "paper_id": 1204.5171,
        "authors": "Ivan Kitov",
        "title": "ConocoPhillips' share price model revisited",
        "comments": "10 pages, 10 Figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Three years ago we found a statistically reliable link between\nConocoPhillips' (NYSE: COP) stock price and the difference between the core and\nheadline CPI in the United States. In this article, the original relationship\nis revisited with new data available since 2009. The agreement between the\nobserved monthly closing price (adjusted for dividends and splits) and that\npredicted from the CPI difference is confirmed. The original quantitative link\nis validated. In order to improve the accuracy of the COP price prediction a\nseries of advanced models is developed. The original set of two major CPIs is\nextended by smaller components of the headline CPIs (e.g. the CPIs of motor\nfuel and housing energy) and several PPIs (e.g. the PPIs of crude oil and coal)\nwhich may be inherently related to ConocoPhillips and other energy companies.\nThese advanced models have demonstrated much lower modeling errors with better\nstatistical properties. The earlier reported quasi-linear trend in the CPI\ndifference is also revisited. This trend allows for an accurate prediction of\nthe COP prices at a five to ten year horizon.\n"
    },
    {
        "paper_id": 1204.5661,
        "authors": "Yoshiharu Maeno, Satoshi Morinaga, Hirokazu Matsushima, Kenichi Amagai",
        "title": "Transmission of distress in a bank credit network",
        "comments": "presented at the 4th World Congress on Social Simulation, Taipei,\n  September 2012",
        "journal-ref": "presented at the 4th World Congress on Social Simulation, Taipei,\n  September 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The European sovereign debt crisis has impaired many European banks. The\ndistress on the European banks may transmit worldwide, and result in a\nlarge-scale knock-on default of financial institutions. This study presents a\ncomputer simulation model to analyze the risk of insolvency of banks and\ndefaults in a bank credit network. Simulation experiments reproduce the\nknock-on default, and quantify the impact which is imposed on the number of\nbank defaults by heterogeneity of the bank credit network, the equity capital\nratio of banks, and the capital surcharge on big banks.\n"
    },
    {
        "paper_id": 1204.5698,
        "authors": "Marcel Ladkau, John G. M. Schoenmakers, Jianing Zhang",
        "title": "Libor model with expiry-wise stochastic volatility and displacement",
        "comments": "3 tables, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a multi-factor stochastic volatility Libor model with\ndisplacement, where each individual forward Libor is driven by its own\nsquare-root stochastic volatility process. The main advantage of this approach\nis that, maturity-wise, each square-root process can be calibrated to the\ncorresponding cap(let)vola-strike panel at the market. However, since even\nafter freezing the Libors in the drift of this model, the Libor dynamics are\nnot affine, new affine approximations have to be developed in order to obtain\nFourier based (approximate) pricing procedures for caps and swaptions. As a\nresult, we end up with a Libor modeling package that allows for efficient\ncalibration to a complete system of cap/swaption market quotes that performs\nwell even in crises times, where structural breaks in vola-strike-maturity\npanels are typically observed.\n"
    },
    {
        "paper_id": 1204.5718,
        "authors": "Tino Kluge and L. C. G. Rogers",
        "title": "The potential approach in practice",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The potential approach is a general and simple method for modelling interest\nrates, foreign exchange rates, and in principle other types of financial\nassets. This paper takes data on some liquid interest rate derivatives, and\nfits potential models using a small finite-state Markov chain as the base\nMarkov process.\n"
    },
    {
        "paper_id": 1204.6483,
        "authors": "Victor M. Yakovenko",
        "title": "Applications of statistical mechanics to economics: Entropic origin of\n  the probability distributions of money, income, and energy consumption",
        "comments": "15 pages, 13 figures, to be published in a book by Routledge (2012 ?)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This Chapter is written for the Festschrift celebrating the 70th birthday of\nthe distinguished economist Duncan Foley from the New School for Social\nResearch in New York. This Chapter reviews applications of statistical physics\nmethods, such as the principle of entropy maximization, to the probability\ndistributions of money, income, and global energy consumption per capita. The\nexponential probability distribution of wages, predicted by the statistical\nequilibrium theory of a labor market developed by Foley in 1996, is supported\nby empirical data on income distribution in the USA for the majority (about\n97%) of population. In addition, the upper tail of income distribution (about\n3% of population) follows a power law and expands dramatically during financial\nbubbles, which results in a significant increase of the overall income\ninequality. A mathematical analysis of the empirical data clearly demonstrates\nthe two-class structure of a society, as pointed out Karl Marx and recently\nhighlighted by the Occupy Movement. Empirical data for the energy consumption\nper capita around the world are close to an exponential distribution, which can\nbe also explained by the entropy maximization principle.\n"
    },
    {
        "paper_id": 1204.6488,
        "authors": "Richard J. Martin",
        "title": "Optimal multifactor trading under proportional transaction costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Proportional transaction costs present difficult theoretical problems in\ntrading algorithm design, on account of their lack of analytical tractability.\nThe author derives a solution of DT-NT-DT form for an arbitrary model in which\nthe the traded asset has diffusive dynamics described by one or more stochastic\nrisk factors. The width of the NT zone is found to be, as expected,\nproportional to the cube root of the transaction cost. It is also proportional\nto the 2/3 power of the volatility of the target position, thereby causing a\nfaster trading strategy to be buffered more than a slower one. The displacement\nof the middle of the buffer from the costfree position is found to be\nproportional to the square of the width, and hence to the 2/3 power of the\ntransaction cost; the proportionality constant depends on the expected\nshort-term change in position.\n"
    },
    {
        "paper_id": 1204.659,
        "authors": "G\\\"unter von Kiedrowski and E\\\"ors Szathm\\'ary",
        "title": "The monetary growth order",
        "comments": "15 pages, 3 figures, and 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Growth of monetary assets and debts is commonly described by the formula of\ncompound interest which for the case of continuous compounding is the\nexponential growth law. Its differential form is dc/dt = i c where dc/dt\ndescribes the rate of monetary growth, i the compounded interest rate and c the\nactual principal. Exponential growth of this type is fixed to be neither\nresource-limited nor self-limiting which is in contrast to real economic growth\n(such as the GDP) which may have exponential, but also subexponential, linear,\nsaturation, and even decline phases. As a result assets and debts commonly\noutgrow their economic fundament giving rise to the financial equivalent of\nMalthusian catastrophes after a certain interval of time. We here introduce an\nalternative for exponential compounding and propose to replace dc/dt = i c by\ndc/dt = i c^p where the exponent p (called reaction order in chemistry) is a\nquantity which will be termed monetary growth order. The monetary growth order\np is seen as a tuning handle which enables to adjust gross monetary growth to\nreal economic growth. It is suggested that the central banks take a serious\nlook to this control instrument which allows tuning in crisis situations and\nimmediate return to the exponential norm if needed.\n"
    },
    {
        "paper_id": 1204.6613,
        "authors": "Paul M. N. Feehan",
        "title": "Maximum principles for boundary-degenerate second-order linear elliptic\n  differential operators",
        "comments": "62 pages, 2 figures. Accepted for publication in Communications in\n  Partial Differential Equations. Incorporates final galley proof corrections\n  corresponding to published version",
        "journal-ref": "Communications in Partial Differential Equations 38 (2013), no.11,\n  1863-1935",
        "doi": "10.1080/03605302.2013.831446",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove weak and strong maximum principles, including a Hopf lemma, for\nsmooth subsolutions to equations defined by linear, second-order, partial\ndifferential operators whose principal symbols vanish along a portion of the\ndomain boundary. The boundary regularity property of the smooth subsolutions\nalong this boundary vanishing locus ensures that these maximum principles hold\nirrespective of the sign of the Fichera function. Boundary conditions need only\nbe prescribed on the complement in the domain boundary of the principal symbol\nvanishing locus. We obtain uniqueness and a priori maximum principle estimates\nfor smooth solutions to boundary value and obstacle problems defined by these\nboundary-degenerate elliptic operators for partial Dirichlet or Neumann\nboundary conditions along the complement of the boundary vanishing locus. We\nalso prove weak maximum principles and uniqueness for solutions to the\ncorresponding variational equations and inequalities defined with the aide of\nweighted Sobolev spaces. The domain is allowed to be unbounded when the\noperator coefficients and solutions obey certain growth conditions.\n"
    },
    {
        "paper_id": 1204.6638,
        "authors": "Jung-Hun Yang, Dick Ettema, Koen Frenken",
        "title": "Modelling the emergence of spatial patterns of economic activity",
        "comments": "Conference Proceeding in European Regional Science Association,\n  Liverpool, England, August, 2008",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Understanding how spatial configurations of economic activity emerge is\nimportant when formulating spatial planning and economic policy. A simple model\nwas proposed by Simon, who assumed that firms grow at a rate proportional to\ntheir size, and that new divisions of firms with certain probabilities relocate\nto other firms or to new centres of economic activity. Simon's model produces\nrealistic results in the sense that the sizes of economic centres follow a Zipf\ndistribution, which is also observed in reality. It lacks realism in the sense\nthat mechanisms such as cluster formation, congestion (defined as an overly\nhigh density of the same activities) and dependence on the spatial distribution\nof external parties (clients, labour markets) are ignored.\n  The present paper proposed an extension of the Simon model that includes both\ncentripetal and centrifugal forces. Centripetal forces are included in the\nsense that firm divisions are more likely to settle in locations that offer a\nhigher accessibility to other firms. Centrifugal forces are represented by an\naversion of a too high density of activities in the potential location. The\nmodel is implemented as an agent-based simulation model in a simplified spatial\nsetting. By running both the Simon model and the extended model, comparisons\nare made with respect to their effects on spatial configurations. To this end a\nseries of metrics are used, including the rank-size distribution and indices of\nthe degree of clustering and concentration.\n"
    },
    {
        "paper_id": 1205.0106,
        "authors": "Verche Cvetanoska, Toni Stojanovski",
        "title": "Using high performance computing and Monte Carlo simulation for pricing\n  american options",
        "comments": "CIIT Conference, April 2012, Bitola Macedonia",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  High performance computing (HPC) is a very attractive and relatively new area\nof research, which gives promising results in many applications. In this paper\nHPC is used for pricing of American options. Although the American options are\nvery significant in computational finance; their valuation is very challenging,\nespecially when the Monte Carlo simulation techniques are used. For getting the\nmost accurate price for these types of options we use Quasi Monte Carlo\nsimulation, which gives the best convergence. Furthermore, this algorithm is\nimplemented on both GPU and CPU. Additionally, the CUDA architecture is used\nfor harnessing the power and the capability of the GPU for executing the\nalgorithm in parallel which is later compared with the serial implementation on\nthe CPU. In conclusion this paper gives the reasons and the advantages of\napplying HPC in computational finance.\n"
    },
    {
        "paper_id": 1205.0332,
        "authors": "Aki-Hiro Sato",
        "title": "A Comprehensive Analysis of Time Series Segmentation on the Japanese\n  Stock Prices",
        "comments": "10 pages, 5 figures, submitted to the 4th World Congress on Social\n  Simulation (WCSS2012)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study conducts a comprehensive analysis of time series segmentation on\nthe Japanese stock prices listed on the first section of the Tokyo Stock\nExchange during the period from 4 January 2000 to 30 January 2012. A recursive\nsegmentation procedure is used under the assumption of a Gaussian mixture. The\ndaily number of each quintile of volatilities for all the segments is\ninvestigated empirically. It is found that from June 2004 to June 2007, a large\nmajority of stocks are stable and that from 2008 several stocks showed\ninstability. On March 2011, the daily number of instable securities steeply\nincreased due to societal turmoil influenced by the East Japan Great\nEarthquake. It is concluded that the number of stocks included in each quintile\nof volatilities provides useful information on macroeconomic situations.\n"
    },
    {
        "paper_id": 1205.0336,
        "authors": "Aki-Hiro Sato",
        "title": "Segmentation analysis on a multivariate time series of the foreign\n  exchange rates",
        "comments": "5 pages 3 figures, submitted to the 2nd International Conference on\n  Management, Manufacturing and Materials Engineering (ICMMM2012)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study considers the multivariate segmentation procedure under the\nassumption of the multivariate Gaussian mixture. Jensen-Shannon divergence\nbetween two multivariate Gaussian distributions is employed as a discriminator\nand a recursive segmentation procedure is proposed. The daily log-return time\nseries for 30 currency pairs consisting of 12 currencies for the last decade\n(January 3, 2001 to December 30, 2011) are analyzed using the proposed method.\nThe proposed method can detect several important periods related to the\nsignificant affairs of the international economy.\n"
    },
    {
        "paper_id": 1205.0505,
        "authors": "Andreas Gronlund and Il Gu Yi and Beom Jun Kim",
        "title": "Fractal Profit Landscape of the Stock Market",
        "comments": "12 pages, 4 figures",
        "journal-ref": "PLoS One (7)4 : e33960 (2012)",
        "doi": "10.1371/journal.pone.0033960",
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  We investigate the structure of the profit landscape obtained from the most\nbasic, fluctuation based, trading strategy applied for the daily stock price\ndata. The strategy is parameterized by only two variables, p and q. Stocks are\nsold and bought if the log return is bigger than p and less than -q,\nrespectively. Repetition of this simple strategy for a long time gives the\nprofit defined in the underlying two-dimensional parameter space of p and q. It\nis revealed that the local maxima in the profit landscape are spread in the\nform of a fractal structure. The fractal structure implies that successful\nstrategies are not localized to any region of the profit landscape and are\nneither spaced evenly throughout the profit landscape, which makes the\noptimization notoriously hard and hypersensitive for partial or limited\ninformation. The concrete implication of this property is demonstrated by\nshowing that optimization of one stock for future values or other stocks\nrenders worse profit than a strategy that ignores fluctuations, i.e., a\nlong-term buy-and-hold strategy.\n"
    },
    {
        "paper_id": 1205.0635,
        "authors": "Andreas H\\\"usler, Didier Sornette, Cars H. Hommes",
        "title": "Super-exponential bubbles in lab experiments: evidence for anchoring\n  over-optimistic expectations on price",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze a controlled price formation experiment in the laboratory that\nshows evidence for bubbles. We calibrate two models that demonstrate with high\nstatistical significance that these laboratory bubbles have a tendency to grow\nfaster than exponential due to positive feedback. We show that the positive\nfeedback operates by traders continuously upgrading their over-optimistic\nexpectations of future returns based on past prices rather than on realized\nreturns.\n"
    },
    {
        "paper_id": 1205.0877,
        "authors": "Giacomo Livan, Jun-ichi Inoue, Enrico Scalas",
        "title": "On the non-stationarity of financial time series: impact on optimal\n  portfolio selection",
        "comments": "12 pages, 4 figures (revised version)",
        "journal-ref": "J. Stat. Mech. (2012) P07025",
        "doi": "10.1088/1742-5468/2012/07/P07025",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the possible drawbacks of employing the standard Pearson\nestimator to measure correlation coefficients between financial stocks in the\npresence of non-stationary behavior, and we provide empirical evidence against\nthe well-established common knowledge that using longer price time series\nprovides better, more accurate, correlation estimates. Then, we investigate the\npossible consequences of instabilities in empirical correlation coefficient\nmeasurements on optimal portfolio selection. We rely on previously published\nworks which provide a framework allowing to take into account possible risk\nunderestimations due to the non-optimality of the portfolio weights being used\nin order to distinguish such non-optimality effects from risk underestimations\ngenuinely due to non-stationarities. We interpret such results in terms of\ninstabilities in some spectral properties of portfolio correlation matrices.\n"
    },
    {
        "paper_id": 1205.0976,
        "authors": "Rahul Kaushik and Stefano Battiston",
        "title": "Credit Default Swaps Drawup Networks: Too Tied To Be Stable?",
        "comments": "15 pages, 5 figures, Supplementary information",
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0061815",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyse time series of CDS spreads for a set of major US and European\ninstitutions on a pe- riod overlapping the recent financial crisis. We extend\nthe existing methodology of {\\epsilon}-drawdowns to the one of joint\n{\\epsilon}-drawups, in order to estimate the conditional probabilities of\nabrupt co-movements among spreads. We correct for randomness and for finite\nsize effects and we find significant prob- ability of joint drawups for certain\npairs of CDS. We also find significant probability of trend rein- forcement,\ni.e. drawups in a given CDS followed by drawups in the same CDS. Finally, we\ntake the matrix of probability of joint drawups as an estimate of the network\nof financial dependencies among institutions. We then carry out a network\nanalysis that provides insights into the role of systemically important\nfinancial institutions.\n"
    },
    {
        "paper_id": 1205.1007,
        "authors": "Michael Ludkovski and Qunying Shen",
        "title": "European Option Pricing with Liquidity Shocks",
        "comments": "25 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1142/S021902491350043X",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the valuation and hedging problem of European options in a market\nsubject to liquidity shocks. Working within a Markovian regime-switching\nsetting, we model illiquidity as the inability to trade. To isolate the impact\nof such liquidity constraints, we focus on the case where the market is\ncompletely static in the illiquid regime. We then consider derivative pricing\nusing either equivalent martingale measures or exponential indifference\nmechanisms. Our main results concern the analysis of the semi-linear coupled\nHJB equation satisfied by the indifference price, as well as its asymptotics\nwhen the probability of a liquidity shock is small. We then present several\nnumerical studies of the liquidity risk premia obtained in our models leading\nto practical guidelines on how to adjust for liquidity risk in option valuation\nand hedging.\n"
    },
    {
        "paper_id": 1205.1012,
        "authors": "Marco Frittelli and Ilaria Peri",
        "title": "From Risk Measures to Research Measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In order to evaluate the quality of the scientific research, we introduce a\nnew family of scientific performance measures, called Scientific Research\nMeasures (SRM). Our proposal originates from the more recent developments in\nthe theory of risk measures and is an attempt to resolve the many problems of\nthe existing bibliometric indices. The SRM that we introduce are based on the\nwhole scientist's citation record and are: coherent, as they share the same\nstructural properties; flexible to fit peculiarities of different areas and\nseniorities; granular, as they allow a more precise comparison between\nscientists, and inclusive, as they comprehend several popular indices. Another\nkey feature of our SRM is that they are planned to be calibrated to the\nparticular scientific community. We also propose a dual formulation of this\nproblem and explain its relevance in this context.\n"
    },
    {
        "paper_id": 1205.1154,
        "authors": "Umut \\c{C}etin",
        "title": "On absolutely continuous compensators and nonlinear filtering equations\n  in default risk models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the pricing of defaultable assets in an incomplete information\nmodel where the default time is given by a first hitting time of an\nunobservable process. We show that in a fairly general Markov setting, the\nindicator function of the default has an absolutely continuous compensator.\nGiven this compensator we then discuss the optional projection of a class of\nsemimartingales onto the filtration generated by the observation process and\nthe default indicator process. Available formulas for the pricing of\ndefaultable assets are analyzed in this setting and some alternative formulas\nare suggested.\n"
    },
    {
        "paper_id": 1205.1163,
        "authors": "Karel in 't Hout, Chittaranjan Mishra",
        "title": "Stability of ADI schemes for multidimensional diffusion equations with\n  mixed derivative terms",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper the unconditional stability of four well-known ADI schemes is\nanalyzed in the application to time-dependent multidimensional diffusion\nequations with mixed derivative terms. Necessary and sufficient conditions on\nthe parameter theta of each scheme are obtained that take into account the\nactual size of the mixed derivative coefficients. Our results generalize\nresults obtained previously by Craig & Sneyd (1988) and In 't Hout & Welfert\n(2009). Numerical experiments are presented illustrating our main theorems.\n"
    },
    {
        "paper_id": 1205.1364,
        "authors": "V. I. Yukalov and D. Sornette",
        "title": "Statistical Outliers and Dragon-Kings as Bose-Condensed Droplets",
        "comments": "Latex file, 16 pages, 1 figure",
        "journal-ref": "Eur. Phys. J. Spec. Top. 205 (2012) 53-64",
        "doi": "10.1140/epjst/e2012-01561-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A theory of exceptional extreme events, characterized by their abnormal sizes\ncompared with the rest of the distribution, is presented. Such outliers, called\n\"dragon-kings\", have been reported in the distribution of financial drawdowns,\ncity-size distributions (e.g., Paris in France and London in the UK), in\nmaterial failure, epileptic seizure intensities, and other systems. Within our\ntheory, the large outliers are interpreted as droplets of Bose-Einstein\ncondensate: the appearance of outliers is a natural consequence of the\noccurrence of Bose-Einstein condensation controlled by the relative degree of\nattraction, or utility, of the largest entities. For large populations, Zipf's\nlaw is recovered (except for the dragon-king outliers). The theory thus\nprovides a parsimonious description of the possible coexistence of a power law\ndistribution of event sizes (Zipf's law) and dragon-king outliers.\n"
    },
    {
        "paper_id": 1205.1533,
        "authors": "Matthias Arnsdorf",
        "title": "Central Counterparty Risk",
        "comments": null,
        "journal-ref": "Journal of Risk Management in Financial Institutions, (2012)\n  Vol.5, 3 273-287",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A clearing member of a Central Counterparty (CCP) is exposed to losses on\ntheir default fund and initial margin contributions. Such losses can be\nincurred whenever the CCP has insufficient funds to unwind the portfolio of a\ndefaulting clearing member. This does not necessarily require the default of\nthe CCP itself. In this note we aim to quantify the risk a financial\ninstitution has when facing a CCP.\n  We show that a clearing member's CCP risk is given by a sum of exposures to\neach of the other clearing members. This arises because of the implicit default\ninsurance that each member has provided in the form of mutualised, loss sharing\ncollateral. We calculate the exposures by explicitly modeling the capital\nstructure of a CCP as well as the loss distributions of the individual member\nportfolios.\n  An important consideration in designing the model is the limited transparency\nwith respect to the portfolio composition and collateral levels of individual\nclearing members. To overcome this we leverage the fact that, for a typical\nCCP, margin levels are risk-based. In particular, we parameterise the portfolio\nloss tail as a Pareto distribution and we calibrate this to the CCP defined\nprobability of losses exceeding the posted initial margin levels.\n  A key aspect of the model is that we explicitly take into account wrong-way\nrisk, i.e. the fact that member defaults are more likely to occur in stressed\nmarket conditions, as well as potential contagion between a member's default\nand the losses on his portfolio.\n"
    },
    {
        "paper_id": 1205.1617,
        "authors": "Stefan Aulbach, Verena Bayer, Michael Falk",
        "title": "A multivariate piecing-together approach with an application to\n  operational loss data",
        "comments": "Published in at http://dx.doi.org/10.3150/10-BEJ343 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2012, Vol. 18, No. 2, 455-475",
        "doi": "10.3150/10-BEJ343",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The univariate piecing-together approach (PT) fits a univariate generalized\nPareto distribution (GPD) to the upper tail of a given distribution function in\na continuous manner. We propose a multivariate extension. First it is shown\nthat an arbitrary copula is in the domain of attraction of a multivariate\nextreme value distribution if and only if its upper tail can be approximated by\nthe upper tail of a multivariate GPD with uniform margins. The multivariate PT\nthen consists of two steps: The upper tail of a given copula $C$ is cut off and\nsubstituted by a multivariate GPD copula in a continuous manner. The result is\nagain a copula. The other step consists of the transformation of each margin of\nthis new copula by a given univariate distribution function. This provides,\naltogether, a multivariate distribution function with prescribed margins whose\ncopula coincides in its central part with $C$ and in its upper tail with a GPD\ncopula. When applied to data, this approach also enables the evaluation of a\nwide range of rational scenarios for the upper tail of the underlying\ndistribution function in the multivariate case. We apply this approach to\noperational loss data in order to evaluate the range of operational risk.\n"
    },
    {
        "paper_id": 1205.171,
        "authors": "Sayantan Ghosh and Uwe Jaekel and Francesco Petruccione",
        "title": "Singularity strength based characterization of financial networks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets are well known examples of multi-fractal complex systems\nthat have garnered much interest in their characterization through complex\nnetwork theory. The recent studies have used correlation based distance metrics\nfor defining and analyzing financial networks. In this work the singularity\nstrength is employed to define a distance metric and the existence of\nhierarchical structure in the Johannesburg Stock Exchange is investigated. The\nmulti-fractal nature of the financial market, which is otherwise hidden in the\ncorrelation coefficient based prescriptions, is analyzed through the use of the\nsingularity strength based method. The presence of a super cluster is exhibited\nin the network which accounts for half of the network size and is homogeneous\nin the sectoral composition of the South African market.\n"
    },
    {
        "paper_id": 1205.1711,
        "authors": "Prasanta K. Panigrahi, Sayantan Ghosh, Arjun Banerjee, Jainendra\n  Bahadur and P. Manimaran",
        "title": "Characterizing price index behavior through fluctuation dynamics",
        "comments": null,
        "journal-ref": "Econophysics of Systemic Risk and Network Dynamics, part- III, pp.\n  287-295 (2013)",
        "doi": "10.1007/978-88-470-2553-0_18",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the nature of fluctuations in variety of price indices involving\ncompanies listed on the New York Stock Exchange. The fluctuations at multiple\nscales are extracted through the use of wavelets belonging to Daubechies basis.\nThe fact that these basis sets satisfy vanishing moments conditions makes them\nideal to extract local polynomial trends, through the low pass or `average\ncoefficients'. Subtracting the trends from the original time series yields the\nfluctuations, at different scales, depending on the level of low-pass\ncoefficients used for finding the `average behavior'. The fluctuations are then\nstudied using wavelet based multifractal detrended fluctuation analysis to\nanalyze their self-similar and non-statistical properties. Due to the\nmultifractality of such time series, they deviate from Gaussian behavior in\ndifferent frequency regimes. Their departure from random matrix theory\npredictions in such regimes is also analyzed. These deviations and\nnon-statistical properties of the fluctuations can be instrumental in throwing\nsignificant light on the dynamics of financial markets.\n"
    },
    {
        "paper_id": 1205.1861,
        "authors": "Zeyu Zheng, Kazuko Yamasaki, Joel N. Tenenbaum, and H. Eugene Stanley",
        "title": "Carbon-dioxide emissions trading and hierarchical structure in worldwide\n  finance and commodities markets",
        "comments": "4 figures",
        "journal-ref": "Phys. Rev. E 87, 012814 (2013)",
        "doi": "10.1103/PhysRevE.87.012814",
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  In a highly interdependent economic world, the nature of relationships\nbetween financial entities is becoming an increasingly important area of study.\nRecently, many studies have shown the usefulness of minimal spanning trees\n(MST) in extracting interactions between financial entities. Here, we propose a\nmodified MST network whose metric distance is defined in terms of\ncross-correlation coefficient absolute values, enabling the connections between\nanticorrelated entities to manifest properly. We investigate 69 daily time\nseries, comprising three types of financial assets: 28 stock market indicators,\n21 currency futures, and 20 commodity futures. We show that though the\nresulting MST network evolves over time, the financial assets of similar type\ntend to have connections which are stable over time. In addition, we find a\ncharacteristic time lag between the volatility time series of the stock market\nindicators and those of the EU CO2 emission allowance (EUA) and crude oil\nfutures (WTI). This time lag is given by the peak of the cross-correlation\nfunction of the volatility time series EUA (or WTI) with that of the stock\nmarket indicators, and is markedly different (>20 days) from 0, showing that\nthe volatility of stock market indicators today can predict the volatility of\nEU emissions allowances and of crude oil in the near future.\n"
    },
    {
        "paper_id": 1205.1966,
        "authors": "S\\\"oren Christensen, Albrecht Irle, Stephan J\\\"urgens",
        "title": "Optimal multiple stopping with random waiting times",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1080/07474946.2013.803814",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the standard models for optimal multiple stopping problems it is assumed\nthat between two exercises there is always a time period of deterministic\nlength $\\delta$, the so called refraction period. This prevents the optimal\nexercise times from bunching up together on top of the optimal stopping time\nfor the one-exercise case. In this article we generalize the standard model by\nconsidering random refraction times. We develop the theory and reduce the\nproblem to a sequence of ordinary stopping problems thus extending the results\nfor deterministic times. This requires an extension of the underlying\nfiltrations in general. Furthermore we consider the Markovian case and treat an\nexample explicitly.\n"
    },
    {
        "paper_id": 1205.2013,
        "authors": "Lorenzo Giada and Claudio Nordio",
        "title": "Bilateral Credit Valuation Adjustment of an Optional Early Termination\n  Clause",
        "comments": "8 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Is an option to early terminate a swap at its market value worth zero? At\nfirst sight it is, but in presence of counterparty risk it depends on the\ncriteria used to determine such market value. In case of a single\nuncollateralised swap transaction under ISDA between two defaultable\ncounterparties, the additional unilateral option to early terminate the swap at\npredefined dates requires a Bermudan credit valuation adjustment. We give a\ngeneral pricing formula assuming a default-free close-out amount, and apply it\nin a simplified setting with deterministic intensity and one single date of\noptional early termination, showing that the impact on the fair value of the\ntransaction at inception might be non negligible.\n"
    },
    {
        "paper_id": 1205.2295,
        "authors": "Huaxiong Huang, Moshe A. Milevsky and Thomas S. Salisbury",
        "title": "Optimal retirement consumption with a stochastic force of mortality",
        "comments": null,
        "journal-ref": "Insurance: Mathematics and Economics 51 (2012), pp. 282-291",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend the lifecycle model (LCM) of consumption over a random horizon\n(a.k.a. the Yaari model) to a world in which (i.) the force of mortality obeys\na diffusion process as opposed to being deterministic, and (ii.) a consumer can\nadapt their consumption strategy to new information about their mortality rate\n(a.k.a. health status) as it becomes available. In particular, we derive the\noptimal consumption rate and focus on the impact of mortality rate uncertainty\nvs. simple lifetime uncertainty -- assuming the actuarial survival curves are\ninitially identical -- in the retirement phase where this risk plays a greater\nrole.\n  In addition to deriving and numerically solving the PDE for the optimal\nconsumption rate, our main general result is that when utility preferences are\nlogarithmic the initial consumption rates are identical. But, in a CRRA\nframework in which the coefficient of relative risk aversion is greater\n(smaller) than one, the consumption rate is higher (lower) and a stochastic\nforce of mortality does make a difference.\n  That said, numerical experiments indicate that even for non-logarithmic\npreferences, the stochastic mortality effect is relatively minor from the\nindividual's perspective. Our results should be relevant to researchers\ninterested in calibrating the lifecycle model as well as those who provide\nnormative guidance (a.k.a. financial advice) to retirees.\n"
    },
    {
        "paper_id": 1205.2299,
        "authors": "Rene Carmona, Michael Coulon, Daniel Schwarz",
        "title": "Electricity price modeling and asset valuation: a multi-fuel structural\n  approach",
        "comments": null,
        "journal-ref": "Mathematics and Financial Economics, 7(2), pp. 167-202, 2013",
        "doi": "10.1007/s11579-012-0091-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new and highly tractable structural model for spot and\nderivative prices in electricity markets. Using a stochastic model of the bid\nstack, we translate the demand for power and the prices of generating fuels\ninto electricity spot prices. The stack structure allows for a range of\ngenerator efficiencies per fuel type and for the possibility of future changes\nin the merit order of the fuels. The derived spot price process captures\nimportant stylized facts of historical electricity prices, including both\nspikes and the complex dependence upon its underlying supply and demand\ndrivers. Furthermore, under mild and commonly used assumptions on the\ndistributions of the input factors, we obtain closed-form formulae for\nelectricity forward contracts and for spark and dark spread options. As merit\norder dynamics and fuel forward prices are embedded into the model, we capture\na much richer and more realistic dependence structure than can be achieved by\nclassical reduced-form models. We illustrate these advantages by comparing with\nMargrabe's formula and a simple cointegration model, and highlight important\nimplications for the valuation of power plants.\n"
    },
    {
        "paper_id": 1205.2302,
        "authors": "Rene Carmona, Michael Coulon, Daniel Schwarz",
        "title": "The Valuation of Clean Spread Options: Linking Electricity, Emissions\n  and Fuels",
        "comments": null,
        "journal-ref": "Quantitative Finance, 12(12), pp. 1951-1965, 2012",
        "doi": "10.1080/14697688.2012.750733",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of the paper is to present a new pricing method for clean spread\noptions, and to illustrate its main features on a set of numerical examples\nproduced by a dedicated computer code. The novelty of the approach is embedded\nin the use of structural models as opposed to reduced-form models which fail to\ncapture properly the fundamental dependencies between the economic factors\nentering the production process.\n"
    },
    {
        "paper_id": 1205.2398,
        "authors": "Matthew Lorig and Oriol Lozano-Carbass\\'e",
        "title": "Exponential L\\'evy-type models with stochastic volatility and stochastic\n  jump-intensity",
        "comments": "24 pages, 4 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of valuing a European option written on an asset\nwhose dynamics are described by an exponential L\\'evy-type model. In our\nframework, both the volatility and jump-intensity are allowed to vary\nstochastically in time through common driving factors -- one fast-varying and\none slow-varying. Using Fourier analysis we derive an explicit formula for the\napproximate price of any European-style derivative whose payoff has a\ngeneralized Fourier transform; in particular, this includes European calls and\nputs. From a theoretical perspective, our results extend the class of\nmultiscale stochastic volatility models of \\citet*{fpss} to models of the\nexponential L\\'evy type. From a financial perspective, the inclusion of jumps\nand stochastic volatility allow us to capture the term-structure of implied\nvolatility. To illustrate the flexibility of our modeling framework we extend\nfive exponential L\\'evy processes to include stochastic volatility and\njump-intensity. For each of the extended models, using a single fast-varying\nfactor of volatility and jump-intensity, we perform a calibration to the S&P500\nimplied volatility surface. Our results show decisively that the extended\nframework provides a significantly better fit to implied volatility than both\nthe traditional exponential L\\'evy models and the fast mean-reverting\nstochastic volatility models of \\citet{fpss}.\n"
    },
    {
        "paper_id": 1205.2415,
        "authors": "Marcel Nutz, Ramon van Handel",
        "title": "Constructing Sublinear Expectations on Path Space",
        "comments": "28 pages; forthcoming in 'Stochastic Processes and their\n  Applications'",
        "journal-ref": "Stoch. Proc. Appl. 123, 3100-3121 (2013)",
        "doi": "10.1016/j.spa.2013.03.022",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a general construction of time-consistent sublinear expectations\non the space of continuous paths. It yields the existence of the conditional\nG-expectation of a Borel-measurable (rather than quasi-continuous) random\nvariable, a generalization of the random G-expectation, and an optional\nsampling theorem that holds without exceptional set. Our results also shed\nlight on the inherent limitations to constructing sublinear expectations\nthrough aggregation.\n"
    },
    {
        "paper_id": 1205.247,
        "authors": "Hideaki Aoyama, Hiroshi Iyetomi, and Hiroshi Yoshikawa",
        "title": "Equilibrium Distribution of Labor Productivity: A Theoretical Model",
        "comments": "11pages, 5 figures, and 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct a theoretical model for equilibrium distribution of workers\nacross sectors with different labor productivity, assuming that a sector can\naccommodate a limited number of workers which depends only on its productivity.\nA general formula for such distribution of productivity is obtained, using the\ndetail-balance condition necessary for equilibrium in the Ehrenfest-Brillouin\nmodel. We also carry out an empirical analysis on the average number of workers\nin given productivity sectors on the basis of an exhaustive dataset in Japan.\nThe theoretical formula succeeds in explaining the two distinctive\nobservational facts in a unified way, that is, a Boltzmann distribution with\nnegative temperature on low-to-medium productivity side and a decreasing part\nin a power-law form on high productivity side.\n"
    },
    {
        "paper_id": 1205.2501,
        "authors": "Alexander Jordan and Alex Lenkoski",
        "title": "Tobit Bayesian Model Averaging and the Determinants of Foreign Direct\n  Investment",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a fully Bayesian, computationally efficient framework for\nincorporating model uncertainty into Type II Tobit models and apply this to the\ninvestigation of the determinants of Foreign Direct Investment (FDI). While\ndirect evaluation of modelprobabilities is intractable in this setting, we show\nthat by using conditional Bayes Factors, which nest model moves inside a Gibbs\nsampler, we are able to incorporate model uncertainty in a straight-forward\nfashion. We conclude with a study of global FDI flows between 1988-2000.\n"
    },
    {
        "paper_id": 1205.2513,
        "authors": "Huaxiong Huang, Moshe A. Milevsky and Thomas S. Salisbury",
        "title": "A different perspective on retirement income sustainability: the\n  blueprint for a ruin contingent life annuity (RCLA)",
        "comments": null,
        "journal-ref": "J. of Wealth Management, 11 (2009), pp. 89-97",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this article is twofold. First, we motivate the need for a new\ntype of stand-alone retirement income insurance product that would help\nindividuals protect against personal longevity risk and possible \"retirement\nruin\" in an economically efficient manner. We label this product a\nruin-contingent life annuity (RCLA), which we elaborate-on and explain with\nvarious numerical examples and a basic pricing model. Second, we argue that\nwith the proper perspective a similar product actually exists, albeit not\navailable on a stand-alone basis. Namely, they are fused and embedded within\nmodern variable annuity (VA) policies with guaranteed living income benefit\n(GLiB) riders. Indeed, the popularity of GLiB riders on VA policies point\ntowards the potential commercial success of such a stand-alone vehicle.\n"
    },
    {
        "paper_id": 1205.2521,
        "authors": "Matteo Ortisi and Valerio Zuccolo",
        "title": "From Minority Game to Black & Scholes pricing",
        "comments": "Extended to the Grand Canonical Minority Game 20 pages, 18 figure",
        "journal-ref": null,
        "doi": "10.1080/1350486X.2013.787246",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study the continuum time dynamics of a stock in a market\nwhere agents behavior is modeled by a Minority Game and a Grand Canonical\nMinority Game. The dynamics derived is a generalized geometric Brownian motion;\nfrom the Black & Scholes formula the calibration of both the Minority Game and\nthe Grand Canonical Minority Game, by means of their characteristic parameters,\nis performed. We conclude that for both games the asymmetric phase with\ncharacteristic parameters close to critical ones is coherent with options\nimplied volatility market.\n"
    },
    {
        "paper_id": 1205.2551,
        "authors": "Guglielmo D'Amico and Filippo Petroni",
        "title": "Weighted-indexed semi-Markov models for modeling financial returns",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1109.4259",
        "journal-ref": "J. Stat. Mech., P07015, 2012",
        "doi": "10.1088/1742-5468/2012/07/P07015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a new stochastic model based on a generalization of\nsemi-Markov chains to study the high frequency price dynamics of traded stocks.\nWe assume that the financial returns are described by a weighted indexed\nsemi-Markov chain model. We show, through Monte Carlo simulations, that the\nmodel is able to reproduce important stylized facts of financial time series as\nthe first passage time distributions and the persistence of volatility. The\nmodel is applied to data from Italian and German stock market from first of\nJanuary 2007 until end of December 2010.\n"
    },
    {
        "paper_id": 1205.2863,
        "authors": "Carlo Castellana",
        "title": "Impact of the economic crisis on the Italian public healthcare\n  expenditure",
        "comments": "27 pages, 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The global financial crisis, beginning in 2008, took an historic toll on\nnational economies around the world. Following equity market crashes,\nunemployment rates rose significantly in many countries: Italy was among those.\nWhat will be the impact of such large shocks on Italian healthcare finances? An\nempirical model for estimating the impact of the crisis on Italian public\nhealthcare expenditure is presented. Based on data from epidemiological studies\nrelated to past economic crisis, the financial impact is estimated to be\ncomparable to the healthcare deficit of Italian Regions (EUR 3-5 bn). According\nto current agreements between the Italian State and its Regions, public funding\nof regional National Health Services (NHSs) is limited to the amount of\nregional deficit and is subject to previous assessment of strict adherence to\nconstraint on regional healthcare balance-sheet. Those Regions that will fail\nto comply to balance-sheet constraints will suffer cuts on their public NHS\nfinancing with foreseeable bad consequences for the health of their regional\npopulation. The current crisis could be a good timing for a large-scale\nre-engineering of the Italian NHS, probably the only way for\nself-sustainability of the public system.\n"
    },
    {
        "paper_id": 1205.2866,
        "authors": "R. Vilela Mendes, M. J. Oliveira and A.M. Rodrigues",
        "title": "The fractional volatility model: No-arbitrage, leverage and completeness",
        "comments": "13 pages Latex. arXiv admin note: substantial text overlap with\n  arXiv:1007.2817",
        "journal-ref": "Physica A 419 (2015) 470-478",
        "doi": "10.1016/j.physa.2014.10.056",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on a criterion of mathematical simplicity and consistency with\nempirical market data, a stochastic volatility model has been obtained with the\nvolatility process driven by fractional noise. Depending on whether the\nstochasticity generators of log-price and volatility are independent or are the\nsame, two versions of the model are obtained with different leverage behavior.\nHere, the no-arbitrage and completeness properties of the models are studied.\n"
    },
    {
        "paper_id": 1205.2872,
        "authors": "David Carf\\`i, Daniele Schilir\\`o",
        "title": "Global Green Economy and Environmental Sustainability: a Coopetitive\n  Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper provides a coopetitive model for a global green economy, taking\ninto account the environmental sustainability. In particular, we propose a\ndifferentiable coopetitive game G (in the sense recently introduced by D.\nCarf`{\\i}) to represent a global green economy interaction, among a country c\nand the rest of the world w. Our game G is a linear parametric (Euclidean)\nperturbation of the classic Cournot duopoly. In the paper we offer the complete\nstudy of the proposed model and in particular a deep examination of its\npossible coopetitive solutions.\n"
    },
    {
        "paper_id": 1205.2878,
        "authors": "Daniela Baglieri, David Carf\\`i, Giovanni Battista Dagnino",
        "title": "Asymmetric R&D Alliances and Coopetitive Games",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1106.3543",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we show how the study of asymmetric R&D alliances, that are\nthose between young and small firms and large and MNEs firms for knowledge\nexploration and/or exploitation, requires the adoption of a coopetitive\nframework which consider both collaboration and competition. We draw upon the\nliterature on asymmetric R&D collaboration and coopetition to propose a\nmathematical model for the coopetitive games which is particularly suitable for\nexploring asymmetric R&D alliances.\n"
    },
    {
        "paper_id": 1205.2915,
        "authors": "Daniel R. Parisi, Didier Sornette and Dirk Helbing",
        "title": "Universality class of balanced flows with bottlenecks: granular flows,\n  pedestrian fluxes and financial price dynamics",
        "comments": "To be submitted to PRE",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose and document the evidence for an analogy between the dynamics of\ngranular counter-flows in the presence of bottlenecks or restrictions and\nfinancial price formation processes. Using extensive simulations, we find that\nthe counter-flows of simulated pedestrians through a door display many stylized\nfacts observed in financial markets when the density around the door is\ncompared with the logarithm of the price. The stylized properties are present\nalready when the agents in the pedestrian model are assumed to display a\nzero-intelligent behavior. If agents are given decision-making capacity and\nadapt to partially follow the majority, periods of herding behavior may\nadditionally occur. This generates the very slow decay of the autocorrelation\nof absolute return due to an intermittent dynamics. Our finding suggest that\nthe stylized facts in the fluctuations of the financial prices result from a\ncompetition of two groups with opposite interests in the presence of a\nconstraint funneling the flow of transactions to a narrow band of prices.\n"
    },
    {
        "paper_id": 1205.2999,
        "authors": "Jaime Gomez-Ramirez and Manuel G. Bedia",
        "title": "Towards a new brain science: lessons from the economic collapse",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Economies are complex man-made systems where organisms and markets interact\naccording to motivations and principles not entirely understood yet. The\nincreasing dissatisfaction with the postulates of traditional economics i.e.\nperfectly rational agents, interacting through efficient markets in the search\nof equilibrium, has created new incentives for different approaches in\neconomics. The science of complexity may provide the platform to cross\ndisciplinary boundaries in seemingly disparate fields such as brain science and\neconomics. In this paper we take an integrative stance, fostering new insights\ninto the economic character of neural activity. The objective here is to\nprecisely delineate common topics in both neural and economic science, within a\nsystemic outlook grounded in empirical basis that jolts the unification across\nthe science of complex systems. It is argued that this mainly relies on the\nstudy of the inverse problem in complex system with a truly Bayesian approach.\n"
    },
    {
        "paper_id": 1205.3051,
        "authors": "Fabien Guilbaud (LPMA), Huy\\^en Pham (LPMA, CREST)",
        "title": "Optimal High Frequency Trading in a Pro-Rata Microstructure with\n  Predictive Information",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a framework to study optimal trading policies in a one-tick\npro-rata limit order book, as typically arises in short-term interest rate\nfutures contracts. The high-frequency trader has the choice to trade via market\norders or limit orders, which are represented respectively by impulse controls\nand regular controls. We model and discuss the consequences of the two main\nfeatures of this particular microstructure: first, the limit orders sent by the\nhigh frequency trader are only partially executed, and therefore she has no\ncontrol on the executed quantity. For this purpose, cumulative executed volumes\nare modelled by compound Poisson processes. Second, the high frequency trader\nfaces the overtrading risk, which is the risk of brutal variations in her\ninventory. The consequences of this risk are investigated in the context of\noptimal liquidation. The optimal trading problem is studied by stochastic\ncontrol and dynamic programming methods, which lead to a characterization of\nthe value function in terms of an integro quasi-variational inequality. We then\nprovide the associated numerical resolution procedure, and convergence of this\ncomputational scheme is proved. Next, we examine several situations where we\ncan on one hand simplify the numerical procedure by reducing the number of\nstate variables, and on the other hand focus on specific cases of practical\ninterest. We examine both a market making problem and a best execution problem\nin the case where the mid-price process is a martingale. We also detail a high\nfrequency trading strategy in the case where a (predictive) directional\ninformation on the mid-price is available. Each of the resulting strategies are\nillustrated by numerical tests.\n"
    },
    {
        "paper_id": 1205.3405,
        "authors": "Tommi Sottinen and Adil Yazigi",
        "title": "Generalized Gaussian Bridges",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A generalized bridge is the law of a stochastic process that is conditioned\non N linear functionals of its path. We consider two types of representations\nof such bridges: orthogonal and canonical.\n  The orthogonal representation is constructed from the entire path of the\nunderlying process. Thus, future knowledge of the path is needed. The\northogonal representation is provided for any continuous Gaussian process.\n  In the canonical representation the filtrations and the linear spaces\ngenerated by the bridge process and the underlying process coincide. Thus, no\nfuture information of the underlying process is needed. Also, in the\nsemimartingale case the canonical bridge representation is related to the\nenlargement of filtration and semimartingale decompositions. The canonical\nrepresentation is provided for the so-called prediction-invertible Gaussian\nprocesses. All martingales are trivially prediction-invertible. A typical\nnon-semimartingale example of a prediction-invertible Gaussian process is the\nfractional Brownian motion.\n  We apply the canonical bridges to insider trading.\n"
    },
    {
        "paper_id": 1205.3482,
        "authors": "Mauricio Labadie and Charles-Albert Lehalle",
        "title": "Optimal starting times, stopping times and risk measures for algorithmic\n  trading: Target Close and Implementation Shortfall",
        "comments": "27 pages",
        "journal-ref": "Journal of Investment Strategies, Volume 3, Issue 2, 2014",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive explicit recursive formulas for Target Close (TC) and\nImplementation Shortfall (IS) in the Almgren-Chriss framework. We explain how\nto compute the optimal starting and stopping times for IS and TC, respectively,\ngiven a minimum trading size. We also show how to add a minimum participation\nrate constraint (Percentage of Volume, PVol) for both TC and IS. We also study\nan alternative set of risk measures for the optimisation of algorithmic trading\ncurves. We assume a self-similar process (e.g. Levy process, fractional\nBrownian motion or fractal process) and define a new risk measure, the\np-variation, which reduces to the variance if the process is a brownian motion.\nWe deduce the explicit formula for the TC and IS algorithms under a\nself-similar process. We show that there is an equivalence between selfsimilar\nmodels and a family of risk measures called p-variations: assuming a\nself-similar process and calibrating empirically the parameter p for the\np-variation yields the same result as assuming a Brownian motion and using the\np-variation as risk measure instead of the variance. We also show that p can be\nseen as a measure of the aggressiveness: p increases if and only if the TC\nalgorithm starts later and executes faster. Finally, we show how the parameter\np of the p-variation can be implied from the optimal starting time of TC, and\nthat under this framework p can be viewed as a measure of the joint impact of\nmarket impact (i.e. liquidity) and volatility.\n"
    },
    {
        "paper_id": 1205.3507,
        "authors": "Igor Halperin and Andrey Itkin",
        "title": "Pricing options on illiquid assets with liquid proxies using utility\n  indifference and dynamic-static hedging",
        "comments": "34 pages, 10 figures, first presented at Global Derivatives USA,\n  Chicago, 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work addresses the problem of optimal pricing and hedging of a European\noption on an illiquid asset Z using two proxies: a liquid asset S and a liquid\nEuropean option on another liquid asset Y. We assume that the S-hedge is\ndynamic while the Y-hedge is static. Using the indifference pricing approach we\nderive a HJB equation for the value function, and solve it analytically (in\nquadratures) using an asymptotic expansion around the limit of the perfect\ncorrelation between assets Y and Z. While in this paper we apply our framework\nto an incomplete market version of the credit-equity Merton's model, the same\napproach can be used for other asset classes (equity, commodity, FX, etc.),\ne.g. for pricing and hedging options with illiquid strikes or illiquid exotic\noptions.\n"
    },
    {
        "paper_id": 1205.3519,
        "authors": "Carlo Castellana",
        "title": "Restructuring the Italian NHS: a case study of the regional hospital\n  network",
        "comments": "36 pages, 21 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One of the main issues affecting the Italian NHS is the healthcare deficit:\naccording to current agreements between the Italian State and its Regions,\npublic funding of regional NHS is now limited to the amount of regional deficit\nand is subject to previous assessment of strict adherence to constraint on\nregional healthcare balance sheet. Many Regions with previously uncontrolled\nhealthcare deficit have now to plan their \"Piano di Rientro\" (PdR) and submit\nit for the approval of the Italian Ministry of Economy and Finances. Those\nRegions that will fail to comply to deficit constraints will suffer cuts on\ntheir public NHS financing. A smart Health Planning can make sure health\nspending is managed appropriately. Indeed a restructuring of the Italian\nhealthcare system has recently been enforced in order to cope for the clumsy\nregional healthcare balance sheets. Half of total Italian healthcare\nexpenditure is accounted by hospital services which therefore configure as one\nof the main restructuring targets. This paper provides a general framework for\nplanning a re-engineering of a hospital network. This framework is made of\neconomic, legal and healthcare constraints. We apply the general framework to\nthe particular case of Puglia region and explore a set of re-engineered\nsolutions which to different extent could help solve the difficult dilemma:\ncutting costs without worsening the delivery of public healthcare services.\n"
    },
    {
        "paper_id": 1205.355,
        "authors": "Andrey Itkin",
        "title": "New solvable stochastic volatility models for pricing volatility\n  derivatives",
        "comments": "28 pages, 3 figures, first presented at Global Derivatives & Risk,\n  Paris 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Classical solvable stochastic volatility models (SVM) use a CEV process for\ninstantaneous variance where the CEV parameter $\\gamma$ takes just few values:\n0 - the Ornstein-Uhlenbeck process, 1/2 - the Heston (or square root) process,\n1- GARCH, and 3/2 - the 3/2 model. Some other models were discovered in\n\\cite{Labordere2009} by making connection between stochastic volatility and\nsolvable diffusion processes in quantum mechanics. In particular, he used to\nbuild a bridge between solvable (super)potentials (the Natanzon\n(super)potentials, which allow reduction of a Schr\\\"{o}dinger equation to a\nGauss confluent hypergeometric equation) and existing SVM. In this paper we\ndiscuss another approach to extend the class of solvable SVM in terms of\nhypergeometric functions. Thus obtained new models could be useful for pricing\nvolatility derivatives (variance and volatility swaps, moment swaps).\n"
    },
    {
        "paper_id": 1205.3555,
        "authors": "Erd\\.in\\c{c} Aky{\\i}ld{\\i}r{\\i}m, Yan Dolinsky, H. Mete Soner",
        "title": "Approximating stochastic volatility by recombinant trees",
        "comments": "Published in at http://dx.doi.org/10.1214/13-AAP977 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 5, 2176-2205",
        "doi": "10.1214/13-AAP977",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A general method to construct recombinant tree approximations for stochastic\nvolatility models is developed and applied to the Heston model for stock price\ndynamics. In this application, the resulting approximation is a four tuple\nMarkov process. The first two components are related to the stock and\nvolatility processes and take values in a two-dimensional binomial tree. The\nother two components of the Markov process are the increments of random walks\nwith simple values in $\\{-1,+1\\}$. The resulting efficient option pricing\nequations are numerically implemented for general American and European options\nincluding the standard put and calls, barrier, lookback and Asian-type\npay-offs. The weak and extended weak convergences are also proved.\n"
    },
    {
        "paper_id": 1205.3671,
        "authors": "Dmitry V. Vinogradov",
        "title": "Arbitrary Truncated Levy Flight: Asymmetrical Truncation and High-Order\n  Correlations",
        "comments": "19 pages, 1 figure, To be submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.06.022",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The generalized correlation approach, which has been successfully used in\nstatistical radio physics to describe non-Gaussian random processes, is\nproposed to describe stochastic financial processes. The generalized\ncorrelation approach has been used to describe a non-Gaussian random walk with\nindependent, identically distributed increments in the general case, and\nhigh-order correlations have been investigated. The cumulants of an\nasymmetrically truncated Levy distribution have been found. The behaviors of\nasymmetrically truncated Levy flight, as a particular case of a random walk,\nare considered. It is shown that, in the Levy regime, high-order correlations\nbetween values of asymmetrically truncated Levy flight exist. The source of\nhigh-order correlations is the non-Gaussianity of the increments: the increment\nskewness generates threefold correlation, and the increment kurtosis generates\nfourfold correlation.\n"
    },
    {
        "paper_id": 1205.3686,
        "authors": "Huaxiong Huang, Moshe A. Milevsky, and Thomas S. Salisbury",
        "title": "Valuation and hedging of the ruin-contingent life annuity (RCLA)",
        "comments": null,
        "journal-ref": "J. Risk and Insurance 81 (2014), 367-395",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper analyzes a novel type of mortality contingent-claim called a\nruin-contingent life annuity (RCLA). This product fuses together a\npath-dependent equity put option with a \"personal longevity\" call option. The\nannuitant's (i.e. long position) payoff from a generic RCLA is \\$1 of income\nper year for life, akin to a defined benefit pension, but deferred until a\npre-specified financial diffusion process hits zero. We derive the PDE and\nrelevant boundary conditions satisfied by the RCLA value (i.e. the hedging\ncost) assuming a complete market where No Arbitrage is possible. We then\ndescribe some efficient numerical techniques and provide estimates of a typical\nRCLA under a variety of realistic parameters.\n  The motivation for studying the RCLA on a stand-alone basis is two-fold.\nFirst, it is implicitly embedded in approximately \\$1 trillion worth of U.S.\nvariable annuity (VA) policies; which have recently attracted scrutiny from\nfinancial analysts and regulators. Second, the U.S. administration - both\nTreasury and Department of Labor - have been encouraging Defined Contribution\n(401k) plans to offer stand-alone longevity insurance to participants, and we\nbelieve the RCLA would be an ideal and cost effective candidate for that job.\n"
    },
    {
        "paper_id": 1205.3763,
        "authors": "Jiri Kukacka, Jozef Barunik",
        "title": "Behavioural breaks in the heterogeneous agent model: the impact of\n  herding, overconfidence, and market sentiment",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.07.050",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main aim of this work is to incorporate selected findings from\nbehavioural finance into a Heterogeneous Agent Model using the Brock and Hommes\n(1998) framework. Behavioural patterns are injected into an asset pricing\nframework through the so-called `Break Point Date', which allows us to examine\ntheir direct impact. In particular, we analyse the dynamics of the model around\nthe behavioural break. Price behaviour of 30 Dow Jones Industrial Average\nconstituents covering five particularly turbulent U.S. stock market periods\nreveals interesting pattern in this aspect. To replicate it, we apply numerical\nanalysis using the Heterogeneous Agent Model extended with the selected\nfindings from behavioural finance: herding, overconfidence, and market\nsentiment. We show that these behavioural breaks can be well modelled via the\nHeterogeneous Agent Model framework and they extend the original model\nconsiderably. Various modifications lead to significantly different results and\nmodel with behavioural breaks is also able to partially replicate price\nbehaviour found in the data during turbulent stock market periods.\n"
    },
    {
        "paper_id": 1205.3767,
        "authors": "Vladimir V'yugin and Vladimir Trunov",
        "title": "Universal Algorithm for Online Trading Based on the Method of\n  Calibration",
        "comments": "32 pages. arXiv admin note: substantial text overlap with\n  arXiv:1105.4272",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a universal algorithm for online trading in Stock Market which\nperforms asymptotically at least as good as any stationary trading strategy\nthat computes the investment at each step using a fixed function of the side\ninformation that belongs to a given RKHS (Reproducing Kernel Hilbert Space).\nUsing a universal kernel, we extend this result for any continuous stationary\nstrategy. In this learning process, a trader rationally chooses his gambles\nusing predictions made by a randomized well-calibrated algorithm. Our strategy\nis based on Dawid's notion of calibration with more general checking rules and\non some modification of Kakade and Foster's randomized rounding algorithm for\ncomputing the well-calibrated forecasts. We combine the method of randomized\ncalibration with Vovk's method of defensive forecasting in RKHS. Unlike the\nstatistical theory, no stochastic assumptions are made about the stock prices.\nOur empirical results on historical markets provide strong evidence that this\ntype of technical trading can \"beat the market\" if transaction costs are\nignored.\n"
    },
    {
        "paper_id": 1205.4008,
        "authors": "Florian Kl\\\"ock, Alexander Schied, Yuemeng Sun",
        "title": "Price manipulation in a market impact model with dark pool",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a market impact model, price manipulation and related notions play a role\nthat is similar to the role of arbitrage in a derivatives pricing model. Here,\nwe give a systematic investigation into such regularity issues when orders can\nbe executed both at a traditional exchange and in a dark pool. To this end, we\nfocus on a class of dark-pool models whose market impact at the exchange is\ndescribed by an Almgren--Chriss model. Conditions for the absence of price\nmanipulation for all Almgren--Chriss models include the absence of temporary\ncross-venue impact, the presence of full permanent cross-venue impact, and the\nadditional penalization of orders executed in the dark pool. When a particular\nAlmgren--Chriss model has been fixed, we show by a number of examples that the\nregularity of the dark-pool model hinges in a subtle way on the interplay of\nall model parameters and on the liquidation time constraint. The paper can also\nbe seen as a case study for the regularity of market impact models in general.\n"
    },
    {
        "paper_id": 1205.4089,
        "authors": "St\\'ephane Goutte (LAGA), Nadia Oudjane (LAGA), Francesco Russo\n  (CERMICS, INRIA Rocquencourt, UMA)",
        "title": "Variance Optimal Hedging for discrete time processes with independent\n  increments. Application to Electricity Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the discretized version of a (continuous-time) two-factor model\nintroduced by Benth and coauthors for the electricity markets. For this model,\nthe underlying is the exponent of a sum of independent random variables. We\nprovide and test an algorithm, which is based on the celebrated\nFoellmer-Schweizer decomposition for solving the mean-variance hedging problem.\nIn particular, we establish that decomposition explicitely, for a large class\nof vanilla contingent claims. Interest is devoted in the choice of rebalancing\ndates and its impact on the hedging error, regarding the payoff regularity and\nthe non stationarity of the log-price process.\n"
    },
    {
        "paper_id": 1205.4345,
        "authors": "Brahim Brahimi",
        "title": "Involving copula functions in Conditional Tail Expectation",
        "comments": "Submitted Paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  Our goal in this paper is to propose an alternative risk measure which takes\ninto account the fluctuations of losses and possible correlations between\nrandom variables. This new notion of risk measures, that we call Copula\nConditional Tail Expectation describes the expected amount of risk that can be\nexperienced given that a potential bivariate risk exceeds a bivariate threshold\nvalue, and provides an important measure for right-tail risk. An application to\nreal financial data is given.\n"
    },
    {
        "paper_id": 1205.4358,
        "authors": "Umut \\c{C}etin and Hao Xing",
        "title": "Point process bridges and weak convergence of insider trading models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct explicitly a bridge process whose distribution, in its own\nfiltration, is the same as the difference of two independent Poisson processes\nwith the same intensity and its time 1 value satisfies a specific constraint.\nThis construction allows us to show the existence of Glosten-Milgrom\nequilibrium and its associated optimal trading strategy for the insider. In the\nequilibrium the insider employs a mixed strategy to randomly submit two types\nof orders: one type trades in the same direction as noise trades while the\nother cancels some of the noise trades by submitting opposite orders when noise\ntrades arrive. The construction also allows us to prove that Glosten-Milgrom\nequilibria converge weakly to Kyle-Back equilibrium, without the additional\nassumptions imposed in \\textit{K. Back and S. Baruch, Econometrica, 72 (2004),\npp. 433-465}, when the common intensity of the Poisson processes tends to\ninfinity.\n"
    },
    {
        "paper_id": 1205.4588,
        "authors": "Johannes Muhle-Karbe, Ren Liu",
        "title": "Portfolio Selection with Small Transaction Costs and Binding Portfolio\n  Constraints",
        "comments": "23 pages, 6 figures, 1 table, to appear in \"SIAM Journal on Financial\n  Mathematics\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An investor with constant relative risk aversion and an infinite planning\nhorizon trades a risky and a safe asset with constant investment opportunities,\nin the presence of small transaction costs and a binding exogenous portfolio\nconstraint. We explicitly derive the optimal trading policy, its welfare, and\nimplied trading volume. As an application, we study the problem of selecting a\nprime broker among alternatives with different lending rates and margin\nrequirements. Moreover, we discuss how changing regulatory constraints affect\nthe deposit rates offered for illiquid loans.\n"
    },
    {
        "paper_id": 1205.4589,
        "authors": "Agata Fronczak",
        "title": "Structural Hamiltonian of the international trade network",
        "comments": "Presented at Summer Solstice 2011 Conference on Discrete Models of\n  Complex Systems, Turku, Finland (15 pages, 3 figures)",
        "journal-ref": "Acta Phys. Pol. B Vol. 5, No. 1, pp. 31-46 (2012)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is common wisdom that no nation is an isolated economic island. All\nnations participate in the global economy and are linked together through trade\nand finance. Here we analyze international trade network (ITN), being the\nnetwork of import-export relationships between countries. We show that in each\nyear over the analyzed period of 50 years (since 1950) the network is a typical\nrepresentative of the ensemble of maximally random networks. Structural\nHamiltonians characterizing binary and weighted versions of ITN are formulated\nand discussed. In particular, given binary representation of ITN (i.e. binary\nnetwork of trade channels) we show that the network of partnership in trade is\nwell described by the configuration model. We also show that in the weighted\nversion of ITN, bilateral trade volumes (i.e. directed connections which\nrepresent trade/money flows between countries) are only characterized by the\nproduct of the trading countries' GDPs, like in the famous gravity model of\ntrade.\n"
    },
    {
        "paper_id": 1205.4643,
        "authors": "Christoph Czichowsky, Johannes Muhle-Karbe, Walter Schachermayer",
        "title": "Transaction Costs, Shadow Prices, and Duality in Discrete Time",
        "comments": "21 pages, 1 figure, to appear in \"SIAM Journal on Financial\n  Mathematics\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For portfolio choice problems with proportional transaction costs, we discuss\nwhether or not there exists a \"shadow price\", i.e., a least favorable\nfrictionless market extension leading to the same optimal strategy and utility.\n  By means of an explicit counter-example, we show that shadow prices may fail\nto exist even in seemingly perfectly benign situations, i.e., for a\nlog-investor trading in an arbitrage-free market with bounded prices and\narbitrarily small transaction costs.\n  We also clarify the connection between shadow prices and duality theory.\nWhereas dual minimizers need not lead to shadow prices in the above \"global\"\nsense, we show that they always correspond to a \"local\" version.\n"
    },
    {
        "paper_id": 1205.4693,
        "authors": "J. F. Mercure and P. Salas",
        "title": "An assessement of global energy resource economic potentials",
        "comments": "17 pages, 14 figures, 2 tables, 18 pages supplementary information\n  with 2 additional figures and 10 additional data tables",
        "journal-ref": "Energy 46 322-336 (2012)",
        "doi": "10.1016/j.energy.2012.08.018",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents an assessment of global economic energy potentials for\nall major natural energy resources. This work is based on both an extensive\nliterature review and calculations using natural resource assessment data.\nEconomic potentials are presented in the form of cost-supply curves, in terms\nof energy flows for renewable energy sources, or fixed amounts for fossil and\nnuclear resources, with strong emphasis on uncertainty, using a consistent\nmethodology that allow direct comparisons to be made. In order to interpolate\nthrough available resource assessment data and associated uncertainty, a\ntheoretical framework and a computational methodology are given based on\nstatistical properties of different types of resources, justified empirically\nby the data, and used throughout. This work aims to provide a global database\nfor natural energy resources ready to integrate into models of energy systems,\nenabling to introduce at the same time uncertainty over natural resource\nassessments. The supplementary material provides theoretical details and tables\nof data and parameters that enable this extensive database to be adapted to a\nvariety of energy systems modelling frameworks.\n"
    },
    {
        "paper_id": 1205.4748,
        "authors": "Christoph Czichowsky",
        "title": "Time-Consistent Mean-Variance Portfolio Selection in Discrete and\n  Continuous Time",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is well known that mean-variance portfolio selection is a\ntime-inconsistent optimal control problem in the sense that it does not satisfy\nBellman's optimality principle and therefore the usual dynamic programming\napproach fails. We develop a time- consistent formulation of this problem,\nwhich is based on a local notion of optimality called local mean-variance\nefficiency, in a general semimartingale setting. We start in discrete time,\nwhere the formulation is straightforward, and then find the natural extension\nto continuous time. This complements and generalises the formulation by Basak\nand Chabakauri (2010) and the corresponding example in Bj\\\"ork and Murgoci\n(2010), where the treatment and the notion of optimality rely on an underlying\nMarkovian framework. We justify the continuous-time formulation by showing that\nit coincides with the continuous-time limit of the discrete-time formulation.\nThe proof of this convergence is based on a global description of the locally\noptimal strategy in terms of the structure condition and the\nF\\\"ollmer-Schweizer decomposition of the mean-variance tradeoff. As a\nbyproduct, this also gives new convergence results for the F\\\"ollmer-Schweizer\ndecomposition, i.e. for locally risk minimising strategies.\n"
    },
    {
        "paper_id": 1205.479,
        "authors": "Tomasz R. Bielecki, Igor Cialenco, Ismail Iyigunler, Rodrigo Rodriguez",
        "title": "Dynamic Conic Finance: Pricing and Hedging in Market Models with\n  Transaction Costs via Dynamic Coherent Acceptability Indices",
        "comments": "extended-preprint version of the published paper",
        "journal-ref": "International Journal of Theoretical and Applied Finance, vol. 16,\n  No 1, 2013",
        "doi": "10.1142/S0219024913500027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present a theoretical framework for determining dynamic ask\nand bid prices of derivatives using the theory of dynamic coherent\nacceptability indices in discrete time. We prove a version of the First\nFundamental Theorem of Asset Pricing using the dynamic coherent risk measures.\nWe introduce the dynamic ask and bid prices of a derivative contract in markets\nwith transaction costs. Based on these results, we derive a representation\ntheorem for the dynamic bid and ask prices in terms of dynamically consistent\nsequence of sets of probability measures and risk-neutral measures. To\nillustrate our results, we compute the ask and bid prices of some\npath-dependent options using the dynamic Gain-Loss Ratio.\n"
    },
    {
        "paper_id": 1205.5369,
        "authors": "Simone Farinelli and Mykhaylo Shkolnikov",
        "title": "Two Models of Stochastic Loss Given Default",
        "comments": "Problems with figures in preceeding version has been solved",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose two structural models for stochastic losses given default which\nallow to model the credit losses of a portfolio of defaultable financial\ninstruments. The credit losses are integrated into a structural model of\ndefault events accounting for correlations between the default events and the\nassociated losses. We show how the models can be calibrated and analyze the\nimpact of correlations between the occurrences of defaults and recoveries by\ntesting our models for a representative sample portfolio.\n"
    },
    {
        "paper_id": 1205.5565,
        "authors": "Giovanni Salvi and Anatoliy V. Swishchuk",
        "title": "Modeling and Pricing of Covariance and Correlation Swaps for Financial\n  Markets with Semi-Markov Volatilities",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we model financial markets with semi-Markov volatilities and\nprice covarinace and correlation swaps for this markets. Numerical evaluations\nof vari- nace, volatility, covarinace and correlations swaps with semi-Markov\nvolatility are presented as well. The novelty of the paper lies in pricing of\nvolatility swaps in closed form, and pricing of covariance and correlation\nswaps in a market with two risky assets.\n"
    },
    {
        "paper_id": 1205.5671,
        "authors": "Ivan Kitov, Oleg Kitov",
        "title": "Real GDP per capita since 1870",
        "comments": "30 pages, 18 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The growth rate of real GDP per capita in the biggest OECD countries is\nrepresented as a sum of two components - a steadily decreasing trend and\nfluctuations related to the change in some specific age population. The long\nterm trend in the growth rate is modelled by an inverse function of real GDP\nper capita with a constant numerator. This numerator is equivalent to a\nconstant annual increment of real GDP per capita. For the most advanced\neconomies, the GDP estimates between 1950 and 2007 have shown very weak and\nstatistically insignificant linear trends (both positive and negative) in the\nannual increment. The fluctuations around relevant mean increments are\ncharacterized by practically normal distribution. For many countries, there\nexist historical estimates of real GDP since 1870. These estimates extend the\ntime span of our analysis together with a few new estimates from 2008 to 2011.\nThere are severe structural breaks in the corresponding time series between\n1940 and 1950, with the slope of linear regression increasing by a factor of\n4.0 (Switzerland) to 22.1 (Spain). Therefore, the GDP estimates before 1940 and\nafter 1950 have been analysed separately. All findings of the original study\nare validated by the newly available data. The most important is that all\nslopes (except that for Australia after 1950) of the regression lines obtained\nfor the annual increments of real GDP per capita are small and statistically\ninsignificant, i.e. one cannot reject the null hypothesis of a zero slope and\nthus constant increment. Hence the growth in real GDP per capita is a linear\none since 1870 with a break in slope between 1940 and 1950.\n"
    },
    {
        "paper_id": 1205.5675,
        "authors": "Alessandro Spelta and Tanya Ara\\'ujo",
        "title": "Interlinkages and structural changes in cross-border liabilities: a\n  network approach",
        "comments": "24 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the international interbank market through a geometrical and a\ntopological analysis of empirical data. The geometrical analysis of the time\nseries of cross-country liabilities shows that the systematic information of\nthe interbank international market is contained in a space of small dimension,\nfrom which a topological characterization could be conveniently carried out.\nWeighted and complete networks of financial linkages across countries are\ndeveloped, for which continuous clustering, degree centrality and closeness\ncentrality are computed. The behavior of these topological coefficients reveals\nan important modification acting in the financial linkages in the period\n1997-2011. Here we show that, besides the generalized clustering increase,\nthere is a persistent increment in the degree of connectivity and in the\ncloseness centrality of some countries. These countries seem to correspond to\ncritical locations where tax policies might provide opportunities to shift\ndebts. Such critical locations highlight the role that specific countries play\nin the network structure and helps to situates the turbulent period that has\nbeen characterizing the global financial system since the Summer 2007 as the\ncounterpart of a larger structural change going on for a more than one decade.\n"
    },
    {
        "paper_id": 1205.582,
        "authors": "Frank W. K. Firk",
        "title": "A Multi-Level Lorentzian Analysis of the Basic Structures of the Daily\n  DJIA",
        "comments": "18 pages,11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A quantitative analysis of the basic components of the daily DJIA. The\nparameters of the underlying Lorentzian states are obtained by fitting the\ndata. Statistical properties of the states are discussed. This is a practical\ndevelopment of the general method introduced in arXiv:1203.6021.\n"
    },
    {
        "paper_id": 1205.5821,
        "authors": "Ian Wilkinson (The University of Sydney) and Louise Young (University\n  of Western Sydney)",
        "title": "Toward A Normative Theory of Normative Marketing Theory",
        "comments": "27 pages, 1 Figure",
        "journal-ref": "Marketing Theory 5 (4) 2005, 363-396",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show how different approaches to developing marketing strategies depending\non the type of environment a firm faces, where environments are distinguished\nin terms of their systems properties not their context. Particular emphasis is\ngiven to turbulent environments in which outcomes are not a priori predictable\nand are not traceable to individual firm actions and we show that, in these\nconditions, the relevant unit of competitive response and understanding is no\nlonger the individual firm but the network of relations comprising\ninterdependent, interacting firms. Networks of relations are complex adaptive\nsystems that are more 'intelligent' than the individual firms that comprise\nthem and are capable of comprehending and responding to more complex and\nturbulent environments. Yet they are co-produced by the patterns of actions and\ninteractions of the firms involved. The creation and accessing of such\ndistributed intelligence cannot be centrally directed, as this necessarily\nlimits it. Instead managers and firms are involved in a kind of participatory\nplanning and adaptation process through which the network self-organises and\nadapts. Drawing on research in systems theory, complexity, biology and\ncognitive science, extensions to the resource-based theory of the firm are\nproposed that include how resources are linked across relations and network in\na dynamic and evolutionary way. The concept of an extended firm and soft\nassembled strategies are introduced to describe the nature of the strategy\ndevelopment process. This results in a more theoretically grounded basis for\nunderstanding the nature and role of relationship and network strategies in\nmarketing and management. We finish by considering the research implications of\nour analysis and the role of agent based models as a means of sensitising and\ninforming management action.\n"
    },
    {
        "paper_id": 1205.5958,
        "authors": "Erhan Bayraktar and Virginia R. Young",
        "title": "Life Insurance Purchasing to Maximize Utility of Household Consumption",
        "comments": "Keywords: Life insurance, utility maximization, optimal consumption,\n  optimal investment, exponential utility",
        "journal-ref": "North American Actuarial Journal, 17 (2), 1-22, 2013",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We determine the optimal amount of life insurance for a household of two wage\nearners. We consider the simple case of exponential utility, thereby removing\nwealth as a factor in buying life insurance, while retaining the relationship\namong life insurance, income, and the probability of dying and thus losing that\nincome. For insurance purchased via a single premium or premium payable\ncontinuously, we explicitly determine the optimal death benefit. We show that\nif the premium is determined to target a specific probability of loss per\npolicy, then the rates of consumption are identical under single premium or\ncontinuously payable premium. Thus, not only is equivalence of consumption\nachieved for the households under the two premium schemes, it is also obtained\nfor the insurance company in the sense of equivalence of loss probabilities.\n"
    },
    {
        "paper_id": 1205.616,
        "authors": "Hao Xing",
        "title": "Stability of the exponential utility maximization problem with respect\n  to preferences",
        "comments": "Keywords: utility maximization, exponential utility, stability,\n  semimartingales, utility-based prices",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies stability of the exponential utility maximization when\nthere are small variations on agent's utility function. Two settings are\nconsidered. First, in a general semimartingale model where random endowments\nare present, a sequence of utilities defined on R converges to the exponential\nutility. Under a uniform condition on their marginal utilities, convergence of\nvalue functions, optimal payoffs and optimal investment strategies are\nobtained, their rate of convergence are also determined. Stability of\nutility-based pricing is studied as an application. Second, a sequence of\nutilities defined on R_+ converges to the exponential utility after shifting\nand scaling. Their associated optimal strategies, after appropriate scaling,\nconverge to the optimal strategy for the exponential hedging problem. This\ncomplements Theorem 3.2 in \\textit{M. Nutz, Probab. Theory Relat. Fields, 152,\n2012}, which establishes the convergence for a sequence of power utilities.\n"
    },
    {
        "paper_id": 1205.6193,
        "authors": "Traian A. Pirvu and Huayue Zhang",
        "title": "A Multi Period Equilibrium Pricing Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we propose an equilibrium pricing model in a dynamic\nmulti-period stochastic framework with uncertain income streams. In an\nincomplete market, there exist two traded risky assets (e.g. stock/commodity\nand weather derivative) and a non-traded underlying (e.g. temperature). The\nrisk preferences are of exponential (CARA) type with a stochastic coefficient\nof risk aversion. Both time consistent and time inconsistent trading strategies\nare considered. We obtain the equilibriums prices of a contingent claim written\non the risky asset and non-traded underlying. By running numerical experiments\nwe examine how the equilibriums prices vary in response to changes in model\nparameters.\n"
    },
    {
        "paper_id": 1205.6254,
        "authors": "Tomasz R. Bielecki, Igor Cialenco and Rodrigo Rodriguez",
        "title": "No-Arbitrage Pricing for Dividend-Paying Securities in Discrete-Time\n  Markets with Transaction Costs",
        "comments": "Forthcoming in Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove a version of First Fundamental Theorem of Asset Pricing under\ntransaction costs for discrete-time markets with dividend-paying securities.\nSpecifically, we show that the no-arbitrage condition under the efficient\nfriction assumption is equivalent to the existence of a risk-neutral measure.\nWe derive dual representations for the superhedging ask and subhedging bid\nprice processes of a derivative contract. Our results are illustrated with a\nvanilla credit default swap contract.\n"
    },
    {
        "paper_id": 1205.6542,
        "authors": "Tomasz R. Bielecki, Igor Cialenco and Ismail Iyigunler",
        "title": "Collateralized CVA Valuation with Rating Triggers and Credit Migrations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we discuss the issue of computation of the bilateral credit\nvaluation adjustment (CVA) under rating triggers, and in presence of\nratings-linked margin agreements. Specifically, we consider collateralized OTC\ncontracts, that are subject to rating triggers, between two parties -- an\ninvestor and a counterparty. Moreover, we model the margin process as a\nfunctional of the credit ratings of the counterparty and the investor. We\nemploy a Markovian approach for modeling of the rating transitions of the two\nparties to the contract. In this framework, we derive the representation for\nbilateral CVA. We also introduce a new component in the decomposition of the\ncounterparty risky price: namely the rating valuation adjustment (RVA) that\naccounts for the rating triggers. We give two examples of dynamic\ncollateralization schemes where the margin thresholds are linked to the credit\nratings of the parties. We account for the rehypothecation risk in the presence\nof independent amounts. Our results are illustrated via computation of various\ncounterparty risk adjustments for a CDS contract and for an IRS contract.\n"
    },
    {
        "paper_id": 1206.0026,
        "authors": "Danilo Delpini and Giacomo Bormetti",
        "title": "Stochastic Volatility with Heterogeneous Time Scales",
        "comments": "Second figure modified, some typos corrected",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Agents' heterogeneity is recognized as a driver mechanism for the persistence\nof financial volatility. We focus on the multiplicity of investment strategies'\nhorizons, we embed this concept in a continuous time stochastic volatility\nframework and prove that a parsimonious, two-scale version effectively captures\nthe long memory as measured from the real data. Since estimating parameters in\na stochastic volatility model is challenging, we introduce a robust methodology\nbased on the Generalized Method of Moments supported by a heuristic selection\nof the orthogonal conditions. In addition to the volatility clustering, the\nestimated model also captures other relevant stylized facts, emerging as a\nminimal but realistic and complete framework for modelling financial time\nseries.\n"
    },
    {
        "paper_id": 1206.0153,
        "authors": "Y. Iron and Y. Kifer",
        "title": "Error estimates for binomial approximations of game put options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct algorithms via binomial approximations for computation of prices\nof game put options and obtain estimates of approximation errors.\n"
    },
    {
        "paper_id": 1206.0243,
        "authors": "Christoph Czichowsky, Martin Schweizer",
        "title": "Cone-Constrained Continuous-Time Markowitz Problems",
        "comments": "To appear in Annals of Applied Probability",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Markowitz problem consists of finding in a financial market a\nself-financing trading strategy whose final wealth has maximal mean and minimal\nvariance. We study this in continuous time in a general semimartingale model\nand under cone constraints: Trading strategies must take values in a (possibly\nrandom and time-dependent) closed cone. We first prove existence of a solution\nfor convex constraints by showing that the space of constrained terminal gains,\nwhich is a space of stochastic integrals, is closed in L^2. Then we use\nstochastic control methods to describe the local structure of the optimal\nstrategy, as follows. The value process of a naturally associated constrained\nlinear-quadratic optimal control problem is decomposed into a sum with two\nopportunity processes L^{\\pm} appearing as coefficients. The martingale\noptimality principle translates into a drift condition for the semimartingale\ncharacteristics of L^{\\pm} or equivalently into a coupled system of backward\nstochastic differential equations for L^{\\pm}. We show how this can be used to\nboth characterise and construct optimal strategies. Our results explain and\ngeneralise all the results available in the literature so far. Moreover, we\neven obtain new sharp results in the unconstrained case.\n"
    },
    {
        "paper_id": 1206.0384,
        "authors": "Michail Anthropelos",
        "title": "The Effect of Market Power on Risk-Sharing",
        "comments": "46 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper studies an oligopolistic equilibrium model of financial agents who\naim to share their random endowments. The risk-sharing securities and their\nprices are endogenously determined as the outcome of a strategic game played\namong all the participating agents. In the complete-market setting, each\nagent's set of strategic choices consists of the security payoffs and the\npricing kernel that are consistent with the optimal-sharing rules; while in the\nincomplete setting, agents respond via demand functions on a vector of given\ntradeable securities. It is shown that at the (Nash) risk-sharing equilibrium,\nthe sharing securities are suboptimal, since agents submit for sharing\ndifferent risk exposures than their true endowments. On the other hand, the\nNash equilibrium prices stay unaffected by the game only in the special case of\nagents with the same risk aversion. In addition, agents with sufficiently lower\nrisk aversion act as predatory traders, since they absorb utility surplus from\nthe high risk averse agents and reduce the efficiency of sharing. The main\nresults of the paper also hold under the generalized models that allow the\npresence of noise traders and heterogeneity in agents' beliefs.\n"
    },
    {
        "paper_id": 1206.045,
        "authors": "Ivan Kitov",
        "title": "Why price inflation in developed countries is systematically\n  underestimated",
        "comments": "12 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There is an extensive historical dataset on real GDP per capita prepared by\nAngus Maddison. This dataset covers the period since 1870 with continuous\nannual estimates in developed countries. All time series for individual\neconomies have a clear structural break between 1940 and 1950. The behavior\nbefore 1940 and after 1950 can be accurately (R2 from 0.7 to 0.99) approximated\nby linear time trends. The corresponding slopes of regressions lines before and\nafter the break differ by a factor of 4 (Switzerland) to 19 (Spain). We have\nextrapolated the early trends into the second interval and obtained much lower\nestimates of real GDP per capita in 2011: from 2.4 (Switzerland) to 5.0 (Japan)\ntimes smaller than the current levels. When the current linear trends are\nextrapolated into the past, they intercept the zero line between 1908\n(Switzerland) and 1944 (Japan). There is likely an internal conflict between\nthe estimating procedures before 1940 and after 1950. A reasonable explanation\nof the discrepancy is that the GDP deflator in developed countries has been\nhighly underestimated since 1950. In the USA, the GDP deflator is\nunderestimated by a factor of 1.4. This is exactly the ratio of the interest\nrate controlled by the Federal Reserve and the rate of inflation. Hence, the\nFederal Reserve actually retains its interest rate at the level of true price\ninflation when corrected for the bias in the GDP deflator.\n"
    },
    {
        "paper_id": 1206.0478,
        "authors": "Walter Farkas, Pablo Koch-Medina, and Cosimo Munari",
        "title": "Beyond cash-additive risk measures: when changing the num\\'{e}raire\n  fails",
        "comments": null,
        "journal-ref": "Finance and Stochastics, 18(1), 145-173, 2014",
        "doi": "10.1007/s00780-013-0220-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss risk measures representing the minimum amount of capital a\nfinancial institution needs to raise and invest in a pre-specified eligible\nasset to ensure it is adequately capitalized. Most of the literature has\nfocused on cash-additive risk measures, for which the eligible asset is a\nrisk-free bond, on the grounds that the general case can be reduced to the\ncash-additive case by a change of numeraire. However, discounting does not work\nin all financially relevant situations, typically when the eligible asset is a\ndefaultable bond. In this paper we fill this gap allowing for general eligible\nassets. We provide a variety of finiteness and continuity results for the\ncorresponding risk measures and apply them to risk measures based on\nValue-at-Risk and Tail Value-at-Risk on $L^p$ spaces, as well as to shortfall\nrisk measures on Orlicz spaces. We pay special attention to the property of\ncash subadditivity, which has been recently proposed as an alternative to cash\nadditivity to deal with defaultable bonds. For important examples, we provide\ncharacterizations of cash subadditivity and show that, when the eligible asset\nis a defaultable bond, cash subadditivity is the exception rather than the\nrule. Finally, we consider the situation where the eligible asset is not\nliquidly traded and the pricing rule is no longer linear. We establish when the\nresulting risk measures are quasiconvex and show that cash subadditivity is\nonly compatible with continuous pricing rules.\n"
    },
    {
        "paper_id": 1206.0482,
        "authors": "Martin Klimmek",
        "title": "The Wronskian parameterizes the class of diffusions with a given\n  distribution at a random time",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a complete characterization of the class of one-dimensional\ntime-homogeneous diffusions consistent with a given law at an exponentially\ndistributed time using classical results in diffusion theory. To illustrate we\ncharacterize the class of diffusions with the same distribution as Brownian\nmotion at an exponentially distributed time.\n"
    },
    {
        "paper_id": 1206.0496,
        "authors": "Andrey Korotayev (Russian Academy of Sciences, Moscow) and Artemy\n  Malkov (Institute of Economics of the Russian Academy of Sciences)",
        "title": "A Compact Mathematical Model of the World System Economic and\n  Demographic Growth, 1 CE - 1973 CE",
        "comments": "44 pages, 25 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose an extremely simple mathematical model that is shown to be able to\naccount for more than 99 per cent of all the variation in economic and\ndemographic macrodynamics of the world for almost two millennia of its history.\nThis appears to suggest a novel approach to the formation of the general theory\nof social macroevolution.\n"
    },
    {
        "paper_id": 1206.0682,
        "authors": "Enzo Busseti and Fabrizio Lillo",
        "title": "Calibration of optimal execution of financial transactions in the\n  presence of transient market impact",
        "comments": "31 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1088/1742-5468/2012/09/P09010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Trading large volumes of a financial asset in order driven markets requires\nthe use of algorithmic execution dividing the volume in many transactions in\norder to minimize costs due to market impact. A proper design of an optimal\nexecution strategy strongly depends on a careful modeling of market impact,\ni.e. how the price reacts to trades. In this paper we consider a recently\nintroduced market impact model (Bouchaud et al., 2004), which has the property\nof describing both the volume and the temporal dependence of price change due\nto trading. We show how this model can be used to describe price impact also in\naggregated trade time or in real time. We then solve analytically and calibrate\nwith real data the optimal execution problem both for risk neutral and for risk\naverse investors and we derive an efficient frontier of optimal execution. When\nwe include spread costs the problem must be solved numerically and we show that\nthe introduction of such costs regularizes the solution.\n"
    },
    {
        "paper_id": 1206.0715,
        "authors": "Daniel Hern\\'andez-Hern\\'andez and Leonel P\\'erez-Hern\\'andez",
        "title": "Robust utility maximization for L\\'evy processes: Penalization and\n  solvability",
        "comments": "24 pages. arXiv admin note: substantial text overlap with\n  arXiv:1205.3827",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper the robust utility maximization problem for a market model\nbased on L\\'evy processes is analyzed. The interplay between the form of the\nutility function and the penalization function required to have a well posed\nproblem is studied, and for a large class of utility functions it is proved\nthat the dual problem is solvable as well as the existence of optimal\nsolutions. The class of equivalent local martingale measures is characterized\nin terms of the parameters of the price process, and the connection with convex\nrisk measures is also presented.\n"
    },
    {
        "paper_id": 1206.0831,
        "authors": "Panagiota Daskalopoulos and Paul M. N. Feehan",
        "title": "C^{1,1} regularity for degenerate elliptic obstacle problems",
        "comments": "31 pages, 8 figures. To appear in the Journal of Differential\n  Equations",
        "journal-ref": "Journal of Differential Equations 260 (2016), 5043-5074",
        "doi": "10.1016/j.jde.2015.11.037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Heston stochastic volatility process is a degenerate diffusion process\nwhere the degeneracy in the diffusion coefficient is proportional to the square\nroot of the distance to the boundary of the half-plane. The generator of this\nprocess with killing, called the elliptic Heston operator, is a second-order,\ndegenerate-elliptic partial differential operator, where the degeneracy in the\noperator symbol is proportional to the distance to the boundary of the\nhalf-plane. In mathematical finance, solutions to the obstacle problem for the\nelliptic Heston operator correspond to value functions for perpetual\nAmerican-style options on the underlying asset. With the aid of weighted\nSobolev spaces and weighted Holder spaces, we establish the optimal $C^{1,1}$\nregularity (up to the boundary of the half-plane) for solutions to obstacle\nproblems for the elliptic Heston operator when the obstacle functions are\nsufficiently smooth.\n"
    },
    {
        "paper_id": 1206.1007,
        "authors": "Dariusz Grech, Zygmunt Mazur",
        "title": "On the scaling ranges of detrended fluctuation analysis for long-memory\n  correlated short series of data",
        "comments": "27 pages, 17 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.01.049",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We examine the scaling regime for the detrended fluctuation analysis (DFA) -\nthe most popular method used to detect the presence of long memory in data and\nthe fractal structure of time series. First, the scaling range for DFA is\nstudied for uncorrelated data as a function of length $L$ of time series and\nregression line coefficient $R^2$ at various confidence levels. Next, an\nanalysis of artificial short series with long memory is performed. In both\ncases the scaling range $\\lambda$ is found to change linearly -- both with $L$\nand $R^2$. We show how this dependence can be generalized to a simple unified\nmodel describing the relation $\\lambda=\\lambda(L, R^2, H)$ where $H$ ($1/2\\leq\nH \\leq 1$) stands for the Hurst exponent of long range autocorrelated data. Our\nfindings should be useful in all applications of DFA technique, particularly\nfor instantaneous (local) DFA where enormous number of short time series has to\nbe examined at once, without possibility for preliminary check of the scaling\nrange of each series separately.\n"
    },
    {
        "paper_id": 1206.1272,
        "authors": "J. L. Subias",
        "title": "Negative Kelvin temperatures in stock markets",
        "comments": "15 pages, 8 figures, revised and substantially extended This paper\n  has been withdrawn by the author due to revision of Appendix A",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A spin model relating physical to financial variables is presented. This work\nis the first to introduce the concept of negative absolute temperature into\nstock market dynamics by establishing a rigorous formal analogy between\nphysical and financial variables. Based on this model, an algorithm evaluating\nnegative temperatures was applied to an analysis of New York Stock Exchange\nquotations from November 2002 up to the present. We found that the magnitude of\nnegative temperature peaks correlates with subsequent index movement. Moreover,\na certain autocorrelation function decays as temperature increases. An effort\nwas directed to the search for patterns similar to known physical processes,\nsince the model hypotheses pointed to the possibility of such a similarity. A\nnumber of cases resembling known processes in phenomenological thermodynamics\nwere found, namely, population inversion and the magneto-caloric effect.\n"
    },
    {
        "paper_id": 1206.138,
        "authors": "A. Gabrielsen, P. Zagaglia, A. Kirchner, Z. Liu",
        "title": "Forecasting Value-at-Risk with Time-Varying Variance, Skewness and\n  Kurtosis in an Exponential Weighted Moving Average Framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper provides an insight to the time-varying dynamics of the shape of\nthe distribution of financial return series by proposing an exponential\nweighted moving average model that jointly estimates volatility, skewness and\nkurtosis over time using a modified form of the Gram-Charlier density in which\nskewness and kurtosis appear directly in the functional form of this density.\nIn this setting VaR can be described as a function of the time-varying higher\nmoments by applying the Cornish-Fisher expansion series of the first four\nmoments. An evaluation of the predictive performance of the proposed model in\nthe estimation of 1-day and 10-day VaR forecasts is performed in comparison\nwith the historical simulation, filtered historical simulation and GARCH model.\nThe adequacy of the VaR forecasts is evaluated under the unconditional,\nindependence and conditional likelihood ratio tests as well as Basel II\nregulatory tests. The results presented have significant implications for risk\nmanagement, trading and hedging activities as well as in the pricing of equity\nderivatives.\n"
    },
    {
        "paper_id": 1206.14,
        "authors": "K. Milanov, O. Kounchev",
        "title": "Binomial Tree Model for Convertible Bond Pricing within Equity to Credit\n  Risk Framework",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper we fill an essential gap in the Convertible Bonds\npricing world by deriving a Binary Tree based model for valuation subject to\ncredit risk. This model belongs to the framework known as Equity to Credit\nRisk. We show that this model converges in continuous time to the model\ndeveloped by Ayache, Forsyth and Vetzal [2003]. To this end, both forms of\ncredit risk modeling, the so-called reduced (constant intensity of default\nmodel for the underlying) and the so-called synthesis (variable intensity of\ndefault model for the underlying) are considered. We highlight and quantify\ncertain issues that arise, as transition probability analysis and threshold\nvalues of model inputs (tree step, underlying stock price, etc.). This study\nmay be considered as an alternative way to develop the price dynamics model of\nAyache et al. [2003] for convertible bonds in credit risk environment.\n"
    },
    {
        "paper_id": 1206.1504,
        "authors": "Michel Fliess (LIX), C\\'edric Join (INRIA Saclay - Ile de France,\n  CRAN)",
        "title": "Preliminary remarks on option pricing and dynamic hedging",
        "comments": "1st International Conference on Systems and Computer Science,\n  Villeneuve d'Ascq : France (2012)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An elementary arbitrage principle and the existence of trends in financial\ntime series, which is based on a theorem published in 1995 by P. Cartier and Y.\nPerrin, lead to a new understanding of option pricing and dynamic hedging.\nIntricate problems related to violent behaviors of the underlying, like the\nexistence of jumps, become then quite straightforward by incorporating them\ninto the trends. Several convincing computer experiments are reported.\n"
    },
    {
        "paper_id": 1206.2022,
        "authors": "Viktor O. Ledenyov and Dimitri O. Ledenyov",
        "title": "Shaping the international financial system in century of globalization",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We educe a perspective on how best to regulate the bank of tomorrow in frames\nof debate launched by the International Centre for Financial Regulation and\nFinancial Times. Our goal is to create a conceptual framework for policymakers\nand regulators to shape the international financial system in century of\nglobalization using the 1888 FT's motto: \"Without fear and without favour.\" Our\nprospect employs an analytical approach, which focuses on the origins and\nevolution of banking system, its transformation over the recent decades,\nsubsequent encountering the limits to growth and redefinition of new strategic\nboundaries of emerging financial industry. We identify the main reasons and\nlimitations, which led to the global financial crisis. We propose the new\nresearch agendas with the aim to understand the situation in finances, evaluate\nthe created systemic damages, and find the possible ways to resolve the\nexisting problems through introduction of new banking regulation. We think that\nthe global economic and financial systems are highly nonlinear systems. In our\nopinion, the frequency, phase and amplitude modulation during the mixing of\nwaves, which characterize the Kitchin, Juglar, Kuznets, Kondratiev economic\ncycles, may result in origination of strong nonlinear dynamics in financial\nsystem, accompanied by chaos- induced phenomena. These nonlinear effects have\nto be taken to the account, when adding the liquidity to the financial system\nin small quantas in series over time period during the Quantitative Easing\npolicy execution by central banks. We propose the Random Tax to be selectively\nimposed on the profits, obtained by market agents during high-risk high-profit\nspeculative transactions. We expect that the Random Tax will stabilize the\nfinancial system in conditions of free market capitalism.\n"
    },
    {
        "paper_id": 1206.2112,
        "authors": "Lorenzo Torricelli",
        "title": "Pricing joint claims on an asset and its realized variance under\n  stochastic volatility models",
        "comments": "13 pages, 5 Tables. Part of the material was presented at Santander\n  monthly seminar in quantitative finance, London, January 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a stochastic volatility framework, we find a general pricing equation for\nthe class of payoffs depending on the terminal value of a market asset and its\nfinal quadratic variation. This allows a pricing tool for European-style claims\npaying off at maturity a joint function of the underlying and its realised\nvolatility/variance. We study the solution under different stochastic\nvolatility models, give a formula for the computation of the Delta and Gamma of\nthese claims, and introduce some new interesting payoffs that can be priced\nthrough this equation. Numerical results are given and compared to those from\nplain vanilla derivatives.\n"
    },
    {
        "paper_id": 1206.2153,
        "authors": "R\\'emy Chicheportiche and Jean-Philippe Bouchaud",
        "title": "The fine-structure of volatility feedback I: multi-scale\n  self-reflexivity",
        "comments": null,
        "journal-ref": "Physica A 410 (2014) 174-195",
        "doi": "10.1016/j.physa.2014.05.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We attempt to unveil the fine structure of volatility feedback effects in the\ncontext of general quadratic autoregressive (QARCH) models, which assume that\ntoday's volatility can be expressed as a general quadratic form of the past\ndaily returns. The standard ARCH or GARCH framework is recovered when the\nquadratic kernel is diagonal. The calibration of these models on US stock\nreturns reveals several unexpected features. The off-diagonal (non ARCH)\ncoefficients of the quadratic kernel are found to be highly significant both\nIn-Sample and Out-of-Sample, but all these coefficients turn out to be one\norder of magnitude smaller than the diagonal elements. This confirms that daily\nreturns play a special role in the volatility feedback mechanism, as postulated\nby ARCH models. The feedback kernel exhibits a surprisingly complex structure,\nincompatible with models proposed so far in the literature. Its spectral\nproperties suggest the existence of volatility-neutral patterns of past\nreturns. The diagonal part of the quadratic kernel is found to decay as a\npower-law of the lag, in line with the long-memory of volatility. Finally,\nQARCH models suggest some violations of Time Reversal Symmetry in financial\ntime series, which are indeed observed empirically, although of much smaller\namplitude than predicted. We speculate that a faithful volatility model should\ninclude both ARCH feedback effects and a stochastic component.\n"
    },
    {
        "paper_id": 1206.2305,
        "authors": "Constantinos Kardaras, Jan Obloj, Eckhard Platen",
        "title": "The numeraire property and long-term growth optimality for\n  drawdown-constrained investments",
        "comments": "32 pages - second, somewhat revised, version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the portfolio choice problem for a long-run investor in a general\ncontinuous semimartingale model. We suggest to use path-wise growth optimality\nas the decision criterion and encode preferences through restrictions on the\nclass of admissible wealth processes. Specifically, the investor is only\ninterested in strategies which satisfy a given linear drawdown constraint. The\npaper introduces the numeraire property through the notion of expected relative\nreturn and shows that drawdown-constrained strategies with the numeraire\nproperty exist and are unique, but may depend on the financial planning\nhorizon. However, when sampled at the times of its maximum and asymptotically\nas the time-horizon becomes distant, the drawdown-constrained numeraire\nportfolio is given explicitly through a model-independent transformation of the\nunconstrained numeraire portfolio. Further, it is established that the\nasymptotically growth-optimal strategy is obtained as limit of numeraire\nstrategies on finite horizons.\n"
    },
    {
        "paper_id": 1206.2333,
        "authors": "Vic Norton",
        "title": "An algorithm for the orthogonal decomposition of financial return data",
        "comments": "arXiv.org references added to rtndecomp.m script",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an algorithm for the decomposition of periodic financial return\ndata into orthogonal factors of expected return and \"systemic\", \"productive\",\nand \"nonproductive\" risk. Generally, when the number of funds does not exceed\nthe number of periods, the expected return of a portfolio is an affine function\nof its productive risk.\n"
    },
    {
        "paper_id": 1206.2494,
        "authors": "Hans G. Danielmeyer, Thomas Martinetz",
        "title": "A physical theory of economic growth",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Economic growth is unpredictable unless demand is quantified. We solve this\nproblem by introducing the demand for unpaid spare time and a user quantity\nnamed human capacity. It organizes and amplifies spare time required for\nenjoying affluence like physical capital, the technical infrastructure for\nproduction, organizes and amplifies working time for supply. The sum of annual\nspare and working time is fixed by the universal flow of time. This yields the\nfirst macroeconomic equilibrium condition. Both storable quantities form\nstabilizing feedback loops. They are driven with the general and technical\nknowledge embodied with parts of the supply by education and construction.\nLinear amplification yields S-functions as only analytic solutions.\nDestructible physical capital controls medium-term recoveries from disaster.\nIndestructible human capacity controls the collective long-term industrial\nevolution. It is immune even to world wars and runs from 1800 to date parallel\nto the unisex life expectancy in the pioneering nations. This is the first\nquantitative information on long-term demand. The theory is self-consistent. It\nreproduces all peaceful data from 1800 to date without adjustable parameter. It\nhas full forecasting power since the decisive parameters are constants of the\nhuman species. They predict an asymptotic maximum for the economic level per\ncapita. Long-term economic growth appears as a part of natural science.\n"
    },
    {
        "paper_id": 1206.2662,
        "authors": "Godfrey Charles-Cadogan",
        "title": "Alpha Representation For Active Portfolio Management and High Frequency\n  Trading In Seemingly Efficient Markets",
        "comments": "15 pages, 0 figures",
        "journal-ref": "In Proceedings of Joint Statistical Meeting (JSM), Business and\n  Economic Statistics Section, Alexandria, VA: American Statistical\n  Association. 673-687, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a trade strategy representation theorem for performance\nmeasurement and portable alpha in high frequency trading, by embedding a robust\ntrading algorithm that describe portfolio manager market timing behavior, in a\ncanonical multifactor asset pricing model. First, we present a spectral test\nfor market timing based on behavioral transformation of the hedge factors\ndesign matrix. Second, we find that the typical trade strategy process is a\nlocal martingale with a background driving Brownian bridge that mimics\nportfolio manager price reversal strategies. Third, we show that equilibrium\nasset pricing models like the CAPM exists on a set with P-measure zero. So that\nexcess returns, i.e. positive alpha, relative to a benchmark index is robust to\nno arbitrage pricing in turbulent capital markets. Fourth, the path properties\nof alpha are such that it is positive between suitably chosen stopping times\nfor trading. Fifth, we demonstrate how, and why, econometric tests of portfolio\nperformance tend to under report positive alpha.\n"
    },
    {
        "paper_id": 1206.2665,
        "authors": "Godfrey Charles-Cadogan",
        "title": "Representation Theory for Risk On Markowitz-Tversky-Kahneman Topology",
        "comments": "27 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a representation theory for risk operations on locally compact\ngroups in a partition of unity on a topological manifold for\nMarkowitz-Tversky-Kahneman (MTK) reference points. We identify (1) risk torsion\ninduced by the flip rate for risk averse and risk seeking behaviour, and (2) a\nstructure constant or coupling of that torsion in the paracompact manifold. The\nrisk torsion operator extends by continuity to prudence and maxmin expected\nutility (MEU) operators, as well as other behavioural operators introduced by\nthe Italian school. In our erstwhile chaotic dynamical system, induced by\nbehavioural rotations of probability domains, the loss aversion index is an\nunobserved gauge transformation; and reference points are hyperbolic on the\nutility hypersurface characterized by the special unitary group SU(n). We\nidentify conditions for existence of harmonic utility functions on paracompact\nMTK manifolds induced by transformation groups. And we use those mathematical\nobjects to estimate: (1) loss aversion index from infinitesimal tangent\nvectors; and (2) value function from a classic Dirichlet problem for first exit\ntime of Brownian motion from regular points on the boundary of MTK base\ntopology.\n"
    },
    {
        "paper_id": 1206.2778,
        "authors": "Viktor O. Ledenyov and Dimitri O. Ledenyov",
        "title": "Designing the new architecture of international financial system in era\n  of great changes by globalization",
        "comments": "18 Pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a broad agenda for meaningful banking regulation reform aiming the\ncreation of evolutive competitive environment to maximize the effectiveness of\ninternational financial system through the introduction of fair competition\nprocess among the banks in free market capitalism. We assume that the\ninternational financial system may evolve or decline within the evolutive\ncompetitive environment depending on both the environmental regulation policies\nas well as the competition between the banks. We present the commonly known\ndefinition of competition and apply the conceptual collateral thinking to\nidentify the source of competitive strengths of financial institutions in free\nmarket capitalism. We explore how the banks conduct a search for competitive\nstrategies. We show that the root cause of crisis in finances is hidden in the\nvery wrong regulation policies and ideas behind these policies, which failed to\ncreate the evolutive competitive environment for effective, profitable,\nresponsible and sustainable bank operation within existing international\nfinancial system. We review a number of initiatives on meaningful banking\nregulation reform proposed by central bankers from the G20 nations. We propose\nto introduce the Random Tax and the Quantum Tax. We argue that the introduction\nof the Random Tax and the Quantum Tax may compensate for the negative effects\ncommonly associated with the existing banking regulation limitations imposed on\nthe international financial system. We believe that the Random Tax and the\nQuantum Tax will improve the evolutive competitive environment and make it\npossible for the management teams at financial institutions to search for and\nto execute the winning virtuous business strategies toward the effective,\nprofitable, responsible and sustainable banks operation.\n"
    },
    {
        "paper_id": 1206.2934,
        "authors": "Yuri Imamura, Yuta Ishigaki, Takuya Kawagoe and Toshiki Okumura",
        "title": "A Numerical Scheme Based on Semi-Static Hedging Strategy",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper, we introduce a numerical scheme for the price of a\nbarrier option when the price of the underlying follows a diffusion process.\nThe numerical scheme is based on an extension of a static hedging formula of\nbarrier options. For getting the static hedging formula, the underlying process\nneeds to have a symmetry. We introduce a way to \"symmetrize\" a given diffusion\nprocess. Then the pricing of a barrier option is reduced to that of plain\noptions under the symmetrized process. To show how our symmetrization scheme\nworks, we will present some numerical results applying (path-independent)\nEuler-Maruyama approximation to our scheme, comparing them with the\npath-dependent Euler-Maruyama scheme when the model is of the Black-Scholes,\nCEV, Heston, and $ (\\lambda) $-SABR, respectively. The results show the\neffectiveness of our scheme.\n"
    },
    {
        "paper_id": 1206.3104,
        "authors": "Alexander Lipton and Ioana Savescu",
        "title": "A structural approach to pricing credit default swaps with credit and\n  debt value adjustments",
        "comments": "17 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A multi-dimensional extension of the structural default model with firms'\nvalues driven by diffusion processes with Marshall-Olkin-inspired correlation\nstructure is presented. Semi-analytical methods for solving the forward\ncalibration problem and backward pricing problem in three dimensions are\ndeveloped. The model is used to analyze bilateral counterparty risk for credit\ndefault swaps and evaluate the corresponding credit and debt value adjustments.\n"
    },
    {
        "paper_id": 1206.322,
        "authors": "Constantinos Kardaras",
        "title": "Valuation and parities for exchange options",
        "comments": "19 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Valuation and parity formulas for both European-style and American-style\nexchange options are presented in a general financial model allowing for jumps,\npossibility of default and \"bubbles\" in asset prices. The formulas are given\nvia expectations of auxiliary probabilities using the change-of-numeraire\ntechnique. Extensive discussion is provided regarding the way that folklore\nresults such as Merton's no-early-exercise theorem and traditional parity\nrelations have to be altered in this more versatile framework.\n"
    },
    {
        "paper_id": 1206.3384,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "International trade of flowers. Tendencies and policies",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There are few papers about the international trade of flowers, so it is\nbelieved that this paper, with this topic, could be an important contribution\nto the international scientific community. It is intended to analyze if the\ninternational trade flowers tendencies and policies are adapted to the actual\nworld global context. For that it was used data about the import and export of\nflowers, in different forms, between Portugal and the world. This is an\napproach to understand the international trade flowers tendencies and policies.\nTo better understand the data analyzed it is made several estimations based in\nthe absolute convergence theory and an analyze of the data volatility. As main\nconclusions, there is a tendency to the countries trade the flowers between the\nneighbors and is needed a more coherent policy for the international trade of\nflowers.\n"
    },
    {
        "paper_id": 1206.3385,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "International trade of fruits between Portugal and the world",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For Portugal there are few or none works about the international trade of\nfruits between Portugal and the other countries. In this work it aims to\nanalyze the more recent data for the Portuguese international trade of fruits.\nThey were used data for the years from 2006 to 2010, available by the INE\n(Statistics Portugal), gently given by the AICEP (Trade & Investment Agency).\nTo complement this data analysis they were made some estimations with several\neconometrics method and based in the neoclassical theory, with the absolute\nconvergence model. It was concluded that the biggest relationship, in the\ninternational trade of fruits, is with the European countries and there are not\nstatistical regularity in the estimations and the data are not stationary.\n"
    },
    {
        "paper_id": 1206.3387,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Import and export of horticultural products in Portugal",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With this work it is analyzed the import and export of horticultural products\nbetween Portugal and the other world countries. It is used data about\nPortuguese international trade of vegetables from 2006 to 2010. The data were\nobtained from the INE (Statistics Portugal), gently given by the AICEP (Trade &\nInvestment Agency). It is did some estimations taking into account the models\nfrom the convergence theory, with panel data and using methods by fixed\neffects, random effects and dynamic effects, for the Portuguese import and\nexport of vegetables, separately. It is found convergence in all estimations.\nThe volatility was also tested. All the tests show no stationary of the data.\nSo, in statically means the data show weak regularity. In this way all the\nconclusion, must be did very carefully. This lack of regularity is a result of\nlack of a national coherent policy for the sector.\n"
    },
    {
        "paper_id": 1206.339,
        "authors": "Karthyek R. A. Murthy, Sandeep Juneja, Jose Blanchet",
        "title": "State-independent Importance Sampling for Random Walks with Regularly\n  Varying Increments",
        "comments": "55 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop importance sampling based efficient simulation techniques for\nthree commonly encountered rare event probabilities associated with random\nwalks having i.i.d. regularly varying increments; namely, 1) the large\ndeviation probabilities, 2) the level crossing probabilities, and 3) the level\ncrossing probabilities within a regenerative cycle. Exponential twisting based\nstate-independent methods, which are effective in efficiently estimating these\nprobabilities for light-tailed increments are not applicable when the\nincrements are heavy-tailed. To address the latter case, more complex and\nelegant state-dependent efficient simulation algorithms have been developed in\nthe literature over the last few years. We propose that by suitably decomposing\nthese rare event probabilities into a dominant and further residual components,\nsimpler state-independent importance sampling algorithms can be devised for\neach component resulting in composite unbiased estimators with desirable\nefficiency properties. When the increments have infinite variance, there is an\nadded complexity in estimating the level crossing probabilities as even the\nwell known zero-variance measures have an infinite expected termination time.\nWe adapt our algorithms so that this expectation is finite while the estimators\nremain strongly efficient. Numerically, the proposed estimators perform at\nleast as well, and sometimes substantially better than the existing\nstate-dependent estimators in the literature.\n"
    },
    {
        "paper_id": 1206.442,
        "authors": "Thomas Bury",
        "title": "Statistical pairwise interaction model of stock market",
        "comments": "11 pages, 8 figures",
        "journal-ref": "Eur. Phys. J. B (2013) 86: 89",
        "doi": "10.1140/epjb/e2013-30598-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets are a classical example of complex systems as they comprise\nmany interacting stocks. As such, we can obtain a surprisingly good description\nof their structure by making the rough simplification of binary daily returns.\nSpin glass models have been applied and gave some valuable results but at the\nprice of restrictive assumptions on the market dynamics or others are\nagent-based models with rules designed in order to recover some empirical\nbehaviours. Here we show that the pairwise model is actually a statistically\nconsistent model with observed first and second moments of the stocks\norientation without making such restrictive assumptions. This is done with an\napproach based only on empirical data of price returns. Our data analysis of\nsix major indices suggests that the actual interaction structure may be thought\nas an Ising model on a complex network with interaction strengths scaling as\nthe inverse of the system size. This has potentially important implications\nsince many properties of such a model are already known and some techniques of\nthe spin glass theory can be straightforwardly applied. Typical behaviours, as\nmultiple equilibria or metastable states, different characteristic time scales,\nspatial patterns, order-disorder, could find an explanation in this picture.\n"
    },
    {
        "paper_id": 1206.4506,
        "authors": "Yuri Kifer",
        "title": "Hedging of game options in discrete markets with transaction costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct algorithms for computation of prices and superhedging strategies\nfor game options in general discrete markets both from the seller and the buyer\npoints of view.\n"
    },
    {
        "paper_id": 1206.4562,
        "authors": "G. Charles-Cadogan",
        "title": "Active Portfolio Management, Positive Jensen-Jarrow Alpha, and Zero Sets\n  of CAPM",
        "comments": "22 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present conditions under which positive alpha exists in the realm of\nactive portfolio management- in contrast to the controversial result in Jarrow\n(2010, pg. 20) which implicates delegated portfolio management by surmising\nthat positive alphas are illusionary. Specifically, we show that the critical\nassumption used in Jarrow (2010, pg. 20), to derive the illusionary alpha\nresult, is based on a zero set for CAPM with Lebesgue measure zero. So\nconclusions based on that assumption may well have probability measure zero of\noccurrence as well. Technically, the existence of [Tanaka] local time on a zero\nset for CAPM implies existence of positive alphas. In fact, we show that\npositive alpha exists under the same scenarios of \"perpetual event swap\" and\n\"market systemic event\" Jarrow (2010) used to formulate the illusionary\npositive alpha result. First, we prove that as long as asset price volatility\nis greater than zero, systemic events like market crash will occur in finite\ntime almost surely. Thus creating an opportunity to hedge against that event.\nSecond, we find that Jarrow's \"false positive alpha\" variable constitutes\nportfolio manager reward for trading strategy. For instance, we show that\npositive alpha exists if portfolio managers develop hedging strategies based on\neither (1) an exotic [barrier] option on the underlying asset - with barrier\nhitting time motivated by the \"market systemic\" event, or (2) a swaption\nstrategy for the implied interest rate risk inherent in Jarrow's triumvirate of\nriskless rate of return, factor sensitivity exposure, and constant risk premium\nfor a perpetual event swap.\n"
    },
    {
        "paper_id": 1206.4626,
        "authors": "Bin Li (NTU), Steven C.H. Hoi (NTU)",
        "title": "On-Line Portfolio Selection with Moving Average Reversion",
        "comments": "ICML2012",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  On-line portfolio selection has attracted increasing interests in machine\nlearning and AI communities recently. Empirical evidences show that stock's\nhigh and low prices are temporary and stock price relatives are likely to\nfollow the mean reversion phenomenon. While the existing mean reversion\nstrategies are shown to achieve good empirical performance on many real\ndatasets, they often make the single-period mean reversion assumption, which is\nnot always satisfied in some real datasets, leading to poor performance when\nthe assumption does not hold. To overcome the limitation, this article proposes\na multiple-period mean reversion, or so-called Moving Average Reversion (MAR),\nand a new on-line portfolio selection strategy named \"On-Line Moving Average\nReversion\" (OLMAR), which exploits MAR by applying powerful online learning\ntechniques. From our empirical results, we found that OLMAR can overcome the\ndrawback of existing mean reversion algorithms and achieve significantly better\nresults, especially on the datasets where the existing mean reversion\nalgorithms failed. In addition to superior trading performance, OLMAR also runs\nextremely fast, further supporting its practical applicability to a wide range\nof applications.\n"
    },
    {
        "paper_id": 1206.4766,
        "authors": "Takeaki Kariya",
        "title": "A CB (corporate bond) pricing probabilities and recovery rates model for\n  deriving default probabilities and recovery rates",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we formulate a corporate bond (CB) pricing model for deriving\nthe term structure of default probabilities (TSDP) and the recovery rate (RR)\nfor each pair of industry factor and credit rating grade, and these derived\nTSDP and RR are regarded as what investors imply in forming CB prices in the\nmarket at each time. A unique feature of this formulation is that the model\nallows each firm to run several business lines corresponding to some industry\ncategories, which is typical in reality. In fact, treating all the\ncross-sectional CB prices simultaneously under a credit correlation structure\nat each time makes it possible to sort out the overlapping business lines of\nthe firms which issued CBs and to extract the TSDPs for each pair of individual\nindustry factor and rating grade together with the RRs. The result is applied\nto a valuation of CDS (credit default swap) and a loan portfolio management in\nbanking business.\n"
    },
    {
        "paper_id": 1206.4804,
        "authors": "David German and Henry Schellhorn",
        "title": "A No-Arbitrage Model of Liquidity in Financial Markets involving\n  Brownian Sheets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a dynamic market model where buyers and sellers submit limit\norders. If at a given moment in time, the buyer is unable to complete his\nentire order due to the shortage of sell orders at the required limit price,\nthe unmatched part of the order is recorded in the order book. Subsequently\nthese buy unmatched orders may be matched with new incoming sell orders. The\nresulting demand curve constitutes the sole input to our model. The clearing\nprice is then mechanically calculated using the market clearing condition. We\nuse a Brownian sheet to model the demand curve, and provide some theoretical\nassumptions under which such a model is justified.\n  Our main result is the proof that if there exists a unique equivalent\nmartingale measure for the clearing price, then under some mild assumptions\nthere is no arbitrage. We use the Ito- Wentzell formula to obtain that result,\nand also to characterize the dynamics of the demand curve and of the clearing\nprice in the equivalent measure. We find that the volatility of the clearing\nprice is (up to a stochastic factor) inversely proportional to the sum of buy\nand sell order flow density (evaluated at the clearing price), which confirms\nthe intuition that volatility is inversely proportional to volume. We also\ndemonstrate that our approach is implementable. We use real order book data and\nsimulate option prices under a particularly simple parameterization of our\nmodel.\n  The no-arbitrage conditions we obtain are applicable to a wide class of\nmodels, in the same way that the Heath-Jarrow-Morton conditions apply to a wide\nclass of interest rate models.\n"
    },
    {
        "paper_id": 1206.481,
        "authors": "Pietro Fodra and Mauricio Labadie",
        "title": "High-frequency market-making with inventory constraints and directional\n  bets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we extend the market-making models with inventory constraints\nof Avellaneda and Stoikov (\"High-frequency trading in a limit-order book\",\nQuantitative Finance Vol.8 No.3 2008) and Gueant, Lehalle and Fernandez-Tapia\n(\"Dealing with inventory risk\", Preprint 2011) to the case of a rather general\nclass of mid-price processes, under either exponential or linear PNL utility\nfunctions, and we add an inventory-risk-aversion parameter that penalises the\nmarker-maker if she finishes her day with a non-zero inventory. This general,\nnon-martingale framework allows a market-maker to make directional bets on\nmarket trends whilst keeping under control her inventory risk. In order to\nachieve this, the marker-maker places non-symmetric limit orders that favour\nmarket orders to hit her bid (resp. ask) quotes if she expects that prices will\ngo up (resp. down).\n  With this inventory-risk-aversion parameter, the market-maker has not only\ndirect control on her inventory risk but she also has indirect control on the\nmoments of her PNL distribution. Therefore, this parameter can be seen as a\nfine-tuning of the marker-maker's risk-reward profile.\n  In the case of a mean-reverting mid-price, we show numerically that the\ninventory-risk-aversion parameter gives the market-maker enough room to tailor\nher risk-reward profile, depending on her risk budgets in inventory and PNL\ndistribution (especially variance, skewness, kurtosis and VaR). For example,\nwhen compared to the martingale benchmark, a market can choose to either\nincrease her average PNL by more than 15% and carry a huge risk, on inventory\nand PNL, or either give up 5% of her benchmark PNL to increase her control on\ninventory and PNL, as well as increasing her Sharpe ratio by a factor bigger\nthan 2.\n"
    },
    {
        "paper_id": 1206.4917,
        "authors": "Tom Fischer",
        "title": "A shorter proof of Lemma A.6 (arXiv:1005.0768)",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For the convenience of readers of the article {\\em No-arbitrage pricing under\nsystemic risk: accounting for cross-ownership} (Fischer, 2012,\narXiv:1005.0768), a full proof of Lemma A.5 and a shorter proof of Lemma A.6 of\nthat paper are provided.\n"
    },
    {
        "paper_id": 1206.5046,
        "authors": "Dongjae Lim, Lingfei Li, Vadim Linetsky",
        "title": "Evaluating Callable and Putable Bonds: An Eigenfunction Expansion\n  Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose an efficient method to evaluate callable and putable bonds under a\nwide class of interest rate models, including the popular short rate diffusion\nmodels, as well as their time changed versions with jumps. The method is based\non the eigenfunction expansion of the pricing operator. Given the set of call\nand put dates, the callable and putable bond pricing function is the value\nfunction of a stochastic game with stopping times. Under some technical\nconditions, it is shown to have an eigenfunction expansion in eigenfunctions of\nthe pricing operator with the expansion coefficients determined through a\nbackward recursion. For popular short rate diffusion models, such as CIR,\nVasicek, 3/2, the method is orders of magnitude faster than the alternative\napproaches in the literature. In contrast to the alternative approaches in the\nliterature that have so far been limited to diffusions, the method is equally\napplicable to short rate jump-diffusion and pure jump models constructed from\ndiffusion models by Bochner's subordination with a L\\'{e}vy subordinator.\n"
    },
    {
        "paper_id": 1206.5224,
        "authors": "Tiago Colliri, Fernando F. Ferreira",
        "title": "Stock prices assessment: proposal of a new index based on volume\n  weighted historical prices through the use of computer modeling",
        "comments": "9 pages, 15 figures",
        "journal-ref": null,
        "doi": "10.1109/BWSS.2012.23",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The importance of considering the volumes to analyze stock prices movements\ncan be considered as a well-accepted practice in the financial area. However,\nwhen we look at the scientific production in this field, we still cannot find a\nunified model that includes volume and price variations for stock assessment\npurposes. In this paper we present a computer model that could fulfill this\ngap, proposing a new index to evaluate stock prices based on their historical\nprices and volumes traded. Besides the model can be considered mathematically\nvery simple, it was able to improve significantly the performance of agents\noperating with real financial data. Based on the results obtained, and also on\nthe very intuitive logic of our model, we believe that the index proposed here\ncan be very useful to help investors on the activity of determining ideal price\nranges for buying and selling stocks in the financial market.\n"
    },
    {
        "paper_id": 1206.5252,
        "authors": "Yiling Chen, David M Pennock",
        "title": "A Utility Framework for Bounded-Loss Market Makers",
        "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a class of utility-based market makers that always accept orders\nat their risk-neutral prices. We derive necessary and sufficient conditions for\nsuch market makers to have bounded loss. We prove that hyperbolic absolute risk\naversion utility market makers are equivalent to weighted pseudospherical\nscoring rule market makers. In particular, Hanson's logarithmic scoring rule\nmarket maker corresponds to a negative exponential utility market maker in our\nframework. We describe a third equivalent formulation based on maintaining a\ncost function that seems most natural for implementation purposes, and we\nillustrate how to translate among the three equivalent formulations. We examine\nthe tradeoff between the market's liquidity and the market maker's worst-case\nloss. For a fixed bound on worst-case loss, some market makers exhibit greater\nliquidity near uniform prices and some exhibit greater liquidity near extreme\nprices, but no market maker can exhibit uniformly greater liquidity in all\nregimes. For a fixed minimum liquidity level, we give the lower bound of market\nmaker's worst-case loss under some regularity conditions.\n"
    },
    {
        "paper_id": 1206.5324,
        "authors": "Riccardo Cesari, Massimiliano Marzo, Paolo Zagaglia",
        "title": "Effective Trade Execution",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the role of algorithmic trading in modern financial\nmarkets. Additionally, order types, characteristics, and special features of\nalgorithmic trading are described under the lens provided by the large\ndevelopment of high frequency trading technology. Special order types are\nexamined together with an intuitive description of the implied dynamics of the\norder book conditional to special orders (iceberg and hidden). The chapter\nprovides an analysis of the transaction costs associated with trading activity\nand examines the most common trading strategy employed in the market. It also\nexamines optimal execution strategy with the description of the Efficient\nTrading Frontier. These concepts represent the tools needed to understand the\nmost recent innovations in financial markets and the most recent advances in\nmicrostructures research.\n"
    },
    {
        "paper_id": 1206.5393,
        "authors": "Carmine De Franco, Peter Tankov and Xavier Warin",
        "title": "Numerical methods for the quadratic hedging problem in Markov models\n  with jumps",
        "comments": "37 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop algorithms for the numerical computation of the quadratic hedging\nstrategy in incomplete markets modeled by pure jump Markov process. Using the\nHamilton-Jacobi-Bellman approach, the value function of the quadratic hedging\nproblem can be related to a triangular system of parabolic partial\nintegro-differential equations (PIDE), which can be shown to possess unique\nsmooth solutions in our setting. The first equation is non-linear, but does not\ndepend on the pay-off of the option to hedge (the pure investment problem),\nwhile the other two equations are linear. We propose convergent finite\ndifference schemes for the numerical solution of these PIDEs and illustrate our\nresults with an application to electricity markets, where time-inhomogeneous\npure jump Markov processes appear in a natural manner.\n"
    },
    {
        "paper_id": 1206.5756,
        "authors": "Nils Chr. Framstad",
        "title": "On free lunches in random walk markets with short-sale constraints and\n  small transaction costs, and weak convergence to Gaussian continuous-time\n  processes",
        "comments": "To appear in the Brazilian Journal of Probability and Statistics,\n  http://www.imstat.org/bjps/",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers a sequence of discrete-time random walk markets with a\nsafe and a single risky investment opportunity, and gives conditions for the\nexistence of arbitrages or free lunches with vanishing risk, of the form of\nwaiting to buy and selling the next period, with no shorting, and furthermore\nfor weak convergence of the random walk to a Gaussian continuous-time\nstochastic process. The conditions are given in terms of the kernel\nrepresentation with respect to ordinary Brownian motion and the discretisation\nchosen. Arbitrage and free lunch with vanishing risk examples are established\nwhere the continuous-time analogue is arbitrage-free under small transaction\ncosts - including for the semimartingale modifications of fractional Brownian\nmotion suggested in the seminal Rogers (1997) article proving arbitrage in fBm\nmodels.\n"
    },
    {
        "paper_id": 1206.5983,
        "authors": "Jiro Akahori and Yuri Imamura",
        "title": "On a Symmetrization of Diffusion Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The latter author, together with collaborators, proposed a numerical scheme\nto calculate the price of barrier options. The scheme is based on a\nsymmetrization of diffusion process. The present paper aims to give a\nmathematical credit to the use of the numerical scheme for Heston or SABR type\nstochastic volatility models. This will be done by showing a fairly general\nresult on the symmetrization (in multi-dimension/multi-reflections). Further\napplications (to time-inhomogeneous diffusions/ to time dependent boundaries/to\ncurved boundaries) are also discussed.\n"
    },
    {
        "paper_id": 1206.6268,
        "authors": "Erhan Bayraktar and Virginia R. Young",
        "title": "Maximizing Utility of Consumption Subject to a Constraint on the\n  Probability of Lifetime Ruin",
        "comments": "Keywords: Utility maximization from consumption, probability of\n  lifetime ruin constraint, nonconvex risk constraint on the entire path of the\n  wealth process",
        "journal-ref": "Finance and Research Letters, (2008), 5 (4), 204-212",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note, we explicitly solve the problem of maximizing utility of\nconsumption (until the minimum of bankruptcy and the time of death) with a\nconstraint on the probability of lifetime ruin, which can be interpreted as a\nrisk measure on the whole path of the wealth process.\n"
    },
    {
        "paper_id": 1206.6283,
        "authors": "Erhan Bayraktar and Mike Ludkovski",
        "title": "Inventory Management with Partially Observed Nonstationary Demand",
        "comments": "Keywords: Inventory management, Markov modulated Poisson process,\n  hidden Markov model, partially observable demand, censored demand",
        "journal-ref": "Annals of Operations Research, 2010, 176 (1), 7-39",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a continuous-time model for inventory management with Markov\nmodulated non-stationary demands. We introduce active learning by assuming that\nthe state of the world is unobserved and must be inferred by the manager. We\nalso assume that demands are observed only when they are completely met. We\nfirst derive the explicit filtering equations and pass to an equivalent fully\nobserved impulse control problem in terms of the sufficient statistics, the a\nposteriori probability process and the current inventory level. We then solve\nthis equivalent formulation and directly characterize an optimal inventory\npolicy. We also describe a computational procedure to calculate the value\nfunction and the optimal policy and present two numerical illustrations.\n"
    },
    {
        "paper_id": 1206.6325,
        "authors": "Bruno Bouchard, Ludovic Moreau, Marcel Nutz",
        "title": "Stochastic target games with controlled loss",
        "comments": "Published in at http://dx.doi.org/10.1214/13-AAP938 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 3, 899-934",
        "doi": "10.1214/13-AAP938",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a stochastic game where one player tries to find a strategy such\nthat the state process reaches a target of controlled-loss-type, no matter\nwhich action is chosen by the other player. We provide, in a general setup, a\nrelaxed geometric dynamic programming principle for this problem and derive,\nfor the case of a controlled SDE, the corresponding dynamic programming\nequation in the sense of viscosity solutions. As an example, we consider a\nproblem of partial hedging under Knightian uncertainty.\n"
    },
    {
        "paper_id": 1206.6787,
        "authors": "Leif Andersen and Alexander Lipton",
        "title": "Asymptotics for Exponential Levy Processes and their Volatility Smile:\n  Survey and New Results",
        "comments": "92 pages, 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Exponential L\\'evy processes can be used to model the evolution of various\nfinancial variables such as FX rates, stock prices, etc. Considerable efforts\nhave been devoted to pricing derivatives written on underliers governed by such\nprocesses, and the corresponding implied volatility surfaces have been analyzed\nin some detail. In the non-asymptotic regimes, option prices are described by\nthe Lewis-Lipton formula which allows one to represent them as Fourier\nintegrals; the prices can be trivially expressed in terms of their implied\nvolatility. Recently, attempts at calculating the asymptotic limits of the\nimplied volatility have yielded several expressions for the short-time,\nlong-time, and wing asymptotics. In order to study the volatility surface in\nrequired detail, in this paper we use the FX conventions and describe the\nimplied volatility as a function of the Black-Scholes delta. Surprisingly, this\nconvention is closely related to the resolution of singularities frequently\nused in algebraic geometry. In this framework, we survey the literature,\nreformulate some known facts regarding the asymptotic behavior of the implied\nvolatility, and present several new results. We emphasize the role of\nfractional differentiation in studying the tempered stable exponential Levy\nprocesses and derive novel numerical methods based on judicial\nfinite-difference approximations for fractional derivatives. We also briefly\ndemonstrate how to extend our results in order to study important cases of\nlocal and stochastic volatility models, whose close relation to the L\\'evy\nprocess based models is particularly clear when the Lewis-Lipton formula is\nused. Our main conclusion is that studying asymptotic properties of the implied\nvolatility, while theoretically exciting, is not always practically useful\nbecause the domain of validity of many asymptotic expressions is small.\n"
    },
    {
        "paper_id": 1206.6972,
        "authors": "Satya N. Majumdar, Gregory Schehr, Gregor Wergen",
        "title": "Record statistics and persistence for a random walk with a drift",
        "comments": "51 pages, 22 figures. Published version (typos have been corrected)",
        "journal-ref": "J. Phys. A: Math. Theor. 45 (2012) 355002",
        "doi": "10.1088/1751-8113/45/35/355002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the statistics of records of a one-dimensional random walk of n\nsteps, starting from the origin, and in presence of a constant bias c. At each\ntime-step the walker makes a random jump of length \\eta drawn from a continuous\ndistribution f(\\eta) which is symmetric around a constant drift c. We focus in\nparticular on the case were f(\\eta) is a symmetric stable law with a L\\'evy\nindex 0 < \\mu \\leq 2. The record statistics depends crucially on the\npersistence probability which, as we show here, exhibits different behaviors\ndepending on the sign of c and the value of the parameter \\mu. Hence, in the\nlimit of a large number of steps n, the record statistics is sensitive to these\nparameters (c and \\mu) of the jump distribution. We compute the asymptotic mean\nrecord number <R_n> after n steps as well as its full distribution P(R,n). We\nalso compute the statistics of the ages of the longest and the shortest lasting\nrecord. Our exact computations show the existence of five distinct regions in\nthe (c, 0 < \\mu \\leq 2) strip where these quantities display qualitatively\ndifferent behaviors. We also present numerical simulation results that verify\nour analytical predictions.\n"
    },
    {
        "paper_id": 1206.6998,
        "authors": "Zoran Ivanovski, Toni Draganov Stojanovski, Nadica Ivanovska",
        "title": "Interest Rate Risk of Bond Prices on Macedonian Stock Exchange -\n  Empirical Test of the Duration, Modified Duration and Convexity and Bonds\n  Valuation",
        "comments": "Submitted to Economic Research, Juraj Dobrila University of Pula,\n  Croatia",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article presents valuation of Treasury Bonds (T-Bonds) on Macedonian\nStock Exchange (MSE) and empirical test of duration, modified duration and\nconvexity of the T-bonds at MSE in order to determine sensitivity of bonds\nprices on interest rate changes. The main goal of this study is to determine\nhow standard valuation models fit in case of T- Bonds that are traded on MSE\nand to verify whether they offer reliable results compared with average bonds\nprices on MSE. We test the sensitivity of T- Bonds on MSE on interest rate\nchanges and determine that convexity is more accurate measure as approximation\nof bond prices changes than duration. Final conclusion is that T-Bonds traded\nat MSE are not sensitive on interest rate changes due to institutional\ninvestors' permanent higher demand and at the same time market limited offer of\nrisk-free instruments.\n"
    },
    {
        "paper_id": 1206.7,
        "authors": "G. Seibold and M. Pickhardt",
        "title": "On the role of backauditing for tax evasion in an agent-based\n  Econophysics model",
        "comments": "7 pages, 9 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.01.016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate an inhomogeneous Ising model in the context of tax evasion\ndynamics where different types of agents are parametrized via local\ntemperatures and magnetic fields. In particular, we analyse the impact of\nbackauditing and endogenously determined penalty rates on tax compliance. Both\nfeatures contribute to a microfoundation of agent-based econophysics models of\ntax evasion.\n"
    },
    {
        "paper_id": 1207.0233,
        "authors": "Antoine Jacquier and Matthew Lorig",
        "title": "From characteristic functions to implied volatility expansions",
        "comments": "21 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For any strictly positive martingale $S = \\exp(X)$ for which $X$ has a\ncharacteristic function, we provide an expansion for the implied volatility.\nThis expansion is explicit in the sense that it involves no integrals, but only\npolynomials in the log strike. We illustrate the versatility of our expansion\nby computing the approximate implied volatility smile in three well-known\nmartingale models: one finite activity exponential L\\'evy model (Merton), one\ninfinite activity exponential L\\'evy model (Variance Gamma), and one stochastic\nvolatility model (Heston). Finally, we illustrate how our expansion can be used\nto perform a model-free calibration of the empirically observed implied\nvolatility surface.\n"
    },
    {
        "paper_id": 1207.0356,
        "authors": "Marco Bardoscia, Giacomo Livan, Matteo Marsili",
        "title": "Financial instability from local market measures",
        "comments": "17 pages, 4 figures",
        "journal-ref": "Journal of Statistical Mechanics: Theory and Experiment (2012)\n  P08017",
        "doi": "10.1088/1742-5468/2012/08/P08017",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the emergence of instabilities in a stylized model of a financial\nmarket, when different market actors calculate prices according to different\n(local) market measures. We derive typical properties for ensembles of large\nrandom markets using techniques borrowed from statistical mechanics of\ndisordered systems. We show that, depending on the number of financial\ninstruments available and on the heterogeneity of local measures, the market\nmoves from an arbitrage-free phase to an unstable one, where the complexity of\nthe market - as measured by the diversity of financial instruments - increases,\nand arbitrage opportunities arise. A sharp transition separates the two phases.\nFocusing on two different classes of local measures inspired by real markets\nstrategies, we are able to analytically compute the critical lines,\ncorroborating our findings with numerical simulations.\n"
    },
    {
        "paper_id": 1207.075,
        "authors": "Matthew Lorig",
        "title": "The Exact Smile of some Local Volatility Models",
        "comments": "14 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1207.1630",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new class of local volatility models. Within this framework,\nwe obtain expressions for both (i) the price of any European option and (ii)\nthe induced implied volatility smile. As an illustration of our framework, we\nperform specific pricing and implied volatility computations for a CEV-like\nexample. Numerical examples are provided.\n"
    },
    {
        "paper_id": 1207.0843,
        "authors": "Aleksandar Mijatovi\\'c and Peter Tankov",
        "title": "A new look at short-term implied volatility in asset price models with\n  jumps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyse the behaviour of the implied volatility smile for options close to\nexpiry in the exponential L\\'evy class of asset price models with jumps. We\nintroduce a new renormalisation of the strike variable with the property that\nthe implied volatility converges to a non-constant limiting shape, which is a\nfunction of both the diffusion component of the process and the jump activity\n(Blumenthal-Getoor) index of the jump component. Our limiting implied\nvolatility formula relates the jump activity of the underlying asset price\nprocess to the short end of the implied volatility surface and sheds new light\non the difference between finite and infinite variation jumps from the\nviewpoint of option prices: in the latter, the wings of the limiting smile are\ndetermined by the jump activity indices of the positive and negative jumps,\nwhereas in the former, the wings have a constant model-independent slope. This\nresult gives a theoretical justification for the preference of the infinite\nvariation L\\'evy models over the finite variation ones in the calibration based\non short-maturity option prices.\n"
    },
    {
        "paper_id": 1207.1003,
        "authors": "Taras Bodnar, Nestor Parolya and Wolfgang Schmid",
        "title": "A Closed-Form Solution of the Multi-Period Portfolio Choice Problem for\n  a Quadratic Utility Function",
        "comments": "38 pages, 9 figures, 3 tables, changes: VAR(1)-CCC-GARCH(1,1) process\n  dynamics and the analysis of increasing horizon are included in the\n  simulation study, under revision in Annals of Operations Research",
        "journal-ref": "Annals of Operations Research, 229, 121-158, 2015",
        "doi": "10.1007/s10479-015-1802-z",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper, we derive a closed-form solution of the multi-period\nportfolio choice problem for a quadratic utility function with and without a\nriskless asset. All results are derived under weak conditions on the asset\nreturns. No assumption on the correlation structure between different time\npoints is needed and no assumption on the distribution is imposed. All\nexpressions are presented in terms of the conditional mean vectors and the\nconditional covariance matrices. If the multivariate process of the asset\nreturns is independent it is shown that in the case without a riskless asset\nthe solution is presented as a sequence of optimal portfolio weights obtained\nby solving the single-period Markowitz optimization problem. The process\ndynamics are included only in the shape parameter of the utility function. If a\nriskless asset is present then the multi-period optimal portfolio weights are\nproportional to the single-period solutions multiplied by time-varying\nconstants which are depending on the process dynamics. Remarkably, in the case\nof a portfolio selection with the tangency portfolio the multi-period solution\ncoincides with the sequence of the simple-period solutions. Finally, we compare\nthe suggested strategies with existing multi-period portfolio allocation\nmethods for real data.\n"
    },
    {
        "paper_id": 1207.1029,
        "authors": "Taras Bodnar, Nestor Parolya and Wolfgang Schmid",
        "title": "On the Equivalence of Quadratic Optimization Problems Commonly Used in\n  Portfolio Theory",
        "comments": "Revised preprint. To appear in European Journal of Operational\n  Research. Contains 18 pages, 6 figures",
        "journal-ref": "European Journal of Operational Research, Volume 229, Issue 3,\n  2013, pp. 637-644",
        "doi": "10.1016/j.ejor.2013.03.002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the paper, we consider three quadratic optimization problems which are\nfrequently applied in portfolio theory, i.e, the Markowitz mean-variance\nproblem as well as the problems based on the mean-variance utility function and\nthe quadratic utility.Conditions are derived under which the solutions of these\nthree optimization procedures coincide and are lying on the efficient frontier,\nthe set of mean-variance optimal portfolios. It is shown that the solutions of\nthe Markowitz optimization problem and the quadratic utility problem are not\nalways mean-variance efficient. The conditions for the mean-variance efficiency\nof the solutions depend on the unknown parameters of the asset returns. We deal\nwith the problem of parameter uncertainty in detail and derive the\nprobabilities that the estimated solutions of the Markowitz problem and the\nquadratic utility problem are mean-variance efficient. Because these\nprobabilities deviate from one the above mentioned quadratic optimization\nproblems are not stochastically equivalent. The obtained results are\nillustrated by an empirical study.\n"
    },
    {
        "paper_id": 1207.1037,
        "authors": "Taras Bodnar, Nestor Parolya and Wolfgang Schmid",
        "title": "On the Exact Solution of the Multi-Period Portfolio Choice Problem for\n  an Exponential Utility under Return Predictability",
        "comments": "16 pages, 2 figures",
        "journal-ref": "European Journal of Operational Research, Volume 246, Issue 2,\n  2015, 528-542",
        "doi": "10.1016/j.ejor.2015.04.039",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we derive the exact solution of the multi-period portfolio\nchoice problem for an exponential utility function under return predictability.\nIt is assumed that the asset returns depend on predictable variables and that\nthe joint random process of the asset returns and the predictable variables\nfollow a vector autoregressive process. We prove that the optimal portfolio\nweights depend on the covariance matrices of the next two periods and the\nconditional mean vector of the next period. The case without predictable\nvariables and the case of independent asset returns are partial cases of our\nsolution. Furthermore, we provide an empirical study where the cumulative\nempirical distribution function of the investor's wealth is calculated using\nthe exact solution. It is compared with the investment strategy obtained under\nthe additional assumption that the asset returns are independently distributed.\n"
    },
    {
        "paper_id": 1207.1202,
        "authors": "Tanya Ara\\'ujo, Jo\\~ao Dias, Samuel Eleut\\'erio and Francisco\n  Lou\\c{c}\\~a",
        "title": "How Fama Went Wrong: Measures of Multivariate Kurtosis for the\n  Identification of the Dynamics of a N-Dimensional Market",
        "comments": "17 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.04.019",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the common intuition suggesting that during crises\nthe shape of the financial market clearly differentiates from that of random\nwalk processes. In this sense, it challenges the analysis of the nature of\nfinancial markets proposed by Fama and his associates. For this, a geometric\napproach is proposed in order to define the patterns of change of the market\nand a measure of multivariate kurtosis is used in order to test deviations from\nmultinormality. The emergence of crises can be measured in this framework,\nusing all the available information about the returns of the stocks under\nconsideration and not only the index representing the market.\n"
    },
    {
        "paper_id": 1207.1463,
        "authors": "Bela Nagy, J. Doyne Farmer, Quan M. Bui, Jessika E. Trancik",
        "title": "Statistical Basis for Predicting Technological Progress",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0052669",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Forecasting technological progress is of great interest to engineers, policy\nmakers, and private investors. Several models have been proposed for predicting\ntechnological improvement, but how well do these models perform? An early\nhypothesis made by Theodore Wright in 1936 is that cost decreases as a power\nlaw of cumulative production. An alternative hypothesis is Moore's law, which\ncan be generalized to say that technologies improve exponentially with time.\nOther alternatives were proposed by Goddard, Sinclair et al., and Nordhaus.\nThese hypotheses have not previously been rigorously tested. Using a new\ndatabase on the cost and production of 62 different technologies, which is the\nmost expansive of its kind, we test the ability of six different postulated\nlaws to predict future costs. Our approach involves hindcasting and developing\na statistical model to rank the performance of the postulated laws. Wright's\nlaw produces the best forecasts, but Moore's law is not far behind. We discover\na previously unobserved regularity that production tends to increase\nexponentially. A combination of an exponential decrease in cost and an\nexponential increase in production would make Moore's law and Wright's law\nindistinguishable, as originally pointed out by Sahal. We show for the first\ntime that these regularities are observed in data to such a degree that the\nperformance of these two laws is nearly tied. Our results show that\ntechnological progress is forecastable, with the square root of the logarithmic\nerror growing linearly with the forecasting horizon at a typical rate of 2.5%\nper year. These results have implications for theories of technological change,\nand assessments of candidate technologies and policies for climate change\nmitigation.\n"
    },
    {
        "paper_id": 1207.163,
        "authors": "Antoine Jacquier, Matthew Lorig",
        "title": "The Smile of certain L\\'evy-type Models",
        "comments": "31 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a class of assets whose risk-neutral pricing dynamics are\ndescribed by an exponential L\\'evy-type process subject to default. The class\nof processes we consider features locally-dependent drift, diffusion and\ndefault-intensity as well as a locally-dependent L\\'evy measure. Using\ntechniques from regular perturbation theory and Fourier analysis, we derive a\nseries expansion for the price of a European-style option. We also provide\nprecise conditions under which this series expansion converges to the exact\nprice. Additionally, for a certain subclass of assets in our modeling\nframework, we derive an expansion for the implied volatility induced by our\noption pricing formula. The implied volatility expansion is exact within its\nradius of convergence. As an example of our framework, we propose a class of\nCEV-like L\\'evy-type models. Within this class, approximate option prices can\nbe computed by a single Fourier integral and approximate implied volatilities\nare explicit (i.e., no integration is required). Furthermore, the class of\nCEV-like L\\'evy-type models is shown to provide a tight fit to the implied\nvolatility surface of S{&}P500 index options.\n"
    },
    {
        "paper_id": 1207.1759,
        "authors": "Claudio Fontana, Monique Jeanblanc, Shiqi Song",
        "title": "On arbitrages arising from honest times",
        "comments": "25 pages, revised version",
        "journal-ref": "Finance and Stochastics, 2014, vol. 18(3), 515-543",
        "doi": "10.1007/s00780-014-0231-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the context of a general continuous financial market model, we study\nwhether the additional information associated with an honest time gives rise to\narbitrage profits. By relying on the theory of progressive enlargement of\nfiltrations, we explicitly show that no kind of arbitrage profit can ever be\nrealised strictly before an honest time, while classical arbitrage\nopportunities can be realised exactly at an honest time as well as after an\nhonest time. Moreover, stronger arbitrages of the first kind can only be\nobtained by trading as soon as an honest time occurs. We carefully study the\nbehavior of local martingale deflators and consider no-arbitrage-type\nconditions weaker than NFLVR.\n"
    },
    {
        "paper_id": 1207.1771,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "The Keynesian theory and the manufactured industry in Portugal",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  About the economic growth the Keynesian theorists defend circular and\ncumulative processes, benefiting the rich localities and harming the poorest,\nwithout external interventions. In these processes the Verdoorn law has an\nimportant role. For Verdoorn (1949) the productivity growth rate is endogenous\nand depends of the output growth rate, capturing dynamic contexts, endogeneity\nof the factors and increasing economies of scale, namely in the industry. This\nrelationship later becomes the second law of Kaldor (1966 and 1967). For\nPortugal there are few works or none, than those of the author, with the\nVerdoorn law. In this way, seem important analyze this relationship for the\nmanufactured industry of the Portuguese regions and conclude about these\ncontexts in Portugal. It was used data from two periods, 1986-1994 and\n1995-1999, and panel data econometric methods. The two periods is to capture\nthe effect of the Portuguese entrance in the European Economic Community and of\nthe first Community Support Framework (1989-1993) for Portugal. As main\nconclusion, for the two periods, it is verified strong increasing returns in\nthe manufactured industry and as consequence regional divergence of this\nsector.\n"
    },
    {
        "paper_id": 1207.1842,
        "authors": "Akihiko Noda",
        "title": "A Test of the Adaptive Market Hypothesis using a Time-Varying AR Model\n  in Japan",
        "comments": "10 pages, 2 figure, 2 tables",
        "journal-ref": "Finance Research Letters 17 (2016) 66-71",
        "doi": "10.1016/j.frl.2016.01.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study examines the adaptive market hypothesis (AMH) in Japanese stock\nmarkets (TOPIX and TSE2). In particular, we measure the degree of market\nefficiency by using a time-varying model approach. The empirical results show\nthat (1) the degree of market efficiency changes over time in the two markets,\n(2) the level of market efficiency of the TSE2 is lower than that of the TOPIX\nin most periods, and (3) the market efficiency of the TOPIX has evolved, but\nthat of the TSE2 has not. We conclude that the results support the AMH for the\nmore qualified stock market in Japan.\n"
    },
    {
        "paper_id": 1207.1932,
        "authors": "Yunchol Jong",
        "title": "Optimization Method for Interval Portfolio Selection Based on\n  Satisfaction Index of Interval inequality Relation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider an interval portfolio selection problem with\nuncertain returns and introduce an inclusive concept of satisfaction index for\ninterval inequality relation. Based on the satisfaction index, we propose an\napproach to reduce the interval programming problem with uncertain objective\nand constraints into a standard linear programming problem with two parameters.\nWe showed by simulation experiment that our method is capable of helping\ninvestors to find efficient portfolios according to their preference.\n"
    },
    {
        "paper_id": 1207.201,
        "authors": "Frederik Herzberg and Frank Riedel",
        "title": "Existence of Financial Equilibria in Continuous Time with Potentially\n  Complete Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove that in smooth Markovian continuous-time economies with potentially\ncomplete asset markets, Radner equilibria with endogenously complete markets\nexist.\n"
    },
    {
        "paper_id": 1207.2316,
        "authors": "Damiano Brigo, Cristin Buescu, Andrea Pallavicini, Qing Liu",
        "title": "Illustrating a problem in the self-financing condition in two 2010-2011\n  papers on funding, collateral and discounting",
        "comments": "added references, a footnote and updated abstract",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We illustrate a problem in the self-financing condition used in the papers\n\"Funding beyond discounting: collateral agreements and derivatives pricing\"\n(Risk Magazine, February 2010) and \"Partial Differential Equation\nRepresentations of Derivatives with Counterparty Risk and Funding Costs\" (The\nJournal of Credit Risk, 2011). These papers state an erroneous self-financing\ncondition. In the first paper, this is equivalent to assuming that the equity\nposition is self-financing on its own and without including the cash position.\nIn the second paper, this is equivalent to assuming that a subportfolio is\nself-financing on its own, rather than the whole portfolio. The error in the\nfirst paper is avoided when clearly distinguishing between price processes,\ndividend processes and gain processes. We present an outline of the derivation\nthat yields the correct statement of the self-financing condition, clarifying\nthe structure of the relevant funding accounts, and show that the final result\nin \"Funding beyond discounting\" is correct, even if the self-financing\ncondition stated is not.\n"
    },
    {
        "paper_id": 1207.2452,
        "authors": "Chang-han Rhee, Peter W. Glynn",
        "title": "A new approach to unbiased estimation for SDE's",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we introduce a new approach to constructing unbiased\nestimators when computing expectations of path functionals associated with\nstochastic differential equations (SDEs). Our randomization idea is closely\nrelated to multi-level Monte Carlo and provides a simple mechanism for\nconstructing a finite variance unbiased estimator with \"square root convergence\nrate\" whenever one has available a scheme that produces strong error of order\ngreater than 1/2 for the path functional under consideration.\n"
    },
    {
        "paper_id": 1207.2946,
        "authors": "Thilo A. Schmitt, Rudi Sch\\\"afer, Michael C. M\\\"unnix, Thomas Guhr",
        "title": "Microscopic understanding of heavy-tailed return distributions in an\n  agent-based model",
        "comments": null,
        "journal-ref": "Europhysics Letters 100, 38005 (2012)",
        "doi": "10.1209/0295-5075/100/38005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The distribution of returns in financial time series exhibits heavy tails. In\nempirical studies, it has been found that gaps between the orders in the order\nbook lead to large price shifts and thereby to these heavy tails. We set up an\nagent based model to study this issue and, in particular, how the gaps in the\norder book emerge. The trading mechanism in our model is based on a\ndouble-auction order book, which is used on nearly all stock exchanges. In\nsituations where the order book is densely occupied with limit orders we do not\nobserve fat-tailed distributions. As soon as less liquidity is available, a gap\nstructure forms which leads to return distributions with heavy tails. We show\nthat return distributions with heavy tails are an order-book effect if the\navailable liquidity is constrained. This is largely independent of the specific\ntrading strategies.\n"
    },
    {
        "paper_id": 1207.3118,
        "authors": "M. Hossein Partovi",
        "title": "The Long Neglected Critically Leveraged Portfolio",
        "comments": "8 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that the efficient frontier for a portfolio in which short positions\nprecisely offset the long ones is composed of a pair of straight lines through\nthe origin of the risk-return plane. This unique but important case has been\noverlooked because the original formulation of the mean-variance model by\nMarkowitz as well as all its subsequent elaborations have implicitly excluded\nit by using portfolio weights rather than actual amounts allocated to\nindividual assets. We also elucidate the properties of portfolios where short\npositions dominate the long ones, a case which has similarly been obscured by\nthe adoption of portfolio weights.\n"
    },
    {
        "paper_id": 1207.33,
        "authors": "Fabrizio Lillo, Salvatore Miccich\\`e, Michele Tumminello, Jyrki Piilo\n  and Rosario Nunzio Mantegna",
        "title": "How news affect the trading behavior of different categories of\n  investors in a financial market",
        "comments": "30 pages, 4 figures and 5 tables",
        "journal-ref": "Quantitative Finance, 15(2), 213-229, (2015)",
        "doi": "10.1080/14697688.2014.931593",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the trading behavior of a large set of single investors\ntrading the highly liquid Nokia stock over the period 2003-2008 with the aim of\ndetermining the relative role of endogenous and exogenous factors that may\naffect their behavior. As endogenous factors we consider returns and\nvolatility, whereas the exogenous factors we use are the total daily number of\nnews and a semantic variable based on a sentiment analysis of news. Linear\nregression and partial correlation analysis of data show that different\ncategories of investors are differently correlated to these factors.\nGovernmental and non profit organizations are weakly sensitive to news and\nreturns or volatility, and, typically, they are more correlated with the former\nthan with the latter. Households and companies, on the contrary, are very\nsensitive to both endogenous and exogenous factors, and volatility and returns\nare, on average, much more relevant than the number of news and sentiment,\nrespectively. Finally, financial institutions and foreign organizations are\nintermediate between these two cases, in terms of both the total explanatory\npower of these factors and their relative importance.\n"
    },
    {
        "paper_id": 1207.3412,
        "authors": "Liviu-Adrian Cotfas",
        "title": "A quantum mechanical model for the relationship between stock price and\n  stock ownership",
        "comments": "11 pages",
        "journal-ref": "AIP Conference Proceedings 1497 (2012) 37-44",
        "doi": "10.1063/1.4766764",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The trade of a fixed stock can be regarded as the basic process that measures\nits momentary price. The stock price is exactly known only at the time of sale\nwhen the stock is between traders, that is, only in the case when the owner is\nunknown. We show that the stock price can be better described by a function\nindicating at any moment of time the probabilities for the possible values of\nprice if a transaction takes place. This more general description contains\npartial information on the stock price, but it also contains partial\ninformation on the stock owner. By following the analogy with quantum\nmechanics, we assume that the time evolution of the function describing the\nstock price can be described by a Schrodinger type equation.\n"
    },
    {
        "paper_id": 1207.3464,
        "authors": "Georg Mainik, Eric Schaanning",
        "title": "On dependence consistency of CoVaR and some other systemic risk measures",
        "comments": "32 pages, 15 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is dedicated to the consistency of systemic risk measures with\nrespect to stochastic dependence. It compares two alternative notions of\nConditional Value-at-Risk (CoVaR) available in the current literature. These\nnotions are both based on the conditional distribution of a random variable Y\ngiven a stress event for a random variable X, but they use different types of\nstress events. We derive representations of these alternative CoVaR notions in\nterms of copulas, study their general dependence consistency and compare their\nperformance in several stochastic models. Our central finding is that\nconditioning on X>=VaR_\\alpha(X) gives a much better response to dependence\nbetween X and Y than conditioning on X=VaR_\\alpha(X). We prove general results\nthat relate the dependence consistency of CoVaR using conditioning on\nX>=VaR_\\alpha(X) to well established results on concordance ordering of\nmultivariate distributions or their copulas. These results also apply to some\nother systemic risk measures, such as the Marginal Expected Shortfall (MES) and\nthe Systemic Impact Index (SII). We provide counterexamples showing that CoVaR\nbased on the stress event X=VaR_\\alpha(X) is not dependence consistent. In\nparticular, if (X,Y) is bivariate normal, then CoVaR based on X=VaR_\\alpha(X)\nis not an increasing function of the correlation parameter. Similar issues\narise in the bivariate t model and in the model with t margins and a Gumbel\ncopula. In all these cases, CoVaR based on X>=VaR_\\alpha(X) is an increasing\nfunction of the dependence parameter.\n"
    },
    {
        "paper_id": 1207.4028,
        "authors": "Dorje C. Brody, Lane P. Hughston, Xun Yang",
        "title": "Signal processing with Levy information",
        "comments": "27 pages. Version to appear in: Proc. R. Soc. London A",
        "journal-ref": "Proc. R. Soc. London A 469, 20120433 (2013)",
        "doi": "10.1098/rspa.2012.0433",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Levy processes, which have stationary independent increments, are ideal for\nmodelling the various types of noise that can arise in communication channels.\nIf a Levy process admits exponential moments, then there exists a parametric\nfamily of measure changes called Esscher transformations. If the parameter is\nreplaced with an independent random variable, the true value of which\nrepresents a \"message\", then under the transformed measure the original Levy\nprocess takes on the character of an \"information process\". In this paper we\ndevelop a theory of such Levy information processes. The underlying Levy\nprocess, which we call the fiducial process, represents the \"noise type\". Each\nsuch noise type is capable of carrying a message of a certain specification. A\nnumber of examples are worked out in detail, including information processes of\nthe Brownian, Poisson, gamma, variance gamma, negative binomial, inverse\nGaussian, and normal inverse Gaussian type. Although in general there is no\nadditive decomposition of information into signal and noise, one is led\nnevertheless for each noise type to a well-defined scheme for signal detection\nand enhancement relevant to a variety of practical situations.\n"
    },
    {
        "paper_id": 1207.4069,
        "authors": "Askar Akaev, Andrey Korotayev, and Alexey Fomin",
        "title": "Global Inflation Dynamics: regularities & forecasts",
        "comments": "15 pages, 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The analysis of dollar inflation performed by the authors through the\napproximation of empirical data for 1913-2012 with a power-law function with an\naccelerating log-periodic oscillation superimposed over it has made it possible\nto detect a quasi-singularity point around the 17th of December, 2012. It is\ndemonstrated that, if adequate measures are not taken, one may expect a surge\nof inflation around the end of this year that may also mark the start of\nstagflation as there are no sufficient grounds to expect the re-start of the\ndynamic growth of the world economy by that time. On the other hand, as the\nexperience of the 1970s and the 1980s indicates, the stagflation consequences\ncan only be eliminated with great difficulties and at a rather high cost,\nbecause the combination of low levels of economic growth and employment with\nhigh inflation leads to a sharp decline in consumption, aggravating the\neconomic depression. In order to mitigate the inflationary consequences of the\nexplosive growth of money (and, first of all, US dollar) supply it is necessary\nto take urgently the world monetary emission under control. This issue should\nbecome central at the forthcoming G8 and G20 summits.\n"
    },
    {
        "paper_id": 1207.43,
        "authors": "Oliver Grothe",
        "title": "A higher order correlation unscented Kalman filter",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many nonlinear extensions of the Kalman filter, e.g., the extended and the\nunscented Kalman filter, reduce the state densities to Gaussian densities. This\napproximation gives sufficient results in many cases. However, this filters\nonly estimate states that are correlated with the observation. Therefore,\nsequential estimation of diffusion parameters, e.g., volatility, which are not\ncorrelated with the observations is not possible. While other filters overcome\nthis problem with simulations, we extend the measurement update of the Gaussian\ntwo-moment filters by a higher order correlation measurement update. We\nexplicitly state formulas for a higher order unscented Kalman filter within a\ncontinuous-discrete state space. We demonstrate the filter in the context of\nparameter estimation of an Ornstein-Uhlenbeck process.\n"
    },
    {
        "paper_id": 1207.4309,
        "authors": "Oliver Grothe and Stephan Nicklas",
        "title": "Vine Constructions of Levy Copulas",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Levy copulas are the most general concept to capture jump dependence in\nmultivariate Levy processes. They translate the intuition and many features of\nthe copula concept into a time series setting. A challenge faced by both,\ndistributional and Levy copulas, is to find flexible but still applicable\nmodels for higher dimensions. To overcome this problem, the concept of pair\ncopula constructions has been successfully applied to distributional copulas.\nIn this paper, we develop the pair construction for Levy copulas (PLCC).\nSimilar to pair constructions of distributional copulas, the pair construction\nof a d-dimensional Levy copula consists of d(d-1)/2 bivariate dependence\nfunctions. We show that only d-1 of these bivariate functions are Levy copulas,\nwhereas the remaining functions are distributional copulas. Since there are no\nrestrictions concerning the choice of the copulas, the proposed pair\nconstruction adds the desired flexibility to Levy copula models. We discuss\nestimation and simulation in detail and apply the pair construction in a\nsimulation study.\n"
    },
    {
        "paper_id": 1207.4608,
        "authors": "S\\\"uhan Altay, Stefan Gerhold, Karin Hirhager",
        "title": "Digital double barrier options: Several barrier periods and structure\n  floors",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We determine the price of digital double barrier options with an arbitrary\nnumber of barrier periods in the Black-Scholes model. This means that the\nbarriers are active during some time intervals, but are switched off in\nbetween. As an application, we calculate the value of a structure floor for\nstructured notes whose individual coupons are digital double barrier options.\nThis value can also be approximated by the price of a corridor put.\n"
    },
    {
        "paper_id": 1207.4749,
        "authors": "Pietro Siorpaes",
        "title": "Do arbitrage-free prices come from utility maximization?",
        "comments": "this version: streamlined the paper, fixed typos, cut discussions\n  when introducing the model, deleted Section 9 and part of Section 8, changed\n  bib style",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we ask whether, given a stock market and an illiquid\nderivative, there exists arbitrage-free prices at which an utility-maximizing\nagent would always want to buy the derivative, irrespectively of his own\ninitial endowment of derivatives and cash. We prove that this is false for any\ngiven investor if one considers all initial endowments with finite utility, and\nthat it can instead be true if one restricts to the endowments in the interior.\n  We show however how the endowments on the boundary can give rise to very odd\nphenomena; for example, an investor with such an endowment would choose not to\ntrade in the derivative even at prices arbitrarily close to some arbitrage\nprice.\n"
    },
    {
        "paper_id": 1207.486,
        "authors": "Aki-Hiro Sato",
        "title": "Inference of Extreme Synchrony with an Entropy Measure on a Bipartite\n  Network",
        "comments": "9 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article proposes a method to quantify the structure of a bipartite graph\nusing a network entropy per link. The network entropy of a bipartite graph with\nrandom links is calculated both numerically and theoretically. As an\napplication of the proposed method to analyze collective behavior, the affairs\nin which participants quote and trade in the foreign exchange market are\nquantified. The network entropy per link is found to correspond to the\nmacroeconomic situation. A finite mixture of Gumbel distributions is used to\nfit the empirical distribution for the minimum values of network entropy per\nlink in each week. The mixture of Gumbel distributions with parameter estimates\nby segmentation procedure is verified by the Kolmogorov--Smirnov test. The\nfinite mixture of Gumbel distributions that extrapolate the empirical\nprobability of extreme events has explanatory power at a statistically\nsignificant level.\n"
    },
    {
        "paper_id": 1207.5269,
        "authors": "Caterina Liberati, Massimiliano Marzo, Paolo Zagaglia, Paola Zappa",
        "title": "Structural distortions in the Euro interbank market: The role of 'key\n  players' during the recent market turmoil",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the frictions in the patterns of trades in the Euro money market. We\ncharacterize the structure of lending relations during the period of recent\nfinancial turmoil. We use network-topology method on data from overnight\ntransactions in the Electronic Market for Interbank Deposits (e-Mid) to\ninvestigate on two main issues. First, we characterize the division of roles\nbetween borrowers and lenders in long-run relations by providing evidence on\nnetwork formation at a yearly frequency. Second, we identify the 'key players'\nin the marketplace and study their behaviour. Key players are 'locally-central\nbanks' within a network that lend (or borrow) large volumes to (from) several\ncounterparties, while borrowing (or lending) small volumes from (to) a small\nnumber of institutions. Our results are twofold. We show that the aggregate\ntrading patterns in e-Mid are characterized by largely asymmetric relations.\nThis implies a clear division of roles between lenders and borrowers. Second,\nthe key players do not exploit their position of network leaders by imposing\nopportunistic pricing policies. We find that only a fraction of the networks\ncomposed by big players are characterized by interest rates that are\nstatistically different from the average market rate throughout the turmoil\nperiod.\n"
    },
    {
        "paper_id": 1207.5809,
        "authors": "Alexander Schied",
        "title": "A control problem with fuel constraint and Dawson-Watanabe\n  superprocesses",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP908 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 6, 2472-2499",
        "doi": "10.1214/12-AAP908",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We solve a class of control problems with fuel constraint by means of the\nlog-Laplace transforms of $J$-functionals of Dawson-Watanabe superprocesses.\nThis solution is related to the superprocess solution of quasilinear parabolic\nPDEs with singular terminal condition. For the probabilistic verification\nproof, we develop sharp bounds on the blow-up behavior of log-Laplace\nfunctionals of $J$-functionals, which might be of independent interest.\n"
    },
    {
        "paper_id": 1207.6049,
        "authors": "Alexander Lipton and Ioana Savescu",
        "title": "Pricing credit default swaps with bilateral value adjustments",
        "comments": "49 pages, 31 figures. arXiv admin note: substantial text overlap with\n  arXiv:1206.3104",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A three-dimensional extension of the structural default model with firms'\nvalues driven by correlated diffusion processes is presented. Green's function\nbased semi-analytical methods for solving the forward calibration problem and\nbackward pricing problem are developed. These methods are used to analyze\nbilateral counterparty risk for credit default swaps and evaluate the\ncorresponding credit and debt value adjustments. It is shown that in many\nrealistic cases these value adjustments can be surprisingly large.\n"
    },
    {
        "paper_id": 1207.6081,
        "authors": "Maria Letizia Bertotti, Giovanni Modanese",
        "title": "Exploiting the flexibility of a family of models for taxation and\n  redistribution",
        "comments": "17 pages, 5 figures. Accepted for publication in Eur. Phys. J. B.\n  arXiv admin note: text overlap with arXiv:1109.0606",
        "journal-ref": "Eur. Phys. J. B (2012) 85: 261",
        "doi": "10.1140/epjb/e2012-30239-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss a family of models expressed by nonlinear differential equation\nsystems describing closed market societies in the presence of taxation and\nredistribution. We focus in particular on three example models obtained in\ncorrespondence to different parameter choices. We analyse the influence of the\nvarious choices on the long time shape of the income distribution. Several\nsimulations suggest that behavioral heterogeneity among the individuals plays a\ndefinite role in the formation of fat tails of the asymptotic stationary\ndistributions. This is in agreement with results found with different\napproaches and techniques. We also show that an excellent fit for the\ncomputational outputs of our models is provided by the k-generalized\ndistribution introduced by G. Kaniadakis (Physica A 296 (2001) 405-425).\n"
    },
    {
        "paper_id": 1207.6091,
        "authors": "Juan David Robalino and Henrik Jeldtoft Jensen",
        "title": "Entangled Economy: an ecosystems approach to modeling systemic level\n  dynamics",
        "comments": "25 pages, 11 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.10.037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a model of an economy inspired by individual based model\napproaches in evolutionary ecology. We demonstrate that evolutionary dynamics\nin a space of companies interconnected through a correlated interaction matrix\nproduces time dependencies of the total size of the economy total number of\ncompanies, companies age and capital distribution that compares well with\nstatistics for USA. We discuss the relevance of our modeling framework to\npolicy making.\n"
    },
    {
        "paper_id": 1207.6186,
        "authors": "Marco Bardoscia",
        "title": "A Dynamical Model for Operational Risk in Banks",
        "comments": "5 pages, 2 figures",
        "journal-ref": "Proceedings of the International School of Physics \"Enrico Fermi\"\n  176 (2012), pp. 399-403",
        "doi": "10.3254/978-1-61499-071-0-399",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Operational risk is the risk relative to monetary losses caused by failures\nof bank internal processes due to heterogeneous causes. A dynamical model\nincluding both spontaneous generation of losses and generation via interactions\nbetween different processes is presented; the efforts made by the bank to avoid\nthe occurrence of losses is also taken into account. Under certain hypotheses,\nthe model can be exactly solved and, in principle, the solution can be\nexploited to estimate most of the model parameters from real data. The\nforecasting power of the model is also investigated and proved to be\nsurprisingly remarkable.\n"
    },
    {
        "paper_id": 1207.6205,
        "authors": "Lauri Viitasaari",
        "title": "Option prices with call prices",
        "comments": "10 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There exist several methods how more general options can be priced with call\nprices. In this article, we extend these results to cover a wider class of\noptions and market models. In particular, we introduce a new pricing formula\nwhich can be used to price more general options if prices for call options and\ndigital options are known for every strike price. Moreover, we derive similar\nresults for barrier type options. As a consequence, we obtain a static hedging\nfor general options in the general class of models. Our result can be utilised\nin several significant applications. As a simple example, we derive an upper\nbound for the value of a general American option with convex payoff and\ncharacterise conditions under which the value of this option equals to the\nvalue of the corresponding European option.\n"
    },
    {
        "paper_id": 1207.6278,
        "authors": "Stefano Olgiati, Alessandro Danovi",
        "title": "The financial framework of the sustainability of health universal\n  coverage in Italy. A quantitative financial model for the assessment of the\n  italian stability and reform program of public health financing",
        "comments": "28 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Italy and the Eurozone are heading in the year 2012 into a financial\ndepression of unprecedented magnitude, with a forthcoming multitude of often\ncontradictory public economic and financial stability emergency interventions\nwhose ultimate endogenous and exogenous effects on public and private health\nspending and on the sustainability of universal coverage are difficult to\npredict ex ante. The research question is to assess whether it is possible to\nsynthesise into a single and simple quantitative index such multitude of public\neconomic and financial stability interventions and assess their magnitude and\ndirection towards increasing or decreasing sustainability of publicly funded\nhealth care and universal coverage. We have analyzed the Italian Economic and\nStability Reform Program 2011-2014 and we have proposed a quantitative\nsynthetic sustainability index {\\sigma} based on simple partial and absolute\ndifferential equations. The sustainability index {\\sigma} highlights that in\ncase the growth of the GDP in the period 2011-2014 be insufficient - as is\nalready the case in the first semester of 2012 - all the assumptions on which\nthe Italian Economic and Stability Reform Program 2011-2014 rests will fall,\nand Universal Coverage will become unsustainable. Health and Public Health\nprofessionals should intervene immediately with Italian and Eurozone national\nbudgets planners and financial health regulators before unselective exogenously\ninduced health financing and provision shortages produce irreparable\nepidemiological effects.\n"
    },
    {
        "paper_id": 1207.6281,
        "authors": "Kai Du, Ariel David Neufeld",
        "title": "A note on asymptotic exponential arbitrage with exponentially decaying\n  failure probability",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The goal of this paper is to prove a result conjectured in F\\\"ollmer and\nSchachermayer [FS07], even in slightly more general form. Suppose that S is a\ncontinuous semimartingale and satisfies a large deviations estimate; this is a\nparticular growth condition on the mean-variance tradeoff process of S. We show\nthat S then allows asymptotic exponential arbitrage with exponentially decaying\nfailure probability, which is a strong and quantitative form of long-term\narbitrage. In contrast to F\\\"ollmer and Schachermayer [FS07], our result does\nnot assume that S is a diffusion, nor does it need any ergodicity assumption.\n"
    },
    {
        "paper_id": 1207.6325,
        "authors": "Khalil Dayri and Mathieu Rosenbaum",
        "title": "Large tick assets: implicit spread and optimal tick size",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we provide a framework linking microstructural properties of an\nasset to the tick value of the exchange. In particular, we bring to light a\nquantity, referred to as implicit spread, playing the role of spread for large\ntick assets, for which the effective spread is almost always equal to one tick.\nThe relevance of this new parameter is shown both empirically and\ntheoretically. This implicit spread allows us to quantify the tick sizes of\nlarge tick assets and to define a notion of optimal tick size. Moreover, our\nresults open the possibility of forecasting the behavior of relevant market\nquantities after a change in the tick value and to give a way to modify it in\norder to reach an optimal tick size.\n"
    },
    {
        "paper_id": 1207.6423,
        "authors": "Beomsoo Park, Benjamin Van Roy",
        "title": "Adaptive Execution: Exploration and Learning of Price Impact",
        "comments": "31 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a model in which a trader aims to maximize expected risk-adjusted\nprofit while trading a single security. In our model, each price change is a\nlinear combination of observed factors, impact resulting from the trader's\ncurrent and prior activity, and unpredictable random effects. The trader must\nlearn coefficients of a price impact model while trading. We propose a new\nmethod for simultaneous execution and learning - the confidence-triggered\nregularized adaptive certainty equivalent (CTRACE) policy - and establish a\npoly-logarithmic finite-time expected regret bound. This bound implies that\nCTRACE is efficient in the sense that the ({\\epsilon},{\\delta})-convergence\ntime is bounded by a polynomial function of 1/{\\epsilon} and log(1/{\\delta})\nwith high probability. In addition, we demonstrate via Monte Carlo simulation\nthat CTRACE outperforms the certainty equivalent policy and a recently proposed\nreinforcement learning algorithm that is designed to explore efficiently in\nlinear-quadratic control problems.\n"
    },
    {
        "paper_id": 1207.6566,
        "authors": "Nico Achtsis, Ronald Cools and Dirk Nuyens",
        "title": "Conditional sampling for barrier option pricing under the Heston model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a quasi-Monte Carlo algorithm for pricing knock-out and knock-in\nbarrier options under the Heston (1993) stochastic volatility model. This is\ndone by modifying the LT method from Imai and Tan (2006) for the Heston model\nsuch that the first uniform variable does not influence the stochastic\nvolatility path and then conditionally modifying its marginals to fulfill the\nbarrier condition(s). We show this method is unbiased and never does worse than\nthe unconditional algorithm. Additionally the conditioning is combined with a\nroot finding method to also force positive payouts. The effectiveness of this\nmethod is shown by extensive numerical results.\n"
    },
    {
        "paper_id": 1207.6759,
        "authors": "Alessandro Ramponi",
        "title": "Computing Quantiles in Regime-Switching Jump-Diffusions with Application\n  to Optimal Risk Management: a Fourier Transform Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider the problem of calculating the quantiles of a risky\nposition, the dynamic of which is described as a continuous time\nregime-switching jump-diffusion, by using Fourier Transform methods.\nFurthermore, we study a classical option-based portfolio strategy which\nminimizes the Value-at-Risk of the hedged position and show the impact of jumps\nand switching regimes on the optimal strategy in a numerical example. However,\nthe analysis of this hedging strategy, as well as the computational technique\nfor its implementation, is fairly general, i.e. it can be applied to any\ndynamical model for which Fourier transform methods are viable.\n"
    },
    {
        "paper_id": 1207.7308,
        "authors": "R\\'emy Chicheportiche and Jean-Philippe Bouchaud",
        "title": "Weighted Kolmogorov-Smirnov test: Accounting for the tails",
        "comments": "7 pages, 4 figures",
        "journal-ref": "Phys. Rev. E 86 (4):1115 (2012)",
        "doi": "10.1103/PhysRevE.86.041115",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Accurate goodness-of-fit tests for the extreme tails of empirical\ndistributions is a very important issue, relevant in many contexts, including\ngeophysics, insurance, and finance. We have derived exact asymptotic results\nfor a generalization of the large-sample Kolmogorov-Smirnov test, well suited\nto testing these extreme tails. In passing, we have rederived and made more\nprecise the approximate limit solutions found originally in unrelated fields,\nfirst in [L. Turban, J. Phys. A 25, 127 (1992)] and later in [P. L. Krapivsky\nand S. Redner, Am. J. Phys. 64, 546 (1996)].\n"
    },
    {
        "paper_id": 1207.733,
        "authors": "Paolo Guasoni, Johannes Muhle-Karbe",
        "title": "Portfolio Choice with Transaction Costs: a User's Guide",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent progress in portfolio choice has made a wide class of problems\ninvolving transaction costs tractable. We review the basic approach to these\nproblems, and outline some directions for future research.\n"
    },
    {
        "paper_id": 1208.0317,
        "authors": "Pablo Su\\'arez-Garc\\'ia, David G\\'omez-Ullate",
        "title": "Scaling, stability and distribution of the high-frequency returns of the\n  IBEX35 index",
        "comments": "14 pages, 5 figures, typed in AMS-LaTeX",
        "journal-ref": "Physica A, 392(6) 2013 1409 -1417",
        "doi": "10.1016/j.physa.2012.11.026",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we perform a statistical analysis of the high-frequency returns\nof the IBEX35 Madrid stock exchange index. We find that its probability\ndistribution seems to be stable over different time scales, a stylized fact\nobserved in many different financial time series. However, an in-depth analysis\nof the data using maximum likelihood estimation and different goodness-of-fit\ntests rejects the L\\'evy-stable law as a plausible underlying probabilistic\nmodel. The analysis shows that the Normal Inverse Gaussian distribution\nprovides an overall fit for the data better than any of the other subclasses of\nthe family of the Generalized Hyperbolic distributions and certainly much\nbetter than the L\\'evy-stable laws. Furthermore, the right (resp. left) tail of\nthe distribution seems to follow a power-law with exponent \\alpha=4.60 (resp.\n\\alpha =4.28). Finally, we present evidence that the observed stability is due\nto temporal correlations or non-stationarities of the data.\n"
    },
    {
        "paper_id": 1208.0371,
        "authors": "John Cotter, Stuart Gabriel and Richard Roll",
        "title": "Can Metropolitan Housing Risk be Diversified? A Cautionary Tale from the\n  Recent Boom and Bust",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1110.4119",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Geographic diversification is fundamental to risk mitigation among investors\nand insurers of housing, mortgages, and mortgage-related derivatives. To\ncharacterize diversification potential, we provide estimates of integration,\nspatial correlation, and contagion among US metropolitan housing markets.\nResults reveal a high and increasing level of integration among US markets over\nthe decade of the 2000s, especially in California. We apply integration results\nto assess the risk of alternative housing investment portfolios. Portfolio\nsimulation indicates reduced diversification potential and increased risk in\nthe wake of estimated increases in metropolitan housing market integration.\nResearch findings provide new insights regarding the synchronous\nnon-performance of geographically-disparate MBS investments during the late\n2000s.\n"
    },
    {
        "paper_id": 1208.0451,
        "authors": "Ismael Martinez-Martinez and Ricardo Lopez-Ruiz",
        "title": "Directed Random Markets: Connectivity determines Money",
        "comments": "14 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1142/S012918311250088X",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Boltzmann-Gibbs distribution arises as the statistical equilibrium\nprobability distribution of money among the agents of a closed economic system\nwhere random and undirected exchanges are allowed. When considering a model\nwith uniform savings in the exchanges, the final distribution is close to the\ngamma family. In this work, we implement these exchange rules on networks and\nwe find that these stationary probability distributions are robust and they are\nnot affected by the topology of the underlying network. We introduce a new\nfamily of interactions: random but directed ones. In this case, it is found the\ntopology to be determinant and the mean money per economic agent is related to\nthe degree of the node representing the agent in the network. The relation\nbetween the mean money per economic agent and its degree is shown to be linear.\n"
    },
    {
        "paper_id": 1208.0642,
        "authors": "Jacky Mallett, Charles Keen",
        "title": "Does GDP measure growth in the economy or simply growth in the money\n  supply?",
        "comments": "22 pages, 20 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Gross Domestic Product(GDP) is a widely used measurement of economic growth\nrepresenting the market value of all final goods and services produced by a\ncountry within a given time. In this paper we question the assumption that GDP\nmeasures production, and suggest that in reality it merely captures changes in\nthe rate of expansion of the money supply used to measure the price data it is\nderived from. We first review the Quantity Theory of Money $MV=PT$, and show\nthat the Velocity of Circulation of Money(V) does not affect the price level as\nclaimed, as it is also a factor of the quantity of transactions(T). It then\nfollows directly that attempts to measure total production from any form of\nprice data as the GDP measurement does, will necessarily be confounded by the\ninverse relationship between prices and the quantity of production, which\nrequires that as the total quantity of production increases, prices will drop.\nFinally, in support of this claim we present an empirical analysis of the GDP\nof nine countries and one currency union, showing that when normalized for\nmoney supply growth GDP measures have been uniformly shrinking over the last 20\nyears, and discuss the possible reasons for this behaviour.\n"
    },
    {
        "paper_id": 1208.0763,
        "authors": "M. Nabil Kazi-Tani, Dylan Possama\\\"i, Chao Zhou",
        "title": "Second Order BSDEs with Jumps: Existence and probabilistic\n  representation for fully-nonlinear PIDEs",
        "comments": "39 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we pursue the study of second order BSDEs with jumps (2BSDEJs\nfor short) started in our accompanying paper [15]. We prove existence of these\nequations by a direct method, thus providing complete wellposedness for\n2BSDEJs. These equations are a natural candidate for the probabilistic\ninterpretation of some fully non-linear partial integro-differential equations,\nwhich is the point of the second part of this work. We prove a non-linear\nFeynman-Kac formula and show that solutions to 2BSDEJs provide viscosity\nsolutions of the associated PIDEs.\n"
    },
    {
        "paper_id": 1208.1123,
        "authors": "Joachim Kaldasch",
        "title": "Evolutionary Model of the Growth and Size of Firms",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.01.027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The key idea of this model is that firms are the result of an evolutionary\nprocess. Based on demand and supply considerations the evolutionary model\npresented here derives explicitly Gibrat's law of proportionate effects as the\nresult of the competition between products. Applying a preferential attachment\nmechanism for firms the theory allows to establish the size distribution of\nproducts and firms. Also established are the growth rate and price distribution\nof consumer goods. Taking into account the characteristic property of human\nactivities to occur in bursts, the model allows also an explanation of the\nsize-variance relationship of the growth rate distribution of products and\nfirms. Further the product life cycle, the learning (experience) curve and the\nmarket size in terms of the mean number of firms that can survive in a market\nare derived. The model also suggests the existence of an invariant of a market\nas the ratio of total profit to total revenue. The relationship between a\nneo-classic and an evolutionary view of a market is discussed. The comparison\nwith empirical investigations suggests that the theory is able to describe the\nmain stylized facts concerning the size and growth of firms.\n"
    },
    {
        "paper_id": 1208.1188,
        "authors": "Hayafumi Watanabe, Hideki Takayasu, Misako Takayasu",
        "title": "Relations between allometric scalings and fluctuations in complex\n  systems: The case of Japanese firms",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.10.020",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To elucidate allometric scaling in complex systems, we investigated the\nunderlying scaling relationships between typical three-scale indicators for\napproximately 500,000 Japanese firms; namely, annual sales, number of\nemployees, and number of business partners. First, new scaling relations\nincluding the distributions of fluctuations were discovered by systematically\nanalyzing conditional statistics. Second, we introduced simple probabilistic\nmodels that reproduce all these scaling relations, and we derived relations\nbetween scaling exponents and the magnitude of fluctuations.\n"
    },
    {
        "paper_id": 1208.1189,
        "authors": "Nassim N. Taleb and Raphael Douady",
        "title": "Mathematical Definition, Mapping, and Detection of (Anti)Fragility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a mathematical definition of fragility and antifragility as\nnegative or positive sensitivity to a semi-measure of dispersion and volatility\n(a variant of negative or positive \"vega\") and examine the link to nonlinear\neffects. We integrate model error (and biases) into the fragile or antifragile\ncontext. Unlike risk, which is linked to psychological notions such as\nsubjective preferences (hence cannot apply to a coffee cup) we offer a measure\nthat is universal and concerns any object that has a probability distribution\n(whether such distribution is known or, critically, unknown). We propose a\ndetection of fragility, robustness, and antifragility using a single\n\"fast-and-frugal\", model-free, probability free heuristic that also picks up\nexposure to model error. The heuristic lends itself to immediate\nimplementation, and uncovers hidden risks related to company size, forecasting\nproblems, and bank tail exposures (it explains the forecasting biases). While\nsimple to implement, it outperforms stress testing and other such methods such\nas Value-at-Risk.\n"
    },
    {
        "paper_id": 1208.1277,
        "authors": "Robert Kitt",
        "title": "Economic decision making: application of the theory of complex systems",
        "comments": "Will appear as a chapter in \"Chaos Theory in Politics\", eds Santo\n  Banerjee, S.Sule Ercetin, A.Tekin by Spinger",
        "journal-ref": null,
        "doi": "10.1007/978-94-017-8691-1_4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this chapter the complex systems are discussed in the context of economic\nand business policy and decision making. It will be showed and motivated that\nsocial systems are typically chaotic, non-linear and/or non-equilibrium and\ntherefore complex systems. It is discussed that the rapid change in global\nconsumer behaviour is underway, that further increases the complexity in\nbusiness and management. For policy making under complexity, following\nprinciples are offered: openness and international competition, tolerance and\nvariety of ideas, self-reliability and low dependence on external help. The\nchapter contains four applications that build on the theoretical motivation of\ncomplexity in social systems. The first application demonstrates that small\neconomies have good prospects to gain from the global processes underway, if\nthey can demonstrate production flexibility, reliable business ethics and good\nrisk management. The second application elaborates on and discusses the\nopportunities and challenges in decision making under complexity from macro and\nmicro economic perspective. In this environment, the challenges for corporate\nmanagement are being also permanently changed: the balance between short term\nnoise and long term chaos whose attractor includes customers, shareholders and\nemployees must be found. The emergence of chaos in economic relationships is\ndemonstrated by a simple system of differential equations that relate the\nstakeholders described above. The chapter concludes with two financial\napplications: about debt and risk management. The non-equilibrium economic\nestablishment leads to additional problems by using excessive borrowing;\nunexpected downturns in economy can more easily kill companies. Finally, the\ndemand for quantitative improvements in risk management is postulated.\n"
    },
    {
        "paper_id": 1208.1298,
        "authors": "Ladislav Kristoufek and Miloslav Vosvrda",
        "title": "Measuring capital market efficiency: Global and local correlations\n  structure",
        "comments": "18 pages",
        "journal-ref": "Physica A 392(1), pp. 184-193, 2013",
        "doi": "10.1016/j.physa.2012.08.003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new measure for the capital market efficiency. The measure\ntakes into consideration the correlation structure of the returns (long-term\nand short-term memory) and local herding behavior (fractal dimension). The\nefficiency measure is taken as a distance from an ideal efficient market\nsituation. Methodology is applied to a portfolio of 41 stock indices. We find\nthat the Japanese NIKKEI is the most efficient market. From geographical point\nof view, the more efficient markets are dominated by the European stock indices\nand the less efficient markets cover mainly Latin America, Asia and Oceania.\nThe inefficiency is mainly driven by a local herding, i.e. a low fractal\ndimension.\n"
    },
    {
        "paper_id": 1208.1479,
        "authors": "David Spring",
        "title": "General Balance Functions in the Theory of Interest",
        "comments": "38 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop an axiomatic theory of balance functions (future value functions)\nin the theory of interest that is derived from financial considerations and\nwhich applies to general regulated payment streams, including continuous\npayment streams. Balance functions exist and are unique up to an initial choice\nof deposit and investment accumulation functions. In terms of these balance\nfunctions we also construct a unique internal rate of return for each regulated\npayment stream that is an investment project. This theory subsumes and\nclarifies previous theories of internal rate of return functions for more\nspecialized classes of investment projects.\n"
    },
    {
        "paper_id": 1208.2068,
        "authors": "Tianxiao Wang",
        "title": "Risk minimizing of derivatives via dynamic g-expectation and related\n  topics",
        "comments": "20pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we investigate risk minimization problem of derivatives based\non non-tradable underlyings by means of dynamic g-expectations which are slight\ndifferent from conditional g-expectations. In this framework, inspired by [1]\nand [16], we introduce risk indifference price, marginal risk price and\nderivative hedge and obtain their corresponding explicit expressions. The\ninteresting thing is that their expressions have nothing to do with nonlinear\ngenerator g, and one deep reason for this is due to the completeness of\nfinancial market. By giving three useful special risk minimization problems, we\nobtain the explicit optimal strategies with initial wealth involved,\ndemonstrate some qualitative analysis among optimal strategies, risk aversion\nparameter and market price of risk, together with some economic\ninterpretations.\n"
    },
    {
        "paper_id": 1208.2589,
        "authors": "Sebastian Goncalves, M. F. Laguna, and J. R. Iglesias",
        "title": "Why, when, and how fast innovations are adopted",
        "comments": "11 pages, 13 figures (with subfigures), full paper (EPJB 2012) on\n  innovation adoption model",
        "journal-ref": "The European Phys. Journal B 85, 192 (2012)",
        "doi": "10.1140/epjb/e2012-30082-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  When the full stock of a new product is quickly sold in a few days or weeks,\none has the impression that new technologies develop and conquer the market in\na very easy way. This may be true for some new technologies, for example the\ncell phone, but not for others, like the blue-ray. Novelty, usefulness,\nadvertising, price, and fashion are the driving forces behind the adoption of a\nnew product. But, what are the key factors that lead to adopt a new technology?\nIn this paper we propose and investigate a simple model for the adoption of an\ninnovation which depends mainly on three elements: the appeal of the novelty,\nthe inertia or resistance to adopt it, and the interaction with other agents.\nSocial interactions are taken into account in two ways: by imitation and by\ndifferentiation, i.e., some agents will be inclined to adopt an innovation if\nmany people do the same, but other will act in the opposite direction, trying\nto differentiate from the \"herd\". We determine the conditions for a successful\nimplantation of the new technology, by considering the strength of advertising\nand the effect of social interactions. We find a balance between the\nadvertising and the number of anti-herding agents that may block the adoption\nof a new product. We also compare the effect of social interactions, when\nagents take into account the behavior of the whole society or just a part of\nit. In a nutshell, the present model reproduces qualitatively the available\ndata on adoption of innovation.\n"
    },
    {
        "paper_id": 1208.2658,
        "authors": "Paul M. N. Feehan and Camelia A. Pop",
        "title": "Degenerate-elliptic operators in mathematical finance and higher-order\n  regularity for solutions to variational equations",
        "comments": "55 pages, 1 figure. To appear in Advances in Differential Equations.\n  Incorporates final galley proof corrections corresponding to published\n  version",
        "journal-ref": "Advances in Differential Equations 20 (2015), no. 3/4, 361-432",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We establish higher-order weighted Sobolev and Holder regularity for\nsolutions to variational equations defined by the elliptic Heston operator, a\nlinear second-order degenerate-elliptic operator arising in mathematical\nfinance. Furthermore, given $C^\\infty$-smooth data, we prove\n$C^\\infty$-regularity of solutions up to the portion of the boundary where the\noperator is degenerate. In mathematical finance, solutions to obstacle problems\nfor the elliptic Heston operator correspond to value functions for perpetual\nAmerican-style options on the underlying asset.\n"
    },
    {
        "paper_id": 1208.2696,
        "authors": "Tao Ma, John G. Holden and R. A. Serota",
        "title": "Distribution Of Wealth In A Network Model Of The Economy",
        "comments": "8 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.01.045",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show, analytically and numerically, that wealth distribution in the\nBouchaud-M\\'ezard network model of the economy is described by a\nthree-parameter generalized inverse gamma distribution. In the mean-field limit\nof a network with any two agents linked, it reduces to the inverse gamma\ndistribution.\n"
    },
    {
        "paper_id": 1208.2775,
        "authors": "Jaehyung Choi",
        "title": "Physical approach to price momentum and its application to momentum\n  strategy",
        "comments": "23 pages, 2 figures; published version",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications 415 (2014),\n  pp. 61-72",
        "doi": "10.1016/j.physa.2014.07.075",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce various quantitative and mathematical definitions for price\nmomentum of financial instruments. The price momentum is quantified with\nvelocity and mass concepts originated from the momentum in physics. By using\nthe physical momentum of price as a selection criterion, the weekly contrarian\nstrategies are implemented in South Korea KOSPI 200 and US S&P 500 universes.\nThe alternative strategies constructed by the physical momentum achieve the\nbetter expected returns and reward-risk measures than those of the traditional\ncontrarian strategy in weekly scale. The portfolio performance is not\nunderstood by the Fama-French three-factor model.\n"
    },
    {
        "paper_id": 1208.2878,
        "authors": "Murphy Choy, Enoch Chng, Koo Ping Shung",
        "title": "Interest Rate Manipulation Detection using Time Series Clustering\n  Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Interbank Offered Rate is a vital benchmark interest rate in the\nfinancial markets of every country to which financial contracts are tied. In\nthe light of the recent LIBOR manipulation incident, this paper seeks to\naddress the fear that Interbank Offered Rate are entirely controlled by the\nbank. The paper will focus on the comparison between LIBOR and SIBOR especially\nwith regards to the behavior of the interest rate with time. Because of the\nnature of IBORs, banks will naturally be submitting similar rates which should\nnot differ excessively from the market as well as the other banks. We will\ncompare the LIBOR and SIBOR from 2005 to 2011 with respect to the 1 month rates\non an annual basis. We will present the result that the SIBOR is not\nmanipulated like LIBOR.\n"
    },
    {
        "paper_id": 1208.3083,
        "authors": "A. Lykov, S. Muzychka, K. Vaninsky",
        "title": "Investor's sentiment in multi-agent model of the continuous double\n  auction",
        "comments": "32 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce and treat rigorously a new multi-agent model of the continuous\ndouble auction or in other words the order book (OB). It is designed to explain\ncollective behaviour of the market when new information affecting the market\narrives. The novel feature of the model is two additional slow changing\nparameters, the so-called sentiment functions. These sentiment functions\nmeasure the conception of the fair price of two groups of investors, namely,\nbulls and bears. Our model specifies differential equations for the time\nevolution of sentiment functions and constitutes a nonlinear Markov process\nwhich exhibits long term correlations. We explain the intuition behind\nequations for sentiment functions and present numerical simulations which show\nthat the behaviour of our model is similar to the behaviour of the real market.\nWe also obtain a diffusion limit of the model, the Ornstein-Uhlenbeck type\nprocess with variable volatility. The volatility is proportional to the\ndifference of opinions of bulls and bears about the fair price of a security.\nThe paper is complimentary to our previous work where mathematical proofs are\npresented.\n"
    },
    {
        "paper_id": 1208.3087,
        "authors": "Filip Zikes, Jozef Barunik, Nikhil Shenai",
        "title": "Modeling and Forecasting Persistent Financial Durations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper introduces the Markov-Switching Multifractal Duration (MSMD) model\nby adapting the MSM stochastic volatility model of Calvet and Fisher (2004) to\nthe duration setting. Although the MSMD process is exponential $\\beta$-mixing\nas we show in the paper, it is capable of generating highly persistent\nautocorrelation. We study analytically and by simulation how this feature of\ndurations generated by the MSMD process propagates to counts and realized\nvolatility. We employ a quasi-maximum likelihood estimator of the MSMD\nparameters based on the Whittle approximation and establish its strong\nconsistency and asymptotic normality for general MSMD specifications. We show\nthat the Whittle estimation is a computationally simple and fast alternative to\nmaximum likelihood. Finally, we compare the performance of the MSMD model with\ncompeting short- and long-memory duration models in an out-of-sample\nforecasting exercise based on price durations of three major foreign exchange\nfutures contracts. The results of the comparison show that the MSMD and LMSD\nperform similarly and are superior to the short-memory ACD models.\n"
    },
    {
        "paper_id": 1208.346,
        "authors": "Jaime Gomez-Ramirez",
        "title": "Inverse Thinking in Economic Theory: A Radical Approach to Economic\n  Thinking",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The seriousness of the current crisis urgently demands new economic thinking\nthat breaks the austerity vs. deficit spending circle in economic policy. The\ncore tenet of the paper is that the most important problems that natural and\nsocial science are facing today are inverse problems, and that a new approach\nthat goes beyond optimization is necessary. The approach presented here is\nradical in the sense that identifies the roots in key assumptions in economic\ntheory such as optimal behavior and stability to provide an inverse thinking\nperspective to economic modeling of use in economic and financial stability\npolicy. The inverse problem provides a truly multidisciplinary platform where\nrelated problems from different disciplines can be studied under a common\napproach with comparable results.\n"
    },
    {
        "paper_id": 1208.3785,
        "authors": "Dylan Possama\\\"i, Nizar Touzi, H. Mete Soner",
        "title": "Large liquidity expansion of super-hedging costs",
        "comments": null,
        "journal-ref": "Asymptotic Analysis, 79(1-2), 2012, 45-64",
        "doi": "10.3233/ASY-2011-1089",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a financial market with liquidity cost as in \\c{C}etin, Jarrow\nand Protter [2004], where the supply function $S^{\\epsilon}(s,\\nu)$ depends on\na parameter $\\epsilon\\geq 0$ with $S^0(s,\\nu)=s$ corresponding to the perfect\nliquid situation. Using the PDE characterization of \\c{C}etin, Soner and Touzi\n[2010] of the super-hedging cost of an option written on such a stock, we\nprovide a Taylor expansion of the super-hedging cost in powers of $\\epsilon$.\nIn particular, we explicitly compute the first term in the expansion for a\nEuropean Call option and give bounds for the order of the expansion for a\nEuropean Digital Option.\n"
    },
    {
        "paper_id": 1208.3789,
        "authors": "Bhaskar DasGupta and Lakshmi Kaligounder",
        "title": "On Global Stability of Financial Networks",
        "comments": "arXiv admin note: text overlap with arXiv:1112.5687 by other authors.\n  Prior title for this article was \"Contagion in Financial Networks: Measure,\n  Evaluation and Implications\"",
        "journal-ref": "Journal of Complex Networks, 2(3), 313-354, 2014",
        "doi": "10.1093/comnet/cnu004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The recent financial crisis have generated renewed interests in fragilities\nof global financial networks among economists and regulatory authorities. In\nparticular, a potential vulnerability of the financial networks is the\n\"financial contagion\" process in which insolvencies of individual entities\npropagate through the \"web of dependencies\" to affect the entire system. In\nthis paper, we formalize an extension of a financial network model originally\nproposed by Nier et al. for scenarios such as the OTC derivatives market,\ndefine a suitable global stability measure for this model, and perform a\ncomprehensive empirical evaluation of this stability measure over more than\n700,000 combinations of networks types and parameter combinations. Based on our\nevaluations, we discover many interesting implications of our evaluations of\nthis stability measure, and derive topological properties and parameters\ncombinations that may be used to flag the network as a possible fragile\nnetwork. An interactive software FIN-STAB for computing the stability is\navailable from the website www2.cs.uic.edu/~dasgupta/financial-simulator-files\n"
    },
    {
        "paper_id": 1208.4158,
        "authors": "Ying-Hui Shao (ECUST), Gao Feng Gu (ECUST), Zhi-Qiang Jiang (ECUST),\n  Wei-Xing Zhou (ECUST), Didier Sornette (ETH Zurich)",
        "title": "Comparing the performance of FA, DFA and DMA using different synthetic\n  long-range correlated time series",
        "comments": "6 pages (including 3 figures) + 3 supplementary figures",
        "journal-ref": "Scientific Reports 2, 835 (2012)",
        "doi": "10.1038/srep00835",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Notwithstanding the significant efforts to develop estimators of long-range\ncorrelations (LRC) and to compare their performance, no clear consensus exists\non what is the best method and under which conditions. In addition, synthetic\ntests suggest that the performance of LRC estimators varies when using\ndifferent generators of LRC time series. Here, we compare the performances of\nfour estimators [Fluctuation Analysis (FA), Detrended Fluctuation Analysis\n(DFA), Backward Detrending Moving Average (BDMA), and centred Detrending Moving\nAverage (CDMA)]. We use three different generators [Fractional Gaussian Noises,\nand two ways of generating Fractional Brownian Motions]. We find that CDMA has\nthe best performance and DFA is only slightly worse in some situations, while\nFA performs the worst. In addition, CDMA and DFA are less sensitive to the\nscaling range than FA. Hence, CDMA and DFA remain \"The Methods of Choice\" in\ndetermining the Hurst index of time series.\n"
    },
    {
        "paper_id": 1208.4282,
        "authors": "Stefan Gerhold, Max Kleinert, Piet Porkert, Mykhaylo Shkolnikov",
        "title": "Small time central limit theorems for semimartingales with applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give conditions under which the normalized marginal distribution of a\nsemimartingale converges to a Gaussian limit law as time tends to zero. In\nparticular, our result is applicable to solutions of stochastic differential\nequations with locally bounded and continuous coefficients. The limit theorems\nare subsequently extended to functional central limit theorems on the process\nlevel. We present two applications of the results in the field of mathematical\nfinance: to the pricing of at-the-money digital options with short maturities\nand short time implied volatility skews.\n"
    },
    {
        "paper_id": 1208.4409,
        "authors": "R. Bustos-Guajardo and Cristian F. Moukarzel",
        "title": "Yard-Sale exchange on networks: Wealth sharing and wealth appropriation",
        "comments": "10 pages, 7 figures. Submitted to JSTAT",
        "journal-ref": null,
        "doi": "10.1088/1742-5468/2012/12/P12009",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Yard-Sale (YS) is a stochastic multiplicative wealth-exchange model with two\nphases: a stable one where wealth is shared, and an unstable one where wealth\ncondenses onto one agent. YS is here studied numerically on 1d rings, 2d square\nlattices, and random graphs with variable average coordination, comparing its\nproperties with those in mean field (MF). Equilibrium properties in the stable\nphase are almost unaffected by the introduction of a network. Measurement of\ndecorrelation times in the stable phase allow us to determine the critical\ninterface with very good precision, and it turns out to be the same, for all\nnetworks analyzed, as the one that can be analytically derived in MF. In the\nunstable phase, on the other hand, dynamical as well as asymptotic properties\nare strongly network-dependent. Wealth no longer condenses on a single agent,\nas in MF, but onto an extensive set of agents, the properties of which depend\non the network. Connections with previous studies of coalescence of immobile\nreactants are discussed, and their analytic predictions are successfully\ncompared with our numerical results.\n"
    },
    {
        "paper_id": 1208.4429,
        "authors": "E. Hurwitz and T. Marwala",
        "title": "Common Mistakes when Applying Computational Intelligence and Machine\n  Learning to Stock Market modelling",
        "comments": "5 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a number of reasons, computational intelligence and machine learning\nmethods have been largely dismissed by the professional community. The reasons\nfor this are numerous and varied, but inevitably amongst the reasons given is\nthat the systems designed often do not perform as expected by their designers.\nThe reasons for this lack of performance is a direct result of mistakes that\nare commonly seen in market-prediction systems. This paper examines some of the\nmore common mistakes, namely dataset insufficiency; inappropriate scaling;\ntime-series tracking; inappropriate target quantification and inappropriate\nmeasures of performance. The rationale that leads to each of these mistakes is\nexamined, as well as the nature of the errors they introduce to the analysis /\ndesign. Alternative ways of performing each task are also recommended in order\nto avoid perpetuating these mistakes, and hopefully to aid in clearing the way\nfor the use of these powerful techniques in industry.\n"
    },
    {
        "paper_id": 1208.4799,
        "authors": "Paolo Guasoni and Gu Wang",
        "title": "Hedge and Mutual Funds' Fees and the Separation of Private Investments",
        "comments": "Keywords: Hedge Funds, Portfolio Choice, High-Water Marks,\n  Performance Fees, Management Fees",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A fund manager invests both the fund's assets and own private wealth in\nseparate but potentially correlated risky assets, aiming to maximize expected\nutility from private wealth in the long run. If relative risk aversion and\ninvestment opportunities are constant, we find that the fund's portfolio\ndepends only on the fund's investment opportunities, and the private portfolio\nonly on private opportunities. This conclusion is valid both for a hedge fund\nmanager, who is paid performance fees with a high-water mark provision, and for\na mutual fund manager, who is paid management fees proportional to the fund's\nassets. The manager invests earned fees in the safe asset, allocating remaining\nprivate wealth in a constant-proportion portfolio, while the fund is managed as\nanother constant-proportion portfolio. The optimal welfare is the maximum\nbetween the optimal welfare of each investment opportunity, with no\ndiversification gain. In particular, the manager does not use private\ninvestments to hedge future income from fees.\n"
    },
    {
        "paper_id": 1208.4831,
        "authors": "Jozef Barunik and Michaela Barunikova",
        "title": "Revisiting the fractional cointegrating dynamics of implied-realized\n  volatility relation with wavelet band spectrum regression",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper revisits the fractional cointegrating relationship between ex-ante\nimplied volatility and ex-post realized volatility. We argue that the concept\nof corridor implied volatility (CIV) should be used instead of the popular\nmodel-free option-implied volatility (MFIV) when assessing the fractional\ncointegrating relation as the latter may introduce bias to the estimation. For\nthe realized volatility, we use recently proposed methods which are robust to\nnoise as well as jumps and interestingly we find that it does not affect the\nimplied-realized volatility relation. In addition, we develop a new tool for\nthe estimation of fractional cointegrating relation between implied and\nrealized volatility based on wavelets, a wavelet band least squares (WBLS). The\nmain advantage of WBLS in comparison to other frequency domain methods is that\nit allows us to work conveniently with potentially non-stationary volatility\ndue to the properties of wavelets. We study the dynamics of the relationship in\nthe time-frequency domain with the wavelet coherence confirming that the\ndependence comes solely from the lower frequencies of the spectra. Motivated by\nthis result we estimate the relationship only on this part of the spectra using\nWBLS and compare our results to the fully modified narrow-band least squares\n(FMNBLS) based on the Fourier frequencies. In the estimation, we use the S&P\n500 and DAX monthly and bi-weekly option prices covering the recent financial\ncrisis and we conclude that in the long-run, volatility inferred from the\noption prices using the corridor implied volatility (CIV) provides an unbiased\nforecast of the realized volatility.\n"
    },
    {
        "paper_id": 1208.5303,
        "authors": "Xavier Warin",
        "title": "Hedging Swing contract on gas markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Swing options on the gas market are american style option where daily\nquantities exercices are constrained and global quantities exerciced each year\nconstrained too. The option holder has to decide each day how much he consumes\nof the quantities satisfying the constraints and tries to use a strategy in\norder to maximize its expected profit. The pay off fonction is a spread between\nthe spot gas market and the value of an index composed of the past average of\nsome commodities spot or future prices. We study the valorization and the\neffectiveness of the dynamic hedging of such a contract.\n"
    },
    {
        "paper_id": 1208.5316,
        "authors": "Paolo Magrassi",
        "title": "How Non-linearity will Transform Information Systems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  One 'problem' with the 21st century world, particularly the economic and\nbusiness worlds, is the phenomenal and increasing number of interconnections\nbetween economic agents (consumers, firms, banks, markets, national economies).\nThis implies that such agents are all interacting and consequently giving raise\nto enormous degrees of non-linearity, a.k.a. complexity. Complexity often\nbrings with it unexpected phenomena, such as chaos and emerging behaviour, that\ncan become challenges for the survival of economic agents and systems.\nDeveloping econophysics approaches are beginning to apply, to the 'economic\nweb', methods and models that have been used in physics and/or systems theory\nto tackle non-linear domains. The paper gives an account of the research in\nprogress in this field and shows its implications for enteprise information\nsystems, anticipating the emergence of software that will allow to reflect the\ncomplexity of the business world, as holistic risk management becomes a mandate\nfor financial institutions and business organizations.\n"
    },
    {
        "paper_id": 1208.5382,
        "authors": "Mihail Turlakov",
        "title": "Wrong-way risk in credit and funding valuation adjustments",
        "comments": "2 figures, submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  Wrong-way risk in counterparty and funding exposures is most dramatic in the\nsituations of systemic crises and tails events. A consistent model of wrong-way\nrisk (WWR) is developed here with the probability-weighted addition of tail\nevents to the calculation of credit valuation and funding valuation adjustments\n(CVA and FVA). This new practical model quantifies the tail risks in the\npricing of CVA and FVA of derivatives and does not rely on a limited concept of\nlinear correlation frequently used in many models. The application of the model\nis illustrated with practical examples of WWR arising in the case of a\nsovereign default for the most common interest-rate and foreign exchange\nderivatives.\n"
    },
    {
        "paper_id": 1208.5398,
        "authors": "Caroline Hillairet and Ying Jiao",
        "title": "Portfolio optimization with insider's initial information and\n  counterparty risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the gain of an insider having private information which concerns the\ndefault risk of a counterparty. More precisely, the default time \\tau is\nmodelled as the first time a stochastic process hits a random barrier L. The\ninsider knows this barrier (as it can be the case for example for the manager\nof the counterparty), whereas standard investors only observe its value at the\ndefault time. All investors aim to maximize the expected utility from terminal\nwealth, on a financial market where the risky asset price is exposed to a\nsudden loss at the default time of the counterparty. In this framework, the\ninsider's information is modelled by using an initial enlargement of filtration\nand \\tau is a stopping time with respect to this enlarged filtration. We prove\nthat the regulator must impose short selling constraints for the insider, in\norder to exclude the value process to reach infinity. We then solve the\noptimization problem and we study the gain of the insider, theoretically and\nnumerically. In general, the insider achieves a larger value of expected\nutility than the standard investor. But in extreme situations for the default\nand loss risks, a standard investor may in average outperform the insider, by\ntaking advantage of an aggressive short selling position which is not allowed\nfor the insider, but at the risk of big losses if the default finally occurs\nafter the maturity.\n"
    },
    {
        "paper_id": 1208.552,
        "authors": "Jos\\'e E. Figueroa-L\\'opez, Ruoting Gong, Christian Houdr\\'e",
        "title": "High-order short-time expansions for ATM option prices of exponential\n  L\\'evy models",
        "comments": "35 pages, 8 figures. This is an extension of our earlier submission\n  arXiv:1112.3111. To appear in Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present work, a novel second-order approximation for ATM option prices\nis derived for a large class of exponential L\\'{e}vy models with or without\nBrownian component. The results hereafter shed new light on the connection\nbetween both the volatility of the continuous component and the jump parameters\nand the behavior of ATM option prices near expiration. In the presence of a\nBrownian component, the second-order term, in time-$t$, is of the form\n$d_{2}\\,t^{(3-Y)/2}$, with $d_{2}$ only depending on $Y$, the degree of jump\nactivity, on $\\sigma$, the volatility of the continuous component, and on an\nadditional parameter controlling the intensity of the \"small\" jumps (regardless\nof their signs). This extends the well known result that the leading\nfirst-order term is $\\sigma t^{1/2}/\\sqrt{2\\pi}$. In contrast, under a\npure-jump model, the dependence on $Y$ and on the separate intensities of\nnegative and positive small jumps are already reflected in the leading term,\nwhich is of the form $d_{1}t^{1/Y}$. The second-order term is shown to be of\nthe form $\\tilde{d}_{2} t$ and, therefore, its order of decay turns out to be\nindependent of $Y$. The asymptotic behavior of the corresponding Black-Scholes\nimplied volatilities is also addressed. Our approach is sufficiently general to\ncover a wide class of L\\'{e}vy processes which satisfy the latter property and\nwhose L\\'{e}vy densitiy can be closely approximated by a stable density near\nthe origin. Our numerical results show that the first-order term typically\nexhibits rather poor performance and that the second-order term can\nsignificantly improve the approximation's accuracy, particularly in the absence\nof a Brownian component.\n"
    },
    {
        "paper_id": 1208.5581,
        "authors": "M. Nabil Kazi-Tani, Dylan Possama\\\"i, Chao Zhou",
        "title": "Quadratic BSDEs with jumps: a fixed-point approach",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we prove the existence of bounded solutions of quadratic\nbackward SDEs with jumps, that is to say for which the generator has quadratic\ngrowth in the variables (z,u). From a technical point of view, we use a direct\nfixed point approach as in Tevzadze [38], which allows us to obtain existence\nand uniqueness of a solution when the terminal condition is small enough. Then,\nthanks to a well-chosen splitting, we recover an existence result for general\nbounded solution. Under additional assumptions, we can obtain stability results\nand a comparison theorem, which as usual implies uniqueness.\n"
    },
    {
        "paper_id": 1208.5802,
        "authors": "Jean-Pierre Fouque, Matthew Lorig, Ronnie Sircar",
        "title": "Second Order Multiscale Stochastic Volatility Asymptotics: Stochastic\n  Terminal Layer Analysis & Calibration",
        "comments": "34 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Multiscale stochastic volatility models have been developed as an efficient\nway to capture the principle effects on derivative pricing and portfolio\noptimization of randomly varying volatility. The recent book Fouque,\nPapanicolaou, Sircar and S{\\o}lna (2011, CUP) analyzes models in which the\nvolatility of the underlying is driven by two diffusions -- one fast\nmean-reverting and one slow-varying, and provides a first order approximation\nfor European option prices and for the implied volatility surface, which is\ncalibrated to market data. Here, we present the full second order asymptotics,\nwhich are considerably more complicated due to a terminal layer near the option\nexpiration time. We find that, to second order, the implied volatility\napproximation depends quadratically on log-moneyness, capturing the convexity\nof the implied volatility curve seen in data. We introduce a new probabilistic\napproach to the terminal layer analysis needed for the derivation of the second\norder singular perturbation term, and calibrate to S&P 500 options data.\n"
    },
    {
        "paper_id": 1208.5896,
        "authors": "Paulette Clippe and Marcel Ausloos",
        "title": "Benford's law and Theil transform of financial data",
        "comments": "23 pages, 3 tables, 52 refs., 8 figures",
        "journal-ref": "Physica A (2012) 6556-6567",
        "doi": "10.1016/j.physa.2012.07.063",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Among econophysics investigations, studies of religious groups have been of\ninterest. On one hand, the present paper concerns the Antoinist community\nfinancial reports, - a community which appeared at the end of the 19-th century\nin Belgium. Several growth-decay regimes have been previously found over\ndifferent time spans. However, there is common suspicion about sect finances.\nIn that spirit, the Antoinist community yearly financial reports, income and\nexpenses, are hereby examined along the so-called Benford's law. The latter is\noften used as a test about possible accounting wrongdoings. On the other hand,\nBenford's law is known to be invariant under scale and base transformation.\nTherefore, as a further test, of both such data and Benford's law use, the\nyearly financial reports are nonlinearly remapped through a sort of Theil\ntransformation, i.e. based on a log-transformation. The resulting data is again\nanalyzed along the Benford's law scheme. Bizarre, puzzling, features are seen.\nHowever, it is emphasized that such a non-linear transformation can shift the\nargument toward a more objective conclusion. In an Appendix, some brief\ndiscussion is made on why the original Theil mapping should not be used. In a\nsecond Appendix, an imperfect Benford's law-like form, - better suited for\nanomalous distributions, is presented.\n"
    },
    {
        "paper_id": 1208.6146,
        "authors": "Liviu-Adrian Cotfas",
        "title": "Finite quantum mechanical model for the stock market",
        "comments": "An alternative version for the finite Fourier transform is now used",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The price of a given stock is exactly known only at the time of sale when the\nstock is between the traders. If we know the price (owner) then we have no\ninformation on the owner (price). A more general description including cases\nwhen we have partial information on both price and ownership is obtained by\nusing the quantum mechanics methods. The relation price-ownership is similar to\nthe relation position-momentum. Our approach is based on the mathematical\nformalism used in the case of quantum systems with finite-dimensional Hilbert\nspace. The linear operator corresponding to the ownership is obtained from the\nlinear operator corresponding to the price by using the finite Fourier\ntransform. In our idealized model, the Schrodinger type equation describing the\ntime evolution of the stock price is solved numerically.\n"
    },
    {
        "paper_id": 1208.6305,
        "authors": "G. Toscani, C. Brugna and S. Demichelis",
        "title": "Kinetic models for the trading of goods",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/s10955-012-0653-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce kinetic equations for the evolution of the\nprobability distribution of two goods among a huge population of agents. The\nleading idea is to describe the trading of these goods by means of some\nfundamental rules in price theory, in particular by using Cobb-Douglas utility\nfunctions for the binary exchange, and the Edgeworth box for the description of\nthe common exchange area in which utility is increasing for both agents. This\nleads to a Boltzmann-type equation in which the post-interaction variables\ndepend in a nonlinear way from the pre-interaction ones. Other models will be\nderived, by suitably linearizing this Boltzmann equation. In presence of\nuncertainty in the exchanges, it is shown that the solution to some of the\nlinearized kinetic equations develop Pareto tails, where the Pareto index\ndepends on the ratio between the gain and the variance of the uncertainty. In\nparticular, the result holds true for the solution of a drift-diffusion\nequation of Fokker-Planck type, obtained from the linear Boltzmann equation as\nthe limit of quasi-invariant trades.\n"
    },
    {
        "paper_id": 1208.6486,
        "authors": "Ariel Neufeld, Marcel Nutz",
        "title": "Superreplication under Volatility Uncertainty for Measurable Claims",
        "comments": "16 pages; forthcoming in 'Electronic Journal of Probability'",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We establish the duality-formula for the superreplication price in a setting\nof volatility uncertainty which includes the example of \"random G-expectation.\"\nIn contrast to previous results, the contingent claim is not assumed to be\nquasi-continuous.\n"
    },
    {
        "paper_id": 1209.0305,
        "authors": "S\\\"oren Christensen, Marc Wittlinger",
        "title": "Optimal relaxed portfolio strategies for growth rate maximization\n  problems with transaction costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we investigate a new class of growth rate maximization problems\nbased on impulse control strategies such that the average number of trades per\ntime unit does not exceed a fixed level. Moreover, we include proportional\ntransaction costs to make the portfolio problem more realistic. We provide a\nVerification Theorem to compute the optimal growth rate as well as an optimal\ntrading strategy. Furthermore, we prove the existence of a constant boundary\nstrategy which is optimal. At the end, we compare our approach to other\ndiscrete-time growth rate maximization problems in numerical examples. It turns\nout that constant boundary strategies with a small average number of trades per\nunit perform nearly as good as the classical optimal solutions with infinite\nactivity.\n"
    },
    {
        "paper_id": 1209.039,
        "authors": "Andreas Neuenkirch and Lukasz Szpruch",
        "title": "First order strong approximations of scalar SDEs with values in a domain",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We are interested in strong approximations of one-dimensional SDEs which have\nnon-Lipschitz coefficients and which take values in a domain. Under a set of\ngeneral assumptions we derive an implicit scheme that preserves the domain of\nthe SDEs and is strongly convergent with rate one. Moreover, we show that this\ngeneral result can be applied to many SDEs we encounter in mathematical finance\nand bio-mathematics. We will demonstrate flexibility of our approach by\nanalysing classical examples of SDEs with sublinear coefficients (CIR, CEV\nmodels and Wright-Fisher diffusion) and also with superlinear coefficients\n(3/2-volatility, Ait-Sahalia model).\n  Our goal is to justify an efficient Multi-Level Monte Carlo (MLMC) method for\na rich family of SDEs, which relies on good strong convergence properties.\n"
    },
    {
        "paper_id": 1209.0424,
        "authors": "Jean-Francois Mercure",
        "title": "On the changeover timescales of technology transitions and induced\n  efficiency changes: an overarching theory",
        "comments": "18 pages, 5 figures, submitted to Technology Forecasting and Social\n  Change",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a general theory that aims at explaining timescales\nobserved empirically in technology transitions and predicting those of future\ntransitions. This framework is used further to derive a theory for exploring\nthe dynamics that underlie the complex phenomenon of irreversible and path\ndependent price or policy induced efficiency changes. Technology transitions\nare known to follow patterns well described by logistic functions, which should\nmore rigorously be modelled mathematically using the Lotka-Volterra family of\ndifferential equations, originally developed to described the population growth\nof competing species. The dynamic evolution of technology has also been\ndescribed theoretically using evolutionary dynamics similar to that observed in\nnature. The theory presented here joins both approaches and presents a\nmethodology for predicting changeover time constants in order to describe real\nsystems of competing technologies. The problem of price or policy induced\nefficiency changes becomes naturally explained using this framework. Examples\nof application are given.\n"
    },
    {
        "paper_id": 1209.0453,
        "authors": "Jean-Philippe Bouchaud (Capital Fund Management)",
        "title": "Crises and collective socio-economic phenomena: simple models and\n  challenges",
        "comments": "Review paper accepted for a special issue of J Stat Phys; several\n  minor improvements along reviewers' comments",
        "journal-ref": null,
        "doi": "10.1007/s10955-012-0687-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial and economic history is strewn with bubbles and crashes, booms and\nbusts, crises and upheavals of all sorts. Understanding the origin of these\nevents is arguably one of the most important problems in economic theory. In\nthis paper, we review recent efforts to include heterogeneities and\ninteractions in models of decision. We argue that the Random Field Ising model\n(RFIM) indeed provides a unifying framework to account for many collective\nsocio-economic phenomena that lead to sudden ruptures and crises. We discuss\ndifferent models that can capture potentially destabilising self-referential\nfeedback loops, induced either by herding, i.e. reference to peers, or\ntrending, i.e. reference to the past, and account for some of the phenomenology\nmissing in the standard models. We discuss some empirically testable\npredictions of these models, for example robust signatures of RFIM-like herding\neffects, or the logarithmic decay of spatial correlations of voting patterns.\nOne of the most striking result, inspired by statistical physics methods, is\nthat Adam Smith's invisible hand can badly fail at solving simple coordination\nproblems. We also insist on the issue of time-scales, that can be extremely\nlong in some cases, and prevent socially optimal equilibria to be reached. As a\ntheoretical challenge, the study of so-called \"detailed-balance\" violating\ndecision rules is needed to decide whether conclusions based on current models\n(that all assume detailed-balance) are indeed robust and generic.\n"
    },
    {
        "paper_id": 1209.0646,
        "authors": "Andreas Haier, Thorsten Pfeiffer",
        "title": "Scenarios and their Aggregation in the Regulatory Risk Measurement\n  Environment",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We define scenarios, propose different methods of aggregating them, discuss\ntheir properties and benchmark them against quadrant requirements.\n"
    },
    {
        "paper_id": 1209.0697,
        "authors": "Matthew Lorig, Oriol Lozano Carbasse, Rafael Mendoza-Arriaga",
        "title": "Variance Swaps on Defaultable Assets and Market Implied Time-Changes",
        "comments": "36 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We compute the value of a variance swap when the underlying is modeled as a\nMarkov process time changed by a L\\'{e}vy subordinator. In this framework, the\nunderlying may exhibit jumps with a state-dependent L\\'{e}vy measure, local\nstochastic volatility and have a local stochastic default intensity. Moreover,\nthe L\\'{e}vy subordinator that drives the underlying can be obtained directly\nby observing European call/put prices. To illustrate our general framework, we\nprovide an explicit formula for the value of a variance swap when the\nunderlying is modeled as (i) a L\\'evy subordinated geometric Brownian motion\nwith default and (ii) a L\\'evy subordinated Jump-to-default CEV process (see\n\\citet{carr-linetsky-1}). {In the latter example, we extend} the results of\n\\cite{mendoza-carr-linetsky-1}, by allowing for joint valuation of credit and\nequity derivatives as well as variance swaps.\n"
    },
    {
        "paper_id": 1209.0708,
        "authors": "Jean-Francois Mercure and Pablo Salas",
        "title": "On the global economic potentials and marginal costs of non-renewable\n  resources and the price of energy commodities",
        "comments": "18 pages, 7 figures, 8 pages of supplementary information",
        "journal-ref": "Energy Policy 63 469-483 (2013)",
        "doi": "10.1016/j.enpol.2013.08.040",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A model is presented in this work for simulating endogenously the evolution\nof the marginal costs of production of energy carriers from non-renewable\nresources, their consumption, depletion pathways and timescales. Such marginal\ncosts can be used to simulate the long term average price formation of energy\ncommodities. Drawing on previous work where a global database of energy\nresource economic potentials was constructed, this work uses cost distributions\nof non-renewable resources in order to evaluate global flows of energy\ncommodities. A mathematical framework is given to calculate endogenous flows of\nenergy resources given an exogenous commodity price path. This framework can be\nused in reverse in order to calculate an exogenous marginal cost of production\nof energy carriers given an exogenous carrier demand. Using rigid price\ninelastic assumptions independent of the economy, these two approaches generate\nlimiting scenarios that depict extreme use of natural resources. This is useful\nto characterise the current state and possible uses of remaining non-renewable\nresources such as fossil fuels and natural uranium. The theory is however\ndesigned for use within economic or technology models that allow technology\nsubstitutions. In this work, it is implemented in the global power sector model\nFTT:Power. Policy implications are given.\n"
    },
    {
        "paper_id": 1209.09,
        "authors": "Lukas Vacha and Karel Janda and Ladislav Kristoufek and David\n  Zilberman",
        "title": "Time-Frequency Dynamics of Biofuels-Fuels-Food System",
        "comments": "16 pages, 5 figures",
        "journal-ref": "Energy Economics 40, pp. 233-241, 2013",
        "doi": "10.1016/j.eneco.2013.06.015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For the first time, we apply the wavelet coherence methodology on biofuels\n(ethanol and biodiesel) and a wide range of related commodities (gasoline,\ndiesel, crude oil, corn, wheat, soybeans, sugarcane and rapeseed oil). This\nway, we are able to investigate dynamics of correlations in time and across\nscales (frequencies) with a model-free approach. We show that correlations\nindeed vary in time and across frequencies. We find two highly correlated pairs\nwhich are strongly connected at low frequencies - ethanol with corn and\nbiodiesel with German diesel - during almost the whole analyzed period\n(2003-2011). Structure of correlations remarkably changes during the food\ncrisis - higher frequencies become important for both mentioned pairs. This\nimplies that during stable periods, ethanol is correlated with corn and\nbiodiesel is correlated with German diesel mainly at low frequencies so that\nthey follow a common long-term trend. However, in the crisis periods, ethanol\n(biodiesel) is lead by corn (German diesel) even at high frequencies (low\nscales), which implies that the biofuels prices react more rapidly to the\nchanges in their producing factors.\n"
    },
    {
        "paper_id": 1209.0959,
        "authors": "Claudio J. Tessone, Antonios Garas, Beniamino Guerra, Frank Schweitzer",
        "title": "How big is too big? Critical Shocks for Systemic Failure Cascades",
        "comments": "23 pages, 7 Figures",
        "journal-ref": "Journal of Statistical Physics, Vol. 151, pp. 765-783 (2013)",
        "doi": "10.1007/s10955-013-0723-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  External or internal shocks may lead to the collapse of a system consisting\nof many agents. If the shock hits only one agent initially and causes it to\nfail, this can induce a cascade of failures among neighoring agents. Several\ncritical constellations determine whether this cascade remains finite or\nreaches the size of the system, i.e. leads to systemic risk. We investigate the\ncritical parameters for such cascades in a simple model, where agents are\ncharacterized by an individual threshold \\theta_i determining their capacity to\nhandle a load \\alpha\\theta_i with 1-\\alpha being their safety margin. If agents\nfail, they redistribute their load equally to K neighboring agents in a regular\nnetwork. For three different threshold distributions P(\\theta), we derive\nanalytical results for the size of the cascade, X(t), which is regarded as a\nmeasure of systemic risk, and the time when it stops. We focus on two different\nregimes, (i) EEE, an external extreme event where the size of the shock is of\nthe order of the total capacity of the network, and (ii) RIE, a random internal\nevent where the size of the shock is of the order of the capacity of an agent.\nWe find that even for large extreme events that exceed the capacity of the\nnetwork finite cascades are still possible, if a power-law threshold\ndistribution is assumed. On the other hand, even small random fluctuations may\nlead to full cascades if critical conditions are met. Most importantly, we\ndemonstrate that the size of the \"big\" shock is not the problem, as the\nsystemic risk only varies slightly for changes of 10 to 50 percent of the\nexternal shock. Systemic risk depends much more on ingredients such as the\nnetwork topology, the safety margin and the threshold distribution, which gives\nhints on how to reduce systemic risk.\n"
    },
    {
        "paper_id": 1209.1321,
        "authors": "Mirta B. Gordon, Jean-Pierre Nadal, Denis Phan and Viktoriya\n  Semeshenko",
        "title": "Entanglement between Demand and Supply in Markets with Bandwagon Goods",
        "comments": "Updated version, accepted for publication, Journal of Statistical\n  Physics, online Dec 2012",
        "journal-ref": null,
        "doi": "10.1007/s10955-012-0660-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Whenever customers' choices (e.g. to buy or not a given good) depend on\nothers choices (cases coined 'positive externalities' or 'bandwagon effect' in\nthe economic literature), the demand may be multiply valued: for a same posted\nprice, there is either a small number of buyers, or a large one -- in which\ncase one says that the customers coordinate. This leads to a dilemma for the\nseller: should he sell at a high price, targeting a small number of buyers, or\nat low price targeting a large number of buyers? In this paper we show that the\ninteraction between demand and supply is even more complex than expected,\nleading to what we call the curse of coordination: the pricing strategy for the\nseller which aimed at maximizing his profit corresponds to posting a price\nwhich, not only assumes that the customers will coordinate, but also lies very\nnear the critical price value at which such high demand no more exists. This is\nobtained by the detailed mathematical analysis of a particular model formally\nrelated to the Random Field Ising Model and to a model introduced in social\nsciences by T C Schelling in the 70's.\n"
    },
    {
        "paper_id": 1209.1544,
        "authors": "Jerzy P. Rydlewski, Ma{\\l}gorzata Snarska",
        "title": "On Geometric Ergodicity of Skewed - SVCHARME models",
        "comments": null,
        "journal-ref": "Statistics & Probability Letters, Volume 84, January 2014, Pages\n  192-197",
        "doi": "10.1016/j.spl.2013.10.008",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Markov Chain Monte Carlo is repeatedly used to analyze the properties of\nintractable distributions in a convenient way. In this paper we derive\nconditions for geometric ergodicity of a general class of nonparametric\nstochastic volatility models with skewness driven by hidden Markov Chain with\nswitching.\n"
    },
    {
        "paper_id": 1209.1705,
        "authors": "Eric Kemp-Benedict",
        "title": "General Equilibrium as a Topological Field Theory",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  General equilibrium is the dominant theoretical framework for economic policy\nanalysis at the level of the whole economy. In practice, general equilibrium\ntreats economies as being always in equilibrium, albeit in a sequence of\nequilibria as driven by external changes in parameters. This view is sometimes\ndefended on the grounds that internal dynamics are fast, while external changes\nare slow, so that the economy can be viewed as adjusting instantaneously to any\nchanged conditions. However, the argument has not been presented in a rigorous\nway. In this paper we show that when conditions are such that: a) economies do\nrespond essentially instantaneously to external influences; b) the external\nchanges are small compared to the values that characterize the economy; and c)\nthe economy's dynamics are continuous and first-order in time (as for Walrasian\ntatonnement), the resulting economic theory is equivalent to a topological\nfield theory. Because it is a topological theory it has no dynamics in a strict\nsense, and so perturbatively---that is, when examining dynamics in the region\nof a critical point---the field theory behaves as general equilibrium posits.\nHowever, the field-theoretic form of the theory admits non-perturbative\ninstanton solutions that link different critical points. Thus, in this theory,\nand in contrast to general equilibrium, the internal dynamics of the model\noccasionally make an appearance in the form of abrupt, noise-driven transitions\nbetween critical points.\n"
    },
    {
        "paper_id": 1209.1791,
        "authors": "Yuri Kifer",
        "title": "Dynkin Games and Israeli Options",
        "comments": "survey article",
        "journal-ref": "ISRN Probability and Statistics 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We start briefly surveying research on optimal stopping games since their\nintroduction by E.B.Dynkin more than 40 years ago. Recent renewed interest to\ndynkin's games is due, in particular, to the study of Israeli (game) options\nintroduced in 2000. We discuss the work on these options and related derivative\nsecurities for the last decade. Among various results on game options we\nconsider error estimates for their discrete approximations, swing game options,\ngame options in markets with transaction costs and other questions.\n"
    },
    {
        "paper_id": 1209.1893,
        "authors": "Masaaki Fujii",
        "title": "Momentum-Space Approach to Asymptotic Expansion for Stochastic Filtering",
        "comments": "revised version for publication in Ann Inst Stat Math",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper develops an asymptotic expansion technique in momentum space for\nstochastic filtering. It is shown that Fourier transformation combined with a\npolynomial-function approximation of the nonlinear terms gives a closed\nrecursive system of ordinary differential equations (ODEs) for the relevant\nconditional distribution. Thanks to the simplicity of the ODE system, higher\norder calculation can be performed easily. Furthermore, solving ODEs\nsequentially with small sub-periods with updated initial conditions makes it\npossible to implement a substepping method for asymptotic expansion in a\nnumerically efficient way. This is found to improve the performance\nsignificantly where otherwise the approximation fails badly. The method is\nexpected to provide a useful tool for more realistic financial modeling with\nunobserved parameters, and also for problems involving nonlinear measure-valued\nprocesses.\n"
    },
    {
        "paper_id": 1209.1903,
        "authors": "Sergei Manzhos",
        "title": "Roles of discount rate, risk premium, and device performance in\n  estimating the cost of energy for photovoltaics",
        "comments": "10 pages, 2 figures",
        "journal-ref": "Int. J. Financ. Stud. 2013, 1(3), 54-61",
        "doi": "10.3390/ijfs1030054",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that different rates should be used for borrowing and discount rates,\nand that the risk-free rate should be used for discounting when assessing and\ncomparing the cost of energy accross diffferent producers and technologies, on\nthe example of photovoltaics. Recent quantitative models using the same rate\nfor borrowing and discounting lead to an underestimation of the cost for risky\nborrowers and to distorted sensitivities of the cost to financial and\nnon-financial factors. Specifically, it is shown that they may lead to gross\nunderestimation of the importance of solar-to-electricity conversion\nefficiency. The importance of device efficiency is re-established under the\ntreatment of the discount rate proposed here. The effects on the cost of energy\nof the installation efficiency and degradation rate, on the discount rate and\nrisk premium as well as on the project lifetime are estimated.\n"
    },
    {
        "paper_id": 1209.1909,
        "authors": "Christoph Reisinger and Rasmus Wissmann",
        "title": "Numerical Valuation of Derivatives in High-Dimensional Settings via PDE\n  Expansions",
        "comments": "32 pages, accepted for publication in Journal of Computational\n  Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we propose a new numerical approach to high-dimensional\npartial differential equations (PDEs) arising in the valuation of exotic\nderivative securities. The proposed method is extended from Reisinger and\nWittum (2007) and uses principal component analysis (PCA) of the underlying\nprocess in combination with a Taylor expansion of the value function into\nsolutions to low-dimensional PDEs. The approximation is related to anchored\nanalysis of variance (ANOVA) decompositions and is expected to be accurate\nwhenever the covariance matrix has one or few dominating eigenvalues. A main\npurpose of the present article is to give a careful analysis of the numerical\naccuracy and computational complexity compared to state-of-the-art Monte Carlo\nmethods on the example of Bermudan swaptions and Ratchet floors, which are\nconsidered difficult benchmark problems. We are able to demonstrate that for\nproblems with medium to high dimensionality and moderate time horizons the\npresented PDE method delivers results comparable in accuracy to the MC methods\nconsidered here in similar or (often significantly) faster runtime.\n"
    },
    {
        "paper_id": 1209.2204,
        "authors": "Ekaterina Svetlova and Henk van Elst (Karlshochschule International\n  University)",
        "title": "How is non-knowledge represented in economic theory?",
        "comments": "18 pages, LaTeX2e, hyperlinked references",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we address the question of how non-knowledge about future\nevents that influence economic agents' decisions in choice settings has been\nformally represented in economic theory up to date. To position our discussion\nwithin the ongoing debate on uncertainty, we provide a brief review of\nhistorical developments in economic theory and decision theory on the\ndescription of economic agents' choice behaviour under conditions of\nuncertainty, understood as either (i) ambiguity, or (ii) unawareness.\nAccordingly, we identify and discuss two approaches to the formalisation of\nnon-knowledge: one based on decision-making in the context of a state space\nrepresenting the exogenous world, as in Savage's axiomatisation and some\nsuccessor concepts (ambiguity as situations with unknown probabilities), and\none based on decision-making over a set of menus of potential future\nopportunities, providing the possibility of derivation of agents' subjective\nstate spaces (unawareness as situation with imperfect subjective knowledge of\nall future events possible). We also discuss impeding challenges of the\nformalisation of non-knowledge.\n"
    },
    {
        "paper_id": 1209.2298,
        "authors": "Nassim N. Taleb",
        "title": "The Future Has Thicker Tails than the Past: Model Error As Branching\n  Counterfactuals",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Ex ante forecast outcomes should be interpreted as counterfactuals (potential\nhistories), with errors as the spread between outcomes. Reapplying measurements\nof uncertainty about the estimation errors of the estimation errors of an\nestimation leads to branching counterfactuals. Such recursions of epistemic\nuncertainty have markedly different distributial properties from conventional\nsampling error. Nested counterfactuals of error rates invariably lead to fat\ntails, regardless of the probability distribution used, and to powerlaws under\nsome conditions. A mere .01% branching error rate about the STD (itself an\nerror rate), and .01% branching error rate about that error rate, etc.\n(recursing all the way) results in explosive (and infinite) higher moments than\n1. Missing any degree of regress leads to the underestimation of small\nprobabilities and concave payoffs (a standard example of which is Fukushima).\nThe paper states the conditions under which higher order rates of uncertainty\n(expressed in spreads of counterfactuals) alters the shapes the of final\ndistribution and shows which a priori beliefs about conterfactuals are needed\nto accept the reliability of conventional probabilistic methods (thin tails or\nmildly fat tails).\n"
    },
    {
        "paper_id": 1209.2467,
        "authors": "Takashi Ichinomiya",
        "title": "Bouchaud-M\\'ezard model on a random network",
        "comments": "to be published in Physical Review E",
        "journal-ref": "Physical Review E, 86, 036111(2012)",
        "doi": "10.1103/PhysRevE.86.036111",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We studied the Bouchaud-M\\'ezard(BM) model, which was introduced to explain\nPareto's law in a real economy, on a random network. Using \"adiabatic and\nindependent\" assumptions, we analytically obtained the stationary probability\ndistribution function of wealth. The results shows that wealth-condensation,\nindicated by the divergence of the variance of wealth, occurs at a larger $J$\nthan that obtained by the mean-field theory, where $J$ represents the strength\nof interaction between agents. We compared our results with numerical\nsimulation results and found that they were in good agreement.\n"
    },
    {
        "paper_id": 1209.2555,
        "authors": "Jan Kallsen, Johannes Muhle-Karbe",
        "title": "Option Pricing and Hedging with Small Transaction Costs",
        "comments": "20 pages, to appear in \"Mathematical Finance\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An investor with constant absolute risk aversion trades a risky asset with\ngeneral It\\^o-dynamics, in the presence of small proportional transaction\ncosts. In this setting, we formally derive a leading-order optimal trading\npolicy and the associated welfare, expressed in terms of the local dynamics of\nthe frictionless optimizer. By applying these results in the presence of a\nrandom endowment, we obtain asymptotic formulas for utility indifference prices\nand hedging strategies in the presence of small transaction costs.\n"
    },
    {
        "paper_id": 1209.2781,
        "authors": "Takashi Ichinomiya",
        "title": "Wealth distribution on complex networks",
        "comments": null,
        "journal-ref": "Physical Review E, 86, 066115(2012)",
        "doi": "10.1103/PhysRevE.86.066115",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the wealth distribution of the Bouchaud--M\\'ezard (BM) model on\ncomplex networks. It has been known that this distribution depends on the\ntopology of network by numerical simulations, however, no one have succeeded to\nexplain it. Using \"adiabatic\" and \"independent\" assumptions along with the\ncentral-limit theorem, we derive equations that determine the probability\ndistribution function. The results are compared to those of simulations for\nvarious networks. We find good agreement between our theory and the\nsimulations, except the case of Watts--Strogatz networks with a low rewiring\nrate, due to the breakdown of independent assumption.\n"
    },
    {
        "paper_id": 1209.2813,
        "authors": "Boris Podobnik, Davor Horvatic, Dror Y. Kenett, H. Eugene Stanley",
        "title": "The competitiveness versus the wealth of a country",
        "comments": "11 pages, 7 figures, accepted for publication in Nature Scientific\n  Reports",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Politicians world-wide frequently promise a better life for their citizens.\nWe find that the probability that a country will increase its {\\it per capita}\nGDP ({\\it gdp}) rank within a decade follows an exponential distribution with\ndecay constant $\\lambda = 0.12$. We use the Corruption Perceptions Index (CPI)\nand the Global Competitiveness Index (GCI) and find that the distribution of\nchange in CPI (GCI) rank follows exponential functions with approximately the\nsame exponent as $\\lambda$, suggesting that the dynamics of {\\it gdp}, CPI, and\nGCI may share the same origin. Using the GCI, we develop a new measure, which\nwe call relative competitiveness, to evaluate an economy's competitiveness\nrelative to its {\\it gdp}. For all European and EU countries during the\n2008-2011 economic downturn we find that the drop in {\\it gdp} in more\ncompetitive countries relative to {\\it gdp} was substantially smaller than in\nrelatively less competitive countries, which is valuable information for\npolicymakers.\n"
    },
    {
        "paper_id": 1209.2817,
        "authors": "Boris Podobnik, Davor Horvatic, Mark Dickison, H. Eugene Stanley",
        "title": "Preferential Attachment in the Interaction between Dynamically Generated\n  Interdependent Networks",
        "comments": "8 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1209/0295-5075/100/50004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We generalize the scale-free network model of Barab\\`asi and Albert [Science\n286, 509 (1999)] by proposing a class of stochastic models for scale-free\ninterdependent networks in which interdependent nodes are not randomly\nconnected but rather are connected via preferential attachment (PA). Each\nnetwork grows through the continuous addition of new nodes, and new nodes in\neach network attach preferentially and simultaneously to (a) well-connected\nnodes within the same network and (b) well-connected nodes in other networks.\nWe present analytic solutions for the power-law exponents as functions of the\nnumber of links both between networks and within networks. We show that a\ncross-clustering coefficient vs. size of network $N$ follows a power law. We\nillustrate the models using selected examples from the Internet and finance.\n"
    },
    {
        "paper_id": 1209.3399,
        "authors": "Li-Xin Zhong, Wen-Juan Xu, Fei Ren, Yong-Dong Shi",
        "title": "Coupled effects of market impact and asymmetric sensitivity in financial\n  markets",
        "comments": "21pages,7figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.01.030",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By incorporating market impact and asymmetric sensitivity into the\nevolutionary minority game, we study the coevolutionary dynamics of stock\nprices and investment strategies in financial markets. Both the stock price\nmovement and the investors' global behavior are found to be closely related to\nthe phase region they fall into. Within the region where the market impact is\nsmall, investors' asymmetric response to gains and losses leads to the\noccurrence of herd behavior, when all the investors are prone to behave\nsimilarly in an extreme way and large price fluctuations occur. A linear\nrelation between the standard deviation of stock price changes and the mean\nvalue of strategies is found. With full market impact, the investors tend to\nself-segregate into opposing groups and the introduction of asymmetric\nsensitivity leads to the disappearance of dominant strategies. Compared with\nthe situations in the stock market with little market impact, the stock price\nfluctuations are suppressed and an efficient market occurs. Theoretical\nanalyses indicate that the mechanism of phase transition from clustering to\nself-segregation in the present model is similar to that in the\nmajority-minority game and the occurrence and disappearance of efficient\nmarkets are related to the competition between the trend-following and the\ntrend-aversion forces. The clustering of the strategies in the present model\nresults from the majority-wins effect and the wealth-driven mechanism makes the\nmarket become predictable.\n"
    },
    {
        "paper_id": 1209.3503,
        "authors": "I. Halperin and A. Itkin",
        "title": "Pricing Illiquid Options with $N+1$ Liquid Proxies Using Mixed\n  Dynamic-Static Hedging",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the problem of optimal pricing and hedging of a European option\nwritten on an illiquid asset $Z$ using a set of proxies: a liquid asset $S$,\nand $N$ liquid European options $P_i$, each written on a liquid asset $Y_i,\ni=1,N$. We assume that the $S$-hedge is dynamic while the multi-name $Y$-hedge\nis static. Using the indifference pricing approach with an exponential utility,\nwe derive a HJB equation for the value function, and build an efficient\nnumerical algorithm. The latter is based on several changes of variables, a\nsplitting scheme, and a set of Fast Gauss Transforms (FGT), which turns out to\nbe more efficient in terms of complexity and lower local space error than a\nfinite-difference method. While in this paper we apply our framework to an\nincomplete market version of the credit-equity Merton's model, the same\napproach can be used for other asset classes (equity, commodity, FX, etc.),\ne.g. for pricing and hedging options with illiquid strikes or illiquid exotic\noptions.\n"
    },
    {
        "paper_id": 1209.3513,
        "authors": "Gechun Liang, Eva L\\\"utkebohmert, Wei Wei",
        "title": "Funding Liquidity, Debt Tenor Structure, and Creditor's Belief: An\n  Exogenous Dynamic Debt Run Model",
        "comments": "36 pages, 9 figures. The article was previously circulated under the\n  title A Continuous Time Structural Model for Insolvency, Recovery, and\n  Rollover Risks in Mathematics and Financial Economics, 2015",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a unified structural credit risk model incorporating both\ninsolvency and illiquidity risks, in order to investigate how a firm's default\nprobability depends on the liquidity risk associated with its financing\nstructure. We assume the firm finances its risky assets by mainly issuing\nshort- and long-term debt. Short-term debt can have either a discrete or a more\nrealistic staggered tenor structure. At rollover dates of short-term debt,\ncreditors face a dynamic coordination problem. We show that a unique threshold\nstrategy (i.e., a debt run barrier) exists for short-term creditors to decide\nwhen to withdraw their funding, and this strategy is closely related to the\nsolution of a non-standard optimal stopping time problem with control\nconstraints. We decompose the total credit risk into an insolvency component\nand an illiquidity component based on such an endogenous debt run barrier\ntogether with an exogenous insolvency barrier.\n"
    },
    {
        "paper_id": 1209.357,
        "authors": "Alois Pichler",
        "title": "Spectral Risk Measures, With Adaptions For Stochastic Optimization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Stochastic optimization problems often involve the expectation in its\nobjective. When risk is incorporated in the problem description as well, then\nrisk measures have to be involved in addition to quantify the acceptable risk,\noften in the objective. For this purpose it is important to have an adjusted,\nadapted and efficient evaluation scheme for the risk measure available. In this\narticle different representations of an important class of risk measures, the\nspectral risk measures, are elaborated. The results allow concise problem\nformulations, they are particularly adapted for stochastic optimization\nproblems. Efficient evaluation algorithms can be built on these new results,\nwhich finally make optimization problems involving spectral risk measures\neligible for stochastic optimization.\n"
    },
    {
        "paper_id": 1209.3982,
        "authors": "Zhang Li and Ilya Pollak",
        "title": "Sparsifying Defaults: Optimal Bailout Policies for Financial Networks in\n  Distress",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The events of the last few years revealed an acute need for tools to\nsystematically model and analyze large financial networks. Many applications of\nsuch tools include the forecasting of systemic failures and analyzing probable\neffects of economic policy decisions. We consider optimizing the amount and\nstructure of a bailout in a borrower-lender network: Given a fixed amount of\ncash to be injected into the system, how should it be distributed among the\nnodes in order to achieve the smallest overall amount of unpaid liabilities or\nthe smallest number of nodes in default? We develop an exact algorithm for the\nproblem of minimizing the amount of unpaid liabilities, by showing that it is\nequivalent to a linear program. For the problem of minimizing the number of\ndefaults, we develop an approximate algorithm using a reweighted l1\nminimization approach. We illustrate this algorithm using an example with\nsynthetic data for which the optimal solution can be calculated exactly, and\nshow through numerical simulation that the solutions calculated by our\nalgorithm are close to optimal.\n"
    },
    {
        "paper_id": 1209.4175,
        "authors": "Ya-Chun Gao, Shi-Min Cai, and Bing-Hong Wang",
        "title": "Hierarchical structure of stock price fluctuations in financial markets",
        "comments": "10 pages, 6 Figures",
        "journal-ref": "J. Stat. Mech. (2012) P12016",
        "doi": "10.1088/1742-5468/2012/12/P12016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The financial market and turbulence have been broadly compared on account of\nthe same quantitative methods and several common stylized facts they shared. In\nthis paper, the She-Leveque (SL) hierarchy, proposed to explain the anomalous\nscaling exponents deviated from Kolmogorov monofractal scaling of the velocity\nfluctuation in fluid turbulence, is applied to study and quantify the\nhierarchical structure of stock price fluctuations in financial markets. We\ntherefore observed certain interesting results: (i) The hierarchical structure\nrelated to multifractal scaling generally presents in all the stock price\nfluctuations we investigated. (ii) The quantitatively statistical parameters\nthat describes SL hierarchy are different between developed financial markets\nand emerging ones, distinctively. (iii) For the high-frequency stock price\nfluctuation, the hierarchical structure varies with different time period. All\nthese results provide a novelty analogy in turbulence and financial market\ndynamics and a insight to deeply understand the multifractality in financial\nmarkets.\n"
    },
    {
        "paper_id": 1209.4449,
        "authors": "Claudio Fontana and Wolfgang J. Runggaldier",
        "title": "Diffusion-based models for financial markets without martingale measures",
        "comments": "35 pages",
        "journal-ref": "Risk Measures and Attitudes (F. Biagini, A. Richter and H.\n  Schlesinger, eds.), Springer, EAA Series, pages 45-81 (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a general class of diffusion-based models and show that, even in\nthe absence of an Equivalent Local Martingale Measure, the financial market may\nstill be viable, in the sense that strong forms of arbitrage are excluded and\nportfolio optimisation problems can be meaningfully solved. Relying partly on\nthe recent literature, we provide necessary and sufficient conditions for\nmarket viability in terms of the market price of risk process and martingale\ndeflators. Regardless of the existence of a martingale measure, we show that\nthe financial market may still be complete and contingent claims can be valued\nunder the original (real-world) probability measure, provided we use as\nnumeraire the Growth-Optimal Portfolio.\n"
    },
    {
        "paper_id": 1209.4517,
        "authors": "Ole Peters and William Klein",
        "title": "Ergodicity breaking in geometric Brownian motion",
        "comments": "5 pages, 3 figures",
        "journal-ref": "Phys. Rev. Lett. 110, 100603 (2013)",
        "doi": "10.1103/PhysRevLett.110.100603",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Geometric Brownian motion (GBM) is a model for systems as varied as financial\ninstruments and populations. The statistical properties of GBM are complicated\nby non-ergodicity, which can lead to ensemble averages exhibiting exponential\ngrowth while any individual trajectory collapses according to its time-average.\nA common tactic for bringing time averages closer to ensemble averages is\ndiversification. In this letter we study the effects of diversification using\nthe concept of ergodicity breaking.\n"
    },
    {
        "paper_id": 1209.4608,
        "authors": "Mahesh S. Khadka, K. M. George, N. Park, J. B. Kim",
        "title": "Performance Analysis of Hybrid Forecasting Model In Stock Market\n  Forecasting",
        "comments": null,
        "journal-ref": "International Journal of Managing Information Technology (IJMIT),\n  Vol. 4, No. 3, August 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents performance analysis of hybrid model comprise of\nconcordance and Genetic Programming (GP) to forecast financial market with some\nexisting models. This scheme can be used for in depth analysis of stock market.\nDifferent measures of concordances such as Kendalls Tau, Ginis Mean Difference,\nSpearmans Rho, and weak interpretation of concordance are used to search for\nthe pattern in past that look similar to present. Genetic Programming is then\nused to match the past trend to present trend as close as possible. Then\nGenetic Program estimates what will happen next based on what had happened\nnext. The concept is validated using financial time series data (S&P 500 and\nNASDAQ indices) as sample data sets. The forecasted result is then compared\nwith standard ARIMA model and other model to analyse its performance.\n"
    },
    {
        "paper_id": 1209.4629,
        "authors": "Harbir Lamba",
        "title": "The Transition from Brownian Motion to Boom-and-Bust Dynamics in\n  Financial and Economic Systems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Quasi-equilibrium models for aggregate variables are widely-used throughout\nfinance and economics. The validity of such models depends crucially upon\nassuming that the systems' participants behave both independently and in a\nMarkovian fashion.\n  We present a simplified market model to demonstrate that herding effects\nbetween agents can cause a transition to boom-and-bust dynamics at realistic\nparameter values. The model can also be viewed as a novel stochastic particle\nsystem with switching and reinjection.\n"
    },
    {
        "paper_id": 1209.4695,
        "authors": "Nikolai Dokuchaev",
        "title": "On statistical indistinguishability of the complete and incomplete\n  markets",
        "comments": "13 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The possibility of statistical evaluation of the market completeness and\nincompleteness is investigated for continuous time diffusion stock market\nmodels. It is known that the market completeness is not a robust property:\nsmall random deviations of the coefficients convert a complete market model\ninto a incomplete one. The paper shows that market incompleteness is also\nnon-robust: small deviations can convert an incomplete model into a complete\none. More precisely, it is shown that, for any incomplete market from a wide\nclass of models, there exists a complete market model with arbitrarily close\npaths of the stock prices and the market parameters. This leads to a\ncounterintuitive conclusion that the incomplete markets are indistinguishable\nfrom the complete markets in the terms of the market statistics.\n"
    },
    {
        "paper_id": 1209.4718,
        "authors": "Juho Kanniainen and Robert Pich\\'e",
        "title": "Stock Price Dynamics and Option Valuations under Volatility Feedback\n  Effect",
        "comments": "23 pages, 7 figures, 2 tables",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.10.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  According to the volatility feedback effect, an unexpected increase in\nsquared volatility leads to an immediate decline in the price-dividend ratio.\nIn this paper, we consider the properties of stock price dynamics and option\nvaluations under the volatility feedback effect by modeling the joint dynamics\nof stock price, dividends, and volatility in continuous time. Most importantly,\nour model predicts the negative effect of an increase in squared return\nvolatility on the value of deep-in-the-money call options and, furthermore,\nattempts to explain the volatility puzzle. We theoretically demonstrate a\nmechanism by which the market price of diffusion return risk, or an equity\nrisk-premium, affects option prices and empirically illustrate how to identify\nthat mechanism using forward-looking information on option contracts. Our\ntheoretical and empirical results support the relevance of the volatility\nfeedback effect. Overall, the results indicate that the prevailing practice of\nignoring the time-varying dividend yield in option pricing can lead to\noversimplification of the stock market dynamics.\n"
    },
    {
        "paper_id": 1209.4787,
        "authors": "F. Clementi, M. Gallegati, G. Kaniadakis",
        "title": "A generalized statistical model for the size distribution of wealth",
        "comments": "LaTeX2e; 23 pages with 6 figures; corrected typos",
        "journal-ref": "Journal of Statistical Mechanics: Theory and Experiment, 6\n  December 2012, start page: P12006",
        "doi": "10.1088/1742-5468/2012/12/P12006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a recent paper in this journal [J. Stat. Mech. (2009) P02037] we proposed\na new, physically motivated, distribution function for modeling individual\nincomes having its roots in the framework of the k-generalized statistical\nmechanics. The performance of the k-generalized distribution was checked\nagainst real data on personal income for the United States in 2003. In this\npaper we extend our previous model so as to be able to account for the\ndistribution of wealth. Probabilistic functions and inequality measures of this\ngeneralized model for wealth distribution are obtained in closed form. In order\nto check the validity of the proposed model, we analyze the U.S. household\nwealth distributions from 1984 to 2009 and conclude an excellent agreement with\nthe data that is superior to any other model already known in the literature.\n"
    },
    {
        "paper_id": 1209.4849,
        "authors": "Shilei Wang",
        "title": "Iterated Function Systems with Economic Applications",
        "comments": null,
        "journal-ref": "Czech Econ. Rev. 9 (2015), no. 3, 155-168",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work's purpose is to understand the dynamics of some social systems\nwhose properties can be captured by certain iterated function systems. To\nachieve this intension, we start from the theory of iterated function systems,\nand then we study two specific economic models on random utility function and\noptimal stochastic growth.\n"
    },
    {
        "paper_id": 1209.5175,
        "authors": "Christian Bayer and Bezirgen Veliyev",
        "title": "Utility Maximization in a Binomial Model with transaction costs: a\n  Duality Approach Based on the Shadow Price Process",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of optimizing the expected logarithmic utility of the\nvalue of a portfolio in a binomial model with proportional transaction costs\nwith a long time horizon. By duality methods, we can find expressions for the\nboundaries of the no-trade-region and the asymptotic optimal growth rate, which\ncan be made explicit for small transaction costs. Here we find that, contrary\nto the classical results in continuous time, the size of the no-trade-region as\nwell as the asymptotic growth rate depend analytically on the level of\ntransaction costs, implying a linear first order effect of perturbations of\n(small) transaction costs. We obtain the asymptotic expansion by an almost\nexplicit construction of the shadow price process.\n"
    },
    {
        "paper_id": 1209.519,
        "authors": "Sebastien Valeyre, Denis Grebenkov, Sofiane Aboura, and Qian Liu",
        "title": "The Reactive Volatility Model",
        "comments": null,
        "journal-ref": "Quant. Finance 13, 1697-1706 (2013)",
        "doi": "10.1080/14697688.2013.797594",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new volatility model, simple to implement, that includes a\nleverage effect whose return-volatility correlation function fits to empirical\nobservations. This model is able to capture both the \"retarded effect\" induced\nby the specific risk, and the \"panic effect\", which occurs whenever systematic\nrisk becomes the dominant factor. Consequently, in contrast to a GARCH model\nand a standard volatility estimate from the squared returns, this new model is\nas reactive as the implied volatility: the model adjusts itself in an\ninstantaneous way to each variation of the single stock price or the stock\nindex price and the adjustment is highly correlated to implied volatility\nchanges. We also test the reactivity of our model using extreme events taken\nfrom the 470 most liquid European stocks over the last decade. We show that the\nreactive volatility model is more robust to extreme events, and it allows for\nthe identification of precursors and replicas of extreme events.\n"
    },
    {
        "paper_id": 1209.5881,
        "authors": "Alessio Emanuele Biondo, Alessandro Pluchino, Andrea Rapisarda",
        "title": "The beneficial role of random strategies in social and financial systems",
        "comments": "18 pages, 7 figures, Accepted for publication in Journal of\n  Statistical Physics",
        "journal-ref": "Journal of Statistical Physics (2013) 151:607-622",
        "doi": "10.1007/s10955-013-0691-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we focus on the beneficial role of random strategies in social\nsciences by means of simple mathematical and computational models. We briefly\nreview recent results obtained by two of us in previous contributions for the\ncase of the Peter principle and the efficiency of a Parliament. Then, we\ndevelop a new application of random strategies to the case of financial trading\nand discuss in detail our findings about forecasts of markets dynamics.\n"
    },
    {
        "paper_id": 1209.5953,
        "authors": "Stephane Goutte and Armand Ngoupeyou",
        "title": "Optimization problem and mean variance hedging on defaultable claims",
        "comments": "34 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the pricing and the hedging of claim {\\psi} which depends on the\ndefault times of two firms A and B. In fact, we assume that, in the market, we\ncan not buy or sell any defaultable bond of the firm B but we can only trade\ndefaultable bond of the firm A. Our aim is then to find the best price and\nhedging of {\\psi} using only bond of the firm A. Hence, we solve this problem\nin two cases: firstly in a Markov framework using indifference price and\nsolving a system of Hamilton-Jacobi-Bellman equations, secondly, in a more\ngeneral framework, using the mean variance hedging approach and solving\nbackward stochastic differential equations (BSDE).\n"
    },
    {
        "paper_id": 1209.5976,
        "authors": "Alexandru Badescu, Robert J. Elliott, Juan-Pablo Ortega",
        "title": "Quadratic hedging schemes for non-Gaussian GARCH models",
        "comments": "26 pages, 6 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose different schemes for option hedging when asset returns are\nmodeled using a general class of GARCH models. More specifically, we implement\nlocal risk minimization and a minimum variance hedge approximation based on an\nextended Girsanov principle that generalizes Duan's (1995) delta hedge. Since\nthe minimal martingale measure fails to produce a probability measure in this\nsetting, we construct local risk minimization hedging strategies with respect\nto a pricing kernel. These approaches are investigated in the context of\nnon-Gaussian driven models. Furthermore, we analyze these methods for\nnon-Gaussian GARCH diffusion limit processes and link them to the corresponding\ndiscrete time counterparts. A detailed numerical analysis based on S&P 500\nEuropean Call options is provided to assess the empirical performance of the\nproposed schemes. We also test the sensitivity of the hedging strategies with\nrespect to the risk neutral measure used by recomputing some of our results\nwith an exponential affine pricing kernel.\n"
    },
    {
        "paper_id": 1209.6369,
        "authors": "Marco Lagi and Yaneer Bar-Yam",
        "title": "The European debt crisis: Defaults and market equilibrium",
        "comments": "35 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  During the last two years, Europe has been facing a debt crisis, and Greece\nhas been at its center. In response to the crisis, drastic actions have been\ntaken, including the halving of Greek debt. Policy makers acted because\ninterest rates for sovereign debt increased dramatically. High interest rates\nimply that default is likely due to economic conditions. High interest rates\nalso increase the cost of borrowing and thus cause default to be likely. If\nthere is a departure from equilibrium, increasing interest rates may contribute\nto---rather than be caused by---default risk. Here we build a quantitative\nequilibrium model of sovereign default risk that, for the first time, is able\nto determine if markets are consistently set by economic conditions. We show\nthat over the period 2001-2012, the annually-averaged long-term interest rates\nof Greek debt are quantitatively related to the ratio of debt to GDP. The\nrelationship shows that the market consistently expects default to occur if the\nGreek debt reaches twice the GDP. Our analysis does not preclude\nnon-equilibrium increases in interest rates over shorter timeframes. We find\nevidence of such non-equilibrium fluctuations in a separate analysis. According\nto the equilibrium model, the date by which a half-default must occur is March\n2013, almost one year after the actual debt write-down. Any acceleration of\ndefault by non-equilibrium fluctuations is significant for national and\ninternational interventions. The need for austerity or bailout costs would be\nreduced if market regulations were implemented to increase market stability to\nprevent short term interest rate increases. We similarly evaluate the timing of\nprojected defaults without interventions for Portugal, Ireland, Spain and Italy\nto be March 2013, April 2014, May 2014, and July 2016, respectively. All\ndefaults are mitigated by planned interventions.\n"
    },
    {
        "paper_id": 1209.6376,
        "authors": "Marco Lagi, Yavni Bar-Yam and Yaneer Bar-Yam",
        "title": "UPDATE July 2012 | The Food Crises: The US Drought",
        "comments": "6 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent droughts in the midwestern United States threaten to cause global\ncatastrophe driven by a speculator amplified food price bubble. Here we show\nthe effect of speculators on food prices using a validated quantitative model\nthat accurately describes historical food prices. During the last six years,\nhigh and fluctuating food prices have lead to widespread hunger and social\nunrest. While a relative dip in food prices occurred during the spring of 2012,\na massive drought in the American Midwest in June and July threatens to trigger\nanother crisis. In a previous paper, we constructed a model that quantitatively\nagreed with food prices and demonstrated that, while the behavior could not be\nexplained by supply and demand economics, it could be parsimoniously and\naccurately described by a model which included both the conversion of corn into\nethanol and speculator trend following. An update to the original paper in\nFebruary 2012 demonstrated that the model previously published was predictive\nof the ongoing price dynamics, and anticipated a new food crisis by the end of\n2012 if adequate policy actions were not implemented. Here we provide a second\nupdate, evaluating the effects of the current drought on global food prices. We\nfind that the drought may trigger the expected third food price bubble to occur\nsooner, before new limits to speculation are scheduled to take effect. Reducing\nthe amount of corn that is being converted to ethanol may address the immediate\ncrisis. Over the longer term, market stabilization requires limiting financial\nspeculation.\n"
    },
    {
        "paper_id": 1209.6385,
        "authors": "Haluk Yener",
        "title": "Maximising Survival, Growth, and Goal Reaching Under Borrowing\n  Constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we consider three problems related to survival, growth, and\ngoal reaching maximization of an investment portfolio with proportional net\ncash flow. We solve the problems in a market constrained due to borrowing\nprohibition. To solve the problems, we first construct an auxiliary market and\nthen apply the dynamic programming approach. Via our solutions, an alternative\napproach is introduced in order to solve the problems defined under an\nauxiliary market.\n"
    },
    {
        "paper_id": 1209.6439,
        "authors": "Sara Biagini and Mustafa Pinar",
        "title": "The best gain-loss ratio is a poor performance measure",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The gain-loss ratio is known to enjoy very good properties from a normative\npoint of view. As a confirmation, we show that the best market gain-loss ratio\nin the presence of a random endowment is an acceptability index and we provide\nits dual representation for general probability spaces. However, the gain-loss\nratio was designed for finite $\\Omega$, and works best in that case. For\ngeneral $\\Omega$ and in most continuous time models, the best gain-loss is\neither infinite or fails to be attained. In addition, it displays an odd\nbehaviour due to the scale invariance property, which does not seem desirable\nin this context. Such weaknesses definitely prove that the (best) gain-loss is\na poor performance measure.\n"
    },
    {
        "paper_id": 1209.6459,
        "authors": "Nicol\\'o Musmeci, Stefano Battiston, Guido Caldarelli, Michelangelo\n  Puliga, Andrea Gabrielli",
        "title": "Bootstrapping topology and systemic risk of complex network using the\n  fitness model",
        "comments": "17 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1007/s10955-013-0720-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a novel method to reconstruct complex network from partial\ninformation. We assume to know the links only for a subset of the nodes and to\nknow some non-topological quantity (fitness) characterising every node. The\nmissing links are generated on the basis of the latter quan- tity according to\na fitness model calibrated on the subset of nodes for which links are known. We\nmeasure the quality of the reconstruction of several topological properties,\nsuch as the network density and the degree distri- bution as a function of the\nsize of the initial subset of nodes. Moreover, we also study the resilience of\nthe network to distress propagation. We first test the method on ensembles of\nsynthetic networks generated with the Exponential Random Graph model which\nallows to apply common tools from statistical mechanics. We then test it on the\nempirical case of the World Trade Web. In both cases, we find that a subset of\n10 % of nodes is enough to reconstruct the main features of the network along\nwith its resilience with an error of 5%.\n"
    },
    {
        "paper_id": 1209.6497,
        "authors": "Michael Monoyios",
        "title": "Malliavin calculus method for asymptotic expansion of dual control\n  problems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a technique based on Malliavin-Bismut calculus ideas, for\nasymptotic expansion of dual control problems arising in connection with\nexponential indifference valuation of claims, and with minimisation of relative\nentropy, in incomplete markets. The problems involve optimisation of a\nfunctional of Brownian paths on Wiener space, with the paths perturbed by a\ndrift involving the control. In addition there is a penalty term in which the\ncontrol features quadratically. The drift perturbation is interpreted as a\nmeasure change using the Girsanov theorem, leading to a form of the integration\nby parts formula in which a directional derivative on Wiener space is computed.\nThis allows for asymptotic analysis of the control problem. Applications to\nincomplete It\\^o process markets are given, in which indifference prices are\napproximated in the low risk aversion limit. We also give an application to\nidentifying the minimal entropy martingale measure as a perturbation to the\nminimal martingale measure in stochastic volatility models.\n"
    },
    {
        "paper_id": 1210.0057,
        "authors": "Karol Przanowski and Jolanta Mamczarz",
        "title": "Consumer finance data generator - a new approach to Credit Scoring\n  technique comparison",
        "comments": "21 pages, 9 figures, 7 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper aims to present a general idea of method comparison of Credit\nScoring techniques. Any scorecard can be made in various methods based on\nvariable transformations in the logistic regression model. To make a comparison\nand come up with the proof that one technique is better than another is a big\nchallenge due to the limited availability of data. The same conclusion cannot\nbe guaranteed when using other data from another source. The following research\nchallenge can therefore be formulated: how should the comparison be managed in\norder to get general results that are not biased by particular data? The\nsolution may be in the use of various random data generators. The data\ngenerator uses two approaches: transition matrix and scorings. Here are\npresented both: results of comparison methods and the methodology of these\ncomparison techniques creating. Before building a new model the modeler can\nundertake a comparison exercise that aims at identifying the best method in the\ncase of the particular data. Here are presented various measures of predictive\nmodel like: Gini, Delta Gini, VIF and Max p-value, emphasizing the\nmulti-criteria problem of a \"Good model\". The idea that is being suggested is\nof particular use in the model building process where there are defined complex\ncriteria trying to cover the important problems of model stability over a\nperiod of time, in order to avoid a crisis. Some arguments for choosing Logit\nor WOE approach as the best scorecard technique are presented.\n"
    },
    {
        "paper_id": 1210.0259,
        "authors": "Ioannis Karatzas, Soumik Pal, Mykhaylo Shkolnikov",
        "title": "Systems of Brownian particles with asymmetric collisions",
        "comments": "33 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study systems of Brownian particles on the real line, which interact by\nsplitting the local times of collisions among themselves in an asymmetric\nmanner. We prove the strong existence and uniqueness of such processes and\nidentify them with the collections of ordered processes in a Brownian particle\nsystem, in which the drift coefficients, the diffusion coefficients, and the\ncollision local times for the individual particles are assigned according to\ntheir ranks. These Brownian systems can be viewed as generalizations of those\narising in first-order models for equity markets in the context of stochastic\nportfolio theory, and are able to correct for several shortcomings of such\nmodels while being equally amenable to computations. We also show that, in\naddition to being of interest in their own right, such systems of Brownian\nparticles arise as universal scaling limits of systems of jump processes on the\ninteger lattice with local interactions. A key step in the proof is the\nanalysis of a generalization of Skorokhod maps which include `local times' at\nthe intersection of faces of the nonnegative orthant. The result extends the\nconvergence of TASEP to its continuous analogue. Finally, we identify those\namong the Brownian particle systems which have a probabilistic structure of\ndeterminantal type.\n"
    },
    {
        "paper_id": 1210.057,
        "authors": "Elisabeth Kemajou, Salah-Eldin Mohammed, Antoine Tambue",
        "title": "A Stochastic Delay Model For Pricing Debt And Loan Guarantees:\n  Theoretical Results",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider that the price of a firm follows a non linear stochastic delay\ndifferential equation. We also assume that any claim value whose value depends\non firm value and time follows a non linear stochastic delay differential\nequation. Using self-financed strategy and replication we are able to derive a\nRandom Partial Differential Equation (RPDE) satisfied by any corporate claim\nwhose value is a function of firm value and time. Under specific final and\nboundary conditions, we solve the RPDE for the debt value and loan guarantees\nwithin a single period and homogeneous class of debt.\n"
    },
    {
        "paper_id": 1210.067,
        "authors": "Hideyuki Tanaka, Toshihiro Yamada",
        "title": "Strong Convergence for Euler-Maruyama and Milstein Schemes with\n  Asymptotic Method",
        "comments": "21 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by weak convergence results in the paper of Takahashi and Yoshida\n(2005), we show strong convergence for an accelerated Euler-Maruyama scheme\napplied to perturbed stochastic differential equations. The Milstein scheme\nwith the same acceleration is also discussed as an extended result. The\ntheoretical results can be applied to analyzing the multi-level Monte Carlo\nmethod originally developed by M.B. Giles. Several numerical experiments for\nthe SABR stochastic volatility model are presented in order to confirm the\nefficiency of the schemes.\n"
    },
    {
        "paper_id": 1210.0898,
        "authors": "Yong Tao",
        "title": "Spontaneous Economic Order",
        "comments": "49 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper provides an attempt to formalize Hayek's notion of spontaneous\norder within the framework of the Arrow-Debreu economy. Our study shows that if\na competitive economy is enough fair and free, then a spontaneous economic\norder shall emerge in long-run competitive equilibria so that social members\ntogether occupy an optimal distribution of income. Despite this, the\nspontaneous order might degenerate in the form of economic crises whenever an\nequilibrium economy approaches the extreme competition. Remarkably, such a\ntheoretical framework of spontaneous order provides a bridge linking Austrian\neconomics and Neoclassical economics, where we shall comprehend a truth:\n\"Freedom promotes technological progress\".\n"
    },
    {
        "paper_id": 1210.0968,
        "authors": "Peter C. L. Lin",
        "title": "A New Trinomial Recombination Tree Algorithm and Its Applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A New Trinomial Recombination Tree Algorithm and Its Applications\n"
    },
    {
        "paper_id": 1210.1588,
        "authors": "Philip Z. Maymin",
        "title": "A New Kind of Finance",
        "comments": "13 pages; Forthcoming in \"Irreducibility and Computational\n  Equivalence: 10 Years After Wolfram's A New Kind of Science,\" Hector Zenil,\n  ed., Springer Verlag, 2013",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Finance has benefited from the Wolfram's NKS approach but it can and will\nbenefit even more in the future, and the gains from the influence may actually\nbe concentrated among practitioners who unintentionally employ those principles\nas a group.\n"
    },
    {
        "paper_id": 1210.1598,
        "authors": "Yacine A\\\"it-Sahalia and T. R. Hurd",
        "title": "Portfolio Choice in Markets with Contagion",
        "comments": "32 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of optimal investment and consumption in a class of\nmultidimensional jump-diffusion models in which asset prices are subject to\nmutually exciting jump processes. This captures a type of contagion where each\ndownward jump in an asset's price results in increased likelihood of further\njumps, both in that asset and in the other assets. We solve in closed-form the\ndynamic consumption-investment problem of a log-utility investor in such a\ncontagion model, prove a theorem verifying its optimality and discuss features\nof the solution, including flight-to-quality. The exponential and power utility\ninvestors are also considered: in these cases, the optimal strategy can be\ncharacterized as a distortion of the strategy of a corresponding non-contagion\ninvestor.\n"
    },
    {
        "paper_id": 1210.1625,
        "authors": "Rama Cont, Arseniy Kukanov",
        "title": "Optimal order placement in limit order markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To execute a trade, participants in electronic equity markets may choose to\nsubmit limit orders or market orders across various exchanges where a stock is\ntraded. This decision is influenced by the characteristics of the order flow\nand queue sizes in each limit order book, as well as the structure of\ntransaction fees and rebates across exchanges. We propose a quantitative\nframework for studying this order placement problem by formulating it as a\nconvex optimization problem. This formulation allows to study how the interplay\nbetween the state of order books, the fee structure, order flow properties and\npreferences of a trader determine the optimal placement decision. In the case\nof a single exchange, we derive an explicit solution for the optimal split\nbetween limit and market orders. For the general problem of order placement\nacross multiple exchanges, we propose a stochastic algorithm for computing the\noptimal policy and study the sensitivity of the solution to various parameters\nusing a numerical implementation of the algorithm.\n"
    },
    {
        "paper_id": 1210.1838,
        "authors": "Aleksejus Kononovicius, Vygintas Gontis",
        "title": "Three-state herding model of the financial markets",
        "comments": "11 pages, 3 figures",
        "journal-ref": "EPL 101, 28001 (2013)",
        "doi": "10.1209/0295-5075/101/28001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a Markov jump process with the three-state herding interaction. We\nsee our approach as an agent-based model for the financial markets. Under\ncertain assumptions this agent-based model can be related to the stochastic\ndescription exhibiting sophisticated statistical features. Along with power-law\nprobability density function of the absolute returns we are able to reproduce\nthe fractured power spectral density, which is observed in the high-frequency\nfinancial market data. Given example of consistent agent-based and stochastic\nmodeling will provide background for the further developments in the research\nof complex social systems.\n"
    },
    {
        "paper_id": 1210.1848,
        "authors": "Tiexin Guo, Shien Zhao and Xiaolin Zeng",
        "title": "On random convex analysis -- the analytic foundation of the module\n  approach to conditional risk measures",
        "comments": "69 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To provide a solid analytic foundation for the module approach to conditional\nrisk measures, this paper establishes a complete random convex analysis over\nrandom locally convex modules by simultaneously considering the two kinds of\ntopologies (namely the $(\\varepsilon,\\lambda)$--topology and the locally\n$L^0$-- convex topology). Then, we make use of the advantage of the\n$(\\varepsilon,\\lambda)$--topology and grasp the local property of $L^0$--convex\nconditional risk measures to prove that every $L^{0}$--convex\n$L^{p}$--conditional risk measure ($1\\leq p\\leq+\\infty$) can be uniquely\nextended to an $L^{0}$--convex $L^{p}_{\\mathcal{F}}(\\mathcal{E})$--conditional\nrisk measure and that the dual representation theorem of the former can also be\nregarded as a special case of that of the latter, which shows that the study of\n$L^p$--conditional risk measures can be incorporated into that of\n$L^{p}_{\\mathcal{F}}(\\mathcal{E})$--conditional risk measures. In particular,\nin the process we find that combining the countable concatenation hull of a set\nand the local property of conditional risk measures is a very useful analytic\nskill that may considerably simplify and improve the study of $L^{0}$--convex\nconditional risk measures.\n"
    },
    {
        "paper_id": 1210.1866,
        "authors": "Matyas Barczy, Leif Doering, Zenghu Li, Gyula Pap",
        "title": "On parameter estimation for critical affine processes",
        "comments": "45 pages",
        "journal-ref": "Electronic Journal of Statistics, Vol. 7 (2013) 647-696",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  First we provide a simple set of sufficient conditions for the weak\nconvergence of scaled affine processes with state space $R_+ \\times R^d$. We\nspecialize our result to one-dimensional continuous state branching processes\nwith immigration. As an application, we study the asymptotic behavior of least\nsquares estimators of some parameters of a two-dimensional critical affine\ndiffusion process.\n"
    },
    {
        "paper_id": 1210.1966,
        "authors": "Nassim N. Taleb",
        "title": "How We Tend To Overestimate Powerlaw Tail Exponents",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the presence of a layer of metaprobabilities (from uncertainty concerning\nthe parameters), the asymptotic tail exponent corresponds to the lowest\npossible tail exponent regardless of its probability. The problem explains\n\"Black Swan\" effects, i.e., why measurements tend to chronically underestimate\ntail contributions, rather than merely deliver imprecise but unbiased\nestimates.\n"
    },
    {
        "paper_id": 1210.2021,
        "authors": "Abdul Razaque, Christian Bach, Nyembo salama, Aziz Alotaibi",
        "title": "Fostering Project Scheduling and Controlling Risk Management",
        "comments": "10 pages, 5 figures (International Journal of Business and Social\n  Science)",
        "journal-ref": "International Journal of Business and Social Science Volume 3(14)\n  Special Issue July 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Deployment of emerging technologies and rapid change in industries has\ncreated a lot of risk for initiating the new projects. Many techniques and\nsuggestions have been introduced but still lack the gap from various\nprospective. This paper proposes a reliable project scheduling approach. The\nobjectives of project scheduling approach are to focus on critical chain\nschedule and risk management. Several risks and reservations exist in projects.\nThese critical reservations may not only foil the projects to be finished\nwithin time limit and budget, but also degrades the quality, and operational\nprocess. In the proposed approach, the potential risks of project are\ncritically analyzed. To overcome these potential risks, fuzzy failure mode and\neffect analysis (FMEA) is introduced. In addition, several affects of each risk\nagainst each activity are evaluated. We use Monte Carlo simulation that helps\nto calculate the total time of project. Our approach helps to control risk\nmitigation that is determined using event tree analysis and fault tree\nanalysis. We also implement distribute critical chain schedule for reliable\nscheduling that makes the project to be implemented within defined plan and\nschedule. Finally, adaptive procedure with density (APD) is deployed to get\nreasonable feeding buffer time and project buffer time.\n"
    },
    {
        "paper_id": 1210.2043,
        "authors": "Gregor Wei{\\ss} and Marcus Scheffer",
        "title": "Smooth Nonparametric Bernstein Vine Copulas",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose to use nonparametric Bernstein copulas as bivariate pair-copulas\nin high-dimensional vine models. The resulting smooth and nonparametric vine\ncopulas completely obviate the error-prone need for choosing the pair-copulas\nfrom parametric copula families. By means of a simulation study and an\nempirical analysis of financial market data, we show that our proposed smooth\nnonparametric vine copula model is superior to competing parametric vine models\ncalibrated via Akaike's Information Criterion.\n"
    },
    {
        "paper_id": 1210.2088,
        "authors": "Nicolas Perry (LGM2B), Magali Mauchand (UTT), Alain Bernard (IRCCyN)",
        "title": "Mod\\`eles de co\\^uts en fonderie sable : les limites d'une approche\n  g\\'en\\'erique",
        "comments": null,
        "journal-ref": "Revue Internationale de CFAO et d'informatique graphique et\n  d'informatique graphique 18, 3 (2003) pp. 351-365",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The control of the costs, as soon as possible of the product life cycle,\nbecame a major asset in the competitiveness of the companies confronted with\nthe universalization of competition. After having proposed the problems related\nthis control difficulties, we will present an approach defining a concept of\ncost entity related to the activities of the product to be designed and\nrealized. We will then try to apply this approach to the fields of the sand\ncasting. This work will highlight the hierarchisation difficulties with the\nentities composing the models created as well as the limits of a generic\napproach.\n"
    },
    {
        "paper_id": 1210.2132,
        "authors": "Bojin Zheng, Wenhua Du, Wanneng Shu, Jianmin Wang, Deyi Li",
        "title": "Equalitarian Societies are Economically Impossible",
        "comments": null,
        "journal-ref": "Romanian Journal of Physics 2013 58(7-8):778-789",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The inequality of wealth distribution is a universal phenomenon in the\ncivilized nations, and it is often imputed to the Matthew effect, that is, the\nrich get richer and the poor get poorer. Some philosophers unjustified this\nphenomenon and tried to put the human civilization upon the evenness of wealth.\nNoticing the facts that 1) the emergence of the centralism is the starting\npoint of human civilization, i.e., people in a society were organized\nhierarchically, 2) the inequality of wealth emerges simultaneously, this paper\nproposes a wealth distribution model based on the hidden tree structure from\nthe viewpoint of complex network. This model considers the organized structure\nof people in a society as a hidden tree, and the cooperations among human\nbeings as the transactions on the hidden tree, thereby explains the\ndistribution of wealth. This model shows that the scale-free phenomenon of\nwealth distribution can be produced by the cascade controlling of human\nsociety, that is, the inequality of wealth can parasitize in the social\norganizations, such that any actions in eliminating the unequal wealth\ndistribution would lead to the destroy of social or economic structures,\nresulting in the collapse of the economic system, therefore, would fail in\nvain.\n"
    },
    {
        "paper_id": 1210.2337,
        "authors": "Francesca Biagini, Alessandra Cretarola and Eckhard Platen",
        "title": "Local Risk-Minimization under the Benchmark Approach",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/s11579-014-0115-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the pricing and hedging of derivatives in incomplete financial\nmarkets by considering the local risk-minimization method in the context of the\nbenchmark approach, which will be called benchmarked local risk-minimization.\nWe show that the proposed benchmarked local risk-minimization allows to handle\nunder extremely weak assumptions a much richer modeling world than the\nclassical methodology.\n"
    },
    {
        "paper_id": 1210.2617,
        "authors": "Timothy C. Johnson",
        "title": "The solution of discretionary stopping problems with applications to the\n  optimal timing of investment decisions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a methodology for obtaining explicit solutions to infinite time\nhorizon optimal stopping problems involving general, one-dimensional, It\\^o\ndiffusions, payoff functions that need not be smooth and state-dependent\ndiscounting. This is done within a framework based on dynamic programming\ntechniques employing variational inequalities and links to the probabilistic\napproaches employing $r$-excessive functions and martingale theory. The aim of\nthis paper is to facilitate the the solution of a wide variety of problems,\nparticularly in finance or economics.\n"
    },
    {
        "paper_id": 1210.2953,
        "authors": "Saikat Mukherjee, Farhad Jafari, Jong-Min Kim",
        "title": "Characterization of Differentiable Copulas",
        "comments": "12 pages, 5 figures, Submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes a new class of copulas which characterize the set of all\ntwice continuously differentiable copulas. We show that our proposed new class\nof copulas is a new generalized copula family that include not only asymmetric\ncopulas but also all smooth copula families available in the current\nliterature. Spearman's rho and Kendall's tau for our new Fourier copulas which\nare asymmetric are introduced. Furthermore, an approximation method is\ndiscussed in order to optimize Spearman's rho and the corresponding Kendall's\ntau.\n"
    },
    {
        "paper_id": 1210.3164,
        "authors": "Guglielmo D'Amico, Raimondo Manca and Giovanni Salvi",
        "title": "A Semi-Markov Modulated Interest Rate Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a semi-Markov modulated model of interest rates. We\nassume that the switching process is a semi-Markov process with finite state\nspace E and the modulated process is a diffusive process. We derive recursive\nequations for the higher order moments of the discount factor and we describe a\nMonte Carlo al- gorithm to execute simulations. The results are specialized to\nclassical models as those by Vasicek, Hull and White and CIR with a semi-Markov\nmodulation.\n"
    },
    {
        "paper_id": 1210.3269,
        "authors": "Francesco Picciolo, Tiziano Squartini, Franco Ruzzenenti, Riccardo\n  Basosi, Diego Garlaschelli",
        "title": "The role of distances in the World Trade Web",
        "comments": "Preprint, accepted for SITIS 2012 (http://www.sitis-conf.org/). Final\n  version to be published by IEEE Computer Society as conference proceedings",
        "journal-ref": "in Proceedings of the Eighth International Conference on\n  Signal-Image Technology & Internet-Based Systems (SITIS 2012), pp. 784-792\n  (edited by IEEE) (2013)",
        "doi": "10.1109/SITIS.2012.118",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the economic literature, geographic distances are considered fundamental\nfactors to be included in any theoretical model whose aim is the quantification\nof the trade between countries. Quantitatively, distances enter into the\nso-called gravity models that successfully predict the weight of non-zero trade\nflows. However, it has been recently shown that gravity models fail to\nreproduce the binary topology of the World Trade Web. In this paper a different\napproach is presented: the formalism of exponential random graphs is used and\nthe distances are treated as constraints, to be imposed on a previously chosen\nensemble of graphs. Then, the information encoded in the geographical distances\nis used to explain the binary structure of the World Trade Web, by testing it\non the degree-degree correlations and the reciprocity structure. This leads to\nthe definition of a novel null model that combines spatial and non-spatial\neffects. The effectiveness of spatial constraints is compared to that of\nnonspatial ones by means of the Akaike Information Criterion and the Bayesian\nInformation Criterion. Even if it is commonly believed that the World Trade Web\nis strongly dependent on the distances, what emerges from our analysis is that\ndistances do not play a crucial role in shaping the World Trade Web binary\nstructure and that the information encoded into the reciprocity is far more\nuseful in explaining the observed patterns.\n"
    },
    {
        "paper_id": 1210.3324,
        "authors": "Imre Kondor, Istv\\'an Csabai, G\\'abor Papp, Enys Mones, G\\'abor\n  Czimbalmos, M\\'at\\'e Csaba S\\'andor",
        "title": "Strong random correlations in networks of heterogeneous agents",
        "comments": "28 pages, 17 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Correlations and other collective phenomena in a schematic model of\nheterogeneous binary agents (individual spin-glass samples) are considered on\nthe complete graph and also on 2d and 3d regular lattices. The system's\nstochastic dynamics is studied by numerical simulations. The dynamics is so\nslow that one can meaningfully speak of quasi-equilibrium states. Performing\nmeasurements of correlations in such a quasi-equilibrium state we find that\nthey are random both as to their sign and absolute value, but on average they\nfall off very slowly with distance in all instances that we have studied. This\nmeans that the system is essentially non-local, small changes at one end may\nhave a strong impact at the other. Correlations and other local quantities are\nextremely sensitive to the boundary conditions all across the system, although\nthis sensitivity disappears upon averaging over the samples or partially\naveraging over the agents. The strong, random correlations tend to organize a\nlarge fraction of the agents into strongly correlated clusters that act\ntogether. If we think about this model as a distant metaphor of economic agents\nor bank networks, the systemic risk implications of this tendency are clear:\nany impact on even a single strongly correlated agent will spread, in an\nunforeseeable manner, to the whole system via the strong random correlations.\n"
    },
    {
        "paper_id": 1210.3543,
        "authors": "Raphael Lutz, Michael Spies, Dominik E. Reusser, J\\\"urgen P. Kropp,\n  and Diego Rybski",
        "title": "Characterizing the development of sectoral Gross Domestic Product\n  composition",
        "comments": "7 pages, 4 figures",
        "journal-ref": "Phys. Rev. E 88, 012804 (2013)",
        "doi": "10.1103/PhysRevE.88.012804",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the sectoral composition of a country's GDP, i.e. the\npartitioning into agrarian, industrial, and service sectors. Exploring a simple\nsystem of differential equations we characterize the transfer of GDP shares\nbetween the sectors in the course of economic development. The model fits for\nthe majority of countries providing 4 country-specific parameters. Relating the\nagrarian with the industrial sector, a data collapse over all countries and all\nyears supports the applicability of our approach. Depending on the parameter\nranges, country development exhibits different transfer properties. Most\ncountries follow 3 of 8 characteristic paths. The types are not random but show\ndistinct geographic and development patterns.\n"
    },
    {
        "paper_id": 1210.3678,
        "authors": "Igor Gimenes Cesca and Douglas Duarte Novaes",
        "title": "Physical assets replacement: an analytical approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The economic life of an asset is the optimum length of its usefulness, which\nis the moment that the asset's expenses are minimum. In this paper, the\neconomic life of physical assets, such as industry machine and equipment, can\nbe interpreted as the moment that the minimum is reached by its equivalent\nproperty cost function, defined as the sum of all equivalent capital and\nmaintenance costs during its life.\n  Many authors in classical papers have used principles of engineering economic\nto solve the assets replacement problem. However, in the literature, the main\nattributes found were proved with intuitive ideas instead mathematical\nanalysis. Therefore, in this paper the main goal is to study these principles\nof engineering economic with mathematical techniques.\n  Here, is used non-smooth analysis to classify all the possibilities for the\nminimum of a class of equivalent property cost functions of assets. The minimum\nof these function gives the optimum moment for the asset to be replaced, i.e.,\nits economic life.\n"
    },
    {
        "paper_id": 1210.3716,
        "authors": "Jan Lorenz and Fabian Paetzel and Frank Schweitzer",
        "title": "Redistribution spurs growth by using a portfolio effect on human capital",
        "comments": "12 pages, plus 8 Figures, plus matlab-code to run simulation and\n  produce figure",
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0054904",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We demonstrate by mathematical analysis and systematic computer simulations\nthat redistribution can lead to sustainable growth in a society. The human\ncapital dynamics of each agent is described by a stochastic multiplicative\nprocess which, in the long run, leads to the destruction of individual human\ncapital and the extinction of the individualistic society. When agents are\nlinked by fully-redistributive taxation the situation might turn to individual\ngrowth in the long run. We consider that a government collects a proportion of\nincome and reduces it by a fraction as costs for administration (efficiency\nlosses). The remaining public good is equally redistributed to all agents. We\nderive conditions under which the destruction of human capital can be turned\ninto sustainable growth, despite the losses from the random growth process and\ndespite the administrative costs. Sustainable growth is induced by\nredistribution. This effect could be explained by a simple portfolio-effect\nwhich re-balances individual stochastic processes.\n  The findings are verified for three different tax schemes: proportional tax,\ntaking proportional more from the rich, and proportionally more from the poor.\nWe discuss which of these tax schemes is optimal with respect to maximize\ngrowth under a fixed rate of administrative costs, or with respect to maximize\nthe governmental income. This leads us to some general conclusions about\ngovernmental decisions, the relation to public good games, and the use of\ntaxation in a risk taking society.\n"
    },
    {
        "paper_id": 1210.38,
        "authors": "Nicole Bauerle and Erhan Bayraktar",
        "title": "A Note on Applications of Stochastic Ordering to Control Problems in\n  Insurance and Finance",
        "comments": "To appear in Stochastics. Keywords: Time changed continuous\n  Martingale, Stochastic Ordering, Ruin Problem",
        "journal-ref": null,
        "doi": "10.1080/17442508.2013.778861",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a controlled diffusion process $(X_t)_{t\\ge 0}$ where the\ncontroller is allowed to choose the drift $\\mu_t$ and the volatility $\\sigma_t$\nfrom a set $\\K(x) \\subset \\R\\times (0,\\infty)$ when $X_t=x$. By choosing the\nlargest $\\frac{\\mu}{\\sigma^2}$ at every point in time an extremal process is\nconstructed which is under suitable time changes stochastically larger than any\nother admissible process. This observation immediately leads to a very simple\nsolution of problems where ruin or hitting probabilities have to be minimized.\nUnder further conditions this extremal process also minimizes \"drawdown\"\nprobabilities.\n"
    },
    {
        "paper_id": 1210.3811,
        "authors": "Andrea Pallavicini, Daniele Perini, Damiano Brigo",
        "title": "Funding, Collateral and Hedging: uncovering the mechanics and the\n  subtleties of funding valuation adjustments",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1112.1521",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main result of this paper is a collateralized counterparty valuation\nadjusted pricing equation, which allows to price a deal while taking into\naccount credit and debit valuation adjustments (CVA, DVA) along with margining\nand funding costs, all in a consistent way. Funding risk breaks the bilateral\nnature of the valuation formula. We find that the equation has a recursive\nform, making the introduction of a purely additive funding valuation adjustment\n(FVA) difficult. Yet, we can cast the pricing equation into a set of iterative\nrelationships which can be solved by means of standard least-square Monte Carlo\ntechniques. As a consequence, we find that identifying funding costs and debit\nvaluation adjustments is not tenable in general, contrary to what has been\nsuggested in the literature in simple cases. The assumptions under which\nfunding costs vanish are a very special case of the more general theory. We\ndefine a comprehensive framework that allows us to derive earlier results on\nfunding or counterparty risk as a special case, although our framework is more\nthan the sum of such special cases. We derive the general pricing equation by\nresorting to a risk-neutral approach where the new types of risks are included\nby modifying the payout cash flows. We consider realistic settings and include\nin our models the common market practices suggested by ISDA documentation,\nwithout assuming restrictive constraints on margining procedures and close-out\nnetting rules. In particular, we allow for asymmetric collateral and funding\nrates, and exogenous liquidity policies and hedging strategies.\nRe-hypothecation liquidity risk and close-out amount evaluation issues are also\ncovered. Finally, relevant examples of non-trivial settings illustrate how to\nderive known facts about discounting curves from a robust general framework and\nwithout resorting to ad hoc hypotheses.\n"
    },
    {
        "paper_id": 1210.3814,
        "authors": "A.V. Leonidov, E.L. Rumyantsev",
        "title": "Russian interbank networks: main characteristics and stability with\n  respect to contagion",
        "comments": "To appear in the Proceedings the International Conference\n  \"Instabilities and Control of Excitable Networks: from macro- to nano-\n  systems\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Systemic risks characterizing the Russian overnight interbank market from the\nnetwork point of view are analyzed.\n"
    },
    {
        "paper_id": 1210.3849,
        "authors": "Gareth W. Peters, Alice X. D. Dong, Robert Kohn",
        "title": "A Copula Based Bayesian Approach for Paid-Incurred Claims Models for\n  Non-Life Insurance Reserving",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our article considers the class of recently developed stochastic models that\ncombine claims payments and incurred losses information into a coherent\nreserving methodology. In particular, we develop a family of Heirarchical\nBayesian Paid-Incurred-Claims models, combining the claims reserving models of\nHertig et al. (1985) and Gogol et al. (1993). In the process we extend the\nindependent log-normal model of Merz et al. (2010) by incorporating different\ndependence structures using a Data-Augmented mixture Copula Paid-Incurred\nclaims model.\n  The utility and influence of incorporating both payment and incurred losses\ninto estimating of the full predictive distribution of the outstanding loss\nliabilities and the resulting reserves is demonstrated in the following cases:\n(i) an independent payment (P) data model; (ii) the independent\nPayment-Incurred Claims (PIC) data model of Merz et al. (2010); (iii) a novel\ndependent lag-year telescoping block diagonal Gaussian Copula PIC data model\nincorporating conjugacy via transformation; (iv) a novel data-augmented mixture\nArchimedean copula dependent PIC data model.\n  Inference in such models is developed via a class of adaptive Markov chain\nMonte Carlo sampling algorithms. These incorporate a data-augmentation\nframework utilized to efficiently evaluate the likelihood for the copula based\nPIC model in the loss reserving triangles. The adaptation strategy is based on\nrepresenting a positive definite covariance matrix by the exponential of a\nsymmetric matrix as proposed by Leonard et al. (1992).\n"
    },
    {
        "paper_id": 1210.3851,
        "authors": "P. Del Moral, G. W. Peters, Ch. Verg\\'e",
        "title": "An introduction to particle integration methods: with applications to\n  risk and insurance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Interacting particle methods are increasingly used to sample from complex and\nhigh-dimensional distributions. These stochastic particle integration\ntechniques can be interpreted as an universal acceptance-rejection sequential\nparticle sampler equipped with adaptive and interacting recycling mechanisms.\nPractically, the particles evolve randomly around the space independently and\nto each particle is associated a positive potential function. Periodically,\nparticles with high potentials duplicate at the expense of low potential\nparticle which die. This natural genetic type selection scheme appears in\nnumerous applications in applied probability, physics, Bayesian statistics,\nsignal processing, biology, and information engineering. It is the intention of\nthis paper to introduce them to risk modeling. From a purely mathematical point\nof view, these stochastic samplers can be interpreted as Feynman-Kac particle\nintegration methods. These functional models are natural mathematical\nextensions of the traditional change of probability measures, commonly used to\ndesign an importance sampling strategy. In this article, we provide a brief\nintroduction to the stochastic modeling and the theoretical analysis of these\nparticle algorithms. Then we conclude with an illustration of a subset of such\nmethods to resolve important risk measure and capital estimation in risk and\ninsurance modelling.\n"
    },
    {
        "paper_id": 1210.3865,
        "authors": "Chien-Liang Chen, Chao-Lin Liu, Yuan-Chen Chang, and Hsiang-Ping Tsai",
        "title": "Opinion Mining for Relating Subjective Expressions and Annual Earnings\n  in US Financial Statements",
        "comments": "24 pages, 3 figures, 13 tables, partially appeared in two conference\n  proceedings: (1) Proceedings of the IEEE International Conference on\n  e-Business Engineering 2011 and (2) Proceedings of the 2011 Conference on\n  Technologies and Applications of Artificial Intelligence; Journal of\n  Information Science and Engineering, 29(3), May 2013",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial statements contain quantitative information and manager's\nsubjective evaluation of firm's financial status. Using information released in\nU.S. 10-K filings. Both qualitative and quantitative appraisals are crucial for\nquality financial decisions. To extract such opinioned statements from the\nreports, we built tagging models based on the conditional random field (CRF)\ntechniques, considering a variety of combinations of linguistic factors\nincluding morphology, orthography, predicate-argument structure, syntax, and\nsimple semantics. Our results show that the CRF models are reasonably effective\nto find opinion holders in experiments when we adopted the popular MPQA corpus\nfor training and testing. The contribution of our paper is to identify opinion\npatterns in multiword expressions (MWEs) forms rather than in single word\nforms.\n  We find that the managers of corporations attempt to use more optimistic\nwords to obfuscate negative financial performance and to accentuate the\npositive financial performance. Our results also show that decreasing earnings\nwere often accompanied by ambiguous and mild statements in the reporting year\nand that increasing earnings were stated in assertive and positive way.\n"
    },
    {
        "paper_id": 1210.4,
        "authors": "Christoph K\\\"uhn, Matthias Riedel",
        "title": "Price-Setting of Market Makers: A Filtering Problem with an Endogenous\n  Filtration",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the price-setting problem of market makers under risk neutrality and\nperfect competition in continuous time. Thereby we follow the classic\nGlosten-Milgrom model that defines bid and ask prices as expectations of a true\nvalue of the asset given the market makers' partial information that includes\nthe customers trading decisions. The true value is modeled as a Markov process\nthat can be observed by the customers with some noise at Poisson times.\n  We analyze the price-setting problem in a mathematically rigorous way by\nsolving a filtering problem with an endogenous filtration that depends on the\nbid and ask price process quoted by the market maker. Under some conditions we\nshow existence and uniqueness of the price processes.\n"
    },
    {
        "paper_id": 1210.4129,
        "authors": "Aki-Hiro Sato, Ken Umeno",
        "title": "Towards international E-stat for monitoring the socio-economic\n  activities across the globe",
        "comments": "6 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate relationship between annual electric power consumption per\ncapita and gross domestic production (GDP) per capita for 131 countries. We\nfound that the relationship can be fitted with a power-law function. We examine\nthe relationship for 47 prefectures in Japan. Furthermore, we investigate\nvalues of annual electric power production reported by four international\norganizations. We collected the data from U.S. Energy Information\nAdministration (EIA), Statistics by International Energy Agency (IEA), OECD\nFactbook (Economic, Environmental and Social Statistics), and United Nations\n(UN) Energy Statistics Yearbook. We found that the data structure, values, and\nunit depend on the organizations. This implies that it is further necessary to\nestablish data standards and an organization to collect, store, and distribute\nthe data on socio-economic systems.\n"
    },
    {
        "paper_id": 1210.4461,
        "authors": "Luca D'Acci",
        "title": "Modeling Spatial Equilibrium in Cities: the Isobenefit Lines",
        "comments": "5 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1210.7510",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I propose and briefly define the concept of Urban Isobenefit Lines by using\nfunctions as easy as efficient, whose results can offer a rich tool to use into\nspatial equilibrium analysis involving cities. They are line joining urban\npoints with equal level of positional advantage from city amenities. The\nresults which one obtain by implementing a chosen function, gave specific\nscenarios: numerically described by indicators and graphically visualized by\nefficient city matrix views. This is also a theoretical concept for the Urban\nEconomics theory and Spatial Equilibrium analysis in cities.\n"
    },
    {
        "paper_id": 1210.4643,
        "authors": "Aki-Hiro Sato",
        "title": "Econoinformatics meets Data-Centric Social Sciences",
        "comments": "22 pages, 15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our society has been computerised and globalised due to emergence and spread\nof information and communication technology (ICT). This enables us to\ninvestigate our own socio-economic systems based on large amounts of data on\nhuman activities. In this article, methods of treating complexity arising from\na vast amount of data, and linking data from different sources, are discussed.\nFurthermore, several examples are given of studies into the applications of\neconoinformatics for the Japanese stock exchange, foreign exchange markets,\ndomestic hotel booking data and international flight booking data are shown. It\nis the main message that spatio-temporal information is a key element to\nsynthesise data from different data sources.\n"
    },
    {
        "paper_id": 1210.4713,
        "authors": "Brice Hakwa, Manfred J\\\"ager-Ambro\\.zewicz, Barbara R\\\"udiger",
        "title": "Measuring and Analysing Marginal Systemic Risk Contribution using CoVaR:\n  A Copula Approach",
        "comments": "26 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is devoted to the quantification and analysis of marginal risk\ncontribution of a given single financial institution i to the risk of a\nfinancial system s. Our work expands on the CoVaR concept proposed by Adrian\nand Brunnermeier as a tool for the measurement of marginal systemic risk\ncontribution. We first give a mathematical definition of\nCoVaR_{\\alpha}^{s|L^i=l}. Our definition improves the CoVaR concept by\nexpressing CoVaR_{\\alpha}^{s|L^i=l} as a function of a state l and of a given\nprobability level \\alpha relative to i and s respectively. Based on Copula\ntheory we connect CoVaR_{\\alpha}^{s|L^i=l} to the partial derivatives of Copula\nthrough their probabilistic interpretation and definitions (Conditional\nProbability). Using this we provide a closed formula for the calculation of\nCoVaR_{\\alpha}^{s|L^i=l} for a large class of (marginal) distributions and\ndependence structures (linear and non-linear). Our formula allows a better\nanalysis of systemic risk using CoVaR in the sense that it allows to define\nCoVaR_{\\alpha}^{s|L^i=l} depending on the marginal distributions of the losses\nof i and s respectively and the copula between L^i and L^s. We discuss the\nimplications of this in the context of the quantification and analysis of\nsystemic risk contributions. %some mathematical This makes possible the For\nexample we will analyse the marginal effects of L^i, L^s and C of the risk\ncontribution of i.\n"
    },
    {
        "paper_id": 1210.4837,
        "authors": "Yiling Chen, Mike Ruberry, Jennifer Wortman Vaughan",
        "title": "Designing Informative Securities",
        "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We create a formal framework for the design of informative securities in\nprediction markets. These securities allow a market organizer to infer the\nlikelihood of events of interest as well as if he knew all of the traders'\nprivate signals. We consider the design of markets that are always informative,\nmarkets that are informative for a particular signal structure of the\nparticipants, and informative markets constructed from a restricted selection\nof securities. We find that to achieve informativeness, it can be necessary to\nallow participants to express information that may not be directly of interest\nto the market organizer, and that understanding the participants' signal\nstructure is important for designing informative prediction markets.\n"
    },
    {
        "paper_id": 1210.4853,
        "authors": "Joseph Y. Halpern, Samantha Leung",
        "title": "Weighted Sets of Probabilities and MinimaxWeighted Expected Regret: New\n  Approaches for Representing Uncertainty and Making Decisions",
        "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012). For full version of this article, see\n  arXiv:1302.5681",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a setting where an agent's uncertainty is represented by a set of\nprobability measures, rather than a single measure. Measure-bymeasure updating\nof such a set of measures upon acquiring new information is well-known to\nsuffer from problems; agents are not always able to learn appropriately. To\ndeal with these problems, we propose using weighted sets of probabilities: a\nrepresentation where each measure is associated with a weight, which denotes\nits significance. We describe a natural approach to updating in such a\nsituation and a natural approach to determining the weights. We then show how\nthis representation can be used in decision-making, by modifying a standard\napproach to decision making-minimizing expected regret-to obtain minimax\nweighted expected regret (MWER).We provide an axiomatization that characterizes\npreferences induced by MWER both in the static and dynamic case.\n"
    },
    {
        "paper_id": 1210.49,
        "authors": "Wei Sun, Robin Hanson, Kathryn Blackmond Laskey, Charles Twardy",
        "title": "Probability and Asset Updating using Bayesian Networks for Combinatorial\n  Prediction Markets",
        "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A market-maker-based prediction market lets forecasters aggregate information\nby editing a consensus probability distribution either directly or by trading\nsecurities that pay off contingent on an event of interest. Combinatorial\nprediction markets allow trading on any event that can be specified as a\ncombination of a base set of events. However, explicitly representing the full\njoint distribution is infeasible for markets with more than a few base events.\nA factored representation such as a Bayesian network (BN) can achieve tractable\ncomputation for problems with many related variables. Standard BN inference\nalgorithms, such as the junction tree algorithm, can be used to update a\nrepresentation of the entire joint distribution given a change to any local\nconditional probability. However, in order to let traders reuse assets from\nprior trades while never allowing assets to become negative, a BN based\nprediction market also needs to update a representation of each user's assets\nand find the conditional state in which a user has minimum assets. Users also\nfind it useful to see their expected assets given an edit outcome. We show how\nto generalize the junction tree algorithm to perform all these computations.\n"
    },
    {
        "paper_id": 1210.4901,
        "authors": "Marek Petrik, Dharmashankar Subramanian",
        "title": "An Approximate Solution Method for Large Risk-Averse Markov Decision\n  Processes",
        "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Stochastic domains often involve risk-averse decision makers. While recent\nwork has focused on how to model risk in Markov decision processes using risk\nmeasures, it has not addressed the problem of solving large risk-averse\nformulations. In this paper, we propose and analyze a new method for solving\nlarge risk-averse MDPs with hybrid continuous-discrete state spaces and\ncontinuous action spaces. The proposed method iteratively improves a bound on\nthe value function using a linearity structure of the MDP. We demonstrate the\nutility and properties of the method on a portfolio optimization problem.\n"
    },
    {
        "paper_id": 1210.4973,
        "authors": "Xuqing Huang, Irena Vodenska, Shlomo Havlin, H. Eugene Stanley",
        "title": "Cascading Failures in Bi-partite Graphs: Model for Systemic Risk\n  Propagation",
        "comments": "13 pages, 7 figures",
        "journal-ref": "Scientific Reports 3, Article number: 1219, 2013",
        "doi": "10.1038/srep01219",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  As economic entities become increasingly interconnected, a shock in a\nfinancial network can provoke significant cascading failures throughout the\nsystem. To study the systemic risk of financial systems, we create a bi-partite\nbanking network model composed of banks and bank assets and propose a cascading\nfailure model to describe the risk propagation process during crises. We\nempirically test the model with 2007 US commercial banks balance sheet data and\ncompare the model prediction of the failed banks with the real failed banks\nafter 2007. We find that our model efficiently identifies a significant portion\nof the actual failed banks reported by Federal Deposit Insurance Corporation.\nThe results suggest that this model could be useful for systemic risk stress\ntesting for financial systems. The model also identifies that commercial rather\nthan residential real estate assets are major culprits for the failure of over\n350 US commercial banks during 2008-2011.\n"
    },
    {
        "paper_id": 1210.5046,
        "authors": "St\\'ephane Cr\\'epey, R\\'emi Gerboud, Zorana Grbac and Nathalie Ngor",
        "title": "Counterparty Risk and Funding: The Four Wings of the TVA",
        "comments": "29 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The credit crisis and the ongoing European sovereign debt crisis have\nhighlighted the native form of credit risk, namely the counterparty risk. The\nrelated Credit Valuation Adjustment, (CVA), Debt Valuation Adjustment (DVA),\nLiquidity Valuation Adjustment (LVA) and Replacement Cost (RC) issues, jointly\nreferred to in this paper as Total Valuation Adjustment (TVA), have been\nthoroughly investigated in the theoretical papers [Cr12a] and [Cr12b]. The\npresent work provides an executive summary and numerical companion to these\npapers, through which the TVA pricing problem can be reduced to Markovian\npre-default TVA BSDEs. The first step consists in the counterparty clean\nvaluation of a portfolio of contracts, which is the valuation in a hypothetical\nsituation where the two parties would be risk-free and funded at a risk-free\nrate. In the second step, the TVA is obtained as the value of an option on the\ncounterparty clean value process called Contingent Credit Default Swap (CCDS).\nNumerical results are presented for interest rate swaps in the Vasicek, as well\nas in the inverse Gaussian Hull-White short rate model, also allowing one to\nassess the related model risk issue.\n"
    },
    {
        "paper_id": 1210.5111,
        "authors": "Belkacem Berdjane (LMRS), Sergei Pergamenshchikov (LMRS)",
        "title": "Sequential $\\delta$-optimal consumption and investment for stochastic\n  volatility markets with unknown parameters",
        "comments": "pages:38. arXiv admin note: text overlap with arXiv:1102.1186",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an optimal investment and consumption problem for a Black-Scholes\nfinancial market with stochastic volatility and unknown stock appreciation\nrate. The volatility parameter is driven by an external economic factor modeled\nas a diffusion process of Ornstein-Uhlenbeck type with unknown drift. We use\nthe dynamical programming approach and find an optimal financial strategy which\ndepends on the drift parameter. To estimate the drift coefficient we observe\nthe economic factor $Y$ in an interval $[0,T_0]$ for fixed $T_0>0$, and use\nsequential estimation. We show, that the consumption and investment strategy\ncalculated through this sequential procedure is $\\delta$-optimal.\n"
    },
    {
        "paper_id": 1210.5152,
        "authors": "Roswitha Hofer and Harald Niederreiter",
        "title": "A construction of (t,s)-sequences with finite-row generating matrices\n  using global function fields",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For any prime power $q$ and any dimension $s \\ge 1$, we present a\nconstruction of $(t,s)$-sequences in base $q$ with finite-row generating\nmatrices such that, for fixed $q$, the quality parameter $t$ is asymptotically\noptimal as a function of $s$ as $s \\to \\infty$. This is the first construction\nof $(t,s)$-sequences that yields finite-row generating matrices and\nasymptotically optimal quality parameters at the same time. The construction is\nbased on global function fields. We put the construction into the framework of\n$(u,{\\bf e},s)$-sequences that was recently introduced by Tezuka. In this way\nwe obtain in many cases better discrepancy bounds for the constructed sequences\nthan by previous methods for bounding the discrepancy.\n"
    },
    {
        "paper_id": 1210.5205,
        "authors": "T. Arun",
        "title": "The Merton Problem with a Drawdown Constraint on Consumption",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we work in the framework of the Merton problem but we impose a\ndrawdown constraint on the consumption process. This means that consumption can\nnever fall below a fixed proportion of the running maximum of past consumption.\nIn terms of economic motivation, this constraint represents a type of habit\nformation where the investor is reluctant to let his standard of living fall\ntoo far from the maximum standard achieved to date. We use techniques from\nstochastic optimal control and duality theory to obtain our candidate value\nfunction and optimal controls, which are then verified.\n"
    },
    {
        "paper_id": 1210.539,
        "authors": "Timothy C. Johnson",
        "title": "Ethics and Finance: the role of mathematics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents the contemporary Fundamental Theorem of Asset Pricing as\nbeing equivalent to approaches to pricing that emerged before 1700 in the\ncontext of Virtue Ethics. This is done by considering the history of science\nand mathematics in the thirteenth and seventeenth century. An explanation as to\nwhy these approaches to pricing were forgotten between 1700 and 2000 is given,\nalong with some of the implications on economics of viewing the Fundamental\nTheorem as a product of Virtue Ethics.\n  The Fundamental Theorem was developed in mathematics to establish a `theory'\nthat underpinned the Black-Scholes-Merton approach to pricing derivatives. In\ndoing this, the Fundamental Theorem unified a number of different approaches in\nfinancial economics, this strengthened the status of neo-classical economics\nbased on Consequentialist Ethics. We present an alternative to this narrative.\n"
    },
    {
        "paper_id": 1210.5391,
        "authors": "Christian Bender",
        "title": "Simple arbitrage",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP830 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 5, 2067-2085",
        "doi": "10.1214/11-AAP830",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We characterize absence of arbitrage with simple trading strategies in a\ndiscounted market with a constant bond and several risky assets. We show that\nif there is a simple arbitrage, then there is a 0-admissible one or an obvious\none, that is, a simple arbitrage which promises a minimal riskless gain of\n\\epsilon, if the investor trades at all. For continuous stock models, we\nprovide an equivalent condition for absence of 0-admissible simple arbitrage in\nterms of a property of the fine structure of the paths, which we call \"two-way\ncrossing.\" This property can be verified for many models by the law of the\niterated logarithm. As an application we show that the mixed fractional\nBlack-Scholes model, with Hurst parameter bigger than a half, is free of simple\narbitrage on a compact time horizon. More generally, we discuss the absence of\nsimple arbitrage for stochastic volatility models and local volatility models\nwhich are perturbed by an independent 1/2-H\\\"{o}lder continuous process.\n"
    },
    {
        "paper_id": 1210.5392,
        "authors": "Philipp Doersek, Eskil Hansen",
        "title": "High order splitting schemes with complex timesteps and their\n  application in mathematical finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  High order splitting schemes with complex timesteps are applied to Kolmogorov\nbackward equations stemming from stochastic differential equations in\nStratonovich form. In the setting of weighted spaces, the necessary analyticity\nof the split semigroups can be easily proved. A numerical example from interest\nrate theory, the CIR2 model, is considered. The numerical results are robust\nfor drift-dominated problems, and confirm our theoretical results.\n"
    },
    {
        "paper_id": 1210.5466,
        "authors": "Pietro Siorpaes",
        "title": "Optimal Investment with Stocks and Derivatives",
        "comments": "I have decided to merge this paper with the following one\n  http://arxiv.org/abs/1303.0237 The resulting longer merged article will be\n  posted as http://arxiv.org/abs/1303.0237v2",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the problem of maximizing expected utility from terminal\nwealth combining a static position in derivative securities, which we assume\ncan be traded only at time zero, with a traditional dynamic trading strategy in\nstocks. We work in the framework of a general semi-martingale model and\nconsider a utility function defined on the positive real line.\n"
    },
    {
        "paper_id": 1210.5479,
        "authors": "Lorenzo Torricelli",
        "title": "Valuation of asset and volatility derivatives using decoupled\n  time-changed L\\'evy processes",
        "comments": "30 Pages, 5 Tables, 3 figures. Third revised version: numerical\n  analysis extended",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a general derivative pricing framework which employs\ndecoupled time-changed (DTC) L\\'evy processes to model the underlying asset of\ncontingent claims. A DTC L\\'evy process is a generalized time-changed L\\'evy\nprocess whose continuous and pure jump parts are allowed to follow separate\nrandom time scalings; we devise the martingale structure for a DTC\nL\\'evy-driven asset and revisit many popular models which fall under this\nframework. Postulating different time changes for the underlying L\\'evy\ndecomposition allows to introduce asset price models consistent with the\nassumption of a correlated pair of continuous and jump market activities; we\nstudy one illustrative DTC model having this property by assuming that the\ninstantaneous activity rates follow the the so-called Wishart process. The\ntheory developed is applied to the problem of pricing claims depending not only\non the price or the volatility of an underlying asset, but also to more\nsophisticated derivatives that pay-off on the joint performance of these two\nfinancial variables, like the target volatility option (TVO). We solve the\npricing problem through a Fourier-inversion method; numerical computations\nvalidating our technique are provided.\n"
    },
    {
        "paper_id": 1210.5773,
        "authors": "Rene Carmona, Francois Delarue, Gilles-Edouard Espinosa, and Nizar\n  Touzi",
        "title": "Singular Forward-Backward Stochastic Differential Equations and\n  Emissions Derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce two simple models of forward-backward stochastic differential\nequations with a singular terminal condition and we explain how and why they\nappear naturally as models for the valuation of CO2 emission allowances. Single\nphase cap-and-trade schemes lead readily to terminal conditions given by\nindicator functions of the forward component, and using fine partial\ndifferential equations estimates, we show that the existence theory of these\nequations, as well as the properties of the candidates for solution, depend\nstrongly upon the characteristics of the forward dynamics. Finally, we give a\nfirst order Taylor expansion and show how to numerically calibrate some of\nthese models for the purpose of CO2 option pricing.\n"
    },
    {
        "paper_id": 1210.5781,
        "authors": "Rene Carmona and Kevin Webster",
        "title": "High Frequency Market Making",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Since they were authorized by the U.S. Security and Exchange Commission in\n1998, electronic exchanges have boomed, and by 2010 high frequency trading\naccounted for over 70% of equity trades in the US. Such markets are thought to\nincrease liquidity because of the presence of market makers, who are willing to\ntrade as counterparties at any time, in exchange for a fee, the bid-ask spread.\nIn this paper, we propose an equilibrium model showing how such market makers\nprovide liquidity. The model relies on a codebook for client trades, the\nimplied alpha. After solving the individual clients optimization problems and\nidentifying their implied alphas, we frame the market maker stochastic\noptimization problem as a stochastic control problem with an infinite\ndimensional control variable. Assuming either identical time horizons for all\nthe clients, or a stochastic partial differential equation model for their\nbeliefs, we solve the market maker problem and derive tractable formulas for\nthe optimal strategy and the resulting limit-order book dynamics.\n"
    },
    {
        "paper_id": 1210.5859,
        "authors": "Ertugrul Bayraktar, Ayse Humeyra Bilge",
        "title": "Determination the Parameters of Markowitz Portfolio Optimization Model",
        "comments": "10 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main purpose of this study is the determination of the optimal length of\nthe historical data for the estimation of statistical parameters in Markowitz\nPortfolio Optimization. We present a trading simulation using Markowitz method,\nfor a portfolio consisting of foreign currency exchange rates and selected\nassets from the Istanbul Stock Exchange ISE 30, over the period 2001-2009. In\nthe simulation, the expected returns and the covariance matrix are computed\nfrom historical data observed for past n days and the target returns are chosen\nas multiples of the return of the market index. The trading strategy is to buy\na stock if the simulation resulted in a feasible solution and sell the stock\nafter exactly m days, independently from the market conditions. The actual\nreturns are computed for n and m being equal to 21, 42, 63, 84 and 105 days and\nwe have seen that the best return is obtained when the observation period is 2\nor 3 times the investment period.\n"
    },
    {
        "paper_id": 1210.5987,
        "authors": "Fabio Caccioli, Munik Shrestha, Cristopher Moore, J. Doyne Farmer",
        "title": "Stability analysis of financial contagion due to overlapping portfolios",
        "comments": "25 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Common asset holdings are widely believed to have been the primary vector of\ncontagion in the recent financial crisis. We develop a network approach to the\namplification of financial contagion due to the combination of overlapping\nportfolios and leverage, and we show how it can be understood in terms of a\ngeneralized branching process. By studying a stylized model we estimate the\ncircumstances under which systemic instabilities are likely to occur as a\nfunction of parameters such as leverage, market crowding, diversification, and\nmarket impact. Although diversification may be good for individual\ninstitutions, it can create dangerous systemic effects, and as a result\nfinancial contagion gets worse with too much diversification. Under our model\nthere is a critical threshold for leverage; below it financial networks are\nalways stable, and above it the unstable region grows as leverage increases.\nThe financial system exhibits \"robust yet fragile\" behavior, with regions of\nthe parameter space where contagion is rare but catastrophic whenever it\noccurs. Our model and methods of analysis can be calibrated to real data and\nprovide simple yet powerful tools for macroprudential stress testing.\n"
    },
    {
        "paper_id": 1210.6,
        "authors": "Julien Vedani (SAF), Laurent Devineau (SAF)",
        "title": "Solvency assessment within the ORSA framework: issues and quantitative\n  methodologies",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The implementation of the Own Risk and Solvency Assessment is a critical\nissue raised by Pillar II of Solvency II framework. In particular the Overall\nSolvency Needs calculation left the Insurance companies to define an optimal\nentity-specific solvency constraint on a multi-year time horizon. In a life\ninsurance society framework, the intuitive approaches to answer this problem\ncan sometimes lead to new implementation issues linked to the highly stochastic\nnature of the methodologies used to project a company Net Asset Value over\nseveral years. One alternative approach can be the use of polynomial proxies to\nreplicate the outcomes of this variable throughout the time horizon. Polynomial\nfunctions are already considered as efficient replication methodologies for the\nNet Asset Value over 1 year. The Curve Fitting and Least Squares Monte-Carlo\nprocedures are the best-known examples of such procedures. In this article we\nintroduce a possibility of adaptation for these methodologies to be used on a\nmulti-year time horizon, in order to assess the Overall Solvency Needs.\n"
    },
    {
        "paper_id": 1210.608,
        "authors": "Dominic K. Albino, Karla Z. Bertrand, and Yaneer Bar-Yam",
        "title": "Food for fuel: The price of ethanol",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Conversion of corn to ethanol in the US since 2005 has been a major cause of\nglobal food price increases during that time and has been shown to be\nineffective in achieving US energy independence and reducing environmental\nimpact. We make three key statements to enhance understanding and communication\nabout ethanol production's impact on the food and fuel markets: (1) The amount\nof corn used to produce the ethanol in a gallon of regular gas would feed a\nperson for a day, (2) The production of ethanol is so energy intensive that it\nuses only 20% less fossil fuel than gasoline, and (3) The cost of gas made with\nethanol is actually higher per mile because ethanol reduces gasoline's energy\nper gallon.\n"
    },
    {
        "paper_id": 1210.6197,
        "authors": "Marx Boopathi",
        "title": "Game Theory in Oligopoly",
        "comments": "6 pages",
        "journal-ref": "http://www.ijascse.in/publications-2012--2",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The game theory techniques are used to find the equilibrium of a market. Game\ntheory refers to the ways in which strategic interactions among economic agents\nproduce outcomes with respect to the preferences (or utilities) of those\nagents, where the outcomes in question might have been intended by none of the\nagents. The oligopolistic market structures are taken and how game theory\napplies to them is explained.\n"
    },
    {
        "paper_id": 1210.6201,
        "authors": "Jatin Prasad, Dr Jyoti Singh",
        "title": "A case for FDI in Multi-brand retail in India",
        "comments": "5 pages",
        "journal-ref": "http://www.ijascse.in/publications-2012--2",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  India is ranked as the third most attractive nation for retail investment\namong emerging markets and many MNCs have been looking for the potential\nbenefits to be taken from it. The development of organized retail has the\npotential of generating employment, improvement in technology, development of\nreal estate etc. On the other hand critics of the FDI feel that allowing FDI\nwould jeopardize the unorganized retail sector and would not only adversely\naffect the small retailers and consumers but will give rise to monopolies of\nlarge corporate houses also, which can adversely affect the pricing and\navailability of goods. A case for the prospects for the same is discussed in\nthis paper.\n"
    },
    {
        "paper_id": 1210.6321,
        "authors": "Ryohei Hisano, Didier Sornette, Takayuki Mizuno, Takaaki Ohnishi,\n  Tsutomu Watanabe",
        "title": "High quality topic extraction from business news explains abnormal\n  financial market volatility",
        "comments": "The previous version of this article included an error. This is a\n  revised version",
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0064846",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Understanding the mutual relationships between information flows and social\nactivity in society today is one of the cornerstones of the social sciences. In\nfinancial economics, the key issue in this regard is understanding and\nquantifying how news of all possible types (geopolitical, environmental,\nsocial, financial, economic, etc.) affect trading and the pricing of firms in\norganized stock markets. In this article, we seek to address this issue by\nperforming an analysis of more than 24 million news records provided by\nThompson Reuters and of their relationship with trading activity for 206 major\nstocks in the S&P US stock index. We show that the whole landscape of news that\naffect stock price movements can be automatically summarized via simple\nregularized regressions between trading activity and news information pieces\ndecomposed, with the help of simple topic modeling techniques, into their\n\"thematic\" features. Using these methods, we are able to estimate and quantify\nthe impacts of news on trading. We introduce network-based visualization\ntechniques to represent the whole landscape of news information associated with\na basket of stocks. The examination of the words that are representative of the\ntopic distributions confirms that our method is able to extract the significant\npieces of information influencing the stock market. Our results show that one\nof the most puzzling stylized fact in financial economies, namely that at\ncertain times trading volumes appear to be \"abnormally large,\" can be partially\nexplained by the flow of news. In this sense, our results prove that there is\nno \"excess trading,\" when restricting to times when news are genuinely novel\nand provide relevant financial information.\n"
    },
    {
        "paper_id": 1210.6372,
        "authors": "Olivier Gu\\'eant",
        "title": "Optimal execution and block trade pricing: a general framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we develop a general framework to study optimal execution\nand to price block trades. We prove existence of optimal liquidation strategies\nand we provide regularity results for optimal strategies under very general\nhypotheses. We exhibit a Hamiltonian characterization for the optimal strategy\nthat can be used for numerical approximation. We also focus on the important\ntopic of block trade pricing and we propose a methodology to give a price to\nfinancial (il)liquidity. In particular, we provide a closed-form formula for\nthe price of a block trade when there is no time constraint to liquidate.\n"
    },
    {
        "paper_id": 1210.6481,
        "authors": "Ricardo Lopez-Ruiz",
        "title": "Complex Systems with Trivial Dynamics",
        "comments": "9 gaes, 0 figures; Contributed Talk to ECCS'12 (European Conference\n  of Complex Systems, Brussels, September, 2012)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this communication, complex systems with a near trivial dynamics are\naddressed. First, under the hypothesis of equiprobability in the asymptotic\nequilibrium, it is shown that the (hyper) planar geometry of an $N$-dimensional\nmulti-agent economic system implies the exponential (Boltzmann-Gibss) wealth\ndistribution and that the spherical geometry of a gas of particles implies the\nGaussian (Maxwellian) distribution of velocities. Moreover, two non-linear\nmodels are proposed to explain the decay of these statistical systems from an\nout-of-equilibrium situation toward their asymptotic equilibrium states.\n"
    },
    {
        "paper_id": 1210.6727,
        "authors": "Paul M. N. Feehan and Camelia Pop",
        "title": "Schauder a priori estimates and regularity of solutions to\n  boundary-degenerate elliptic linear second-order partial differential\n  equations",
        "comments": "58 pages, 1 figure. To appear in the Journal of Differential\n  Equations. Incorporates final galley proof corrections corresponding to\n  published version",
        "journal-ref": "Journal of Differential Equations 256 (2014), 895-956",
        "doi": "10.1016/j.jde.2013.08.012",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We establish Schauder a priori estimates and regularity for solutions to a\nclass of boundary-degenerate elliptic linear second-order partial differential\nequations. Furthermore, given a smooth source function, we prove regularity of\nsolutions up to the portion of the boundary where the operator is degenerate.\nDegenerate-elliptic operators of the kind described in our article appear in a\ndiverse range of applications, including as generators of affine diffusion\nprocesses employed in stochastic volatility models in mathematical finance,\ngenerators of diffusion processes arising in mathematical biology, and the\nstudy of porous media.\n"
    },
    {
        "paper_id": 1210.7111,
        "authors": "Gaoyue Guo, Antoine Jacquier, Claude Martini, Leo Neufcourt",
        "title": "Generalised arbitrage-free SVI volatility surfaces",
        "comments": "20 pages, 4 figures. Corrected some typos",
        "journal-ref": null,
        "doi": "10.1137/120900320",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we propose a generalisation of the recent work of Gatheral\nand Jacquier on explicit arbitrage-free parameterisations of implied volatility\nsurfaces. We also discuss extensively the notion of arbitrage freeness and\nRoger Lee's moment formula using the recent analysis by Roper. We further\nexhibit an arbitrage-free volatility surface different from Gatheral's SVI\nparameterisation.\n"
    },
    {
        "paper_id": 1210.7215,
        "authors": "Kylie-Anne Richards, Gareth W. Peters, William Dunsmuir",
        "title": "Heavy-Tailed Features and Empirical Analysis of the Limit Order Book\n  Volume Profiles in Futures Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper poses a few fundamental questions regarding the attributes of the\nvolume profile of a Limit Order Books stochastic structure by taking into\nconsideration aspects of intraday and interday statistical features, the impact\nof different exchange features and the impact of market participants in\ndifferent asset sectors. This paper aims to address the following questions:\n  1. Is there statistical evidence that heavy-tailed sub-exponential volume\nprofiles occur at different levels of the Limit Order Book on the bid and ask\nand if so does this happen on intra or interday time scales ?\n  2.In futures exchanges, are heavy tail features exchange (CBOT, CME, EUREX,\nSGX and COMEX) or asset class (government bonds, equities and precious metals)\ndependent and do they happen on ultra-high (<1sec) or mid-range (1sec -10min)\nhigh frequency data?\n  3.Does the presence of stochastic heavy-tailed volume profile features evolve\nin a manner that would inform or be indicative of market participant behaviors,\nsuch as high frequency algorithmic trading, quote stuffing and price discovery\nintra-daily?\n  4. Is there statistical evidence for a need to consider dynamic behavior of\nthe parameters of models for Limit Order Book volume profiles on an intra-daily\ntime scale ?\n  Progress on aspects of each question is obtained via statistically rigorous\nresults to verify the empirical findings for an unprecedentedly large set of\nfutures market LOB data. The data comprises several exchanges, several futures\nasset classes and all trading days of 2010, using market depth (Type II) order\nbook data to 5 levels on the bid and ask.\n"
    },
    {
        "paper_id": 1210.723,
        "authors": "Zhi Zheng, Richard B. Sowers",
        "title": "A Model of Market Limit Orders By Stochastic PDE's, Parameter\n  Estimation, and Investment Optimization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce a completely continuous and time-variate model of\nthe evolution of market limit orders based on the existence, uniqueness, and\nregularity of the solutions to a type of stochastic partial differential\nequations obtained in Zheng and Sowers (2012). In contrary to several models\nproposed and researched in literature, this model provides complete continuity\nin both time and price inherited from the stochastic PDE, and thus is\nparticularly suitable for the cases where transactions happen in an extremely\nfast pace, such as those delivered by high frequency traders (HFT's).\n  We first elaborate the precise definition of the model with its associated\nparameters, and show its existence and uniqueness from the related mathematical\nresults given a fixed set of parameters. Then we statistically derive parameter\nestimation schemes of the model using maximum likelihood and least\nmean-square-errors estimation methods under certain criteria such as AIC to\naccommodate to variant number of parameters . Finally as a typical economics\nand finance use case of the model we settle the investment optimization problem\nin both static and dynamic sense by analysing the stochastic (It\\^{o})\nevolution of the utility function of an investor or trader who takes the model\nand its parameters as exogenous. Two theorems are proved which provide criteria\nfor determining the best (limit) price and time point to make the transaction.\n"
    },
    {
        "paper_id": 1210.7257,
        "authors": "Alois Pichler, Alexander Shapiro",
        "title": "Uniqueness of Kusuoka Representations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper addresses law invariant coherent risk measures and their Kusuoka\nrepresentations. By elaborating the existence of a minimal representation we\nshow that every Kusuoka representation can be reduced to its minimal\nrepresentation. Uniqueness -- in a sense specified in the paper -- of the risk\nmeasure's Kusuoka representation is derived from this initial result.\n  Further, stochastic order relations are employed to identify the minimal\nKusuoka representation. It is shown that measures in the minimal representation\nare extremal with respect to the order relations. The tools are finally\nemployed to provide the minimal representation for important practical\nexamples. Although the Kusuoka representation is usually given only for\nnonatomic probability spaces, this presentation closes the gap to spaces with\natoms.\n"
    },
    {
        "paper_id": 1210.7329,
        "authors": "Marco Bianchetti",
        "title": "The Zeeman Effect in Finance: Libor Spectroscopy and Basis Risk\n  Management",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Once upon a time there was a classical financial world in which all the\nLibors were equal. Standard textbooks taught that simple relations held, such\nthat, for example, a 6 months Libor Deposit was replicable with a 3 months\nLibor Deposits plus a 3x6 months Forward Rate Agreement (FRA), and that Libor\nwas a good proxy of the risk free rate required as basic building block of\nno-arbitrage pricing theory. Nowadays, in the modern financial world after the\ncredit crunch, some Libors are more equal than others, depending on their rate\ntenor, and classical formulas are history. Banks are not anymore too \"big to\nfail\", Libors are fixed by panels of risky banks, and they are risky rates\nthemselves. These simple empirical facts carry very important consequences in\nderivative's trading and risk management, such as, for example, basis risk,\ncollateralization and regulatory pressure in favour of Central Counterparties.\nSomething that should be carefully considered by anyone managing even a single\nplain vanilla Swap. In this qualitative note we review the problem trying to\nshed some light on this modern animal farm, recurring to an analogy with\nquantum physics, the Zeeman effect.\n"
    },
    {
        "paper_id": 1210.751,
        "authors": "Luca D'Acci",
        "title": "Isobenefit Lines, Breaking Point of equal attraction, Uniformity\n  Benefit, Variety Value and Proximity Value, Preference Gap Gain",
        "comments": "7 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1210.4461",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Isobenefit Lines can offer a certain range of applicability in Location\nTheory and Gravitational Models for Urban and Geography Economics, in\npositional decision processes made by citizens, and, last but not least, in\nland value and property market theories and analysis. The value of a land, or a\nproperty, in a generic k point, is, ceteris paribus, the mirror of the quality,\nattractiveness, benefit characterizing k. Preference Gap Gain (PGG) of a\nperson, is the difference between his Personal Isobenefit Lines and that of the\nmajority of people. In monetary terms, when buying or renting a property, it\ncan become an economic gain or vice versa, and PGG localizes and quantifies\nthis gain.\n"
    },
    {
        "paper_id": 1210.7608,
        "authors": "Olivier Gu\\'eant",
        "title": "Execution and block trade pricing with optimal constant rate of\n  participation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  When executing their orders, investors are proposed different strategies by\nbrokers and investment banks. Most orders are executed using VWAP algorithms.\nOther basic execution strategies include POV (also called PVol) -- for\npercentage of volume --, IS -- implementation shortfall -- or Target Close. In\nthis article dedicated to POV strategies, we develop a liquidation model in\nwhich a trader is constrained to liquidate a portfolio with a constant\nparticipation rate to the market. Considering the functional forms commonly\nused by practitioners for market impact functions, we obtain a closed-form\nexpression for the optimal participation rate. Also, we develop a microfounded\nrisk-liquidity premium that permits to better assess the costs and risks of\nexecution processes and to give a price to a large block of shares. We also\nprovide a thorough comparison between IS strategies and POV strategies in terms\nof risk-liquidity premium.\n"
    },
    {
        "paper_id": 1210.7642,
        "authors": "J. Martin van Zyl",
        "title": "Estimation of the shape parameter of a generalized Pareto distribution\n  based on a transformation to Pareto distributed variables",
        "comments": null,
        "journal-ref": "Journal of Statistical Theory and Practice, 2015, 9(1), pp.\n  171-183",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Random variables of the generalized Pareto distribution, can be transformed\nto that of the Pareto distribution. Explicit expressions exist for the maximum\nlikelihood estimators of the parameters of the Pareto distribution. The\nperformance of the estimation of the shape parameter of generalized Pareto\ndistributed using transformed observations, based on the probability weighted\nmethod is tested. It was found to improve the performance of the probability\nweighted estimator and performs good with respect to bias and MSE.\n"
    },
    {
        "paper_id": 1210.7721,
        "authors": "Harald Niederreiter and Anderson Siang Jing Yeo",
        "title": "Halton-type sequences from global function fields",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/s11425-013-4623-z",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For any prime power $q$ and any dimension $s$, a new construction of\n$(t,s)$-sequences in base $q$ using global function fields is presented. The\nconstruction yields an analog of Halton sequences for global function fields.\nIt is the first general construction of $(t,s)$-sequences that is not based on\nthe digital method. The construction can also be put into the framework of the\ntheory of $(u,e,s)$-sequences that was recently introduced by Tezuka and leads\nin this way to better discrepancy bounds for the constructed sequences.\n"
    },
    {
        "paper_id": 1210.8175,
        "authors": "Ren\\'e A\\\"id (FiME Lab), Luciano Campi (CREST, LAGA), Nicolas\n  Langren\\'e (LPMA), Huy\\^en Pham (CREST, LPMA)",
        "title": "A probabilistic numerical method for optimal multiple switching problem\n  and application to investments in electricity generation",
        "comments": null,
        "journal-ref": "SIAM Journal on Financial Mathematics 5(1) 191-231 (2014)",
        "doi": "10.1137/120897298",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present a probabilistic numerical algorithm combining\ndynamic programming, Monte Carlo simulations and local basis regressions to\nsolve non-stationary optimal multiple switching problems in infinite horizon.\nWe provide the rate of convergence of the method in terms of the time step used\nto discretize the problem, of the size of the local hypercubes involved in the\nregressions, and of the truncating time horizon. To make the method viable for\nproblems in high dimension and long time horizon, we extend a memory reduction\nmethod to the general Euler scheme, so that, when performing the numerical\nresolution, the storage of the Monte Carlo simulation paths is not needed.\nThen, we apply this algorithm to a model of optimal investment in power plants.\nThis model takes into account electricity demand, cointegrated fuel prices,\ncarbon price and random outages of power plants. It computes the optimal level\nof investment in each generation technology, considered as a whole, w.r.t. the\nelectricity spot price. This electricity price is itself built according to a\nnew extended structural model. In particular, it is a function of several\nfactors, among which the installed capacities. The evolution of the optimal\ngeneration mix is illustrated on a realistic numerical problem in dimension\neight, i.e. with two different technologies and six random factors.\n"
    },
    {
        "paper_id": 1210.838,
        "authors": "Thomas Bury",
        "title": "Market structure explained by pairwise interactions",
        "comments": "14 pages, 14 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.10.046",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets are a typical example of complex systems where interactions\nbetween constituents lead to many remarkable features. Here, we show that a\npairwise maximum entropy model (or auto-logistic model) is able to describe\nswitches between ordered (strongly correlated) and disordered market states. In\nthis framework, the influence matrix may be thought as a dissimilarity measure\nand we explain how it can be used to study market structure. We make the link\nwith the graph-theoretic description of stock markets reproducing the\nnon-random and scale-free topology, shrinking length during crashes and\nmeaningful clustering features as expected. The pairwise model provides an\nalternative method to study financial networks which may be useful for\ncharacterization of abnormal market states (crises and bubbles), in capital\nallocation or for the design of regulation rules.\n"
    },
    {
        "paper_id": 1211.013,
        "authors": "Joan del castillo, Jalila Daoudi and Isabel Serra",
        "title": "The full-tails gamma distribution applied to model extreme values",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we show the relationship between the Pareto distribution and\nthe gamma distribution. This shows that the second one, appropriately extended,\nexplains some anomalies that arise in the practical use of extreme value\ntheory. The results are useful to certain phenomena that are fitted by the\nPareto distribution but, at the same time, they present a deviation from this\nlaw for very large values. Two examples of data analysis with the new model are\nprovided. The first one is on the influence of climate variability on the\noccurrence of tropical cyclones. The second one on the analysis of aggregate\nloss distributions associated to operational risk management.\n"
    },
    {
        "paper_id": 1211.0225,
        "authors": "Alberto Elices",
        "title": "The role of the Model Validation function to manage and mitigate model\n  risk",
        "comments": "6 pages, 1 figure, accepted for publication in Bloomberg Risk\n  Newsletter",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper describes the current taxonomy of model risk, ways for its\nmitigation and management and the importance of the model validation function\nin collaboration with other departments to design and implement them.\n"
    },
    {
        "paper_id": 1211.0412,
        "authors": "Giorgio Ferrari",
        "title": "On an integral equation for the free-boundary of stochastic,\n  irreversible investment problems",
        "comments": "Published in at http://dx.doi.org/10.1214/13-AAP991 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 1, 150-176",
        "doi": "10.1214/13-AAP991",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we derive a new handy integral equation for the free-boundary\nof infinite time horizon, continuous time, stochastic, irreversible investment\nproblems with uncertainty modeled as a one-dimensional, regular diffusion $X$.\nThe new integral equation allows to explicitly find the free-boundary\n$b(\\cdot)$ in some so far unsolved cases, as when the operating profit function\nis not multiplicatively separable and $X$ is a three-dimensional Bessel process\nor a CEV process. Our result follows from purely probabilistic arguments.\nIndeed, we first show that $b(X(t))=l^*(t)$, with $l^*$ the unique optional\nsolution of a representation problem in the spirit of Bank-El Karoui [Ann.\nProbab. 32 (2004) 1030-1067]; then, thanks to such an identification and the\nfact that $l^*$ uniquely solves a backward stochastic equation, we find the\nintegral problem for the free-boundary.\n"
    },
    {
        "paper_id": 1211.0443,
        "authors": "Irene Klein, Emmanuel Lepinette and Lavinia Ostafe",
        "title": "Large Financial Markets and Asymptotic Arbitrage with Small Transaction\n  Costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give characterizations of asymptotic arbitrage of the first and second\nkind and of strong asymptotic arbitrage for large financial markets with small\nproportional transaction costs $\\la_n$ on market $n$ in terms of contiguity\nproperties of sequences of equivalent probability measures induced by\n$\\la_n$--consistent price systems. These results are analogous to the\nfrictionless case. Our setting is simple, each market $n$ contains two assets\nwith continuous price processes. The proofs use quantitative versions of the\nHalmos--Savage Theorem and a monotone convergence result of nonnegative local\nmartingales. Moreover, we present an example admitting a strong asymptotic\narbitrage without transaction costs; but with transaction costs $\\la_n>0$ on\nmarket $n$ ($\\la_n\\to0$ not too fast) there does not exist any form of\nasymptotic arbitrage.\n"
    },
    {
        "paper_id": 1211.0707,
        "authors": "Karolina Bujok and Ben Hambly and Christoph Reisinger",
        "title": "Multilevel simulation of functionals of Bernoulli random variables with\n  application to basket credit derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider $N$ Bernoulli random variables, which are independent conditional\non a common random factor determining their probability distribution. We show\nthat certain expected functionals of the proportion $L_N$ of variables in a\ngiven state converge at rate $1/N$ as $N\\rightarrow \\infty$. Based on these\nresults, we propose a multi-level simulation algorithm using a family of\nsequences with increasing length, to obtain estimators for these expected\nfunctionals with a mean-square error of $\\epsilon^2$ and computational\ncomplexity of order $\\epsilon^{-2}$, independent of $N$. In particular, this\noptimal complexity order also holds for the infinite-dimensional limit.\nNumerical examples are presented for tranche spreads of basket credit\nderivatives.\n"
    },
    {
        "paper_id": 1211.0856,
        "authors": "Andrea Macrina",
        "title": "Heat Kernel Framework for Asset Pricing in Finite Time",
        "comments": "34 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A heat kernel approach is proposed for the development of a general,\nflexible, and mathematically tractable asset pricing framework in finite time.\nThe pricing kernel, giving rise to the price system in an incomplete market, is\nmodelled by weighted heat kernels which are driven by multivariate Markov\nprocesses and which provide enough degrees of freedom in order to calibrate to\nrelevant data, e.g. to the term structure of bond prices. It is shown how, for\na class of models, the prices of bonds, caplets, and swaptions can be computed\nin closed form. The dynamical equations for the price processes are derived,\nand explicit formulae are obtained for the short rate of interest, the risk\npremium, and for the stochastic volatility of prices. Several of the\nclosed-form asset price models presented in this paper are driven by\ncombinations of Markovian jump processes with different probability laws. Such\nmodels provide a rich basis for consistent applications in several sectors of a\nfinancial market including equity, fixed-income, commodities, and insurance.\nThe flexible, multidimensional and multivariate structure, on which the asset\nprice models are constructed, lends itself well to the transparent modelling of\ndependence across asset classes. As an illustration, the impact on prices by\nspiralling debt, a typical feature of a financial crisis, is modelled\nexplicitly, and contagion effects are readily observed in the dynamics of asset\nreturns.\n"
    },
    {
        "paper_id": 1211.1285,
        "authors": "Salvatore Federico, Paul Gassiat, Fausto Gozzi",
        "title": "Impact of time illiquidity in a mixed market without full observation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a problem of optimal investment/consumption over an infinite horizon\nin a market consisting of two possibly correlated assets: one liquid and one\nilliquid. The liquid asset is observed and can be traded continuously, while\nthe illiquid one can be traded only at discrete random times corresponding to\nthe jumps of a Poisson process with intensity $\\lambda$, is observed at the\ntrading dates, and is partially observed between two different trading dates.\nThe problem is a nonstandard mixed discrete/continuous optimal control problem\nwhich we face by the dynamic programming approach. When the utility has a\ngeneral form we prove that the value function is the unique viscosity solution\nof the HJB equation and, assuming sufficient regularity of the value function,\nwe give a verification theorem that describes the optimal investment strategies\nfor the illiquid asset. In the case of power utility, we prove the regularity\nof the value function needed to apply the verification theorem, providing the\ncomplete theoretical solution of the problem. This allows us to perform\nnumerical simulation, so to analyze the impact of time illiquidity in this\nmixed market and how this impact is affected by the degree of observation.\n"
    },
    {
        "paper_id": 1211.1286,
        "authors": "Salvatore Federico, Paul Gassiat",
        "title": "Viscosity characterization of the value function of an\n  investment-consumption problem in presence of illiquid assets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a problem of optimal investment/consumption over an infinite horizon\nin a market consisting of a liquid and an illiquid asset. The liquid asset is\nobserved and can be traded continuously, while the illiquid one can only be\ntraded and observed at discrete random times corresponding to the jumps of a\nPoisson process. The problem is a nonstandard mixed discrete/continuous optimal\ncontrol problem which we face by the dynamic programming approach. The main aim\nof the paper is to prove that the value function is the unique viscosity\nsolution of an associated HJB equation. We then use such result to build a\nnumerical algorithm allowing to approximate the value function and so to\nmeasure the cost of illiquidity.\n"
    },
    {
        "paper_id": 1211.1564,
        "authors": "Lorenzo Giada and Claudio Nordio",
        "title": "Funded Bilateral Valuation Adjustment",
        "comments": "10 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show how the cost of funding the collateral in a particular set up can be\nequal to the Bilateral Valuation Adjustment with the \"funded\" probability of\ndefault, leading to the definition of a Funded Bilateral Valuation Adjustment\n(FBVA). That set up can also be viewed by an investor as an effective way to\nrestructure the counterparty risk arising from an uncollateralized transaction\nwith a counterparty, mitigating or even avoiding entirely the additional\ncapital charge introduced by the new Basel III framework.\n"
    },
    {
        "paper_id": 1211.1897,
        "authors": "Dimitri O. Ledenyov and Viktor O. Ledenyov",
        "title": "On the new central bank strategy toward monetary and financial\n  instabilities management in finances: Econophysical analysis of nonlinear\n  dynamical financial systems",
        "comments": "8 pages, 1 table",
        "journal-ref": "The Financial Times, The Bodley Head and The Random House first\n  annual essay competition in London in the U.K. in 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We describe the innovations in finances, introduced over the recent decades,\nand analyze most of the business and regulatory challenges, faced by the\nfinancial industry, because of the present disruptive changes in the global\ncapital markets. We use the integrative thinking approach to formulate the new\ncentral bank strategy and propose that the new strategy has to be focused on\nthe constant management of the monetary and financial instabilities, using the\nknowledge base in the field of econophysics. We propose the new theoretical\nmodel of economics, which is called the Nonlinear Dynamic Stochastic General\nEquilibrium (NDSGE), which takes to the account the nonlinearities, appearing\nduring the interaction between the business cycles. We show that the central\nbanks, which will apply the knowledge gained from the econophysical analysis to\nunderstand the complex processes in the national financial systems in the time\nof high volatility in global capital markets, will be able to govern the\nnational financial systems successfully.\n"
    },
    {
        "paper_id": 1211.1919,
        "authors": "Austin Gerig",
        "title": "High-Frequency Trading Synchronizes Prices in Financial Markets",
        "comments": "6 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  High-speed computerized trading, often called \"high-frequency trading\" (HFT),\nhas increased dramatically in financial markets over the last decade. In the US\nand Europe, it now accounts for nearly one-half of all trades. Although\nevidence suggests that HFT contributes to the efficiency of markets, there are\nconcerns it also adds to market instability, especially during times of stress.\nCurrently, it is unclear how or why HFT produces these outcomes. In this paper,\nI use data from NASDAQ to show that HFT synchronizes prices in financial\nmarkets, making the values of related securities change contemporaneously. With\na model, I demonstrate how price synchronization leads to increased efficiency:\nprices are more accurate and transaction costs are reduced. During times of\nstress, however, localized errors quickly propagate through the financial\nsystem if safeguards are not in place. In addition, there is potential for HFT\nto enforce incorrect relationships between securities, making prices more (or\nless) correlated than economic fundamentals warrant. This research highlights\nan important role that HFT plays in markets and helps answer several puzzling\nquestions that previously seemed difficult to explain: why HFT is so prevalent,\nwhy HFT concentrates in certain securities and largely ignores others, and\nfinally, how HFT can lower transaction costs yet still make profits.\n"
    },
    {
        "paper_id": 1211.1938,
        "authors": "Liviu-Adrian Cotfas",
        "title": "A quantum mechanical model for the rate of return",
        "comments": null,
        "journal-ref": "Romanian Reports in Physics 65 (2013) 327-333",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In their activity, the traders approximate the rate of return by integer\nmultiples of a minimal one. Therefore, it can be regarded as a quantized\nvariable. On the other hand, there is the impossibility of observing the rate\nof return and its instantaneous forward time derivative, even if we consider it\nas a continuous variable. We present a quantum model for the rate of return\nbased on the mathematical formalism used in the case of quantum systems with\nfinite-dimensional Hilbert space. The rate of return is described by a discrete\nwave function and its time evolution by a Schodinger type equation.\n"
    },
    {
        "paper_id": 1211.2078,
        "authors": "Kenan Qiao",
        "title": "Market Liquidity and Convexity of Order Book (Evidence From China)",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Market liquidity plays a vital role in the field of market micro-structure,\nbecause it is the vigor of the financial market. This paper uses a variable\ncalled convexity to measure the potential liquidity provided by order-book.\nBased on the high-frequency data of each stock included in the SSE (Shanghai\nStock Exchange) 50 Index for the year 2011, we report several statistical\nproperties of convexity and analyze the association between convexity and some\nother important variables (bid/ask-depth, spread, volatility, return.)\n"
    },
    {
        "paper_id": 1211.2709,
        "authors": "Barbora Voln\\'a",
        "title": "Can we explain unexpected fluctuations of long-term real interest rate?",
        "comments": "24 pages, 13 figures. arXiv admin note: substantial text overlap with\n  arXiv:1203.1020",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present own point of view how the unexpected fluctuations\nof the long-term real interest rate can be explained. We describe a\nmacroeconomic environment by the modification of the fundamental macroeconomic\nequilibrium model called the IS-LM model. Last but not least, we suggest a\npossible cooperation between the fiscal and monetary policy to reduce these\nfluctuations. Our modelling is demonstrated on an illustrative example.\n"
    },
    {
        "paper_id": 1211.2754,
        "authors": "Kenan Qiao",
        "title": "Coal Enterprise Management and Asynchronism of Return",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For researching the association between coal enterprise management and return\nin financial market, this paper applies the method of time difference relevance\nand PageRank method to seek the leader-index of a stock set containing 21 coal\nenterprises in A-share market and score those stocks. Based on the return in\n2011, the asynchronism of the return series is revealed and presents a\nhierarchical structure of our stock set. Finally, we compare the result with\nthe firm-level variables and discuss the relation between them. The results\nshow that those large coal enterprises with a good management condition always\npresent an antecedence of stock return; there is a significant positive\nassociation between company scale and the score given by PageRank method.\n"
    },
    {
        "paper_id": 1211.2862,
        "authors": "Jingzhao Qi, and Huijie Yang",
        "title": "Hurst Exponents For Short Time Series",
        "comments": "6 pages, 4 figures",
        "journal-ref": "Physical Review E 84,066114 (2011)",
        "doi": "10.1103/PhysRevE.84.066114",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new concept, called balanced estimator of diffusion entropy, is proposed to\ndetect scalings in short time series. The effectiveness of the method is\nverified by means of a large number of artificial fractional Brownian motions.\nIt is used also to detect scaling properties and structural breaks in stock\nprice series of Shanghai Stock market.\n"
    },
    {
        "paper_id": 1211.306,
        "authors": "H.F. Coronel-Brizio, A.R. Hern\\'andez Montoya, H.R Olivares S\\'anchez,\n  E. Scalas",
        "title": "Analysis of short term price trends in daily stock-market index data",
        "comments": "7 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In financial time series there are periods in which the value increases or\ndecreases monotonically. We call those periods elemental trends and study the\nprobability distribution of their duration for the indices DJIA, NASDAQ and\nIPC. It is found that the trend duration distribution often differs from the\none expected under no memory. The expected and observed distributions are\ncompared by means of the Anderson-Darling test.\n"
    },
    {
        "paper_id": 1211.3102,
        "authors": "Timothy J. Garrett",
        "title": "Can we predict long-run economic growth?",
        "comments": null,
        "journal-ref": "Garrett, T. J., 2012: Can we predict long-run economic growth?,\n  Retirement Management Journal 2(2) 53-61",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For those concerned with the long-term value of their accounts, it can be a\nchallenge to plan in the present for inflation-adjusted economic growth over\ncoming decades. Here, I argue that there exists an economic constant that\ncarries through time, and that this can help us to anticipate the more distant\nfuture: global economic wealth has a fixed link to civilization's overall rate\nof energy consumption from all sources; the ratio of these two quantities has\nnot changed over the past 40 years that statistics are available. Power\nproduction and wealth rise equally quickly because civilization, like any other\nsystem in the universe, must consume and dissipate its energy reserves in order\nto sustain its current size. One perspective might be that financial wealth\nmust ultimately collapse as we deplete our energy reserves. However, we can\nalso expect that highly aggregated quantities like global wealth have inertia,\nand that growth rates must persist. Exceptionally rapid innovation in the two\ndecades following 1950 allowed for unprecedented acceleration of\ninflation-adjusted rates of return. But today, real innovation rates are more\nstagnant. This means that, over the coming decade or so, global GDP and wealth\nshould rise fairly steadily at an inflation-adjusted rate of about 2.2% per\nyear.\n"
    },
    {
        "paper_id": 1211.3599,
        "authors": "Janusz Mi\\'skiewicz",
        "title": "Network analysis of correlation strength between the most developed\n  countries",
        "comments": "submitted to Acta Physica Polonica A",
        "journal-ref": null,
        "doi": "10.12693/APhysPolA.123.589",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new algorithm of the analysis of correlation among economy time series is\nproposed. The algorithm is based on the power law classification scheme (PLCS)\nfollowed by the analysis of the network on the percolation threshold (NPT). The\nalgorithm was applied to the analysis of correlations among GDP per capita time\nseries of 19 most developed countries in the periods (1982, 2011), (1992, 2011)\nand (2002, 2011). The representative countries with respect to strength of\ncorrelation, convergence of time series and stability of correlation are\ndistinguished. The results are compared with ultrametric distance matrix\nanalysed by NPT.\n"
    },
    {
        "paper_id": 1211.3824,
        "authors": "Karine Michalon (CEREG)",
        "title": "Les r\\'eservations et les suspensions de cotation sont-elles un frein\n  \\`a l'efficience informationnelle des march\\'es ?",
        "comments": null,
        "journal-ref": "Option Finance, 1182 (2012) 9",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The use of the trading halts is a practice common to all markets. However,\nthe advantages and the disadvantages of the measurements are regularly\ndiscussed. The partisans think that the trading suspensions or the price limits\nmake it possible to the investors to have time to react to the new information.\nThe detractors think that the trading halts are barriers with the trade. A\ntheorical debate thus continued with an empirical discussion. The results of\nthis study appear relatively scattered. It is today difficult to draw a general\nconclusion as for the effectiveness of the trading halts.\n"
    },
    {
        "paper_id": 1211.4108,
        "authors": "Dimitri O. Ledenyov and Viktor O. Ledenyov",
        "title": "On the Risk Management with Application of Econophysics Analysis in\n  Central Banks and Financial Institutions",
        "comments": "10 pages",
        "journal-ref": "The Financial Times, The Bodley Head and The Random House first\n  annual essay competition in London in the UK in 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this research article is to discover how the econophysics\nanalysis can complement the econometrics models in application to the risk\nmanagement in the central banks and financial institutions, operating within\nthe nonlinear dynamical financial system. We consider the modern risk\nmanagement models and show the appropriate techniques to calculate the various\nexisting risks in the finances. We make a few comments on the possible\nlimitations in the models of statistical modeling of volatility such as the\nAutoregressive Conditional Heteroskedasticity (GARCH) model, because of the\nnonlinearities appearance in the nonlinear dynamical financial systems. We\npropose that the various types of nonlinearities, which can originate in the\nfinancial and economical systems, have to be taken to the detailed\nconsideration during the Cost of Capital calculation in the finances and\neconomics. We propose the new theory of nonlinear dynamic volatilities and the\nnew nonlinear dynamic chaos (NDC) volatility model for the statistical modeling\nof financial volatility with the aim to determine the Value at Risk.\n"
    },
    {
        "paper_id": 1211.4157,
        "authors": "Alexis Fauth (SAMM), Ciprian A. Tudor (LPP)",
        "title": "Modeling First Line Of An Order Book With Multivariate Marked Point\n  Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new model in order to describe the fluctuation of tick-by-tick\nfinancial time series. Our model, based on marked point process, allows us to\nincorporate in a unique process the duration of the transaction and the\ncorresponding volume of orders. The model is motivated by the fact that the\n\"excitation\" of the market is different in periods of time with low exchanged\nvolume and high volume exchanged. We illustrate our result by numerical\nsimulations on foreign exchange data sampling in millisecond. By checking the\nmain stylized facts, we show that the model is consistent with the empirical\ndata. We also find an interesting relation between the distribution of the\nvolume of limited order and the volume of market orders. To conclude, we\npropose an application to risk management and we introduce a forecast\nprocedure.\n"
    },
    {
        "paper_id": 1211.4173,
        "authors": "Manfred Jaeger-Ambrozewicz",
        "title": "Closed form solutions of measures of systemic risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper derives -- considering a Gaussian setting -- closed form solutions\nof the statistics that Adrian and Brunnermeier and Acharya et al. have\nsuggested as measures of systemic risk to be attached to individual banks. The\nstatistics equal the product of statistic specific Beta-coefficients with the\nmean corrected Value at Risk. Hence, the measures of systemic risks are closely\nrelated to well known concepts of financial economics. Another benefit of the\nanalysis is that it is revealed how the concepts are related to each other.\nAlso, it may be relatively easy to convince the regulators to consider a closed\nform solution, especially so if the statistics involved are well known and can\neasily be communicated to the financial community.\n"
    },
    {
        "paper_id": 1211.4282,
        "authors": "Victor Chernozhukov, Emre Kocatulum, Konrad Menzel",
        "title": "Inference on Sets in Finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider the problem of inference on a class of sets\ndescribing a collection of admissible models as solutions to a single smooth\ninequality. Classical and recent examples include, among others, the\nHansen-Jagannathan (HJ) sets of admissible stochastic discount factors,\nMarkowitz-Fama (MF) sets of mean-variances for asset portfolio returns, and the\nset of structural elasticities in Chetty (2012)'s analysis of demand with\noptimization frictions. We show that the econometric structure of the problem\nallows us to construct convenient and powerful confidence regions based upon\nthe weighted likelihood ratio and weighted Wald (directed weighted Hausdorff)\nstatistics. The statistics we formulate differ (in part) from existing\nstatistics in that they enforce either exact or first order equivariance to\ntransformations of parameters, making them especially appealing in the target\napplications. Moreover, the resulting inference procedures are also more\npowerful than the structured projection methods, which rely upon building\nconfidence sets for the frontier-determining sufficient parameters (e.g.\nfrontier-spanning portfolios), and then projecting them to obtain confidence\nsets for HJ sets or MF sets. Lastly, the framework we put forward is also\nuseful for analyzing intersection bounds, namely sets defined as solutions to\nmultiple smooth inequalities, since multiple inequalities can be conservatively\napproximated by a single smooth inequality. We present two empirical examples\nthat show how the new econometric methods are able to generate sharp economic\nconclusions.\n"
    },
    {
        "paper_id": 1211.4396,
        "authors": "R. E. Caflisch, G. Gambino, M. Sammartino, C. Sgarra",
        "title": "European Option Pricing with Transaction Costs and Stochastic\n  Volatility: an Asymptotic Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper the valuation problem of a European call option in presence of\nboth stochastic volatility and transaction costs is considered. In the limit of\nsmall transaction costs and fast mean reversion, an asymptotic expression for\nthe option price is obtained. While the dominant term in the expansion it is\nshown to be the classical Black and Scholes solution, the correction terms\nappear at $O(\\varepsilon^{1/2})$ and $O(\\varepsilon)$. The optimal hedging\nstrategy is then explicitly obtained for the Scott's model.\n"
    },
    {
        "paper_id": 1211.4416,
        "authors": "Jean-David Fermanian",
        "title": "An overview of the goodness-of-fit test problem for copulas",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review the main \"omnibus procedures\" for goodness-of-fit testing for\ncopulas: tests based on the empirical copula process, on probability integral\ntransformations, on Kendall's dependence function, etc, and some corresponding\nreductions of dimension techniques. The problems of finding asymptotic\ndistribution-free test statistics and the calculation of reliable p-values are\ndiscussed. Some particular cases, like convenient tests for time-dependent\ncopulas, for Archimedean or extreme-value copulas, etc, are dealt with.\nFinally, the practical performances of the proposed approaches are briefly\nsummarized.\n"
    },
    {
        "paper_id": 1211.4598,
        "authors": "Tahir Choulli, Jun Deng and Junfeng Ma",
        "title": "How Non-Arbitrage, Viability and Num\\'eraire Portfolio are Related",
        "comments": "21 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes two approaches that quantify the exact relationship among\nthe viability, the absence of arbitrage, and/or the existence of the\nnum\\'eraire portfolio under minimal assumptions and for general continuous-time\nmarket models. Precisely, our first and principal contribution proves the\nequivalence among the No-Unbounded-Profit-with-Bounded-Risk condition (NUPBR\nhereafter), the existence of the num\\'eraire portfolio, and the existence of\nthe optimal portfolio under an equivalent probability measure for any \"nice\"\nutility and positive initial capital. Herein, a 'nice\" utility is any smooth\nvon Neumann-Morgenstern utility satisfying Inada's conditions and the\nelasticity assumptions of Kramkov and Schachermayer. Furthermore, the\nequivalent probability measure ---under which the utility maximization problems\nhave solutions--- can be chosen as close to the real-world probability measure\nas we want (but might not be equal). Without changing the underlying\nprobability measure and under mild assumptions, our second contribution proves\nthat the NUPBR is equivalent to the \"{\\it local}\" existence of the optimal\nportfolio. This constitutes an alternative to the first contribution, if one\ninsists on working under the real-world probability. These two contributions\nlead naturally to new types of viability that we call weak and local\nviabilities.\n"
    },
    {
        "paper_id": 1211.4636,
        "authors": "Paul M. N. Feehan, Camelia Pop",
        "title": "On the martingale problem for degenerate-parabolic partial differential\n  operators with unbounded coefficients and a mimicking theorem for Ito\n  processes",
        "comments": "27 pages, corresponds to Part 2 of our previous article\n  [arXiv:1112.4824v1]; to appear in Transactions of the American Mathematical\n  Society",
        "journal-ref": "Transactions of the American Mathematical Society 367 (2015),\n  7565-7593",
        "doi": "10.1090/tran/6243",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using results from our companion article [arXiv:1112.4824v2] on a Schauder\napproach to existence of solutions to a degenerate-parabolic partial\ndifferential equation, we solve three intertwined problems, motivated by\nprobability theory and mathematical finance, concerning degenerate diffusion\nprocesses. We show that the martingale problem associated with a\ndegenerate-elliptic differential operator with unbounded, locally Holder\ncontinuous coefficients on a half-space is well-posed in the sense of Stroock\nand Varadhan. Second, we prove existence, uniqueness, and the strong Markov\nproperty for weak solutions to a stochastic differential equation with\ndegenerate diffusion and unbounded coefficients with suitable H\\\"older\ncontinuity properties. Third, for an Ito process with degenerate diffusion and\nunbounded but appropriately regular coefficients, we prove existence of a\nstrong Markov process, unique in the sense of probability law, whose\none-dimensional marginal probability distributions match those of the given Ito\nprocess.\n"
    },
    {
        "paper_id": 1211.4686,
        "authors": "Zhi-Qiang Jiang (ECUST), Wen-Jie Xie (ECUST), and Wei-Xing Zhou\n  (ECUST)",
        "title": "Testing the weak-form efficiency of the WTI crude oil futures market",
        "comments": "9 pages and 5 figures",
        "journal-ref": "Physica A, 405, 235-244, (2014)",
        "doi": "10.1016/j.physa.2014.02.042",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform detrending moving average analysis (DMA) and detrended fluctuation\nanalysis (DFA) of the WTI crude oil futures prices (1983-2012) to investigate\nits efficiency. We further put forward a strict statistical test in the spirit\nof bootstrapping to verify the weak-form market efficiency hypothesis by\nemploying the DMA (or DFA) exponent as the statistic. We verify the weak-form\nefficiency of the crude oil futures market when the whole period is considered.\nWhen we break the whole series into three sub-series separated by the outbreaks\nof the Gulf War and the Iraq War, our statistical tests uncover that only the\nGulf War has the impact of reducing the efficiency of the crude oil market. If\nwe split the whole time series into two sub-series based on the signing date of\nthe North American Free Trade Agreement, we find that the market is inefficient\nin the sub-periods during which the Gulf War broke out. We also perform the\nsame analysis on short time series in moving windows and find that the market\nis inefficient only when some turbulent events occur, such as the oil price\ncrash in 1985, the Gulf war, and the oil price crash in 2008. Our analysis may\noffer a new understanding of the efficiency of the crude oil futures market and\nshed new lights on the investigation of the efficiency in other financial\nmarkets.\n"
    },
    {
        "paper_id": 1211.4946,
        "authors": "Wolfgang Reitgruber",
        "title": "The Calculus of Expected Loss: Backtesting Parameter-Based Expected Loss\n  in a Basel II Framework",
        "comments": "26 pages, new sections added to align with Basel 2 model validation\n  concepts and to highlight possible application within IFRS 9 accounting\n  standards. Accepted for publication by the Journal of Risk Model Validation,\n  Fall 2013",
        "journal-ref": "Reitgruber, W. (2013). Expected loss and Impact of Risk:\n  backtesting parameter-based expected loss in a Basel II framework. The\n  Journal of Risk Model Validation 7(3), 59-84",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The dependency structure of credit risk parameters is a key driver for\ncapital consumption and receives regulatory and scientific attention. The\nimpact of parameter imperfections on the quality of expected loss (EL) in the\nsense of a fair, unbiased estimate of risk expenses however is barely covered.\nSo far there are no established backtesting procedures for EL, quantifying its\nimpact with regards to pricing or risk adjusted profitability measures. In this\npaper, a practically oriented, top-down approach to assess the quality of EL by\nbacktesting with a properly defined risk measure is introduced. In a first\nstep, the concept of risk expenses (Cost of Risk) has to be extended beyond the\nclassical provisioning view, towards a more adequate capital consumption\napproach (Impact of Risk, IoR). On this basis, the difference between\nparameter-based EL and actually reported Impact of Risk is decomposed into its\nkey components. The proposed method will deepen the understanding of practical\nproperties of EL, reconciles the EL with a clearly defined and observable risk\nmeasure and provides a link between upcoming IFRS 9 accounting standards for\nloan loss provisioning with IRBA regulatory capital requirements. The method is\nrobust irrespective whether parameters are simple, expert based values or\nhighly predictive and perfectly calibrated IRBA compliant methods, as long as\nparameters and default identification procedures are stable.\n"
    },
    {
        "paper_id": 1211.4978,
        "authors": "Stefan Gerhold",
        "title": "Can there be an explicit formula for implied volatility?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is \"well known\" that there is no explicit expression for the Black-Scholes\nimplied volatility. We prove that, as a function of underlying, strike, and\ncall price, implied volatility does not belong to the class of D-finite\nfunctions. This does not rule out all explicit expressions, but shows that\nimplied volatility does not belong to a certain large class, which contains\nmany elementary functions and classical special functions.\n"
    },
    {
        "paper_id": 1211.5035,
        "authors": "Bruno R\\'emillard (GERAD), Sylvain Rubenthaler (JAD)",
        "title": "Optimal hedging in discrete time",
        "comments": "Cette pr\\'epublication appara\\^it aussi sur SSRN et les cahiers du\n  GERAD",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Building on the work of Schweizer (1995) and Cern and Kallseny (2007), we\npresent discrete time formulas minimizing the mean square hedging error for\nmultidimensional assets. In particular, we give explicit formulas when a\nregime-switching random walk or a GARCH-type process is utilized to model the\nreturns. Monte Carlo simulations are used to compare the optimal and delta\nhedging methods.\n"
    },
    {
        "paper_id": 1211.5235,
        "authors": "Yoshiharu Maeno, Kenji Nishiguchi, Satoshi Morinaga, Hirokazu\n  Matsushima",
        "title": "Optimal portfolio for a robust financial system",
        "comments": null,
        "journal-ref": "presented at the IEEE Workshop on Computational Intelligence for\n  Financial Engineering and Economics, Singapore, April 2013",
        "doi": "10.1109/CIFEr.2013.6611695",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study presents an ANWSER model (asset network systemic risk model) to\nquantify the risk of financial contagion which manifests itself in a financial\ncrisis. The transmission of financial distress is governed by a heterogeneous\nbank credit network and an investment portfolio of banks. Bankruptcy\nreproductive ratio of a financial system is computed as a function of the\ndiversity and risk exposure of an investment portfolio of banks, and the\ndenseness and concentration of a heterogeneous bank credit network. An analytic\nsolution of the bankruptcy reproductive ratio for a small financial system is\nderived and a numerical solution for a large financial system is obtained. For\na large financial system, Large diversity among banks in the investment\nportfolio makes financial contagion more damaging on the average. But large\ndiversity is essentially effective in eliminating the risk of financial\ncontagion in the worst case of financial crisis scenarios. A bank-unique\nspecialization portfolio is more suitable than a uniform diversification\nportfolio and a system-wide specialization portfolio in strengthening the\nrobustness of a financial system.\n"
    },
    {
        "paper_id": 1211.5502,
        "authors": "Wen-Jie Xie (ECUST), Zhi-Qiang Jiang (ECUST), and Wei-Xing Zhou\n  (ECUST)",
        "title": "Extreme value statistics and recurrence intervals of NYMEX energy\n  futures volatility",
        "comments": "11 pages, 8 figures and 3 tables",
        "journal-ref": "Economic Modelling 36, 8-17 (2014)",
        "doi": "10.1016/j.econmod.2013.09.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Energy markets and the associated energy futures markets play a crucial role\nin global economies. We investigate the statistical properties of the\nrecurrence intervals of daily volatility time series of four NYMEX energy\nfutures, which are defined as the waiting times $\\tau$ between consecutive\nvolatilities exceeding a given threshold $q$. We find that the recurrence\nintervals are distributed as a stretched exponential $P_q(\\tau)\\sim\ne^{(a\\tau)^{-\\gamma}}$, where the exponent $\\gamma$ decreases with increasing\n$q$, and there is no scaling behavior in the distributions for different\nthresholds $q$ after the recurrence intervals are scaled with the mean\nrecurrence interval $\\bar\\tau$. These findings are significant under the\nKolmogorov-Smirnov test and the Cram{\\'e}r-von Mises test. We show that\nempirical estimations are in nice agreement with the numerical integration\nresults for the occurrence probability $W_q(\\Delta{t}|t)$ of a next event above\nthe threshold $q$ within a (short) time interval after an elapsed time $t$ from\nthe last event above $q$. We also investigate the memory effects of the\nrecurrence intervals. It is found that the conditional distributions of large\nand small recurrence intervals differ from each other and the conditional mean\nof the recurrence intervals scales as a power law of the preceding interval\n$\\bar\\tau(\\tau_0)/\\bar\\tau \\sim (\\tau_0/\\bar\\tau)^\\beta$, indicating that the\nrecurrence intervals have short-term correlations. Detrended fluctuation\nanalysis and detrending moving average analysis further uncover that the\nrecurrence intervals possess long-term correlations. We confirm that the\n\"clustering\" of the volatility recurrence intervals is caused by the long-term\ncorrelations well known to be present in the volatility.\n"
    },
    {
        "paper_id": 1211.5517,
        "authors": "Chris Kenyon and Andrew Green",
        "title": "CDS pricing under Basel III: capital relief and default protection",
        "comments": "16 pages, 10 figues, 3 tables",
        "journal-ref": "Risk, 2013, 26(10), 62-66",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Basel III introduces new capital charges for CVA. These charges, and the\nBasel 2.5 default capital charge can be mitigated by CDS. Therefore, to price\nin the capital relief that CDS contracts provide, we introduce a CDS pricing\nmodel with three legs: premium; default protection; and capital relief. If\nmarkets are complete, with no CDS bond basis, then CDSs can be replicated by\ntaking short positions in risky floating bonds issued by the reference entity\nand a riskless bank account. If these conditions do not hold, then it is\ntheoretically possible that the capital relief that CDSs provide may be priced\nin. Thus our model provides bounds on the CDS-implied hazard rates when markets\nare incomplete. Under simple assumptions we show that 20% to over 50% of\nobserved CDS spread could be due to priced in capital relief. Given that this\nis different for IMM and non-IMM banks will we see differential pricing?\n"
    },
    {
        "paper_id": 1211.5575,
        "authors": "Cornelia Metzig and Mirta Gordon",
        "title": "Heterogeneous Enterprises in a Macroeconomic Agent-Based Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a macroeconomic agent-based model that combines several mechanisms\noperating at the same timescale, while remaining mathematically tractable. It\ncomprises enterprises and workers who compete in a job market and a commodity\ngoods market. The model is stock-flow consistent; a bank lends money charging\ninterest rates, and keeps track of equities. Important features of the model\nare heterogeneity of enterprises, existence of bankruptcies and creation of new\nenterprises, as well as productivity increase. The model's evolution reproduces\nempirically found regularities for firm size and growth rate distributions. It\ncombines probabilistic elements and deterministic dynamics, with relative\nweights that may be modified according to the considered problem or the belief\nof the modeler. We discuss statistical regularities on enterprises, the origin\nand the amplitude of endogeneous fluctuations of the system's steady state, as\nwell as the role of the interest rate and the credit volume. We also summarize\nobtained results which are not discussed in detail in this paper.\n"
    },
    {
        "paper_id": 1211.5628,
        "authors": "Tianyu Hao",
        "title": "Optimal portfolio model based on WVAR",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article is focused on using a new measurement of risk-- Weighted Value\nat Risk to develop a new method of constructing initiate from the TVAR solving\nproblem, based on MATLAB software, using the historical simulation method\n(avoiding income distribution will be assumed to be normal), the results of\nprevious studies also based on, study the U.S. Nasdaq composite index,\ncombining the Simpson formula for the solution of TVAR and its deeply study;\nthen, through the representation of WVAR formula discussed and indispensable\nanalysis, also using the Simpson formula and the numerical calculations, we\nhave done the empirical analysis and review test. this paper is based on WVAR\nwhich possesses better properties, taking the idea of portfolio into the\nmulti-index comprehensive evaluation, to build innovative WVAR based portfolio\nselection under the framework of a theoretical model; in this framework, a\ndescription of risks is designed by WVAR, its advantage is no influence by\nincome distribution, meanwhile various optimization problems have a unique\nsolution; then take AHP weights to different indicators deal on this basis,\nafter that we put a nonlinear satisfaction portfolio selected model forward and\nconduct tests of empirical analysis, finally we use weighted linear approach to\nconvert the portfolio model into a single-objective problem, which is easier to\nsolve, then we use the data of two ETFs to construct portfolio, and compare the\nperformance of portfolio constructed by Mean-Weighted V@R and by Mean-Variance.\n"
    },
    {
        "paper_id": 1211.5726,
        "authors": "M. Krivko and M.V. Tretyakov",
        "title": "Application of simplest random walk algorithms for pricing barrier\n  options",
        "comments": "It's a pre-publication which final version will appear as a chapter\n  in Recent Developments in Computational Finance (Eds. T. Gerstner and P.E.\n  Kloeden), 2013. [it has one picture and 22 pages]",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We demonstrate effectiveness of the first-order algorithm from [Milstein,\nTretyakov. Theory Prob. Appl. 47 (2002), 53-68] in application to barrier\noption pricing. The algorithm uses the weak Euler approximation far from\nbarriers and a special construction motivated by linear interpolation of the\nprice near barriers. It is easy to implement and is universal: it can be\napplied to various structures of the contracts including derivatives on\nmulti-asset correlated underlyings and can deal with various type of barriers.\nIn contrast to the Brownian bridge techniques currently commonly used for\npricing barrier options, the algorithm tested here does not require knowledge\nof trigger probabilities nor their estimates. We illustrate this algorithm via\npricing a barrier caplet, barrier trigger swap and barrier swaption.\n"
    },
    {
        "paper_id": 1211.5816,
        "authors": "Moawia Alghalith",
        "title": "Relaxing the Differentiability Assumption in Taylor Theorem and\n  Optimization: Applications to the HJB PDE and Finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce Taylor expansions that do not require the differentiability. We\nalso provide new solutions to partial differential equations. We apply our\nmethods to finance.\n"
    },
    {
        "paper_id": 1211.5819,
        "authors": "Moawia Alghalith",
        "title": "New stochastic calculus",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present new stochastic differential equations, that are more general and\nsimpler than the existing Ito-based stochastic differential equations. As an\nexample, we apply our approach to the investment (portfolio) model.\n"
    },
    {
        "paper_id": 1211.5858,
        "authors": "Nikolai Dokuchaev",
        "title": "Degenerate backward SPDEs in domains: non-local boundary conditions and\n  applications to finance",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1211.1460,\n  arXiv:1208.5538",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Backward stochastic partial differential equations of parabolic type in\nbounded domains are studied in the setting where the coercivity condition is\nnot necessary satisfied and the equation can be degenerate. Some generalized\nsolutions based on the representation theorem are suggested. In addition to\nproblems with a standard Cauchy condition at the terminal time, problems with\nspecial non-local boundary conditions are considered. These non-local\nconditions connect the terminal value of the solution with a functional over\nthe entire past solution. Uniqueness, solvability and regularity results are\nobtained. Some applications to portfolio selection problem are considered.\n"
    },
    {
        "paper_id": 1211.5867,
        "authors": "Masaaki Fujii, Seisho Sato and Akihiko Takahashi",
        "title": "An FBSDE Approach to American Option Pricing with an Interacting\n  Particle Method",
        "comments": "18 pages, 5 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the paper, we propose a new calculation scheme for American options in the\nframework of a forward backward stochastic differential equation (FBSDE). The\nwell-known decomposition of an American option price with that of a European\noption of the same maturity and the remaining early exercise premium can be\ncast into the form of a decoupled non-linear FBSDE. We numerically solve the\nFBSDE by applying an interacting particle method recently proposed by Fujii and\nTakahashi (2012d), which allows one to perform a Monte Carlo simulation in a\nfully forward-looking manner. We perform the fourth-order analysis for the\nBlack-Scholes (BS) model and the third-order analysis for the Heston model. The\ncomparison to those obtained from existing tree algorithms shows the\neffectiveness of the particle method.\n"
    },
    {
        "paper_id": 1211.6349,
        "authors": "Chris Kenyon and Andrew Green",
        "title": "Will Central Counterparties become the New Rating Agencies?",
        "comments": "6 pages",
        "journal-ref": "Risk, September 2013",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Central Counterparties (CCPs) are widely promoted as a requirement for safe\nbanking with little dissent except on technical grounds (such as proliferation\nof CCPs). Whilst CCPs can have major operational positives, we argue that CCPs\nhave many of the business characteristics of Rating Agencies, and face similar\nbusiness pressures. Thus we see a risk that prices from CCPs may develop the\ncharacteristics attributed to ratings from Rating Agency pre-crisis. Business\nover-reliance on ratings of questionable accuracy is seen as a cause of the\nfinancial crisis. We see the potential for same situation to be repeated with\nprices from CCPs. Thus the regulatory emphasis on CCPs, rather than on\ncollateralization, may create the preconditions for an avoidable repeat of the\nfinancial crisis.\n"
    },
    {
        "paper_id": 1211.6517,
        "authors": "Jaehyung Choi, Sungsoo Choi, Wonseok Kang",
        "title": "Momentum universe shrinkage effect in price momentum",
        "comments": "38 pages, 19 figures, submitted version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We test the price momentum effect in the Korean stock markets under the\nmomentum universe shrinkage to subuniverses of the KOSPI 200. Performance of\nthe momentum strategy is not homogeneous with respect to change of the momentum\nuniverse. It is found that some submarkets generate the higher momentum returns\nthan other universes do but large-size companies such as the KOSPI 50\ncomponents hinder the performance of the momentum strategy. The observation is\nalso cross-checked with size portfolios and liquidity portfolios. Transactions\nby investor groups, in particular, the trading patterns by foreign investors\ncan be a source of the momentum universe shrinkage effect in the momentum\nreturns.\n"
    },
    {
        "paper_id": 1211.6525,
        "authors": "Shige Peng",
        "title": "The Pricing Mechanism of Contingent Claims and its Generating Function",
        "comments": "36 pages. arXiv admin note: substantial text overlap with\n  arXiv:math/0501415, arXiv:math/0605599",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study dynamic pricing mechanism of contingent claims. A\ntypical model of such pricing mechanism is the so-called g-expectation\n$E^g_{s,t}[X]$ defined by the solution of the backward stochastic differential\nequation with generator g and with the contingent claim X as terminal\ncondition. The generating function g this BSDE. We also provide examples of\ndetermining the price generating function $g=g(y,z)$ by testing.\n  The main result of this paper is as follows: if a given dynamic pricing\nmechanism is $E^{g_\\mu}$-dominated, i.e., the criteria (A5)\n$E_{s,t}[X]-E_{s,t}[X']\\leq E^{g_\\mu}_{s,t}[X-X']$ is satisfied for a large\nenough $\\mu> 0$, where $g_\\mu=g_{\\mu}(|y|+|z|)$, then $E_{s,t}$ is a g-pricing\nmechanism. This domination condition was statistically tested using CME data\ndocuments. The result of test is significantly positive.\n"
    },
    {
        "paper_id": 1211.6667,
        "authors": "Anton Golub, John Keane and Ser-Huang Poon",
        "title": "High Frequency Trading and Mini Flash Crashes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyse all Mini Flash Crashes (or Flash Equity Failures) in the US equity\nmarkets in the four most volatile months during 2006-2011. In contrast to\nprevious studies, we find that Mini Flash Crashes are the result of regulation\nframework and market fragmentation, in particular due to the aggressive use of\nIntermarket Sweep Orders and Regulation NMS protecting only Top of the Book. We\nfind strong evidence that Mini Flash Crashes have an adverse impact on market\nliquidity and are associated with Fleeting Liquidity.\n"
    },
    {
        "paper_id": 1211.6695,
        "authors": "Felix Patzelt and Klaus R. Pawelzik",
        "title": "Unstable Price Dynamics as a Result of Information Absorption in\n  Speculative Markets",
        "comments": "Paper and supplement are combined in a single file. Changes in this\n  Version: Added an introductory paragraph. Expanded discussion on the\n  differences between the presented model and minority games. Added two\n  supplementary figures",
        "journal-ref": "F. Patzelt & K. Pawelzik: An Inherent Instability of Efficient\n  Markets. Scientific Reports 3 (2013). Article 2784",
        "doi": "10.1038/srep02784",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In speculative markets, risk-free profit opportunities are eliminated by\ntraders exploiting them. Markets are therefore often described as\n\"informationally efficient\", rapidly removing predictable price changes, and\nleaving only residual unpredictable fluctuations. This classical view of\nmarkets absorbing information and otherwise operating close to an equilibrium\nis challenged by extreme price fluctuations, in particular since they occur far\nmore frequently than can be accounted for by external news. Here we show that\nspeculative markets which absorb mainly self-generated information can exhibit\nboth: evolution towards efficient equilibrium states as well as their\nsubsequent destabilization. This peculiar dynamics, a generic instability\narising from an adaptive control which annihilates predictable information, is\nrealized in a minimal agent-based market model where the impacts of agents'\nstrategies adapt according to their trading success. This adaptation implements\na learning rule for the market as a whole minimizing predictable price changes.\nThe model reproduces stylized statistical properties of price changes in\nquantitative detail, including heavy tailed log return distributions and\nvolatility clusters. Our results demonstrate that the perpetual occurrence of\nmarket instabilities can be a direct consequence of the very mechanisms that\nlead to market efficiency.\n"
    },
    {
        "paper_id": 1211.7172,
        "authors": "Belal E. Baaquie",
        "title": "Statistical Microeconomics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A statistical generalization is made of microeconomics in the spirit of going\nfrom classical to statistical mechanics. The price and quantity of every\ncommodity1 traded in the market, at each instant of time, is considered to be\nan independent random variable: all prices and quantities are considered to be\nstochastic processes, with the observed market prices being a random sample of\nthe stochastic prices. The dynamics of market prices is determined by an action\nfunctional and, for concreteness, a specific model is proposed. The model can\nbe calibrated from the unequal time correlation of the market commodity prices.\nA perturbation expansion for the correlation functions is defined in powers of\nthe inverse of the total budget of the aggregate consumer and the propagator\nfor the market prices is evaluated.\n"
    },
    {
        "paper_id": 1211.7365,
        "authors": "Erhan Bayraktar, Andreas Kyprianou, Kazutoshi Yamazaki",
        "title": "On optimal dividends in the dual model",
        "comments": "To appear in the ASTIN Bulletin. Key words: dual model; dividends;\n  capital injections; spectrally positive Levy processes; scale functions",
        "journal-ref": "ASTIN Bull. 43 (2013) 359-372",
        "doi": "10.1017/asb.2013.17",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit the dividend payment problem in the dual model of Avanzi et al.\n([2], [1], and [3]). Using the fluctuation theory of spectrally positive\nL\\'{e}vy processes, we give a short exposition in which we show the optimality\nof barrier strategies for all such L\\'{e}vy processes. Moreover, we\ncharacterize the optimal barrier using the functional inverse of a scale\nfunction. We also consider the capital injection problem of [3] and show that\nits value function has a very similar form to the one in which the horizon is\nthe time of ruin.\n"
    },
    {
        "paper_id": 1212.0092,
        "authors": "J. L. van Velsen",
        "title": "Parameter estimation of a Levy copula of a discretely observed bivariate\n  compound Poisson process with an application to operational risk modelling",
        "comments": "25 pages including 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A method is developed to estimate the parameters of a Levy copula of a\ndiscretely observed bivariate compound Poisson process without knowledge of\ncommon shocks. The method is tested in a small sample simulation study. Also,\nthe method is applied to a real data set and a goodness of fit test is\ndeveloped. With the methodology of this work, the Levy copula becomes a\nrealistic tool of the advanced measurement approach of operational risk.\n"
    },
    {
        "paper_id": 1212.0354,
        "authors": "P. O\\'swi\\k{e}cimka, S. Dro\\.zd\\.z, J. Kwapie\\'n and A. Z. G\\'orski",
        "title": "Effect of detrending on multifractal characteristics",
        "comments": "Presented by P. O\\'swi\\k{e}cimka at FENS2012 conference, 17 pages, 9\n  figures",
        "journal-ref": "Acta Phys. Pol. A 123, 597-603 (2013)",
        "doi": "10.12693/APhysPolA.123.597",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Different variants of MFDFA technique are applied in order to investigate\nvarious (artificial and real-world) time series. Our analysis shows that the\ncalculated singularity spectra are very sensitive to the order of the\ndetrending polynomial used within the MFDFA method. The relation between the\nwidth of the multifractal spectrum (as well as the Hurst exponent) and the\norder of the polynomial used in calculation is evident. Furthermore, type of\nthis relation itself depends on the kind of analyzed signal. Therefore, such an\nanalysis can give us some extra information about the correlative structure of\nthe time series being studied.\n"
    },
    {
        "paper_id": 1212.038,
        "authors": "Moawia Alghalith",
        "title": "A note on estimating stochastic volatility and its volatility: a new\n  simple method",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new simple method of estimating stochastic volatility and its\nvolatility. This method is applicable to both cross-sectional and time-series\ndata. Moreover, this method does not require volatility data series.\n"
    },
    {
        "paper_id": 1212.044,
        "authors": "Hern\\'an Larralde",
        "title": "Maximum Entropy distributions of correlated variables with prespecified\n  marginals",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.86.061117",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of determining the joint probability distributions for correlated\nrandom variables with pre-specified marginals is considered. When the joint\ndistribution satisfying all the required conditions is not unique, the \"most\nunbiased\" choice corresponds to the distribution of maximum entropy. The\ncalculation of the maximum entropy distribution requires the solution of rather\ncomplicated nonlinear coupled integral equations, exact solutions to which are\nobtained for the case of Gaussian marginals; otherwise, the solution can be\nexpressed as a perturbation around the product of the marginals if the marginal\nmoments exist.\n"
    },
    {
        "paper_id": 1212.0476,
        "authors": "Anis Matoussi, Lambert Piozin, Dylan Possama\\\"i",
        "title": "Second-order BSDEs with general reflection and game options under\n  uncertainty",
        "comments": "37 pages. To appear in Stochastic processes and their Applications.\n  arXiv admin note: text overlap with arXiv:1201.0746",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is twofold. First, we extend the results of [33]\nconcerning the existence and uniqueness of second-order reflected 2BSDEs to the\ncase of two obstacles. Under some regularity assumptions on one of the\nbarriers, similar to the ones in [10], and when the two barriers are completely\nseparated, we provide a complete wellposedness theory for doubly reflected\nsecond-order BSDEs. We also show that these objects are related to non-standard\noptimal stopping games, thus generalizing the connection between DRBSDEs and\nDynkin games first proved by Cvitanic and Karatzas [11]. More precisely, we\nshow under a technical assumption that the second order DRBSDEs provide\nsolutions of what we call uncertain Dynkin games and that they also allow us to\nobtain super and subhedging prices for American game options (also called\nIsraeli options) in financial markets with volatility uncertainty\n"
    },
    {
        "paper_id": 1212.0479,
        "authors": "Linda Ponta, Mailan Trinh, Marco Raberto, Enrico Scalas, Silvano\n  Cincotti",
        "title": "Modeling non-stationarities in high-frequency financial time series",
        "comments": "This version contains an additional analysis on model selection based\n  on information criteria. Version submitted to PLOS ONE",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study tick-by-tick financial returns belonging to the FTSE MIB index of\nthe Italian Stock Exchange (Borsa Italiana). We can confirm previously detected\nnon-stationarities. However, scaling properties reported in the previous\nliterature for other high-frequency financial data are only approximately\nvalid. As a consequence of the empirical analyses, we propose a simple method\nfor describing non-stationary returns, based on a non-homogeneous normal\ncompound Poisson process. We test this model against the empirical findings and\nit turns out that the model can approximately reproduce several stylized facts\nof high-frequency financial time series. Moreover, using Monte Carlo\nsimulations, we analyze order selection for this model class using three\ninformation criteria: Akaike's information criterion (AIC), the Bayesian\ninformation criterion (BIC) and the Hannan-Quinn information criterion (HQ).\nFor comparison, we also perform a similar Monte Carlo experiment for the ACD\n(autoregressive conditional duration) model. Our results show that the\ninformation criteria work best for small parameter numbers for the compound\nPoisson type models, whereas for the ACD model the model selection procedure\ndoes not work well in certain cases.\n"
    },
    {
        "paper_id": 1212.0779,
        "authors": "Antoine Jacquier and Patrick Roome",
        "title": "Asymptotics of forward implied volatility",
        "comments": "37 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove here a general closed-form expansion formula for forward-start\noptions and the forward implied volatility smile in a large class of models,\nincluding the Heston stochastic volatility and time-changed exponential L\\'evy\nmodels. This expansion applies to both small and large maturities and is based\nsolely on the properties of the forward characteristic function of the\nunderlying process. The method is based on sharp large deviations techniques,\nand allows us to recover (in particular) many results for the spot implied\nvolatility smile. In passing we (i) show that the forward-start date has to be\nrescaled in order to obtain non-trivial small-maturity asymptotics, (ii) prove\nthat the forward-start date may influence the large-maturity behaviour of the\nforward smile, and (iii) provide some examples of models with finite quadratic\nvariation where the small-maturity forward smile does not explode.\n"
    },
    {
        "paper_id": 1212.0781,
        "authors": "Maria B. Chiarolla and Tiziano De Angelis",
        "title": "Analytical Pricing of American Bond Options in the Heath-Jarrow-Morton\n  Model",
        "comments": "28 pages; we removed the positive part from the discount factor,\n  improved the probabilistic analysis of the value function and provided\n  solutions of the variational inequality in a stronger sense",
        "journal-ref": "Stochastic Processes and their Applications 125 (2015) 678-707",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the optimal stopping problem of pricing an American Put option on a\nZero Coupon Bond (ZCB) in the Musiela's parametrization of the\nHeath-Jarrow-Morton (HJM) model for forward interest rates.\n  First we show regularity properties of the price function by probabilistic\nmethods. Then we find an infinite dimensional variational formulation of the\npricing problem by approximating the original optimal stopping problem by\nfinite dimensional ones, after a suitable smoothing of the payoff. As expected,\nthe first time the price of the American bond option equals the payoff is shown\nto be optimal.\n"
    },
    {
        "paper_id": 1212.1037,
        "authors": "Tushar Rao (NSIT-Delhi) and Saket Srivastava (IIIT-Delhi)",
        "title": "Modeling Movements in Oil, Gold, Forex and Market Indices using Search\n  Volume Index and Twitter Sentiments",
        "comments": "10 pages, 4 figures, 9 Tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Study of the forecasting models using large scale microblog discussions and\nthe search behavior data can provide a good insight for better understanding\nthe market movements. In this work we collected a dataset of 2 million tweets\nand search volume index (SVI from Google) for a period of June 2010 to\nSeptember 2011. We perform a study over a set of comprehensive causative\nrelationships and developed a unified approach to a model for various market\nsecurities like equity (Dow Jones Industrial Average-DJIA and NASDAQ-100),\ncommodity markets (oil and gold) and Euro Forex rates. We also investigate the\nlagged and statistically causative relations of Twitter sentiments developed\nduring active trading days and market inactive days in combination with the\nsearch behavior of public before any change in the prices/ indices. Our results\nshow extent of lagged significance with high correlation value upto 0.82\nbetween search volumes and gold price in USD. We find weekly accuracy in\ndirection (up and down prediction) uptil 94.3% for DJIA and 90% for NASDAQ-100\nwith significant reduction in mean average percentage error for all the\nforecasting models.\n"
    },
    {
        "paper_id": 1212.1061,
        "authors": "L. A. Braunstein, P. A. Macri, J. R. Iglesias",
        "title": "Study of a Market Model with Conservative Exchanges on Complex Networks",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1007.0461",
        "journal-ref": "Physica A, 392, 1788-1794 (2013)",
        "doi": "10.1016/j.physa.2012.12.030",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many models of market dynamics make use of the idea of conservative wealth\nexchanges among economic agents. A few years ago an exchange model using\nextremal dynamics was developed and a very interesting result was obtained: a\nself-generated minimum wealth or poverty line. On the other hand, the wealth\ndistribution exhibited an exponential shape as a function of the square of the\nwealth. These results have been obtained both considering exchanges between\nnearest neighbors or in a mean field scheme. In the present paper we study the\neffect of distributing the agents on a complex network. We have considered\narchetypical complex networks: Erd\\\"{o}s-R\\'enyi random networks and scale-free\nnetworks. The presence of a poverty line with finite wealth is preserved but\nspatial correlations are important, particularly between the degree of the node\nand the wealth. We present a detailed study of the correlations, as well as the\nchanges in the Gini coefficient, that measures the inequality, as a function of\nthe type and average degree of the considered networks.\n"
    },
    {
        "paper_id": 1212.1282,
        "authors": "Hans G. Danielmeyer and Thomas Martinetz",
        "title": "The physics of business cycles and inflation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyse four consecutive cycles observed in the USA for employment and\ninflation. They are driven by three oil price shocks and an intended interest\nrate shock. Non-linear coupling between the rate equations for consumer\nproducts as prey and consumers as predators provides the required instability,\nbut its natural damping is too high for spontaneous cycles. Extending the\nLotka-Volterra equations with a small term for collective anticipation yields a\nsecond analytic solution without damping. It predicts the base period, phase\nshifts, and the sensitivity to shocks for all six cyclic variables correctly.\n"
    },
    {
        "paper_id": 1212.1286,
        "authors": "Hans G. Danielmeyer and Thomas Martinetz",
        "title": "Predicting economic growth with classical physics and human biology",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We collect and analyze the data for working time, life expectancy, and the\npair output and infrastructure of industrializing nations. During S-functional\nrecovery from disaster the pair's time shifts yield 25 years for the\ninfrastructure's physical lifetime. At G7 level the per capita outputs converge\nand the time shifts identify a heritable quantity with a reaction time of 62\nyears. It seems to control demand and the spare time required for enjoying G7\naffluence. The sum of spare and working time is fixed by the universal flow of\ntime. This yields analytic solutions for equilibrium, recovery, and long-term\nevolution for all six variables with biologically stabilized parameters.\n"
    },
    {
        "paper_id": 1212.1377,
        "authors": "Mike Giles and Lukasz Szpruch",
        "title": "Multilevel Monte Carlo methods for applications in finance",
        "comments": "arXiv admin note: text overlap with arXiv:1202.6283; and with\n  arXiv:1106.4730 by other authors",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Since Giles introduced the multilevel Monte Carlo path simulation method\n[18], there has been rapid development of the technique for a variety of\napplications in computational finance. This paper surveys the progress so far,\nhighlights the key features in achieving a high rate of multilevel variance\nconvergence, and suggests directions for future research.\n"
    },
    {
        "paper_id": 1212.1661,
        "authors": "Ivan Kitov",
        "title": "Cross comparison and modelling of Goldman Sachs, Morgan Stanley,\n  JPMorgan Chase, Bank of America, and Franklin Resources",
        "comments": "12 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have studied statistical characteristics of five share price time series.\nFor each stock price, we estimated a best fit quantitative model for the\nmonthly closing price as based on the decomposition into two defining consumer\nprice indices selected from a large set of CPIs. It was found that there are\ntwo pairs of similar models (Bank of America/Morgan Stanley and Goldman\nSachs/JPMorgan Chase) with a standalone model for Franklin Resources. From each\npair, one can choose the company with the highest return depending on the\nfuture evolution of defining CPIs\n"
    },
    {
        "paper_id": 1212.1679,
        "authors": "Dimitris Sardelis",
        "title": "The Greek Public Debt Path: From Zero to Infinity",
        "comments": "8 pages, 3 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of the present article is to treat the Greek public debt issue\nstrictly as a curve fitting problem. Thus, based on Eurostat data and using the\nMathematica technical computing software, an exponential function that best\nfits the data is determined modelling how the Greek public debt expands with\ntime. Exploring the main features of this best fit model, it is concluded that\nthe Greek public debt cannot possibly be serviced in the long run unless a\nradical growth is implemented and/or part of the debt is written off.\n"
    },
    {
        "paper_id": 1212.1877,
        "authors": "Winslow Strong",
        "title": "Generalizations of Functionally Generated Portfolios with Applications\n  to Statistical Arbitrage",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The theory of functionally generated portfolios (FGPs) is an aspect of the\ncontinuous-time, continuous-path Stochastic Portfolio Theory of Robert\nFernholz. FGPs have been formulated to yield a master equation - a description\nof their return relative to a passive (buy-and-hold) benchmark portfolio\nserving as the num\\'eraire. This description has proven to be analytically very\nuseful, as it is both pathwise and free of stochastic integrals. Here we\ngeneralize the class of FGPs in several ways: (1) the num\\'eraire may be any\nstrictly positive wealth process, not necessarily the market portfolio or even\na passive portfolio; (2) generating functions may be stochastically dynamic,\nadjusting to changing market conditions through an auxiliary continuous-path\nstochastic argument of finite variation. These generalizations do not forfeit\nthe important tractability properties of the associated master equation. We\nshow how these generalizations can be usefully applied to scenario analysis,\nstatistical arbitrage, portfolio risk immunization, and the theory of mirror\nportfolios.\n"
    },
    {
        "paper_id": 1212.1919,
        "authors": "Brandon Kaplowitz and Siddharth G. Reddy",
        "title": "Stochastic PDEs and Quantitative Finance: The Black-Scholes-Merton Model\n  of Options Pricing and Riskless Trading",
        "comments": "Withdrawn",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Differential equations can be used to construct predictive models of a\ndiverse set of real-world phenomena like heat transfer, predator-prey\ninteractions, and missile tracking. In our work, we explore one particular\napplication of stochastic differential equations, the Black-Scholes-Merton\nmodel, which can be used to predict the prices of financial derivatives and\nmaintain a riskless, hedged position in the stock market. This paper is\nintended to provide the reader with a history, derivation, and implementation\nof the canonical model as well as an improved trading strategy that better\nhandles arbitrage opportunities in high-volatility markets. Our attempted\nimprovements may be broken into two components: an implementation of 24-hour,\nworldwide trading designed to create a continuous trading scenario and the use\nof the Student's t-distribution (with two degrees of freedom) in evaluating the\nBlack-Scholes equations.\n"
    },
    {
        "paper_id": 1212.1946,
        "authors": "Marcel Ausloos",
        "title": "Econophysics in Belgium. The first (?) 15 years",
        "comments": "6 pages, 79 refs.; written for \"Econophysics\", a special issue of\n  \"Science and Culture\" (Kolkata, India) to celebrate 15 years of Econophysics",
        "journal-ref": "Science and Culture (Kolkata, India) VOL. 76, NOS. 9-10, pp.\n  380-385 (2010)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This reviews the econophysics activities in Belgium from my admittedly biased\npoint of view. Unknown historical notes or facts are presented for the first\ntime explaining the aims, whence evolution of the research papers and friendly\nconnections with colleagues. Comments on endeavors are also provided. The lack\nof official, academic and private support is outlined.\n"
    },
    {
        "paper_id": 1212.2129,
        "authors": "Bin Li and Steven C. H. Hoi",
        "title": "Online Portfolio Selection: A Survey",
        "comments": "33 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Online portfolio selection is a fundamental problem in computational finance,\nwhich has been extensively studied across several research communities,\nincluding finance, statistics, artificial intelligence, machine learning, and\ndata mining, etc. This article aims to provide a comprehensive survey and a\nstructural understanding of published online portfolio selection techniques.\nFrom an online machine learning perspective, we first formulate online\nportfolio selection as a sequential decision problem, and then survey a variety\nof state-of-the-art approaches, which are grouped into several major\ncategories, including benchmarks, \"Follow-the-Winner\" approaches,\n\"Follow-the-Loser\" approaches, \"Pattern-Matching\" based approaches, and\n\"Meta-Learning Algorithms\". In addition to the problem formulation and related\nalgorithms, we also discuss the relationship of these algorithms with the\nCapital Growth theory in order to better understand the similarities and\ndifferences of their underlying trading ideas. This article aims to provide a\ntimely and comprehensive survey for both machine learning and data mining\nresearchers in academia and quantitative portfolio managers in the financial\nindustry to help them understand the state-of-the-art and facilitate their\nresearch and practical applications. We also discuss some open issues and\nevaluate some emerging new trends for future research directions.\n"
    },
    {
        "paper_id": 1212.214,
        "authors": "Marcel Nutz, Jianfeng Zhang",
        "title": "Optimal stopping under adverse nonlinear expectation and related games",
        "comments": "Published at http://dx.doi.org/10.1214/14-AAP1054 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 5, 2503-2534",
        "doi": "10.1214/14-AAP1054",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the existence of optimal actions in a zero-sum game\n$\\inf_{\\tau}\\sup_PE^P[X_{\\tau}]$ between a stopper and a controller choosing a\nprobability measure. This includes the optimal stopping problem\n$\\inf_{\\tau}\\mathcal{E}(X_{\\tau})$ for a class of sublinear expectations\n$\\mathcal{E}(\\cdot)$ such as the $G$-expectation. We show that the game has a\nvalue. Moreover, exploiting the theory of sublinear expectations, we define a\nnonlinear Snell envelope $Y$ and prove that the first hitting time\n$\\inf\\{t:Y_t=X_t\\}$ is an optimal stopping time. The existence of a saddle\npoint is shown under a compactness condition. Finally, the results are applied\nto the subhedging of American options under volatility uncertainty.\n"
    },
    {
        "paper_id": 1212.2189,
        "authors": "Guannan Zhao, Mark McDonald, Dan Fenn, Stacy Williams and Neil F.\n  Johnson",
        "title": "Transition in the Waiting-Time Distribution of Price-Change Events in a\n  Global Socioeconomic System",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.08.036",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The goal of developing a firmer theoretical understanding of inhomogenous\ntemporal processes -- in particular, the waiting times in some collective\ndynamical system -- is attracting significant interest among physicists.\nQuantifying the deviations in the waiting-time distribution away from one\ngenerated by a random process, may help unravel the feedback mechanisms that\ndrive the underlying dynamics. We analyze the waiting-time distributions of\nhigh frequency foreign exchange data for the best executable bid-ask prices\nacross all major currencies. We find that the lognormal distribution yields a\ngood overall fit for the waiting-time distribution between currency rate\nchanges if both short and long waiting times are included. If we restrict our\nstudy to long waiting-times, each currency pair's distribution is consistent\nwith a power law tail with exponent near to 3.5. However for short waiting\ntimes, the overall distribution resembles one generated by an archetypal\ncomplex systems model in which boundedly rational agents compete for limited\nresources. Our findings suggest a gradual transition arises in trading behavior\nbetween a fast regime in which traders act in a boundedly rational way, and a\nslower one in which traders' decisions are driven by generic feedback\nmechanisms across multiple timescales and hence produce similar power-law tails\nirrespective of currency type.\n"
    },
    {
        "paper_id": 1212.2473,
        "authors": "Liping Liu, Catherine Shenoy, Prakash P. Shenoy",
        "title": "A Linear Belief Function Approach to Portfolio Evaluation",
        "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By elaborating on the notion of linear belief functions (Dempster 1990; Liu\n1996), we propose an elementary approach to knowledge representation for expert\nsystems using linear belief functions. We show how to use basic matrices to\nrepresent market information and financial knowledge, including complete\nignorance, statistical observations, subjective speculations, distributional\nassumptions, linear relations, and empirical asset pricing models. We then\nappeal to Dempster's rule of combination to integrate the knowledge for\nassessing an overall belief of portfolio performance, and updating the belief\nby incorporating additional information. We use an example of three gold stocks\nto illustrate the approach.\n"
    },
    {
        "paper_id": 1212.2676,
        "authors": "Aaron Gerow and Mark Keane",
        "title": "Mining the Web for the Voice of the Herd to Track Stock Market Bubbles",
        "comments": "Proceedings of the 22nd International Joint Conference on Artificial\n  Intelligence (IJCAI '11), Barcelona, Spain, 16-22 July, 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that power-law analyses of financial commentaries from newspaper\nweb-sites can be used to identify stock market bubbles, supplementing\ntraditional volatility analyses. Using a four-year corpus of 17,713 online,\nfinance-related articles (10M+ words) from the Financial Times, the New York\nTimes, and the BBC, we show that week-to-week changes in power-law\ndistributions reflect market movements of the Dow Jones Industrial Average\n(DJI), the FTSE-100, and the NIKKEI-225. Notably, the statistical regularities\nin language track the 2007 stock market bubble, showing emerging structure in\nthe language of commentators, as progressively greater agreement arose in their\npositive perceptions of the market. Furthermore, during the bubble period, a\nmarked divergence in positive language occurs as revealed by a Kullback-Leibler\nanalysis.\n"
    },
    {
        "paper_id": 1212.2833,
        "authors": "D. Sornette and P. Cauwels",
        "title": "The Illusion of the Perpetual Money Machine",
        "comments": "27 pages, 18 figures (Notenstein Academy White Paper Series)",
        "journal-ref": "Risks 2, 103-131 (2014)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We argue that the present crisis and stalling economy continuing since 2007\nare rooted in the delusionary belief in policies based on a \"perpetual money\nmachine\" type of thinking. We document strong evidence that, since the early\n1980s, consumption has been increasingly funded by smaller savings, booming\nfinancial profits, wealth extracted from house price appreciation and explosive\ndebt. This is in stark contrast with the productivity-fueled growth that was\nseen in the 1950s and 1960s. This transition, starting in the early 1980s, was\nfurther supported by a climate of deregulation and a massive growth in\nfinancial derivatives designed to spread and diversify the risks globally. The\nresult has been a succession of bubbles and crashes, including the worldwide\nstock market bubble and great crash of October 1987, the savings and loans\ncrisis of the 1980s, the burst in 1991 of the enormous Japanese real estate and\nstock market bubbles, the emerging markets bubbles and crashes in 1994 and\n1997, the LTCM crisis of 1998, the dotcom bubble bursting in 2000, the recent\nhouse price bubbles, the financialization bubble via special investment\nvehicles, the stock market bubble, the commodity and oil bubbles and the debt\nbubbles, all developing jointly and feeding on each other. Rather than still\nhoping that real wealth will come out of money creation, we need fundamentally\nnew ways of thinking. In uncertain times, it is essential, more than ever, to\nthink in scenarios: what can happen in the future, and, what would be the\neffect on your wealth and capital? How can you protect against adverse\nscenarios? We thus end by examining the question \"what can we do?\" from the\nmacro level, discussing the fundamental issue of incentives and of constructing\nand predicting scenarios as well as developing investment insights.\n"
    },
    {
        "paper_id": 1212.3137,
        "authors": "Baojun Bian, Harry Zheng",
        "title": "Smooth Value Function with Applications in Wealth-CVaR Efficient\n  Portfolio and Turnpike Property",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we continue the study of Bian-Miao-Zheng (2011) and extend the\nresults there to a more general class of utility functions which may be bounded\nand non-strictly-concave and show that there is a classical solution to the HJB\nequation with the dual control method. We then apply the results to study the\nefficient frontier of wealth and conditional VaR (CVaR) problem and the\nturnpike property problem. For the former we construct explicitly the optimal\ncontrol and discuss the choice of the optimal threadshold level and illustrate\nthat the wealth and the CVaR are positively correlated. For the latter we give\na simple proof to the turnpike property of the optimal policy of long-run\ninvestors and generalize the results of Huang-Zariphopoulou (1999).\n"
    },
    {
        "paper_id": 1212.3145,
        "authors": "Baojun Bian, Nan Wu, Harry Zheng",
        "title": "Optimal Liquidation in a Finite Time Regime Switching Model with\n  Permanent and Temporary Pricing Impact",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we discuss the optimal liquidation over a finite time horizon\nuntil the exit time. The drift and diffusion terms of the asset price are\ngeneral functions depending on all variables including control and market\nregime. There is also a local nonlinear transaction cost associated to the\nliquidation. The model deals with both the permanent impact and the temporary\nimpact in a regime switching framework. The problem can be solved with the\ndynamic programming principle. The optimal value function is the unique\ncontinuous viscosity solution to the HJB equation and can be computed with the\nfinite difference method.\n"
    },
    {
        "paper_id": 1212.3147,
        "authors": "Guoping Xu, Harry Zheng",
        "title": "Lower Bound Approximation to Basket Option Values for Local Volatility\n  Jump-Diffusion Models",
        "comments": "12 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we derive an easily computed approximation to European basket\ncall prices for a local volatility jump-diffusion model. We apply the\nasymptotic expansion method to find the approximate value of the lower bound of\nEuropean basket call prices. If the local volatility function is time\nindependent then there is a closed-form expression for the approximation.\nNumerical tests show that the suggested approximation is fast and accurate in\ncomparison with the Monte Carlo and other approximation methods in the\nliterature.\n"
    },
    {
        "paper_id": 1212.3195,
        "authors": "Raffaello Morales, T. Di Matteo and Tomaso Aste",
        "title": "Non stationary multifractality in stock returns",
        "comments": "27 pages, 10 figures",
        "journal-ref": "Physica A, 392, 6470-6483, 2013",
        "doi": "10.1016/j.physa.2013.08.037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform an extensive empirical analysis of scaling properties of equity\nreturns, suggesting that financial data show time varying multifractal\nproperties. This is obtained by comparing empirical observations of the\nweighted generalised Hurst exponent (wGHE) with time series simulated via\nMultifractal Random Walk (MRW) by Bacry \\textit{et al.} [\\textit{E.Bacry,\nJ.Delour and J.Muzy, Phys.Rev.E \\,{\\bf 64} 026103, 2001}]. While dynamical wGHE\ncomputed on synthetic MRW series is consistent with a scenario where\nmultifractality is constant over time, fluctuations in the dynamical wGHE\nobserved in empirical data are not in agreement with a MRW with constant\nintermittency parameter. We test these hypotheses of constant multifractality\nconsidering different specifications of MRW model with fatter tails: in all\ncases considered, although the thickness of the tails accounts for most of\nanomalous fluctuations of multifractality, still cannot fully explain the\nobserved fluctuations.\n"
    },
    {
        "paper_id": 1212.3716,
        "authors": "Dirk Tasche",
        "title": "The art of probability-of-default curve calibration",
        "comments": "35 pages, 1 figure, 12 tables, minor changes",
        "journal-ref": "Journal of Credit Risk 9(4), 63-103, 2013",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  PD curve calibration refers to the transformation of a set of rating grade\nlevel probabilities of default (PDs) to another average PD level that is\ndetermined by a change of the underlying portfolio-wide PD. This paper presents\na framework that allows to explore a variety of calibration approaches and the\nconditions under which they are fit for purpose. We test the approaches\ndiscussed by applying them to publicly available datasets of agency rating and\ndefault statistics that can be considered typical for the scope of application\nof the approaches. We show that the popular 'scaled PDs' approach is\ntheoretically questionable and identify an alternative calibration approach\n('scaled likelihood ratio') that is both theoretically sound and performs\nbetter on the test datasets.\n  Keywords: Probability of default, calibration, likelihood ratio, Bayes'\nformula, rating profile, binary classification.\n"
    },
    {
        "paper_id": 1212.3958,
        "authors": "Sara Biagini and Jocelyne Bion-Nadal",
        "title": "Dynamic quasi-concave performance measures",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We define Conditional quasi concave Performance Measures (CPMs), on random\nvariables bounded from below, to accommodate for additional information. Our\nnotion encompasses a wide variety of cases, from conditional expected utility\nand certainty equivalent to conditional acceptability indexes. We provide the\ncharacterization of a CPM in terms of an induced family of conditional convex\nrisk measures. In the case of indexes these risk measures are coherent. Then,\nDynamic Performance Measures (DPMs) are introduced and the problem of time\nconsistency is addressed. The definition of time consistency chosen here\nensures that the positions which are considered good tomorrow are already\nconsidered good today. We prove the equivalence between time consistency for a\nDPM and weak acceptance consistency for the induced families of risk measures.\nFinally, we extend CPMs and DPMs to dividend processes.\n"
    },
    {
        "paper_id": 1212.4126,
        "authors": "Rainer Haidinger and Richard Warnung",
        "title": "Risk Measures in a Regime Switching Model Capturing Stylized Facts",
        "comments": "17 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We pick up the regime switching model for asset returns introduced by Rogers\nand Zhang. The calibration involves various markets including implied\nvolatility in order to gain additional predictive power. We focus on the\ncalculation of risk measures by Fourier methods that have successfully been\napplied to option pricing and analyze the accuracy of the results.\n"
    },
    {
        "paper_id": 1212.4279,
        "authors": "Cassio Neri, Lorenz Schneider",
        "title": "A Note on \"A Family of Maximum Entropy Densities Matching Call Option\n  Prices\"",
        "comments": "6 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In Neri and Schneider (2012) we presented a method to recover the Maximum\nEntropy Density (MED) inferred from prices of call and digital options on a set\nof n strikes. To find the MED we need to numerically invert a one-dimensional\nfunction for n values and a Newton-Raphson method is suggested. In this note we\nrevisit this inversion problem and show that it can be rewritten in terms of\nthe Langevin function for which numerical approximations of its inverse are\nknown. The approach is very similar to that of Buchen and Kelly (BK) with the\ndifference that BK only requires call option prices. Then, in continuation of\nour first paper, we presented another approach which uses call prices only and\nrecovers the same density as BK with a few advantages, notably, numerical\nstability. This second paper provides a detailed analysis of convergence and,\nin particular, gives various estimates of how far (in different senses) the\niterative algorithm is from the solution. These estimates rely on a constant m\n> 0. The larger m is the better the estimates will be. A concrete value of m is\nsuggested in the second paper, and this note provides a sharper value.\n"
    },
    {
        "paper_id": 1212.4293,
        "authors": "F. Tahmasebi, S. Meskini, A. Namaki, G.R. Jafari",
        "title": "Information content of financial markets: a practical approach based on\n  Bohmian quantum mechanics",
        "comments": "9 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Bohmian quantum approach is implemented to analyze the financial markets.\nIn this approach, there is a wave function that leads to a quantum potential.\nThis potential can explain the relevance and entanglements of the agent's\nbehaviors with the past. The light is shed by considering the relevance of the\nmarket conditions with the previous market conditions enabling the conversion\nof the local concepts to the global ones. We have shown that there are two\npotential limits for each market. In essence, these potential limits act as a\nboundary which limits the return values inside it. By estimating the difference\nbetween these two limits in each market, it is found that the quantum\npotentials of the return time series in different time scales, possess a\nscaling behavior. The slopes of the scaling behaviors in mature, emerging and\ncommodity markets show different patterns. The emerge market having a slope\ngreater than 0.5, has a higher value compared to the corresponding values for\nthe mature and commodity markets which is less than 0.5. The cut-off observed\nin the curve of the commodity market indicates the threshold for the efficiency\nof the global effects. While before the cut-off, local effects in the market\nare dominant, as in the case of the mature markets. The findings could prove\nadequate for investors in different markets to invest in different time\nhorizons.\n"
    },
    {
        "paper_id": 1212.4751,
        "authors": "Sebastian M. Krause, Stefan Bornholdt",
        "title": "Opinion formation model for markets with a social temperature and fear",
        "comments": "8 pages, 9 figures",
        "journal-ref": "Phys. Rev. E 86, 056106 (2012)",
        "doi": "10.1103/PhysRevE.86.056106",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the spirit of behavioral finance, we study the process of opinion\nformation among investors using a variant of the 2D Voter Model with a tunable\nsocial temperature. Further, a feedback acting on the temperature is\nintroduced, such that social temperature reacts to market imbalances and thus\nbecomes time dependent. In this toy market model, social temperature represents\nnervousness of agents towards market imbalances representing speculative risk.\nWe use the knowledge about the discontinuous Generalized Voter Model phase\ntransition to determine critical fixed points. The system exhibits metastable\nphases around these fixed points characterized by structured lattice states,\nwith intermittent excursions away from the fixed points. The statistical\nmechanics of the model is characterized and its relation to dynamics of opinion\nformation among investors in real markets is discussed.\n"
    },
    {
        "paper_id": 1212.477,
        "authors": "Jonathan Donier",
        "title": "Market Impact with Autocorrelated Order Flow under Perfect Competition",
        "comments": "37 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our goal in this paper is to study the market impact in a market in which the\norder flow is autocorrelated. We build a model which explains qualitatively and\nquantitatively the empirical facts observed so far concerning market impact. We\ndefine different notions of market impact, and show how they lead to the\ndifferent price paths observed in the literature. For each one, under the\nassumption of perfect competition and information, we derive and explain the\nrelationships between the correlations in the order flow, the shape of the\nmarket impact function while a meta-order is being executed, and the expected\nprice after the completion. We also derive an expression for the decay of\nmarket impact after a trade, and show how it can result in a better liquidation\nstrategy for an informed trader. We show how, in spite of auto-correlation in\norder-flow, prices can be martingales, and how price manipulation is ruled out\neven though the bare impact function is concave. We finally assess the cost of\nmarket impact and try to make a step towards optimal strategies.\n"
    },
    {
        "paper_id": 1212.489,
        "authors": "Mark Leeds",
        "title": "Bollinger Bands Thirty Years Later",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The goal of this study is to explain and examine the statistical\nunderpinnings of the Bollinger Band methodology. We start off by elucidating\nthe rolling regression time series model and deriving its explicit relationship\nto Bollinger Bands. Next we illustrate the use of Bollinger Bands in pairs\ntrading and prove the existence of a specific return duration relationship in\nBollinger Band pairs trading.Then by viewing the Bollinger Band moving average\nas an approximation to the random walk plus noise (RWPN) time series model, we\ndevelop a pairs trading variant that we call \"Fixed Forecast Maximum Duration'\nBands\" (FFMDPT). Lastly, we conduct pairs trading simulations using SAP and\nNikkei index data in order to compare the performance of the variant with\nBollinger Bands.\n"
    },
    {
        "paper_id": 1212.4894,
        "authors": "Erhan Bayraktar and Zhou Zhou",
        "title": "On controller-stopper problems with jumps and their applications to\n  indifference pricing of American options",
        "comments": "To appear in SIFIN (SIAM Journal on Financial Mathematics). Keywords:\n  Controller-stopper problems, jumps, decomposition, indifference pricing,\n  American options, RBSDEs",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider controller-stopper problems in which the controlled processes can\nhave jumps. The global filtration is represented by the Brownian filtration,\nenlarged by the filtration generated by the jump process. We assume that there\nexists a conditional probability density function for the jump times and marks\ngiven the filtration of the Brownian motion and decompose the global\ncontroller-stopper problem into controller-stopper problems with respect to the\nBrownian filtration, which are determined by a backward induction. We apply our\ndecomposition method to indifference pricing of American options under multiple\ndefault risk. The backward induction leads to a system of reflected backward\nstochastic differential equations (RBSDEs). We show that there exists a\nsolution to this RBSDE system and that the solution provides a characterization\nof the value function.\n"
    },
    {
        "paper_id": 1212.507,
        "authors": "Grech Dariusz, Mazur Zygmunt",
        "title": "On the scaling range of power-laws originated from fluctuation analysis",
        "comments": "20 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend our previous study of scaling range properties done for detrended\nfluctuation analysis (DFA) \\cite{former_paper} to other techniques of\nfluctuation analysis (FA). The new technique called Modified Detrended Moving\nAverage Analysis (MDMA) is introduced and its scaling range properties are\nexamined and compared with those of detrended moving average analysis (DMA) and\nDFA. It is shown that contrary to DFA, DMA and MDMA techniques exhibit power\nlaw dependence of the scaling range with respect to the length of the searched\nsignal and with respect to the accuracy $R^2$ of the fit to the considered\nscaling law imposed by DMA or MDMA schemes. This power law dependence is\nsatisfied for both uncorrelated and autocorrelated data. We find also a simple\ngeneralization of this power law relation for series with different level of\nautocorrelations measured in terms of the Hurst exponent. Basic relations\nbetween scaling ranges for different techniques are also discussed. Our\nfindings should be particularly useful for local FA in e.g., econophysics,\nfinances or physiology, where the huge number of short time series has to be\nexamined at once and wherever the preliminary check of the scaling range regime\nfor each of the series separately is neither effective nor possible.\n"
    },
    {
        "paper_id": 1212.5395,
        "authors": "Claudio Fontana and Juan Miguel A. Montes",
        "title": "A unified approach to pricing and risk management of equity and credit\n  risk",
        "comments": "18 pages, 4 figures. Revised version (remarks and references added)",
        "journal-ref": "Journal of Computational and Applied Mathematics (2014), vol. 259,\n  pp. 350-261",
        "doi": "10.1016/j.cam.2013.04.047",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a unified framework for equity and credit risk modeling, where the\ndefault time is a doubly stochastic random time with intensity driven by an\nunderlying affine factor process. This approach allows for flexible\ninteractions between the defaultable stock price, its stochastic volatility and\nthe default intensity, while maintaining full analytical tractability. We\ncharacterise all risk-neutral measures which preserve the affine structure of\nthe model and show that risk management as well as pricing problems can be\ndealt with efficiently by shifting to suitable survival measures. As an\nexample, we consider a jump-to-default extension of the Heston stochastic\nvolatility model.\n"
    },
    {
        "paper_id": 1212.5563,
        "authors": "Zachary Feinstein, Birgit Rudloff",
        "title": "Multiportfolio time consistency for set-valued convex and coherent risk\n  measures",
        "comments": null,
        "journal-ref": "Finance and Stochastics 19 (1), 67-107 (2015)",
        "doi": "10.1007/s00780-014-0247-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Equivalent characterizations of multiportfolio time consistency are deduced\nfor closed convex and coherent set-valued risk measures on $L^p(\\Omega,\\mathcal\nF, P; R^d)$ with image space in the power set of $L^p(\\Omega,\\mathcal\nF_t,P;R^d)$. In the convex case, multiportfolio time consistency is equivalent\nto a cocycle condition on the sum of minimal penalty functions. In the coherent\ncase, multiportfolio time consistency is equivalent to a generalized version of\nstability of the dual variables. As examples, the set-valued entropic risk\nmeasure with constant risk aversion coefficient is shown to satisfy the cocycle\ncondition for its minimal penalty functions, the set of superhedging portfolios\nin markets with proportional transaction costs is shown to have the stability\nproperty and in markets with convex transaction costs is shown to satisfy the\ncomposed cocycle condition, and a multiportfolio time consistent version of the\nset-valued average value at risk, the composed AV@R, is given and its dual\nrepresentation deduced.\n"
    },
    {
        "paper_id": 1212.6016,
        "authors": "Gordon J. Ross",
        "title": "Modeling Financial Volatility in the Presence of Abrupt Changes",
        "comments": null,
        "journal-ref": "Physica A: Statistical Mechanics and its Applications (2013).\n  192(2) 350-360",
        "doi": "10.1016/j.physa.2012.08.015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The volatility of financial instruments is rarely constant, and usually\nvaries over time. This creates a phenomenon called volatility clustering, where\nlarge price movements on one day are followed by similarly large movements on\nsuccessive days, creating temporal clusters. The GARCH model, which treats\nvolatility as a drift process, is commonly used to capture this behavior.\nHowever research suggests that volatility is often better described by a\nstructural break model, where the volatility undergoes abrupt jumps in addition\nto drift. Most efforts to integrate these jumps into the GARCH methodology have\nresulted in models which are either very computationally demanding, or which\nmake problematic assumptions about the distribution of the instruments, often\nassuming that they are Gaussian. We present a new approach which uses ideas\nfrom nonparametric statistics to identify structural break points without\nmaking such distributional assumptions, and then models drift separately within\neach identified regime. Using our method, we investigate the volatility of\nseveral major stock indexes, and find that our approach can potentially give an\nimproved fit compared to more commonly used techniques.\n"
    },
    {
        "paper_id": 1212.6275,
        "authors": "Dylan Possama\\\"i and H. Mete Soner and Nizar Touzi",
        "title": "Homogenization and asymptotics for small transaction costs: the\n  multidimensional case",
        "comments": "46 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the context of the multi-dimensional infinite horizon optimal\nconsumption-investment problem with proportional transaction costs, we provide\nthe first order expansion in small transact costs. Similar to the\none-dimensional derivation in our accompanying paper [42], the asymptotic\nexpansion is expressed in terms of a singular ergodic control problem, and our\narguments are based on the theory of viscosity solutions, and the techniques of\nhomogenization which leads to a system of corrector equations. In contrast with\nthe one-dimensional case, no explicit solution of the first corrector equation\nis available anymore. Finally, we provide some numerical results which\nillustrate the structure of the first order optimal controls.\n"
    },
    {
        "paper_id": 1212.63,
        "authors": "Bruce M. Boghosian",
        "title": "The Kinetics of Wealth and the Origin of the Pareto Law",
        "comments": "31 pages, 28 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.89.042804",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An important class of economic models involve agents whose wealth changes due\nto transactions with other agents. Several authors have pointed out an analogy\nwith kinetic theory, which describes molecules whose momentum and energy\nchanges due to interactions with other molecules. We pursue this analogy and\nderive a Boltzmann equation for the time evolution of the wealth distribution\nof a population of agents for the so-called Yard-Sale Model of wealth exchange.\nWe examine the solutions to this equation by a combination of analytical and\nnumerical methods, and investigate its long-time limit. We study an important\nlimit of this equation for small transaction sizes, and derive a partial\nintegrodifferential equation governing the evolution of the wealth distribution\nin a closed economy. We then describe how this model may be extended to include\nfeatures such as inflation, production and taxation. In particular, we show\nthat the model with taxation is capable of explaining the basic features of the\nPareto law, namely a lower cutoff to the wealth density at small values of\nwealth, and approximate power-law behavior at large values of wealth.\n"
    },
    {
        "paper_id": 1212.6601,
        "authors": "V. Sasidevan and Deepak Dhar",
        "title": "Strategy switches and co-action equilibria in a minority game",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2014.02.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose an analytically tractable variation of the minority game in which\nrational agents use probabilistic strategies. In our model, $N$ agents choose\nbetween two alternatives repeatedly, and those who are in the minority get a\npay-off 1, others zero. The agents optimize the expectation value of their\ndiscounted future pay-off, the discount parameter being $\\lambda$. We propose\nan alternative to the standard Nash equilibrium, called co-action equilibrium,\nwhich gives higher expected pay-off for all agents. The optimal choice of\nprobabilities of different actions are determined exactly in terms of simple\nself -consistent equations. The optimal strategy is characterized by $N$ real\nparameters, which are non-analytic functions of $\\lambda$, even for a finite\nnumber of agents. The solution for $N \\leq 7$ is worked out explicitly\nindicating the structure of the solution for larger $N$. For large enough\nfuture time horizon, the optimal strategy switches from random choice to a\nwin-stay lose-shift strategy, with the shift probability depending on the\ncurrent state and $\\lambda$.\n"
    },
    {
        "paper_id": 1212.6732,
        "authors": "Samuel Drapeau and Michael Kupper and Antonis Papapantoleon",
        "title": "A Fourier Approach to the Computation of CV@R and Optimized Certainty\n  Equivalents",
        "comments": null,
        "journal-ref": "Journal of Risk 16(6), 3-29, 2014",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the class of risk measures associated with optimized certainty\nequivalents. This class includes several popular examples, such as CV@R and\nmonotone mean-variance. Numerical schemes are developed for the computation of\nthese risk measures using Fourier transform methods. This leads, in particular,\nto a very competitive method for the calculation of CV@R which is comparable in\ncomputational time to the calculation of V@R. We also develop methods for the\nefficient computation of risk contributions.\n"
    },
    {
        "paper_id": 1212.6791,
        "authors": "Younes Ben-Ghabrit",
        "title": "The normaly distributed daily returns in stock trading",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this report, we talked about a new quantitative strategy for choosing the\noptimal(s) stock(s) to trade. The basic notions are generally very known by the\nfinancial community. The key here is to understand 1) the standard score\napplied to a sample and 2) the correlation factor applied to different time\nseries in real life. These notions are the core of our research. We are going\nto begin with the introduction section. In this part, we talked about variance,\ncovariance, correlation factor, daily returns in stock trading and the\nShapiro-Wilk test to test the normality of a time serie. Next to that, I talked\nabout the core of my method (what do you do if you want to pick the optimal(s)\nstock(s) to trade). At the end of this report, I talked about a new idea if you\nwant to analyze more than one stock at the time. All my work goes with a\nprimary reflexion : forecasting a stock direction is a random walk and nobody\ncan be 100 % sure where a stock is going. All we can do, is to pretend to have\na technic with a win/loss ratio greater than 51 %.\n"
    },
    {
        "paper_id": 1212.6795,
        "authors": "Mazen Kebewar",
        "title": "La structure du capital et la profitabilit\\'e: Le cas des entreprises\n  industrielles fran\\c{c}aises",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The objective of this article is to analyze the impact of capital structure\non profitability. This impact can be explained by three essential theories:\nsignaling theory, tax theory and the agency costs theory. A sample of 1846\nFrench industrial firms are taken over the period 1999-2006, as a dynamic panel\nstudy by using the generalized method of moments (GMM). We show that capital\nstructure has no influence on the profitability of French firms, regardless the\nsize of the company.\n"
    },
    {
        "paper_id": 1301.0007,
        "authors": "Zhi-Qiang Jiang (ECUST), Wen-Jie Xie (ECUST), Xiong Xiong (TJU), Wei\n  Zhang (TJU), Yong-Jie Zhang (TJU), W.-X. Zhou (ECUST)",
        "title": "Trading networks, abnormal motifs and stock manipulation",
        "comments": "14 Latex pages including 5 figures and 2 tables, Submitted to QFL",
        "journal-ref": "Quantitative Finance Letters 1, 1-8 (2013)",
        "doi": "10.1080/21649502.2013.802877",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study trade-based manipulation of stock prices from the perspective of\ncomplex trading networks constructed by using detailed information of trades. A\nstock trading network consists of nodes and directed links, where every trader\nis a node and a link is formed from one trader to the other if the former sells\nshares to the latter. Specifically, three abnormal network motifs are\ninvestigated, which are found to be formed by a few traders, implying potential\nintention of price manipulation. We further investigate the dynamics of\nvolatility, trading volume, average trade size and turnover around the\ntransactions associated with the abnormal motifs for large, medium and small\ntrades. It is found that these variables peak at the abnormal events and\nexhibit a power-law accumulation in the pre-event time period and a power-law\nrelaxation in the post-event period. We also find that the cumulative excess\nreturns are significantly positive after buyer-initiated suspicious trades and\nexhibit a mild price reversal after seller-initiated suspicious trades. These\nfindings can be better understood in favor of price manipulation. Our work shed\nnew lights into the detection of price manipulation resorting to the abnormal\nmotifs of complex trading networks.\n"
    },
    {
        "paper_id": 1301.0072,
        "authors": "Mazen Kebewar",
        "title": "The effect of debt on corporate profitability : Evidence from French\n  service sector",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Current study aims to provide new empirical evidence on the impact of debt on\ncorporate profitability. This impact can be explained by three essential\ntheories: signaling theory, tax theory and the agency cost theory. Using panel\ndata sample of 2240 French non listed companies of service sector during\n1999-2006. By utilizing generalized method of moments (GMM) econometric\ntechnique on three measures of profitability ratio (PROF1, PROF2 and ROA), we\nshow that debt ratio has no effect on corporate profitability, regardless of\nthe size of company (VSEs, SMEs or LEs)\n"
    },
    {
        "paper_id": 1301.0091,
        "authors": "Erhan Bayraktar and Song Yao",
        "title": "On the Robust Optimal Stopping Problem",
        "comments": "Final Version, 50 pages. This is a much more comprehensive version of\n  what appeared in the SIAM Journal on Control and Optimization",
        "journal-ref": "SIAM Journal on Control and Optimization, 52(5), 3135-3175, 2014",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a robust optimal stopping problem with respect to a set $\\cP$ of\nmutually singular probabilities. This can be interpreted as a zero-sum\ncontroller-stopper game in which the stopper is trying to maximize its pay-off\nwhile an adverse player wants to minimize this payoff by choosing an evaluation\ncriteria from $\\cP$. We show that the \\emph{upper Snell envelope $\\ol{Z}$} of\nthe reward process $Y$ is a supermartingale with respect to an appropriately\ndefined nonlinear expectation $\\ul{\\sE}$, and $\\ol{Z}$ is further an\n$\\ul{\\sE}-$martingale up to the first time $\\t^*$ when $\\ol{Z}$ meets $Y$.\nConsequently, $\\t^*$ is the optimal stopping time for the robust optimal\nstopping problem and the corresponding zero-sum game has a value. Although the\nresult seems similar to the one obtained in the classical optimal stopping\ntheory, the mutual singularity of probabilities and the game aspect of the\nproblem give rise to major technical hurdles, which we circumvent using some\nnew methods.\n"
    },
    {
        "paper_id": 1301.0109,
        "authors": "Jia-Wen Gu, Wai-Ki Ching, Tak-Kuen Siu and Harry Zheng",
        "title": "On Reduced Form Intensity-based Model with Trigger Events",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Corporate defaults may be triggered by some major market news or events such\nas financial crises or collapses of major banks or financial institutions. With\na view to develop a more realistic model for credit risk analysis, we introduce\na new type of reduced-form intensity-based model that can incorporate the\nimpacts of both observable \"trigger\" events and economic environment on\ncorporate defaults. The key idea of the model is to augment a Cox process with\ntrigger events. Both single-default and multiple-default cases are considered\nin this paper. In the former case, a simple expression for the distribution of\nthe default time is obtained. Applications of the proposed model to price\ndefaultable bonds and multi-name Credit Default Swaps (CDSs) are provided.\n"
    },
    {
        "paper_id": 1301.0186,
        "authors": "Jia-Wen Gu, Wai-Ki Ching, Tak-Kuen Siu and Harry Zheng",
        "title": "On Infectious Model for Dependent Defaults",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we propose a two-sector Markovian infectious model, which is\nan extension of Greenwood's model. The central idea of this model is that the\ncausality of defaults of two sectors is in both direction, which enrich\ndependence dynamics. The Bayesian Information Criterion is adopted to compare\nthe proposed model with the two-sector model in credit literature using the\nreal data. We find that the newly proposed model is statistically better than\nthe model in past literature. We also introduce two measures: CRES and CRVaR to\ngive risk evaluation of our model.\n"
    },
    {
        "paper_id": 1301.028,
        "authors": "Salvatore Federico, Paul Gassiat, Fausto Gozzi",
        "title": "Utility maximization with current utility on the wealth: regularity of\n  solutions to the HJB equation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a utility maximization problem for an investment-consumption\nportfolio when the current utility depends also on the wealth process. Such\nkind of problems arise, e.g., in portfolio optimization with random horizon or\nwith random trading times. To overcome the difficulties of the problem we use\nthe dual approach. We define a dual problem and treat it by means of dynamic\nprogramming, showing that the viscosity solutions of the associated\nHamilton-Jacobi-Bellman equation belong to a suitable class of smooth\nfunctions. This allows to define a smooth solution of the primal\nHamilton-Jacobi-Bellman equation, proving that this solution is indeed unique\nin a suitable class and coincides with the value function of the primal\nproblem. Some financial applications of the results are provided.\n"
    },
    {
        "paper_id": 1301.0381,
        "authors": "Nikolai Dokuchaev",
        "title": "Optimal replication of random claims by ordinary integrals with\n  applications in finance",
        "comments": null,
        "journal-ref": "SIAM Conference on Control and Its Applications, Jul 8, 2013, San\n  Diego, California USA: Society for Industrial and Applied Mathematics;pp.\n  59-66",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By the classical Martingale Representation Theorem, replication of random\nvectors can be achieved via stochastic integrals or solutions of stochastic\ndifferential equations. We introduce a new approach to replication of random\nvectors via adapted differentiable processes generated by a controlled ordinary\ndifferential equation. We found that the solution of this replication problem\nexists and is not unique. This leads to a new optimal control problem: find a\nreplicating process that is minimal in an integral norm. We found an explicit\nsolution of this problem. Possible applications to portfolio selection problems\nand to bond pricing models are suggested.\n"
    },
    {
        "paper_id": 1301.0594,
        "authors": "David M Pennock, Sandip Debnath, Eric Glover, C. Lee Giles",
        "title": "Modelling Information Incorporation in Markets, with Application to\n  Detecting and Explaining Events",
        "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a model of how information flows into a market, and derive\nalgorithms for automatically detecting and explaining relevant events. We\nanalyze data from twenty-two \"political stock markets\" (i.e., betting markets\non political outcomes) on the Iowa Electronic Market (IEM). We prove that,\nunder certain efficiency assumptions, prices in such betting markets will on\naverage approach the correct outcomes over time, and show that IEM data\nconforms closely to the theory. We present a simple model of a betting market\nwhere information is revealed over time, and show a qualitative correspondence\nbetween the model and real market data. We also present an algorithm for\nautomatically detecting significant events and generating semantic explanations\nof their origin. The algorithm operates by discovering significant changes in\nvocabulary on online news sources (using expected entropy loss) that align with\nmajor price spikes in related betting markets.\n"
    },
    {
        "paper_id": 1301.0719,
        "authors": "Han Feng and David Hobson",
        "title": "Gambling in contests with regret",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper discusses the gambling contest introduced in Seel & Strack\n(Gambling in contests, Discussion Paper Series of SFB/TR 15 Governance and the\nEfficiency of Economic Systems 375, Mar 2012.) and considers the impact of\nadding a penalty associated with failure to follow a winning strategy.\n  The Seel & Strack model consists of $n$-agents each of whom privately\nobserves a transient diffusion process and chooses when to stop it. The player\nwith the highest stopped value wins the contest, and each player's objective is\nto maximise their probability of winning the contest. We give a new derivation\nof the results of Seel & Strack based on a Lagrangian approach. Moreover, we\nconsider an extension of the problem in which in the case when an agent is\npenalised when their strategy is suboptimal, in the sense that they do not win\nthe contest, but there existed an alternative strategy which would have\nresulted in victory.\n"
    },
    {
        "paper_id": 1301.0907,
        "authors": "Phillip Monin",
        "title": "On a dynamic adaptation of the Distribution Builder approach to\n  investment decisions",
        "comments": "42 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Sharpe et al. proposed the idea of having an expected utility maximizer\nchoose a probability distribution for future wealth as an input to her\ninvestment problem instead of a utility function. They developed a computer\nprogram, called The Distribution Builder, as one way to elicit such a\ndistribution. In a single-period model, they then showed how this desired\ndistribution for terminal wealth can be used to infer the investor's risk\npreferences. We adapt their idea, namely that a risk-averse investor can choose\na desired distribution for future wealth as an alternative input attribute for\ninvestment decisions, to continuous time. In a variety of scenarios, we show\nhow the investor's desired distribution combines with her initial wealth and\nmarket-related input to determine the feasibility of her distribution, her\nimplied risk preferences, and her optimal policies throughout her investment\nhorizon. We then provide several examples.\n"
    },
    {
        "paper_id": 1301.101,
        "authors": "Saeed Mehraban, Amirhossein Shirazi, Maryam Zamani, Gholamreza Jafari",
        "title": "Coupling between time series: a network view",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1209/0295-5075/103/50011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recently, the visibility graph has been introduced as a novel view for\nanalyzing time series, which maps it to a complex network. In this paper, we\nintroduce new algorithm of visibility, \"cross-visibility\", which reveals the\nconjugation of two coupled time series. The correspondence between the two time\nseries is mapped to a network, \"the cross-visibility graph\", to demonstrate the\ncorrelation between them. We applied the algorithm to several correlated and\nuncorrelated time series, generated by the linear stationary ARFIMA process.\nThe results demonstrate that the cross-visibility graph associated with\ncorrelated time series with power-law auto-correlation is scale-free. If the\ntime series are uncorrelated, the degree distribution of their cross-visibility\nnetwork deviates from power-law. For more clarifying the process, we applied\nthe algorithm to real-world data from the financial trades of two companies,\nand observed significant small-scale coupling in their dynamics.\n"
    },
    {
        "paper_id": 1301.109,
        "authors": "N.J.Moura Jr (1) and Marcelo B. Ribeiro (2), ((1) Instituto Brasileiro\n  de Geografia e Estat\\'istica - IBGE, Rio de Janeiro, Brazil, (2) Instituto de\n  F\\'isica, Universidade Federal do Rio de Janeiro, Brazil)",
        "title": "Testing the Goodwin growth-cycle macroeconomic dynamics in Brazil",
        "comments": "21 pages, 9 figures, 1 table, LaTeX. Minor changes to match corrected\n  proofs. To appear in \"Physica A\"",
        "journal-ref": "Physica A, 392 (2013) 2088-2103",
        "doi": "10.1016/j.physa.2013.01.024",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper discusses the empirical validity of Goodwin's (1967) macroeconomic\nmodel of growth with cycles by assuming that the individual income distribution\nof the Brazilian society is described by the Gompertz-Pareto distribution\n(GPD). This is formed by the combination of the Gompertz curve, representing\nthe overwhelming majority of the population (~99%), with the Pareto power law,\nrepresenting the tiny richest part (~1%). In line with Goodwin's original\nmodel, we identify the Gompertzian part with the workers and the Paretian\ncomponent with the class of capitalists. Since the GPD parameters are obtained\nfor each year and the Goodwin macroeconomics is a time evolving model, we use\npreviously determined, and further extended here, Brazilian GPD parameters, as\nwell as unemployment data, to study the time evolution of these quantities in\nBrazil from 1981 to 2009 by means of the Goodwin dynamics. This is done in the\noriginal Goodwin model and an extension advanced by Desai et al. (2006). As far\nas Brazilian data is concerned, our results show partial qualitative and\nquantitative agreement with both models in the studied time period, although\nthe original one provides better data fit. Nevertheless, both models fall short\nof a good empirical agreement as they predict single center cycles which were\nnot found in the data. We discuss the specific points where the Goodwin\ndynamics must be improved in order to provide a more realistic representation\nof the dynamics of economic systems.\n"
    },
    {
        "paper_id": 1301.1135,
        "authors": "E. Bacry and J.F Muzy",
        "title": "Hawkes model for price and trades high-frequency dynamics",
        "comments": "12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a multivariate Hawkes process that accounts for the dynamics of\nmarket prices through the impact of market order arrivals at microstructural\nlevel. Our model is a point process mainly characterized by 4 kernels\nassociated with respectively the trade arrival self-excitation, the price\nchanges mean reversion the impact of trade arrivals on price variations and the\nfeedback of price changes on trading activity. It allows one to account for\nboth stylized facts of market prices microstructure (including random time\narrival of price moves, discrete price grid, high frequency mean reversion,\ncorrelation functions behavior at various time scales) and the stylized facts\nof market impact (mainly the concave-square-root-like/relaxation characteristic\nshape of the market impact of a meta-order). Moreover, it allows one to\nestimate the entire market impact profile from anonymous market data. We show\nthat these kernels can be estimated from the empirical conditional mean\nintensities. We provide numerical examples, application to real data and\ncomparisons to former approaches.\n"
    },
    {
        "paper_id": 1301.1471,
        "authors": "Frank Riedel and Tobias Hellmann",
        "title": "The Foster-Hart Measure of Riskiness for General Gambles",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Foster and Hart proposed an operational measure of riskiness for discrete\nrandom variables. We show that their defining equation has no solution for many\ncommon continuous distributions including many uniform distributions, e.g. We\nshow how to extend consistently the definition of riskiness to continuous\nrandom variables. For many continuous random variables, the risk measure is\nequal to the worst--case risk measure, i.e. the maximal possible loss incurred\nby that gamble. We also extend the Foster--Hart risk measure to dynamic\nenvironments for general distributions and probability spaces, and we show that\nthe extended measure avoids bankruptcy in infinitely repeated gambles.\n"
    },
    {
        "paper_id": 1301.1496,
        "authors": "Ignacio Cascos and Ilya Molchanov",
        "title": "Multivariate risk measures: a constructive approach based on selections",
        "comments": "38 pages, 5 figures. Corrections to Section 7 concerning the duality\n  results",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Since risky positions in multivariate portfolios can be offset by various\nchoices of capital requirements that depend on the exchange rules and related\ntransaction costs, it is natural to assume that the risk measures of random\nvectors are set-valued. Furthermore, it is reasonable to include the exchange\nrules in the argument of the risk measure and so consider risk measures of\nset-valued portfolios. This situation includes the classical Kabanov's\ntransaction costs model, where the set-valued portfolio is given by the sum of\na random vector and an exchange cone, but also a number of further cases of\nadditional liquidity constraints.\n  We suggest a definition of the risk measure based on calling a set-valued\nportfolio acceptable if it possesses a selection with all individually\nacceptable marginals. The obtained selection risk measure is coherent (or\nconvex), law invariant and has values being upper convex closed sets. We\ndescribe the dual representation of the selection risk measure and suggest\nefficient ways of approximating it from below and from above. In case of\nKabanov's exchange cone model, it is shown how the selection risk measure\nrelates to the set-valued risk measures considered by Kulikov (2008), Hamel and\nHeyde (2010), and Hamel, Heyde and Rudloff (2013).\n"
    },
    {
        "paper_id": 1301.1824,
        "authors": "Jan A. Lipski, Ryszard Kutner",
        "title": "Trust in foreseeing neighbours - a novel threshold model of financial\n  market",
        "comments": "Accepted at Acta Physica Polonica A, to be published in early 2013",
        "journal-ref": null,
        "doi": "10.12693/APhysPolA.123.584",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The three-state agent-based 2D model of financial markets in the version\nproposed by Giulia Iori in 2002 has been herein extended. We have introduced\nthe increase of herding behaviour by modelling the altering trust of an agent\nin his nearest neighbours. The trust increases if the neighbour has foreseen\nthe price change correctly and the trust decreases in the opposite case. Our\nversion only slightly increases the number of parameters present in the Iori\nmodel. This version well reproduces the main stylized facts observed on\nfinancial markets. That is, it reproduces log-returns clustering, fat-tail\nlog-returns distribution and power-law decay in time of the volatility\nautocorrelation function.\n"
    },
    {
        "paper_id": 1301.1893,
        "authors": "Milan \\v{Z}ukovi\\v{c}",
        "title": "Dynamics of episodic transient correlations in currency exchange rate\n  returns and their predictability",
        "comments": "19 pages, 8 figures",
        "journal-ref": "Central European Journal of Physics 10 (3) 615 (2012)",
        "doi": "10.2478/s11534-011-0120-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the dynamics of the linear and non-linear serial dependencies in\nfinancial time series in a rolling window framework. In particular, we focus on\nthe detection of episodes of statistically significant two- and three-point\ncorrelations in the returns of several leading currency exchange rates that\ncould offer some potential for their predictability. We employ a rolling window\napproach in order to capture the correlation dynamics for different window\nlengths and analyze the distributions of periods with statistically significant\ncorrelations. We find that for sufficiently large window lengths these\ndistributions fit well to power-law behavior. We also measure the\npredictability itself by a hit rate, i.e. the rate of consistency between the\nsigns of the actual returns and their predictions, obtained from a simple\ncorrelation-based predictor. It is found that during these relatively brief\nperiods the returns are predictable to a certain degree and the predictability\ndepends on the selection of the window length.\n"
    },
    {
        "paper_id": 1301.2076,
        "authors": "Maciej Jagielski and Ryszard Kutner",
        "title": "Modeling of income distribution in the European Union with the\n  Fokker-Planck equation",
        "comments": "Accepted for publication in Physcia A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.01.028",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Herein, we applied statistical physics to study incomes of three (low-,\nmedium- and high-income) society classes instead of the two (low- and\nmedium-income)classes studied so far. In the frame of the threshold nonlinear\nLangevin dynamics and its threshold Fokker-Planck counterpart, we derived a\nunified formula for description of income of all society classes, by way of\nexample, of those of the European Union in year 2006 and 2008. Hence, the\nformula is more general than the well known that of Yakovenko et al. That is,\nour formula well describes not only two regions but simultaneously the third\nregion in the plot of the complementary cumulative distribution function vs. an\nannual household income. Furthermore, the known stylised facts concerning this\nincome are well described by our formula. Namely, the formula provides the\nBoltzmann-Gibbs income distribution function for the low-income society class\nand the weak Pareto law for the medium-income society class, as expected.\nImportantly, it predicts (to satisfactory approximation) the Zipf law for the\nhigh-income society class. Moreover, the region of medium-income society class\nis now distinctly reduced because the bottom of high-income society class is\ndistinctly lowered. This reduction made, in fact, the medium-income society\nclass an intermediate-income society class.\n"
    },
    {
        "paper_id": 1301.2169,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Consumers behavior of Portuguese wine",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There are few papers about the consumption pattern of the Portuguese wine,\nusing econometrics techniques. This work, pretend to analyze the consumers\nbehavior of the wine produced in Portugal, determining the demand equation with\npanel data methods. There were used statistical data available in the Alentejo\nRegional Winegrowing Commission (CVRA) website. These data were obtained from a\nstudy about the market analysis, made, in 2009, by the A.C. Nielsen. The data\nare disaggregated by region and type of wine (Doc Verde+Regional Minho, Doc\nRegiao do Douro+Regional Terras Durienses, Doc Regiao da Bairrada+Regional\nBeiras, Doc Regiao do Dao+Regional Beiras, Doc da Regiao de Lisboa+Regional de\nLisboa, Doc da Regiao do Tejo+Regional do Tejo, Doc da Regiao de\nSetubal+Regional Terras do Sado, Doc Alentejo+Regional Alentejano e Doc da\nRegiao do Algarve+Regional do Algarve), year (2008 and 2009) and by form of\nconsumption (take home, direct consumption and discount). This work found some\nlinear regularity in the consumers behavior of the Portuguese wine.\n"
    },
    {
        "paper_id": 1301.2196,
        "authors": "Aleksandar Bradic",
        "title": "The Role of Social Feedback in Financing of Technology Ventures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This research examines relationship between staging of Venture Capital (VC)\ninvestments and social feedback visible in publicly available data on the Web.\nWe address the question of Venture Capital investment sensitivity to\nperformance and prospects of new venture, given as likelihood of obtaining\nfuture financing, available exit options and duration between investment\nrounds. We argue that in the case of Internet companies, publicly available\nsocial feedback data, such as search trends and website traffic information,\ncan be used as a proxy for some of company's internal metrics such as user base\ngrowth and product adoption. In order to answer questions of interest, we\ncompile unique dataset consisting of detailed information about Venture Capital\ninvestments in the Internet Technology sector over the period from 2004 to 2012\nand associated longitudinal search trend and website traffic data. By applying\nmethods of survival analysis, we find that positive trends in search and\nwebsite traffic volumes can lead to increased likelihood of future financing\nand shortening of duration between subsequent financing rounds. We also find\nevidence that social feedback only impacts company's ability to attract next\nround of financing or exit via IPO, while M&A exits seem relatively independent\nof such performance metrics and can occur at any stage of company development.\nSuch findings provide strong evidence in support of learning hypothesis and\nsuggest VC's ability to identify prospects of new venture early in it's\ndevelopment and allocate funding accordingly. Given research also provides\nmethodological contributions to the problem of evaluating the prospects of new\nstartup companies using only publicly available data, and as such should be of\ninterest in applications such as new investment screening and industry-level\nassessments by analysts or policy makers.\n"
    },
    {
        "paper_id": 1301.2363,
        "authors": "Stefania Vitali, Stefano Battiston",
        "title": "The Community Structure of the Global Corporate Network",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0104655",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the community structure of the global ownership network of\ntransnational corporations. We find a pronounced organization in communities\nthat cannot be explained by randomness. Despite the global character of this\nnetwork, communities reflect first of all the geographical location of firms,\nwhile the industrial sector plays only a marginal role. We also analyze the\nnetwork in which the nodes are the communities and the links are obtained by\naggregating the links among firms belonging to pairs of communities. We analyze\nthe network centrality of the top 50 communities and we provide the first\nquantitative assessment of the financial sector role in connecting the global\neconomy.\n"
    },
    {
        "paper_id": 1301.253,
        "authors": "M. Wili\\'nski, A. Sienkiewicz, T. Gubiec, R. Kutner and Z.R. Struzik",
        "title": "Structural and topological phase transitions on the German Stock\n  Exchange",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.07.064",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We find numerical and empirical evidence for dynamical, structural and\ntopological phase transitions on the (German) Frankfurt Stock Exchange (FSE) in\nthe temporal vicinity of the worldwide financial crash. Using the Minimal\nSpanning Tree (MST) technique, a particularly useful canonical tool of the\ngraph theory, two transitions of the topology of a complex network representing\nFSE were found. First transition is from a hierarchical scale-free MST\nrepresenting the stock market before the recent worldwide financial crash, to a\nsuperstar-like MST decorated by a scale-free hierarchy of trees representing\nthe market's state for the period containing the crash. Subsequently, a\ntransition is observed from this transient, (meta)stable state of the crash, to\na hierarchical scale-free MST decorated by several star-like trees after the\nworldwide financial crash. The phase transitions observed are analogous to the\nones we obtained earlier for the Warsaw Stock Exchange and more pronounced than\nthose found by Onnela-Chakraborti-Kaski-Kert\\'esz for S&P 500 index in the\nvicinity of Black Monday (October 19, 1987) and also in the vicinity of January\n1, 1998. Our results provide an empirical foundation for the future theory of\ndynamical, structural and topological phase transitions on financial markets.\n"
    },
    {
        "paper_id": 1301.2535,
        "authors": "Mateusz Denys, Tomasz Gubiec, Ryszard Kutner",
        "title": "Reinterpretation of Sieczka-Ho{\\l}yst financial market model",
        "comments": null,
        "journal-ref": null,
        "doi": "10.12693/APhysPolA.123.513",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we essentially reinterpreted the Sieczka-Ho{\\l}yst (SH) model to\nmake it more suited for description of real markets. For instance, this\nreinterpretation made it possible to consider agents as crafty. These agents\nencourage their neighbors to buy some stocks if agents have an opportunity to\nsell these stocks. Also, agents encourage them to sell some stocks if agents\nhave an opposite opportunity. Furthermore, in our interpretation price changes\nrespond only to the agents' opinions change. This kind of respond protects the\nstock market dynamics against the paradox (present in the SH model), where all\nagents e.g. buy stocks while the corresponding prices remain unchanged. In this\nwork we found circumstances, where distributions of returns (obtained for quite\ndifferent time scales) either obey power-law or have at least fat tails. We\nobtained these distributions from numerical simulations performed in the frame\nof our approach.\n"
    },
    {
        "paper_id": 1301.2728,
        "authors": "Misako Takayasu, Hayafumi Watanabe, Hideki Takayasu",
        "title": "Generalised central limit theorems for growth rate distribution of\n  complex systems",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/s10955-014-0956-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a solvable model of randomly growing systems consisting of many\nindependent subunits. Scaling relations and growth rate distributions in the\nlimit of infinite subunits are analysed theoretically. Various types of scaling\nproperties and distributions reported for growth rates of complex systems in a\nvariety of fields can be derived from this basic physical model. Statistical\ndata of growth rates for about 1 million business firms are analysed as a\nreal-world example of randomly growing systems. Not only are the scaling\nrelations consistent with the theoretical solution, but the entire functional\nform of the growth rate distribution is fitted with a theoretical distribution\nthat has a power-law tail.\n"
    },
    {
        "paper_id": 1301.2964,
        "authors": "Dorje C. Brody, Lane P. Hughston",
        "title": "L\\'evy Information and the Aggregation of Risk Aversion",
        "comments": "Version to appear in: Proceedings of the Royal Society London A",
        "journal-ref": "Proc. R. Soc. London A 469, 20130024 (2013)",
        "doi": "10.1098/rspa.2013.0024",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  When investors have heterogeneous attitudes towards risk, it is reasonable to\nassume that each investor has a pricing kernel, and that these individual\npricing kernels are aggregated to form a market pricing kernel. The various\ninvestors are then buyers or sellers depending on how their individual pricing\nkernels compare to that of the market. In Brownian-based models, we can\nrepresent such heterogeneous attitudes by letting the market price of risk be a\nrandom variable, the distribution of which corresponds to the variability of\nattitude across the market. If the flow of market information is determined by\nthe movements of prices, then neither the Brownian driver nor the market price\nof risk are directly visible: the filtration is generated by an \"information\nprocess\" given by a combination of the two. We show that the market pricing\nkernel is then given by the harmonic mean of the individual pricing kernels\nassociated with the various market participants. Remarkably, with an\nappropriate definition of L\\'evy information one draws the same conclusion in\nthe case when asset prices can jump. As a consequence we are led to a rather\ngeneral scheme for the management of investments in heterogeneous markets\nsubject to jump risk.\n"
    },
    {
        "paper_id": 1301.3096,
        "authors": "Rodica Branzei, Marco Dall'Aglio, Stef H. Tijs",
        "title": "On Bankruptcy Game Theoretic Interval Rules",
        "comments": "14 pages, no figures. Updated version of the CentER Discussion Paper\n  Series (No. 2008-97) Tilburg University",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Interval bankruptcy problems arise in situations where an estate has to be\nliquidated among a fixed number of creditors and uncertainty about the amounts\nof the claims is modeled by intervals. We extend in the interval setting the\nclassical results by Curiel, Maschler and Tijs (1987) that characterize\ndivision rules which correspond to solutions of the cooperative bankruptcy\ngame. Finally, we analyze the difficulties with incorporating the uncertainty\nabout the estate.\n"
    },
    {
        "paper_id": 1301.31,
        "authors": "Erhan Bayraktar and Zhou Zhou",
        "title": "On an Optimal Stopping Problem of an Insider",
        "comments": "Final version. To appear in Theory of Probability and Its\n  Applications",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the optimal stopping problem\n$v^{(\\eps)}:=\\sup_{\\tau\\in\\mathcal{T}_{0,T}}\\mathbb{E}B_{(\\tau-\\eps)^+}$ posed\nby Shiryaev at the International Conference on Advanced Stochastic Optimization\nProblems organized by the Steklov Institute of Mathematics in September 2012.\nHere $T>0$ is a fixed time horizon, $(B_t)_{0\\leq t\\leq T}$ is the Brownian\nmotion, $\\eps\\in[0,T]$ is a constant, and $\\mathcal{T}_{\\eps,T}$ is the set of\nstopping times taking values in $[\\eps,T]$. The solution of this problem is\ncharacterized by a path dependent reflected backward stochastic differential\nequations, from which the continuity of $\\eps \\to v^{(\\eps)}$ follows. For\nlarge enough $\\eps$, we obtain an explicit expression for $v^{(\\eps)}$ and for\nsmall $\\eps$ we have lower and upper bounds. The main result of the paper is\nthe asymptotics of $v^{(\\eps)}$ as $\\eps\\searrow 0$. As a byproduct, we also\nobtain L\\'{e}vy's modulus of continuity result in the $L^1$ sense.\n"
    },
    {
        "paper_id": 1301.3114,
        "authors": "Sylvain Delattre, Christian Y. Robert and Mathieu Rosenbaum",
        "title": "Estimating the efficient price from the order flow: a Brownian Cox\n  process approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  At the ultra high frequency level, the notion of price of an asset is very\nambiguous. Indeed, many different prices can be defined (last traded price,\nbest bid price, mid price,...). Thus, in practice, market participants face the\nproblem of choosing a price when implementing their strategies. In this work,\nwe propose a notion of efficient price which seems relevant in practice.\nFurthermore, we provide a statistical methodology enabling to estimate this\nprice form the order flow.\n"
    },
    {
        "paper_id": 1301.3118,
        "authors": "Qasim Nasar-Ullah",
        "title": "A parallel implementation of a derivative pricing model incorporating\n  SABR calibration and probability lookup tables",
        "comments": "21 pages, 16 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We describe a high performance parallel implementation of a derivative\npricing model, within which we introduce a new parallel method for the\ncalibration of the industry standard SABR (stochastic-\\alpha \\beta \\rho)\nstochastic volatility model using three strike inputs. SABR calibration\ninvolves a non-linear three dimensional minimisation and parallelisation is\nachieved by incorporating several assumptions unique to the SABR class of\nmodels. Our calibration method is based on principles of surface intersection,\nguarantees convergence to a unique solution and operates by iteratively\nrefining a two dimensional grid with local mesh refinement. As part of our\npricing model we additionally present a fast parallel iterative algorithm for\nthe creation of dynamically sized cumulative probability lookup tables that are\nable to cap maximum estimated linear interpolation error. We optimise\nperformance for probability distributions that exhibit clustering of linear\ninterpolation error. We also make an empirical assessment of error propagation\nthrough our pricing model as a result of changes in accuracy parameters within\nthe pricing model's multiple algorithmic steps. Algorithms are implemented on a\nGPU (graphics processing unit) using Nvidia's Fermi architecture. The pricing\nmodel targets the evaluation of spread options using copula methods, however\nthe presented algorithms can be applied to a wider class of financial\ninstruments.\n"
    },
    {
        "paper_id": 1301.3227,
        "authors": "Marcel Nutz",
        "title": "Superreplication under Model Uncertainty in Discrete Time",
        "comments": "14 pages; forthcoming in 'Finance and Stochastics'",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the superreplication of contingent claims under model uncertainty in\ndiscrete time. We show that optimal superreplicating strategies exist in a\ngeneral measure-theoretic setting; moreover, we characterize the minimal\nsuperreplication price as the supremum over all continuous linear pricing\nfunctionals on a suitable Banach space. The main ingredient is a closedness\nresult for the set of claims which can be superreplicated from zero capital;\nits proof relies on medial limits.\n"
    },
    {
        "paper_id": 1301.3531,
        "authors": "Dilip Madan, Martijn Pistorius, Mitja Stadje",
        "title": "On dynamic spectral risk measures, a limit theorem and optimal portfolio\n  allocation",
        "comments": "To appear in Finance and Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose the notion of continuous-time dynamic spectral\nrisk-measure (DSR). Adopting a Poisson random measure setting, we define this\nclass of dynamic coherent risk-measures in terms of certain backward stochastic\ndifferential equations. By establishing a functional limit theorem, we show\nthat DSRs may be considered to be (strongly) time-consistent continuous-time\nextensions of iterated spectral risk-measures, which are obtained by iterating\na given spectral risk-measure (such as Expected Shortfall) along a given\ntime-grid. Specifically, we demonstrate that any DSR arises in the limit of a\nsequence of such iterated spectral risk-measures driven by lattice-random\nwalks, under suitable scaling and vanishing time- and spatial-mesh sizes. To\nillustrate its use in financial optimisation problems, we analyse a dynamic\nportfolio optimisation problem under a DSR.\n"
    },
    {
        "paper_id": 1301.3823,
        "authors": "Grzegorz Michalski",
        "title": "Portfolio Management Approach in Trade Credit Decision Making",
        "comments": "no coments",
        "journal-ref": "Romanian Journal of Economic Forecasting, 3, 2007, 42-53",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The basic financial purpose of an enterprise is maximization of its value.\nTrade credit management should also contribute to realization of this\nfundamental aim. Many of the current asset management models that are found in\nfinancial management literature assume book profit maximization as the basic\nfinancial purpose. These book profitbased models could be lacking in what\nrelates to another aim (i.e., maximization of enterprise value). The enterprise\nvalue maximization strategy is executed with a focus on risk and uncertainty.\nThis article presents the consequences that can result from operating risk that\nis related to purchasers using payment postponement for goods and/or services.\nThe present article offers a method that uses portfolio management theory to\ndetermine the level of accounts receivable in a firm. An increase in the level\nof accounts receivables in a firm increases both net working capital and the\ncosts of holding and managing accounts receivables. Both of these decrease the\nvalue of the firm, but a liberal policy in accounts receivable coupled with the\nportfolio management approach could increase the value. Efforts to assign ways\nto manage these risks were also undertaken; among them, special attention was\npaid to adapting assumptions from portfolio theory as well as gauging the\npotential effect on the firm value.\n"
    },
    {
        "paper_id": 1301.3824,
        "authors": "Grzegorz Michalski",
        "title": "Planning Optimal From the Firm Value Creation Perspective Levels of\n  Operating Cash Investments",
        "comments": null,
        "journal-ref": "Romanian Journal of Economic Forecasting 1 2010, 198-214",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The basic financial purpose of corporation is creation of its value.\nLiquidity management should also contribute to realization of this fundamental\naim. Many of the current asset management models that are found in financial\nmanagement literature assume book profit maximization as the basic financial\npurpose. These book profit based models could be lacking in what relates to\nanother aim like maximization of enterprise value. The corporate value creation\nstrategy is executed with a focus on risk and uncertainty. Firms hold cash for\na variety of reasons. Generally, cash balances held in a firm can be called\nconsidered, precautionary, speculative, transactional and intentional. The\nfirst are the result of management anxieties. Managers fear the negative part\nof the risk and hold cash to hedge against it. Second, cash balances are held\nto use chances that are created by the positive part of the risk equation.\nNext, cash balances are the result of the operating needs of the firm. In this\narticle, we analyze the relation between these types of cash balances and risk.\nThis article presents the discussion about relations between firm net working\ninvestment policy and as result operating cash balances and firm value. This\narticle also contains propositions for marking levels of precautionary cash\nbalances and speculative cash balances. Application of these propositions\nshould help managers to make better decisions to maximize the value of a firm.\n"
    },
    {
        "paper_id": 1301.3825,
        "authors": "Grzegorz Michalski, Aleksander Mercik",
        "title": "Polish and Silesian Non-Profit Organizations Liquidity Strategies",
        "comments": null,
        "journal-ref": "Statistika 2011 48(4), 45-61",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The kind of realized mission inflows the sensitivity to risk. Among other\nfactors, the risk results from decision about liquid assets investment level\nand liquid assets financing. The higher the risk exposure, the higher the level\nof liquid assets. If the specific risk exposure is smaller, the more aggressive\ncould be the net liquid assets strategy. The organization choosing between\nvarious solutions in liquid assets needs to decide what level of risk is\nacceptable for her owners (or donors) and / or capital suppliers. The paper\nshows how, in authors opinion, decisions, about liquid assets management\nstrategy inflow the risk of the organizations and its economical results during\nrealization of main mission. Comparison of theoretical model with empirical\ndata for over 450 Silesian nonprofit organization results suggests that\nnonprofit organization managing teams choose more risky aggressive liquid\nassets solutions than for-profit firms.\n"
    },
    {
        "paper_id": 1301.3826,
        "authors": "Grzegorz Michalski",
        "title": "Value-Based Inventory Management",
        "comments": "no coments",
        "journal-ref": "Romanian Journal of Economic Forecasting 1 2008, 82-90",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The basic financial purpose of a firm is to maximize its value. An inventory\nmanagement system should also contribute to realization of this basic aim. Many\ncurrent asset management models currently found in financial management\nliterature were constructed with the assumption of book profit maximization as\nbasic aim. However these models could lack what relates to another aim, i.e.,\nmaximization of enterprise value. This article presents a modified value-based\ninventory management model.\n"
    },
    {
        "paper_id": 1301.3886,
        "authors": "David M. Pennock, Michael P. Wellman",
        "title": "Compact Securities Markets for Pareto Optimal Reallocation of Risk",
        "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The emph{securities market} is the fundamental theoretical framework in\neconomics and finance for resource allocation under uncertainty. Securities\nserve both to reallocate risk and to disseminate probabilistic information.\nemph{Complete} securities markets - which contain one security for every\npossible state of nature - support Pareto optimal allocations of risk. Complete\nmarkets suffer from the same exponential dependence on the number of underlying\nevents as do joint probability distributions. We examine whether markets can be\nstructured and \"compacted\" in the same manner as Bayesian network\nrepresentations of joint distributions. We show that, if all agents'\nrisk-neutral independencies agree with the independencies encoded in the market\nstructure, then the market is emph{operationally complete}: risk is still\nPareto optimally allocated, yet the number of securities can be exponentially\nsmaller. For collections of agents of a certain type, agreement on Markov\nindependencies is sufficient to admit compact and operationally complete\nmarkets.\n"
    },
    {
        "paper_id": 1301.416,
        "authors": "J. F. Muzy, R. Baile and E. Bacry",
        "title": "Random cascade model in the limit of infinite integral scale as the\n  exponential of a non-stationary $1/f$ noise. Application to volatility\n  fluctuations in stock markets",
        "comments": "9 Figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.87.042813",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a new model for volatility fluctuations in financial\ntime series. This model relies on a non-stationary gaussian process that\nexhibits aging behavior. It turns out that its properties, over any finite time\ninterval, are very close to continuous cascade models. These latter models are\nindeed well known to reproduce faithfully the main stylized facts of financial\ntime series. However, it involve a large scale parameter (the so-called\n\"integral scale\" where the cascade is initiated) that is hard to interpret in\nfinance. Moreover the empirical value of the integral scale is in general\ndeeply correlated to the overall length of the sample. This feature is\nprecisely predicted by our model that turns out, as illustrated on various\nexamples from daily stock index data, to quantitatively reproduce the empirical\nobservations.\n"
    },
    {
        "paper_id": 1301.4173,
        "authors": "Attila Herczegh and Vilmos Prokaj and Mikl\\'os R\\'asonyi",
        "title": "Diversity and no arbitrage",
        "comments": "14 pages, final version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A stock market is called diverse if no stock can dominate the market in terms\nof relative capitalization. On one hand, this natural property leads to\narbitrage in diffusion models under mild assumptions. On the other hand, it is\nalso easy to construct diffusion models which are both diverse and free of\narbitrage. Can one tell whether an observed diverse market admits arbitrage?\n  In the present paper we argue that this may well be impossible by proving\nthat the known examples of diverse markets in the literature (which do admit\narbitrage) can be approximated uniformly (on the logarithmic scale) by models\nwhich are both diverse and arbitrage-free.\n"
    },
    {
        "paper_id": 1301.4194,
        "authors": "Ankit Dangi",
        "title": "Financial Portfolio Optimization: Computationally guided agents to\n  investigate, analyse and invest!?",
        "comments": "Thesis work under the guidance of Dr. Abhijit Kulkarni, Advanced\n  Analytics Lab. (SSO), SAS Research & Development, India. Submitted at Centre\n  for Modeling and Simulation, University of Pune for completion of Master of\n  Technology (M. Tech.) in Modeling and Simulation (M&S)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial portfolio optimization is a widely studied problem in mathematics,\nstatistics, financial and computational literature. It adheres to determining\nan optimal combination of weights associated with financial assets held in a\nportfolio. In practice, it faces challenges by virtue of varying math.\nformulations, parameters, business constraints and complex financial\ninstruments. Empirical nature of data is no longer one-sided; thereby\nreflecting upside and downside trends with repeated yet unidentifiable cyclic\nbehaviours potentially caused due to high frequency volatile movements in asset\ntrades. Portfolio optimization under such circumstances is theoretically and\ncomputationally challenging. This work presents a novel mechanism to reach an\noptimal solution by encoding a variety of optimal solutions in a solution bank\nto guide the search process for the global investment objective formulation. It\nconceptualizes the role of individual solver agents that contribute optimal\nsolutions to a bank of solutions, a super-agent solver that learns from the\nsolution bank, and, thus reflects a knowledge-based computationally guided\nagents approach to investigate, analyse and reach to optimal solution for\ninformed investment decisions.\n  Conceptual understanding of classes of solver agents that represent varying\nproblem formulations and, mathematically oriented deterministic solvers along\nwith stochastic-search driven evolutionary and swarm-intelligence based\ntechniques for optimal weights are discussed. Algorithmic implementation is\npresented by an enhanced neighbourhood generation mechanism in Simulated\nAnnealing algorithm. A framework for inclusion of heuristic knowledge and human\nexpertise from financial literature related to investment decision making\nprocess is reflected via introduction of controlled perturbation strategies\nusing a decision matrix for neighbourhood generation.\n"
    },
    {
        "paper_id": 1301.4207,
        "authors": "Leonid A. Shapiro",
        "title": "Anticipatory Systems, Preferences, Averages: Inflation, Uncertain\n  Phenomena, Management",
        "comments": "Conference pre-print with revisions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Behavior of systems that are functions of anticipated behavior of other\nsystems, whose own behavior is also anticipatory but homeostatic and determined\nby hierarchical ordering, which changes over time, of sets of possible\nenvironments that are not co-possible, is proven to be highly non-linear and\nsensitively dependent on precise parameters. Averages and other kinds of\naggregates cannot be calculated for sets of measurements of behavior of\nsystems, defined in this essay, that are \"index complex\" in this way. This\nincludes many systems, for instance, social behavior, where anticipation of\nbehavior of other individuals plays a central role. Anticipation of preferences\nof economic actors are discussed in this way. Analysis by way of generalized\nfunctions of complex variables is done for these kinds of systems, and\nequations of change of state are formally described. Behavior that comprises of\nresponses to market interest rates is taken for example. Continuity assumptions\nin economics analyzed in this context. Anticipatory responses to inflation in\neconomics are discussed. Applications to theory of production are presented.\n"
    },
    {
        "paper_id": 1301.4442,
        "authors": "Igor Halperin and Andrey Itkin",
        "title": "USLV: Unspanned Stochastic Local Volatility Model",
        "comments": "Sections 3.2 and 3.3 are re-written, 3 figures added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new framework for modeling stochastic local volatility, with\npotential applications to modeling derivatives on interest rates, commodities,\ncredit, equity, FX etc., as well as hybrid derivatives. Our model extends the\nlinearity-generating unspanned volatility term structure model by Carr et al.\n(2011) by adding a local volatility layer to it. We outline efficient numerical\nschemes for pricing derivatives in this framework for a particular four-factor\nspecification (two \"curve\" factors plus two \"volatility\" factors). We show that\nthe dynamics of such a system can be approximated by a Markov chain on a\ntwo-dimensional space (Z_t,Y_t), where coordinates Z_t and Y_t are given by\ndirect (Kroneker) products of values of pairs of curve and volatility factors,\nrespectively. The resulting Markov chain dynamics on such partly \"folded\" state\nspace enables fast pricing by the standard backward induction. Using a\nnonparametric specification of the Markov chain generator, one can accurately\nmatch arbitrary sets of vanilla option quotes with different strikes and\nmaturities. Furthermore, we consider an alternative formulation of the model in\nterms of an implied time change process. The latter is specified\nnonparametrically, again enabling accurate calibration to arbitrary sets of\nvanilla option quotes.\n"
    },
    {
        "paper_id": 1301.4519,
        "authors": "Daniel T. Cassidy",
        "title": "Homogeneously Saturated Model for Development in Time of the Price of an\n  Asset",
        "comments": "24 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The time development of the price of a financial asset is considered by\nconstructing and solving Langevin equations for a homogeneously saturated\nmodel, and for comparison, for a standard model and for a logistic model. The\nhomogeneously saturated model uses coupled rate equations for the money supply\nand for the price of the asset, similar to the coupled rate equations for\npopulation inversion and power density in a simple model of a homogeneously\nbroadened laser.\n  Predictions of the models are compared for random numbers drawn from a\nStudent's t-distribution. It is known that daily returns of the DJIA and S&P\n500 indices are fat tailed and are described well by Student's t-distributions\nover the range of observed values. The homogeneously saturated model shows\nreturns that are consistent with daily returns for the indices (in the range of\n-30% to +30%) whereas the standard model and the logistic model show returns\nthat are far from consistent with observed daily returns for the indices.\n"
    },
    {
        "paper_id": 1301.4614,
        "authors": "Larry G. Epstein and Shaolin Ji",
        "title": "Ambiguous volatility and asset pricing in continuous time",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper formulates a model of utility for a continuous time framework that\ncaptures the decision-maker's concern with ambiguity about both volatility and\ndrift. Corresponding extensions of some basic results in asset pricing theory\nare presented. First, we derive arbitrage-free pricing rules based on hedging\narguments. Ambiguous volatility implies market incompleteness that rules out\nperfect hedging. Consequently, hedging arguments determine prices only up to\nintervals. However, sharper predictions can be obtained by assuming preference\nmaximization and equilibrium. Thus we apply the model of utility to a\nrepresentative agent endowment economy to study equilibrium asset returns. A\nversion of the C-CAPM is derived and the effects of ambiguous volatility are\ndescribed.\n"
    },
    {
        "paper_id": 1301.4832,
        "authors": "Thomas Breuer and Imre Csiszar",
        "title": "Measuring Model Risk",
        "comments": "30 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose to interpret distribution model risk as sensitivity of expected\nloss to changes in the risk factor distribution, and to measure the\ndistribution model risk of a portfolio by the maximum expected loss over a set\nof plausible distributions defined in terms of some divergence from an\nestimated distribution. The divergence may be relative entropy, a Bregman\ndistance, or an $f$-divergence. We give formulas for the calculation of\ndistribution model risk and explicitly determine the worst case distribution\nfrom the set of plausible distributions. We also give formulas for the\nevaluation of divergence preferences describing ambiguity averse decision\nmakers.\n"
    },
    {
        "paper_id": 1301.4869,
        "authors": "Henrik Hult, Filip Lindskog, and Johan Nykvist",
        "title": "A simple time-consistent model for the forward density process",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper a simple model for the evolution of the forward density of the\nfuture value of an asset is proposed. The model allows for a straightforward\ninitial calibration to option prices and has dynamics that are consistent with\nempirical findings from option price data. The model is constructed with the\naim of being both simple and realistic, and avoid the need for frequent\nre-calibration. The model prices of $n$ options and a forward contract are\nexpressed as time-varying functions of an $(n+1)$-dimensional Brownian motion\nand it is investigated how the Brownian trajectory can be determined from the\ntrajectories of the price processes. An approach based on particle filtering is\npresented for determining the location of the driving Brownian motion from\noption prices observed in discrete time. A simulation study and an empirical\nstudy of call options on the S&P 500 index illustrates that the model provides\na good fit to option price data.\n"
    },
    {
        "paper_id": 1301.4881,
        "authors": "Dimitri O. Ledenyov and Viktor O. Ledenyov",
        "title": "On the optimal allocation of assets in investment portfolio with\n  application of modern portfolio and nonlinear dynamic chaos theories in\n  investment, commercial and central banks",
        "comments": "34 pages, 35 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The investment economy is a main characteristic of prosperous society. The\ninvestment portfolio management is a main financial problem, which has to be\nsolved by the investment, commercial and central banks with the application of\nmodern portfolio theory in the investment economy. We use the learning\nanalytics together with the integrative creative imperative intelligent\nconceptual co-lateral adaptive thinking with the purpose to advance our\nscientific knowledge on the diversified investment portfolio management in the\nnonlinear dynamic financial system. We apply the econophysics principles and\nthe econometrics methods with the aim to find the solution to the problem of\nthe optimal allocation of assets in the investment portfolio, using the\nadvanced risk management techniques with the efficient frontier modeling in\nagreement with the modern portfolio theory and using the stability management\ntechniques with the dynamic regimes modeling on the bifurcation diagram in\nagreement with the dynamic chaos theory. We show that the bifurcation diagram,\ncreated with the use of the logistic function in Matlab, can provide some\nvaluable information on the stability of combining risky investments in the\ninvestment portfolio, solving the problem of optimization of assets allocation\nin the investment portfolio. We propose the Ledenyov investment portfolio\ntheorem, based on the Lyapunov stability criteria, with the aim to create the\noptimized investment portfolio with the uncorrelated diversified assets, which\ncan deliver the increased expected returns to the institutional and private\ninvestors in the nonlinear dynamic financial system in the frames of investment\neconomy.\n"
    },
    {
        "paper_id": 1301.5007,
        "authors": "Ban Zheng (LTCI, FiQuant), Fran\\c{c}ois Roueff (LTCI), Fr\\'ed\\'eric\n  Abergel (FiQuant, MAS)",
        "title": "Ergodicity and scaling limit of a constrained multivariate Hawkes\n  process",
        "comments": "32 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a multivariate Hawkes process with constraints on its\nconditional density. It is a multivariate point process with conditional\nintensity similar to that of a multivariate Hawkes process but certain events\nare forbidden with respect to boundary conditions on a multidimensional\nconstraint variable, whose evolution is driven by the point process. We study\nthis process in the special case where the fertility function is exponential so\nthat the process is entirely described by an underlying Markov chain, which\nincludes the constraint variable. Some conditions on the parameters are\nestablished to ensure the ergodicity of the chain. Moreover, scaling limits are\nderived for the integrated point process. This study is primarily motivated by\nthe stochastic modelling of a limit order book for high frequency financial\ndata analysis.\n"
    },
    {
        "paper_id": 1301.5129,
        "authors": "Audrone Virbickaite, M. Concepci\\'on Aus\\'in and Pedro Galeano",
        "title": "A Bayesian Non-Parametric Approach to Asymmetric Dynamic Conditional\n  Correlation Model With Application to Portfolio Selection",
        "comments": "35 pages, 10 figures",
        "journal-ref": null,
        "doi": "10.1016/j.csda.2014.12.005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a Bayesian non-parametric approach for modeling the distribution\nof multiple returns. In particular, we use an asymmetric dynamic conditional\ncorrelation (ADCC) model to estimate the time-varying correlations of financial\nreturns where the individual volatilities are driven by GJR-GARCH models. The\nADCC-GJR-GARCH model takes into consideration the asymmetries in individual\nassets' volatilities, as well as in the correlations. The errors are modeled\nusing a Dirichlet location-scale mixture of multivariate Gaussian distributions\nallowing for a great flexibility in the return distribution in terms of\nskewness and kurtosis. Model estimation and prediction are developed using MCMC\nmethods based on slice sampling techniques. We carry out a simulation study to\nillustrate the flexibility of the proposed approach. We find that the proposed\nDPM model is able to adapt to several frequently used distribution models and\nalso accurately estimates the posterior distribution of the volatilities of the\nreturns, without assuming any underlying distribution. Finally, we present a\nfinancial application using Apple and NASDAQ Industrial index data to solve a\nportfolio allocation problem. We find that imposing a restrictive parametric\ndistribution can result into underestimation of the portfolio variance, whereas\nDPM model is able to overcome this problem.\n"
    },
    {
        "paper_id": 1301.5425,
        "authors": "Chris Kenyon and Richard David Kenyon",
        "title": "DVA for Assets",
        "comments": "16 pages, 4 figures",
        "journal-ref": "Risk, 2013, 26(2), 72-75",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The effect of self-default on the valuation of liabilities and derivatives\n(DVA) has been widely discussed but the effect on assets has not received\nsimilar attention. Any asset whose value depends on the status, or existence,\nof the firm will have a DVA. We extend (Burgard and Kjaer 2011) to provide a\nhedging strategy for such assets and provide an in-depth example from the\nbalance sheet (Goodwill). We calibrate our model to seven US banks over the\ncrisis period of mid-2007 to 2011. This suggests that their reported profits\nwould have changed significantly if DVA on assets, as well as liabilities, was\nincluded - unless the DVA was hedged.\n"
    },
    {
        "paper_id": 1301.5467,
        "authors": "Alexander M. G. Cox, Christoph Hoeggerl",
        "title": "Model-independent no-arbitrage conditions on American put options",
        "comments": "32 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the pricing of American put options in a model-independent\nsetting: that is, we do not assume that asset prices behave according to a\ngiven model, but aim to draw conclusions that hold in any model. We incorporate\nmarket information by supposing that the prices of European options are known.\n  In this setting, we are able to provide conditions on the American Put prices\nwhich are necessary for the absence of arbitrage. Moreover, if we further\nassume that there are finitely many European and American options traded, then\nwe are able to show that these conditions are also sufficient. To show\nsufficiency, we construct a model under which both American and European\noptions are correctly priced at all strikes simultaneously. In particular, we\nneed to carefully consider the optimal stopping strategy in the construction of\nour process.\n"
    },
    {
        "paper_id": 1301.5497,
        "authors": "Eduard Kromer and Ludger Overbeck",
        "title": "Suitability of Capital Allocations for Performance Measurement",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Capital allocation principles are used in various contexts in which a risk\ncapital or a cost of an aggregate position has to be allocated among its\nconstituent parts. We study capital allocation principles in a performance\nmeasurement framework. We introduce the notation of suitability of allocations\nfor performance measurement and show under different assumptions on the\ninvolved reward and risk measures that there exist suitable allocation methods.\nThe existence of certain suitable allocation principles generally is given\nunder rather strict assumptions on the underlying risk measure. Therefore we\nshow, with a reformulated definition of suitability and in a slightly modified\nsetting, that there is a known suitable allocation principle that does not\nrequire any properties of the underlying risk measure. Additionally we extend a\nprevious characterization result from the literature from a mean-risk to a\nreward-risk setting. Formulations of this theory are also possible in a game\ntheoretic setting.\n"
    },
    {
        "paper_id": 1301.5504,
        "authors": "Ulrich Kirchner and Simon Moolman",
        "title": "Cash Flow Entropy",
        "comments": "8 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we aim to find a measure for the diversity of cash flows\nbetween agents in an economy. We argue that cash flows can be linked to\nprobabilities of finding a currency unit in a given cash flow. We then use the\ninformation entropy as a natural measure of diversity. This leads to a\nhirarchical inequality measure, which includes the well-known Theil index as a\nspecial case, and a constraint on agent entropy differentials, i.e., the\ndifference between cash inflow and outflow entropies. The last result is\nparticularly intriguing as it formalises the fact that an economy must contain\nboth, cash flow aggregating and cash flow diversifying agents.\n"
    },
    {
        "paper_id": 1301.5568,
        "authors": "Beatrice Acciaio, Mathias Beiglb\\\"ock, Friedrich Penkner, Walter\n  Schachermayer",
        "title": "A model-free version of the fundamental theorem of asset pricing and the\n  super-replication theorem",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a Fundamental Theorem of Asset Pricing and a Super-Replication\nTheorem in a model-independent framework. We prove these theorems in the\nsetting of finite, discrete time and a market consisting of a risky asset S as\nwell as options written on this risky asset. As a technical condition, we\nassume the existence of a traded option with a super-linearly growing\npayoff-function, e.g., a power option. This condition is not needed when\nsufficiently many vanilla options maturing at the horizon T are traded in the\nmarket.\n"
    },
    {
        "paper_id": 1301.5821,
        "authors": "Eduardo Viegas, Misako Takayasu, Wataru Miura, Koutarou Tamura,\n  Takaaki Ohnishi, Hideki Takayasu and Henrik Jeldtoft Jensen",
        "title": "Ecosystems perspective on financial networks: diagnostic tools",
        "comments": "21 pages, 5 figures and one appendix",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The economical world consists of a highly interconnected and interdependent\nnetwork of firms. Here we develop temporal and structural network tools to\nanalyze the state of the economy. Our analysis indicates that a strong\nclustering can be a warning sign. Reduction in diversity, which was an\nessential aspect of the dynamics surrounding the crash in 2008, is seen as a\nkey emergent feature arising naturally from the evolutionary and adaptive\ndynamics inherent to the financial markets. Similarly, collusion amongst\nconstruction firms in a number of regions in Japan in the 2000s can be\nidentified with the formation of clusters of anomalous highly connected\ncompanies.\n"
    },
    {
        "paper_id": 1301.5877,
        "authors": "Daniel T. Cassidy",
        "title": "Pricing Using a Homogeneously Saturated Equation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A homogeneously saturated equation for the time development of the price of a\nfinancial asset is presented and investigated for the pricing of European call\noptions using noise that is distributed as a Student's t-distribution. In the\nlimit that the saturation parameter of the equation equals zero, the standard\nmodel of geometric motion for the price of an asset is obtained. The\nhomogeneously saturated equation for the price of an asset is similar to a\nsimple equation for the output of a homogeneously broadened laser. The\nhomogeneously saturated equation tends to limit the range of returns and thus\nseems to be realistic.\n  Fits to linear returns obtained from the adjusted closing values for the S&P\n500 index were used to obtain best-fit parameters for Student's t-distributions\nand for normal distributions, and these fits were used to price options, and to\ncompare approaches to modelling prices.\n  This work has value in understanding the pricing of assets and of European\ncall options.\n"
    },
    {
        "paper_id": 1301.5974,
        "authors": "Paul Cockshott and David Zachariah",
        "title": "Conservation laws, financial entropy and the Eurozone crisis",
        "comments": null,
        "journal-ref": "Economics: The Open-Access, Open-Assessment E-Journal, Vol. 8,\n  2014",
        "doi": "10.5018/economics-ejournal.ja.2014-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The report attempts of apply econophysics concepts to the Eurozone crisis. It\nstarts by examining the idea of conservation laws as applied to market\neconomies. It formulates a measure of financial entropy and gives numerical\nsimulations indicating that this tends to rise. We discuss an analogue for free\nenergy released during this process. The concepts of real and symbolic\nappropriation are introduced as a means to analyse debt and taxation.\n  We then examine the conflict between the conservation laws that apply to\ncommodity exchange with the exponential growth implied by capital accumulation\nand how these have necessitated a sequence of evolutionary forms for money, and\ngo on to present a simple stochastic model for the formation of rates of\ninterest and a model for the time evolution of the rate of profit.\n  Finally we apply the conservation law model to examining the Euro Crisis and\nthe European Stability pact, arguing that if the laws we hypothesise actually\nhold, then the goals of the stability pact are unobtainable.\n"
    },
    {
        "paper_id": 1301.6069,
        "authors": "Sabine Karl and Tom Fischer",
        "title": "Cross-Ownership as a Structural Explanation for Over- and\n  Underestimation of Default Probability",
        "comments": "40 pages, 5 figures",
        "journal-ref": "Quantitative Finance 14 (6), 1031-1046",
        "doi": "10.1080/14697688.2013.834377",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on the work of Suzuki (2002), we consider a generalization of Merton's\nasset valuation approach (Merton, 1974) in which two firms are linked by\ncross-ownership of equity and liabilities. Suzuki's results then provide no\narbitrage prices of firm values, which are derivatives of exogenous asset\nvalues. In contrast to the Merton model, the assumption of lognormally\ndistributed assets does not result in lognormally distributed firm values,\nwhich also affects the corresponding probabilities of default. In a simulation\nstudy we see that, depending on the type of cross-ownership, the lognormal\nmodel can lead to both, over- and underestimation of the actual probability of\ndefault of a firm under cross-ownership. In the limit, i.e. if the levels of\ncross-ownership tend to their maximum possible value, these findings can be\nshown theoretically as well. Furthermore, we consider the default probability\nof a firm in general, i.e. without a distributional assumption, and show that\nthe lognormal model is often able to yield only a limited range of\nprobabilities of default, while the actual probabilities may take any value\nbetween 0 and 1.\n"
    },
    {
        "paper_id": 1301.6114,
        "authors": "Sebastian Poledna, Stefan Thurner, J. Doyne Farmer and John\n  Geanakoplos",
        "title": "Leverage-induced systemic risk under Basle II and other credit risk\n  policies",
        "comments": "27 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use a simple agent based model of value investors in financial markets to\ntest three credit regulation policies. The first is the unregulated case, which\nonly imposes limits on maximum leverage. The second is Basle II and the third\nis a hypothetical alternative in which banks perfectly hedge all of their\nleverage-induced risk with options. When compared to the unregulated case both\nBasle II and the perfect hedge policy reduce the risk of default when leverage\nis low but increase it when leverage is high. This is because both regulation\npolicies increase the amount of synchronized buying and selling needed to\nachieve deleveraging, which can destabilize the market. None of these policies\nare optimal for everyone: Risk neutral investors prefer the unregulated case\nwith low maximum leverage, banks prefer the perfect hedge policy, and fund\nmanagers prefer the unregulated case with high maximum leverage. No one prefers\nBasle II.\n"
    },
    {
        "paper_id": 1301.6115,
        "authors": "Stefan Thurner and Sebastian Poledna",
        "title": "DebtRank-transparency: Controlling systemic risk in financial networks",
        "comments": "8 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Banks in the interbank network can not assess the true risks associated with\nlending to other banks in the network, unless they have full information on the\nriskiness of all the other banks. These risks can be estimated by using network\nmetrics (for example DebtRank) of the interbank liability network which is\navailable to Central Banks. With a simple agent based model we show that by\nincreasing transparency by making the DebtRank of individual nodes (banks)\nvisible to all nodes, and by imposing a simple incentive scheme, that reduces\ninterbank borrowing from systemically risky nodes, the systemic risk in the\nfinancial network can be drastically reduced. This incentive scheme is an\neffective regulation mechanism, that does not reduce the efficiency of the\nfinancial network, but fosters a more homogeneous distribution of risk within\nthe system in a self-organized critical way. We show that the reduction of\nsystemic risk is to a large extent due to the massive reduction of cascading\nfailures in the transparent system. An implementation of this minimal\nregulation scheme in real financial networks should be feasible from a\ntechnical point of view.\n"
    },
    {
        "paper_id": 1301.6141,
        "authors": "Giacomo Bormetti, Lucio Maria Calcagnile, Michele Treccani, Fulvio\n  Corsi, Stefano Marmi, and Fabrizio Lillo",
        "title": "Modelling systemic price cojumps with Hawkes factor models",
        "comments": "11 figures, 8 tables, block bootstrap section removed, some typos\n  corrected",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Instabilities in the price dynamics of a large number of financial assets are\na clear sign of systemic events. By investigating a set of 20 high cap stocks\ntraded at the Italian Stock Exchange, we find that there is a large number of\nhigh frequency cojumps. We show that the dynamics of these jumps is described\nneither by a multivariate Poisson nor by a multivariate Hawkes model. We\nintroduce a Hawkes one factor model which is able to capture simultaneously the\ntime clustering of jumps and the high synchronization of jumps across assets.\n"
    },
    {
        "paper_id": 1301.6252,
        "authors": "Gregoire Loeper",
        "title": "Option pricing with linear market impact and non-linear Black and\n  Scholes equations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a model of linear market impact, and address the problem of\nreplicating a contingent claim in this framework. We derive a non-linear\nBlack-Scholes Equation that provides an exact replication strategy.\n  This equation is fully non-linear and singular, but we show that it is well\nposed, and we prove existence of smooth solutions for a large class of final\npayoffs, both for constant and local volatility. To obtain regularity of the\nsolutions, we develop an original method based on Legendre transforms.\n  The close connections with the problem of hedging with it gamma constraints\nstudied by Cheridito, Soner and Touzi and with the problem of hedging under it\nliquidity costs are discussed.\n  We also derive a modified Black-Scholes formula valid for asymptotically\nsmall impact parameter, and finally provide numerical simulations as an\nillustration.\n"
    },
    {
        "paper_id": 1301.6334,
        "authors": "Lev Pustilnik and Gregory Yom Din",
        "title": "On Possible Influence of Space Weather on Agricultural Markets:\n  Necessary Conditions and Probable Scenarios",
        "comments": "26 pages,9 figures",
        "journal-ref": "Astrophysical Bulletin, 2013, Vol. 68, No.1, pp.1-18",
        "doi": "10.1134/S1990341313010100",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present the results of study of a possible relationship between the space\nweather and terrestrial markets of agricultural products. It is shown that to\nimplement the possible effect of space weather on the terrestrial harvests and\nprices, a simultaneous fulfillment of three conditions is required: 1)\nsensitivity of local weather (cloud cover, atmospheric circulation) to the\nstate of space weather; 2) sensitivity of the area of specific agricultural\ncrops to the weather anomalies (belonging to the area of risk farming); 3)\nrelative isolation of the market, making it difficult to damp the price hikes\nby the external food supplies. Four possible scenarios of the market response\nto the modulations of local terrestrial weather via the solar activity are\ndescribed. The data sources and analysis methods applied to detect this\nrelationship are characterized. We describe the behavior of 22 European markets\nduring the medieval period, in particular, during the Maunder minimum\n(1650-1715). We demonstrate a reliable manifestation of the influence of space\nweather on prices, discovered in the statistics of intervals between the price\nhikes and phase price asymmetry. We show that the effects of phase price\nasymmetry persist even during the early modern period in the U.S. in the\nproduction of the durum wheat. Within the proposed approach, we analyze the\nstatistics of depopulation in the eighteenth and nineteenth century Iceland,\ninduced by the famine due to a sharp livestock reduction owing to, in its turn,\nthe lack of foodstuff due to the local weather anomalies. A high statistical\nsignificance of temporal matching of these events with the periods of extreme\nsolar activity is demonstrated. We discuss the possible consequences of the\nobserved global climate change in the formation of new areas of risk farming,\nsensitive to space weather.\n"
    },
    {
        "paper_id": 1301.6415,
        "authors": "Tom Fischer",
        "title": "A primer on reflexivity and price dynamics under systemic risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A simple quantitative example of a reflexive feedback process and the\nresulting price dynamics after an exogenous price shock to a financial network\nis presented. Furthermore, an outline of a theory that connects financial\nreflexivity, which stems from cross-ownership and delayed or incomplete\ninformation, and no-arbitrage pricing theory under systemic risk is provided.\n"
    },
    {
        "paper_id": 1301.6468,
        "authors": "Takashi Kato",
        "title": "Stock Price Fluctuations in an Agent-Based Model with Market Liquidity",
        "comments": "27 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study an agent-based stock market model with heterogeneous agents and\nfriction. Our model is based on that of Foellmer-Schweizer(1993): The process\nof a stock price in a discrete-time framework is determined by temporary\nequilibria via agents' excess demand functions, and the diffusion approximation\napproach is applied to characterize the continuous-time limit (as transaction\nintervals shorten) as a solution of the corresponding stochastic differential\nequation (SDE). In this paper we further make the assumption that some of the\nagents are bound by either short sale constraints or budget constraints. Then\nwe show that the continuous-time process of the stock price can be derived from\na certain SDE with oblique reflection. Moreover we find that the short sale\n(respectively, budget) constraint causes overpricing (respectively,\nunderpricing).\n"
    },
    {
        "paper_id": 1301.6485,
        "authors": "Kensuke Ishitani and Takashi Kato",
        "title": "Mathematical Formulation of an Optimal Execution Problem with Uncertain\n  Market Impact",
        "comments": "17 pages. Forthcoming in \"Communications on Stochastic Analysis.\"",
        "journal-ref": "Communications on Stochastic Analysis 9(1), 113-129 (2015)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study an optimal execution problem with uncertain market impact to derive\na more realistic market model. We construct a discrete-time model as a value\nfunction for optimal execution. Market impact is formulated as the product of a\ndeterministic part increasing with execution volume and a positive stochastic\nnoise part. Then, we derive a continuous-time model as a limit of a\ndiscrete-time value function. We find that the continuous-time value function\nis characterized by a stochastic control problem with a Levy process.\n"
    },
    {
        "paper_id": 1301.6506,
        "authors": "A. Sienkiewicz, T. Gubiec, R. Kutner, Z. R. Struzik",
        "title": "Dynamic structural and topological phase transitions on the Warsaw Stock\n  Exchange: A phenomenological approach",
        "comments": null,
        "journal-ref": null,
        "doi": "10.12693/APhysPolA.123.615",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the crash dynamics of the Warsaw Stock Exchange (WSE) by using the\nMinimal Spanning Tree (MST) networks. We find the transition of the complex\nnetwork during its evolution from a (hierarchical) power law MST network,\nrepresenting the stable state of WSE before the recent worldwide financial\ncrash, to a superstar-like (or superhub) MST network of the market decorated by\na hierarchy of trees (being, perhaps, an unstable, intermediate market state).\nSubsequently, we observed a transition from this complex tree to the topology\nof the (hierarchical) power law MST network decorated by several star-like\ntrees or hubs. This structure and topology represent, perhaps, the WSE after\nthe worldwide financial crash, and could be considered to be an aftershock. Our\nresults can serve as an empirical foundation for a future theory of dynamic\nstructural and topological phase transitions on financial markets.\n"
    },
    {
        "paper_id": 1301.6519,
        "authors": "Maciej Jagielski and Ryszard Kutner",
        "title": "Ab initio analysis of all income society classes in the European Union",
        "comments": "Accepted for publication in Acta Physica Polonica A. arXiv admin\n  note: substantial text overlap with arXiv:1301.2076",
        "journal-ref": null,
        "doi": "10.12693/APhysPolA.123.538",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We found a unified formula for description of the household incomes of all\nsociety classes, for instance, of those of the European Union in year 2007.\nThis formula is a stationary solution of the threshold Fokker-Planck equation\n(derived from the threshold nonlinear Langevin one). The formula is more\ngeneral than the well known that of Yakovenko et al. because it satisfactorily\ndescribes not only household incomes of low- and medium-income society classes\nbut also the household incomes of the high-income society class.\n"
    },
    {
        "paper_id": 1301.6638,
        "authors": "Carlo Marinelli, Alex Weissensteiner",
        "title": "On the relation between forecast precision and trading profitability of\n  financial analysts",
        "comments": "26 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the relation between earning forecast accuracy and expected\nprofitability of financial analysts. Modeling forecast errors with a\nmultivariate Gaussian distribution, a complete characterization of the payoff\nof each analyst is provided. In particular, closed-form expressions for the\nprobability density function, for the expectation, and, more generally, for\nmoments of all orders are obtained. Our analysis shows that the relationship\nbetween forecast precision and trading profitability need not to be monotonic,\nand that, for any analyst, the impact on his expected payoff of the correlation\nbetween his forecasts and those of the other market participants depends on the\naccuracy of his signals. Furthermore, our model accommodates a unique\nfull-communication equilibrium in the sense of Radner (1979): if all\ninformation is reflected in the market price, then the expected payoff of all\nmarket participants is equal to zero.\n"
    },
    {
        "paper_id": 1301.7078,
        "authors": "Marco Bianchetti and Mattia Carlicchi",
        "title": "Markets Evolution After the Credit Crunch",
        "comments": "35 pages, 19 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review the main changes in the interbank market after the financial crisis\nstarted in August 2007. In particular, we focus on the fixed income market and\nwe analyse the most relevant empirical evidences regarding the divergence of\nthe existing basis between interbank rates with different tenor, such as Libor\nand OIS. We also discuss a qualitative explanation of these effects based on\nthe consideration of credit and liquidity variables. Then, we focus our\nattention on the diffusion of collateral agreements among OTC derivatives\nmarket counterparties, and on the consequent change of paradigm for pricing\nderivatives. We illustrate the main qualitative features of the new market\npractice, called CSA discounting, and we point out the most relevant issues for\nmarket players associated to its adoption.\n"
    },
    {
        "paper_id": 1301.7413,
        "authors": "Yoram Singer",
        "title": "Switching Portfolios",
        "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A constant rebalanced portfolio is an asset allocation algorithm which keeps\nthe same distribution of wealth among a set of assets along a period of time.\nRecently, there has been work on on-line portfolio selection algorithms which\nare competitive with the best constant rebalanced portfolio determined in\nhindsight. By their nature, these algorithms employ the assumption that high\nreturns can be achieved using a fixed asset allocation strategy. However, stock\nmarkets are far from being stationary and in many cases the wealth achieved by\na constant rebalanced portfolio is much smaller than the wealth achieved by an\nad-hoc investment strategy that adapts to changes in the market. In this paper\nwe present an efficient Bayesian portfolio selection algorithm that is able to\ntrack a changing market. We also describe a simple extension of the algorithm\nfor the case of a general transaction cost, including the transactions cost\nmodels recently investigated by Blum and kalai. We provide a simple analysis of\nthe competitiveness of the algorithm and check its performance on real stock\ndata from the New York Stock Exchange accumulated during a 22-year period.\n"
    },
    {
        "paper_id": 1302.0134,
        "authors": "Laurence Carassus and Miklos Rasonyi",
        "title": "Maximization of Non-Concave Utility Functions in Discrete-Time Financial\n  Market Models",
        "comments": "Second revision",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the problem of maximizing expected terminal utility\nin a (generically incomplete) discrete-time financial market model with finite\ntime horizon. In contrast to the standard setting, a possibly non-concave\nutility function $U$ is considered, with domain of definition $\\mathbb{R}$.\nSimple conditions are presented which guarantee the existence of an optimal\nstrategy for the problem. In particular, the asymptotic elasticity of $U$ plays\na decisive role: existence can be shown when it is strictly greater at\n$-\\infty$ than at $+\\infty$.\n"
    },
    {
        "paper_id": 1302.0361,
        "authors": "Bruno Bouchard, Emmanuel Lepinette, Erik Taflin",
        "title": "Robust no-free lunch with vanishing risk, a continuum of assets and\n  proportional transaction costs",
        "comments": "41 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a continuous time model for financial markets with proportional\ntransactions costs and a continuum of risky assets. This is motivated by bond\nmarkets in which the continuum of assets corresponds to the continuum of\npossible maturities. Our framework is well adapted to the study of no-arbitrage\nproperties and related hedging problems. In particular, we extend the\nFundamental Theorem of Asset Pricing of Guasoni, R\\'asonyi and L\\'epinette\n(2012) which concentrates on the one dimensional case. Namely, we prove that\nthe Robust No Free Lunch with Vanishing Risk assumption is equivalent to the\nexistence of a Strictly Consistent Price System. Interestingly, the presence of\ntransaction costs allows a natural definition of trading strategies and avoids\nall the technical and un-natural restrictions due to stochastic integration\nthat appear in bond models without friction. We restrict to the case where\nexchange rates are continuous in time and leave the general c\\`adl\\`ag case for\nfurther studies.\n"
    },
    {
        "paper_id": 1302.0465,
        "authors": "Lixin Wu",
        "title": "CVA and FVA to Derivatives Trades Collateralized by Cash",
        "comments": "29 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we combine replication pricing with expectation pricing for\nderivative trades that are partially collateralized by cash. The derivatives\nare replicated by underlying assets and cash, using repurchasing agreement\n(repo) and margining, which incur funding costs. We derive a partial\ndifferential equation (PDE) for the derivatives price, obtain and decompose its\nsolution into the risk-free value of the derivative plus credit valuation\nadjustment (CVA) and funding valuation adjustment (FVA). For most derivatives,\nas we shall show, CVAs can be evaluated analytically or semi-analytically,\nwhile FVAs, as well as the derivatives values, will have to be solved\nrecursively through numerical procedures due to their interdependence. In\nnumerical demonstrations, continuous and discrete margin revisions are\nconsidered, respectively, for an equity call option and a vanilla interest-rate\nswaps.\n"
    },
    {
        "paper_id": 1302.0537,
        "authors": "Krzysztof Piasecki",
        "title": "Basis of financial arithmetic from the viewpoint of the utility theory",
        "comments": null,
        "journal-ref": "Operations Research and Decisions 22(3), 2012, pp 37-53",
        "doi": "10.5277/ord120303",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main goal of this paper is presentation a modern axiomatic approach to\nfinancial arithmetic. At the first, the axiomatic financial arithmetic theory\nwas proposed by Peccati who has introduced the axiomatic definition of the\nfuture value. This theory has been extensively developed in past years.\nProposed approach to financial arithmetic is based on the financial flow\nutility concept. This utility function is defined as linear extension of\nmulticriteria comparison determined by the time preference and the capital\npreference. Then the present value is equal to financial flow utility.\nTherefore, the law of diminishing marginal wealth utility has been considered\nas additional feature of the present value. The future value is defined as the\ninverse of utility function. This definition is a generalization of the Peccati\none. The net present value is given as the unique additive extension of\nfinancial flow utility. Moreover, the synergy effect and the diversification\neffect will be discussed. At the end, the axiomatic present value definition\nwill be specified in three ways.\n"
    },
    {
        "paper_id": 1302.0538,
        "authors": "Krzysztof Piasecki",
        "title": "On return rate implied by behavioural present value",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The future value of a security is described as a random variable.\nDistribution of this random variable is the formal image of risk uncertainty.\nOn the other side, any present value is defined as a value equivalent to the\ngiven future value. This equivalence relationship is a subjective. Thus\nfollows, that present value is described as a fuzzy number, which is depend on\nthe investor's susceptibility to behavioural factors. All above reasons imply,\nthat return rate is given as a fuzzy probabilistic set. The basic properties of\nsuch image of return rate are studied. At the last the set of effective\nsecurities is distinguished as a fuzzy set.\n"
    },
    {
        "paper_id": 1302.0539,
        "authors": "Krzysztof Piasecki",
        "title": "Behavioural present value",
        "comments": null,
        "journal-ref": "SSRN Electronic Journal 2011",
        "doi": "10.2139/ssrn.1729351",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Impact of chosen behavioural factors on imprecision of present value is\ndiscussed here. The formal model of behavioural present value is offered as a\nresult of this discussion. Behavioural present value is described here by fuzzy\nset. These considerations were illustrated by means of extensive numerical case\nstudy. Finally there are shown that in proposed model the return rate is given,\nas a fuzzy probabilistic set.\n"
    },
    {
        "paper_id": 1302.0574,
        "authors": "Lixin Wu",
        "title": "Inflation-rate Derivatives: From Market Model to Foreign Currency\n  Analogy",
        "comments": "36 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we establish a market model for the term structure of forward\ninflation rates based on the risk-neutral dynamics of nominal and real\nzero-coupon bonds. Under the market model, we can price inflation caplets as\nwell as inflation swaptions with a formula similar to the Black's formula, thus\njustify the current market practice. We demonstrate how to further extend the\nmarket model to cope with volatility smiles. Moreover, we establish a\nconsistency condition on the volatility of real zero-coupon bonds using\narbitrage arguments, and with that re-derive the model of Jarrow and Yildirim\n(2003) with real forward rates based on \"foreign currency analogy\", and thus\ninterconnect the two modeling paradigms.\n"
    },
    {
        "paper_id": 1302.0583,
        "authors": "Cheng-Der Fuh and Huei-Wen Teng and Ren-Her Wang",
        "title": "Efficient Importance Sampling for Rare Event Simulation with\n  Applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Importance sampling has been known as a powerful tool to reduce the variance\nof Monte Carlo estimator for rare event simulation. Based on the criterion of\nminimizing the variance of Monte Carlo estimator within a parametric family, we\npropose a general account for finding the optimal tilting measure. To this end,\nwhen the moment generating function of the underlying distribution exists, we\nobtain a simple and explicit expression of the optimal alternative\ndistribution. The proposed algorithm is quite general to cover many interesting\nexamples, such as normal distribution, noncentral $\\chi^2$ distribution, and\ncompound Poisson processes. To illustrate the broad applicability of our\nmethod, we study value-at-risk (VaR) computation in financial risk management\nand bootstrap confidence regions in statistical inferences.\n"
    },
    {
        "paper_id": 1302.059,
        "authors": "Yan Dolinsky and H.Mete Soner",
        "title": "Robust Hedging with Proportional Transaction Costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Duality for robust hedging with proportional transaction costs of path\ndependent European options is obtained in a discrete time financial market with\none risky asset. Investor's portfolio consists of a dynamically traded stock\nand a static position in vanilla options which can be exercised at maturity.\nBoth the stock and the option trading is subject to proportional transaction\ncosts. The main theorem is duality between hedging and a Monge-Kantorovich type\noptimization problem. In this dual transport problem the optimization is over\nall the probability measures which satisfy an approximate martingale condition\nrelated to consistent price systems in addition to the usual marginal\nconstraints.\n"
    },
    {
        "paper_id": 1302.0926,
        "authors": "Jianqing Fan, Yuan Liao, Xiaofeng Shi",
        "title": "Risks of Large Portfolios",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Estimating and assessing the risk of a large portfolio is an important topic\nin financial econometrics and risk management. The risk is often estimated by a\nsubstitution of a good estimator of the volatility matrix. However, the\naccuracy of such a risk estimator for large portfolios is largely unknown, and\na simple inequality in the previous literature gives an infeasible upper bound\nfor the estimation error. In addition, numerical studies illustrate that this\nupper bound is very crude. In this paper, we propose factor-based risk\nestimators under a large amount of assets, and introduce a high-confidence\nlevel upper bound (H-CLUB) to assess the accuracy of the risk estimation. The\nH-CLUB is constructed based on three different estimates of the volatility\nmatrix: sample covariance, approximate factor model with known factors, and\nunknown factors (POET, Fan, Liao and Mincheva, 2013). For the first time in the\nliterature, we derive the limiting distribution of the estimated risks in high\ndimensionality. Our numerical results demonstrate that the proposed upper\nbounds significantly outperform the traditional crude bounds, and provide\ninsightful assessment of the estimation of the portfolio risks. In addition,\nour simulated results quantify the relative error in the risk estimation, which\nis usually negligible using 3-month daily data. Finally, the proposed methods\nare applied to an empirical study.\n"
    },
    {
        "paper_id": 1302.1228,
        "authors": "Marco Antonio Penteado",
        "title": "Efficient Markets, Behavioral Finance and a Statistical Evidence of the\n  Validity of Technical Analysis",
        "comments": "20 pages; Keywords: Efficient Markets, Behavioral Finance, Technical\n  Analysis",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work tried to detect the existence of a relationship between the graphic\nsignals - or patterns - observed day by day in the Brazilian stock market and\nthe trends which happen after these signals, within a period of 8 years, for a\nnumber of securities. The results obtained from this study show evidence of the\nexistence of such a relationship, suggesting the validity of the Technical\nAnalysis as an instrument to predict the trend of security prices in the\nBrazilian stock market within that period.\n"
    },
    {
        "paper_id": 1302.1405,
        "authors": "Stephen J. Hardiman and Nicolas Bercot and Jean-Philippe Bouchaud",
        "title": "Critical reflexivity in financial markets: a Hawkes process analysis",
        "comments": "9 pages, 6 figures. Some clarification and correction made to section\n  II, minor alterations elsewhere",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2013-40107-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We model the arrival of mid-price changes in the E-Mini S&P futures contract\nas a self-exciting Hawkes process. Using several estimation methods, we find\nthat the Hawkes kernel is power-law with a decay exponent close to -1.15 at\nshort times, less than approximately 10^3 seconds, and crosses over to a second\npower-law regime with a larger decay exponent of approximately -1.45 for longer\ntimes scales in the range [10^3, 10^6] seconds. More importantly, we find that\nthe Hawkes kernel integrates to unity independently of the analysed period,\nfrom 1998 to 2011. This suggests that markets are and have always been close to\ncriticality, challenging a recent study which indicates that reflexivity\n(endogeneity) has increased in recent years as a result of increased automation\nof trading. However, we note that the scale over which market events are\ncorrelated has decreased steadily over time with the emergence of higher\nfrequency trading.\n"
    },
    {
        "paper_id": 1302.1564,
        "authors": "David M. Pennock, Michael P. Wellman",
        "title": "Representing Aggregate Belief through the Competitive Equilibrium of a\n  Securities Market",
        "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of belief aggregation: given a group of individual\nagents with probabilistic beliefs over a set of uncertain events, formulate a\nsensible consensus or aggregate probability distribution over these events.\nResearchers have proposed many aggregation methods, although on the question of\nwhich is best the general consensus is that there is no consensus. We develop a\nmarket-based approach to this problem, where agents bet on uncertain events by\nbuying or selling securities contingent on their outcomes. Each agent acts in\nthe market so as to maximize expected utility at given securities prices,\nlimited in its activity only by its own risk aversion. The equilibrium prices\nof goods in this market represent aggregate beliefs. For agents with constant\nrisk aversion, we demonstrate that the aggregate probability exhibits several\ndesirable properties, and is related to independently motivated techniques. We\nargue that the market-based approach provides a plausible mechanism for belief\naggregation in multiagent systems, as it directly addresses self-motivated\nagent incentives for participation and for truthfulness, and can provide a\ndecision-theoretic foundation for the \"expert weights\" often employed in\ncentralized pooling techniques.\n"
    },
    {
        "paper_id": 1302.185,
        "authors": "Dylan Possama\\\"i and Guillaume Royer and Nizar Touzi",
        "title": "On the Robust superhedging of measurable claims",
        "comments": "14 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of robust hedging requires to solve the problem of superhedging\nunder a nondominated family of singular measures. Recent progress was achieved\nby [9,11]. We show that the dual formulation of this problem is valid in a\ncontext suitable for martingale optimal transportation or, more generally, for\noptimal transportation under controlled stochastic dynamics.\n"
    },
    {
        "paper_id": 1302.1965,
        "authors": "St\\'ephane Goutte (LAGA), Nadia Oudjane (FiME Lab), Francesco Russo\n  (UMA)",
        "title": "Variance optimal hedging for continuous time additive processes and\n  applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a large class of vanilla contingent claims, we establish an explicit\nF\\\"ollmer-Schweizer decomposition when the underlying is an exponential of an\nadditive process. This allows to provide an efficient algorithm for solving the\nmean variance hedging problem. Applications to models derived from the\nelectricity market are performed.\n"
    },
    {
        "paper_id": 1302.2009,
        "authors": "Aur\\'elien Alfonsi (CERMICS, INRIA Paris-Rocquencourt), C\\'eline\n  Labart (INRIA Paris-Rocquencourt, LAMA), J\\'er\\^ome Lelong (INRIA\n  Paris-Rocquencourt, LJK)",
        "title": "Stochastic Local Intensity Loss Models with Interacting Particle Systems",
        "comments": null,
        "journal-ref": "Mathematical Finance 00, 00 (2013) 1-29",
        "doi": "10.1111/mafi.12059",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is well-known from the work of Sch\\\"onbucher (2005) that the marginal laws\nof a loss process can be matched by a unit increasing time inhomogeneous Markov\nprocess, whose deterministic jump intensity is called local intensity. The\nStochastic Local Intensity (SLI) models such as the one proposed by Arnsdorf\nand Halperin (2008) allow to get a stochastic jump intensity while keeping the\nsame marginal laws. These models involve a non-linear SDE with jumps. The first\ncontribution of this paper is to prove the existence and uniqueness of such\nprocesses. This is made by means of an interacting particle system, whose\nconvergence rate towards the non-linear SDE is analyzed. Second, this approach\nprovides a powerful way to compute pathwise expectations with the SLI model: we\nshow that the computational cost is roughly the same as a crude Monte-Carlo\nalgorithm for standard SDEs.\n"
    },
    {
        "paper_id": 1302.2063,
        "authors": "Tiziano Squartini, Iman van Lelyveld, Diego Garlaschelli",
        "title": "Early-warning signals of topological collapse in interbank networks",
        "comments": "28 pages, 23 figures, 1 table",
        "journal-ref": "Sci. Rep. 3 (3357) (2013)",
        "doi": "10.1038/srep03357",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The financial crisis clearly illustrated the importance of characterizing the\nlevel of 'systemic' risk associated with an entire credit network, rather than\nwith single institutions. However, the interplay between financial distress and\ntopological changes is still poorly understood. Here we analyze the quarterly\ninterbank exposures among Dutch banks over the period 1998-2008, ending with\nthe crisis. After controlling for the link density, many topological properties\ndisplay an abrupt change in 2008, providing a clear - but unpredictable -\nsignature of the crisis. By contrast, if the heterogeneity of banks'\nconnectivity is controlled for, the same properties show a gradual transition\nto the crisis, starting in 2005 and preceded by an even earlier period during\nwhich anomalous debt loops could have led to the underestimation of\ncounter-party risk. These early-warning signals are undetectable if the network\nis reconstructed from partial bank-specific data, as routinely done. We discuss\nimportant implications for bank regulatory policies.\n"
    },
    {
        "paper_id": 1302.2231,
        "authors": "Chuancun Yin, Yuzhen Wen, Yongxia Zhao",
        "title": "On the optimal dividend problem for a spectrally positive Levy process",
        "comments": "to appear in Astin Bull",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study the optimal dividend problem for a company whose\nsurplus process evolves as a spectrally positive Levy process. This model\nincluding the dual model of the classical risk model and the dual model with\ndiffusion as special cases. We assume that dividends are paid to the\nshareholders according to admissible strategy whose dividend rate is bounded by\na constant. The objective is to find a dividend policy so as to maximize the\nexpected discounted value of dividends which are paid to the shareholders until\nthe company is ruined. We show that the optimal dividend strategy is formed by\na threshold strategy.\n"
    },
    {
        "paper_id": 1302.2312,
        "authors": "Fabien Heuwelyckx",
        "title": "Convergence of European Lookback Options with Floating Strike in the\n  Binomial Model",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1142/S0219024914500253",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we study the convergence of a European lookback option with\nfloating strike evaluated with the binomial model of Cox-Ross-Rubinstein to its\nevaluation with the Black-Scholes model. We do the same for its delta. We\nconfirm that these convergences are of order 1/Sqrt(n). For this, we use the\nbinomial model of Cheuk-Vorst which allows us to write the price of the option\nusing a double sum. Based on an improvement of a lemma of Lin-Palmer, we are\nable to give the precise value of the term in 1/Sqrt(n) in the expansion of the\nerror; we also obtain the value of the term in 1/n if the risk free interest\nrate is non zero. This modelisation will also allow us to determine the first\nterm in the expansion of the delta.\n"
    },
    {
        "paper_id": 1302.2337,
        "authors": "Archil Gulisashvili and Peter Laurence",
        "title": "The Heston Riemannian distance function",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Heston model is a popular stock price model with stochastic volatility\nthat has found numerous applications in practice. In the present paper, we\nstudy the Riemannian distance function associated with the Heston model and\nobtain explicit formulas for this function using geometrical and analytical\nmethods. Geometrical approach is based on the study of the Heston geodesics,\nwhile the analytical approach exploits the links between the Heston distance\nfunction and the sub-Riemannian distance function in the Grushin plane. For the\nGrushin plane, we establish an explicit formula for the Legendre-Fenchel\ntransform of the limiting cumulant generating function and prove a partial\nlarge deviation principle that is true only inside a special set.\n"
    },
    {
        "paper_id": 1302.2493,
        "authors": "Wei Lin, Linbo Shao",
        "title": "Evaluation on the Financial Competitiveness of Chinese Listed Real\n  Estate Companies Based on Entropy Method",
        "comments": "4 pages, 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  The real estate is a pillar industry of China's national economy. Due to\nchanges in policy and market conditions, the real estate companies are facing\ngreater pressures to survive in a competitive environment. They must improve\ntheir financial competitiveness. Based on the conceptual framework of financial\ncompetitiveness, this paper presented a financial competitiveness evaluation\nindex system, covering four aspects, including profitability, solvency,\nsustainable development and operational capacity. Entropy value method is\napplied to determine the index weight. 105 listed real estate company's\nfinancial competitiveness are evaluated, the results show that: high-scoring\ncompany has strong profitability, sustainable development and operational\ncapacity; low-scoring company has weak profitability and poor ability of\nsustainable development; solvency doesn't affect the company's financial\ncompetitiveness obviously.\n"
    },
    {
        "paper_id": 1302.2534,
        "authors": "Matyas Barczy, Leif Doering, Zenghu Li, Gyula Pap",
        "title": "Stationarity and ergodicity for an affine two factor model",
        "comments": "28 pages; the title has been changed; a mistake in the proof of\n  Theorem 4.1 has been corrected",
        "journal-ref": "Advances in Applied Probability 46 (3), 2014, 878-898",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the existence of a unique stationary distribution and ergodicity for\na 2-dimensional affine process. The first coordinate is supposed to be a\nso-called alpha-root process with \\alpha\\in(1,2]. The existence of a unique\nstationary distribution for the affine process is proved in case of\n\\alpha\\in(1,2]; further, in case of \\alpha=2, the ergodicity is also shown.\n"
    },
    {
        "paper_id": 1302.2544,
        "authors": "Bent Flyvbjerg",
        "title": "Quality Control and Due Diligence in Project Management: Getting\n  Decisions Right by Taking the Outside View",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper explores how theories of the planning fallacy and the outside view\nmay be used to conduct quality control and due diligence in project management.\nFirst, a much-neglected issue in project management is identified, namely that\nthe front-end estimates of costs and benefits--used in the business cases,\ncost-benefit analyses, and social and environmental impact assessments that\ntypically support decisions on projects--are typically significantly different\nfrom actual ex post costs and benefits, and are therefore poor predictors of\nthe actual value and viability of projects. Second, it is discussed how\nKahneman and Tversky's theories of the planning fallacy and the outside view\nmay help explain and remedy this situation through quality control of\ndecisions. Third, it is described what quality control and due diligence are in\nthe context of project management, and an eight-step procedure is outlined for\ndue diligence based on the outside view. Fourth, the procedure is tested on a\nreal-life, multibillion-dollar project, organized as a public-private\npartnership. Finally, Akerlof and Shiller's recent discussion in economics of\n\"firing the forecaster\" is discussed together with its relevance to project\nmanagement. In sum, the paper demonstrates the need, the theoretical basis, a\npractical methodology, and a real-life example for how to de-bias project\nmanagement using quality control and due diligence based on the outside view.\n"
    },
    {
        "paper_id": 1302.2567,
        "authors": "Jean-Baptiste Monnier",
        "title": "Technical report : Risk-neutral density recovery via spectral analysis",
        "comments": "32 pages, 17 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we propose a new method for estimating the conditional\nrisk-neutral density (RND) directly from a cross-section of put option bid-ask\nquotes. More precisely, we propose to view the RND recovery problem as an\ninverse problem. We first show that it is possible to define restricted put and\ncall operators that admit a singular value decomposition (SVD), which we\ncompute explicitly. We subsequently show that this new framework allows us to\ndevise a simple and fast quadratic programming method to recover the smoothest\nRND whose corresponding put prices lie inside the bid-ask quotes. This method\nis termed the spectral recovery method (SRM). Interestingly, the SVD of the\nrestricted put and call operators sheds some new light on the RND recovery\nproblem. The SRM improves on other RND recovery methods in the sense that:\n  - it is fast and simple to implement since it requires solution of a single\nquadratic program, while being fully nonparametric; - it takes the bid ask\nquotes as sole input and does not require any sort of calibration, smoothing or\npreprocessing of the data; - it is robust to the paucity of price quotes; - it\nreturns the smoothest density giving rise to prices that lie inside the bid ask\nquotes. The estimated RND is therefore as well-behaved as can be; - it returns\na closed form estimate of the RND on the interval [0,B] of the positive real\nline, where B is a positive constant that can be chosen arbitrarily. We thus\nobtain both the middle part of the RND together with its full left tail and\npart of its right tail.\n  We confront this method to both real and simulated data and observe that it\nfares well in practice. The SRM is thus found to be a promising alternative to\nother RND recovery methods.\n"
    },
    {
        "paper_id": 1302.3001,
        "authors": "Gabriel Frahm",
        "title": "A Modern Approach to the Efficient-Market Hypothesis",
        "comments": "This paper has been withdrawn by the author due to substantial\n  shortcomings of the concept of \"market completeness\" and some other issues\n  related to the definition of \"market efficiency.\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Market efficiency at least requires the absence of weak arbitrage\nopportunities, but this is not sufficient to establish a situation where the\nmarket is sensitive, i.e., where it \"fully reflects\" or \"rapidly adjusts to\"\nsome information flow including the evolution of asset prices. By contrast, No\nWeak Arbitrage together with market sensitivity is sufficient and necessary for\na market to be informationally efficient.\n"
    },
    {
        "paper_id": 1302.3169,
        "authors": "Mario Guti\\'errez-Roig and Josep Perell\\'o",
        "title": "Volatility polarization of non-specialized investors' heterogeneous\n  activity",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets provide an ideal frame for studying decision making in\ncrowded environments. Both the amount and accuracy of the data allows to apply\ntools and concepts coming from physics that studies collective and emergent\nphenomena or self-organised and highly heterogeneous systems. We analyse the\nactivity of 29,930 non-expert individuals that represent a small portion of the\nwhole market trading volume. The very heterogeneous activity of individuals\nobeys a Zipf's law, while synchronization network properties unveil a community\nstructure. We thus correlate individual activity with the most eminent\nmacroscopic signal in financial markets, that is volatility, and quantify how\nindividuals are clearly polarized by volatility. The assortativity by\nattributes of our synchronization networks also indicates that individuals look\nat the volatility rather than imitate directly each other thus providing an\ninteresting interpretation of herding phenomena in human activity. The results\ncan also improve agent-based models since they provide direct estimation of the\nagent's parameters.\n"
    },
    {
        "paper_id": 1302.3197,
        "authors": "Sabrina Camargo, Silvio M. Duarte Queiros, Celia Anteneodo",
        "title": "Bridging stylized facts in finance and data non-stationarities",
        "comments": "13 pages, 12 figures",
        "journal-ref": "Eur. Phys. J. B 86, 159 (2013)",
        "doi": "10.1140/epjb/e2013-30974-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Employing a recent technique which allows the representation of nonstationary\ndata by means of a juxtaposition of locally stationary patches of different\nlength, we introduce a comprehensive analysis of the key observables in a\nfinancial market: the trading volume and the price fluctuations. From the\nsegmentation procedure we are able to introduce a quantitative description of a\ngroup of statistical features (stylizes facts) of the trading volume and price\nfluctuations, namely the tails of each distribution, the U-shaped profile of\nthe volume in a trading session and the evolution of the trading volume\nautocorrelation function. The segmentation of the trading volume series\nprovides evidence of slow evolution of the fluctuating parameters of each\npatch, pointing to the mixing scenario. Assuming that long-term features are\nthe outcome of a statistical mixture of simple local forms, we test and compare\ndifferent probability density functions to provide the long-term distribution\nof the trading volume, concluding that the log-normal gives the best agreement\nwith the empirical distribution. Moreover, the segmentation of the magnitude\nprice fluctuations are quite different from the results for the trading volume,\nindicating that changes in the statistics of price fluctuations occur at a\nfaster scale than in the case of trading volume.\n"
    },
    {
        "paper_id": 1302.3306,
        "authors": "Takashi Kato, Akihiko Takahashi, Toshihiro Yamada",
        "title": "An Asymptotic Expansion Formula for Up-and-Out Barrier Option Price\n  under Stochastic Volatility Model",
        "comments": "9 pages",
        "journal-ref": "JSIAM Letters Vol. 5 (2013) p.17-20",
        "doi": "10.14495/jsiaml.5.17",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper derives a new semi closed-form approximation formula for pricing\nan up-and-out barrier option under a certain type of stochastic volatility\nmodel including SABR model by applying a rigorous asymptotic expansion method\ndeveloped by Kato, Takahashi and Yamada (2012). We also demonstrate the\nvalidity of our approximation method through numerical examples.\n"
    },
    {
        "paper_id": 1302.3319,
        "authors": "Hyong-Chol O and Mun-Chol KiM",
        "title": "The Pricing of Multiple-Expiry Exotics",
        "comments": "16 pages, 3 figures, Ver. 1 was presented in the 1st International\n  Conference of Pyongyang University of Science & Technology, 5~6, Oct, 2011,\n  in ver. 2 added proof, in ver. 3 revised and added some detail of proofs,\n  Ver. 4,5: latex version, Ver. 6~8: corrected typos in EJMAA\n  Vol.1(2)2013,247-259",
        "journal-ref": "Electronic Journal of Mathematical Analysis and Applications,\n  Vol.1, No.2, July 2013, pp.247-259",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we extend Buchen's method to develop a new technique for\npricing of some exotic options with several expiry dates(more than 3 expiry\ndates) using a concept of higher order binary option. At first we introduce the\nconcept of higher order binary option and then provide the pricing formulae of\n$n$-th order binaries using PDE method. After that, we apply them to pricing of\nsome multiple-expiry exotic options such as Bermudan option, multi time\nextendable option, multi shout option and etc. Here, when calculating the price\nof concrete multiple-expiry exotic options, we do not try to get the formal\nsolution to corresponding initial-boundary problem of the Black-Scholes\nequation, but explain how to express the expiry payoffs of the exotic options\nas a combination of the payoffs of some class of higher order binary options.\nOnce the expiry payoffs are expressed as a linear combination of the payoffs of\nsome class of higher order binary options, in order to avoid arbitrage, the\nexotic option prices are obtained by static replication with respect to this\nfamily of higher order binaries.\n"
    },
    {
        "paper_id": 1302.3451,
        "authors": "Matyas Barczy, Leif Doering, Zenghu Li, Gyula Pap",
        "title": "Parameter estimation for a subcritical affine two factor model",
        "comments": "31 pages. Title is changed. Extended version: new parameters are\n  estimated and an Appendix is added",
        "journal-ref": "Journal of Statistical Planning and Inference 151-152, 2014, 37-59",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For an affine two factor model, we study the asymptotic properties of the\nmaximum likelihood and least squares estimators of some appearing parameters in\nthe so-called subcritical (ergodic) case based on continuous time observations.\nWe prove strong consistency and asymptotic normality of the estimators in\nquestion.\n"
    },
    {
        "paper_id": 1302.3642,
        "authors": "Bent Flyvbjerg",
        "title": "From Nobel Prize to Project Management: Getting Risks Right",
        "comments": "arXiv admin note: text overlap with arXiv:1302.2544",
        "journal-ref": "Bent Flyvbjerg, \"From Nobel Prize to Project Management: Getting\n  Risks Right,\" Project Management Journal, vol. 37, no. 3, August 2006, pp.\n  5-15",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A major source of risk in project management is inaccurate forecasts of\nproject costs, demand, and other impacts. The paper presents a promising new\napproach to mitigating such risk, based on theories of decision making under\nuncertainty which won the 2002 Nobel prize in economics. First, the paper\ndocuments inaccuracy and risk in project management. Second, it explains\ninaccuracy in terms of optimism bias and strategic misrepresentation. Third,\nthe theoretical basis is presented for a promising new method called \"reference\nclass forecasting,\" which achieves accuracy by basing forecasts on actual\nperformance in a reference class of comparable projects and thereby bypassing\nboth optimism bias and strategic misrepresentation. Fourth, the paper presents\nthe first instance of practical reference class forecasting, which concerns\ncost forecasts for large transportation infrastructure projects. Finally,\npotentials for and barriers to reference class forecasting are assessed.\n"
    },
    {
        "paper_id": 1302.3654,
        "authors": "Hyong-Chol O, Jong-Jun Jo and Chol-Ho Kim",
        "title": "Pricing Corporate Defaultable Bond using Declared Firm Value",
        "comments": "12 pages, version 5 is written in tex and accepted in\n  EJMAA(Electronic Journal of Mathematical Analysis and Applications)",
        "journal-ref": "Electronic Journal of Mathematical Analysis and Applications,\n  Vol.2(1),Jan 2014,1-11",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the pricing problem for corporate defaultable bond from the\nviewpoint of the investors outside the firm that could not exactly know about\nthe information of the firm. We consider the problem for pricing of corporate\ndefaultable bond in the case when the firm value is only declared in some fixed\ndiscrete time and unexpected default intensity is determined by the declared\nfirm value. Here we provide a partial differential equation model for such a\ndefaultable bond and give its pricing formula. Our pricing model is derived to\nsolving problems of partial differential equations with random constants (de-\nfault intensity) and terminal values of binary types. Our main method is to use\nthe solving method of a partial differential equation with a random constant in\nevery subinterval and to take expectation to remove the random constants.\n"
    },
    {
        "paper_id": 1302.3704,
        "authors": "R\\'emy Chicheportiche, Anirban Chakraborti",
        "title": "A model-free characterization of recurrences in stationary time series",
        "comments": "4 pages, 2 figures, 2 proofs included in supplementary material",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Study of recurrences in earthquakes, climate, financial time-series, etc. is\ncrucial to better forecast disasters and limit their consequences. However,\nalmost all the previous phenomenological studies involved only a long-ranged\nautocorrelation function, or disregarded the multi-scaling properties induced\nby potential higher order dependencies. Consequently, they missed the facts\nthat non-linear dependences do impact both the statistics and dynamics of\nrecurrence times, and that scaling arguments for the unconditional distribution\nmay not be applicable. We argue that copulas is the correct model-free\nframework to study non-linear dependencies in time series and related concepts\nlike recurrences. Fitting and/or simulating the intertemporal distribution of\nrecurrence intervals is very much system specific, and cannot actually benefit\nfrom universal features, in contrast to the previous claims. This has important\nimplications in epilepsy prognosis and financial risk management applications.\n"
    },
    {
        "paper_id": 1302.3771,
        "authors": "Giuseppe Campolieti, Roman N. Makarov, and Karl Wouterloot",
        "title": "Pricing Step Options under the CEV and other Solvable Diffusion Models",
        "comments": "30 pages, 16 figures, submitted to IJTAF",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a special family of occupation-time derivatives, namely\nproportional step options introduced by Linetsky in [Math. Finance, 9, 55--96\n(1999)]. We develop new closed-form spectral expansions for pricing such\noptions under a class of nonlinear volatility diffusion processes which\nincludes the constant-elasticity-of-variance (CEV) model as an example. In\nparticular, we derive a general analytically exact expression for the resolvent\nkernel (i.e. Green's function) of such processes with killing at an exponential\nstopping time (independent of the process) of occupation above or below a fixed\nlevel. Moreover, we succeed in Laplace inverting the resolvent kernel and\nthereby derive newly closed-form spectral expansion formulae for the transition\nprobability density of such processes with killing. The spectral expansion\nformulae are rapidly convergent and easy-to-implement as they are based simply\non knowledge of a pair of fundamental solutions for an underlying solvable\ndiffusion process. We apply the spectral expansion formulae to the pricing of\nproportional step options for four specific families of solvable nonlinear\ndiffusion asset price models that include the CEV diffusion model and three\nother multi-parameter state-dependent local volatility confluent hypergeometric\ndiffusion processes.\n"
    },
    {
        "paper_id": 1302.3818,
        "authors": "Anindya S. Chakrabarti",
        "title": "Bimodality in the firm size distributions: a kinetic exchange model\n  approach",
        "comments": "6 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2013-40114-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Firm growth process in the developing economies is known to produce\ndivergence in their growth path giving rise to bimodality in the size\ndistribution. Similar bimodality has been observed in wealth distribution as\nwell. Here, we introduce a modified kinetic exchange model which can reproduce\nsuch features. In particular, we will show numerically that a nonlinear\nretention rate (or savings propensity) causes this bimodality. This model can\naccommodate binary trading as well as the whole system-side trading thus making\nit more suitable to explain the non-standard features of wealth distribution as\nwell as firm size distribution.\n"
    },
    {
        "paper_id": 1302.387,
        "authors": "Robert Fernholz, Tomoyuki Ichiba and Ioannis Karatzas",
        "title": "A second-order stock market model",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A first-order model for a stock market assigns to each stock a return\nparameter and a variance parameter that depend only on the rank of the stock. A\nsecond-order model assigns these parameters based on both the rank and the name\nof the stock. First- and second-order models exhibit stability properties that\nmake them appropriate as a backdrop for the analysis of the idiosyncratic\nbehavior of individual stocks. Methods for the estimation of the parameters of\nsecond-order models are developed in this paper.\n"
    },
    {
        "paper_id": 1302.3958,
        "authors": "Laszlo Balazsi and Krisztina Kiss",
        "title": "Cross-diffusion Modeling in Macroeconomics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with the stability properties of a closed market, where\ncapital and labour force are acting like a predator-prey system in\npopulation-dynamics. The spatial movement of the capital and labour force are\ntaken into account by cross-diffusion effect. First, we are showing two\npossible ways for modeling this system in only one country's market (applying a\nsimple functional response and a Holling-type ratio-dependent response as\nwell), examining the conditions of their stability properties. We extend the\nratio-dependent model into two countries common market where two kind of\ncross-diffusion effects are present, and find those additional conditions,\nwhose are necessary for the stability of the global common market besides the\nstability of each countries local markets. Our four-dimensional model\nhighlights that a hectic movement of the capital toward labour force can cause\na Turing instability.\n"
    },
    {
        "paper_id": 1302.4112,
        "authors": "Jacky Mallett",
        "title": "An examination of the effect on the Icelandic Banking System of\n  Ver{\\dh}trygg{\\dh} L\\'{a}n (Indexed-Linked Loans)",
        "comments": "19 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In 1979 following a decade of hyperinflation, Iceland introduced\nVer{\\dh}trygg{\\dh} l\\'an, negatively amortised, index-linked loans whose\noutstanding principal is increased by the rate of the consumer price inflation\nindex(CPI). The loans were part of a general government policy which used\nindexation to the CPI to address the economic consequences of the\nhyperinflation. Although most other forms of indexation were subsequently\nremoved, loan indexation has remained, and these loans now comprise the\nmajority of mortgages in Iceland. Although it is still often argued that\nindex-linked loans helped to stop the hyperinflation, these arguments are\ntypically based on high level macro-economic interpretations of the Icelandic\neconomy, they fail to identify specific mechanisms to support their claims. In\nthis paper we take the opposite approach, and present a detailed analysis of\nthe monetary mechanics used for the loans at the double entry bookkeeping level\nof the banking system.\n  Based on this analysis there appears to be no evidence or mechanism that\nwould support the claim that index-linked loans reduce or stop inflation. On\nthe contrary: our research shows that the bookkeeping treatment of these loans\nwithin the banking system directly contributes to the banking system's monetary\nexpansion rate, and hence index-linked loans act to increase the inflation rate\nto which they are linked, rather than reducing it. They consequently create a\npositive feedback loop within the banking system's monetary regulation\noperating directly on the money supply. Since the feedback into monetary\nexpansion only occurs at annual CPI rates above approximately 2%, we suggest\none solution would be to stabilise the money supply to 0% growth, and we\nexplore some ways this could be achieved by modifying the Basel Regulatory\nFramework within the Icelandic Banking System.\n"
    },
    {
        "paper_id": 1302.4181,
        "authors": "Luis H. R. Alvarez E., Pekka Matom\\\"aki, Teppo A. Rakkolainen",
        "title": "A Class of Solvable Optimal Stopping Problems of Spectrally Negative\n  Jump Diffusions",
        "comments": "32 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the optimal stopping of a class of spectrally negative jump\ndiffusions. We state a set of conditions under which the value is shown to have\na representation in terms of an ordinary nonlinear programming problem. We\nestablish a connection between the considered problem and a stopping problem of\nan associated continuous diffusion process and demonstrate how this connection\nmay be applied for characterizing the stopping policy and its value. We also\nestablish a set of typically satisfied conditions under which increased\nvolatility as well as higher jump-intensity decelerates rational exercise by\nincreasing the value and expanding the continuation region.\n"
    },
    {
        "paper_id": 1302.4254,
        "authors": "Claudio Fontana, Bernt {\\O}ksendal and Agn\\`es Sulem",
        "title": "Market viability and martingale measures under partial information",
        "comments": "22 pages, revised version",
        "journal-ref": "Methodology and Computing in Applied Probability, 2015, vol.\n  17(1), 15-39",
        "doi": "10.1007/s11009-014-9397-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a financial market model with a single risky asset whose price\nprocess evolves according to a general jump-diffusion with locally bounded\ncoefficients and where market participants have only access to a partial\ninformation flow. For any utility function, we prove that the partial\ninformation financial market is locally viable, in the sense that the optimal\nportfolio problem has a solution up to a stopping time, if and only if the\n(normalised) marginal utility of the terminal wealth generates a partial\ninformation equivalent martingale measure (PIEMM). This equivalence result is\nproved in a constructive way by relying on maximum principles for stochastic\ncontrol problems under partial information. We then characterize a global\nnotion of market viability in terms of partial information local martingale\ndeflators (PILMDs). We illustrate our results by means of a simple example.\n"
    },
    {
        "paper_id": 1302.4592,
        "authors": "Charles-Albert Lehalle",
        "title": "Market Microstructure Knowledge Needed for Controlling an Intra-Day\n  Trading Process",
        "comments": "33 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A great deal of academic and theoretical work has been dedicated to optimal\nliquidation of large orders these last twenty years. The optimal split of an\norder through time (`optimal trade scheduling') and space (`smart order\nrouting') is of high interest \\rred{to} practitioners because of the increasing\ncomplexity of the market micro structure because of the evolution recently of\nregulations and liquidity worldwide. This paper translates into quantitative\nterms these regulatory issues and, more broadly, current market design. It\nrelates the recent advances in optimal trading, order-book simulation and\noptimal liquidity to the reality of trading in an emerging global network of\nliquidity.\n"
    },
    {
        "paper_id": 1302.4595,
        "authors": "Chris Kenyon and Andrew Green",
        "title": "Collateral-Enhanced Default Risk",
        "comments": "12 pages; 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Changes in collateralization have been implicated in significant default (or\nnear-default) events during the financial crisis, most notably with AIG. We\nhave developed a framework for quantifying this effect based on moving between\nMerton-type and Black-Cox-type structural default models. Our framework leads\nto a single equation that emcompasses the range of possibilities, including\ncollateralization remargining frequency (i.e. discrete observations). We show\nthat increases in collateralization, by exposing entities to daily\nmark-to-market volatility, enhance default probability. This quantifies the\nwell-known problem with collateral triggers. Furthermore our model can be used\nto quantify the degree to which central counterparties, whilst removing credit\nrisk transmission, systematically increase default risk.\n"
    },
    {
        "paper_id": 1302.4676,
        "authors": "Michael B. Giles, Kristian Debrabant, Andreas R\\\"o{\\ss}ler",
        "title": "Analysis of multilevel Monte Carlo path simulation using the Milstein\n  discretisation",
        "comments": "33 pages, 4 figures, to appear in Discrete and Continuous Dynamical\n  Systems - Series B",
        "journal-ref": "Discrete & Continuous Dynamical Systems - B, 2019, 24 (8) :\n  3881-3903",
        "doi": "10.3934/dcdsb.2018335",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The multilevel Monte Carlo path simulation method introduced by Giles ({\\it\nOperations Research}, 56(3):607-617, 2008) exploits strong convergence\nproperties to improve the computational complexity by combining simulations\nwith different levels of resolution. In this paper we analyse its efficiency\nwhen using the Milstein discretisation; this has an improved order of strong\nconvergence compared to the standard Euler-Maruyama method, and it is proved\nthat this leads to an improved order of convergence of the variance of the\nmultilevel estimator. Numerical results are also given for basket options to\nillustrate the relevance of the analysis.\n"
    },
    {
        "paper_id": 1302.4679,
        "authors": "Carole Bernard, Jit Seng Chen, Steven Vanduffel",
        "title": "Rationalizing Investors Choice",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Assuming that agents' preferences satisfy first-order stochastic dominance,\nwe show how the Expected Utility paradigm can rationalize all optimal\ninvestment choices: the optimal investment strategy in any behavioral\nlaw-invariant (state-independent) setting corresponds to the optimum for an\nexpected utility maximizer with an explicitly derived concave non-decreasing\nutility function. This result enables us to infer the utility and risk aversion\nof agents from their investment choice in a non-parametric way. We relate the\nproperty of decreasing absolute risk aversion (DARA) to distributional\nproperties of the terminal wealth and of the financial market. Specifically, we\nshow that DARA is equivalent to a demand for a terminal wealth that has more\nspread than the opposite of the log pricing kernel at the investment horizon.\n"
    },
    {
        "paper_id": 1302.4854,
        "authors": "Pierre Henry-Labordere (SOCIETE GENERALE), Nizar Touzi (CMAP)",
        "title": "An Explicit Martingale Version of Brenier's Theorem",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By investigating model-independent bounds for exotic options in financial\nmathematics, a martingale version of the Monge-Kantorovich mass transport\nproblem was introduced in \\cite{BeiglbockHenry\nLaborderePenkner,GalichonHenry-LabordereTouzi}. In this paper, we extend the\none-dimensional Brenier's theorem to the present martingale version. We provide\nthe explicit martingale optimal transference plans for a remarkable class of\ncoupling functions corresponding to the lower and upper bounds. These explicit\nextremal probability measures coincide with the unique left and right monotone\nmartingale transference plans, which were introduced in \\cite{BeiglbockJuillet}\nby suitable adaptation of the notion of cyclic monotonicity. Instead, our\napproach relies heavily on the (weak) duality result stated in\n\\cite{BeiglbockHenry-LaborderePenkner}, and provides, as a by-product, an\nexplicit expression for the corresponding optimal semi-static hedging\nstrategies. We finally provide an extension to the multiple marginals case.\n"
    },
    {
        "paper_id": 1302.5339,
        "authors": "Julia Kraus, Philippe Bertrand, Rudi Zagst",
        "title": "Theory of Performance Participation Strategies",
        "comments": "First version: January 25, 2010 (see\n  http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1548384) This version:\n  February 7, 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this article is to introduce, analyze and compare two\nperformance participation methods based on a portfolio consisting of two risky\nassets: Option-Based Performance Participation (OBPP) and Constant Proportion\nPerformance Participation (CPPP). By generalizing the provided guarantee to a\nparticipation in the performance of a second risky underlying, the new\nstrategies allow to cope with well-known problems associated with standard\nportfolio insurance methods, like e.g. the CPPI cash lock-in. This is\nespecially an issue in times of market crisis. However, the minimum guaranteed\nportfolio value at the end of the investment horizon is not deterministic\nanymore, but subject to systematic risk instead. With respect to the comparison\nof the two strategies, various criteria are applied such as comparison of\nterminal payoffs and payoff distributions. General analytical expressions for\nall moments of both performance participation strategies as well as standard\nOBPI and CPPI are derived. Furthermore, dynamic hedging properties are\nexamined, in particular classical delta hedging.\n"
    },
    {
        "paper_id": 1302.5548,
        "authors": "Peter K. Friz, Stefan Gerhold, Marc Yor",
        "title": "How to make Dupire's local volatility work with jumps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There are several (mathematical) reasons why Dupire's formula fails in the\nnon-diffusion setting. And yet, in practice, ad-hoc preconditioning of the\noption data works reasonably well. In this note we attempt to explain why. In\nparticular, we propose a regularization procedure of the option data so that\nDupire's local vol diffusion process recreates the correct option prices, even\nin manifest presence of jumps.\n"
    },
    {
        "paper_id": 1302.5966,
        "authors": "Gregory Laughlin, Anthony Aguirre, Joseph Grundfest",
        "title": "Information Transmission Between Financial Markets in Chicago and New\n  York",
        "comments": "18 pages, 10 figures. Submitted to The Financial Review's Special\n  Issue on Computerized and High Frequency Trading",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  High frequency trading has led to widespread efforts to reduce information\npropagation delays between physically distant exchanges. Using relativistically\ncorrect millisecond-resolution tick data, we document a 3-millisecond decrease\nin one-way communication time between the Chicago and New York areas that has\noccurred from April 27th, 2010 to August 17th, 2012. We attribute the first\nsegment of this decline to the introduction of a latency-optimized fiber optic\nconnection in late 2010. A second phase of latency decrease can be attributed\nto line-of-sight microwave networks, operating primarily in the 6-11 GHz region\nof the spectrum, licensed during 2011 and 2012. Using publicly available\ninformation, we estimate these networks' latencies and bandwidths. We estimate\nthe total infrastructure and 5-year operations costs associated with these\nlatency improvements to exceed $500 million.\n"
    },
    {
        "paper_id": 1302.6011,
        "authors": "Chuancun Yin and Yuzhen Wen",
        "title": "Optimal dividends problem with a terminal value for spectrally positive\n  Levy processes",
        "comments": "13 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider a modified version of the classical optimal\ndividends problem of de Finetti in which the dividend payments subject to a\npenalty at ruin. We assume that the risk process is modeled by a general\nspectrally positive Levy process before dividends are deducted. Using the\nfluctuation theory of spectrally positive Levy processes we give an explicit\nexpression of the value function of a barrier strategy. Subsequently we show\nthat a barrier strategy is the optimal strategy among all admissible ones. Our\nwork is motivated by the recent work of Bayraktar, Kyprianou and Yamazaki\n(2013).\n"
    },
    {
        "paper_id": 1302.612,
        "authors": "Qingshuo Song, Qing Zhang",
        "title": "An Optimal Pairs-Trading Rule",
        "comments": "4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is concerned with a pairs trading rule. The idea is to monitor two\nhistorically correlated securities. When divergence is underway, i.e., one\nstock moves up while the other moves down, a pairs trade is entered which\nconsists of a pair to short the outperforming stock and to long the\nunderperforming one. Such a strategy bets the \"spread\" between the two would\neventually converge. In this paper, a difference of the pair is governed by a\nmean-reverting model. The objective is to trade the pair so as to maximize an\noverall return. A fixed commission cost is charged with each transaction. In\naddition, a stop-loss limit is imposed as a state constraint. The associated\nHJB equations (quasi-variational inequalities) are used to characterize the\nvalue functions. It is shown that the solution to the optimal stopping problem\ncan be obtained by solving a number of quasi-algebraic equations. We provide a\nset of sufficient conditions in terms of a verification theorem. Numerical\nexamples are reported to demonstrate the results.\n"
    },
    {
        "paper_id": 1302.6212,
        "authors": "Dimitris Sardelis",
        "title": "On The EU and Euro-zone Stability",
        "comments": "20 pages, 16 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of the present article is to offer a strictly mathematical,\nstatistical treatment of the current account balances in EU and in the\nEurozone. Based on Eurostat data, an overview of the total and annual balances\nis first made for different collections among the EU countries. Then, using the\nMathematica technical computing software, curve fitting is employed to\ndetermine the functions which best reflect how surpluses and deficits\naccumulate with time. It is shown that both EU and the Eurozone economies\nultimately have to pass through a critical, turning point beyond which the\naccumulation of deficits exceeds the accumulation of surpluses thus marking a\nperiod of instability. An interval estimate at a ninety eight percent degree of\nconfidence, yields that EU is found in a phase of instability since 2011 while\nthe instability turning point for the Eurozone is bound to occur any year from\n2015 to 2018.\n"
    },
    {
        "paper_id": 1302.6305,
        "authors": "Ashadun Nobi, Seong Eun Maeng, Gyeong Gyun Ha, and Jae Woo Lee",
        "title": "Random Matrix Theory and Cross-correlations in Global Financial Indices\n  and Local Stock Market Indices",
        "comments": null,
        "journal-ref": null,
        "doi": "10.3938/jkps.62.569",
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  We analyzed cross-correlations between price fluctuations of global financial\nindices (20 daily stock indices over the world) and local indices (daily\nindices of 200 companies in the Korean stock market) by using random matrix\ntheory (RMT). We compared eigenvalues and components of the largest and the\nsecond largest eigenvectors of the cross-correlation matrix before, during, and\nafter the global financial the crisis in the year 2008. We find that the\nmajority of its eigenvalues fall within the RMT bounds [{\\lambda}_,\n{\\lambda}+], where {\\lambda}_- and {\\lambda}_+ are the lower and the upper\nbounds of the eigenvalues of random correlation matrices. The components of the\neigenvectors for the largest positive eigenvalues indicate the identical\nfinancial market mode dominating the global and local indices. On the other\nhand, the components of the eigenvector corresponding to the second largest\neigenvalue are positive and negative values alternatively. The components\nbefore the crisis change sign during the crisis, and those during the crisis\nchange sign after the crisis. The largest inverse participation ratio (IPR)\ncorresponding to the smallest eigenvector is higher after the crisis than\nduring any other periods in the global and local indices. During the global\nfinancial the crisis, the correlations among the global indices and among the\nlocal stock indices are perturbed significantly. However, the correlations\nbetween indices quickly recover the trends before the crisis.\n"
    },
    {
        "paper_id": 1302.6363,
        "authors": "Robert Azencott and Arjun Beri and Yutheeka Gadhyan and Nicolas Joseph\n  and Charles-Albert Lehalle and Matthew Rowley",
        "title": "Realtime market microstructure analysis: online Transaction Cost\n  Analysis",
        "comments": "33 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by the practical challenge in monitoring the performance of a large\nnumber of algorithmic trading orders, this paper provides a methodology that\nleads to automatic discovery of the causes that lie behind a poor trading\nperformance. It also gives theoretical foundations to a generic framework for\nreal-time trading analysis. Academic literature provides different ways to\nformalize these algorithms and show how optimal they can be from a\nmean-variance, a stochastic control, an impulse control or a statistical\nlearning viewpoint. This paper is agnostic about the way the algorithm has been\nbuilt and provides a theoretical formalism to identify in real-time the market\nconditions that influenced its efficiency or inefficiency. For a given set of\ncharacteristics describing the market context, selected by a practitioner, we\nfirst show how a set of additional derived explanatory factors, called anomaly\ndetectors, can be created for each market order. We then will present an online\nmethodology to quantify how this extended set of factors, at any given time,\npredicts which of the orders are underperforming while calculating the\npredictive power of this explanatory factor set. Armed with this information,\nwhich we call influence analysis, we intend to empower the order monitoring\nuser to take appropriate action on any affected orders by re-calibrating the\ntrading algorithms working the order through new parameters, pausing their\nexecution or taking over more direct trading control. Also we intend that use\nof this method in the post trade analysis of algorithms can be taken advantage\nof to automatically adjust their trading action.\n"
    },
    {
        "paper_id": 1302.6399,
        "authors": "Marcus Eriksson, Jukka Lempa, Trygve Kastberg Nilssen",
        "title": "Swing options in commodity markets: A multidimensional L\\'evy diffusion\n  model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study valuation of swing options on commodity markets when the commodity\nprices are driven by multiple factors. The factors are modeled as diffusion\nprocesses driven by a multidimensional L\\'evy process. We set up a valuation\nmodel in terms of a dynamic programming problem where the option can be\nexercised continuously in time. Here, the number of swing rights is given by a\ntotal volume constraint. We analyze some general properties of the model and\nstudy the solution by analyzing the associated HJB-equation. Furthermore, we\ndiscuss the issues caused by the multi-dimensionality of the commodity price\nmodel. The results are illustrated numerically with three explicit examples.\n"
    },
    {
        "paper_id": 1302.6477,
        "authors": "Adri\\'an Carro, Ra\\'ul Toral, Maxi San Miguel",
        "title": "Signal amplification in an agent-based herding model",
        "comments": "This paper has been withdrawn by the authors in order to avoid\n  confusion with a thoroughly revised and updated version of the same work,\n  arXiv:1506.03708",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A growing part of the behavioral finance literature has addressed some of the\nstylized facts of financial time series as macroscopic patterns emerging from\nherding interactions among groups of agents with heterogeneous trading\nstrategies and a limited rationality. We extend a stochastic herding formalism\nintroduced for the modeling of decision making among financial agents, in order\nto take also into account an external influence. In particular, we study the\namplification of an external signal imposed upon the agents by a mechanism of\nresonance. This signal can be interpreted as an advertising or a public\nperception in favor or against one of the two possible trading behaviors, thus\nperiodically breaking the symmetry of the system and acting as a continuously\nvarying exogenous shock. The conditions for the ensemble of agents to more\naccurately follow the periodicity of the signal are studied, finding a maximum\nin the response of the system for a given range of values of both the noise and\nthe frequency of the input signal.\n"
    },
    {
        "paper_id": 1302.6491,
        "authors": "Fatma Haba and Antoine Jacquier",
        "title": "Asymptotic arbitrage in the Heston model",
        "comments": "13 pages. New definition of partial asymptotic arbitrage introduced.\n  Main theorems revised",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the context of the Heston model, we establish a precise link between the\nset of equivalent martingale measures, the ergodicity of the underlying\nvariance process and the concept of asymptotic arbitrage proposed in\nKabanov-Kramkov and in Follmer-Schachermayer.\n"
    },
    {
        "paper_id": 1302.6629,
        "authors": "Damiano Brigo, Jo\\~ao Garcia, Nicola Pede",
        "title": "CoCo Bonds Valuation with Equity- and Credit-Calibrated First Passage\n  Structural Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  After the beginning of the credit and liquidity crisis, financial\ninstitutions have been considering creating a convertible-bond type contract\nfocusing on Capital. Under the terms of this contract, a bond is converted into\nequity if the authorities deem the institution to be under-capitalized. This\npaper discusses this Contingent Capital (or Coco) bond instrument and presents\na pricing methodology based on firm value models. The model is calibrated to\nreadily available market data. A stress test of model parameters is illustrated\nto account for potential model risk. Finally, a brief overview of how the\ninstrument performs is presented.\n"
    },
    {
        "paper_id": 1302.6669,
        "authors": "Wan-Kai Pang, Yuan-Hua Ni, Xun Li, and Ka-Fai Cedric Yiu",
        "title": "Continuous-time Mean-Variance Portfolio Selection with Stochastic\n  Parameters",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies a continuous-time market {under stochastic environment}\nwhere an agent, having specified an investment horizon and a target terminal\nmean return, seeks to minimize the variance of the return with multiple stocks\nand a bond. In the considered model firstly proposed by [3], the mean returns\nof individual assets are explicitly affected by underlying Gaussian economic\nfactors. Using past and present information of the asset prices, a\npartial-information stochastic optimal control problem with random coefficients\nis formulated. Here, the partial information is due to the fact that the\neconomic factors can not be directly observed. Via dynamic programming theory,\nthe optimal portfolio strategy can be constructed by solving a deterministic\nforward Riccati-type ordinary differential equation and two linear\ndeterministic backward ordinary differential equations.\n"
    },
    {
        "paper_id": 1302.6721,
        "authors": "Dimitri O. Ledenyov and Viktor O. Ledenyov",
        "title": "On the theory of firm in nonlinear dynamic financial and economic\n  systems",
        "comments": "27 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The new business paradigms originate a strong necessity to re-think the\ntheory of the firm with the aim to get a better understanding on the\norganizational and functional principles of the firm, operating in the\ninvestment economies in the prosperous societies. In this connection, we make\nthe innovative research to advance our scientific knowledge on the theory of\nfirm in the conditions of the nonlinear dynamic financial and economic systems.\nWe propose that the nonlinearities have to be taken to the consideration and\nthe nonlinear differential equation have to be used to model the firm in the\nmodern theories of the firm in the nonlinear dynamic financial and economic\nsystems. We apply the econophysical approach with the dynamic regimes modeling\non the bifurcation diagram as in the dynamic chaos theory with the purpose to\naccurately characterize the nonlinearities in the economic theory of the firm.\nWe introduce the Ledenyov firm stability theorem, based on the Lyapunov\nstability criteria, to precisely characterize the stability of the firm in the\nnonlinear dynamic financial and economic systems in the time of globalization.\n"
    },
    {
        "paper_id": 1302.6757,
        "authors": "Chuancun Yin, Yuzhen Wen",
        "title": "An extension of Paulsen-Gjessing's risk model with stochastic return on\n  investments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider in this paper a general two-sided jump-diffusion risk model that\nallows for risky investments as well as for correlation between the two\nBrownian motions driving insurance risk and investment return. We first\nintroduce the model and then find the integro-differential equations satisfied\nby the Gerber-Shiu functions as well as the expected discounted penalty\nfunctions at ruin caused by a claim or by oscillation; We also study the\ndividend problem for the threshold and barrier strategies, the moments and\nmoment-generating function of the total discounted dividends until ruin are\ndiscussed. Some examples are given for special cases.\n"
    },
    {
        "paper_id": 1302.6762,
        "authors": "Chuancun Yin, Yuzhen Wen, Zhaojun Zong, Ying Shen",
        "title": "The first passage time problem for mixed-exponential jump processes with\n  applications in insurance and finance",
        "comments": "Abstract and Applied Analysis (To appear)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper stidies the first passage times to constant boundaries for\nmixed-exponential jump diffusion processes. Explicit solutions of the Laplace\ntransforms of the distribution of the first passage times, the joint\ndistribution of the first passage times and undershoot (overshoot) are\nobtained. As applications, we present explicit expression of the Gerber-Shiu\nfunctions for surplus processes with two-sided jumps, present the analytical\nsolutions for popular path-dependent options such as lookback and barrier\noptions in terms of Laplace transforms and give a closed-form expression on the\nprice of the zero-coupon bond under a structural credit risk model with jumps.\n"
    },
    {
        "paper_id": 1302.701,
        "authors": "Damiano Brigo, Francesco Rapisarda, Abir Sridi",
        "title": "The arbitrage-free Multivariate Mixture Dynamics Model: Consistent\n  single-assets and index volatility smiles",
        "comments": "Added several results on dependence structure and to basket markovian\n  projection to the original version posted on Feb 2013. Given length we also\n  added a table of contents",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a multivariate diffusion model that is able to price derivative\nsecurities featuring multiple underlying assets. Each asset volatility smile is\nmodeled according to a density-mixture dynamical model while the same property\nholds for the multivariate process of all assets, whose density is a mixture of\nmultivariate basic densities. This allows to reconcile single name and\nindex/basket volatility smiles in a consistent framework. Our approach could be\ndubbed a multidimensional local volatility approach with vector-state dependent\ndiffusion matrix. The model is quite tractable, leading to a complete market\nand not requiring Fourier techniques for calibration and dependence measures,\ncontrary to multivariate stochastic volatility models such as Wishart. We prove\nexistence and uniqueness of solutions for the model stochastic differential\nequations, provide formulas for a number of basket options, and analyze the\ndependence structure of the model in detail by deriving a number of results on\ncovariances, its copula function and rank correlation measures and\nvolatilities-assets correlations. A comparison with sampling simply-correlated\nsuitably discretized one-dimensional mixture dynamical paths is made, both in\nterms of option pricing and of dependence, and first order expansion\nrelationships between the two models' local covariances are derived. We also\nshow existence of a multivariate uncertain volatility model of which our\nmultivariate local volatilities model is a Markovian projection, highlighting\nthat the projected model is smoother and avoids a number of drawbacks of the\nuncertain volatility version. We also show a consistency result where the\nMarkovian projection of a geometric basket in the multivariate model is a\nunivariate mixture dynamics model. A few numerical examples on basket and\nspread options pricing conclude the paper.\n"
    },
    {
        "paper_id": 1302.7036,
        "authors": "Jozef Barunik and Jiri Kukacka",
        "title": "Realizing stock market crashes: stochastic cusp catastrophe model of\n  returns under the time-varying volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper develops a two-step estimation methodology, which allows us to\napply catastrophe theory to stock market returns with time-varying volatility\nand model stock market crashes. Utilizing high frequency data, we estimate the\ndaily realized volatility from the returns in the first step and use stochastic\ncusp catastrophe on data normalized by the estimated volatility in the second\nstep to study possible discontinuities in markets. We support our methodology\nby simulations where we also discuss the importance of stochastic noise and\nvolatility in deterministic cusp catastrophe model. The methodology is\nempirically tested on almost 27 years of U.S. stock market evolution covering\nseveral important recessions and crisis periods. Due to the very long sample\nperiod we also develop a rolling estimation approach and we find that while in\nthe first half of the period stock markets showed marks of bifurcations, in the\nsecond half catastrophe theory was not able to confirm this behavior. Results\nsuggest that the proposed methodology provides an important shift in\napplication of catastrophe theory to stock markets.\n"
    },
    {
        "paper_id": 1302.7192,
        "authors": "Claudio Fontana",
        "title": "Weak and strong no-arbitrage conditions for continuous financial markets",
        "comments": "28 pages",
        "journal-ref": "International Journal of Theoretical and Applied Finance, 2015,\n  vol. 18(01), 155005",
        "doi": "10.1142/S0219024915500053",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a unified analysis of a whole spectrum of no-arbitrage conditions\nfor financial market models based on continuous semimartingales. In particular,\nwe focus on no-arbitrage conditions weaker than the classical notions of No\nArbitrage and No Free Lunch with Vanishing Risk. We provide a complete\ncharacterisation of the considered no-arbitrage conditions, linking their\nvalidity to the characteristics of the discounted asset price process and to\nthe existence and the properties of (weak) martingale deflators, and review\nclassical as well as recent results.\n"
    },
    {
        "paper_id": 1302.7238,
        "authors": "Maria Viktorovna Droganova, Valentin Vankov Iliev",
        "title": "On the Preference Relations with Negatively Transitive Asymmetric Part.\n  I",
        "comments": "28 pages. This new version is shortened, reorganized, and with new\n  title. Minor corrections",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Given a linearly ordered set I, every surjective map p: A --> I endows the\nset A with a structure of set of preferences by \"replacing\" the elements of I\nwith their inverse images via p considered as \"balloons\" (sets endowed with an\nequivalence relation), lifting the linear order on A, and \"agglutinating\" this\nstructure with the balloons. Every ballooning A of a structure of linearly\nordered set I is a set of preferences whose preference relation (not\nnecessarily complete) is negatively transitive and every such structure on a\ngiven set A can be obtained by ballooning of certain structure of a linearly\nordered set I, intrinsically encoded in A. In other words, the difference\nbetween linearity and negative transitivity is constituted of balloons. As a\nconsequence of this characterization, under certain natural topological\nconditions on the set of preferences A furnished with its interval topology,\nthe existence of a continuous generalized utility function on A is proved.\n"
    },
    {
        "paper_id": 1302.7246,
        "authors": "Alessandro Gnoatto and Martino Grasselli",
        "title": "An analytic multi-currency model with stochastic volatility and\n  stochastic interest rates",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a tractable multi-currency model with stochastic volatility and\ncorrelated stochastic interest rates that takes into account the smile in the\nFX market and the evolution of yield curves. The pricing of vanilla options on\nFX rates can be performed effciently through the FFT methodology thanks to the\naffinity of the model Our framework is also able to describe many non trivial\nlinks between FX rates and interest rates: a second calibration exercise\nhighlights the ability of the model to fit simultaneously FX implied\nvolatilities while being coherent with interest rate products.\n"
    },
    {
        "paper_id": 1303.0073,
        "authors": "Uri Kartoun",
        "title": "A Method for Comparing Hedge Funds",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper presents new machine learning methods: signal composition, which\nclassifies time-series regardless of length, type, and quantity; and\nself-labeling, a supervised-learning enhancement. The paper describes further\nthe implementation of the methods on a financial search engine system to\nidentify behavioral similarities among time-series representing monthly returns\nof 11,312 hedge funds operated during approximately one decade (2000 - 2010).\nThe presented approach of cross-category and cross-location classification\nassists the investor to identify alternative investments.\n"
    },
    {
        "paper_id": 1303.0237,
        "authors": "Pietro Siorpaes",
        "title": "Optimal investment and price dependence in a semi-static market",
        "comments": "31 pages. I have decided to merge the paper arXiv:1210.5466 with the\n  version 1 of the present paper. This version 2 is the result of the merge",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the problem of maximizing expected utility from terminal\nwealth in a semi-static market composed of derivative securities, which we\nassume can be traded only at time zero, and of stocks, which can be traded\ncontinuously in time and are modeled as locally-bounded semi-martingales.\n  Using a general utility function defined on the positive real line, we first\nstudy existence and uniqueness of the solution, and then we consider the\ndependence of the outputs of the utility maximization problem on the price of\nthe derivatives, investigating not only stability but also differentiability,\nmonotonicity, convexity and limiting properties.\n"
    },
    {
        "paper_id": 1303.0283,
        "authors": "Uri Kartoun",
        "title": "Inverse Signal Classification for Financial Instruments",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1303.0073",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper presents new machine learning methods: signal composition, which\nclassifies time-series regardless of length, type, and quantity; and\nself-labeling, a supervised-learning enhancement. The paper describes further\nthe implementation of the methods on a financial search engine system using a\ncollection of 7,881 financial instruments traded during 2011 to identify\ninverse behavior among the time-series.\n"
    },
    {
        "paper_id": 1303.1064,
        "authors": "Xiangyu Cui, Xun Li, Duan Li",
        "title": "Unified Framework of Mean-Field Formulations for Optimal Multi-period\n  Mean-Variance Portfolio Selection",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The classical dynamic programming-based optimal stochastic control methods\nfail to cope with nonseparable dynamic optimization problems as the principle\nof optimality no longer applies in such situations. Among these notorious\nnonseparable problems, the dynamic mean-variance portfolio selection\nformulation had posted a great challenge to our research community until\nrecently. A few solution methods, including the embedding scheme, have been\ndeveloped in the last decade to solve the dynamic mean-variance portfolio\nselection formulation successfully. We propose in this paper a novel mean-field\nframework that offers a more efficient modeling tool and a more accurate\nsolution scheme in tackling directly the issue of nonseparability and deriving\nthe optimal policies analytically for the multi-period mean-variance-type\nportfolio selection problems.\n"
    },
    {
        "paper_id": 1303.1134,
        "authors": "Anastasia Ellanskaya, Lioudmila Vostrikova",
        "title": "Utility maximisation and utility indifference price for exponential\n  semi-martingale models with random factor",
        "comments": "43 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider utility maximization problem for semi-martingale models depending\non a random factor $\\xi$. We reduce initial maximization problem to the\nconditional one, given $\\xi=u$, which we solve using dual approach. For HARA\nutilities we consider information quantities like Kullback-Leibler information\nand Hellinger integrals, and corresponding information processes. As a\nparticular case we study exponential Levy models depending on random factor. In\nthat case the information processes are deterministic and this fact simplify\nvery much indifference price calculus. Then we give the equations for\nindifference prices. We show that indifference price for seller and minus\nindifference price for buyer are risk measures. Finally, we apply the results\nto Geometric Brownian motion case. Using identity in law technique we give the\nexplicit expression for information quantities. Then, the previous formulas for\nindifference price can be applied.\n"
    },
    {
        "paper_id": 1303.1248,
        "authors": "Traian Pirvu and Huayue Zhang",
        "title": "Investment and Consumption with Regime-Switching Discount Rates",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1107.1895",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the problem of consumption and investment in a financial\nmarket within a continuous time stochastic economy. The investor exhibits a\nchange in the discount rate. The investment opportunities are a stock and a\nriskless account. The market coefficients and discount factor switch according\nto a finite state Markov chain. The change in the discount rate leads to time\ninconsistencies of the investor's decisions. The randomness in our model is\ndriven by a Brownian motion and a Markov chain. Following Ekeland and Pirvu we\nintroduce and characterize the subgame perfect strategies. Numerical\nexperiments show the effect of time preference on subgame perfect strategies\nand the pre-commitment strategies.\n"
    },
    {
        "paper_id": 1303.1296,
        "authors": "Hyong-chol O",
        "title": "The Pricing of A Moving Barrier Option",
        "comments": "11 pages, written in working paper series in 2004",
        "journal-ref": null,
        "doi": "10.2139/ssrn.742924",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provided an analytical representation of the price of a barrier option\nwith one type of special moving barrier. We consider the case that risk free\nrate, dividend rate and stock volatility are time dependent. We get a pricing\nformula and put call parity for barrier option when the moving barrier has a\nspecial relation with risk free rate, dividend rate and stock volatility.\n"
    },
    {
        "paper_id": 1303.1298,
        "authors": "Hyong-Chol O, Ning Wan",
        "title": "Analytical Pricing of Defaultable Bond with Stochastic Default Intensity",
        "comments": "35 pages, 6 figures; written in working paper series in 2005, version\n  3 added references with crossref and revised introduction",
        "journal-ref": null,
        "doi": "10.2139/ssrn.723601",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide analytical pricing formula of corporate defaultable bond with both\nexpected and unexpected default in the case with stochastic default intensity.\nIn the case with constant short rate and exogenous default recovery using PDE\nmethod, we gave some pricing formula of the defaultable bond under the\nconditions that 1)expected default recovery is the same with unexpected default\nrecovery; 2) default intensity follows one of 3 special cases of Willmott\nmodel; 3) default intensity is uncorrelated with firm value. Then we derived a\npricing formula of a credit default swap. And in the case of stochastic short\nrate and exogenous default recovery using PDE method, we gave some pricing\nformula of the defaultable bond under the conditions that 1) expected default\nrecovery is the same with unexpected default recovery; 2) the short rate\nfollows Vasicek model; 3) default intensity follows one of 3 special cases of\nWillmott model; 4) default intensity is uncorrelated with firm value; 5)\ndefault intensity is uncorrelated with short rate. Then we derived a pricing\nformula of a credit default swap. We give some credit spread analysis, too.\n"
    },
    {
        "paper_id": 1303.1334,
        "authors": "Denis Belomestny, Fabian Dickmann and Tigran Nagapetyan",
        "title": "Pricing American options via multi-level approximation methods",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we propose a novel approach to reduce the computational\ncomplexity of various approximation methods for pricing discrete time American\noptions. Given a sequence of continuation values estimates corresponding to\ndifferent levels of spatial approximation and time discretization, we propose a\nmulti-level low biased estimate for the price of an American option. It turns\nout that the resulting complexity gain can be rather high and can even reach\nthe order (\\varepsilon^{-1}) with (\\varepsilon) denoting the desired precision.\nThe performance of the proposed multilevel algorithm is illustrated by a\nnumerical example of pricing Bermudan max-call options.\n"
    },
    {
        "paper_id": 1303.1663,
        "authors": "Floarea Baicu, Maria Alexandra Baches",
        "title": "Impact Analysis for Risks in Informatics Systems",
        "comments": "12 pages, 3 figures, 5 refferences, ENEC 2008, ISSN 265-2550",
        "journal-ref": "F.BAICU, M.A.BACHES - Impact Analysis for Risks in Informatics\n  Systems, ENEC 2008, PP. 269-281",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper are presented methods of impact analysis on informatics system\nsecurity accidents, qualitative and quantitative methods, starting with risk\nand informational system security definitions. It is presented the relationship\nbetween the risks of exploiting vulnerabilities of security system, security\nlevel of these informatics systems, probability of exploiting the weak points\nsubject to financial losses of a company, respectively impact of a security\naccident on the company. Herewith are presented some examples concerning losses\ncaused by excesses within informational systems and depicted from the study\ncarried out by CSI.\n"
    },
    {
        "paper_id": 1303.1672,
        "authors": "Nicolae Popoviciu, Floarea Baicu",
        "title": "A new approach for an unitary risk theory",
        "comments": "7 pages, 2 figures, 1 table, 3 references",
        "journal-ref": "Proc. of the WSEAS Int. Conf. on Signal Processing, Computational\n  Geometry and Artificial Vision, Athena, Grece, aug. 2007, pp. 218-222, ISSN\n  1790-5117, ISBN 978-960-8457-97-3",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The work deals with the risk assessment theory. An unitary risk algorithm is\nelaborated. The algorithm is based on parallel curves. The basic curve of risk\nis a hyperbolic curve, obtained as a multiplication between the probability of\noccurrence of certain event and its impact. Section 1 contains the problem\nformulation. Section 2 contains some specific notations and the mathematical\nbackground of risk algorithm. A numerical application based on risk algorithm\nis the content of section 3. Section 4 contains several conclusions.\n"
    },
    {
        "paper_id": 1303.169,
        "authors": "Johanna F. Ziegel",
        "title": "Coherence and elicitability",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The risk of a financial position is usually summarized by a risk measure. As\nthis risk measure has to be estimated from historical data, it is important to\nbe able to verify and compare competing estimation procedures. In statistical\ndecision theory, risk measures for which such verification and comparison is\npossible, are called elicitable. It is known that quantile based risk measures\nsuch as value at risk are elicitable. In this paper we show that law-invariant\nspectral risk measures such as expected shortfall are not elicitable unless\nthey reduce to minus the expected value. Hence, it is unclear how to perform\nforecast verification or comparison. However, the class of elicitable\nlaw-invariant coherent risk measures does not reduce to minus the expected\nvalue. We show that it consists of certain expectiles.\n"
    },
    {
        "paper_id": 1303.2044,
        "authors": "Felix Patzelt and Klaus Pawelzik",
        "title": "Bubbles, Jumps, and Scaling from Properly Anticipated Prices",
        "comments": "6 Pages, 3 Figures. Conference: Self-Organization in Complex Systems:\n  The Past, Present, and Future of Synergetics. On the Occasion of the 85th\n  Birthday of Hermann Haken. -- This version: updated reference 11",
        "journal-ref": "Proceedings of the International Symposium, Hanse Institute of\n  Advanced Studies, Delmenhorst, Germany, November 13-16, 2012. Springer, 2016",
        "doi": "10.1007/978-3-319-27635-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Prices in financial markets exhibit extreme jumps far more often than can be\naccounted for by external news. Further, magnitudes of price changes are\ncorrelated over long times. These so called stylized facts are quantified by\nscaling laws similar to, for example, turbulent fluids. They are believed to\nreflect the complex interactions of heterogenous agents which give rise to\nirrational herding. Therefore, the stylized facts have been argued to provide\nevidence against the efficient market hypothesis which states that prices\nrapidly reflect available information and therefore are described by a\nmartingale. Here we show, that in very simple bidding processes efficiency is\nnot opposed to, but causative to scaling properties observed in real markets.\nThereby, we link the stylized facts not only to price efficiency, but also to\nthe economic theory of rational bubbles. We then demonstrate effects predicted\nfrom our normative model in the dynamics of groups of real human subjects\nplaying a modified minority game. An extended version of the latter can be\nplayed online at seesaw.neuro.uni-bremen.de.\n"
    },
    {
        "paper_id": 1303.211,
        "authors": "Sebastian M. Krause, Stefan Boerries, Stefan Bornholdt",
        "title": "Econophysics of adaptive power markets: When a market does not dampen\n  fluctuations but amplifies them",
        "comments": "5 pages, 5 figures",
        "journal-ref": "Phys. Rev. E 92, 012815 (2015)",
        "doi": "10.1103/PhysRevE.92.012815",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The average economic agent is often used to model the dynamics of simple\nmarkets, based on the assumption that the dynamics of many agents can be\naveraged over in time and space. A popular idea that is based on this seemingly\nintuitive notion is to dampen electric power fluctuations from fluctuating\nsources (as e.g. wind or solar) via a market mechanism, namely by variable\npower prices that adapt demand to supply. The standard model of an average\neconomic agent predicts that fluctuations are reduced by such an adaptive\npricing mechanism.\n  However, the underlying assumption that the actions of all agents average out\non the time axis is not always true in a market of many agents. We numerically\nstudy an econophysics agent model of an adaptive power market that does not\nassume averaging a priori. We find that when agents are exposed to source noise\nvia correlated price fluctuations (as adaptive pricing schemes suggest), the\nmarket may amplify those fluctuations. In particular, small price changes may\ntranslate to large load fluctuations through catastrophic consumer\nsynchronization. As a result, an adaptive power market may cause the opposite\neffect than intended: Power fluctuations are not dampened but amplified\ninstead.\n"
    },
    {
        "paper_id": 1303.2513,
        "authors": "R\\\"udiger Frey, Abdelali Gabih, Ralf Wunderlich",
        "title": "Portfolio Optimization under Partial Information with Expert Opinions: a\n  Dynamic Programming Approach",
        "comments": "31 pages",
        "journal-ref": "Communications on Stochastic Analysis , Vol. 8, No. 1, 49-79, 2014",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates optimal portfolio strategies in a market where the\ndrift is driven by an unobserved Markov chain. Information on the state of this\nchain is obtained from stock prices and expert opinions in the form of signals\nat random discrete time points. As in Frey et al. (2012), Int. J. Theor. Appl.\nFinance, 15, No. 1, we use stochastic filtering to transform the original\nproblem into an optimization problem under full information where the state\nvariable is the filter for the Markov chain. The dynamic programming equation\nfor this problem is studied with viscosity-solution techniques and with\nregularization arguments.\n"
    },
    {
        "paper_id": 1303.2901,
        "authors": "Nicola Pestalozzi, Peter Cauwels, and Didier Sornette",
        "title": "Dynamics and Spatial Distribution of Global Nighttime Lights",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using open source data, we observe the fascinating dynamics of nighttime\nlight. Following a global economic regime shift, the planetary center of light\ncan be seen moving eastwards at a pace of about 60 km per year. Introducing\nspatial light Gini coefficients, we find a universal pattern of human\nsettlements across different countries and see a global centralization of\nlight. Observing 160 different countries we document the expansion of\ndeveloping countries, the growth of new agglomerations, the regression in\ncountries suffering from demographic decline and the success of light pollution\nabatement programs in western countries.\n"
    },
    {
        "paper_id": 1303.291,
        "authors": "Gareth W.Peters and Rodrigo S. Targino and Pavel V. Shevchenko",
        "title": "Understanding Operational Risk Capital Approximations: First and Second\n  Orders",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We set the context for capital approximation within the framework of the\nBasel II / III regulatory capital accords. This is particularly topical as the\nBasel III accord is shortly due to take effect. In this regard, we provide a\nsummary of the role of capital adequacy in the new accord, highlighting along\nthe way the significant loss events that have been attributed to the\nOperational Risk class that was introduced in the Basel II and III accords.\nThen we provide a semi-tutorial discussion on the modelling aspects of capital\nestimation under a Loss Distributional Approach (LDA). Our emphasis is to focus\non the important loss processes with regard to those that contribute most to\ncapital, the so called high consequence, low frequency loss processes. This\nleads us to provide a tutorial overview of heavy tailed loss process modelling\nin OpRisk under Basel III, with discussion on the implications of such tail\nassumptions for the severity model in an LDA structure. This provides\npractitioners with a clear understanding of the features that they may wish to\nconsider when developing OpRisk severity models in practice. From this\ndiscussion on heavy tailed severity models, we then develop an understanding of\nthe impact such models have on the right tail asymptotics of the compound loss\nprocess and we provide detailed presentation of what are known as first and\nsecond order tail approximations for the resulting heavy tailed loss process.\nFrom this we develop a tutorial on three key families of risk measures and\ntheir equivalent second order asymptotic approximations: Value-at-Risk (Basel\nIII industry standard); Expected Shortfall (ES) and the Spectral Risk Measure.\nThese then form the capital approximations.\n"
    },
    {
        "paper_id": 1303.295,
        "authors": "Agostino Capponi, Jose Enrique Figueroa Lopez and Andrea Pascucci",
        "title": "Dynamic Credit Investment in Partially Observed Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of maximizing expected utility for a power investor\nwho can allocate his wealth in a stock, a defaultable security, and a money\nmarket account. The dynamics of these security prices are governed by geometric\nBrownian motions modulated by a hidden continuous time finite state Markov\nchain. We reduce the partially observed stochastic control problem to a\ncomplete observation risk sensitive control problem via the filtered regime\nswitching probabilities. We separate the latter into pre-default and\npost-default dynamic optimization subproblems, and obtain two coupled\nHamilton-Jacobi-Bellman (HJB) partial differential equations. We prove\nexistence and uniqueness of a globally bounded classical solution to each HJB\nequation, and give the corresponding verification theorem. We provide a\nnumerical analysis showing that the investor increases his holdings in stock as\nthe filter probability of being in high growth regimes increases, and decreases\nhis credit risk exposure when the filter probability of being in high default\nrisk regimes gets larger.\n"
    },
    {
        "paper_id": 1303.3133,
        "authors": "Shilei Wang",
        "title": "Dynamical Trading Mechanism in Limit Order Markets",
        "comments": "27 pages",
        "journal-ref": "Algorithm. Finance 2 (2013), no. 3-4, 213-231",
        "doi": "10.3233/AF-13027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work's purpose is to understand the dynamics of limit order books in\norder-driven markets. We try to illustrate a dynamical trading mechanism\nattached to the microstructure of limit order markets. We capture the iterative\nnature of trading processes, which is critical in the dynamics of bid-ask pairs\nand the switching laws between different traders' types and their orders. In\ngeneral, after introducing the atomic trading scheme, we study a general\niterated trading process in both combinatorial and stochastic ways, and state a\nfew results on the stability of a dynamical trading system. We also study the\ncontrolled dynamics of the spread and the mid-price in an iterated trading\nsystem, when their movements, generated from the dynamics of bid-ask pairs, are\nassumed to be restricted within some extremely small ranges.\n"
    },
    {
        "paper_id": 1303.3148,
        "authors": "Jan Kallsen, Johannes Muhle-Karbe",
        "title": "The General Structure of Optimal Investment and Consumption with Small\n  Transaction Costs",
        "comments": "39 pages, to appear in \"Mathematical Finance\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the general structure of optimal investment and consumption\nwith small proportional transaction costs. For a safe asset and a risky asset\nwith general continuous dynamics, traded with random and time-varying but small\ntransaction costs, we derive simple formal asymptotics for the optimal policy\nand welfare. These reveal the roles of the investors' preferences as well as\nthe market and cost dynamics, and also lead to a fully dynamic model for the\nimplied trading volume. In frictionless models that can be solved in closed\nform, explicit formulas for the leading-order corrections due to small\ntransaction costs are obtained.\n"
    },
    {
        "paper_id": 1303.3391,
        "authors": "Syed Muhammad Noaman Ahmed Shah and Mazen Kebewar",
        "title": "US Corporate Bond Yield Spread : A default risk debate",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  According to theoretical models of valuing risky corporate securities, risk\nof default is primary component in overall yield spread. However, sizable\nempirical literature considers it otherwise by giving more importance to\nnon-default risk factors. Current study empirically attempts to provide\nrelative solution to this conundrum by presuming that problem lies in the\nsubjective empirical treatment of default risk. By using post-hoc estimator\napproach of Lubotsky & Wittenberg (2006), we construct an efficient indicator\nfor risk of default, by using sample of 252 US non-financial corporate data\n(2000-2010). On average, our results validate that almost 48% of change in\nyield spread is explained by default risk especially in recent financial crisis\nperiod (2007-2009). Hence, our results relatively suggest that potential\nproblem lies in the ad-hoc measurement methods used in existing empirical\nliterature.\n"
    },
    {
        "paper_id": 1303.3693,
        "authors": "Aleksejus Kononovicius, Valentas Daniunas",
        "title": "Agent-based and macroscopic modeling of the complex socio-economic\n  systems",
        "comments": "12 pages, 6 figures",
        "journal-ref": "Social Technologies 3 (1): 85-103 (2013)",
        "doi": "10.13165/ST-13-3-1-06",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The current economic crisis has provoked an active response from the\ninterdisciplinary scientific community. As a result many papers suggesting what\ncan be improved in understanding of the complex socio-economics systems were\npublished. Some of the most prominent papers on the topic include (Bouchaud,\n2009; Farmer and Foley, 2009; Farmer et al, 2012; Helbing, 2010; Pietronero,\n2008). These papers share the idea that agent-based modeling is essential for\nthe better understanding of the complex socio-economic systems and consequently\nbetter policy making. Yet in order for an agent-based model to be useful it\nshould also be analytically tractable, possess a macroscopic treatment\n(Cristelli et al, 2012). In this work we shed a new light on our research\ngroup's contributions towards understanding of the correspondence between the\ninter-individual interactions and collective behavior. We also provide some new\ninsights into the implications of the global and local interactions, the\nleadership and the predator-prey interactions in the complex socio-economic\nsystems.\n"
    },
    {
        "paper_id": 1303.3956,
        "authors": "Masashi Ieda, Takashi Yamashita, Yumiharu Nakano",
        "title": "A liability tracking approach to long term management of pension funds",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a long term portfolio management method which takes into account a\nliability. Our approach is based on the LQG (Linear, Quadratic cost, Gaussian)\ncontrol problem framework and then the optimal portfolio strategy hedges the\nliability by directly tracking a benchmark process which represents the\nliability. Two numerical results using empirical data published by Japanese\norganizations are served: simulations tracking an artificial liability and an\nestimated liability of Japanese organization. The latter one demonstrates that\nour optimal portfolio strategy can hedge his or her liability.\n"
    },
    {
        "paper_id": 1303.4082,
        "authors": "{\\L}ukasz Delong and Antoon Pelsser",
        "title": "Instantaneous mean-variance hedging and instantaneous Sharpe ratio\n  pricing in a regime-switching financial model, with applications to\n  equity-linked claims",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study hedging and pricing of unattainable contingent claims in a\nnon-Markovian regime-switching financial model. Our financial market consists\nof a bank account and a risky asset whose dynamics are driven by a Brownian\nmotion and a multivariate counting process with stochastic intensities. The\ninterest rate, drift, volatility and intensities fluctuate over time and, in\nparticular, they depend on the state (regime) of the economy which is modelled\nby the multivariate counting process. Hence, we can allow for stressed market\nconditions. We assume that the trajectory of the risky asset is continuous\nbetween the transition times for the states of the economy and that the value\nof the risky asset jumps at the time of the transition. We find the hedging\nstrategy which minimizes the instantaneous mean-variance risk of the hedger's\nsurplus and we set the price so that the instantaneous Sharpe ratio of the\nhedger's surplus equals a predefined target. We use Backward Stochastic\nDifferential Equations. Interestingly, the instantaneous mean-variance hedging\nand instantaneous Sharpe ratio pricing can be related to no-good-deal pricing\nand robust pricing and hedging under model ambiguity. We discuss key properties\nof the optimal price and the optimal hedging strategy. We also use our results\nto price and hedge mortality-contingent claims with financial components\n(equity-linked insurance claims) in a combined insurance and regime-switching\nfinancial model.\n"
    },
    {
        "paper_id": 1303.4268,
        "authors": "Antoine Jacquier and Patrick Roome",
        "title": "The Small-Maturity Heston Forward Smile",
        "comments": "23 pages, 11 figures. Updated proof of Lemma 6.3",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we investigate the asymptotics of forward-start options and the\nforward implied volatility smile in the Heston model as the maturity approaches\nzero. We prove that the forward smile for out-of-the-money options explodes and\ncompute a closed-form high-order expansion detailing the rate of the explosion.\nFurthermore the result shows that the square-root behaviour of the variance\nprocess induces a singularity such that for certain parameter configurations\none cannot obtain high-order out-of-the-money forward smile asymptotics. In the\nat-the-money case a separate model-independent analysis shows that the\nsmall-maturity limit is well defined for any Ito diffusion. The proofs rely on\nthe theory of sharp large deviations (and refinements) and incidentally we\nprovide an example of degenerate large deviations behaviour.\n"
    },
    {
        "paper_id": 1303.4274,
        "authors": "Mingshang Hu and Shaolin Ji",
        "title": "A note on pricing of contingent claims under G-expectation",
        "comments": "15 pages. arXiv admin note: substantial text overlap with\n  arXiv:1212.5403, arXiv:1206.5889",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the pricing of contingent claims under G-expectation.\nIn order to accomodate volatility uncertainty, the price of the risky security\nis supposed to governed by a general linear stochastic differential equation\n(SDE) driven by G-Brownian motion. Utilizing the recently developed results of\nBackward SDE driven by G-Brownian motion, we obtain the superhedging and\nsuberhedging prices of a given contingent claim. Explicit results in the\nMarkovian case are also derived.\n"
    },
    {
        "paper_id": 1303.4314,
        "authors": "Matthew Ames, Guillaume Bagnarosa, Gareth W. Peters",
        "title": "Reinvestigating the Uncovered Interest Rate Parity Puzzle via Analysis\n  of Multivariate Tail Dependence in Currency Carry Trades",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The currency carry trade is the investment strategy that involves selling low\ninterest rate currencies in order to purchase higher interest rate currencies,\nthus profiting from the interest rate differentials. This is a well known\nfinancial puzzle to explain, since assuming foreign exchange risk is\nuninhibited and the markets have rational risk-neutral investors, then one\nwould not expect profits from such strategies. That is uncovered interest rate\nparity (UIP), the parity condition in which exposure to foreign exchange risk,\nwith unanticipated changes in exchange rates, should result in an outcome that\nchanges in the exchange rate should offset the potential to profit from such\ninterest rate differentials. The two primary assumptions required for interest\nrate parity are related to capital mobility and perfect substitutability of\ndomestic and foreign assets. Given foreign exchange market equilibrium, the\ninterest rate parity condition implies that the expected return on domestic\nassets will equal the exchange rate-adjusted expected return on foreign\ncurrency assets.\n  However, it has been shown empirically, that investors can actually earn\narbitrage profits by borrowing in a country with a lower interest rate,\nexchanging for foreign currency, and investing in a foreign country with a\nhigher interest rate, whilst allowing for any losses (or gains) from exchanging\nback to their domestic currency at maturity. Therefore trading strategies that\naim to exploit the interest rate differentials can be profitable on average.\nThe intention of this paper is therefore to reinterpret the currency carry\ntrade puzzle in light of heavy tailed marginal models coupled with multivariate\ntail dependence features in the analysis of the risk-reward for the currency\nportfolios with high interest rate differentials and low interest rate\ndifferentials.\n"
    },
    {
        "paper_id": 1303.4351,
        "authors": "A.E.Biondo, A.Pluchino, A.Rapisarda, D.Helbing",
        "title": "Are random trading strategies more successful than technical ones?",
        "comments": "17 pages, 9 figures",
        "journal-ref": "PLoS ONE 8(7): e68344 (2013)",
        "doi": "10.1371/journal.pone.0068344",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we explore the specific role of randomness in financial\nmarkets, inspired by the beneficial role of noise in many physical systems and\nin previous applications to complex socio- economic systems. After a short\nintroduction, we study the performance of some of the most used trading\nstrategies in predicting the dynamics of financial markets for different\ninternational stock exchange indexes, with the goal of comparing them with the\nperformance of a completely random strategy. In this respect, historical data\nfor FTSE-UK, FTSE-MIB, DAX, and S&P500 indexes are taken into account for a\nperiod of about 15-20 years (since their creation until today).\n"
    },
    {
        "paper_id": 1303.4514,
        "authors": "Diego Ardila, Peter Cauwels, Dorsa Sanadgol, and Didier Sornette",
        "title": "Is There A Real Estate Bubble in Switzerland?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have analyzed the risks of possible development of bubbles in the Swiss\nresidential real estate market. The data employed in this work has been\ncollected by comparis.ch, and carefully cleaned from duplicate records through\na procedure based on supervised machine learning methods. The study uses the\nlog periodic power law (LPPL) bubble model to analyze the development of asking\nprices of residential properties in all Swiss districts between 2005 and 2013.\nThe results suggest that there are 11 critical districts that exhibit\nsignatures of bubbles, and seven districts where bubbles have already burst.\nDespite these strong signatures, it is argued that, based on the current\neconomic environment, a soft landing rather than a severe crash is expected.\n"
    },
    {
        "paper_id": 1303.4607,
        "authors": "Satya N. Majumdar, Philippe Mounaix, Gregory Schehr",
        "title": "Exact Statistics of the Gap and Time Interval Between the First Two\n  Maxima of Random Walks",
        "comments": "5 pages, 3 figures",
        "journal-ref": "Phys. Rev. Lett. 111, 070601 (2013)",
        "doi": "10.1103/PhysRevLett.111.070601",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the statistics of the gap, G_n, between the two rightmost\npositions of a Markovian one-dimensional random walker (RW) after n time steps\nand of the duration, L_n, which separates the occurrence of these two extremal\npositions. The distribution of the jumps \\eta_i's of the RW, f(\\eta), is\nsymmetric and its Fourier transform has the small k behavior 1-\\hat{f}(k)\\sim|\nk|^\\mu with 0 < \\mu \\leq 2. We compute the joint probability density function\n(pdf) P_n(g,l) of G_n and L_n and show that, when n \\to \\infty, it approaches a\nlimiting pdf p(g,l). The corresponding marginal pdf of the gap, p_{\\rm gap}(g),\nis found to behave like p_{\\rm gap}(g) \\sim g^{-1 - \\mu} for g \\gg 1 and 0<\\mu\n< 2. We show that the limiting marginal distribution of L_n, p_{\\rm time}(l),\nhas an algebraic tail p_{\\rm time}(l) \\sim l^{-\\gamma(\\mu)} for l \\gg 1 with\n\\gamma(1<\\mu \\leq 2) = 1 + 1/\\mu, and \\gamma(0<\\mu<1) = 2. For l, g \\gg 1 with\nfixed l g^{-\\mu}, p(g,l) takes the scaling form p(g,l) \\sim g^{-1-2\\mu} \\tilde\np_\\mu(l g^{-\\mu}) where \\tilde p_\\mu(y) is a (\\mu-dependent) scaling function.\nWe also present numerical simulations which verify our analytic results.\n"
    },
    {
        "paper_id": 1303.4847,
        "authors": "Nikolai Dokuchaev",
        "title": "Two unconditionally implied parameters and volatility smiles and skews",
        "comments": "Sections 3-4 here was not included in the printed version; they were\n  added in 2013",
        "journal-ref": "Applied Financial Economics Letters 2006, V. 2, 199-204",
        "doi": "10.1080/17446540500426771",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper studies estimation of parameters of diffusion market models from\nhistorical data. The standard definition of implied volatility for these models\npresents its value as an implicit function of several parameters, including the\nrisk-free interest rate. In reality, the risk free interest rate is unknown and\nneed to be forecasted, because the option price depends on its future curve.\nTherefore, the standard implied volatility is {\\it conditional}: it depends on\nthe future values of the risk free rate. We study two implied parameters: the\nimplied volatility and the implied average cumulative risk free interest rate.\nThey can be found unconditionally from a system of two equations. We found that\nvery simple models with random volatilities (for instance, with two point\ndistributions) generate various volatility smiles and skews with this approach.\n"
    },
    {
        "paper_id": 1303.4849,
        "authors": "Ju-Gyong Kim, Il-Su Choe",
        "title": "A Solution to Kolmogorov-Feller Equation and Pricing of Options",
        "comments": "4 pages, Presented in International Symposium in Commemoration of the\n  65th Anniversary of the Foundation of Kim Il Sung University\n  (Mathematics)20-21. Sep. Juche100(2011), Pyongyang DPR Korea",
        "journal-ref": "International Symposium in Commemoration of the 65th Anniversary\n  of the Foundation of Kim Il Sung University (Mathematics)20-21. Sep.\n  Juche100(2011), Pyongyang DPR Korea, 111-114pp",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the solution to Kolmogorov-Feller equation and by using it provide\npricing formulas of well known some options under jump-diffusion model.\n"
    },
    {
        "paper_id": 1303.4867,
        "authors": "Song-Yon Kim and Mun-Chol Kim",
        "title": "The Identification of Thresholds and Time Delay in Self-Exciting\n  Threshold AR Model by Wavelet",
        "comments": "4 pages, presented in International Symposium in Commemoration of the\n  65th Anniversary of the Foundation of Kim Il Sung University (Mathematics),\n  20-21. Sep. Juche100(2011) Pyongyang DPR Korea, ver 2 corrected title and\n  some typos",
        "journal-ref": "International Symposium in Commemoration of the 65th Anniversary\n  of the Foundation of Kim Il Sung University (Mathematics), 20-21. Sep.\n  Juche100(2011) Pyongyang DPR Korea, 92-95pp",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we studied about the wavelet identification of the thresholds\nand time delay for more general case without the constraint that the time delay\nis smaller than the order of the model. Here we composed an empirical wavelet\nfrom the SETAR (Self-Exciting Threshold Autoregressive) model and identified\nthe thresholds and time delay in the model using it.\n"
    },
    {
        "paper_id": 1303.529,
        "authors": "Evangelos I. Gkanas, Vasso MagkouKriticou, Sofoklis S. Makridis,\n  Athanasios K. Stubos and Ioannis Bakouros",
        "title": "Nanotechnology and Innovation, Recent status and the strategic\n  implication for the formation of high tech clusters in Greece, in between a\n  global economic crisis",
        "comments": null,
        "journal-ref": "International Journal of Technology Innovations and Research,\n  Vol.2, 2013",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Nanotechnology is the first major worldwide research initiative of the 21st\ncentury and probably is the solution vector in the economic environment. Also,\ninnovation is widely recognized as a key factor in the economic development of\nnations, and is essential for the competitiveness of the industrial firms as\nwell. Policy and management of innovation are necessary in order to develop\ninnovation and it involves processes. It is essential to develop new methods\nfor nanotechnology development for better understanding of nanotechnology based\ninnovation. Nanotechnologies reveal commercialization processes, from start ups\nto large firms in collaboration with public sector research. In the current\npaper, a study in the present status of innovation in nanotechnology and the\naffection of global economic crisis in this section is made and also the\npotential of increase the innovation via the presence of clusters in a small\ncountry like Greece which is in the eye of tornado from the global crisis is\nstudied.\n"
    },
    {
        "paper_id": 1303.5552,
        "authors": "Paolo Tasca and Pavlin Mavrodiev and Frank Schweitzer",
        "title": "Quantifying the Impact of Leveraging and Diversification on Systemic\n  Risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Excessive leverage, i.e. the abuse of debt financing, is considered one of\nthe primary factors in the default of financial institutions. Systemic risk\nresults from correlations between individual default probabilities that cannot\nbe considered independent. Based on the structural framework by Merton (1974),\nwe discuss a model in which these correlations arise from overlaps in banks'\nportfolios. Portfolio diversification is used as a strategy to mitigate losses\nfrom investments in risky projects. We calculate an optimal level of\ndiversification that has to be reached for a given level of excessive leverage\nto still mitigate an increase in systemic risk. In our model, this optimal\ndiversification further depends on the market size and the market conditions\n(e.g. volatility). It allows to distinguish between a safe regime, in which\nexcessive leverage does not result in an increase of systemic risk, and a risky\nregime, in which excessive leverage cannot be mitigated leading to an increased\nsystemic risk. Our results are of relevance for financial regulators.\n"
    },
    {
        "paper_id": 1303.5703,
        "authors": "Bruce Abramson",
        "title": "ARCO1: An Application of Belief Networks to the Oil Market",
        "comments": "Appears in Proceedings of the Seventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1991)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Belief networks are a new, potentially important, class of knowledge-based\nmodels. ARCO1, currently under development at the Atlantic Richfield Company\n(ARCO) and the University of Southern California (USC), is the most advanced\nreported implementation of these models in a financial forecasting setting.\nARCO1's underlying belief network models the variables believed to have an\nimpact on the crude oil market. A pictorial market model-developed on a MAC II-\nfacilitates consensus among the members of the forecasting team. The system\nforecasts crude oil prices via Monte Carlo analyses of the network. Several\ndifferent models of the oil market have been developed; the system's ability to\nbe updated quickly highlights its flexibility.\n"
    },
    {
        "paper_id": 1303.5809,
        "authors": "Yingying Li, Zhiyuan Zhang and Xinghua Zheng",
        "title": "Volatility Inference in the Presence of Both Endogenous Time and\n  Microstructure Noise",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we consider the volatility inference in the presence of both\nmarket microstructure noise and endogenous time. Estimators of the integrated\nvolatility in such a setting are proposed, and their asymptotic properties are\nstudied. Our proposed estimator is compared with the existing popular\nvolatility estimators via numerical studies. The results show that our\nestimator can have substantially better performance when time endogeneity\nexists.\n"
    },
    {
        "paper_id": 1303.5882,
        "authors": "Harris V. Georgiou",
        "title": "Feedback models and stability analysis of three economic paradigms",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  In this paper, simple mathematical models from Control Theory are applied to\nthree very important economic paradigms, namely (a) minimum wages in\nself-regulating markets, (b) market-versus-true values and currency rates, and\n(c) government spending and taxation levels. Analytical solutions are provided\nin all three paradigms and some useful conclusions are drawn in terms of\nvariable analysis. This short study can be used as an example of how feedback\nmodels and stability analysis can be applied as a guideline of 'proofs' in the\ncontext of economic policies.\n"
    },
    {
        "paper_id": 1303.609,
        "authors": "Simon Bossoney",
        "title": "Volatility Swap Under the SABR Model",
        "comments": "10 pages. No figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The SABR model is shortly presented and the volatility swap explained. The\nfair value for a volatility swap is then computed using the usual theory in\nfinancial mathematics. An analytical solution using confluent hypergeometric\nfunctions is found. The solution is then verified using Rama Cont's functional\ncalculus.\n"
    },
    {
        "paper_id": 1303.6183,
        "authors": "Karl Svozil",
        "title": "Quantitative easing is an incomplete strategy that must be accompanied\n  by the nullification of debt",
        "comments": "8 pages, some revisions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Compound interest as well as inflation grows exponentially with time, whereas\nother means to repay debt grow polynomially. For this and other, mostly\npolitical, reasons, debt without inflation is unsustainable. We suggest a\ndiscontinuous way to eliminate debt by nullifying it. This scenario is\npreferable to current central bank strategies of quantitative easing because it\nallows the disposal of debt without hyperinflation or bloated balance sheets.\n"
    },
    {
        "paper_id": 1303.6192,
        "authors": "Muhammad Khan, Mazen Kebewar, Nikolay Nenovsky",
        "title": "Inflation Uncertainty, Output Growth Uncertainty and Macroeconomic\n  Performance: Comparing Alternative Exchange Rate Regimes in Eastern Europe",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the late 90's, after severe financial and economic crisis, accompanied by\ninflation and exchange rate instability, Eastern Europe emerged into two groups\nof countries with radically contrasting monetary regimes (Currency Boards and\nInflation targeting). The task of our study is to compare econometrically the\nperformance of these two regimes in terms of the relationship between\ninflation, output growth, nominal and real uncertainties from 2000 till now. In\nother words, we test the hypothesis of non-neutrality of monetary and exchange\nrate regimes with respect to these connections. In a whole, the empirical\nresults do not allow us to judge which monetary regime is more appropriate and\nreasonable to assume. EU enlargement is one of the possible explanations for\nthe numbing of the differences and the lack of coherence between the two\nregimes in terms of inflation, growth and their uncertainties\n"
    },
    {
        "paper_id": 1303.634,
        "authors": "Jos\\'e Fajardo",
        "title": "Barrier Options under L\\'evy Processes: a Simple Short-Cut",
        "comments": "http://ssrn.com/abstract=2239427",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present a very simple way to price a class of barrier\noptions when the underlying process is driven by a huge class of L\\'evy\nprocesses. To achieve our goal we assume that our market satisfies a symmetry\nproperty. In case of not satisfying that property some approximations can be\nobtained.\n"
    },
    {
        "paper_id": 1303.6569,
        "authors": "Bent Flyvbjerg, Nils Bruzelius, and Bert van Wee",
        "title": "Comparison of Capital Costs per Route-Kilometre in Urban Rail",
        "comments": null,
        "journal-ref": "European Journal of Transport and Infrastructure Research, vol. 8,\n  no. 1, March 2008, 17-30",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Because of the prominent position of urban rail in reducing urban\ntransport-related problems, such as congestion and air pollution, insights into\nthe costs of possible new urban rail projects is very relevant for those\ninvolved with cost estimations, policy makers, cost-benefit analysts, and other\ntarget groups. Knowledge of the differences in costs per kilometre, including\nexplanations of differences and their breakdowns is currently lacking in the\nliterature. This paper aims to provide a first stage insight into how cost per\nkilometre varies across urban rail projects. The methodology applied is a\nsimple cost comparison across projects where the data collected are comparable.\nWe conclude that capital costs per route-kilometre of urban rail vary highly\nbetween projects. Looking at European projects and excluding outliers, the\ntotal capital costs per route-kilometre (including stations and rolling stock)\nlie mainly between US$50-100 million (2002 prices). Including US projects, the\nrange is US$50-150 million. The main reasons for the high variation in the\nroute-kilometre costs are differences between projects as regards the ratio of\nunderground to above-ground construction, ground conditions, station spacing,\ntype of rolling stock, environmental and safety constraints and labour costs.\nWe warn, however, that the observations used to reach the conclusions are too\nfew to obtain results with statistical significance. Our results must therefore\nbe seen as a first step towards collecting more data so that a more succinct\nstatistical analysis can be conducted. Another conclusion is therefore that\nthis area has future research potential.\n"
    },
    {
        "paper_id": 1303.6571,
        "authors": "Bent Flyvbjerg",
        "title": "Survival of the Unfittest: Why the Worst Infrastructure Gets Built, And\n  What We Can Do about It",
        "comments": "arXiv admin note: text overlap with arXiv:1302.3642",
        "journal-ref": "Oxford Review of Economic Policy, vol. 25, no. 3, 2009",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The article first describes characteristics of major infrastructure projects.\nSecond, it documents a much neglected topic in economics: that ex ante\nestimates of costs and benefits are often very different from actual ex post\ncosts and benefits. For large infrastructure projects the consequence is cost\noverruns, benefit shortfalls, and the systematic underestimation of risks.\nThird, implications for cost-benefit analysis are described, including that\nsuch analysis is not to be trusted for major infrastructure projects. Fourth,\nthe article uncovers the causes of this state of affairs in terms of perverse\nincentives that encourage promoters to underestimate costs and overestimate\nbenefits in the business cases for their projects. But the projects that are\nmade to look best on paper are the projects that amass the highest cost\noverruns and benefit shortfalls in reality. The article depicts this situation\nas \"survival of the un-fittest.\" Fifth, the article sets out to explain how the\nproblem may be solved, with a view to arriving at more efficient and more\ndemocratic projects, and avoiding the scandals that often accompany major\ninfrastructure investments. Finally, the article identifies current trends in\nmajor infrastructure development. It is argued that a rapid increase in\nstimulus spending combined with more investments in emerging economies combined\nwith more spending on information technology is catapulting infrastructure\ninvestment from the frying pan into the fire.\n"
    },
    {
        "paper_id": 1303.6604,
        "authors": "Bent Flyvbjerg, Mette K. Skamris Holm, S{\\o}ren L. Buhl",
        "title": "Underestimating Costs in Public Works Projects: Error or Lie?",
        "comments": "40 pages",
        "journal-ref": "Bent Flyvbjerg, Mette K. Skamris Holm, S{\\o}ren L. Buhl,\n  \"Underestimating Costs in Public Works Projects: Error or Lie?\" Journal of\n  the American Planning Association, vol. 68, no. 3, Summer 2002, pp. 279-295",
        "doi": "10.1080/01944360208976273",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article presents results from the first statistically significant study\nof cost escalation in transportation infrastructure projects. Based on a sample\nof 258 transportation infrastructure projects worth US$90 billion and\nrepresenting different project types, geographical regions, and historical\nperiods, it is found with overwhelming statistical significance that the cost\nestimates used to decide whether such projects should be built are highly and\nsystematically misleading. Underestimation cannot be explained by error and is\nbest explained by strategic misrepresentation, that is, lying. The policy\nimplications are clear: legislators, administrators, investors, media\nrepresentatives, and members of the public who value honest numbers should not\ntrust cost estimates and cost-benefit analyses produced by project promoters\nand their analysts.\n"
    },
    {
        "paper_id": 1303.6654,
        "authors": "Bent Flyvbjerg, Mette Skamris Holm, and S{\\o}ren L. Buhl",
        "title": "How (In)accurate Are Demand Forecasts in Public Works Projects? The Case\n  of Transportation",
        "comments": "arXiv admin note: text overlap with arXiv:1302.2544, arXiv:1303.6571,\n  arXiv:1302.3642",
        "journal-ref": "Journal of the American Planning Association, vol. 71, no. 2,\n  Spring 2005, 131-146",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article presents results from the first statistically significant study\nof traffic forecasts in transportation infrastructure projects. The sample used\nis the largest of its kind, covering 210 projects in 14 nations worth US$59\nbillion. The study shows with very high statistical significance that\nforecasters generally do a poor job of estimating the demand for transportation\ninfrastructure projects. The result is substantial downside financial and\neconomic risks. Such risks are typically ignored or downplayed by planners and\ndecision makers, to the detriment of social and economic welfare. For nine out\nof ten rail projects passenger forecasts are overestimated; average\noverestimation is 106 percent. This results in large benefit shortfalls for\nrail projects. For half of all road projects the difference between actual and\nforecasted traffic is more than plus/minus 20 percent. Forecasts have not\nbecome more accurate over the 30-year period studied. If techniques and skills\nfor arriving at accurate demand forecasts have improved over time, as often\nclaimed by forecasters, this does not show in the data. The causes of\ninaccuracy in forecasts are different for rail and road projects, with\npolitical causes playing a larger role for rail than for road. The cure is\ntransparency, accountability, and new forecasting methods. The challenge is to\nchange the governance structures for forecasting and project development. The\narticle shows how planners may help achieve this.\n"
    },
    {
        "paper_id": 1303.7092,
        "authors": "Eric Gautier (CREST, ENSAE), Alexandre Tsybakov (CREST, ENSAE)",
        "title": "Pivotal estimation in high-dimensional regression via linear programming",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new method of estimation in high-dimensional linear regression\nmodel. It allows for very weak distributional assumptions including\nheteroscedasticity, and does not require the knowledge of the variance of\nrandom errors. The method is based on linear programming only, so that its\nnumerical implementation is faster than for previously known techniques using\nconic programs, and it allows one to deal with higher dimensional models. We\nprovide upper bounds for estimation and prediction errors of the proposed\nestimator showing that it achieves the same rate as in the more restrictive\nsituation of fixed design and i.i.d. Gaussian errors with known variance.\nFollowing Gautier and Tsybakov (2011), we obtain the results under weaker\nsensitivity assumptions than the restricted eigenvalue or assimilated\nconditions.\n"
    },
    {
        "paper_id": 1303.7177,
        "authors": "Pietro Fodra, Mauricio Labadie",
        "title": "High-frequency market-making for multi-dimensional Markov processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we complete and extend our previous work on stochastic control\napplied to high frequency market-making with inventory constraints and\ndirectional bets. Our new model admits several state variables (e.g. market\nspread, stochastic volatility and intensities of market orders) provided the\nfull system is Markov. The solution of the corresponding HJB equation is exact\nin the case of zero inventory risk. The inventory risk enters into play in two\nways: a path-dependent penalty based on the volatility and a penalty at expiry\nbased on the market spread. We perform perturbation methods on the inventory\nrisk parameter and obtain explicitly the solution and its controls up to first\norder. We also include transaction costs; we show that the spread of the\nmarket-maker is widened to compensate the transaction costs, but the expected\ngain per traded spread remains constant. We perform several numerical\nsimulations to assess the effect of the parameters on the PNL, showing in\nparticular how the directional bet and the inventory risk change the shape of\nthe PNL density. Finally, we extend our results to the case of multi-aset\nmarket-making strategies; we show that the correct notion of inventory risk is\nthe L2-norm of the (multi-dimensional) inventory with respect to the inventory\npenalties.\n"
    },
    {
        "paper_id": 1303.74,
        "authors": "Bent Flyvbjerg",
        "title": "Policy and Planning for Large Infrastructure Projects: Problems, Causes,\n  Cures",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1303.6571,\n  arXiv:1303.6654, arXiv:1303.6571, arXiv:1302.3642",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper argues, first, that a major problem in the planning of large\ninfrastructure projects is the high level of misinformation about costs and\nbenefits that decision makers face in deciding whether to build, and the high\nrisks such misinformation generates. Second, it explores the causes of\nmisinformation and risk, mainly in the guise of optimism bias and strategic\nmisrepresentation. Finally, the paper presents a number of measures aimed at\nimproving planning and decision making for large infrastructure projects,\nincluding changed incentive structures and better planning methods. Thus the\npaper is organized as a simple triptych consisting in problems, causes, and\ncures.\n"
    },
    {
        "paper_id": 1303.7401,
        "authors": "Bent Flyvbjerg",
        "title": "Measuring Inaccuracy in Travel Demand Forecasting: Methodological\n  Considerations Regarding Ramp Up and Sampling",
        "comments": null,
        "journal-ref": "Transportation Research A, vol. 39, no. 6, July 2005, 522-530",
        "doi": "10.1016/j.tra.2005.02.003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Project promoters, forecasters, and managers sometimes object to two things\nin measuring inaccuracy in travel demand forecasting: (1) using the forecast\nmade at the time of making the decision to build as the basis for measuring\ninaccuracy and (2) using traffic during the first year of operations as the\nbasis for measurement. This paper presents the case against both objections.\nFirst, if one is interested in learning whether decisions about building\ntransport infrastructure are based on reliable information, then it is exactly\nthe traffic forecasted at the time of making the decision to build that is of\ninterest. Second, although ideally studies should take into account so-called\ndemand \"ramp up\" over a period of years, the empirical evidence and practical\nconsiderations do not support this ideal requirement, at least not for large-N\nstudies. Finally, the paper argues that large samples of inaccuracy in travel\ndemand forecasts are likely to be conservatively biased, i.e., accuracy in\ntravel demand forecasts estimated from such samples would likely be higher than\naccuracy in travel demand forecasts in the project population. This bias must\nbe taken into account when interpreting the results from statistical analyses\nof inaccuracy in travel demand forecasting.\n"
    },
    {
        "paper_id": 1303.7402,
        "authors": "Bent Flyvbjerg",
        "title": "Cost Overruns and Demand Shortfalls in Urban Rail and Other\n  Infrastructure",
        "comments": null,
        "journal-ref": "Transportation Planning and Technology, vol. 30, no. 1, February\n  2007, 9-30",
        "doi": "10.1080/03081060701207938",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Risk, including economic risk, is increasingly a concern for public policy\nand management. The possibility of dealing effectively with risk is hampered,\nhowever, by lack of a sound empirical basis for risk assessment and management.\nThe paper demonstrates the general point for cost and demand risks in urban\nrail projects. The paper presents empirical evidence that allow valid economic\nrisk assessment and management of urban rail projects, including benchmarking\nof individual or groups of projects. Benchmarking of the Copenhagen Metro is\npresented as a case in point. The approach developed is proposed as a model for\nother types of policies and projects in order to improve economic and financial\nrisk assessment and management in policy and planning.\n"
    },
    {
        "paper_id": 1303.7403,
        "authors": "Bent Flyvbjerg, Massimo Garbuio, and Dan Lovallo",
        "title": "Delusion and Deception in Large Infrastructure Projects: Two Models for\n  Explaining and Preventing Executive Disaster",
        "comments": null,
        "journal-ref": "California Management Review, vol. 51, no. 2, Winter 2009, 170-193",
        "doi": "10.1225/CMR423",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Economist recently reported that infrastructure spending is the largest\nit is ever been as a share of world GDP. With $22 trillion in projected\ninvestments over the next ten years in emerging economies alone, the magazine\ncalls it the \"biggest investment boom in history.\" The efficiency of\ninfrastructure planning and execution is therefore particularly important at\npresent. Unfortunately, the private sector, the public sector and\nprivate/public sector partnerships have a dismal record of delivering on large\ninfrastructure cost and performance promises. This paper explains why and how\nto solve the problem.\n"
    },
    {
        "paper_id": 1303.7404,
        "authors": "Bent Flyvbjerg, Nils Bruzelius, and Werner Rothengatter",
        "title": "Megaprojects and Risk: An Anatomy of Ambition",
        "comments": "Cambridge University Press, 2003",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Back cover text: Megaprojects and Risk provides the first detailed\nexamination of the phenomenon of megaprojects. It is a fascinating account of\nhow the promoters of multibillion-dollar megaprojects systematically and\nself-servingly misinform parliaments, the public and the media in order to get\nprojects approved and built. It shows, in unusual depth, how the formula for\napproval is an unhealthy cocktail of underestimated costs, overestimated\nrevenues, undervalued environmental impacts and overvalued economic development\neffects. This results in projects that are extremely risky, but where the risk\nis concealed from MPs, taxpayers and investors. The authors not only explore\nthe problems but also suggest practical solutions drawing on theory and hard,\nscientific evidence from the several hundred projects in twenty nations that\nillustrate the book. Accessibly written, it will be essential reading in its\nfield for students, scholars, planners, economists, auditors, politicians,\njournalists and interested citizens.\n"
    },
    {
        "paper_id": 1303.7405,
        "authors": "Bent Flyvbjerg",
        "title": "How Planners Deal with Uncomfortable Knowledge: The Dubious Ethics of\n  the American Planning Association",
        "comments": "Flyvbjerg, Bent, 2013, \"How Planners Deal with Uncomfortable\n  Knowledge: The Dubious Ethics of the American Planning Association,\" Cities",
        "journal-ref": null,
        "doi": "10.1016/J.CITIES.2012.10.016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With a point of departure in the concept \"uncomfortable knowledge,\" this\narticle presents a case study of how the American Planning Association (APA)\ndeals with such knowledge. APA was found to actively suppress publicity of\nmalpractice concerns and bad planning in order to sustain a boosterish image of\nplanning. In the process, APA appeared to disregard and violate APA's own Code\nof Ethics. APA justified its actions with a need to protect APA members'\ninterests, seen as preventing planning and planners from being presented in\npublic in a bad light. The current article argues that it is in members'\ninterest to have malpractice critiqued and reduced, and that this best happens\nby exposing malpractice, not by denying or diverting attention from it as APA\ndid in this case. Professions, organizations, and societies that stifle\ncritique tend to degenerate and become socially and politically irrelevant\n\"zombie institutions.\" The article asks whether such degeneration has set in\nfor APA and planning. Finally, it is concluded that more debate about APA's\nethics and actions is needed for improving planning practice. Nine key\nquestions are presented to constructively stimulate such debate.\n"
    },
    {
        "paper_id": 1303.7445,
        "authors": "Saad Ahmad Khan, Ladislau Boloni",
        "title": "Agent-based modeling of a price information trading business",
        "comments": "Extended version of the paper published at Computer and Information\n  Sciences, Proc. of ISCIS-26, 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We describe an agent-based simulation of a fictional (but feasible)\ninformation trading business. The Gas Price Information Trader (GPIT) buys\ninformation about real-time gas prices in a metropolitan area from drivers and\nresells the information to drivers who need to refuel their vehicles.\n  Our simulation uses real world geographic data, lifestyle-dependent driving\npatterns and vehicle models to create an agent-based model of the drivers. We\nuse real world statistics of gas price fluctuation to create scenarios of\ntemporal and spatial distribution of gas prices. The price of the information\nis determined on a case-by-case basis through a simple negotiation model. The\ntrader and the customers are adapting their negotiation strategies based on\ntheir historical profits.\n  We are interested in the general properties of the emerging information\nmarket: the amount of realizable profit and its distribution between the trader\nand customers, the business strategies necessary to keep the market operational\n(such as promotional deals), the price elasticity of demand and the impact of\npricing strategies on the profit.\n"
    },
    {
        "paper_id": 1304.0212,
        "authors": "Michal Brzezinski",
        "title": "Do wealth distributions follow power laws? Evidence from \"rich lists\"",
        "comments": "17 pages, 6 figures, 1 table, 1 appendix",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2014.03.052",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use data on wealth of the richest persons taken from the \"rich lists\"\nprovided by business magazines like Forbes to verify if upper tails of wealth\ndistributions follow, as often claimed, a power-law behaviour. The data sets\nused cover the world's richest persons over 1996-2012, the richest Americans\nover 1988-2012, the richest Chinese over 2006-2012 and the richest Russians\nover 2004-2011. Using a recently introduced comprehensive empirical methodology\nfor detecting power laws, which allows for testing goodness of fit as well as\nfor comparing the power-law model with rival distributions, we find that a\npower-law model is consistent with data only in 35% of the analysed data sets.\nMoreover, even if wealth data are consistent with the power-law model, usually\nthey are also consistent with some rivals like the log-normal or stretched\nexponential distributions.\n"
    },
    {
        "paper_id": 1304.0265,
        "authors": "Bent Flyvbjerg and Alexander Budzier",
        "title": "Why Your IT Project Might Be Riskier Than You Think",
        "comments": null,
        "journal-ref": "Harvard Business Review, Vol. 89 (2011), No. 9, pp. 23-25",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Out-of-control information technology (IT) projects have ended the careers of\ntop managers, such as EADS CEO Noel Forgeard and Levi Strauss' CIO David\nBergen. Moreover, IT projects have brought down whole companies, like Kmart in\nthe US and Auto Windscreen in the UK. Software and other IT is now such an\nintegral part of most business processes and products that CEOs must know their\nIT risks, which are typically substantial and overlooked. The analysis of a\nsample of 1,471 IT projects showed that the average cost overrun was 27% - but\nthat figure masks a far more alarming 'fat tail' risk. Fully one in six of the\nprojects in the sample was a Black Swan, with a cost overrun of 200%, on\naverage, and a schedule overrun of almost 70%. This highlights the true pitfall\nof IT change initiatives: It's not that they're particularly prone to high cost\noverruns on average - it is that there are a disproportionate number of Black\nSwans. By focusing on averages instead of the more damaging outliers, most\nmanagers and consultants have been missing the real risk in doing IT. In\nconclusion, the article outlines ideas as to what can be done to avoid Black\nSwans.\n"
    },
    {
        "paper_id": 1304.0353,
        "authors": "Galen Sher, Pedro Vitoria",
        "title": "An Information-Theoretic Test for Dependence with an Application to the\n  Temporal Structure of Stock Returns",
        "comments": "22 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Information theory provides ideas for conceptualising information and\nmeasuring relationships between objects. It has found wide application in the\nsciences, but economics and finance have made surprisingly little use of it. We\nshow that time series data can usefully be studied as information -- by noting\nthe relationship between statistical redundancy and dependence, we are able to\nuse the results of information theory to construct a test for joint dependence\nof random variables. The test is in the same spirit of those developed by\nRyabko and Astola (2005, 2006b,a), but differs from these in that we add extra\nrandomness to the original stochatic process. It uses data compression to\nestimate the entropy rate of a stochastic process, which allows it to measure\ndependence among sets of random variables, as opposed to the existing\neconometric literature that uses entropy and finds itself restricted to\npairwise tests of dependence. We show how serial dependence may be detected in\nS&P500 and PSI20 stock returns over different sample periods and frequencies.\nWe apply the test to synthetic data to judge its ability to recover known\ntemporal dependence structures.\n"
    },
    {
        "paper_id": 1304.0368,
        "authors": "Jan Ob{\\l}\\'oj and Peter Spoida",
        "title": "An Iterated Az\\'{e}ma-Yor Type Embedding for Finitely Many Marginals",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We solve the $n$-marginal Skorokhod embedding problem for a continuous local\nmartingale and a sequence of probability measures $\\mu_1,...,\\mu_n$ which are\nin convex order and satisfy an additional technical assumption. Our\nconstruction is explicit and is a multiple marginal generalisation of the Azema\nand Yor (1979) solution. In particular, we recover the stopping boundaries\nobtained by Brown et al. (2001) and Madan and Yor (2002). Our technical\nassumption is necessary for the explicit embedding, as demonstrated with a\ncounterexample. We discuss extensions to the general case giving details when\n$n=3$.\n  In our analysis we compute the law of the maximum at each of the n stopping\ntimes. This is used in Henry-Labordere et al. (2013) to show that the\nconstruction maximises the distribution of the maximum among all solutions to\nthe $n$-marginal Skorokhod embedding problem. The result has direct\nimplications for robust pricing and hedging of Lookback options.\n"
    },
    {
        "paper_id": 1304.049,
        "authors": "Alois Pichler",
        "title": "Premiums And Reserves, Adjusted By Distortions",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1209.3570",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The net-premium principle is considered to be the most genuine and fair\npremium principle in actuarial applications. However, an insurance company,\napplying the net-premium principle, goes bankrupt with probability one in the\nlong run, even if the company covers its entire costs by collecting the\nrespective fees from its customers. It is therefore an intrinsic necessity for\nthe insurance industry to apply premium principles, which guarantee at least\nfurther existence of the company itself; otherwise, the company naturally could\nnot insure its clients to cover their potential, future claims. Beside this\nintriguing fact the underlying loss distribution typically is not known\nprecisely. Hence alternative premium principles have been developed. A simple\nprinciple, ensuring risk-adjusted credibility premiums, is the distorted\npremium principle. This principle is convenient in insurance companies, as the\nactuary does not have to change his or her tools to compute the premiums or\nreserves. This paper addresses the distorted premium principle from various\nangles. First, dual characterizations are developed. Next, distorted premiums\nare typically computed by under-weighting or ignoring low, but over-weighting\nhigh losses. It is demonstrated here that there is an alternative, opposite\npoint of view, which consists in leaving the probability measure unchanged, but\nincreasing the outcomes instead. It turns out that this new point of view is\nnatural in actuarial practice, as it can be used for premium calculations, as\nwell as to determine the reserves of subsequent years in a time consistent way.\n"
    },
    {
        "paper_id": 1304.0718,
        "authors": "Ben Klemens",
        "title": "A Peer-based Model of Fat-tailed Outcomes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/publicdomain/",
        "abstract": "  It is well known that the distribution of returns from various financial\ninstruments are leptokurtic, meaning that the distributions have \"fatter tails\"\nthan a Normal distribution, and have skew toward zero. This paper presents a\ngraceful micro-level explanation for such fat-tailed outcomes, using agents\nwhose private valuations have Normally-distributed errors, but whose utility\nfunction includes a term for the percentage of others who also buy.\n"
    },
    {
        "paper_id": 1304.0923,
        "authors": "Claudio Fontana, Zorana Grbac, Monique Jeanblanc and Qinghua Li",
        "title": "Information, no-arbitrage and completeness for asset price models with a\n  change point",
        "comments": "21 pages",
        "journal-ref": "Stochastic Processes and their Applications, 2014, 124, 3009-3030",
        "doi": "10.1016/j.spa.2014.04.010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a general class of continuous asset price models where the drift\nand the volatility functions, as well as the driving Brownian motions, change\nat a random time $\\tau$. Under minimal assumptions on the random time and on\nthe driving Brownian motions, we study the behavior of the model in all the\nfiltrations which naturally arise in this setting, establishing martingale\nrepresentation results and characterizing the validity of the NA1 and NFLVR\nno-arbitrage conditions.\n"
    },
    {
        "paper_id": 1304.1186,
        "authors": "Bent Flyvbjerg",
        "title": "Five Misunderstandings About Case-Study Research",
        "comments": null,
        "journal-ref": "Qualitative Inquiry, vol. 12, no. 2, April 2006, 219-245",
        "doi": "10.1177/1077800405284363",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article examines five common misunderstandings about case-study\nresearch: (1) Theoretical knowledge is more valuable than practical knowledge;\n(2) One cannot generalize from a single case, therefore the single case study\ncannot contribute to scientific development; (3) The case study is most useful\nfor generating hypotheses, while other methods are more suitable for hypotheses\ntesting and theory building; (4) The case study contains a bias toward\nverification; and (5) It is often difficult to summarize specific case studies.\nThe article explains and corrects these misunderstandings one by one and\nconcludes with the Kuhnian insight that a scientific discipline without a large\nnumber of thoroughly executed case studies is a discipline without systematic\nproduction of exemplars, and that a discipline without exemplars is an\nineffective one. Social science may be strengthened by the execution of more\ngood case studies.\n"
    },
    {
        "paper_id": 1304.1397,
        "authors": "Andrea Pallavicini and Damiano Brigo",
        "title": "Interest-Rate Modelling in Collateralized Markets: Multiple curves,\n  credit-liquidity effects, CCPs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The market practice of extrapolating different term structures from different\ninstruments lacks a rigorous justification in terms of cash flows structure and\nmarket observables. In this paper, we integrate our previous consistent theory\nfor pricing under credit, collateral and funding risks into term structure\nmodelling, integrating the origination of different term structures with such\neffects. Under a number of assumptions on collateralization, wrong-way risk,\ngap risk, credit valuation adjustments and funding effects, including the\ntreasury operational model, and via an immersion hypothesis, we are able to\nderive a synthetic master equation for the multiple term structure dynamics\nthat integrates multiple curves with credit/funding adjustments.\n"
    },
    {
        "paper_id": 1304.142,
        "authors": "Konstantinos Spiliopoulos, Justin A. Sirignano, Kay Giesecke",
        "title": "Fluctuation Analysis for the Loss From Default",
        "comments": null,
        "journal-ref": "Stochastic Processes and their Applications, Volume 124, Issue 7,\n  2014, pp. 2322-2362",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the fluctuation of the loss from default around its large\nportfolio limit in a class of reduced-form models of correlated firm-by-firm\ndefault timing. We prove a weak convergence result for the fluctuation process\nand use it for developing a conditionally Gaussian approximation to the loss\ndistribution. Numerical results illustrate the accuracy and computational\nefficiency of the approximation.\n"
    },
    {
        "paper_id": 1304.1665,
        "authors": "Bent Flyvbjerg",
        "title": "Why Mass Media Matter to Planning Research: The Case of Megaprojects",
        "comments": null,
        "journal-ref": "Journal of Planning Education and Research, vol. 32, no. 2, June\n  2012, 169-181",
        "doi": "10.1177/0739456X12441950",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article asks how planning scholarship may effectively gain impact in\nplanning practice through media exposure. In liberal democracies the public\nsphere is dominated by mass media. Therefore, working with such media is a\nprerequisite for effective public impact of planning research. Using the\nexample of megaproject planning, it is illustrated how so-called \"phronetic\nplanning research,\" which explicitly incorporates in its methodology active and\nstrategic collaboration with media, may be helpful in generating change in\nplanning practice via the public sphere. Main lessons learned are: (1) Working\nwith mass media is an extremely cost-effective way to increase the impact of\nplanning scholarship on practice; (2) Recent developments in information\ntechnology and social media have made impact via mass media even more\neffective; (3) Research on \"tension points,\" i.e., points of potential\nconflict, are particularly interesting to media and the public, and are\nespecially likely to generate change in practice; and (4) Tension points bite\nback; planning researchers should be prepared for, but not afraid of, this.\n"
    },
    {
        "paper_id": 1304.1783,
        "authors": "Cody Blaine Hyndman and Polynice Oyono Ngou",
        "title": "A convolution method for numerical solution of backward stochastic\n  differential equations",
        "comments": "29 pages, 4 figures; Revised (Version 3): Editorial changes;\n  Additional references; Section 2: Removed derivation of implicit Euler\n  scheme; Section 3: Further details on numerical implementation and algorithm;\n  Section 4: Improved Error Analysis by adding new Theorem 4.2 on stability and\n  convergence; Section 6: improved discussion of examples and numerical results",
        "journal-ref": null,
        "doi": "10.1007/s11009-015-9449-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new method for the numerical solution of backward stochastic\ndifferential equations (BSDEs) which finds its roots in Fourier analysis. The\nmethod consists of an Euler time discretization of the BSDE with certain\nconditional expectations expressed in terms of Fourier transforms and computed\nusing the fast Fourier transform (FFT). The problem of error control is\naddressed and a local error analysis is provided. We consider the extension of\nthe method to forward-backward stochastic differential equations (FBSDEs) and\nreflected FBSDEs. Numerical examples are considered from finance demonstrating\nthe performance of the method.\n"
    },
    {
        "paper_id": 1304.1821,
        "authors": "H. Huang, M.A. Milevsky, and T.S. Salisbury",
        "title": "Optimal initiation of a GLWB in a variable annuity: no arbitrage\n  approach",
        "comments": null,
        "journal-ref": "Insurance Math. Econom. 56 (2014), 102-111",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper offers a financial economic perspective on the optimal time (and\nage) at which the owner of a Variable Annuity (VA) policy with a Guaranteed\nLiving Withdrawal Benefit (GLWB) rider should initiate guaranteed lifetime\nincome payments. We abstract from utility, bequest and consumption preference\nissues by treating the VA as liquid and tradable. This allows us to use an\nAmerican option pricing framework to derive a so-called optimal initiation\nregion. Our main practical finding is that given current design parameters in\nwhich volatility (asset allocation) is restricted to less than 20%, while\nguaranteed payout rates (GPR) as well as bonus (roll-up) rates are less than\n5%, GLWBs that are in-the-money should be turned on by the late 50s and\ncertainly the early 60s. The exception to the rule is when a non-constant GPR\nis about to increase (soon) to a higher age band, in which case the optimal\npolicy is to wait until the new GPR is hit and then initiate immediately. Also,\nto offer a different perspective, we invert the model and solve for the bonus\n(roll-up) rate that is required to justify delaying initiation at any age. We\nfind that the required bonus is quite high and more than what is currently\npromised by existing products. Our methodology and results should be of\ninterest to researchers as well as to the individuals that collectively have\nover \\$1 USD trillion in aggregate invested in these products. We conclude by\nsuggesting that much of the non-initiation at older age is irrational (which\nobviously benefits the insurance industry.)\n"
    },
    {
        "paper_id": 1304.1849,
        "authors": "Matthew Lorig, Stefano Pagliarani, Andrea Pascucci",
        "title": "Pricing approximations and error estimates for local L\\'evy-type models\n  with default",
        "comments": "36 pages, 4 figures, 1 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We find approximate solutions of partial integro-differential equations,\nwhich arise in financial models when defaultable assets are described by\ngeneral scalar L\\'evy-type stochastic processes. We derive rigorous error\nbounds for the approximate solutions. We also provide numerical examples\nillustrating the usefulness and versatility of our methods in a variety of\nfinancial settings.\n"
    },
    {
        "paper_id": 1304.194,
        "authors": "Lingjiong Zhu",
        "title": "Ruin Probabilities for Risk Processes with Non-Stationary Arrivals and\n  Subexponential Claims",
        "comments": "15 pages",
        "journal-ref": "Insurance: Mathematics and Economics 2013, Volume 53, Issue 3,\n  544-550",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we obtain the finite-horizon and infinite-horizon ruin\nprobability asymptotics for risk processes with claims of subexponential tails\nfor non-stationary arrival processes that satisfy a large deviation principle.\nAs a result, the arrival process can be dependent, non-stationary and\nnon-renewal. We give three examples of non-stationary and non-renewal point\nprocesses: Hawkes process, Cox process with shot noise intensity and\nself-correcting point process. We also show some aggregate claims results for\nthese three examples.\n"
    },
    {
        "paper_id": 1304.1999,
        "authors": "Saul D. Jacka, Aleksandar Mijatovic, and Dejan Siraj",
        "title": "Mirror and Synchronous Couplings of Geometric Brownian Motions",
        "comments": "15 pages, introduction extended, details added to the proof of\n  Theorem 9, this version to appear in SPA",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper studies the question of whether the classical mirror and\nsynchronous couplings of two Brownian motions minimise and maximise,\nrespectively, the coupling time of the corresponding geometric Brownian\nmotions. We establish a characterisation of the optimality of the two couplings\nover any finite time horizon and show that, unlike in the case of Brownian\nmotion, the optimality fails in general even if the geometric Brownian motions\nare martingales. On the other hand, we prove that in the cases of the ergodic\naverage and the infinite time horizon criteria, the mirror coupling and the\nsynchronous coupling are always optimal for general (possibly non-martingale)\ngeometric Brownian motions. We show that the two couplings are efficient if and\nonly if they are optimal over a finite time horizon and give a conjectural\nanswer for the efficient couplings when they are suboptimal.\n"
    },
    {
        "paper_id": 1304.2069,
        "authors": "Christina Erlwein and Peter Ruckdeschel",
        "title": "Robustification of Elliott's on-line EM algorithm for HMMs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we establish a robustification of an on-line algorithm for\nmodelling asset prices within a hidden Markov model (HMM). In this HMM\nframework, parameters of the model are guided by a Markov chain in discrete\ntime, parameters of the asset returns are therefore able to switch between\ndifferent regimes. The parameters are estimated through an on-line algorithm,\nwhich utilizes incoming information from the market and leads to adaptive\noptimal estimates. We robustify this algorithm step by step against additive\noutliers appearing in the observed asset prices with the rationale to better\nhandle possible peaks or missings in asset returns.\n"
    },
    {
        "paper_id": 1304.2141,
        "authors": "David Hobson and Martin Klimmek",
        "title": "Robust price bounds for the forward starting straddle",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we consider the problem of giving a robust,\nmodel-independent, lower bound on the price of a forward starting straddle with\npayoff $|F_{T_1} - F_{T_0}|$ where $0<T_0<T_1$. Rather than assuming a model\nfor the underlying forward price $(F_t)_{t \\geq 0}$, we assume that call prices\nfor maturities $T_0<T_1$ are given and hence that the marginal laws of the\nunderlying are known. The primal problem is to find the model which is\nconsistent with the observed call prices, and for which the price of the\nforward starting straddle is minimised. The dual problem is to find the\ncheapest semi-static subhedge.\n  Under an assumption on the supports of the marginal laws, but no assumption\nthat the laws are atom-free or in any other way regular, we derive explicit\nexpressions for the coupling which minimises the price of the option, and the\nform of the semi-static subhedge.\n"
    },
    {
        "paper_id": 1304.2942,
        "authors": "Damiano Brigo, Giuseppe Di Graziano",
        "title": "Optimal execution comparison across risks and dynamics, with solutions\n  for displaced diffusions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We solve a version of the optimal trade execution problem when the mid asset\nprice follows a displaced diffusion. Optimal strategies in the adapted class\nunder various risk criteria, namely value-at-risk, expected shortfall and a new\ncriterion called \"squared asset expectation\" (SAE), related to a version of the\ncost variance measure, are derived and compared. It is well known that\ndisplaced diffusions (DD) exhibit dynamics which are in-between arithmetic\nBrownian motions (ABM) and geometric Brownian motions (GBM) depending of the\nchoice of the shift parameter. Furthermore, DD allows for changes in the\nsupport of the mid asset price distribution, allowing one to include a minimum\npermitted value for the mid price, either positive or negative. We study the\ndependence of the optimal solution on the choice of the risk aversion\ncriterion. Optimal solutions across criteria and asset dynamics are comparable\nalthough differences are not negligible for high levels of risk aversion and\nlow market impact assets. This is illustrated with numerical examples.\n"
    },
    {
        "paper_id": 1304.3135,
        "authors": "Jinzhong Niu and Simon Parsons",
        "title": "Maximizing Matching in Double-sided Auctions",
        "comments": "16 pages, 4 figures, full-length version of an extended abstract\n  published at the AAMAS 2013 conference",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we introduce a novel, non-recursive, maximal matching\nalgorithm for double auctions, which aims to maximize the amount of commodities\nto be traded. It differs from the usual equilibrium matching, which clears a\nmarket at the equilibrium price. We compare the two algorithms through\nexperimental analyses, showing that the maximal matching algorithm is favored\nin scenarios where trading volume is a priority and that it may possibly\nimprove allocative efficiency over equilibrium matching as well. A\nparameterized algorithm that incorporates both maximal matching and equilibrium\nmatching as special cases is also presented to allow flexible control on how\nmuch to trade in a double auction.\n"
    },
    {
        "paper_id": 1304.3159,
        "authors": "Andrey Itkin",
        "title": "Efficient Solution of Backward Jump-Diffusion PIDEs with Splitting and\n  Matrix Exponentials",
        "comments": "29 pages, 3 figures, 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new, unified approach to solving jump-diffusion partial\nintegro-differential equations (PIDEs) that often appear in mathematical\nfinance. Our method consists of the following steps. First, a second-order\noperator splitting on financial processes (diffusion and jumps) is applied to\nthese PIDEs. To solve the diffusion equation, we use standard finite-difference\nmethods, which for multi-dimensional problems could also include splitting on\nvarious dimensions. For the jump part, we transform the jump integral into a\npseudo-differential operator. Then for various jump models we show how to\nconstruct an appropriate first and second order approximation on a grid which\nsupersets the grid that we used for the diffusion part. These approximations\nmake the scheme to be unconditionally stable in time and preserve positivity of\nthe solution which is computed either via a matrix exponential, or via P{\\'a}de\napproximation of the matrix exponent. Various numerical experiments are\nprovided to justify these results.\n"
    },
    {
        "paper_id": 1304.3252,
        "authors": "Tiziano Squartini, Diego Garlaschelli",
        "title": "Jan Tinbergen's legacy for economic networks: from the gravity model to\n  quantum statistics",
        "comments": "26 pages, 7 figures",
        "journal-ref": "in Econophysics of Agent-Based Models (series: New Economic\n  Windows 8/2014), chapter 9, pp. 161-186, Springer (edited by F. Abergel, H.\n  Ayoama, B. K. Chakrabarti, A. Chakraborti and A. Gosh) (2014)",
        "doi": "10.1007/978-3-319-00023-7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Jan Tinbergen, the first recipient of the Nobel Memorial Prize in Economics\nin 1969, obtained his PhD in physics at the University of Leiden under the\nsupervision of Paul Ehrenfest in 1929. Among many achievements as an economist\nafter his training as a physicist, Tinbergen proposed the so-called Gravity\nModel of international trade. The model predicts that the intensity of trade\nbetween two countries is described by a formula similar to Newton's law of\ngravitation, where mass is replaced by Gross Domestic Product. Since\nTinbergen's proposal, the Gravity Model has become the standard model of\nnon-zero trade flows in macroeconomics. However, its intrinsic limitation is\nthe prediction of a completely connected network, which fails to explain the\nobserved intricate topology of international trade. Recent network models\novercome this limitation by describing the real network as a member of a\nmaximum-entropy statistical ensemble. The resulting expressions are formally\nanalogous to quantum statistics: the international trade network is found to\nclosely follow the Fermi-Dirac statistics in its purely binary topology, and\nthe recently proposed mixed Bose-Fermi statistics in its full (binary plus\nweighted) structure. This seemingly esoteric result is actually a simple effect\nof the heterogeneity of world countries, that imposes strong structural\nconstraints on the network. Our discussion highlights similarities and\ndifferences between macroeconomics and statistical-physics approaches to\neconomic networks.\n"
    },
    {
        "paper_id": 1304.3284,
        "authors": "Dmitry Kramkov",
        "title": "Existence and uniqueness of Arrow-Debreu equilibria with consumptions in\n  $\\mathbf{L}^0_+$",
        "comments": "12 pages; a few typos were corrected and additional explanations were\n  provided; submitted",
        "journal-ref": "Theory of Probability and Its Applications, Vol 60, No 4, 2016,\n  pp. 688-695",
        "doi": "10.1137/S0040585X97T987958",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an economy where agents' consumption sets are given by the cone\n$\\mathbf{L}^0_+$ of non-negative measurable functions and whose preferences are\ndefined by additive utilities satisfying the Inada conditions. We extend to\nthis setting the results in \\citet{Dana:93} on the existence and uniqueness of\nArrow-Debreu equilibria. In the case of existence, our conditions are necessary\nand sufficient.\n"
    },
    {
        "paper_id": 1304.335,
        "authors": "Marta Tomczak, Anna Ziolkowska, Martyna Rosik",
        "title": "Return on net sales from three companies in the manufacturing of\n  fabricated metal products (except machinery and equipment)",
        "comments": "10 pages A4",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Keywords: corporate finance, Wroc{\\l}aw University of Economics, net profit\nmargin lub net sales profitability\n"
    },
    {
        "paper_id": 1304.3516,
        "authors": "Dmitry Kramkov",
        "title": "Existence of an endogenously complete equilibrium driven by a diffusion",
        "comments": "minor changes to make it identical to the version accepted by Finance\n  and Stochastics",
        "journal-ref": "Finance and Stochastics January 2015, Volume 19, Issue 1, pp 1-22",
        "doi": "10.1007/s00780-014-0250-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The existence of complete Radner equilibria is established in an economy\nwhich parameters are driven by a diffusion process. Our results complement\nthose in the literature. In particular, we work under essentially minimal\nregularity conditions and treat time-inhomogeneous case.\n"
    },
    {
        "paper_id": 1304.3574,
        "authors": "Yan Dolinsky",
        "title": "Hedging of Game Options under Model Uncertainty in Discrete Time",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a setup of model uncertainty in discrete time. In this setup we\nderive dual expressions for the super--replication prices of game options with\nupper semicontinuous payoffs. We show that the super--replication price is\nequal to the supremum over a special (non dominated) set of martingale\nmeasures, of the corresponding Dynkin games values. This type of results is\nalso new for American options.\n"
    },
    {
        "paper_id": 1304.3602,
        "authors": "J.-F. Mercure",
        "title": "An age structured demographic theory of technological change",
        "comments": "24 pages, 5 figures, 2014",
        "journal-ref": "Journal of Evolutionary Economics (2015) 25:787-820",
        "doi": "10.1007/s00191-015-0413-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  At the heart of technology transitions lie complex processes of social and\nindustrial dynamics. The quantitative study of sustainability transitions\nrequires modelling work, which necessitates a theory of technology\nsubstitution. Many, if not most, contemporary modelling approaches for future\ntechnology pathways overlook most aspects of transitions theory, for instance\ndimensions of heterogenous investor choices, dynamic rates of diffusion and the\nprofile of transitions. A significant body of literature however exists that\ndemonstrates how transitions follow S-shaped diffusion curves or Lotka-Volterra\nsystems of equations. This framework is used ex-post since timescales can only\nbe reliably obtained in cases where the transitions have already occurred,\nprecluding its use for studying cases of interest where nascent innovations in\nprotective niches await favourable conditions for their diffusion. In\nprinciple, scaling parameters of transitions can, however, be derived from\nknowledge of industrial dynamics, technology turnover rates and technology\ncharacteristics. In this context, this paper presents a theory framework for\nevaluating the parameterisation of S-shaped diffusion curves for use in\nsimulation models of technology transitions without the involvement of\nhistorical data fitting, making use of standard demography theory applied to\ntechnology at the unit level. The classic Lotka-Volterra competition system\nemerges from first principles from demography theory, its timescales explained\nin terms of technology lifetimes and industrial dynamics. The theory is placed\nin the context of the multi-level perspective on technology transitions, where\ninnovation and the diffusion of new socio-technical regimes take a prominent\nplace, as well as discrete choice theory, the primary theoretical framework for\nintroducing agent diversity.\n"
    },
    {
        "paper_id": 1304.3722,
        "authors": "Krzysztof Sokalski",
        "title": "Hierarchy of Frustrations as Supplementary Indices in Complex System\n  Dynamics, Applied to the U.S. Intermarket",
        "comments": "10 pages 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  Definition of frustration is expressed by transitivity of binary entanglement\nrelation in considered complex system. Extending this definition into n-ary\nrelation a hierarchy of frustrations is derived. As a complex system the U.S.\nIntermarket is chosen where the correlation coefficient of intermarket sectors\nplays the role of entanglement measure. In each hierarchy level the frustration\nand the transitivity are interpreted as values of an order of measure for\ncorresponding subsystem. The derived theory is applied to 1983-2012 data of the\nU.S. Intermarket.\n"
    },
    {
        "paper_id": 1304.3814,
        "authors": "Hongwei Chuang, Hwai-Chung Ho",
        "title": "Measuring the default risk of sovereign debt from the perspective of\n  network",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.01.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recently, there has been a growing interest in network research, especially\nin these fields of biology, computer science, and sociology. It is natural to\naddress complex financial issues such as the European sovereign debt crisis\nfrom the perspective of network. In this article, we construct a network model\naccording to the debt--credit relations instead of using the conventional\nmethodology to measure the default risk. Based on the model, a risk index is\nexamined using the quarterly report of consolidated foreign claims from the\nBank for International Settlements (BIS) and debt/GDP ratios among these\nreporting countries. The empirical results show that this index can help the\nregulators and practitioners not only to determine the status of\ninterconnectivity but also to point out the degree of the sovereign debt\ndefault risk. Our approach sheds new light on the investigation of quantifying\nthe systemic risk.\n"
    },
    {
        "paper_id": 1304.3824,
        "authors": "Gabriel Frahm",
        "title": "Pricing and Valuation under the Real-World Measure",
        "comments": "Previous versions of this paper have been distributed under the\n  titles \"Pricing in Complex and Efficient Financial Markets,\" \"Absorbability\n  of Financial Markets,\" \"The Fundamental Theorem of Asset Pricing for Liquid\n  Financial Markets,\" and \"Asset Pricing and Valuation under the Real-World\n  Probability Measure.\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In general it is not clear which kind of information is supposed to be used\nfor calculating the fair value of a contingent claim. Even if the information\nis specified, it is not guaranteed that the fair value is uniquely determined\nby the given information. A further problem is that asset prices are typically\nexpressed in terms of a risk-neutral measure. This makes it difficult to\ntransfer the fundamental results of financial mathematics to econometrics. I\nshow that the aforementioned problems evaporate if the financial market is\ncomplete and sensitive. In this case, after an appropriate choice of the\nnumeraire, the discounted price processes turn out to be uniformly integrable\nmartingales under the real-world measure. This leads to a Law of One Price and\na simple real-world valuation formula in a model-independent framework where\nthe number of assets as well as the lifetime of the market can be finite or\ninfinite.\n"
    },
    {
        "paper_id": 1304.4311,
        "authors": "Cornelia Metzig and Mirta B. Gordon",
        "title": "A Model for Scaling in Firms' Size and Growth Rate Distribution",
        "comments": "accepted for publication in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.11.027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a simple agent-based model which allows us to analyze three\nstylized facts: a fat-tailed size distribution of companies, a `tent-shaped'\ngrowth rate distribution, the scaling relation of the growth rate variance with\nfirm size, and the causality between them. This is achieved under the simple\nhypothesis that firms compete for a scarce quantity (either aggregate demand or\nworkforce) which is allocated probabilistically. The model allows us to relate\nsize and growth rate distributions. We compare the results of our model to\nsimulations with other scaling relationships, and to similar models and relate\nit to existing theory. Effects arising from binning data are discussed.\n"
    },
    {
        "paper_id": 1304.4476,
        "authors": "Bent Flyvbjerg, Mette K. Skamris Holm, and S{\\o}ren L. Buhl",
        "title": "What Causes Cost Overrun in Transport Infrastructure Projects?\"",
        "comments": null,
        "journal-ref": "Transport Reviews, vol. 24, no. 1, January 2004, 3-18",
        "doi": "10.1080/0144164032000080494a",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article presents results from the first statistically significant study\nof causes of cost escalation in transport infrastructure projects. The study is\nbased on a sample of 258 rail, bridge, tunnel and road projects worth US$90\nbillion. The focus is on the dependence of cost escalation on (1) length of\nproject implementation phase, (2) size of project and (3) type of project\nownership. First, it is found with very high statistical significance that cost\nescalation is strongly dependent on length of implementation phase. The policy\nimplications are clear: Decision makers and planners should be highly concerned\nabout delays and long implementation phases because they translate into risks\nof substantial cost escalations. Second, it is found that projects have grown\nlarger over time and that for bridges and tunnels larger projects have larger\npercentage cost escalations. Finally, by comparing cost escalation for three\ntypes of project ownership--private, state-owned enterprise and other public\nownership--it is shown that the oft-seen claim that public ownership is\nproblematic and private ownership effective in curbing cost escalation is an\noversimplification. Type of accountability appears to matter more to cost\nescalation than type of ownership.\n"
    },
    {
        "paper_id": 1304.4525,
        "authors": "Alexander Budzier and Bent Flyvbjerg",
        "title": "Overspend? Late? Failure? What the Data Say About IT Project Risk in the\n  Public Sector",
        "comments": "Published in Commonwealth Secretariat (Eds.): Commonwealth Governance\n  Handbook 2012/13: Democracy, development and public administration, London:\n  Commonwealth Secretariat, December 2012. ISBN 978-1-908609-04-5",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Implementing large-scale information and communication technology (IT)\nprojects carries large risks and easily might disrupt operations, waste\ntaxpayers' money, and create negative publicity. Because of the high risks it\nis important that government leaders manage the attendant risks. We analysed a\nsample of 1,355 public sector IT projects. The sample included large-scale\nprojects, on average the actual expenditure was $130 million and the average\nduration was 35 months. Our findings showed that the typical project had no\ncost overruns and took on average 24% longer than initially expected. However,\ncomparing the risk distribution with the normative model of a thin-tailed\ndistribution, projects' actual costs should fall within -30% and +25% of the\nbudget in nearly 99 out of 100 projects. The data showed, however, that a\nstaggering 18% of all projects are outliers with cost overruns >25%. Tests\nshowed that the risk of outliers is even higher for standard software (24%) as\nwell as in certain project types, e.g., data management (41%), office\nmanagement (23%), eGovernment (21%) and management information systems (20%).\nAnalysis showed also that projects duration adds risk: every additional year of\nproject duration increases the average cost risk by 4.2 percentage points.\nLastly, we suggest four solutions that public sector organization can take: (1)\nbenchmark your organization to know where you are, (2) de-bias your IT project\ndecision-making, (3) reduce the complexities of your IT projects, and (4)\ndevelop Masterbuilders to learn from the best in the field.\n"
    },
    {
        "paper_id": 1304.4534,
        "authors": "Florian Kleinert and Kees van Schaik",
        "title": "A variation of the Canadisation algorithm for the pricing of American\n  options driven by L\\'evy processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce an algorithm for the pricing of finite expiry American options\ndriven by L\\'evy processes. The idea is to tweak Carr's `Canadisation' method,\ncf. Carr [9] (see also Bouchard et al [5]), in such a way that the adjusted\nalgorithm is viable for any L\\'evy process whose law at an independent,\nexponentially distributed time consists of a (possibly infinite) mixture of\nexponentials. This includes Brownian motion plus (hyper)exponential jumps, but\nalso the recently introduced rich class of so-called meromorphic L\\'evy\nprocesses, cf. Kyprianou et al [16]. This class contains all L\\'evy processes\nwhose L\\'evy measure is an infinite mixture of exponentials which can generate\nboth finite and infinite jump activity. L\\'evy processes well known in\nmathematical finance can in a straightforward way be obtained as a limit of\nmeromorphic L\\'evy processes. We work out the algorithm in detail for the\nclassic example of the American put, and we illustrate the results with some\nnumerics.\n"
    },
    {
        "paper_id": 1304.459,
        "authors": "Alexander Budzier and Bent Flyvbjerg",
        "title": "Double Whammy - How ICT Projects are Fooled by Randomness and Screwed by\n  Political Intent",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The cost-benefit analysis formulates the holy trinity of objectives of\nproject management - cost, schedule, and benefits. As our previous research has\nshown, ICT projects deviate from their initial cost estimate by more than 10%\nin 8 out of 10 cases. Academic research has argued that Optimism Bias and Black\nSwan Blindness cause forecasts to fall short of actual costs. Firstly, optimism\nbias has been linked to effects of deception and delusion, which is caused by\ntaking the inside-view and ignoring distributional information when making\ndecisions. Secondly, we argued before that Black Swan Blindness makes\ndecision-makers ignore outlying events even if decisions and judgements are\nbased on the outside view. Using a sample of 1,471 ICT projects with a total\nvalue of USD 241 billion - we answer the question: Can we show the different\neffects of Normal Performance, Delusion, and Deception? We calculated the\ncumulative distribution function (CDF) of (actual-forecast)/forecast. Our\nresults show that the CDF changes at two tipping points - the first one\ntransforms an exponential function into a Gaussian bell curve. The second\ntipping point transforms the bell curve into a power law distribution with the\npower of 2. We argue that these results show that project performance up to the\nfirst tipping point is politically motivated and project performance above the\nsecond tipping point indicates that project managers and decision-makers are\nfooled by random outliers, because they are blind to thick tails. We then show\nthat Black Swan ICT projects are a significant source of uncertainty to an\norganisation and that management needs to be aware of.\n"
    },
    {
        "paper_id": 1304.4623,
        "authors": "Christian Bayer and Peter K. Friz",
        "title": "Cubature on Wiener space: pathwise convergence",
        "comments": null,
        "journal-ref": "Applied Mathematics & Optimization, April 2013, Volume 67, Issue\n  2, pp 261-278",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Cubature on Wiener space [Lyons, T.; Victoir, N.; Proc. R. Soc. Lond. A 8\nJanuary 2004 vol. 460 no. 2041 169-198] provides a powerful alternative to\nMonte Carlo simulation for the integration of certain functionals on Wiener\nspace. More specifically, and in the language of mathematical finance, cubature\nallows for fast computation of European option prices in generic diffusion\nmodels.\n  We give a random walk interpretation of cubature and similar (e.g. the\nNinomiya--Victoir) weak approximation schemes. By using rough path analysis, we\nare able to establish weak convergence for general path-dependent option\nprices.\n"
    },
    {
        "paper_id": 1304.4688,
        "authors": "Youssef El-Khatib and Abdulnasser Hatemi-J",
        "title": "On the pricing and hedging of options for highly volatile periods",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Option pricing is an integral part of modern financial risk management. The\nwell-known Black and Scholes (1973) formula is commonly used for this purpose.\nThis paper is an attempt to extend their work to a situation in which the\nunconditional volatility of the original asset is increasing during a certain\nperiod of time. We consider a market suffering from a financial crisis. We\nprovide the solution for the equation of the underlying asset price as well as\nfinding the hedging strategy. In addition, a closed formula of the pricing\nproblem is proved for a particular case. The suggested formulas are expected to\nmake the valuation of options and the underlying hedging strategies during\nfinancial crisis more precise.\n"
    },
    {
        "paper_id": 1304.469,
        "authors": "Youssef El-Khatib and Abdulnasser Hatemi-J",
        "title": "On option pricing in illiquid markets with jumps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One of the shortcomings of the Black and Scholes model on option pricing is\nthe assumption that trading of the underlying asset does not affect the price\nof that asset. This assumption can be fulfilled only in perfectly liquid\nmarkets. Since most markets are illquid, this assumption might be too\nrestrictive. Thus, taking into account the price impact in option pricing is an\nimportant issue. This issue has been dealt with, to some extent, for illiquid\nmarkets by assuming a continuous process, mainly based on the Brownian motion.\nHowever, the recent financial crisis and its effects on the global stock\nmarkets have propagated the urgent need for more realistic models where the\nstochastic process describing the price trajectories involves random jumps.\nNonetheless, works related to markets with jumps are scant compared to the\ncontinuous ones. In addition, these previous studies do not deal with illiquid\nmarkets. The contribution of this paper is to tackle the pricing problem for\noptions in illiquid markets with jumps as well as the hedging strategy within\nthis context, which is the first of its kind to the best knowledge.\n"
    },
    {
        "paper_id": 1304.4807,
        "authors": "Dimitri O. Ledenyov and Viktor O. Ledenyov",
        "title": "On the accurate characterization of business cycles in nonlinear dynamic\n  financial and economic systems",
        "comments": "26 pages, 8 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The accurate characterization of the business cycles in the nonlinear dynamic\nfinancial and economic systems in the time of globalization represents a\nformidable research problem. The central banks and other financial institutions\nmake their decisions on the minimum capital requirements, countercyclical\ncapital buffer allocation and capital investments, going from the precise data\non the business cycles. We consider the two possible interaction scenarios,\nwhen there are: the linear interactions, and the non-linear interactions. In\nour opinion, the main parameters of the business cycle may deviate during the\nbusiness cycle nonlinear interaction with the nonlinear dynamic financial and\neconomic systems, because of the origination of the nonlinear effects such as\nthe Four Waves Mixing (FWM), Stimulated Brillouin Scattering (SBS), Stimulated\nRaman Scattering (SRS), Carrier Induced Phase Modulation.\n"
    },
    {
        "paper_id": 1304.4852,
        "authors": "Nadia Loukil (Fiesta), Ouidad Yousfi (MRM)",
        "title": "Firm's Information Environment and Stock Liquidity : Evidence from\n  Tunisian Context,",
        "comments": null,
        "journal-ref": "Journal of Accounting in Emerging Economies, 2, 1 (2011) 30",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper analyzes the relationship between public disclosure, private\ninformation and stock liquidity in Tunisian context using a sample of 41 listed\nfirms in the Tunis Stock Exchange in 2007. First, we find no evidence that\nthere is a relation between public and private information. Second, Tunisian\ninvestors do not trust the information disclosed in both annual reports and web\nsites, consequently it has no effects on stock liquidity, in contrast with\nprivate information.\n"
    },
    {
        "paper_id": 1304.4853,
        "authors": "Irina Penner, Anthony Reveillac (CEREMADE)",
        "title": "Risk measures for processes and BSDEs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper analyzes risk assessment for cash flows in continuous time using\nthe notion of convex risk measures for processes. By combining a decomposition\nresult for optional measures, and a dual representation of a convex risk\nmeasure for bounded \\cd processes, we show that this framework provides a\nsystematic approach to the both issues of model ambiguity, and uncertainty\nabout the time value of money. We also establish a link between risk measures\nfor processes and BSDEs.\n"
    },
    {
        "paper_id": 1304.4929,
        "authors": "Yannis G. Yatracos",
        "title": "A new method to obtain risk neutral probability, without stochastic\n  calculus and price modeling, confirms the universal validity of\n  Black-Scholes-Merton formula and volatility's role",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new method is proposed to obtain the risk neutral probability of share\nprices without stochastic calculus and price modeling, via an embedding of the\nprice return modeling problem in Le Cam's statistical experiments framework.\nStrategies-probabilities $P_{t_0,n}$ and $P_{T,n}$ are thus determined and\nused, respectively,for the trader selling the share's European call option at\ntime $t_0$ and for the buyer who may exercise it in the future, at $T; \\ n$\nincreases with the number of share's transactions in $[t_0,T].$ When the\ntransaction times are dense in $[t_0,T]$ it is shown, with mild conditions,\nthat under each of these probabilities $\\log \\frac{S_T}{S_{t_0}}$ has\ninfinitely divisible distribution and in particular normal distribution for\n\"calm\" share; $S_t$ is the share's price at time $t.$ The price of the share's\ncall is the limit of the expected values of the call's payoff under the\ntranslated $P_{t_0,n}.$ It coincides for \"calm\" share prices with the\nBlack-Scholes-Merton formula with variance not necessarily proportional to\n$(T-t_0),$ thus confirming formula's universal validity without model\nassumptions. Additional results clarify volatility's role in the transaction\nand the behaviors of the trader and the buyer. Traders may use the pricing\nformulae after estimation of the unknown parameters.\n"
    },
    {
        "paper_id": 1304.4995,
        "authors": "Juan M. Romero, Ulises Lavana, Elio Mart\\'inez",
        "title": "Schr\\\"odinger group and quantum finance",
        "comments": "10 page, non figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using the one dimensional free particle symmetries, the quantum finance\nsymmetries are obtained. Namely, it is shown that Black-Scholes equation is\ninvariant under Schr\\\"odinger group. In order to do this, the one dimensional\nfree non-relativistic particle and its symmetries are revisited. To get the\nBlack-Scholes equation symmetries, the particle mass is identified as the\ninverse of square of the volatility. Furthermore, using financial variables, a\nSchr\\\"odinger algebra representation is constructed.\n"
    },
    {
        "paper_id": 1304.504,
        "authors": "Bernt {\\O}ksendal and Agn\\`es Sulem",
        "title": "Dynamic robust duality in utility maximization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A celebrated financial application of convex duality theory gives an explicit\nrelation between the following two quantities:\n  (i) The optimal terminal wealth $X^*(T) : = X_{\\varphi^*}(T)$ of the problem\nto maximize the expected $U$-utility of the terminal wealth $X_{\\varphi}(T)$\ngenerated by admissible portfolios $\\varphi(t), 0 \\leq t \\leq T$ in a market\nwith the risky asset price process modeled as a semimartingale;\n  (ii) The optimal scenario $\\frac{dQ^*}{dP}$ of the dual problem to minimize\nthe expected $V$-value of $\\frac{dQ}{dP}$ over a family of equivalent local\nmartingale measures $Q$, where $V$ is the convex conjugate function of the\nconcave function $U$.\n  In this paper we consider markets modeled by It\\^o-L\\'evy processes. In the\nfirst part we use the maximum principle in stochastic control theory to extend\nthe above relation to a \\emph{dynamic} relation, valid for all $t \\in [0,T]$.\nWe prove in particular that the optimal adjoint process for the primal problem\ncoincides with the optimal density process, and that the optimal adjoint\nprocess for the dual problem coincides with the optimal wealth process, $0 \\leq\nt \\leq T$. In the terminal time case $t=T$ we recover the classical duality\nconnection above. We get moreover an explicit relation between the optimal\nportfolio $\\varphi^*$ and the optimal measure $Q^*$. We also obtain that the\nexistence of an optimal scenario is equivalent to the replicability of a\nrelated $T$-claim.\n  In the second part we present robust (model uncertainty) versions of the\noptimization problems in (i) and (ii), and we prove a similar dynamic relation\nbetween them. In particular, we show how to get from the solution of one of the\nproblems to the other. We illustrate the results with explicit examples.\n"
    },
    {
        "paper_id": 1304.5065,
        "authors": "Rama Cont and Thomas Kokholm",
        "title": "Central Clearing of OTC Derivatives: bilateral vs multilateral netting",
        "comments": null,
        "journal-ref": "Statistics and Risk Modeling, Vol 31, No. 1, 3-22, March 2014",
        "doi": "10.1515/strm-2013-1161",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the impact of central clearing of over-the-counter (OTC)\ntransactions on counterparty exposures in a market with OTC transactions across\nseveral asset classes with heterogeneous characteristics. The impact of\nintroducing a central counterparty (CCP) on expected interdealer exposure is\ndetermined by the tradeoff between multilateral netting across dealers on one\nhand and bilateral netting across asset classes on the other hand. We find this\ntradeoff to be sensitive to assumptions on heterogeneity of asset classes in\nterms of `riskyness' of the asset class as well as correlation of exposures\nacross asset classes. In particular, while an analysis assuming independent,\nhomogeneous exposures suggests that central clearing is efficient only if one\nhas an unrealistically high number of participants, the opposite conclusion is\nreached if differences in riskyness and correlation across asset classes are\nrealistically taken into account. We argue that empirically plausible\nspecifications of model parameters lead to the conclusion that central clearing\ndoes reduce interdealer exposures: the gain from multilateral netting in a CCP\noverweighs the loss of netting across asset classes in bilateral netting\nagreements. When a CCP exists for interest rate derivatives, adding a CCP for\ncredit derivatives is shown to decrease overall exposures. These findings are\nshown to be robust to the statistical assumptions of the model as well as the\nchoice of risk measure used to quantify exposures.\n"
    },
    {
        "paper_id": 1304.513,
        "authors": "Thilo A. Schmitt, Desislava Chetalova, Rudi Sch\\\"afer, Thomas Guhr",
        "title": "Non-Stationarity in Financial Time Series and Generic Features",
        "comments": null,
        "journal-ref": "EPL 103 (2013) 58003",
        "doi": "10.1209/0295-5075/103/58003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets are prominent examples for highly non-stationary systems.\nSample averaged observables such as variances and correlation coefficients\nstrongly depend on the time window in which they are evaluated. This implies\nsevere limitations for approaches in the spirit of standard equilibrium\nstatistical mechanics and thermodynamics. Nevertheless, we show that there are\nsimilar generic features which we uncover in the empirical return distributions\nfor whole markets. We explain our findings by setting up a random matrix model.\n"
    },
    {
        "paper_id": 1304.5156,
        "authors": "Yannis G. Yatracos",
        "title": "Option pricing, Bayes risks and Applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A statistical decision problem is hidden in the core of option pricing. A\nsimple form for the price C of a European call option is obtained via the\nminimum Bayes risk, R_B, of a 2-parameter estimation problem, thus justifying\ncalling C Bayes (B-)price. The result provides new insight in option pricing,\namong others obtaining C for some stock-price models using the underlying\nprobability instead of the risk neutral probability and giving R_B an economic\ninterpretation. When logarithmic stock prices follow Brownian motion, discrete\nnormal mixture and hyperbolic Levy motion the obtained B-prices are \"fair\"\nprices. A new expression for the price of American call option is also obtained\nand statistical modeling of R_B can be used when pricing European and American\ncall options.\n"
    },
    {
        "paper_id": 1304.5337,
        "authors": "Hsuan-Ku Liu",
        "title": "The Convexity of the Free Boundary for the American put option",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the parabolic free boundary problem arising from pricing\nAmerican-style put options on an asset whose index follows a geometric Brownian\nmotion process. The contribution is to propose a condition for that the early\nexercise boundary is a convex function.\n"
    },
    {
        "paper_id": 1304.538,
        "authors": "Juha Karvanen, Ari Rantanen, Lasse Luoma",
        "title": "Survey data and Bayesian analysis: a cost-efficient way to estimate\n  customer equity",
        "comments": null,
        "journal-ref": "Quantitative Marketing and Economics, Volume 12, Issue 3, Pages\n  305-329, 2014",
        "doi": "10.1007/s11129-014-9148-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a Bayesian framework for estimating the customer lifetime value\n(CLV) and the customer equity (CE) based on the purchasing behavior deducible\nfrom the market surveys on customer purchasing behavior. The proposed framework\nsystematically addresses the challenges faced when the future value of\ncustomers is estimated based on survey data. The scarcity of the survey data\nand the sampling variance are countered by utilizing the prior information and\nquantifying the uncertainty of the CE and CLV estimates by posterior\ndistributions. Furthermore, information on the purchase behavior of the\ncustomers of competitors available in the survey data is integrated to the\nframework. The introduced approach is directly applicable in the domains where\na customer relationship can be thought to be monogamous.\n  As an example on the use of the framework, we analyze a consumer survey on\nmobile phones carried out in Finland in February 2013. The survey data contains\nconsumer given information on the current and previous brand of the phone and\nthe times of the last two purchases.\n"
    },
    {
        "paper_id": 1304.5962,
        "authors": "Hsuan-Ku Liu",
        "title": "The pricing formula for cancellable European options",
        "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation 13",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the value of a cancellable European option in a finite\ntime horizon setting. The specifications of this generalized European option\nallow the seller to cancel the option at any point in time for a fixed penalty\npaid directly to the holder. Here, we provide an explicit valuation formula for\nthe European game call where the early cancellation time is obtained\niteratively.\n"
    },
    {
        "paper_id": 1304.6006,
        "authors": "Tetsuya Takaishi, Ting Ting Chen and Zeyu Zheng",
        "title": "Analysis of Realized Volatility in Two Trading Sessions of the Japanese\n  Stock Market",
        "comments": "12 pages, reference corrected",
        "journal-ref": "Prog. Theor. Phys. Supplement No.194 (2012) pp. 43-54",
        "doi": "10.1143/PTPS.194.43",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze realized volatilities constructed using high-frequency stock data\non the Tokyo Stock Exchange. In order to avoid non-trading hours issue in\nvolatility calculations we define two realized volatilities calculated\nseparately in the two trading sessions of the Tokyo Stock Exchange, i.e.\nmorning and afternoon sessions. After calculating the realized volatilities at\nvarious sampling frequencies we evaluate the bias from the microstructure noise\nas a function of sampling frequency. Taking into account of the bias to\nrealized volatility we examine returns standardized by realized volatilities\nand confirm that price returns on the Tokyo Stock Exchange are described\napproximately by Gaussian time series with time-varying volatility, i.e.\nconsistent with a mixture of distributions hypothesis.\n"
    },
    {
        "paper_id": 1304.6165,
        "authors": "Nicolas Privault and Timothy Robin Teng",
        "title": "Hedging in bond markets by the Clark-Ocone formula",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Hedging strategies in bond markets are computed by martingale representation\nand the Clark-Ocone formula under the choice of a suitable of numeraire, in a\nmodel driven by the dynamics of bond prices. Applications are given to the\nhedging of swaptions and other interest rate derivatives, and our approach is\ncompared to delta hedging when the underlying swap rate is modeled by a\ndiffusion process.\n"
    },
    {
        "paper_id": 1304.6819,
        "authors": "A. Gareche, G. Disdier, J. Kockelkoren, J.-P. Bouchaud",
        "title": "A Fokker-Planck description for the queue dynamics of large tick stocks",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.88.032809",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by empirical data, we develop a statistical description of the\nqueue dynamics for large tick assets based on a two-dimensional Fokker-Planck\n(diffusion) equation, that explicitly includes state dependence, i.e. the fact\nthat the drift and diffusion depends on the volume present on both sides of the\nspread. \"Jump\" events, corresponding to sudden changes of the best limit price,\nmust also be included as birth-death terms in the Fokker-Planck equation. All\nquantities involved in the equation can be calibrated using high-frequency data\non best quotes. One of our central finding is the the dynamical process is\napproximately scale invariant, i.e., the only relevant variable is the ratio of\nthe current volume in the queue to its average value. While the latter shows\nintraday seasonalities and strong variability across stocks and time periods,\nthe dynamics of the rescaled volumes is universal. In terms of rescaled\nvolumes, we found that the drift has a complex two-dimensional structure, which\nis a sum of a gradient contribution and a rotational contribution, both stable\nacross stocks and time. This drift term is entirely responsible for the\ndynamical correlations between the ask queue and the bid queue.\n"
    },
    {
        "paper_id": 1304.6846,
        "authors": "Ovidiu Racorean",
        "title": "Time-independent pricing of options in range bound markets",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Assuming that price of the underlying stock is moving in range bound, the\nBlack-Scholes formula for options pricing supports a separation of variables.\nThe resulting time-independent equation is solved employing different behavior\nof the option price function and three significant results are deduced. The\nfirst is the probability of stock price penetration through support or\nresistance level, called transmission coefficient. The second is the distance\nthat price will go through once stock price penetrates out of the range bound.\nThe last one is a predicted short time dramatic fall in the stock volatility\nright ahead of price tunneling. All three results are useful tools that give\nmarket practitioners valuable insights in choosing the right time to get\ninvolved in an option contract, about how far the price will go in case of a\nbreakout, and how to correctly interpret volatility downfalls.\n"
    },
    {
        "paper_id": 1304.733,
        "authors": "Karim Azizi, Nicolas Canry, Jean-Bernard Chatelain, Bruno Tinel",
        "title": "Government Solvency, Austerity and Fiscal Consolidation in the OECD: A\n  Keynesian Appraisal of Transversality and No Ponzi Game Conditions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the relevance of the No-Ponzi game condition for\npublic debt (i.e. the public debt growth rate has to be lower than the real\ninterest rate, a necessary assumption for Ricardian equivalence) and of the\ntransversality condition for the GDP growth rate (i.e. the GDP growth rate has\nto be lower than the real interest rate). First, on the unbalanced panel of 21\ncountries from 1961 to 2010 available in OECD database, those two conditions\nwere simultaneously validated only for 29% of the cases under examination.\nSecond, those two conditions were more frequent in the 1980s and the 1990s when\nmonetary policies were more restrictive. Third, in tune with the Keynesian\nview, when the real interest rate is higher than the GDP growth, it corresponds\nto 75% of the cases of the increases of the debt/GDP ratio but to only 43% of\nthe cases of the decreases of the debt/GDP ratio (fiscal consolidations).\n"
    },
    {
        "paper_id": 1304.7533,
        "authors": "Andrei N. Soklakov",
        "title": "Deriving Derivatives",
        "comments": "13 pages, 2 figures",
        "journal-ref": "Risk, July (2016), pp. 78-83",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Quantitative structuring is a rigorous framework for the design of financial\nproducts. We show how it incorporates traditional investment ideas while\nsupporting a more accurate expression of clients' views. We touch upon adjacent\ntopics regarding the safety of financial derivatives and the role of pricing\nmodels in product design.\n"
    },
    {
        "paper_id": 1304.7535,
        "authors": "Andrei N. Soklakov",
        "title": "Elasticity theory of structuring",
        "comments": "16 pages, 3 figures",
        "journal-ref": "Risk, December (2016), pp. 81-86",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial derivatives have often been criticized as casino-style betting\ninstruments. It turns out that many naive ways of making them are indeed\nequivalent to gambling. Fortunately, this inadvertent effect can be understood\nand prevented. We present a theory of product design which achieves that.\n"
    },
    {
        "paper_id": 1304.7562,
        "authors": "Jose V. Alcala and Arash Fahim",
        "title": "Balancing small fixed and proportional transaction cost in trading\n  strategies",
        "comments": "9 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Transaction costs appear in financial markets in more than one form. There\nare several results in the literature on small proportional transaction cost\nand not that many on fixed transaction cost. In the present work, we\nheuristically study the effect of both types of transaction cost by focusing on\na portfolio optimization. Here we assume the presence of fixed transaction cost\nand that there is a balance between fixed and proportional transaction cost,\nsuch that none of them dominates the other, asymptotically. We find out that\nthe deviation of value function, when the fixed transaction cost is\n$\\varepsilon$, from the Merton value function, without transaction cost, is of\norder $\\varepsilon^1/2$ which is different from the pure proportional cost of\n$\\varepsilon^2/3$. Based on this, we propose an expansion for the value\nfunction in terms of powers of $\\varepsilon^1/2$.\n"
    },
    {
        "paper_id": 1304.7563,
        "authors": "Xiaolin Luo and Pavel Shevchenko",
        "title": "Pricing TARN Using a Finite Difference Method",
        "comments": "17 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Typically options with a path dependent payoff, such as Target Accumulation\nRedemption Note (TARN), are evaluated by a Monte Carlo method. This paper\ndescribes a finite difference scheme for pricing a TARN option. Key steps in\nthe proposed scheme involve tracking of multiple one-dimensional finite\ndifference solutions, application of jump conditions at each cash flow exchange\ndate, and a cubic spline interpolation of results after each jump. Since a\nfinite difference scheme for TARN has significantly different features from a\ntypical finite difference scheme for options with a path independent payoff, we\ngive a step by step description on the implementation of the scheme, which is\nnot available in the literature. The advantages of the proposed finite\ndifference scheme over the Monte Carlo method are illustrated by examples with\nthree different knockout types. In the case of constant or time dependent\nvolatility models (where Monte Carlo requires simulation at cash flow dates\nonly), the finite difference method can be faster by an order of magnitude than\nthe Monte Carlo method to achieve the same accuracy in price. Finite difference\nmethod can be even more efficient in comparison with Monte Carlo in the case of\nlocal volatility model where Monte Carlo requires significantly larger number\nof time steps. In terms of robust and accurate estimation of Greeks, the\nadvantage of the finite difference method will be even more pronounced.\n"
    },
    {
        "paper_id": 1304.7878,
        "authors": "Qian Zhao, Jiaqin Wei, Rongming Wang",
        "title": "On the Dividend Strategies with Non-Exponential Discounting",
        "comments": "2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the dividend strategies for a shareholder with\nnon-constant discount rate in a diffusion risk model. We assume that the\ndividends can only be paid at a bounded rate and restrict ourselves to the\nMarkov strategies. This is a time inconsistent control problem. The extended\nHJB equation is given and the verification theorem is proved for a general\ndiscount function. Considering the pseudo-exponential discount functions (Type\nI and Type II), we get the equilibrium dividend strategies and the equilibrium\nvalue functions by solving the extended HJB equations.\n"
    },
    {
        "paper_id": 1304.7882,
        "authors": "Qian Zhao, Jiaqin Wei, Rongming Wang",
        "title": "Mean-Variance Asset-Liability Management with State-Dependent Risk\n  Aversion",
        "comments": "12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we consider the asset-liability management under the\nmean-variance criterion. The financial market consists of a risk-free bond and\na stock whose price process is modeled by a geometric Brownian motion. The\nliability of the investor is uncontrollable and is modeled by another geometric\nBrownian motion. We consider a specific state-dependent risk aversion which\ndepends on a power function of the liability. By solving a flow of FBSDEs with\nbivariate state process, we obtain the equilibrium strategy among all the\nopen-loop controls for this time-inconsistent control problem. It shows that\nthe equilibrium strategy is a feedback control of the liability.\n"
    },
    {
        "paper_id": 1304.7934,
        "authors": "Keita Owari",
        "title": "Maximum Lebesgue Extension of Monotone Convex Functions",
        "comments": "To Appear in Journal of Functional Analysis, 32 pages",
        "journal-ref": "Journal of Functional Analysis, 266, issue 6, 2014, pp. 3572-3611",
        "doi": "10.1016/j.jfa.2014.01.002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Given a monotone convex function on the space of essentially bounded random\nvariables with the Lebesgue property (order continuity), we consider its\nextension preserving the Lebesgue property to as big solid vector space of\nrandom variables as possible. We show that there exists a maximum such\nextension, with explicit construction, where the maximum domain of extension is\nobtained as a (possibly proper) subspace of a natural Orlicz-type space,\ncharacterized by a certain uniform integrability property. As an application,\nwe provide a characterization of the Lebesgue property of monotone convex\nfunction on arbitrary solid spaces of random variables in terms of uniform\nintegrability and a \"nice\" dual representation of the function.\n"
    },
    {
        "paper_id": 1305.004,
        "authors": "Lorenzo Giada and Claudio Nordio",
        "title": "A note on replicating a CDS through a repo and an asset swap",
        "comments": "6 pages, 1 figure, working paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note we show how to replicate a stylized CDS with a repurchase\nagreement and an asset swap. The latter must be designed in such a way that, on\ndefault of the issuer, it is terminated with a zero close-out amount. This\nbreak clause can be priced using the well known unilateral credit/debit\nvaluation adjustment formulas.\n"
    },
    {
        "paper_id": 1305.0101,
        "authors": "Pierre Lescanne (LIP)",
        "title": "Bubbles are rational",
        "comments": "Translation of http://hal-ens-lyon.archives-ouvertes.fr/ensl-00646546",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  As we show using the notion of equilibrium in the theory of infinite\nsequential games, bubbles and escalations are rational for economic and\nenvironmental agents, who believe in an infinite world. This goes against a\nvision of a self regulating, wise and pacific economy in equilibrium. In other\nwords, in this context, equilibrium is not a synonymous of stability. We\nattempt to draw from this statement methodological consequences and a new\napproach to economics. To the mindware of economic agents (a concept due to\ncognitive psychology) we propose to add coinduction to properly reason on\ninfinite games. This way we refine the notion of rationality.\n"
    },
    {
        "paper_id": 1305.0105,
        "authors": "Pietro Fodra (LPMA), Huy\\^en Pham (LPMA)",
        "title": "Semi Markov model for market microstructure",
        "comments": "number of pages: 25",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new model for describing the fluctuations of a tick-by-tick\nsingle asset price. Our model is based on Markov renewal processes. We consider\na point process associated to the timestamps of the price jumps, and marks\nassociated to price increments. By modeling the marks with a suitable Markov\nchain, we can reproduce the strong mean-reversion of price returns known as\nmicrostructure noise. Moreover, by using Markov renewal processes, we can model\nthe presence of spikes in intensity of market activity, i.e. the volatility\nclustering, and consider dependence between price increments and jump times. We\nalso provide simple parametric and nonparametric statistical procedures for the\nestimation of our model. We obtain closed-form formula for the mean signature\nplot, and show the diffusive behavior of our model at large scale limit. We\nillustrate our results by numerical simulations, and that our model is\nconsistent with empirical data on the Euribor future.\n"
    },
    {
        "paper_id": 1305.0144,
        "authors": "Raphael Hauser, Vijay Krishnamurthy and Reha T\\\"ut\\\"unc\\\"u",
        "title": "Relative Robust Portfolio Optimization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Considering mean-variance portfolio problems with uncertain model parameters,\nwe contrast the classical absolute robust optimization approach with the\nrelative robust approach based on a maximum regret function. Although the\nlatter problems are NP-hard in general, we show that tractable inner and outer\napproximations exist in several cases that are of central interest in asset\nmanagement.\n"
    },
    {
        "paper_id": 1305.0239,
        "authors": "Sitabhra Sinha and Uday Kovur",
        "title": "Uncovering the network structure of the world currency market:\n  Cross-correlations in the fluctuations of daily exchange rates",
        "comments": "16 pages, 6 figures, to appear in Proceedings of International\n  Workshop on \"Econophysics of Agent-Based Models\" (Econophys-Kolkata VII), Nov\n  8-12, 2012",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The cross-correlations between the exchange rate fluctuations of 74\ncurrencies over the period 1995-2012 are analyzed in this paper. The eigenvalue\ndistribution of the cross-correlation matrix exhibits a bulk which\napproximately matches the bounds predicted from random matrices constructed\nusing mutually uncorrelated time-series. However, a few large eigenvalues\ndeviating from the bulk contain important information about the global market\nmode as well as important clusters of strongly interacting currencies.We\nreconstruct the network structure of the world currency market by using two\ndifferent graph representation techniques, after filtering out the effects of\nglobal or market-wide signals on the one hand and random effects on the other.\nThe two networks reveal complementary insights about the major motive forces of\nthe global economy, including the identification of a group of potentially fast\ngrowing economies whose development trajectory may affect the global economy in\nthe future as profoundly as the rise of India and China has affected it in the\npast decades.\n"
    },
    {
        "paper_id": 1305.0413,
        "authors": "Olivier Gu\\'eant",
        "title": "Permanent market impact can be nonlinear",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There are two schools of thought regarding market impact modeling. On the one\nhand, seminal papers by Almgren and Chriss introduced a decomposition between a\npermanent market impact and a temporary (or instantaneous) market impact. This\ndecomposition is used by most practitioners in execution models. On the other\nhand, recent research advocates for the use of a new modeling framework that\ngoes down to the resilient dynamics of order books: transient market impact.\nOne of the main criticisms against permanent market impact is that it has to be\nlinear to avoid dynamic arbitrage. This important discovery made by Huberman\nand Stanzl and Gatheral favors the transient market impact framework, as linear\npermanent market impact is at odds with reality. In this paper, we reconsider\nthe point made by Gatheral using a simple model for market impact and show that\npermanent market impact can be nonlinear. Also, and this is the most important\npart from a practical point of view, we propose different statistics to\nestimate permanent market impact and execution costs that generalize the ones\nproposed in Almgren at al. (2005).\n"
    },
    {
        "paper_id": 1305.0436,
        "authors": "Guglielmo D'Amico and Filippo Petroni",
        "title": "Multivariate high-frequency financial data via semi-Markov processes",
        "comments": "arXiv admin note: substantial text overlap with arXiv:1205.2551,\n  arXiv:1109.4259",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a bivariate generalization of a weighted indexed\nsemi-Markov chains to study the high frequency price dynamics of traded stocks.\nWe assume that financial returns are described by a weighted indexed\nsemi-Markov chain model. We show, through Monte Carlo simulations, that the\nmodel is able to reproduce important stylized facts of financial time series\nlike the persistence of volatility and at the same time it can reproduce the\ncorrelation between stocks. The model is applied to data from Italian stock\nmarket from 1 January 2007 until the end of December 2010.\n"
    },
    {
        "paper_id": 1305.0479,
        "authors": "Elisa Appolloni, Lucia Caramellino, Antonino Zanette",
        "title": "A robust tree method for pricing American options with CIR stochastic\n  interest rate",
        "comments": null,
        "journal-ref": "IMA Journal of Management Mathematics, 26, 345-375, 2015",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a robust and stable lattice method which permits to obtain very\naccurate American option prices in presence of CIR stochastic interest rate\nwithout any numerical restriction on its parameters. Numerical results show the\nreliability and the accuracy of the proposed method.\n"
    },
    {
        "paper_id": 1305.0639,
        "authors": "Gregory Schehr, Satya N. Majumdar",
        "title": "Exact record and order statistics of random walks via first-passage\n  ideas",
        "comments": "25 pages, 2 figures. To appear in the special volume \"First-Passage\n  Phenomena and Their Applications\", Eds. R. Metzler, G. Oshanin, S. Redner.\n  World Scientific (2013)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  While records and order statistics of independent and identically distributed\n(i.i.d.) random variables X_1, ..., X_N are fully understood, much less is\nknown for strongly correlated random variables, which is often the situation\nencountered in statistical physics. Recently, it was shown, in a series of\nworks, that one-dimensional random walk (RW) is an interesting laboratory where\nthe influence of strong correlations on records and order statistics can be\nstudied in detail. We review here recent exact results which have been obtained\nfor these questions about RW, using techniques borrowed from the study of\nfirst-passage problems. We also present a brief review of the well known (and\nnot so well known) results for records and order statistics of i.i.d.\nvariables.\n"
    },
    {
        "paper_id": 1305.0741,
        "authors": "Bent Flyvbjerg",
        "title": "Delusions of Success: Comment on Dan Lovallo and Daniel Kahneman",
        "comments": null,
        "journal-ref": "Harvard Business Review, December 2003, 121-122",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Dan Lovallo and Daniel Kahneman must be commended for their clear\nidentification of causes and cures to the planning fallacy in \"Delusions of\nSuccess: How Optimism Undermines Executives' Decisions\" (HBR July 2003). Their\nlook at overoptimism, anchoring, competitor neglect, and the outside view in\nforecasting is highly useful to executives and forecasters. However, Lovallo\nand Kahneman underrate one source of bias in forecasting - the deliberate\n\"cooking\" of forecasts to get ventures started.\n"
    },
    {
        "paper_id": 1305.0768,
        "authors": "Marco Patriarca and Anirban Chakraborti",
        "title": "Kinetic exchange models: From molecular physics to social science",
        "comments": "7 pages, 4 figures, REVTeX format. Tutorial article to appear in the\n  American Journal of Physics. Revised figures, corrected and added references",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss several multi-agent models that have their origin in the kinetic\nexchange theory of statistical mechanics and have been recently applied to a\nvariety of problems in the social sciences. This class of models can be easily\nadapted for simulations in areas other than physics, such as the modeling of\nincome and wealth distributions in economics and opinion dynamics in sociology.\n"
    },
    {
        "paper_id": 1305.0794,
        "authors": "Kang Liu, N. Lubbers, W. Klein, J. Tobochnik, B. Boghosian, and Harvey\n  Gould",
        "title": "The Effect of Growth On Equality in Models of the Economy",
        "comments": "5 pages, 7 figures (2 with 3 subfigures)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the relation between economic growth and equality in a\nmodified version of the agent-based asset exchange model (AEM). The modified\nmodel is a driven system that for a range of parameter space is effectively\nergodic in the limit of an infinite system. We find that the belief that \"a\nrising tide lifts all boats\" does not always apply, but the effect of growth on\nthe wealth distribution depends on the nature of the growth. In particular, we\nfind that the rate of growth, the way the growth is distributed, and the\npercentage of wealth exchange determine the degree of equality. We find strong\nnumerical evidence that there is a phase transition in the modified model, and\nfor a part of parameter space the modified AEM acts like a geometric random\nwalk.\n"
    },
    {
        "paper_id": 1305.1559,
        "authors": "Ovidiu Racorean",
        "title": "Are Financial Markets an aspect of Quantum World?",
        "comments": "7 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Writing the article-Time independent pricing of options in range bound\nmarkets; the question in the title came naturally to my mind. It is stated, in\nthe above article, that in certain market conditions the stock price is\nsubjected to an equation that exactly matches a time independent Schrodinger\nequation. The time independent equation for options valuation is used further\nto explain a stock market phenomenon that resembles an alpha particle decay\ntunneling effect. The transmission coefficient for the stock price tunneling\neffect it is also deduced. Although, it may not have important impact in\nquantum physics, the philosophical aspects residing in the use of quantum\nmechanics for stock market specific are very important.\n"
    },
    {
        "paper_id": 1305.1747,
        "authors": "Chuancun Yin",
        "title": "Optimal dividend problem for a generalized compound Poisson risk model",
        "comments": "11 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note we study the optimal dividend problem for a company whose\nsurplus process, in the absence of dividend payments, evolves as a generalized\ncompound Poisson model in which the counting process is a generalized Poisson\nprocess. This model including the classical risk model and the Polya-Aeppli\nrisk model as special cases. The objective is to find a dividend policy so as\nto maximize the expected discounted value of dividends which are paid to the\nshareholders until the company is ruined. We show that under some conditions\nthe optimal dividend strategy is formed by a barrier strategy.\n"
    },
    {
        "paper_id": 1305.1868,
        "authors": "Jiang-Lun Wu, Wei Yang",
        "title": "A Galerkin approximation scheme for the mean correction in a\n  mean-reversion stochastic differential equation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is concerned with the following Markovian stochastic differential\nequation of mean-reversion type \\[ dR_t= (\\theta +\\sigma \\alpha(R_t, t))R_t dt\n+\\sigma R_t dB_t \\] with an initial value $R_0=r_0\\in\\mathbb{R}$, where\n$\\theta\\in\\mathbb{R}$ and $\\sigma>0$ are constants, and the mean correction\nfunction $\\alpha:\\mathbb{R}\\times[0,\\infty)\\to \\alpha(x,t)\\in\\mathbb{R}$ is\ntwice continuously differentiable in $x$ and continuously differentiable in\n$t$. We first derive that under the assumption of path independence of the\ndensity process of Girsanov transformation for the above stochastic\ndifferential equation, the mean correction function $\\alpha$ satisfies a\nnon-linear partial differential equation which is known as the viscous Burgers\nequation. We then develop a Galerkin type approximation scheme for the function\n$\\alpha$ by utilizing truncation of discretised Fourier transformation to the\nviscous Burgers equation.\n"
    },
    {
        "paper_id": 1305.2121,
        "authors": "Anirban Chakraborti, Damien Challet, Arnab Chatterjee, Matteo Marsili,\n  Yi-Cheng Zhang, Bikas K. Chakrabarti",
        "title": "Statistical Mechanics of Competitive Resource Allocation using\n  Agent-based Models",
        "comments": "24 pages, 4 figures, review article; Accepted in Physics Reports",
        "journal-ref": "Physics Reports 552 (2015) 1-25",
        "doi": "10.1016/j.physrep.2014.09.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Demand outstrips available resources in most situations, which gives rise to\ncompetition, interaction and learning. In this article, we review a broad\nspectrum of multi-agent models of competition (El Farol Bar problem, Minority\nGame, Kolkata Paise Restaurant problem, Stable marriage problem, Parking space\nproblem and others) and the methods used to understand them analytically. We\nemphasize the power of concepts and tools from statistical mechanics to\nunderstand and explain fully collective phenomena such as phase transitions and\nlong memory, and the mapping between agent heterogeneity and physical disorder.\nAs these methods can be applied to any large-scale model of competitive\nresource allocation made up of heterogeneous adaptive agent with non-linear\ninteraction, they provide a prospective unifying paradigm for many scientific\ndisciplines.\n"
    },
    {
        "paper_id": 1305.2151,
        "authors": "Zachary Feinstein and Birgit Rudloff",
        "title": "A comparison of techniques for dynamic multivariate risk measures",
        "comments": null,
        "journal-ref": "In: A. Hamel, F. Heyde, A. L{\\\"o}hne, B. Rudloff, C. Schrage\n  (eds.): Set Optimization and Applications in Finance - The State of the Art,\n  Springer PROMS series, Vol. 151, 3-41, (2015). ISBN: 978-3-662-48668-9",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper contains an overview of results for dynamic multivariate risk\nmeasures. We provide the main results of four different approaches. We will\nprove under which assumptions results within these approaches coincide, and how\nproperties like primal and dual representation and time consistency in the\ndifferent approaches compare to each other.\n"
    },
    {
        "paper_id": 1305.2263,
        "authors": "Yuichi Ikeda, Hideaki Aoyama, Hiroshi Iyetomi, Hiroshi Yoshikawa",
        "title": "Direct Evidence for Synchronization in Japanese Business Cycle",
        "comments": "14 pages, 9 figures, submitted to Evolutionary and Institutional\n  Economics Review",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have analyzed the Indices of Industrial Production (Seasonal Adjustment\nIndex) for a long period of 240 months (January 1988 to December 2007) to\ndevelop a deeper understanding of the economic shocks. The angular frequencies\nestimated using the Hilbert transformation, are almost identical for the 16\nindustrial sectors. Moreover, the partial phase locking was observed for the 16\nsectors. These are the direct evidence of the synchronization in the Japanese\nbusiness cycle. We also showed that the information of the economic shock is\ncarried by the phase time-series. The common shock and individual shocks are\nseparated using phase time-series. The former dominates the economic shock in\nall of 1992, 1998 and 2001. The obtained results suggest that the business\ncycle may be described as a dynamics of the coupled limit-cycle oscillators\nexposed to the common shocks and random individual shocks.\n"
    },
    {
        "paper_id": 1305.2271,
        "authors": "Keita Owari",
        "title": "On the Lebesgue Property of Monotone Convex Functions",
        "comments": "8 pages, to appear in Mathematics and Financial Economics",
        "journal-ref": "Mathematics and Financial Economics, 8, Issue 2, pp 159-167, 2014",
        "doi": "10.1007/s11579-013-0111-z",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Lebesgue property (order-continuity) of a monotone convex function on a\nsolid vector space of measurable functions is characterized in terms of (1) the\nweak inf-compactness of the conjugate function on the order-continuous dual\nspace, (2) the attainment of the supremum in the dual representation by\norder-continuous linear functionals. This generalizes and unifies several\nrecent results obtained in the context of convex risk measures.\n"
    },
    {
        "paper_id": 1305.2655,
        "authors": "Jongwook Kim and Junghyo Jo",
        "title": "An Exactly Solvable Discrete Stochastic Process with Correlated\n  Properties",
        "comments": "4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a correlated stochastic process of which the novel non-Gaussian\nprobability mass function is constructed by exactly solving moment generating\nfunction. The calculation of cumulants and auto-correlation shows that the\nprocess is convergent and scale invariant in the large but finite number limit.\nWe demonstrate that the model consistently explains both the distribution and\nthe correlation of discrete financial time-series data, and predicts the data\ndistribution with high precision in the small number regime.\n"
    },
    {
        "paper_id": 1305.2693,
        "authors": "St\\'ephane Goutte (LPMA)",
        "title": "Markov switching quadratic term structure models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we consider a discrete time economy where we assume that the\nshort term interest rate follows a quadratic term structure of a regime\nswitching asset process. The possible non-linear structure and the fact that\nthe interest rate can have different economic or financial trends justify the\ninterest of Regime Switching Quadratic Term Structure Model (RS-QTSM). Indeed,\nthis regime switching process depends on the values of a Markov chain with a\ntime dependent transition probability matrix which can well captures the\ndifferent states (regimes) of the economy. We prove that under this modelling\nthat the conditional zero coupon bond price admits also a quadratic term\nstructure. Moreover, the stochastic coefficients which appear in this\ndecomposition satisfy an explicit system of coupled stochastic backward\nrecursions.\n"
    },
    {
        "paper_id": 1305.2716,
        "authors": "Tijana Radivojevi\\'c, Jonatha Anselmi, Enrico Scalas",
        "title": "Ergodic transition in a simple model of the continuous double auction",
        "comments": "10 pages, 5 figures, 1 table",
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0088095",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a phenomenological model for the continuous double auction,\nequivalent to two independent $M/M/1$ queues. The continuous double auction\ndefines a continuous-time random walk for trade prices. The conditions for\nergodicity of the auction are derived and, as a consequence, three possible\nregimes in the behavior of prices and logarithmic returns are observed. In the\nergodic regime, prices are unstable and one can observe an intermittent\nbehavior in the logarithmic returns. On the contrary, non-ergodicity triggers\nstability of prices, even if two different regimes can be seen.\n"
    },
    {
        "paper_id": 1305.2824,
        "authors": "Gerard Keogh",
        "title": "The Statistical and Econometric Analysis of Asylum Application Trends\n  and their relationship to GDP in the EEA",
        "comments": "23 pages, 3 figures, 2 tables, 5 appendix tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The sharp decline in Ireland's economic performance in recent years has\ncoincided with a recent fall in asylum applications. Simultaneously countries\nsuch as Switzerland are seeing increases in asylum numbers with evidence for\ngreater numbers of Nigerian applicants, a group that have for some time been\nthe largest nationality group applying in Ireland. A possible reason for this\nshift in asylum seeker preference is the general economic conditions here\nversus those in other European countries. In this paper we investigate whether\nthis belief holds water. We model asylum applications as a function of GDP\nusing a time varying parameter multiplicative growth model. Our results show\nthere is an economic basis for asylum seeker preferences. We further show there\nis no regional basis for asylum seekers' expectation of a more favourable claim\nin the 'developed box' in central Europe as compared to countries on the\nso-called 'periphery'.\n"
    },
    {
        "paper_id": 1305.3184,
        "authors": "Tetsuya Takaishi",
        "title": "Empirical Analysis of Stochastic Volatility Model by Hybrid Monte Carlo\n  Algorithm",
        "comments": "10 pages, 5 figures",
        "journal-ref": "Journal of Physics: Conference Series 423 (2013) 012021",
        "doi": "10.1088/1742-6596/423/1/012021",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The stochastic volatility model is one of volatility models which infer\nlatent volatility of asset returns. The Bayesian inference of the stochastic\nvolatility (SV) model is performed by the hybrid Monte Carlo (HMC) algorithm\nwhich is superior to other Markov Chain Monte Carlo methods in sampling\nvolatility variables. We perform the HMC simulations of the SV model for two\nliquid stock returns traded on the Tokyo Stock Exchange and measure the\nvolatilities of those stock returns. Then we calculate the accuracy of the\nvolatility measurement using the realized volatility as a proxy of the true\nvolatility and compare the SV model with the GARCH model which is one of other\nvolatility models. Using the accuracy calculated with the realized volatility\nwe find that empirically the SV model performs better than the GARCH model.\n"
    },
    {
        "paper_id": 1305.3243,
        "authors": "Marco Zamparo, Fulvio Baldovin, Michele Caraglio, Attilio L. Stella",
        "title": "Scaling symmetry, renormalization, and time series modeling",
        "comments": "Main text (17 pages, 13 figures) plus Supplementary Material (16\n  pages, 5 figures)",
        "journal-ref": "Phys. Rev. E 88, 062808 (2013)",
        "doi": "10.1103/PhysRevE.88.062808",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present and discuss a stochastic model of financial assets dynamics based\non the idea of an inverse renormalization group strategy. With this strategy we\nconstruct the multivariate distributions of elementary returns based on the\nscaling with time of the probability density of their aggregates. In its\nsimplest version the model is the product of an endogenous auto-regressive\ncomponent and a random rescaling factor designed to embody also exogenous\ninfluences. Mathematical properties like increments' stationarity and\nergodicity can be proven. Thanks to the relatively low number of parameters,\nmodel calibration can be conveniently based on a method of moments, as\nexemplified in the case of historical data of the S&P500 index. The calibrated\nmodel accounts very well for many stylized facts, like volatility clustering,\npower law decay of the volatility autocorrelation function, and multiscaling\nwith time of the aggregated return distribution. In agreement with empirical\nevidence in finance, the dynamics is not invariant under time reversal and,\nwith suitable generalizations, skewness of the return distribution and leverage\neffects can be included. The analytical tractability of the model opens\ninteresting perspectives for applications, for instance in terms of obtaining\nclosed formulas for derivative pricing. Further important features are: The\npossibility of making contact, in certain limits, with auto-regressive models\nwidely used in finance; The possibility of partially resolving the long-memory\nand short-memory components of the volatility, with consistent results when\napplied to historical series.\n"
    },
    {
        "paper_id": 1305.3433,
        "authors": "L C G Rogers and Pawel Zaczkowski",
        "title": "Monte Carlo approximation to optimal investment",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper sets up a methodology for approximately solving optimal investment\nproblems using duality methods combined with Monte Carlo simulations. In\nparticular, we show how to tackle high dimensional problems in incomplete\nmarkets, where traditional methods fail due to the curse of dimensionality.\n"
    },
    {
        "paper_id": 1305.3988,
        "authors": "Christian Bender and Nikolai Dokuchaev",
        "title": "A First-Order BSPDE for Swing Option Pricing",
        "comments": null,
        "journal-ref": "Mathematical Finance, Vol. 26, 461-491, 2016",
        "doi": "10.1111/mafi.12067",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study an optimal control problem related to swing option pricing in a\ngeneral non-Markovian setting in continuous time. As a main result we show that\nthe value process solves a first-order non-linear backward stochastic partial\ndifferential equation. Based on this result we can characterize the set of\noptimal controls and derive a dual minimization problem.\n"
    },
    {
        "paper_id": 1305.4013,
        "authors": "Alexander Schied and Tao Zhang",
        "title": "A market impact game under transient price impact",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a Nash equilibrium between two high-frequency traders in a simple\nmarket impact model with transient price impact and additional quadratic\ntransaction costs. Extending a result by Sch\\\"oneborn (2008), we prove\nexistence and uniqueness of the Nash equilibrium and show that for small\ntransaction costs the high-frequency traders engage in a \"hot-potato game\", in\nwhich the same asset position is sold back and forth. We then identify a\ncritical value for the size of the transaction costs above which all\noscillations disappear and strategies become buy-only or sell-only. Numerical\nsimulations show that for both traders the expected costs can be lower with\ntransaction costs than without. Moreover, the costs can increase with the\ntrading frequency when there are no transaction costs, but decrease with the\ntrading frequency when transaction costs are sufficiently high. We argue that\nthese effects occur due to the need of protection against predatory trading in\nthe regime of low transaction costs.\n"
    },
    {
        "paper_id": 1305.4078,
        "authors": "Dirk Helbing",
        "title": "Economics 2.0: The Natural Step towards A Self-Regulating, Participatory\n  Market Society",
        "comments": "For related work see http://www.soms.ethz.ch and\n  http://www.futurict.eu",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Despite all our great advances in science, technology and financial\ninnovations, many societies today are struggling with a financial, economic and\npublic spending crisis, over-regulation, and mass unemployment, as well as lack\nof sustainability and innovation. Can we still rely on conventional economic\nthinking or do we need a new approach?\n  I argue that, as the complexity of socio-economic systems increases,\nnetworked decision-making and bottom-up self-regulation will be more and more\nimportant features. It will be explained why, besides the \"homo economicus\"\nwith strictly self-regarding preferences, natural selection has also created a\n\"homo socialis\" with other-regarding preferences. While the \"homo economicus\"\noptimizes the own prospects in separation, the decisions of the \"homo socialis\"\nare self-determined, but interconnected, a fact that may be characterized by\nthe term \"networked minds\". Notably, the \"homo socialis\" manages to earn higher\npayoffs than the \"homo economicus\".\n  I show that the \"homo economicus\" and the \"homo socialis\" imply a different\nkind of dynamics and distinct aggregate outcomes. Therefore, next to the\ntraditional economics for the \"homo economicus\" (\"economics 1.0\"), a\ncomplementary theory must be developed for the \"homo socialis\". This economic\ntheory might be called \"economics 2.0\" or \"socionomics\". The names are\njustified, because the Web 2.0 is currently promoting a transition to a new\nmarket organization, which benefits from social media platforms and could be\ncharacterized as \"participatory market society\". To thrive, the \"homo socialis\"\nrequires suitable institutional settings such a particular kinds of reputation\nsystems, which will be sketched in this paper. I also propose a new kind of\nmoney, so-called \"qualified money\", which may overcome some of the problems of\nour current financial system.\n"
    },
    {
        "paper_id": 1305.4132,
        "authors": "Jacek Jakubowski and Mariusz Niew\\k{e}g{\\l}owski",
        "title": "Risk-minimization and hedging claims on a jump-diffusion market model,\n  Feynman-Kac Theorem and PIDE",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  At first, we solve a problem of finding a risk-minimizing hedging strategy on\na general market with ratings. Next, we find a solution to this problem on\nMarkovian market with ratings on which prices are influenced by additional\nfactors and rating, and behavior of this system is described by SDE driven by\nWiener process and compensated Poisson random measure and claims depend on\nrating. To find a tool to calculate hedging strategy we prove a Feynman-Kac\ntype theorem. This result is of independent interest and has many applications,\nsince it enables to calculate some conditional expectations using related\nPIDE's. We illustrate our theory on two examples of market. The first is a\ngeneral exponential L\\'{e}vy model with stochastic volatility, and the second\nis a generalization of exponential L\\'{e}vy model with regime-switching.\n"
    },
    {
        "paper_id": 1305.4173,
        "authors": "Tao Ma and R. A. Serota",
        "title": "A Model for Stock Returns and Volatility",
        "comments": "17 pages, 30 figures, 2 tables",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.11.032",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove that Student's t-distribution provides one of the better fits to\nreturns of S&P component stocks and the generalized inverse gamma distribution\nbest fits VIX and VXO volatility data. We further argue that a more accurate\nmeasure of the volatility may be possible based on the fact that stock returns\ncan be understood as the product distribution of the volatility and normal\ndistributions. We find Brown noise in VIX and VXO time series and explain the\nmean and the variance of the relaxation times on approach to the steady-state\ndistribution.\n"
    },
    {
        "paper_id": 1305.4321,
        "authors": "Helin Zhu, Fan Ye, Enlu Zhou",
        "title": "Fast Estimation of True Bounds on Bermudan Option Prices under\n  Jump-diffusion Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Fast pricing of American-style options has been a difficult problem since it\nwas first introduced to financial markets in 1970s, especially when the\nunderlying stocks' prices follow some jump-diffusion processes. In this paper,\nwe propose a new algorithm to generate tight upper bounds on the Bermudan\noption price without nested simulation, under the jump-diffusion setting. By\nexploiting the martingale representation theorem for jump processes on the dual\nmartingale, we are able to explore the unique structure of the optimal dual\nmartingale and construct an approximation that preserves the martingale\nproperty. The resulting upper bound estimator avoids the nested Monte Carlo\nsimulation suffered by the original primal-dual algorithm, therefore\nsignificantly improves the computational efficiency. Theoretical analysis is\nprovided to guarantee the quality of the martingale approximation. Numerical\nexperiments are conducted to verify the efficiency of our proposed algorithm.\n"
    },
    {
        "paper_id": 1305.4719,
        "authors": "Jos\\'e E. Figueroa-L\\'opez, Ruoting Gong, Christian Houdr\\'e",
        "title": "Third-Order Short-Time Expansions for Close-to-the-Money Option Prices\n  under the CGMY Model",
        "comments": "22 pages, 7 figures, 1 table. This paper extends a previous\n  submission [arXiv:1112.3111] to a third-order approximation. In the latest\n  version, we generalized the ATM third-order approximation to the\n  close-to-the-money case for both the pure-jump CGMY model and the CGMY model\n  with an additional independent Brownian component",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A third-order approximation for close-to-the-money European option prices\nunder an infinite-variation CGMY L\\'{e}vy model is derived, and is then\nextended to a model with an additional independent Brownian component. The\nasymptotic regime considered, in which the strike is made to converge to the\nspot stock price as the maturity approaches zero, is relevant in applications\nsince the most liquid options have strikes that are close to the spot price.\nOur results shed new light on the connection between both the volatility of the\ncontinuous component and the jump parameters and the behavior of option prices\nnear expiration when the strike is close to the spot price. In particular, a\nnew type of transition phenomenon is uncovered in which the third order term\nexhibits two distinct asymptotic regimes depending on whether $Y\\in(1,3/2)$ or\n$Y\\in(3/2,2)$. Unlike second order approximations, the expansions herein are\nshown to be remarkably accurate so that they can actually be used for\ncalibrating some model parameters. For illustration, we calibrate the\nvolatility $\\sigma$ of the Brownian component and the jump intensity $C$ of the\nCGMY model to actual option prices.\n"
    },
    {
        "paper_id": 1305.4879,
        "authors": "Gilles Edouard Espinosa (CERMICS), Caroline Hillairet (CMAP), Benjamin\n  Jourdain (CERMICS, MATHRISK), Monique Pontier (IMT)",
        "title": "Reducing the debt : is it optimal to outsource an investment?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We deal with the problem of outsourcing the debt for a big investment,\naccording two situations: either the firm outsources both the investment (and\nthe associated debt) and the exploitation to a private consortium, or the firm\nsupports the debt and the investment but outsources the exploitation. We prove\nthe existence of Stackelberg and Nash equilibria between the firm and the\nprivate consortium, in both situations. We compare the benefits of these\ncontracts. We conclude with a study of what happens in case of incomplete\ninformation, in the sense that the risk aversion coefficient of each partner\nmay be unknown by the other partner.\n"
    },
    {
        "paper_id": 1305.522,
        "authors": "Jan-Frederik Mai, Marc Wittlinger",
        "title": "Pricing bonds with optional sinking feature using Markov Decision\n  Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An efficient method to price bonds with optional sinking feature is\npresented. Such instruments equip their issuer with the option (but not the\nobligation) to redeem parts of the notional prior to maturity, therefore the\nfuture cash flows are random. In a one-factor model for the issuer's default\nintensity we show that the pricing algorithm can be formulated as a Markov\nDecision Process, which is both accurate and quick. The method is demonstrated\nusing a 1.5-factor credit-equity model which defines the default intensity in a\nreciprocal relationship to the issuer's stock price process, termed\njump-to-default extended model with constant elasticity of variance (JDCEV).\n"
    },
    {
        "paper_id": 1305.5238,
        "authors": "Taiane S. Prass and S\\'ilvia R.C. Lopes",
        "title": "Risk Measure Estimation On Fiegarch Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the Fractionally Integrated Exponential Generalized\nAutoregressive Conditional Heteroskedasticity process, denoted by\nFIEGARCH(p,d,q), introduced by Bollerslev and Mikkelsen (1996). We present a\nsimulated study regarding the estimation of the risk measure $VaR_p$ on\nFIEGARCH processes. We consider the distribution function of the portfolio\nlog-returns (univariate case) and the multivariate distribution function of the\nrisk-factor changes (multivariate case). We also compare the performance of the\nrisk measures $VaR_p$, $ES_p$ and MaxLoss for a portfolio composed by stocks of\nfour Brazilian companies.\n"
    },
    {
        "paper_id": 1305.5373,
        "authors": "Peter Stallinga",
        "title": "Mathematical Analysis of Money in the Scope of Austerity",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This summarizes the study of the financial and economic crisis in Europe. The\nstarting questions were: 1) Why do we have a crisis? Unde venis? 2) What will\nbe the outcome? Quo vadis? Here is the reasoning which touches many areas,\nranging from financial to politics and from psychology and economy.\n"
    },
    {
        "paper_id": 1305.5575,
        "authors": "Lijun Bo and Agostino Capponi",
        "title": "Bilateral Credit Valuation Adjustment for Large Credit Derivatives\n  Portfolios",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We obtain an explicit formula for the bilateral counterparty valuation\nadjustment of a credit default swaps portfolio referencing an asymptotically\nlarge number of entities. We perform the analysis under a doubly stochastic\nintensity framework, allowing for default correlation through a common jump\nprocess. The key insight behind our approach is an explicit characterization of\nthe portfolio exposure as the weak limit of measure-valued processes associated\nto survival indicators of portfolio names. We validate our theoretical\npredictions by means of a numerical analysis, showing that counterparty\nadjustments are highly sensitive to portfolio credit risk volatility as well as\nto default correlation.\n"
    },
    {
        "paper_id": 1305.5621,
        "authors": "Jan Kallsen, Paul Kr\\\"uhner",
        "title": "On a Heath-Jarrow-Morton approach for stock options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper aims at transferring the philosophy behind Heath-Jarrow-Morton to\nthe modelling of call options with all strikes and maturities. Contrary to the\napproach by Carmona and Nadtochiy (2009) and related to the recent contribution\nCarmona and Nadtochiy (2012) by the same authors, the key parametrisation of\nour approach involves time-inhomogeneous L\\'evy processes instead of local\nvolatility models. We provide necessary and sufficient conditions for absence\nof arbitrage. Moreover we discuss the construction of arbitrage-free models.\nSpecifically, we prove their existence and uniqueness given basic building\nblocks.\n"
    },
    {
        "paper_id": 1305.5656,
        "authors": "Dimitri O. Ledenyov and Viktor O. Ledenyov",
        "title": "To the problem of turbulence in quantitative easing transmission\n  channels and transactions network channels at quantitative easing policy\n  implementation by central banks",
        "comments": "40 pages, 26 figures, 10 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In agreement with the recent research findings in the econophysics, we\npropose that the nonlinear dynamic chaos can be generated by the turbulent\ncapital flows in both the quantitative easing transmission channels and the\ntransaction networks channels, when there are the laminar turbulent capital\nflows transitions in the financial system. We demonstrate that the capital\nflows in both the quantitative easing transmission channels and the transaction\nnetworks channels in the financial system can be accurately characterized by\nthe Reynolds numbers. We explain that the transition to the nonlinear dynamic\nchaos regime can be realized through the cascade of the Landau, Hopf\nbifurcations in the turbulent capital flows in both the quantitative easing\ntransmission channels and the transaction networks channels in the financial\nsystem. We completed the computer modeling, using both the Nonlinear Dynamic\nStochastic General Equilibrium Theory (NDSGET) and the Hydrodynamics Theory\n(HT), to accurately characterize the US economy in the conditions of the QE\npolicy implementation by the US Federal Reserve. We found that the ability of\nthe US financial system to adjust to the different levels of liquidity depends\non the nonlinearities appearance in the QE transmission channels, and is\nlimited by the laminar turbulent capital flows transitions in the QE\ntransmission channels and the transaction networks channels in the US financial\nsystem. The proposed computer model allows us to make the accurate forecasts of\nthe US economy performance in the cases, when there are the different levels of\nliquidity in the US financial system.\n"
    },
    {
        "paper_id": 1305.5915,
        "authors": "Alexander Schied",
        "title": "Model-free CPPI",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider Constant Proportion Portfolio Insurance (CPPI) and its dynamic\nextension, which may be called Dynamic Proportion Portfolio Insurance (DPPI).\nIt is shown that these investment strategies work within the setting of\nF\\\"ollmer's pathwise It\\^o calculus, which makes no probabilistic assumptions\nwhatsoever. This shows, on the one hand, that CPPI and DPPI are completely\nindependent of any choice of a particular model for the dynamics of asset\nprices. They even make sense beyond the class of semimartingale sample paths\nand can be successfully defined for models admitting arbitrage, including some\nmodels based on fractional Brownian motion. On the other hand, the result can\nbe seen as a case study for the general issue of robustness in the face of\nmodel uncertainty in finance.\n"
    },
    {
        "paper_id": 1305.5958,
        "authors": "Vygintas Gontis, Aleksejus Kononovicius",
        "title": "Fluctuation analysis of the three agent groups herding model",
        "comments": "9 pages, 2 figures",
        "journal-ref": "2013 22nd International Conference on Noise and Fluctuations\n  (ICNF)",
        "doi": "10.1109/ICNF.2013.6578896",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive a system of stochastic differential equations simulating the\ndynamics of the three agent groups with herding interaction. Proposed approach\ncan be valuable in the modeling of the complex socio-economic systems with\nsimilar composition of the agents. We demonstrate how the sophisticated\nstatistical features of the absolute return in the financial markets can be\nreproduced by extending the herding interaction of the agents and introducing\nthe third agent state. As well we consider possible extension of proposed\nherding model introducing additional exogenous noise. Such consistent\nmicroscopic and macroscopic model precisely reproduces empirical power law\nstatistics of the return in the financial markets.\n"
    },
    {
        "paper_id": 1305.5963,
        "authors": "Jarno Talponen and Lauri Viitasaari",
        "title": "Note on multidimensional Breeden-Litzenberger representation for state\n  price densities",
        "comments": null,
        "journal-ref": "Mathematics and Financial Economics 8:153-157, 2014",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note, we consider European options of type $h(X^1_T, X^2_T,\\ldots,\nX^n_T)$ depending on several underlying assets. We give a multidimensional\nversion of the result of Breeden and Litzenberger \\cite{Breeden} on the\nrelation between derivatives of the call price and the risk-neutral density of\nthe underlying asset. The pricing measure is assumed to be absolutely\ncontinuous with respect to the Lebesgue measure on the state space.\n"
    },
    {
        "paper_id": 1305.6008,
        "authors": "Bruno Bouchard, Marcel Nutz",
        "title": "Arbitrage and duality in nondominated discrete-time models",
        "comments": "Published in at http://dx.doi.org/10.1214/14-AAP1011 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 2, 823-859",
        "doi": "10.1214/14-AAP1011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a nondominated model of a discrete-time financial market where\nstocks are traded dynamically, and options are available for static hedging. In\na general measure-theoretic setting, we show that absence of arbitrage in a\nquasi-sure sense is equivalent to the existence of a suitable family of\nmartingale measures. In the arbitrage-free case, we show that optimal\nsuperhedging strategies exist for general contingent claims, and that the\nminimal superhedging price is given by the supremum over the martingale\nmeasures. Moreover, we obtain a nondominated version of the Optional\nDecomposition Theorem.\n"
    },
    {
        "paper_id": 1305.6023,
        "authors": "Keita Owari",
        "title": "A Robust Version of Convex Integral Functionals",
        "comments": "Minor typos are corrected. To appear in Journal of Convex Analysis",
        "journal-ref": "J. Convex Anal. 22 (2015), no. 3, 827-852",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the pointwise supremum of convex integral functionals\n$\\mathcal{I}_{f,\\gamma}(\\xi)= \\sup_{Q} \\left( \\int_\\Omega\nf(\\omega,\\xi(\\omega))Q(d\\omega)-\\gamma(Q)\\right)$ on\n$L^\\infty(\\Omega,\\mathcal{F},\\mathbb{P})$ where\n$f:\\Omega\\times\\mathbb{R}\\rightarrow\\overline{\\mathbb{R}}$ is a proper normal\nconvex integrand, $\\gamma$ is a proper convex function on the set of\nprobability measures absolutely continuous w.r.t. $\\mathbb{P}$, and the\nsupremum is taken over all such measures. We give a pair of upper and lower\nbounds for the conjugate of $\\mathcal{I}_{f,\\gamma}$ as direct sums of a common\nregular part and respective singular parts; they coincide when\n$\\mathrm{dom}(\\gamma)=\\{\\mathbb{P}\\}$ as Rockafellar's result, while both\ninequalities can generally be strict. We then investigate when the conjugate\neliminates the singular measures, which a fortiori yields the equality in\nbounds, and its relation to other finer regularity properties of the original\nfunctional and of the conjugate.\n"
    },
    {
        "paper_id": 1305.6037,
        "authors": "Tshilidzi Marwala",
        "title": "Semi-bounded Rationality: A model for decision making",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper the theory of semi-bounded rationality is proposed as an\nextension of the theory of bounded rationality. In particular, it is proposed\nthat a decision making process involves two components and these are the\ncorrelation machine, which estimates missing values, and the causal machine,\nwhich relates the cause to the effect. Rational decision making involves using\ninformation which is almost always imperfect and incomplete as well as some\nintelligent machine which if it is a human being is inconsistent to make\ndecisions. In the theory of bounded rationality this decision is made\nirrespective of the fact that the information to be used is incomplete and\nimperfect and the human brain is inconsistent and thus this decision that is to\nbe made is taken within the bounds of these limitations. In the theory of\nsemi-bounded rationality, signal processing is used to filter noise and\noutliers in the information and the correlation machine is applied to complete\nthe missing information and artificial intelligence is used to make more\nconsistent decisions.\n"
    },
    {
        "paper_id": 1305.6148,
        "authors": "Jean-Bernard Chatelain (CES, EEP-PSE, UP1)",
        "title": "Goodhart, Charles A.E. and Tsomocos, Dimitros P.: The challenge of\n  financial stability: a new model and its applications",
        "comments": "nombre de pages: 5",
        "journal-ref": "Journal of Economics 109, 2 (2013) 201-205",
        "doi": "10.1007/s00712-013-0345-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This review of the book \"The Challenge of Financial Stability: A New Model\nand its Applications\" by Goodhart C.A.E. and Tsomocos D.P. highlights the\npotential of the framework of strategic partial default of banks with credit\nchain on the interbank market for further theoretical and applied research on\nfinancial stability.\n"
    },
    {
        "paper_id": 1305.6323,
        "authors": "Aim\\'e Lachapelle, Jean-Michel Lasry, Charles-Albert Lehalle,\n  Pierre-Louis Lions",
        "title": "Efficiency of the Price Formation Process in Presence of High Frequency\n  Participants: a Mean Field Game analysis",
        "comments": "28 pages, 11 Figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with a stochastic order-driven market model with waiting\ncosts, for order books with heterogenous traders. Offer and demand of liquidity\ndrives price formation and traders anticipate future evolutions of the order\nbook. The natural framework we use is mean field game theory, a class of\nstochastic differential games with a continuum of anonymous players. Several\nsources of heterogeneity are considered including the mean size of orders. Thus\nwe are able to consider the coexistence of Institutional Investors and High\nFrequency Traders (HFT). We provide both analytical solutions and numerical\nexperiments. Implications on classical quantities are explored: order book\nsize, prices, and effective bid/ask spread. According to the model, in markets\nwith Institutional Investors only we show the existence of inefficient\nliquidity imbalances in equilibrium, with two symmetrical situations\ncorresponding to what we call liquidity calls for liquidity. During these\nsituations the transaction price significantly moves away from the fair price.\nHowever this macro phenomenon disappears in markets with both Institutional\nInvestors and HFT, although a more precise study shows that the benefits of the\nnew situation go to HFT only, leaving Institutional Investors even with higher\ntrading costs.\n"
    },
    {
        "paper_id": 1305.6541,
        "authors": "Stefan Ankirchner and Monique Jeanblanc and Thomas Kruse",
        "title": "BSDEs with singular terminal condition and control problems with\n  constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a probabilistic solution of a not necessarily Markovian control\nproblem with a state constraint by means of a Backward Stochastic Differential\nEquation (BSDE). The novelty of our solution approach is that the BSDE\npossesses a singular terminal condition. We prove that a solution of the BSDE\nexists, thus partly generalizing existence results obtained by Popier in [7]\nand [8]. We perform a verification and discuss special cases for which the\ncontrol problem has explicit solutions.\n"
    },
    {
        "paper_id": 1305.6762,
        "authors": "Terje Lensberg and Klaus Reiner Schenk-Hopp\\'e",
        "title": "Hedging without sweat: a genetic programming approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Hedging in the presence of transaction costs leads to complex optimization\nproblems. These problems typically lack closed-form solutions, and their\nimplementation relies on numerical methods that provide hedging strategies for\nspecific parameter values. In this paper we use a genetic programming algorithm\nto derive explicit formulas for near-optimal hedging strategies under nonlinear\ntransaction costs. The strategies are valid over a large range of parameter\nvalues and require no information about the structure of the optimal hedging\nstrategy.\n"
    },
    {
        "paper_id": 1305.6765,
        "authors": "J.D. Deuschel, P.K. Friz, A. Jacquier, S. Violante",
        "title": "Marginal density expansions for diffusions and stochastic volatility,\n  part II: Applications [to the Stein--Stein model]",
        "comments": "to appear in Comm. Pure Appl. Math",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the compagnion paper [Marginal density expansions for diffusions and\nstochastic volatility, part I] we discussed density expansions for\nmultidimensional diffusions $(X^1,...,X^d)$, at fixed time $T$ and projected to\ntheir first $l$ coordinates, in the small noise regime. Global conditions were\nfound which replace the well-known \"not-in-cutlocus\" condition known from\nheat-kernel asymptotics. In the present paper we discuss financial\napplications; these include tail and implied volatility asymptotics in some\ncorrelated stochastic volatility models. In particular, we solve a problem left\nopen by A. Gulisashvili and E.M. Stein (2009).\n"
    },
    {
        "paper_id": 1305.6797,
        "authors": "Tomasz Gubiec and Ryszard Kutner",
        "title": "Continuous-Time Random Walk with multi-step memory: An application to\n  market dynamics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A novel version of the Continuous-Time Random Walk (CTRW) model with memory\nis developed. This memory means the dependence between arbitrary number of\nsuccessive jumps of the process, while waiting times between jumps are\nconsidered as i.i.d. random variables. The dependence was found by analysis of\nempirical histograms for the stochastic process of a single share price on a\nmarket within the high frequency time scale, and justified theoretically by\nconsidering bid-ask bounce mechanism containing some delay characteristic for\nany double-auction market. Our model turns out to be exactly analytically\nsolvable, which enables a direct comparison of its predictions with their\nempirical counterparts, for instance, with empirical velocity autocorrelation\nfunction. Thus this paper significantly extends the capabilities of the CTRW\nformalism.\n"
    },
    {
        "paper_id": 1305.6831,
        "authors": "Vladimir Cherny and Jan Obloj",
        "title": "Optimal portfolios of a long-term investor with floor or drawdown\n  constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the portfolio selection problem of a long-run investor who is\nmaximising the asymptotic growth rate of her expected utility. We show that,\nsomewhat surprisingly, it is essentially not affected by introduction of a\nfloor constraint which requires the wealth process to dominate a given\nbenchmark at all times. We further study the notion of long-run optimality of\nwealth processes via convergence of finite horizon value functions to the\nasymptotic optimal value. We characterise long-run optimality under floor and\ndrawdown constraints.\n"
    },
    {
        "paper_id": 1305.6868,
        "authors": "Hyong-Chol O, Yong-Gon Kim and Dong-Hyok Kim",
        "title": "Higher Order Binaries with Time Dependent Coefficients and Two Factors -\n  Model for Defaultable Bond with Discrete Default Information",
        "comments": "20 pages, 10 figures, corrected errors of ver.1, added the results on\n  the case with endogenous default recovery and credit spread analysis with\n  graphs. This version is a continued study and development of\n  arXiv:1305.6988v4[q-fin.PR]",
        "journal-ref": null,
        "doi": "10.2139/ssrn.2337865",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we consider a 2 factors-model for pricing defaultable bond\nwith discrete default intensity and barrier where the 2 factors are stochastic\nrisk free short rate process and firm value process. We assume that the default\nevent occurs in an expected manner when the firm value reaches a given default\nbarrier at predetermined discrete announcing dates or in an unexpected manner\nat the first jump time of a Poisson process with given default intensity given\nby a step function of time variable. Then our pricing model is given by a\nsolving problem of several linear PDEs with variable coefficients and terminal\nvalue of binary type in every subinterval between the two adjacent announcing\ndates. Our main approach is to use higher order binaries. We first provide the\npricing formulae of higher order binaries with time dependent coefficients and\nconsider their integrals on the last expiry date variable. Then using the\npricing formulae of higher binary options and their integrals, we give the\npricing formulae of defaultable bonds in both cases of exogenous and endogenous\ndefault recoveries and credit spread analysis.\n"
    },
    {
        "paper_id": 1305.6988,
        "authors": "Hyong-Chol O, Dong-Hyok Kim, Jong-Jun Jo and Song-Hun Ri",
        "title": "Integrals of Higher Binary Options and Defaultable Bond with Discrete\n  Default Information",
        "comments": "27 pages, 18 figures; ver 5 writen in laTex and corrected typos in\n  previous versions. arXiv admin note: substantial text overlap with\n  arXiv:1305.6868",
        "journal-ref": null,
        "doi": "10.2139/ssrn.726624",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we study the problem of pricing defaultable bond with\ndiscrete default intensity and barrier under constant risk free short rate\nusing higher order binary options and their integrals. In our credit risk\nmodel, the risk free short rate is a constant and the default event occurs in\nan expected manner when the firm value reaches a given default barrier at\npredetermined discrete announcing dates or in an unexpected manner at the first\njump time of a Poisson process with given default intensity given by a step\nfunction of time variable, respectively. We consider both endogenous and\nexogenous default recovery. Our pricing problem is derived to a solving problem\nof inhomogeneous or homogeneous Black-Scholes PDEs with different coefficients\nand terminal value of binary type in every subinterval between the two adjacent\nannouncing dates. In order to deal with the difference of coefficients in\nsubintervals we use a relation between prices of higher order binaries with\ndifferent coefficients. In our model, due to the inhomogenous term related to\nendogenous recovery, our pricing formulae are represented by not only the\nprices of higher binary options but also the integrals of them. So we consider\na special binary option called integral of i-th binary or nothing and then we\nobtain the pricing formulae of our defaultable corporate bond by using the\npricing formulae of higher binary options and integrals of them.\n"
    },
    {
        "paper_id": 1305.7092,
        "authors": "Carole Bernard and Zhenyu Cui",
        "title": "Prices and Asymptotics for Discrete Variance Swaps",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1080/1350486X.2013.820524",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the fair strike of a discrete variance swap for a general\ntime-homogeneous stochastic volatility model. In the special cases of Heston,\nHull-White and Schobel-Zhu stochastic volatility models we give simple explicit\nexpressions (improving Broadie and Jain (2008a) in the case of the Heston\nmodel). We give conditions on parameters under which the fair strike of a\ndiscrete variance swap is higher or lower than that of the continuous variance\nswap. The interest rate and the correlation between the underlying price and\nits volatility are key elements in this analysis. We derive asymptotics for the\ndiscrete variance swaps and compare our results with those of Broadie and Jain\n(2008a), Jarrow et al. (2013) and Keller-Ressel and Griessler (2012).\n"
    },
    {
        "paper_id": 1305.7309,
        "authors": "Bogdan Iftimie (IMAR), Monique Jeanblanc (DP), Thomas Lim (ENSIIE),\n  Hai-Nam Nguyen",
        "title": "Optimization problem under change of regime of interest rate",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the classical problem of maximization of the sum of\nthe utility of the terminal wealth and the utility of the consumption, in a\ncase where a sudden jump in the risk-free interest rate creates incompleteness.\nThe value function of the dual problem is proved to be solution of a BSDE and\nthe duality between the primal and the dual value functions is exploited to\nstudy the BSDE associated to the primal problem.\n"
    },
    {
        "paper_id": 1306.01,
        "authors": "Pasquale Cirillo",
        "title": "Are your data really Pareto distributed?",
        "comments": "8 figures; presented at the \"Econophysics and Networks Across Scales\"\n  workshop at Lorentz Center Leiden in May 2013",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.07.061",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Pareto distributions, and power laws in general, have demonstrated to be very\nuseful models to describe very different phenomena, from physics to finance. In\nrecent years, the econophysical literature has proposed a large amount of\npapers and models justifying the presence of power laws in economic data. Most\nof the times, this Paretianity is inferred from the observation of some plots,\nsuch as the Zipf plot and the mean excess plot. If the Zipf plot looks almost\nlinear, then everything is ok and the parameters of the Pareto distribution are\nestimated. Often with OLS. Unfortunately, as we show in this paper, these\nheuristic graphical tools are not reliable. To be more exact, we show that only\na combination of plots can give some degree of confidence about the real\npresence of Paretianity in the data. We start by reviewing some of the most\nimportant plots, discussing their points of strength and weakness, and then we\npropose some additional tools that can be used to refine the analysis.\n"
    },
    {
        "paper_id": 1306.0215,
        "authors": "Andreas Joseph, Stephan Joseph and Guanrong Chen",
        "title": "Cross-border Portfolio Investment Networks and Indicators for Financial\n  Crises",
        "comments": "21 pages, 9 figures, 5 tables",
        "journal-ref": "Scientific Reports (4), 3991, 2014",
        "doi": "10.1038/srep03991",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Cross-border equity and long-term debt securities portfolio investment\nnetworks are analysed from 2002 to 2012, covering the 2008 global financial\ncrisis. They serve as network-proxies for measuring the robustness of the\nglobal financial system and the interdependence of financial markets,\nrespectively. Two early-warning indicators for financial crises are identified:\nFirst, the algebraic connectivity of the equity securities network, as a\nmeasure for structural robustness, drops close to zero already in 2005, while\nthere is an over-representation of high-degree off-shore financial centres\namong the countries most-related to this observation, suggesting an\ninvestigation of such nodes with respect to the structural stability of the\nglobal financial system. Second, using a phenomenological model, the edge\ndensity of the debt securities network is found to describe, and even forecast,\nthe proliferation of several over-the-counter-traded financial derivatives,\nmost prominently credit default swaps, enabling one to detect potentially\ndangerous levels of market interdependence and systemic risk.\n"
    },
    {
        "paper_id": 1306.0345,
        "authors": "Chen Xiaoshan, Song Qingshuo",
        "title": "American option of stochastic volatility model with negative Fichera\n  function on degenerate boundary",
        "comments": "19 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study a general framework of American put option with\nstochastic volatility whose value function is associated with a 2-dimensional\nparabolic variational inequality with degenerate boundaries. We apply PDE\nmethods to analyze the existences of the strong solution and the properties of\nthe 2-dimensional manifold for the free boundary. Thanks to the regularity\nresult on the solution of the underlying PDE, we can also provide the\nuniqueness of the solution by the argument of the verification theorem together\nwith the generalized Ito's formula even though the solution may not be second\norder differentiable in the space variable across the free boundary.\n"
    },
    {
        "paper_id": 1306.0468,
        "authors": "Novriana Sumarti, Iman Gunadi",
        "title": "Reserve Requirement Analysis using a Dynamical System of a Bank based on\n  Monti-Klein model of Bank's Profit Function",
        "comments": "16 pages, 23 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Commercial banks and other depository institutions in some countries are\nrequired to hold in reserve against deposits made by their customers at their\nCentral Bank or Federal Reserve. Although some countries have been eliminated\nit, this requirement is useful as one of many Central Bank's regulation made to\ncontrol rate of inflation and conditions of excess liquidity in banks which\ncould affect the monetary stability. The amount of this reserve is affected by\nthe volumes of the commercial bank's loan and deposit, and also by the bank's\nLoan to Deposit Ratio (LDR) value. In this research, a dynamical system of the\nvolume of deposits (dD/dt) and loans (dL/dt) of a bank is constructed from the\nbank profit equation by Monti-Klein. The model is implemented using the\nregulation of Bank of Indonesia, and analysed in terms of the behaviour of the\nsolution. Based on some simplifying assumptions in this model, the results show\nthat eventhough the LDR values at the initial points of two solutions are the\nsame, the behavior of solutions will be significantly different due to\ndifferent magnitude of L and D volumes.\n"
    },
    {
        "paper_id": 1306.049,
        "authors": "Pablo Su\\'arez-Garc\\'ia and David G\\'omez-Ullate",
        "title": "Multifractality and long memory of a financial index",
        "comments": "12 pages, 7 figures, typed in AMS-LaTeX",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2013.09.038",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we will try to assess the multifractality displayed by the\nhigh-frequency returns of Madrid's Stock Exchange IBEX35 index. A Multifractal\nDetrended Fluctuation Analysis shows that this index has a wide singularity\nspectrum which is most likely caused by its long memory. Our findings also show\nthat this long-memory can be considered as the superposition of a\nhigh-frequency component (related to the daily cycles of arrival of information\nto the market), over a slowly-varying component that reverberates for long\nperiods of time and which shows no apparent relation with human economic\ncycles. This later component is therefore postulated to be endogenous to\nmarket's dynamics and to be also the most probable source of some of the\nstylized facts commonly associated with financial time series.\n"
    },
    {
        "paper_id": 1306.0887,
        "authors": "Damiano Brigo, Jan-Frederik Mai, Matthias Scherer",
        "title": "Consistent iterated simulation of multi-variate default times: a\n  Markovian indicators characterization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate under which conditions a single simulation of joint default\ntimes at a final time horizon can be decomposed into a set of simulations of\njoint defaults on subsequent adjacent sub-periods leading to that final\nhorizon. Besides the theoretical interest, this is also a practical problem as\npart of the industry has been working under the misleading assumption that the\ntwo approaches are equivalent for practical purposes. As a reasonable trade-off\nbetween realistic stylized facts, practical demands, and mathematical\ntractability, we propose models leading to a Markovian multi-variate\nsurvival--indicator process, and we investigate two instances of static models\nfor the vector of default times from the statistical literature that fall into\nthis class. On the one hand, the \"looping default\" case is known to be equipped\nwith this property, and we point out that it coincides with the classical\n\"Freund distribution\" in the bivariate case. On the other hand, if all\nsub-vectors of the survival indicator process are Markovian, this constitutes a\nnew characterization of the Marshall--Olkin distribution, and hence of\nmulti-variate lack-of-memory. A paramount property of the resulting model is\nstability of the type of multi-variate distribution with respect to elimination\nor insertion of a new marginal component with marginal distribution from the\nsame family. The practical implications of this \"nested margining\" property are\nenormous. To implement this distribution we present an efficient and unbiased\nsimulation algorithm based on the L\\'evy-frailty construction. We highlight\ndifferent pitfalls in the simulation of dependent default times and examine,\nwithin a numerical case study, the effect of inadequate simulation practices.\n"
    },
    {
        "paper_id": 1306.0938,
        "authors": "Laszlo F. Korsos",
        "title": "The Dirichlet Portfolio Model: Uncovering the Hidden Composition of\n  Hedge Fund Investments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Hedge funds have long been viewed as a veritable \"black box\" of investing\nsince outsiders may never view the exact composition of portfolio holdings.\nTherefore, the ability to estimate an informative set of asset weights is\nhighly desirable for analysis. We present a compositional state space model for\nestimation of an investment portfolio's unobserved asset allocation weightings\non a set of candidate assets when the only observed information is the time\nseries of portfolio returns and the candidate asset returns. In this paper, we\nexhibit both sequential Monte Carlo numerical and conditionally Normal\nanalytical approaches to solve for estimates of the unobserved asset weight\ntime series. This methodology is motivated by the estimation of monthly asset\nclass weights on the aggregate hedge fund industry from 1996 to 2012.\nFurthermore, we show how to implement the results as predictive investment\nweightings in order to construct hedge fund replicating portfolios.\n"
    },
    {
        "paper_id": 1306.0966,
        "authors": "Novriana Sumarti and Rafki Hidayat",
        "title": "A Financial Risk Analysis: Does the 2008 Financial Crisis Give Impact on\n  Weekends Returns of the U.S. Movie Box Office?",
        "comments": "6 pages, 10 figures",
        "journal-ref": "IAENG International Journal of Applied Mathematics, 41 vol. 4,\n  2011 pp: 343-348",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Financial Crisis of 2008 is a worldwide financial crisis causing a\nworldwide economic decline that is the most severe since the 1930s. According\nto the International Monetary Fund (IMF), the global financial crisis gave\nimpact on USD 3.4 trillion losses from financial institutions around the world\nbetween 2007 and 2010. Does the crisis give impact on the returns of the U.S.\nmovie Box Office? It will be answered by doing an analysis on the financial\nrisk model based on Extreme Value Theory (EVT) and calculations of Value at\nRisk (VaR) and Expected Shortfall (ES). The values of VaR and ES from 2\nperiods, 1982 to 1995 and 1996 to 2010, are compared. Results show that the\npossibility of loss for an investment in the movie industry is relatively lower\nthan the possibility of gain for both periods of time. The values of VaR and ES\nfor the second period are higher than the first period. We are able to conclude\nthat the 2008 financial crisis gave no significant effect on these measurement\nvalues in the second period. This result describes the high potential\nopportunity in the investment of the U.S. movie makers.\n"
    },
    {
        "paper_id": 1306.098,
        "authors": "Kais Hamza, Fima Klebaner and Olivia Mah",
        "title": "Volatility in options formulae for general stochastic dynamics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is well-known that the Black-Scholes formula has been derived under the\nassumption of constant volatility in stocks. In spite of evidence that this\nparameter is not constant, this formula is widely used by financial markets.\nThis paper addresses the question of whether an alternative model for stock\nprice exists for which the Black-Scholes or similar formulae hold. The results\nobtained in this paper are very general as no assumptions are made on the\ndynamics of the model, whether it be the underlying price process, the\nvolatility process or how they relate to each other. We show that if the\nformula holds for a continuum of strikes and three terminal times, then the\nvolatility must be constant. However, when it only holds for finitely many\nstrikes, and three or more maturity times, we obtain a universal bound on the\nvariation of the volatility. This bound yields that the implied volatility is\nconstant when the sequence of strikes increases to cover the entire half-line.\nThis recovers the result for a continuum of strikes by a different approach.\n"
    },
    {
        "paper_id": 1306.0995,
        "authors": "Sylvain Corlay",
        "title": "B-spline techniques for volatility modeling",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is devoted to the application of B-splines to volatility modeling,\nspecifically the calibration of the leverage function in stochastic local\nvolatility models and the parameterization of an arbitrage-free implied\nvolatility surface calibrated to sparse option data. We use an extension of\nclassical B-splines obtained by including basis functions with infinite\nsupport. We first come back to the application of shape-constrained B-splines\nto the estimation of conditional expectations, not merely from a scatter plot\nbut also from the given marginal distributions. An application is the Monte\nCarlo calibration of stochastic local volatility models by Markov projection.\nThen we present a new technique for the calibration of an implied volatility\nsurface to sparse option data. We use a B-spline parameterization of the\nRadon-Nikodym derivative of the underlying's risk-neutral probability density\nwith respect to a roughly calibrated base model. We show that this method\nprovides smooth arbitrage-free implied volatility surfaces. Finally, we sketch\na Galerkin method with B-spline finite elements to the solution of the partial\ndifferential equation satisfied by the Radon-Nikodym derivative.\n"
    },
    {
        "paper_id": 1306.1062,
        "authors": "Shiqi Song",
        "title": "An alternative proof of a result of Takaoka",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In Karatzas and Kardaras's paper on semimartingale financial models, it is\nproved that the NUPBR condition is a property of the local characteristic of\nthe asset process alone. In Takaoka's paper on NUPBR, it is proved that the\nNUPBR condition is equivalent to the existence of a simga-martingale deflator.\nHowever, Takaoka's paper founds its proof on Delbaen and Schachermayer's\nfundamental asset pricing theorem, i.e. the NFLVR condition, which is not a\npure property of the local characteristic of the asset process. In this paper\nwe give an alternative proof of the result of Takaoka, which makes use only the\nproperties of the local characteristic of the asset process.\n"
    },
    {
        "paper_id": 1306.1378,
        "authors": "Bin Li and Dingjiang Huang and Steven C.H. Hoi",
        "title": "CORN: Correlation-Driven Nonparametric Learning Approach for Portfolio\n  Selection -- an Online Appendix",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This appendix proves CORN's universal consistency. One of Bin's PhD thesis\nexaminer (Special thanks to Vladimir Vovk from Royal Holloway, University of\nLondon) suggested that CORN is universal and provided sketch proof of Lemma\n1.6, which is the key of this proof. Based on the proof in Gy\\\"prfi et al.\n[2006], we thus prove CORN's universal consistency. Note that the notations in\nthis appendix follows Gy\\\"orfi et al. [2006].\n"
    },
    {
        "paper_id": 1306.1781,
        "authors": "Panagiotis Nanos and Christian Schluter",
        "title": "The Composition of Wage Differentials between Migrants and Natives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  We consider the role of unobservables, such as differences in search\nfrictions, reservation wages, and productivities for the explanation of wage\ndifferentials between migrants and natives. We disentangle these by estimating\nan empirical general equilibrium search model with on-the-job search due to\nBontemps, Robin, and van den Berg (1999) on segments of the labour market\ndefined by occupation, age, and nationality using a large scale German\nadministrative dataset.\n  The native-migrant wage differential is then decomposed into several parts,\nand we focus especially on the component that we label \"migrant effect\", being\nthe difference in wage offers between natives and migrants in the same\noccupation-age segment in firms of the same productivity. Counterfactual\ndecompositions of wage differentials allow us to identify and quantify their\ndrivers, thus explaining within a common framework what is often labelled the\nunexplained wage gap.\n"
    },
    {
        "paper_id": 1306.1882,
        "authors": "Pavel V. Shevchenko and Gareth W. Peters",
        "title": "Loss Distribution Approach for Operational Risk Capital Modelling under\n  Basel II: Combining Different Data Sources for Risk Estimation",
        "comments": null,
        "journal-ref": "The Journal of Governance and Regulation 2(3), pages 33-57, (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The management of operational risk in the banking industry has undergone\nsignificant changes over the last decade due to substantial changes in\noperational risk environment. Globalization, deregulation, the use of complex\nfinancial products and changes in information technology have resulted in\nexposure to new risks very different from market and credit risks. In response,\nBasel Committee for banking Supervision has developed a regulatory framework,\nreferred to as Basel II, that introduced operational risk category and\ncorresponding capital requirements. Over the past five years, major banks in\nmost parts of the world have received accreditation under the Basel II Advanced\nMeasurement Approach (AMA) by adopting the loss distribution approach (LDA)\ndespite there being a number of unresolved methodological challenges in its\nimplementation. Different approaches and methods are still under hot debate. In\nthis paper, we review methods proposed in the literature for combining\ndifferent data sources (internal data, external data and scenario analysis)\nwhich is one of the regulatory requirement for AMA.\n"
    },
    {
        "paper_id": 1306.2073,
        "authors": "Maxence Soumare, J{\\o}rgen Vitting Andersen, Francis Bouchard, Alain\n  Elkaim, Dominique Gu\\'egan, Justin Leroux, Michel Miniconi, Lars Stentoft",
        "title": "A theoretical framework for trading experiments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A general framework is suggested to describe human decision making in a\ncertain class of experiments performed in a trading laboratory. We are in\nparticular interested in discerning between two different moods, or states of\nthe investors, corresponding to investors using fundamental investment\nstrategies, technical analysis investment strategies respectively. Our\nframework accounts for two opposite situations already encountered in\nexperimental setups: i) the rational expectations case, and ii) the case of\npure speculation. We consider new experimental conditions which allow both\nelements to be present in the decision making process of the traders, thereby\ncreating a dilemma in terms of investment strategy. Our theoretical framework\nallows us to predict the outcome of this type of trading experiments, depending\non such variables as the number of people trading, the liquidity of the market,\nthe amount of information used in technical analysis strategies, as well as the\ndividends attributed to an asset. We find that it is possible to give a\nqualitative prediction of trading behavior depending on a ratio that quantifies\nthe fluctuations in the model.\n"
    },
    {
        "paper_id": 1306.2188,
        "authors": "Jun-ichi Maskawa, Joshin Murai and Koji Kuroda",
        "title": "Market-wide price co-movement around crashes in the Tokyo Stock Exchange",
        "comments": "18 pages, 7 figures, to appear in Evolutionary and Institutional\n  Economics Review special issue",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  As described in this paper, we study market-wide price co-movements around\ncrashes by analyzing a dataset of high-frequency stock returns of the\nconstituent issues of Nikkei 225 Index listed on the Tokyo Stock Exchange for\nthe three years during 2007--2009. Results of day-to-day principal component\nanalysis of the time series sampled at the 1 min time interval during the\ncontinuous auction of the daytime reveal the long range up to a couple of\nmonths significant auto-correlation of the maximum eigenvalue of the\ncorrelation matrix, which express the intensity of market-wide co-movement of\nstock prices. It also strongly correlates with the open-to-close intraday\nreturn and daily return of Nikkei 225 Index. We also study the market mode,\nwhich is the first principal component corresponding to the maximum eigenvalue,\nin the framework of Multi-fractal random walk model. The parameter of the model\nestimated in a sliding time window, which describes the covariance of the\nlogarithm of the stochastic volatility, grows before almost all large intraday\nprice declines of less than -5%. This phenomenon signifies the upwelling of the\nmarket-wide collective behavior before the crash, which might reflect a herding\nof market participants.\n"
    },
    {
        "paper_id": 1306.2245,
        "authors": "Vladimir Filimonov, Spencer Wheatley, Didier Sornette",
        "title": "Effective Measure of Endogeneity for the Autoregressive Conditional\n  Duration Point Processes via Mapping to the Self-Excited Hawkes Process",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In order to disentangle the internal dynamics from exogenous factors within\nthe Autoregressive Conditional Duration (ACD) model, we present an effective\nmeasure of endogeneity. Inspired from the Hawkes model, this measure is defined\nas the average fraction of events that are triggered due to internal feedback\nmechanisms within the total population. We provide a direct comparison of the\nHawkes and ACD models based on numerical simulations and show that our\neffective measure of endogeneity for the ACD can be mapped onto the \"branching\nratio\" of the Hawkes model.\n"
    },
    {
        "paper_id": 1306.2251,
        "authors": "T. S. Kholupenko, E. E. Kholupenko, P. A. Guseva",
        "title": "Some Possible Solution of Problem of Sovereign Debts: a short plan",
        "comments": "5 pages, no figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Possible solution of problem of sovereign debts is suggested. At the current\nmoment this solution still can be provided only by methods of the world\nmonetary policy.\n"
    },
    {
        "paper_id": 1306.2508,
        "authors": "Matthias Raddant and Friedrich Wagner",
        "title": "Phase Transition in the S&P Stock Market",
        "comments": null,
        "journal-ref": "Journal of Economic Interaction and Coordination, 11(2), 229-246,\n  2016",
        "doi": "10.1007/s11403-015-0160-x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the stock prices of the S&P market from 1987 until 2012 with the\ncovariance matrix of the firm returns determined in time windows of several\nyears. The eigenvector belonging to the leading eigenvalue (market) exhibits in\nits long term time dependence a phase transition with an order parameter which\ncan be interpreted within an agent-based model. From 1995 to 2005 the market is\nin an ordered state and after 2005 in a disordered state.\n"
    }
]