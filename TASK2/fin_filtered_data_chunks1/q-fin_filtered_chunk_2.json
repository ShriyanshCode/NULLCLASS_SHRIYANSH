[
    {
        "paper_id": 1001.4889,
        "authors": "Ivan O. Kitov",
        "title": "Modelling and predicting labor force productivity",
        "comments": "8 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Labor productivity in Turkey, Spain, Belgium, Austria, Switzerland, and New\nZealand has been analyzed and modeled. These counties extend the previously\nanalyzed set of the US, UK, Japan, France, Italy, and Canada. Modelling is\nbased on the link between the rate of labor participation and real GDP per\ncapita. New results validate the link and allow predicting a drop in\nproductivity by 2010 in almost all studied countries.\n"
    },
    {
        "paper_id": 1001.5058,
        "authors": "Abhimanyu Mitra, Sidney I. Resnick",
        "title": "Hidden Regular Variation: Detection and Estimation",
        "comments": "37 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Hidden regular variation defines a subfamily of distributions satisfying\nmultivariate regular variation on $\\mathbb{E} = [0, \\infty]^d \\backslash\n\\{(0,0, ..., 0) \\} $ and models another regular variation on the sub-cone\n$\\mathbb{E}^{(2)} = \\mathbb{E} \\backslash \\cup_{i=1}^d \\mathbb{L}_i$, where\n$\\mathbb{L}_i$ is the $i$-th axis. We extend the concept of hidden regular\nvariation to sub-cones of $\\mathbb{E}^{(2)}$ as well. We suggest a procedure\nfor detecting the presence of hidden regular variation, and if it exists,\npropose a method of estimating the limit measure exploiting its semi-parametric\nstructure. We exhibit examples where hidden regular variation yields better\nestimates of probabilities of risk sets.\n"
    },
    {
        "paper_id": 1001.5124,
        "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer, Thomas Guhr",
        "title": "Impact of the tick-size on financial returns and correlations",
        "comments": "18 pages, 10 figures",
        "journal-ref": "Physica A Vol. 389, No. 21 (2010)",
        "doi": "10.1016/j.physa.2010.06.037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We demonstrate that the lowest possible price change (tick-size) has a large\nimpact on the structure of financial return distributions. It induces a\nmicrostructure as well as it can alter the tail behavior. On small return\nintervals, the tick-size can distort the calculation of correlations. This\nespecially occurs on small return intervals and thus contributes to the decay\nof the correlation coefficient towards smaller return intervals (Epps effect).\nWe study this behavior within a model and identify the effect in market data.\nFurthermore, we present a method to compensate this purely statistical error.\n"
    },
    {
        "paper_id": 1001.5202,
        "authors": "Simone Scotti",
        "title": "The impact of uncertainties on the pricing of contingent claims",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the effect of parameters uncertainties on a stochastic diffusion\nmodel, in particular the impact on the pricing of contingent claims, thanks to\nDirichlet Forms methods. We apply recent techniques, developed by Bouleau, to\nhedging procedures in order to compute the sensitivities of SDE trajectories\nwith respect to parameter perturbations. We show that this model can reproduce\na bid-ask spread. We also prove that, if the stochastic differential equation\nadmits a closed form representation, also the sensitivities have closed form\nrepresentations.\n  We exhibit the case of log-normal diffusion and we show that this framework\nforesees a smiled implied volatility surface coherent with historical data.\n"
    },
    {
        "paper_id": 1001.5421,
        "authors": "Ronald Hochreiter",
        "title": "A note on evolutionary stochastic portfolio optimization and\n  probabilistic constraints",
        "comments": null,
        "journal-ref": "Proceedings of MENDEL 2010: 1-6. 2010",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note, we extend an evolutionary stochastic portfolio optimization\nframework to include probabilistic constraints. Both the stochastic\nprogramming-based modeling environment as well as the evolutionary optimization\nenvironment are ideally suited for an integration of various types of\nprobabilistic constraints. We show an approach on how to integrate these\nconstraints. Numerical results using recent financial data substantiate the\napplicability of the presented approach.\n"
    },
    {
        "paper_id": 1002.0277,
        "authors": "Ivan O. Kitov",
        "title": "Inflation and unemployment in Japan: from 1980 to 2050",
        "comments": "15 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The evolution of inflation, p(t), and unemployment, UE(t), in Japan has been\nmodeled. Both variables were represented as linear functions of the change rate\nof labor force, dLF/LF. These models provide an accurate description of\ndisinflation in the 1990s and a deflationary period in the 2000s. In Japan,\nthere exists a statistically reliable (R2=0.68) Phillips curve, which is\ncharacterized by a negative relation between inflation and unemployment and\ntheir synchronous evolution: UE(t) = -0.94p(t) + 0.045. Effectively, growing\nunemployment has resulted in decreasing inflation since 1982. A linear and\nlagged generalized relationship between inflation, unemployment and labor force\nhas been also obtained for Japan: p(t) = 2.8*dLF(t)/LF(t) + 0.9*UE(t) - 0.0392.\nLabor force projections allow a prediction of inflation and unemployment in\nJapan: CPI inflation will be negative (between -0.5% and -1% per year) during\nthe next 40 years. Unemployment will increase from ~4.0% in 2010 to 5.3% in\n2050.\n"
    },
    {
        "paper_id": 1002.0284,
        "authors": "Jie-Jun Tseng and Sai-Ping Li",
        "title": "Asset returns and volatility clustering in financial time series",
        "comments": "29 pages, 14 figures, 5 tables",
        "journal-ref": "Physica A 390, 1300 - 1314 (2011)",
        "doi": "10.1016/j.physa.2010.12.002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An analysis of the stylized facts in financial time series is carried out. We\nfind that, instead of the heavy tails in asset return distributions, the slow\ndecay behaviour in autocorrelation functions of absolute returns is actually\ndirectly related to the degree of clustering of large fluctuations within the\nfinancial time series. We also introduce an index to quantitatively measure the\nclustering behaviour of fluctuations in these time series and show that big\nlosses in financial markets usually lump more severely than big gains. We\nfurther give examples to demonstrate that comparing to conventional methods,\nour index enables one to extract more information from the financial time\nseries.\n"
    },
    {
        "paper_id": 1002.0321,
        "authors": "Thomas Conlon, Heather J. Ruskin, Martin Crane",
        "title": "Cross-Correlation Dynamics in Financial Time Series",
        "comments": null,
        "journal-ref": "Physica A 388 (5) (2009), 705-714",
        "doi": "10.1016/j.physa.2008.10.047",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The dynamics of the equal-time cross-correlation matrix of multivariate\nfinancial time series is explored by examination of the eigenvalue spectrum\nover sliding time windows. Empirical results for the S&P 500 and the Dow Jones\nEuro Stoxx 50 indices reveal that the dynamics of the small eigenvalues of the\ncross-correlation matrix, over these time windows, oppose those of the largest\neigenvalue. This behaviour is shown to be independent of the size of the time\nwindow and the number of stocks examined.\n  A basic one-factor model is then proposed, which captures the main dynamical\nfeatures of the eigenvalue spectrum of the empirical data. Through the addition\nof perturbations to the one-factor model, (leading to a 'market plus sectors'\nmodel), additional sectoral features are added, resulting in an Inverse\nParticipation Ratio comparable to that found for empirical data. By\npartitioning the eigenvalue time series, we then show that negative index\nreturns, (drawdowns), are associated with periods where the largest eigenvalue\nis greatest, while positive index returns, (drawups), are associated with\nperiods where the largest eigenvalue is smallest. The study of correlation\ndynamics provides some insight on the collective behaviour of traders with\nvarying strategies.\n"
    },
    {
        "paper_id": 1002.0377,
        "authors": "Austin Gerig",
        "title": "Universal Laws and Economic Phenomena",
        "comments": "3 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This is a short commentary piece that discusses how the methods used in the\nnatural sciences can apply to economics in general and financial markets\nspecifically.\n"
    },
    {
        "paper_id": 1002.0567,
        "authors": "Paul M. Voutier",
        "title": "A New Approximation to the Normal Distribution Quantile Function",
        "comments": "added contact details",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  We present a new approximation to the normal distribution quantile function.\nIt has a similar form to the approximation of Beasley and Springer [3],\nproviding a maximum absolute error of less than $2.5 \\cdot 10^{-5}$. This is\nless accurate than [3], but still sufficient for many applications. However it\nis faster than [3]. This is its primary benefit, which can be crucial to many\napplications, including in financial markets.\n"
    },
    {
        "paper_id": 1002.0571,
        "authors": "Miquel Montero, Javier Villarroel",
        "title": "Exit times in non-Markovian drifting continuous-time random walk\n  processes",
        "comments": "9 pages, 3 color plots, two-column revtex 4; new Appendix and\n  references added",
        "journal-ref": "Phys. Rev. 82, 021102 (2010)",
        "doi": "10.1103/PhysRevE.82.021102",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By appealing to renewal theory we determine the equations that the mean exit\ntime of a continuous-time random walk with drift satisfies both when the\npresent coincides with a jump instant or when it does not. Particular attention\nis paid to the corrections ensuing from the non-Markovian nature of the\nprocess. We show that when drift and jumps have the same sign the relevant\nintegral equations can be solved in closed form. The case when holding times\nhave the classical Erlang distribution is considered in detail.\n"
    },
    {
        "paper_id": 1002.0609,
        "authors": "Maria Boguta and Eric J\\\"arpe",
        "title": "A new space-time model for volatility clustering in the financial market",
        "comments": "11 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new space-time model for interacting agents on the financial market is\npresented. It is a combination of the Curie-Weiss model and a space-time model\nintroduced by J\\\"arpe 2005. Properties of the model are derived with focus on\nthe critical temperature and magnetization. It turns out that the Hamiltonian\nis a sufficient statistic for the temperature parameter and thus statistical\ninference about this parameter can be performed. Thus e.g. statements about how\nfar the current financial situation is from a financial crisis can be made, and\nfinancial trading stability be monitored for detection of malicious risk\nindicating signals.\n"
    },
    {
        "paper_id": 1002.0864,
        "authors": "Ljudmila A. Bordag",
        "title": "Pricing options in illiquid markets: optimal systems, symmetry\n  reductions and exact solutions",
        "comments": "14 pages",
        "journal-ref": "Lobachevskii Journal of Mathematics , 2010,vol. 31,no 2, pp.90-99;\n  ISSN 1995-0802",
        "doi": "10.1134/S1995080210020022",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a class of nonlinear pricing models which involves the feedback\neffect from the dynamic hedging strategies on the price of asset introduced by\nSircar and Papanicolaou. We are first to study the case of a nonlinear demand\nfunction involved in the model. Using a Lie group analysis we investigate the\nsymmetry properties of these nonlinear diffusion equations. We provide the\noptimal systems of subalgebras and the complete set of non-equivalent\nreductions of studied PDEs to ODEs. In most cases we obtain families of exact\nsolutions or derive particular solutions to the equations.\n"
    },
    {
        "paper_id": 1002.0917,
        "authors": "Jie-Jun Tseng, Chih-Hao Lin, Chih-Ting Lin, Sun-Chong Wang, Sai-Ping\n  Li",
        "title": "Statistical properties of agent-based models in markets with continuous\n  double auction mechanism",
        "comments": "16 pages, 7 figures",
        "journal-ref": "Physica A 389, 1699 - 1707 (2010)",
        "doi": "10.1016/j.physa.2009.12.034",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Real world markets display power-law features in variables such as price\nfluctuations in stocks. To further understand market behavior, we have\nconducted a series of market experiments on our web-based prediction market\nplatform which allows us to reconstruct transaction networks among traders.\n  From these networks, we are able to record the degree of a trader, the size\nof a community of traders, the transaction time interval among traders and\nother variables that are of interest. The distributions of all these variables\nshow power-law behavior. On the other hand, agent-based models have been\nproposed to study the properties of real financial markets. We here study the\nstatistical properties of these agent-based models and compare them with the\nresults from our web-based market experiments. In this work, three agent-based\nmodels are studied, namely, zero-intelligence (ZI), zero-intelligence-plus\n(ZIP) and Gjerstad-Dickhaut (GD). Computer simulations of variables based on\nthese three agent-based models were carried out. We found that although being\nthe most naive agent-based model, ZI indeed best describes the properties\nobserved in real markets. Our study suggests that the basic ingredient to\nproduce the observed properties from real world markets could in fact be the\nresult of a continuously evolving dynamical system with basic features similar\nto the ZI model.\n"
    },
    {
        "paper_id": 1002.0934,
        "authors": "Zdzis{\\l}aw Burda, Andrzej Jarosz, Maciej A. Nowak, Ma{\\l}gorzata\n  Snarska",
        "title": "A Random Matrix Approach to VARMA Processes",
        "comments": "16 pages, 6 figures, submitted to New Journal of Physics",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/12/7/075036",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We apply random matrix theory to derive spectral density of large sample\ncovariance matrices generated by multivariate VMA(q), VAR(q) and VARMA(q1,q2)\nprocesses. In particular, we consider a limit where the number of random\nvariables N and the number of consecutive time measurements T are large but the\nratio N/T is fixed. In this regime the underlying random matrices are\nasymptotically equivalent to Free Random Variables (FRV). We apply the FRV\ncalculus to calculate the eigenvalue density of the sample covariance for\nseveral VARMA-type processes. We explicitly solve the VARMA(1,1) case and\ndemonstrate a perfect agreement between the analytical result and the spectra\nobtained by Monte Carlo simulations. The proposed method is purely algebraic\nand can be easily generalized to q1>1 and q2>1.\n"
    },
    {
        "paper_id": 1002.0979,
        "authors": "Martin Lauko, Daniel Sevcovic",
        "title": "Comparison of numerical and analytical approximations of the early\n  exercise boundary of the American put option",
        "comments": null,
        "journal-ref": "The ANZIAM Journal (2010), 51: 430-448",
        "doi": "10.1017/S1446181110000854",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present qualitative and quantitative comparison of various\nanalytical and numerical approximation methods for calculating a position of\nthe early exercise boundary of the American put option paying zero dividends.\nFirst we analyze their asymptotic behavior close to expiration. In the second\npart of the paper, we introduce a new numerical scheme for computing the entire\nearly exercise boundary. The local iterative numerical scheme is based on a\nsolution to a nonlinear integral equation. We compare numerical results\nobtained by the new method to those of the projected successive over relaxation\nmethod and the analytical approximation formula recently derived by Zhu.\n"
    },
    {
        "paper_id": 1002.101,
        "authors": "David S. Bree (Institute for Scientific Interchange, Torino) and\n  Nathan Lael Joseph (Aston University, Birmingham)",
        "title": "Testing for financial crashes using the Log Periodic Power Law mode",
        "comments": "24 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A number of papers claim that a Log Periodic Power Law (LPPL) fitted to\nfinancial market bubbles that precede large market falls or 'crashes', contain\nparameters that are confined within certain ranges. The mechanism that has been\nclaimed as underlying the LPPL, is based on influence percolation and a\nmartingale condition. This paper examines these claims and the robustness of\nthe LPPL for capturing large falls in the Hang Seng stock market index, over a\n30-year period, including the current global downturn. We identify 11 crashes\non the Hang Seng market over the period 1970 to 2008. The fitted LPPLs have\nparameter values within the ranges specified post hoc by Johansen and Sornette\n(2001) for only seven of these crashes. Interestingly, the LPPL fit could have\npredicted the substantial fall in the Hang Seng index during the recent global\ndownturn. We also find that influence percolation combined with a martingale\ncondition holds for only half of the pre-crash bubbles previously reported.\nOverall, the mechanism posited as underlying the LPPL does not do so, and the\ndata used to support the fit of the LPPL to bubbles does so only partially.\n"
    },
    {
        "paper_id": 1002.107,
        "authors": "Pawe{\\l} Sieczka, Didier Sornette, Janusz A. Ho{\\l}yst",
        "title": "The Lehman Brothers Effect and Bankruptcy Cascades",
        "comments": null,
        "journal-ref": "Eur. Phys. J. B 82, 257 - 269 (2011)",
        "doi": "10.1140/epjb/e2011-10757-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Inspired by the bankruptcy of Lehman Brothers and its consequences on the\nglobal financial system, we develop a simple model in which the Lehman default\nevent is quantified as having an almost immediate effect in worsening the\ncredit worthiness of all financial institutions in the economic network. In our\nstylized description, all properties of a given firm are captured by its\neffective credit rating, which follows a simple dynamics of co-evolution with\nthe credit ratings of the other firms in our economic network. The dynamics\nresembles the evolution of Potts spin-glass with external global field\ncorresponding to a panic effect in the economy. The existence of a global phase\ntransition, between paramagnetic and ferromagnetic phases, explains the large\nsusceptibility of the system to negative shocks. We show that bailing out the\nfirst few defaulting firms does not solve the problem, but does have the effect\nof alleviating considerably the global shock, as measured by the fraction of\nfirms that are not defaulting as a consequence. This beneficial effect is the\ncounterpart of the large vulnerability of the system of coupled firms, which\nare both the direct consequences of the collective self-organized endogenous\nbehaviors of the credit ratings of the firms in our economic network.\n"
    },
    {
        "paper_id": 1002.1653,
        "authors": "Fei Ren and Wei-Xing Zhou",
        "title": "Recurrence interval analysis of trading volumes",
        "comments": "9 pages, 9 figures and 1 table",
        "journal-ref": "Physical Review E 81 (6), 066107 (2010)",
        "doi": "10.1103/PhysRevE.81.066107",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the statistical properties of the recurrence intervals $\\tau$\nbetween successive trading volumes exceeding a certain threshold $q$. The\nrecurrence interval analysis is carried out for the 20 liquid Chinese stocks\ncovering a period from January 2000 to May 2009, and two Chinese indices from\nJanuary 2003 to April 2009. Similar to the recurrence interval distribution of\nthe price returns, the tail of the recurrence interval distribution of the\ntrading volumes follows a power-law scaling, and the results are verified by\nthe goodness-of-fit tests using the Kolmogorov-Smirnov (KS) statistic, the\nweighted KS statistic and the Cram{\\'{e}}r-von Mises criterion. The\nmeasurements of the conditional probability distribution and the detrended\nfluctuation function show that both short-term and long-term memory effects\nexist in the recurrence intervals between trading volumes. We further study the\nrelationship between trading volumes and price returns based on the recurrence\ninterval analysis method. It is found that large trading volumes are more\nlikely to occur following large price returns, and the comovement between\ntrading volumes and price returns is more pronounced for large trading volumes.\n"
    },
    {
        "paper_id": 1002.1889,
        "authors": "Constantinos Kardaras, Gordan Zitkovic",
        "title": "Forward-convex convergence in probability of sequences of nonnegative\n  random variables",
        "comments": "11 pages - new version with strengthened result and simplified proof",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a sequence of nonnegative random variables, we provide simple necessary\nand sufficient conditions to ensure that each sequence of its forward convex\ncombinations converges in probability to the same limit. These conditions\ncorrespond to an essentially measure-free version of the notion of uniform\nintegrability.\n"
    },
    {
        "paper_id": 1002.1995,
        "authors": "Andrey Itkin, Peter Carr",
        "title": "Using pseudo-parabolic and fractional equations for option pricing in\n  jump diffusion models",
        "comments": "37 pages, 16 figures. submitted to Applied Mathematical Finance.\n  submitted to Applied Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In mathematical finance a popular approach for pricing options under some\nLevy model is to consider underlying that follows a Poisson jump diffusion\nprocess. As it is well known this results in a partial integro-differential\nequation (PIDE) that usually does not allow an analytical solution while\nnumerical solution brings some problems. In this paper we elaborate a new\napproach on how to transform the PIDE to some class of so-called\npseudo-parabolic equations which are known in mathematics but are relatively\nnew for mathematical finance. As an example we discuss several jump-diffusion\nmodels which Levy measure allows such a transformation.\n"
    },
    {
        "paper_id": 1002.2086,
        "authors": "Rim Amami",
        "title": "Contr\\^ole impulsionnel appliqu\\'e \\`a la gestion de changement de\n  technologie dans une entreprise",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an impulse control problem in infinite horizon applied with\nswitching technology. We suppose that the firm decides at certain moments\n(impulse moments) to switch technology, leading to a jump of the firm value. We\nshow that the value function for such problems satisfies a dynamic programming\nprinciple version. Our objective is to look for an optimal strategy which\nmaximizes the value function associated with a switching problem.\n"
    },
    {
        "paper_id": 1002.2171,
        "authors": "J. Wiesinger, D. Sornette, J. Satinover",
        "title": "Reverse Engineering Financial Markets with Majority and Minority Games\n  using Genetic Algorithms",
        "comments": "14 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using virtual stock markets with artificial interacting software investors,\naka agent-based models (ABMs), we present a method to reverse engineer\nreal-world financial time series. We model financial markets as made of a large\nnumber of interacting boundedly rational agents. By optimizing the similarity\nbetween the actual data and that generated by the reconstructed virtual stock\nmarket, we obtain parameters and strategies, which reveal some of the inner\nworkings of the target stock market. We validate our approach by out-of-sample\npredictions of directional moves of the Nasdaq Composite Index.\n"
    },
    {
        "paper_id": 1002.2265,
        "authors": "Ryo Adachi and Akimichi Takemura",
        "title": "Sequential optimizing investing strategy with neural networks",
        "comments": null,
        "journal-ref": "Expert Systems with Applications 38 (2011) 12991-12998",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose an investing strategy based on neural network models\ncombined with ideas from game-theoretic probability of Shafer and Vovk. Our\nproposed strategy uses parameter values of a neural network with the best\nperformance until the previous round (trading day) for deciding the investment\nin the current round. We compare performance of our proposed strategy with\nvarious strategies including a strategy based on supervised neural network\nmodels and show that our procedure is competitive with other strategies.\n"
    },
    {
        "paper_id": 1002.2269,
        "authors": "Venkat Venkatasubramanian",
        "title": "What is Fair Pay for Executives? An Information Theoretic Analysis of\n  Wage Distributions",
        "comments": "16 pages",
        "journal-ref": "Entropy 2009, 11, 766-781",
        "doi": "10.3390/e11040766",
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  The high pay packages of U.S. CEOs have raised serious concerns about what\nwould constitute a fair pay.\n"
    },
    {
        "paper_id": 1002.2281,
        "authors": "Philip Maymin",
        "title": "Regulation Simulation",
        "comments": null,
        "journal-ref": "European Journal of Finance and Banking Research 2009, vol. 2, no.\n  2, 1-12",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A deterministic trading strategy by a representative investor on a single\nmarket asset, which generates complex and realistic returns with its first four\nmoments similar to the empirical values of European stock indices, is used to\nsimulate the effects of financial regulation that either pricks bubbles, props\nup crashes, or both. The results suggest that regulation makes the market\nprocess appear more Gaussian and less complex, with the difference more\npronounced for more frequent intervention, though particular periods can be\nworse than the non-regulated version, and that pricking bubbles and propping up\ncrashes are not symmetrical.\n"
    },
    {
        "paper_id": 1002.2282,
        "authors": "Philip Maymin",
        "title": "The Hazards of Propping Up: Bubbles and Chaos",
        "comments": null,
        "journal-ref": "International Journal of Business and Finance Research 2009, vol.\n  3, no. 2, 83-93",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the current environment of financial distress, many governments are likely\nto soon become major holders of financial assets, but the policy debate focuses\nonly on the likelihood and extent of short-term market stabilization. This\npaper shows that government intervention and propping up are likely to lead to\nlong-term bubbles and even wildly chaotic behavior. The discontinuities occur\nwhen the committed capital reaches a critical amount that depends on just two\nparameters: the market impact of trading and the target exposure percentage.\n"
    },
    {
        "paper_id": 1002.2284,
        "authors": "Philip Maymin",
        "title": "Markets are efficient if and only if P = NP",
        "comments": "33 pages; extended literature review and some additions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I prove that if markets are weak-form efficient, meaning current prices fully\nreflect all information available in past prices, then P = NP, meaning every\ncomputational problem whose solution can be verified in polynomial time can\nalso be solved in polynomial time. I also prove the converse by showing how we\ncan \"program\" the market to solve NP-complete problems. Since P probably does\nnot equal NP, markets are probably not efficient. Specifically, markets become\nincreasingly inefficient as the time series lengthens or becomes more frequent.\nAn illustration by way of partitioning the excess returns to momentum\nstrategies based on data availability confirms this prediction.\n"
    },
    {
        "paper_id": 1002.2486,
        "authors": "Claudia Kluppelberg, Serguei Pergamenchtchikov (LMRS)",
        "title": "Optimal consumption and investment with bounded downside risk measures\n  for logarithmic utility functions",
        "comments": null,
        "journal-ref": "Optimal consumption and investment with bounded downside risk\n  measures for logarithmic utility functions (2009) 428",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate optimal consumption problems for a Black-Scholes market under\nuniform restrictions on Value-at-Risk and Expected Shortfall for logarithmic\nutility functions. We find the solutions in terms of a dynamic strategy in\nexplicit form, which can be compared and interpreted. This paper continues our\nprevious work, where we solved similar problems for power utility functions.\n"
    },
    {
        "paper_id": 1002.2487,
        "authors": "Claudia Kluppelberg, Serguei Pergamenchtchikov (LMRS)",
        "title": "Optimal consumption and investment with bounded downside risk for power\n  utility functions",
        "comments": "36 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate optimal consumption and investment problems for a\nBlack-Scholes market under uniform restrictions on Value-at-Risk and Expected\nShortfall. We formulate various utility maximization problems, which can be\nsolved explicitly. We compare the optimal solutions in form of optimal value,\noptimal control and optimal wealth to analogous problems under additional\nuniform risk bounds. Our proofs are partly based on solutions to\nHamilton-Jacobi-Bellman equations, and we prove a corresponding verification\ntheorem. This work was supported by the European Science Foundation through the\nAMaMeF programme.\n"
    },
    {
        "paper_id": 1002.2491,
        "authors": "Alexander M. Petersen, Boris Podobnik, Davor Horvatic, H. Eugene\n  Stanley",
        "title": "Scale invariant properties of public debt growth",
        "comments": "9 pages, 8 figures",
        "journal-ref": "Europhysics Letters 90, 38006 (2010)",
        "doi": "10.1209/0295-5075/90/38006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Public debt is one of the important economic variables that quantitatively\ndescribes a nation's economy. Because bankruptcy is a risk faced even by\ninstitutions as large as governments (e.g. Iceland), national debt should be\nstrictly controlled with respect to national wealth. Also, the problem of\neliminating extreme poverty in the world is closely connected to the study of\nextremely poor debtor nations. We analyze the time evolution of national public\ndebt and find \"convergence\": initially less-indebted countries increase their\ndebt more quickly than initially more-indebted countries. We also analyze the\npublic debt-to-GDP ratio R, a proxy for default risk, and approximate the\nprobability density function P(R) with a Gamma distribution, which can be used\nto establish thresholds for sustainable debt. We also observe \"convergence\" in\nR: countries with initially small R increase their R more quickly than\ncountries with initially large R. The scaling relationships for debt and R have\npractical applications, e.g. the Maastricht Treaty requires members of the\nEuropean Monetary Union to maintain R < 0.6.\n"
    },
    {
        "paper_id": 1002.2573,
        "authors": "Alex Langnau",
        "title": "A model-insensitive determination of First-hitting-time densities with\n  Application to Equity default-swaps",
        "comments": "keywords: Equity default swaps, hitting probability, stopping time\n  density, barrier options, forward volatility,forward volatility skew,\n  american digital put",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Equity default-swaps pay the holder a fixed amount of money when the\nunderlying spot level touches a (far-down) barrier during the life of the\ninstrument. While most pricing models give reasonable results when the barrier\nlies within the range of liquidly traded strikes of plain-vanilla option\nprices, the situation is more involved for extremely out-of-the money barriers.\nIn this paper we discuss a model-insensitive approach for the determination of\nfirst hitting times that does not rely on the full a priori knowledge of the\nstochastic process for the price dynamics. Hence more robust pricing and\nhedging results are expected as a result of this analysis. In contrast to\nstochastic volatility-models our approach is well suited for the conservative\npricing of equity default-swaps.\n"
    },
    {
        "paper_id": 1002.2604,
        "authors": "Dirk Tasche",
        "title": "The two defaults scenario for stressing credit portfolio loss\n  distributions",
        "comments": "20 pages, 1 figure, 2 tables",
        "journal-ref": "Journal of Risk and Financial Management 9(1), 1-18, 2016",
        "doi": "10.3390/jrfm9010001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The impact of a stress scenario of default events on the loss distribution of\na credit portfolio can be assessed by determining the loss distribution\nconditional on these events. While it is conceptually easy to estimate loss\ndistributions conditional on default events by means of Monte Carlo simulation,\nit becomes impractical for two or more simultaneous defaults as then the\nconditioning event is extremely rare. We provide an analytical approach to the\ncalculation of the conditional loss distribution for the CreditRisk+ portfolio\nmodel with independent random loss given default distributions. The analytical\nsolution for this case can be used to check the accuracy of an approximation to\nthe conditional loss distribution whereby the unconditional model is run with\nstressed input probabilities of default (PDs). It turns out that this\napproximation is unbiased. Numerical examples, however, suggest that the\napproximation may be seriously inaccurate but that the inaccuracy leads to\noverestimation of tail losses and hence the approach errs on the conservative\nside.\n"
    },
    {
        "paper_id": 1002.274,
        "authors": "Constantinos Kardaras",
        "title": "Arbitrage strategy",
        "comments": "2 pages; a version of this paper will appear in the Encyclopaedia of\n  Quantitative Finance, John Wiley and Sons Inc",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An arbitrage strategy allows a financial agent to make certain profit out of\nnothing, i.e., out of zero initial investment. This has to be disallowed on\neconomic basis if the market is in equilibrium state, as opportunities for\nriskless profit would result in an instantaneous movement of prices of certain\nfinancial instruments. The principle of not allowing for arbitrage\nopportunities in financial markets has far-reaching consequences, most notably\nthe option-pricing and hedging formulas in complete markets.\n"
    },
    {
        "paper_id": 1002.2741,
        "authors": "Constantinos Kardaras",
        "title": "Free Lunch",
        "comments": "3 pages; a version of this note will appear in the Encyclopaedia of\n  Quantitative Finance, John Wiley and Sons Inc",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The concept of absence of opportunities for free lunches is one of the\npillars in the economic theory of financial markets. This natural assumption\nhas proved very fruitful and has lead to great mathematical, as well as\neconomical, insights in Quantitative Finance. Formulating rigorously the exact\ndefinition of absence of opportunities for riskless profit turned out to be a\nhighly non-trivial fact that troubled mathematicians and economists for at\nleast two decades. The purpose of this note is to give a quick (and,\nnecessarily, incomplete) account of the recent work aimed at providing a simple\nand intuitive no-free-lunch assumption that would suffice in formulating a\nversion of the celebrated Fundamental Theorem of Asset Pricing.\n"
    },
    {
        "paper_id": 1002.2909,
        "authors": "Yuri A. Katz and Nikolai V. Shokhirev",
        "title": "Default Risk Modeling Beyond the First-Passage Approximation: Extended\n  Black-Cox Model",
        "comments": "Accepted by Phys. Rev. E",
        "journal-ref": "Phys. Rev. E 82, 016116 (2010)",
        "doi": "10.1103/PhysRevE.82.016116",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a generalization of the Black-Cox structural model of default\nrisk. The extended model captures uncertainty related to firm's ability to\navoid default even if company's liabilities momentarily exceeding its assets.\nDiffusion in a linear potential with the radiation boundary condition is used\nto mimic a company's default process. The exact solution of the corresponding\nFokker-Planck equation allows for derivation of analytical expressions for the\ncumulative probability of default and the relevant hazard rate. Obtained closed\nformulas fit well the historical data on global corporate defaults and\ndemonstrate the split behavior of credit spreads for bonds of companies in\ndifferent categories of speculative-grade ratings with varying time to\nmaturity. Introduction of the finite rate of default at the boundary improves\nvaluation of credit risk for short time horizons, which is the key advantage of\nthe proposed model. We also consider the influence of uncertainty in the\ninitial distance to the default barrier on the outcome of the model and\ndemonstrate that this additional source of incomplete information may be\nresponsible for non-zero credit spreads for bonds with very short time to\nmaturity.\n"
    },
    {
        "paper_id": 1002.3256,
        "authors": "Caroline Hillairet (CMAP), Ying Jiao (PMA)",
        "title": "Information Asymmetry in Pricing of Credit Derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the pricing of credit derivatives with asymmetric information. The\nmanagers have complete information on the value process of the firm and on the\ndefault threshold, while the investors on the market have only partial\nobservations, especially about the default threshold. Different information\nstructures are distinguished using the framework of enlargement of filtrations.\nWe specify risk neutral probabilities and we evaluate default sensitive\ncontingent claims in these cases.\n"
    },
    {
        "paper_id": 1002.3432,
        "authors": "Tian Qiu, Bo Zheng and Guang Chen",
        "title": "Adaptive financial networks with static and dynamic thresholds",
        "comments": "14 pages, 9 figures",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/12/4/043057",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on the daily data of American and Chinese stock markets, the dynamic\nbehavior of a financial network with static and dynamic thresholds is\ninvestigated. Compared with the static threshold, the dynamic threshold\nsuppresses the large fluctuation induced by the cross-correlation of individual\nstock prices, and leads to a stable topological structure in the dynamic\nevolution. Long-range time-correlations are revealed for the average clustering\ncoefficient, average degree and cross-correlation of degrees. The dynamic\nnetwork shows a two-peak behavior in the degree distribution.\n"
    },
    {
        "paper_id": 1002.356,
        "authors": "M. Bardoscia, P. Facchi, S. Pascazio, A. Trullo",
        "title": "Spin Glass Model of Operational Risk",
        "comments": "12 Pages, 15 Figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze operational risk in terms of a spin glass model. Several regimes\nare investigated, as a functions of the parameters that characterize the\ndynamics. The system is found to be robust against variations of these\nparameters. We unveil the presence of limit cycles and scrutinize the features\nof the asymptotic state.\n"
    },
    {
        "paper_id": 1002.3627,
        "authors": "Beatrice Acciaio, Hans Foellmer, Irina Penner",
        "title": "Risk assessment for uncertain cash flows: Model ambiguity, discounting\n  ambiguity, and the role of bubbles",
        "comments": "40 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the risk assessment of uncertain cash flows in terms of dynamic\nconvex risk measures for processes as introduced in Cheridito, Delbaen, and\nKupper (2006). These risk measures take into account not only the amounts but\nalso the timing of a cash flow. We discuss their robust representation in terms\nof suitably penalized probability measures on the optional sigma-field. This\nyields an explicit analysis both of model and discounting ambiguity. We focus\non supermartingale criteria for different notions of time consistency. In\nparticular we show how bubbles may appear in the dynamic penalization, and how\nthey cause a breakdown of asymptotic safety of the risk assessment procedure.\n"
    },
    {
        "paper_id": 1002.3633,
        "authors": "Jim Gatheral, Antoine Jacquier",
        "title": "Convergence of Heston to SVI",
        "comments": "5 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this short note, we prove by an appropriate change of variables that the\nSVI implied volatility parameterization presented in Gatheral's book and the\nlarge-time asymptotic of the Heston implied volatility agree algebraically,\nthus confirming a conjecture from Gatheral as well as providing a simpler\nexpression for the asymptotic implied volatility in the Heston model. We show\nhow this result can help in interpreting SVI parameters.\n"
    },
    {
        "paper_id": 1002.3681,
        "authors": "B\\'enamar Chouaf, Serguei Pergamenchtchikov (LMRS)",
        "title": "Optimal investment with bounded VaR for power utility functions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the optimal investment problem for Black-Scholes type financial\nmarket with bounded VaR measure on the whole investment interval $[0,T]$. The\nexplicit form for the optimal strategies is found.\n"
    },
    {
        "paper_id": 1002.3689,
        "authors": "Federico Bassetti, Giuseppe Toscani",
        "title": "Explicit equilibria in a kinetic model of gambling",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.81.066115",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce and discuss a nonlinear kinetic equation of Boltzmann type which\ndescribes the evolution of wealth in a pure gambling process, where the entire\nsum of wealths of two agents is up for gambling, and randomly shared between\nthe agents. For this equation the analytical form of the steady states is found\nfor various realizations of the random fraction of the sum which is shared to\nthe agents. Among others, Gibbs distribution appears as steady state in case of\na uniformly distributed random fraction, while Gamma distribution appears for a\nrandom fraction which is Beta distributed. The case in which the gambling game\nis only conservative-in-the-mean is shown to lead to an explicit heavy tailed\ndistribution.\n"
    },
    {
        "paper_id": 1002.3747,
        "authors": "X.F. Jiang, B. Zheng, J. Shen",
        "title": "Large-volatility dynamics in financial markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the large-volatility dynamics in financial markets, based on\nthe minute-to-minute and daily data of the Chinese Indices and German DAX. The\ndynamic relaxation both before and after large volatilities is characterized by\na power law, and the exponents $p_\\pm$ usually vary with the strength of the\nlarge volatilities. The large-volatility dynamics is time-reversal symmetric at\nthe time scale in minutes, while asymmetric at the daily time scale. Careful\nanalysis reveals that the time-reversal asymmetry is mainly induced by\nexogenous events. It is also the exogenous events which drive the financial\ndynamics to a non-stationary state. Different characteristics of the Chinese\nand German stock markets are uncovered.\n"
    },
    {
        "paper_id": 1002.3794,
        "authors": "Beatrice Acciaio, Irina Penner",
        "title": "Dynamic risk measures",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper gives an overview of the theory of dynamic convex risk measures\nfor random variables in discrete time setting. We summarize robust\nrepresentation results of conditional convex risk measures, and we characterize\nvarious time consistency properties of dynamic risk measures in terms of\nacceptance sets, penalty functions, and by supermartingale properties of risk\nprocesses and penalty functions.\n"
    },
    {
        "paper_id": 1002.4592,
        "authors": "Jasmina Hasanhodzic, Andrew W. Lo, Emanuele Viola",
        "title": "Is It Real, or Is It Randomized?: A Financial Turing Test",
        "comments": "12 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct a financial \"Turing test\" to determine whether human subjects\ncan differentiate between actual vs. randomized financial returns. The\nexperiment consists of an online video-game (http://arora.ccs.neu.edu) where\nplayers are challenged to distinguish actual financial market returns from\nrandom temporal permutations of those returns. We find overwhelming statistical\nevidence (p-values no greater than 0.5%) that subjects can consistently\ndistinguish between the two types of time series, thereby refuting the\nwidespread belief that financial markets \"look random.\" A key feature of the\nexperiment is that subjects are given immediate feedback regarding the validity\nof their choices, allowing them to learn and adapt. We suggest that such novel\ninterfaces can harness human capabilities to process and extract information\nfrom financial data in ways that computers cannot.\n"
    },
    {
        "paper_id": 1002.4641,
        "authors": "Vitus J. Leung, Randall A. LaViolette",
        "title": "Sensitivity of the Performance of a Simple Exchange Model to its\n  Topology",
        "comments": "20 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a simple exchange model in which price is fixed and the amount of a\ngood transferred between actors depends only on the actors' respective budgets\nand the existence of a link between transacting actors. The model induces a\nsimply-connected but possibly multi-component bipartite graph. A trading\nsession on a fixed graph consists of a sequence of exchanges between connected\nbuyers and sellers until no more exchanges are possible. We deem a trading\nsession \"feasible\" if all of the buyers satisfy their respective demands. If\nall trading sessions are feasible the graph is deemed \"successful\", otherwise\nthe feasibility of a trading session depends on the order of the sequence of\nexchanges. We demonstrate that topology is important for the success of trading\nsessions on graphs. In particular, for the case that supply equals demand for\neach component of the graph, we prove that the graph is successful if and only\nif the graph consists of components each of which are complete bipartite. For\nthe case that supply exceeds demand, we prove that the other topologies also\ncan be made successful but with finite reserve (i.e., excess supply)\nrequirements that may grow proportional to the number of buyers. Finally, with\ncomputations for a small instance of the model, we provide an example of the\nwide range of performance in which only the connectivity varies. These results\ntaken together place limits on the improvements in performance that can be\nexpected from proposals to increase the connectivity of sparse exchange\nnetworks.\n"
    },
    {
        "paper_id": 1002.4744,
        "authors": "Yongjoo Baek, Sang Hoon Lee, Hawoong Jeong",
        "title": "Market behavior and performance of different strategy evaluation schemes",
        "comments": "10 pages, 6 figures",
        "journal-ref": "Phys. Rev. E 82, 026109 (2010)",
        "doi": "10.1103/PhysRevE.82.026109",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Strategy evaluation schemes are a crucial factor in any agent-based market\nmodel, as they determine the agents' strategy preferences and consequently\ntheir behavioral pattern. This study investigates how the strategy evaluation\nschemes adopted by agents affect their performance in conjunction with the\nmarket circumstances. We observe the performance of three strategy evaluation\nschemes, the history-dependent wealth game, the trend-opposing minority game,\nand the trend-following majority game, in a stock market where the price is\nexogenously determined. The price is either directly adopted from the real\nstock market indices or generated with a Markov chain of order $\\le 2$. Each\nscheme's success is quantified by average wealth accumulated by the traders\nequipped with the scheme. The wealth game, as it learns from the history, shows\nrelatively good performance unless the market is highly unpredictable. The\nmajority game is successful in a trendy market dominated by long periods of\nsustained price increase or decrease. On the other hand, the minority game is\nsuitable for a market with persistent zig-zag price patterns. We also discuss\nthe consequence of implementing finite memory in the scoring processes of\nstrategies. Our findings suggest under which market circumstances each\nevaluation scheme is appropriate for modeling the behavior of real market\ntraders.\n"
    },
    {
        "paper_id": 1002.4817,
        "authors": "Giacomo Bormetti, Valentina Cazzola, Danilo Delpini, Giacomo Livan",
        "title": "Accounting for risk of non linear portfolios: a novel Fourier approach",
        "comments": "10 pages, 12 figures. Final version accepted for publication on Eur.\n  Phys. J. B",
        "journal-ref": "Eur. Phys. J. B 76 157-165 (2010)",
        "doi": "10.1140/epjb/e2010-00199-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The presence of non linear instruments is responsible for the emergence of\nnon Gaussian features in the price changes distribution of realistic\nportfolios, even for Normally distributed risk factors. This is especially true\nfor the benchmark Delta Gamma Normal model, which in general exhibits\nexponentially damped power law tails. We show how the knowledge of the model\ncharacteristic function leads to Fourier representations for two standard risk\nmeasures, the Value at Risk and the Expected Shortfall, and for their\nsensitivities with respect to the model parameters. We detail the numerical\nimplementation of our formulae and we emphasizes the reliability and efficiency\nof our results in comparison with Monte Carlo simulation.\n"
    },
    {
        "paper_id": 1002.5031,
        "authors": "Christian Fries and Joerg Kampen",
        "title": "Global existence, regularity and a probabilistic scheme for a class of\n  ultraparabolic Cauchy problems",
        "comments": "25 pages, revised, results extended",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we establish a constructive method in order to show global\nexistence and regularity for a class of degenerate parabolic Cauchy problems\nwhich satisfy a weak Hoermander condition on a subset of the domain where the\ndata are measurable and which have regular data on the complementary set of the\ndomain. This result has practical incentives related to the computation of\nGreeks in reduced LIBOR market models, which are standard computable\napproximations of the HJM-description of interest rate markets. The method\nleads to a probabilistic scheme for the computation of the value function and\nits sensitivities based on Malliavin calculus. From a practical perspective the\nmain contribution of the paper is an Monte-Carlo algorithm which includes\nweight corrections for paths which move in time into a region where a (weak)\nHoermander condition holds.\n"
    },
    {
        "paper_id": 1002.5041,
        "authors": "Rudra P. Jena, Peter Tankov",
        "title": "Arbitrage Opportunities in Misspecified Stochastic volatility Models",
        "comments": "Several typos in section 5 have been corrected in this new version\n  (with thanks to Amy Y. Zhou from MIT)",
        "journal-ref": "SIAM J. Finan. Math. 2, pp. 317-341 (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There is vast empirical evidence that given a set of assumptions on the\nreal-world dynamics of an asset, the European options on this asset are not\nefficiently priced in options markets, giving rise to arbitrage opportunities.\nWe study these opportunities in a generic stochastic volatility model and\nexhibit the strategies which maximize the arbitrage profit. In the case when\nthe misspecified dynamics is a classical Black-Scholes one, we give a new\ninterpretation of the classical butterfly and risk reversal contracts in terms\nof their (near) optimality for arbitrage strategies. Our results are\nillustrated by a numerical example including transaction costs.\n"
    },
    {
        "paper_id": 1003.0041,
        "authors": "Alberto Elices, Jean-Pierre Fouque",
        "title": "Perturbed Copula: Introducing the skew effect in the co-dependence",
        "comments": "34 pages, 6 figures and 3 tables",
        "journal-ref": "Reduced version published in Risk Magazine, Vol. 25, No. 1, pp.\n  98-103, January 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Gaussian copulas are widely used in the industry to correlate two random\nvariables when there is no prior knowledge about the co-dependence between\nthem. The perturbed Gaussian copula approach allows introducing the skew\ninformation of both random variables into the co-dependence structure. The\nanalytical expression of this copula is derived through an asymptotic expansion\nunder the assumption of a common fast mean reverting stochastic volatility\nfactor. This paper applies this new perturbed copula to the valuation of\nderivative products; in particular FX quanto options to a third currency. A\ncalibration procedure to fit the skew of both underlying securities is\npresented. The action of the perturbed copula is interpreted compared to the\nGaussian copula. A real worked example is carried out comparing both copulas\nand a local volatility model with constant correlation for varying maturities,\ncorrelations and skew configurations.\n"
    },
    {
        "paper_id": 1003.0135,
        "authors": "Shimao Fan, Sheng Xiong, Wei-Shih Yang",
        "title": "A proof of a conjecture in the Cram\\'er-Lundberg model with investments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we discuss the Cram\\'er-Lundberg model with investments, where\nthe price of the invested risk asset follows a geometric Brownian motion with\ndrift $a$ and volatility $\\sigma> 0.$ By assuming there is a cap on the claim\nsizes, we prove that the probability of ruin has at least an algebraic decay\nrate if $2a/\\sigma^2 > 1$. More importantly, without this assumption, we show\nthat the probability of ruin is certain for all initial capital $u$, if\n$2a/\\sigma^2 \\le 1$.\n"
    },
    {
        "paper_id": 1003.0168,
        "authors": "Guo-Hua Mu (ECUST), Wei-Xing Zhou (ECUST), Wei Chen (SZSE), Janos\n  Kertesz (BME)",
        "title": "Order flow dynamics around extreme price changes on an emerging stock\n  market",
        "comments": "22 pages",
        "journal-ref": "New J. Phys. 12 (2010) 075037",
        "doi": "10.1088/1367-2630/12/7/075037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the dynamics of order flows around large intraday price changes\nusing ultra-high-frequency data from the Shenzhen Stock Exchange. We find a\nsignificant reversal of price for both intraday price decreases and increases\nwith a permanent price impact. The volatility, the volume of different types of\norders, the bid-ask spread, and the volume imbalance increase before the\nextreme events and decay slowly as a power law, which forms a well-established\npeak. The volume of buy market orders increases faster and the corresponding\npeak appears earlier than for sell market orders around positive events, while\nthe volume peak of sell market orders leads buy market orders in the magnitude\nand time around negative events. When orders are divided into four groups\naccording to their aggressiveness, we find that the behaviors of order volume\nand order number are similar, except for buy limit orders and canceled orders\nthat the peak of order number postpones two minutes later after the peak of\norder volume, implying that investors placing large orders are more informed\nand play a central role in large price fluctuations. We also study the relative\nrates of different types of orders and find differences in the dynamics of\nrelative rates between buy orders and sell orders and between individual\ninvestors and institutional investors. There is evidence showing that\ninstitutions behave very differently from individuals and that they have more\naggressive strategies. Combing these findings, we conclude that institutional\ninvestors are more informed and play a more influential role in driving large\nprice fluctuations.\n"
    },
    {
        "paper_id": 1003.0709,
        "authors": "Mats Brod\\'en, Peter Tankov",
        "title": "Tracking errors from discrete hedging in exponential L\\'evy models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the errors arising from discrete readjustment of the hedging\nportfolio when hedging options in exponential Levy models, and establish the\nrate at which the expected squared error goes to zero when the readjustment\nfrequency increases. We compare the quadratic hedging strategy with the common\nmarket practice of delta hedging, and show that for discontinuous option\npay-offs the latter strategy may suffer from very large discretization errors.\nFor options with discontinuous pay-offs, the convergence rate depends on the\nunderlying Levy process, and we give an explicit relation between the rate and\nthe Blumenthal-Getoor index of the process.\n"
    },
    {
        "paper_id": 1003.0764,
        "authors": "Dorje C. Brody, Julian Brody, Bernhard K. Meister, Matthew F. Parry",
        "title": "Outsider Trading",
        "comments": "2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we examine inefficiencies and information disparity in the\nJapanese stock market. By carefully analysing information publicly available on\nthe internet, an `outsider' to conventional statistical arbitrage\nstrategies--which are based on market microstructure, company releases, or\nanalyst reports--can nevertheless pursue a profitable trading strategy. A large\nvolume of blog data is used to demonstrate the existence of an inefficiency in\nthe market. An information-based model that replicates the trading strategy is\ndeveloped to estimate the degree of information disparity.\n"
    },
    {
        "paper_id": 1003.0793,
        "authors": "B. Coluzzi, M. Ghil, S. Hallegatte, and G. Weisbuch",
        "title": "Boolean delay equations on networks: An application to economic damage\n  propagation",
        "comments": "Latex, 52 pages with 22 eps figures",
        "journal-ref": "International Journal of Bifurcation and Chaos 21, (2011)\n  3511-3548",
        "doi": "10.1142/S0218127411030702",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce economic models based on Boolean Delay Equations: this formalism\nmakes easier to take into account the complexity of the interactions between\nfirms and is particularly appropriate for studying the propagation of an\ninitial damage due to a catastrophe. Here we concentrate on simple cases, which\nallow to understand the effects of multiple concurrent production paths as well\nas the presence of stochasticity in the path time lengths or in the network\nstructure.\n  In absence of flexibility, the shortening of production of a single firm in\nan isolated network with multiple connections usually ends up by attaining a\nfinite fraction of the firms or the whole economy, whereas the interactions\nwith the outside allow a partial recovering of the activity, giving rise to\nperiodic solutions with waves of damage which propagate across the structure.\nThe damage propagation speed is strongly dependent upon the topology. The\nexistence of multiple concurrent production paths does not necessarily imply a\nslowing down of the propagation, which can be as fast as the shortest path.\n"
    },
    {
        "paper_id": 1003.0889,
        "authors": "Damiano Brigo, Mirela Predescu, Agostino Capponi",
        "title": "Credit Default Swaps Liquidity modeling: A survey",
        "comments": "36 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review different approaches for measuring the impact of liquidity on CDS\nprices. We start with reduced form models incorporating liquidity as an\nadditional discount rate. We review Chen, Fabozzi and Sverdlove (2008) and\nBuhler and Trapp (2006, 2008), adopting different assumptions on how liquidity\nrates enter the CDS premium rate formula, about the dynamics of liquidity rate\nprocesses and about the credit-liquidity correlation. Buhler and Trapp (2008)\nprovides the most general and realistic framework, incorporating correlation\nbetween liquidity and credit, liquidity spillover effects between bonds and CDS\ncontracts and asymmetric liquidity effects on the Bid and Ask CDS premium\nrates. We then discuss the Bongaerts, De Jong and Driessen (2009) study which\nderives an equilibrium asset pricing model incorporating liquidity effects.\nFindings include that both expected illiquidity and liquidity risk have a\nstatistically significant impact on expected CDS returns. We finalize our\nreview with a discussion of Predescu et al (2009), which analyzes also data\nin-crisis. This is a statistical model that associates an ordinal liquidity\nscore with each CDS reference entity and allows one to compare liquidity of\nover 2400 reference entities. This study points out that credit and illiquidity\nare correlated, with a smile pattern. All these studies highlight that CDS\npremium rates are not pure measures of credit risk. Further research is needed\nto measure liquidity premium at CDS contract level and to disentangle liquidity\nfrom credit effectively.\n"
    },
    {
        "paper_id": 1003.1344,
        "authors": "Daniel T. Cassidy (1), Michael J. Hamp (2), Rachid Ouyed (3) ((1)\n  Department of Engineering Physics, McMaster University, Hamilton, Ontario,\n  Canada, (2) Scotiabank, Toronto, Ontario, Canada, (3) Department of Physics\n  and Astronomy, University of Calgary, Calgary, Alberta, Canada)",
        "title": "Student's t-Distribution Based Option Sensitivities: Greeks for the\n  Gosset Formulae",
        "comments": "28 pages, 14 figures and 6 tables. Follow-up to the arXiv:0906.4092\n  work/paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  European options can be priced when returns follow a Student's\nt-distribution, provided that the asset is capped in value or the distribution\nis truncated. We call pricing of options using a log Student's t-distribution a\nGosset approach, in honour of W.S. Gosset. In this paper, we compare the greeks\nfor Gosset and Black-Scholes formulae and we discuss implementation. The\nt-distribution requires a shape parameter \\nu to match the \"fat tails\" of the\nobserved returns. For large \\nu, the Gosset and Black-Scholes formulae are\nequivalent. The Gosset formulae removes the requirement that the volatility be\nknown, and in this sense can be viewed as an extension of the Black-Scholes\nformula.\n"
    },
    {
        "paper_id": 1003.1802,
        "authors": "Edouard Debonneuil",
        "title": "A simple model of mortality trends aiming at universality: Lee Carter +\n  Cohort",
        "comments": "5 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Lee Carter modelling framework is widely used because of its simplicity\nand robustness despite its inability to model specific cohort effects. A large\nnumber of extensions have been proposed that model cohort effects but there is\nno consensus. It is difficult to simultaneously account for cohort effects and\nage-adjusted improvements and we here test a simple model that accounts for\nboth: we simply add a non age-adjusted cohort component to the Lee Carter\nframework. This is a trade-off between accuracy and robustness but, for various\ncountries present in the Human Mortality Database and compared to various\nmodels, the model accurately fits past mortality data and gives good\nbacktesting projections.\n"
    },
    {
        "paper_id": 1003.1848,
        "authors": "Guoping Xu and Harry Zheng",
        "title": "Basket Options Valuation for a Local Volatility Jump-Diffusion Model\n  with the Asymptotic Expansion Method",
        "comments": "16 pages, 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we discuss the basket options valuation for a jump-diffusion\nmodel. The underlying asset prices follow some correlated local volatility\ndiffusion processes with systematic jumps. We derive a forward partial integral\ndifferential equation (PIDE) for general stochastic processes and use the\nasymptotic expansion method to approximate the conditional expectation of the\nstochastic variance associated with the basket value process. The numerical\ntests show that the suggested method is fast and accurate in comparison with\nthe Monte Carlo and other methods in most cases.\n"
    },
    {
        "paper_id": 1003.2321,
        "authors": "Hideaki Aoyama, Yoshi Fujiwara, and Mauro Gallegati",
        "title": "Micro-Macro Relation of Production - The Double Scaling Law for\n  Statistical Physics of Economy -",
        "comments": "5 pages with 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that an economic system populated by multiple agents generates an\nequilibrium distribution in the form of multiple scaling laws of conditional\nPDFs, which are sufficient for characterizing the probability distribution. The\nexistence of the double scaling law is demonstrated empirically for the sales\nand the labor of one million Japanese firms. Theoretical study of the scaling\nlaws suggests lognormal joint distributions of sales and labor and a scaling\nlaw for labor productivity, both of which are confirmed empirically. This\nframework offers characterization of the equilibrium distribution with a small\nnumber of scaling indices, which determine macroscopic quantities, thus setting\nthe stage for an equivalence with statistical physics, bridging micro- and\nmacro-economics.\n"
    },
    {
        "paper_id": 1003.2459,
        "authors": "Zhi-Qiang Jiang (ECUST) and Wei-Xing Zhou (ECUST)",
        "title": "Complex stock trading network among investors",
        "comments": "14 pages and 12 figures",
        "journal-ref": "Physica A 389 (2010) 4929?4941",
        "doi": "10.1016/j.physa.2010.07.024",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide an empirical investigation aimed at uncovering the statistical\nproperties of intricate stock trading networks based on the order flow data of\na highly liquid stock (Shenzhen Development Bank) listed on Shenzhen Stock\nExchange during the whole year of 2003. By reconstructing the limit order book,\nwe can extract detailed information of each executed order for each trading day\nand demonstrate that the trade size distributions for different trading days\nexhibit power-law tails and that most of the estimated power-law exponents are\nwell within the L{\\'e}vy stable regime. Based on the records of order matching\namong investors, we can construct a stock trading network for each trading day,\nin which the investors are mapped into nodes and each transaction is translated\nas a direct edge from the seller to the buyer with the trade size as its\nweight. We find that all the trading networks comprise a giant component and\nhave power-law degree distributions and disassortative architectures. In\nparticular, the degrees are correlated with order sizes by a power-law\nfunction. By regarding the size executed order as its fitness, the fitness\nmodel can reproduce the empirical power-law degree distribution.\n"
    },
    {
        "paper_id": 1003.2521,
        "authors": "Mark Davis and Sebastien Lleo",
        "title": "Risk Sensitive Investment Management with Affine Processes: a Viscosity\n  Approach",
        "comments": "32 pages",
        "journal-ref": "in \"Recent Advances in Financial Engineering 2009 - Proceedings of\n  the KIER-TMU International Workshop on Financial Engineering 2009.\" M.\n  Kijima, C. Hara and K. Tanaka editors. World Scientific Publishing Co. 2010.",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we extend the jump-diffusion model proposed by Davis and Lleo\nto include jumps in asset prices as well as valuation factors. The criterion,\nfollowing earlier work by Bielecki, Pliska, Nagai and others, is risk-sensitive\noptimization (equivalent to maximizing the expected growth rate subject to a\nconstraint on variance.) In this setting, the Hamilton- Jacobi-Bellman equation\nis a partial integro-differential PDE. The main result of the paper is to show\nthat the value function of the control problem is the unique viscosity solution\nof the Hamilton-Jacobi-Bellman equation.\n"
    },
    {
        "paper_id": 1003.2539,
        "authors": "Sayantan Ghosh, P. Manimaran and Prasanta K. Panigrahi",
        "title": "Characterizing Multi-Scale Self-Similar Behavior and Non-Statistical\n  Properties of Financial Time Series",
        "comments": "11 pages, 8 figures, bibliography updated, conclusion added, minor\n  changes in the manuscript",
        "journal-ref": "Physica A, 390, 23-24, 4304-4316 (2011)",
        "doi": "10.1016/j.physa.2011.06.054",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We make use of wavelet transform to study the multi-scale, self similar\nbehavior and deviations thereof, in the stock prices of large companies,\nbelonging to different economic sectors. The stock market returns exhibit\nmulti-fractal characteristics, with some of the companies showing deviations at\nsmall and large scales. The fact that, the wavelets belonging to the\nDaubechies' (Db) basis enables one to isolate local polynomial trends of\ndifferent degrees, plays the key role in isolating fluctuations at different\nscales. One of the primary motivations of this work is to study the emergence\nof the $k^{-3}$ behavior \\cite{hes5} of the fluctuations starting with high\nfrequency fluctuations. We make use of Db4 and Db6 basis sets to respectively\nisolate local linear and quadratic trends at different scales in order to study\nthe statistical characteristics of these financial time series. The\nfluctuations reveal fat tail non-Gaussian behavior, unstable periodic\nmodulations, at finer scales, from which the characteristic $k^{-3}$ power law\nbehavior emerges at sufficiently large scales. We further identify stable\nperiodic behavior through the continuous Morlet wavelet.\n"
    },
    {
        "paper_id": 1003.2688,
        "authors": "Andrew W. Lo, Mark T. Mueller",
        "title": "WARNING: Physics Envy May Be Hazardous To Your Wealth!",
        "comments": "v3 adds 2 references",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The quantitative aspirations of economists and financial analysts have for\nmany years been based on the belief that it should be possible to build models\nof economic systems - and financial markets in particular - that are as\npredictive as those in physics. While this perspective has led to a number of\nimportant breakthroughs in economics, \"physics envy\" has also created a false\nsense of mathematical precision in some cases. We speculate on the origins of\nphysics envy, and then describe an alternate perspective of economic behavior\nbased on a new taxonomy of uncertainty. We illustrate the relevance of this\ntaxonomy with two concrete examples: the classical harmonic oscillator with\nsome new twists that make physics look more like economics, and a quantitative\nequity market-neutral strategy. We conclude by offering a new interpretation of\ntail events, proposing an \"uncertainty checklist\" with which our taxonomy can\nbe implemented, and considering the role that quants played in the current\nfinancial crisis.\n"
    },
    {
        "paper_id": 1003.2692,
        "authors": "Ivan O. Kitov",
        "title": "Modeling share prices of banks and bankrupts",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Share prices of financial companies from the S&P 500 list have been modeled\nby a linear function of consumer price indices in the USA. The Johansen and\nEngle-Granger tests for cointegration both demonstrated the presence of an\nequilibrium long-term relation between observed and predicted time series.\nEconometrically, the pricing concept is valid. For several companies, share\nprices are defined only by CPI readings in the past. Therefore, our empirical\npricing model is a deterministic one. For a few companies, including Lehman\nBrothers, AIG, Freddie Mac and Fannie Mae, negative share prices could be\nforeseen in May-September 2008. One might interpret the negative share prices\nas a sign of approaching bankruptcies.\n"
    },
    {
        "paper_id": 1003.292,
        "authors": "Vincenzo Liberatore",
        "title": "Computational LPPL Fit to Financial Bubbles",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The log-periodic power law (LPPL) is a model of asset prices during\nendogenous bubbles. If the on-going development of a bubble is suspected, asset\nprices can be fit numerically to the LPPL law. The best solutions can then\nindicate whether a bubble is in progress and, if so, the bubble critical time\n(i.e., when the bubble is expected to burst). Consequently, the LPPL model is\nuseful only if the data can be fit to the model with algorithms that are\naccurate and computationally efficient. In this paper, we address primarily the\ncomputational efficiency and secondarily the precision of the LPPL non-linear\nleast-square fit. Specifically, we present a parallel Levenberg-Marquardt\nalgorithm (LMA) for LPPL least-square fit that sped up computation of more than\na factor of four over a sequential LMA on historical and synthetic price\nseries. Additionally, we isolate a linear sub-structure of the LPPL\nleast-square fit that can be paired with an exact computation of the Jacobian,\ngive new settings for the Levenberg-Marquardt damping factor, and describe a\nheuristic method to choose initial solutions.\n"
    },
    {
        "paper_id": 1003.293,
        "authors": "Qingshuo Song, G. Yin, Chao Zhu",
        "title": "Utility Maximization of an Indivisible Market with Transaction Costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work takes up the challenges of utility maximization problem when the\nmarket is indivisible and the transaction costs are included. First there is a\nso-called solvency region given by the minimum margin requirement in the\nproblem formulation. Then the associated utility maximization is formulated as\nan optimal switching problem. The diffusion turns out to be degenerate and the\nboundary of domain is an unbounded set. One no longer has the continuity of the\nvalue function without posing further conditions due to the degeneracy and the\ndependence of the random terminal time on the initial data. This paper provides\nsufficient conditions under which the continuity of the value function is\nobtained. The essence of our approach is to find a sequence of continuous\nfunctions locally uniformly converging to the desired value function. Thanks to\ncontinuity, the value function can be characterized by using the notion of\nviscosity solution of certain quasi-variational inequality.\n"
    },
    {
        "paper_id": 1003.2981,
        "authors": "Gabriella Vaglica, Fabrizio Lillo, Rosario N. Mantegna",
        "title": "Statistical identification with hidden Markov models of large order\n  splitting strategies in an equity market",
        "comments": "26 pages, 12 figures",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/12/7/075031",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Large trades in a financial market are usually split into smaller parts and\ntraded incrementally over extended periods of time. We address these large\ntrades as hidden orders. In order to identify and characterize hidden orders we\nfit hidden Markov models to the time series of the sign of the tick by tick\ninventory variation of market members of the Spanish Stock Exchange. Our\nmethodology probabilistically detects trading sequences, which are\ncharacterized by a net majority of buy or sell transactions. We interpret these\npatches of sequential buying or selling transactions as proxies of the traded\nhidden orders. We find that the time, volume and number of transactions size\ndistributions of these patches are fat tailed. Long patches are characterized\nby a high fraction of market orders and a low participation rate, while short\npatches have a large fraction of limit orders and a high participation rate. We\nobserve the existence of a buy-sell asymmetry in the number, average length,\naverage fraction of market orders and average participation rate of the\ndetected patches. The detected asymmetry is clearly depending on the local\nmarket trend. We also compare the hidden Markov models patches with those\nobtained with the segmentation method used in Vaglica {\\it et al.} (2008) and\nwe conclude that the former ones can be interpreted as a partition of the\nlatter ones.\n"
    },
    {
        "paper_id": 1003.3114,
        "authors": "Stanislao Gualdi, Matus Medo, Yi-Cheng Zhang",
        "title": "Self-organized model of cascade spreading",
        "comments": "8 pages, 6 figures",
        "journal-ref": "EPJ B 79, 91-98 (2011)",
        "doi": "10.1140/epjb/e2010-10668-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study simultaneous price drops of real stocks and show that for high drop\nthresholds they follow a power-law distribution. To reproduce these collective\ndownturns, we propose a minimal self-organized model of cascade spreading based\non a probabilistic response of the system elements to stress conditions. This\nmodel is solvable using the theory of branching processes and the mean-field\napproximation. For a wide range of parameters, the system is in a critical\nstate and displays a power-law cascade-size distribution similar to the\nempirically observed one. We further generalize the model to reproduce\nvolatility clustering and other observed properties of real stocks.\n"
    },
    {
        "paper_id": 1003.3316,
        "authors": "L. Spadafora, G. P. Berman, and F. Borgonovi",
        "title": "Adiabaticity Conditions for Volatility Smile in Black-Scholes Pricing\n  Model",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1140/epjb/e2010-10305-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our derivation of the distribution function for future returns is based on\nthe risk neutral approach which gives a functional dependence for the European\ncall (put) option price, C(K), given the strike price, K, and the distribution\nfunction of the returns. We derive this distribution function using for C(K) a\nBlack-Scholes (BS) expression with volatility in the form of a volatility\nsmile. We show that this approach based on a volatility smile leads to relative\nminima for the distribution function (\"bad\" probabilities) never observed in\nreal data and, in the worst cases, negative probabilities. We show that these\nundesirable effects can be eliminated by requiring \"adiabatic\" conditions on\nthe volatility smile.\n"
    },
    {
        "paper_id": 1003.3582,
        "authors": "Marcel Nutz",
        "title": "Risk Aversion Asymptotics for Power Utility Maximization",
        "comments": "45 pages",
        "journal-ref": "Probability Theory and Related Fields, Vol. 152, No. 3-4, pp.\n  703-749, 2012",
        "doi": "10.1007/s00440-010-0334-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the economic problem of optimal consumption and investment with\npower utility. We study the optimal strategy as the relative risk aversion\ntends to infinity or to one. The convergence of the optimal consumption is\nobtained for general semimartingale models while the convergence of the optimal\ntrading strategy is obtained for continuous models. The limits are related to\nexponential and logarithmic utility. To derive these results, we combine\napproaches from optimal control, convex analysis and backward stochastic\ndifferential equations (BSDEs).\n"
    },
    {
        "paper_id": 1003.3796,
        "authors": "Ioane Muni Toke",
        "title": "\"Market making\" behaviour in an order book model and its impact on the\n  bid-ask spread",
        "comments": "17 pages, 9 figures",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-1766-5_4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It has been suggested that marked point processes might be good candidates\nfor the modelling of financial high-frequency data. A special class of point\nprocesses, Hawkes processes, has been the subject of various investigations in\nthe financial community. In this paper, we propose to enhance a basic\nzero-intelligence order book simulator with arrival times of limit and market\norders following mutually (asymmetrically) exciting Hawkes processes. Modelling\nis based on empirical observations on time intervals between orders that we\nverify on several markets (equity, bond futures, index futures). We show that\nthis simple feature enables a much more realistic treatment of the bid-ask\nspread of the simulated order book.\n"
    },
    {
        "paper_id": 1003.4118,
        "authors": "Regis Houssou and Olivier Besson",
        "title": "Indifference of Defaultable Bonds with Stochastic Intensity models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The utility-based pricing of defaultable bonds in the case of stochastic\nintensity models of default risk is discussed. The Hamilton-Jacobi- Bellman\n(HJB) equations for the value functions is derived. A finite difference method\nis used to solve this problem. The yield-spreads for both buyer and seller are\nextracted. The behaviour of the spread curve given the default intensity is\nanalyzed. Finally the impacts of the risk aversion and the correlation\ncoefficient are discussed.\n"
    },
    {
        "paper_id": 1003.4216,
        "authors": "Erhan Bayraktar, Xueying Hu, Virginia R. Young",
        "title": "Minimizing the Probability of Lifetime Ruin under Stochastic Volatility",
        "comments": "Keywords: Optimal investment, minimizing the probability of lifetime\n  ruin, stochastic volatility",
        "journal-ref": null,
        "doi": "10.1016/j.insmatheco.2011.04.001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We assume that an individual invests in a financial market with one riskless\nand one risky asset, with the latter's price following a diffusion with\nstochastic volatility. In the current financial market especially, it is\nimportant to include stochastic volatility in the risky asset's price process.\nGiven the rate of consumption, we find the optimal investment strategy for the\nindividual who wishes to minimize the probability of going bankrupt. To solve\nthis minimization problem, we use techniques from stochastic optimal control.\n"
    },
    {
        "paper_id": 1003.4299,
        "authors": "Irmina Czarna and Zbigniew Palmowski",
        "title": "Ruin probability with Parisian delay for a spectrally negative L\\'evy\n  risk process",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we analyze so-called Parisian ruin probability that happens\nwhen surplus process stays below zero longer than fixed amount of time\n$\\zeta>0$. We focus on general spectrally negative L\\'{e}vy insurance risk\nprocess. For this class of processes we identify expression for ruin\nprobability in terms of some other quantities that could be possibly calculated\nexplicitly in many models. We find its Cram\\'{e}r-type and\nconvolution-equivalent asymptotics when reserves tends to infinity. Finally, we\nanalyze few explicit examples.\n"
    },
    {
        "paper_id": 1003.4382,
        "authors": "S.I. Chernyshov, A.V. Voronin, S.A. Razumovsky",
        "title": "The Problem of Modeling of Economic Dynamics (new version)",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The correctness of Harrods model in the differential form is studied. The\ninadequacy of exponential growth of economy is shown; an alternative result is\nobtained. By example of Phillips model, an approach to correction of\nmacroeconomic models (in terms of initial prerequisites) is generalized. A\nmethodology based on balance relations for modelling of economic dynamics,\nincluding obtaining forecast estimates, is developed. The problems thus\nconsidered are reduced to the solution of Volterra and Fredholm integral\nequations of the second kind.\n"
    },
    {
        "paper_id": 1003.4797,
        "authors": "Johannes Ruf",
        "title": "Hedging under arbitrage",
        "comments": "Minor changes, accepted for publication in Journal of Mathematical\n  Finance",
        "journal-ref": null,
        "doi": "10.1111/j.1467-9965.2011.00502.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is shown that delta hedging provides the optimal trading strategy in terms\nof minimal required initial capital to replicate a given terminal payoff in a\ncontinuous-time Markovian context. This holds true in market models where no\nequivalent local martingale measure exists but only a square-integrable market\nprice of risk. A new probability measure is constructed, which takes the place\nof an equivalent local martingale measure. In order to ensure the existence of\nthe delta hedge, sufficient conditions are derived for the necessary\ndifferentiability of expectations indexed over the initial market\nconfiguration. The recently often discussed phenomenon of \"bubbles\" is a\nspecial case of the setting in this paper. Several examples at the end\nillustrate the techniques described in this work.\n"
    },
    {
        "paper_id": 1003.4881,
        "authors": "Florian Steiger",
        "title": "The Validity of Company Valuation Using Discounted Cash Flow Methods",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper closely examines theoretical and practical aspects of the widely\nused discounted cash flows (DCF) valuation method. It assesses its potentials\nas well as several weaknesses. A special emphasize is being put on the\nvaluation of companies using the DCF method. The paper finds that the\ndiscounted cash flow method is a powerful tool to analyze even complex\nsituations. However, the DCF method is subject to massive assumption bias and\neven slight changes in the underlying assumptions of an analysis can\ndrastically alter the valuation results. A practical example of these\nimplications is given using a scenario analysis.\n"
    },
    {
        "paper_id": 1003.4917,
        "authors": "Sonia Fourati",
        "title": "Explicit solutions for the exit problem for a class of L\\'evy processes.\n  Applications to the pricing of double barrier options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Lewis and Mordecki have computed the Wiener-Hopf factorization of a L\\'evy\nprocess whose restriction on $]0,+\\infty[$ of their L\\'evy measure has a\nrational Laplace transform. That allows to compute the distribution of\n$(X_t,\\inf_{0\\leq s\\leq t}X_s)$. For the same class of L\\'evy processes, we\ncompute the distribution of $ (X_t,\\inf_{0\\leq s\\leq t}X_s,\\sup_{0\\leq s\\leq t}\nX_s)$ and also the behavior of this triple at certain stopping time, like the\nfirst exit time of an interval containing the origin. Some applications to the\npricing of double barrier options with or without rebate are evocated.\n"
    },
    {
        "paper_id": 1003.5356,
        "authors": "V. Gontis, A. Kononovicius",
        "title": "Nonlinear Stochastic Model of Return matching to the data of New York\n  and Vilnius Stock Exchanges",
        "comments": "6 pages, 1 figure",
        "journal-ref": "JDySES, vol. 2, no. 1, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We scale and analyze the empirical data of return from New York and Vilnius\nstock exchanges matching it to the same nonlinear double stochastic model of\nreturn in financial market.\n"
    },
    {
        "paper_id": 1003.5514,
        "authors": "Martin Keller-Ressel and Johannes Muhle-Karbe",
        "title": "Asymptotic and Exact Pricing of Options on Variance",
        "comments": "22 pages, 4 figures. Fixed an incorrect citation",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the pricing of derivatives written on the discretely sampled\nrealized variance of an underlying security. In the literature, the realized\nvariance is usually approximated by its continuous-time limit, the quadratic\nvariation of the underlying log-price. Here, we characterize the small-time\nlimits of options on both objects. We find that the difference between them\nstrongly depends on whether or not the stock price process has jumps.\nSubsequently, we propose two new methods to evaluate the price of options on\nthe discretely sampled realized variance. One of the methods is approximative;\nit is based on correcting prices of options on quadratic variation by our\nasymptotic results. The other method is exact; it uses a novel randomization\napproach and applies Fourier-Laplace techniques. We compare the methods and\nillustrate our results by some numerical examples.\n"
    },
    {
        "paper_id": 1003.565,
        "authors": "Winslow Strong and Jean-Pierre Fouque",
        "title": "Diversity and Arbitrage in a Regulatory Breakup Model",
        "comments": "21 pages",
        "journal-ref": "Annals of Finance, Vol. 7, No. 3, 349-374, 2011",
        "doi": "10.1007/s10436-010-0175-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In 1999 Robert Fernholz observed an inconsistency between the normative\nassumption of existence of an equivalent martingale measure (EMM) and the\nempirical reality of diversity in equity markets. We explore a method of\nimposing diversity on market models by a type of antitrust regulation that is\ncompatible with EMMs. The regulatory procedure breaks up companies that become\ntoo large, while holding the total number of companies constant by imposing a\nsimultaneous merge of other companies. The regulatory events are assumed to\nhave no impact on portfolio values. As an example, regulation is imposed on a\nmarket model in which diversity is maintained via a log-pole in the drift of\nthe largest company. The result is the removal of arbitrage opportunities from\nthis market while maintaining the market's diversity.\n"
    },
    {
        "paper_id": 1003.5712,
        "authors": "David German",
        "title": "Overview of utility-based valuation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review the utility-based valuation method for pricing derivative\nsecurities in incomplete markets. In particular, we review the practical\napproach to the utility-based pricing by the means of computing the first order\nexpansion of marginal utility-based prices with respect to a small number of\nrandom endowments.\n"
    },
    {
        "paper_id": 1003.5926,
        "authors": "Wanfeng Yan and Ryan Woodard and Didier Sornette",
        "title": "Diagnosis and Prediction of Market Rebounds in Financial Markets",
        "comments": "49 pages, 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce the concept of \"negative bubbles\" as the mirror image of\nstandard financial bubbles, in which positive feedback mechanisms may lead to\ntransient accelerating price falls. To model these negative bubbles, we adapt\nthe Johansen-Ledoit-Sornette (JLS) model of rational expectation bubbles with a\nhazard rate describing the collective buying pressure of noise traders. The\nprice fall occurring during a transient negative bubble can be interpreted as\nan effective random downpayment that rational agents accept to pay in the hope\nof profiting from the expected occurrence of a possible rally. We validate the\nmodel by showing that it has significant predictive power in identifying the\ntimes of major market rebounds. This result is obtained by using a general\npattern recognition method which combines the information obtained at multiple\ntimes from a dynamical calibration of the JLS model. Error diagrams, Bayesian\ninference and trading strategies suggest that one can extract genuine\ninformation and obtain real skill from the calibration of negative bubbles with\nthe JLS model. We conclude that negative bubbles are in general predictably\nassociated with large rebounds or rallies, which are the mirror images of the\ncrashes terminating standard bubbles.\n"
    },
    {
        "paper_id": 1003.5984,
        "authors": "Guo-Hua Mu and Wei-Xing Zhou (ECUST)",
        "title": "Nonuniversal distributions of stock returns in an emerging market",
        "comments": "6 RevTex 4-1 pages, 7 eps figures, 1 table",
        "journal-ref": "Phys. Rev. E 82, 066103 (2010)",
        "doi": "10.1103/PhysRevE.82.066103",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There is convincing evidence showing that the probability distributions of\nstock returns in mature markets exhibit power-law tails and both the positive\nand negative tails conform to the inverse cubic law. It supports the\npossibility that the tail exponents are universal at least for mature markets\nin the sense that they do not depend on stock market, industry sector, and\nmarket capitalization. We investigate the distributions of one-minute intraday\nreturns of all the A-share stocks traded in the Chinese stock market, which is\nthe largest emerging market in the world. We find that the returns can be well\nfitted by the $q$-Gaussian distribution and the tails have power-law\nrelaxations with the exponents fluctuating around $\\alpha=3$ and being well\noutside the L\\'evy stable regime for individual stocks. We provide\nstatistically significant evidence showing that the exponents logarithmically\ndecrease with the turnover rate and increase with the market capitalization,\nand find that the market capitalization has a greater impact on the tail\nexponent than the turnover rate. Our findings indicate that the intraday return\ndistributions are not universal in emerging stock markets.\n"
    },
    {
        "paper_id": 1003.6002,
        "authors": "Thomas Lim (ENSIIE, D\\'epartement de math\\'ematiques), Marie-Claire\n  Quenez (LPMA)",
        "title": "Portfolio optimization in a default model under full/partial information",
        "comments": null,
        "journal-ref": "Prob. Eng. Inf. Sci. 29 (2015) 565-587",
        "doi": "10.1017/S0269964815000194",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we consider a financial market with assets exposed to some\nrisks inducing jumps in the asset prices, and which can still be traded after\ndefault times. We use a default-intensity modeling approach, and address in\nthis incomplete market context the problem of maximization of expected utility\nfrom terminal wealth for logarithmic, power and exponential utility functions.\nWe study this problem as a stochastic control problem both under full and\npartial information. Our contribution consists in showing that the optimal\nstrategy can be obtained by a direct approach for the logarithmic utility\nfunction, and the value function for the power utility function can be\ndetermined as the minimal solution of a backward stochastic differential\nequation. For the partial information case, we show how the problem can be\ndivided into two problems: a filtering problem and an optimization problem. We\nalso study the indifference pricing approach to evaluate the price of a\ncontingent claim in an incomplete market and the information price for an agent\nwith insider information.\n"
    },
    {
        "paper_id": 1003.6042,
        "authors": "Alexander Kaplun",
        "title": "Continuous time Ehrenfest process in term structure modelling",
        "comments": "20 pages, 6 figures. Submitted to Applied Probability Trust.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, a finite-state mean-reverting model for the short-rate, based\non the continuous time Ehrenfest process, will be examined. Two explicit\npricing formulae for zero-coupon bonds will be derived in the general and the\nspecial symmetric cases. Its limiting relationship to the Vasicek model will be\nexamined with some numerical results.\n"
    },
    {
        "paper_id": 1004.0125,
        "authors": "Antoine Jacquier and Saad Slaoui",
        "title": "Variance dispersion and correlation swaps",
        "comments": "14 pages, 0 figure.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the recent years, banks have sold structured products such as worst-of\noptions, Everest and Himalayas, resulting in a short correlation exposure. They\nhave hence become interested in offsetting part of this exposure, namely buying\nback correlation. Two ways have been proposed for such a strategy : either pure\ncorrelation swaps or dispersion trades, taking position in an index option and\nthe opposite position in the components options. These dispersion trades have\nbeen set up using calls, puts, straddles, variance swaps as well as third\ngeneration volatility products. When considering a dispersion trade using\nvariance swaps, one immediately sees that it gives a correlation exposure.\nEmpirical analysis have showed that this implied correlation was not equal to\nthe strike of a correlation swap with the same maturity. The purpose of this\npaper is to theoretically explain such a spread. In fact, we prove that the P&L\nof a dispersion trade is equal to the sum of the spread between implied and\nrealised correlation - multiplied by an average variance of the components -\nand a volatility part. Furthermore, this volatility part is of second order,\nand, more precisely, is of volga order. Thus the observed correlation spread\ncan be totally explained by the volga of the dispersion trade. This result is\nto be reviewed when considering different weighting schemes for the dispersion\ntrade.\n"
    },
    {
        "paper_id": 1004.0213,
        "authors": "Ivan O. Kitov, Oleg I. Kitov",
        "title": "S&P 500 returns revisited",
        "comments": "18 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The predictions of the S&P 500 returns made in 2007 have been tested and the\nunderlying models amended. The period between 2003 and 2008 should be described\nby the dependence of the S&P 500 stock market index on real GDP because the\npopulation pyramid was highly inaccurate. The 2008 trough and 2009 rally are\nwell predicted by the original model, however. The rally will end in\nMarch/April 2010 and the S&P 500 level will be decreasing into 2011. This\nprediction should validate the model.\n"
    },
    {
        "paper_id": 1004.0417,
        "authors": "H.F. Coronel-Brizio (1), A.R. Hernandez-Montoya (1) ((1) Facultad de\n  Fisica e Inteligencia Artificial, Departamento de Inteligencia Artificial,\n  Universidad Veracruzana, Mexico)",
        "title": "The Anderson-Darling test of fit for the power law distribution from\n  left censored samples",
        "comments": "14 pages, 3 figures",
        "journal-ref": "Physica A, Volume 389, Issue 17, 3508-3515 (2010)",
        "doi": "10.1016/j.physa.2010.03.041",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Maximum likelihood estimation and a test of fit based on the Anderson-Darling\nstatistic is presented for the case of the power law distribution when the\nparameters are estimated from a left-censored sample. Expressions for the\nmaximum likelihood estimators and tables of asymptotic percentage points for\nthe A^2 statistic are given. The technique is illustrated for data from the Dow\nJones Industrial Average index, an example of high theoretical and practical\nimportance in Econophysics, Finance, Physics, Biology and, in general, in other\nrelated Sciences such as Complexity Sciences.\n"
    },
    {
        "paper_id": 1004.0561,
        "authors": "Victor Kozyakin, Brian O'Callaghan, Alexei Pokrovskii",
        "title": "Sequences of Arbitrages",
        "comments": "18 pages, 4 figures, 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The goal of this article is to understand some interesting features of\nsequences of arbitrage operations, which look relevant to various processes in\nEconomics and Finances. In the second part of the paper, analysis of sequences\nof arbitrages is reformulated in the linear algebra terms. This admits an\nelegant geometric interpretation of the problems under consideration linked to\nthe asynchronous systems theory. We feel that this interpretation will be\nuseful in understanding more complicated, and more realistic, mathematical\nmodels in economics.\n"
    },
    {
        "paper_id": 1004.0595,
        "authors": "Masahiko Egami and Kazutoshi Yamazaki",
        "title": "Precautionary Measures for Credit Risk Management in Jump Models",
        "comments": "31 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1080/17442508.2011.653566",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Sustaining efficiency and stability by properly controlling the equity to\nasset ratio is one of the most important and difficult challenges in bank\nmanagement. Due to unexpected and abrupt decline of asset values, a bank must\nclosely monitor its net worth as well as market conditions, and one of its\nimportant concerns is when to raise more capital so as not to violate capital\nadequacy requirements. In this paper, we model the tradeoff between avoiding\ncosts of delay and premature capital raising, and solve the corresponding\noptimal stopping problem. In order to model defaults in a bank's loan/credit\nbusiness portfolios, we represent its net worth by Levy processes, and solve\nexplicitly for the double exponential jump diffusion process and for a general\nspectrally negative Levy process.\n"
    },
    {
        "paper_id": 1004.0682,
        "authors": "Jean-Claude Juhel (CRIFP)",
        "title": "L'effet de levier de tr\\'esorerie",
        "comments": null,
        "journal-ref": "La Revue du Financier Septembre-d\\'ecembre, Num\\'ero 173-174\n  (2008) 16 - 46",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The effect of leverage on liquidity is a tool for analysing the level of\nliquidity for a given production process. It measures the sensitivity of the\nlevel of liquidity that results from changes in the volume of production and\nunit operating margin. A commercial activity is liquid at the moment when all\ncosts are covered by revenues. However, not all of the cash flows from\nproduction influence liquidity levels. The estimated costs do not directly\ninfluence the level of liquidity. Therefore, two indicators are to be taken\ninto consideration: the elasticity of ongoing liquidity - fixed costs include\nestimated costs, and, the elasticity of immediate liquidity - fixed costs only\ninclude costs that are payable. The coefficients of leverage of ongoing\nliquidity and of leverage of immediate liquidity in relation to the operating\nmargin have a behaviour that is identical to that calculated in relation to\nproduction. If the productive capacity remains unchanged, the regulation of the\nchange in elasticity of the costs and of its influence on the unitary operating\nmargin is the sole parameter available to the entrepreneur to maintain the\nliquidity of the company at the desired level. But, if the productive capacity\nis variable, the entrepreneur can use the volume of sales to control liquidity\nbut then the transformation of the production process must be analysed so as to\nadjust the relevant elements to retain in the operating structure the degree of\nliquidity wished for.\n"
    },
    {
        "paper_id": 1004.0685,
        "authors": "Sergey Ivliev",
        "title": "Simple Fuzzy Score for Russian Public Companies Risk of Default",
        "comments": "10 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The model is aimed to discriminate the 'good' and the 'bad' companies in\nRussian corporate sector based on their financial statements data based on\nRussian Accounting Standards. The data sample consists of 126 Russian public\ncompanies- issuers of Ruble bonds which represent about 36% of total number of\ncorporate bonds issuers. 25 companies have defaulted on their debt in 2008-2009\nwhich represent around 30% of default cases. No SPV companies were included in\nthe sample. The model shows in-sample Gini AR about 73% and gives a reasonable\nand simple rule of mapping to external ratings. The model can be used to\ncalculate implied credit rating for Russian companies which many of them don't\nhave.\n"
    },
    {
        "paper_id": 1004.0844,
        "authors": "Fredrick Michael",
        "title": "Quantum Portfolios of Observables and the Risk Neutral Valuation Model",
        "comments": "8 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Quantum Portfolios of quantum algorithms encoded on qbits have recently been\nreported. In this paper a discussion of the continuous variables version of\nquantum portfolios is presented. A risk neutral valuation model for options\ndependent on the measured values of the observables, analogous to the\ntraditional Black-Scholes valuation model, is obtained from the underlying\nstochastic equations. The quantum algorithms are here encoded on simple\nharmonic oscillator (SHO) states, and a Fokker-Planck equation for the Glauber\nP-representation is obtained as a starting point for the analysis. A discussion\nof the observation of the polarization of a portfolio of qbits is also obtained\nand the resultant Fokker-Planck equation is used to obtain the risk neutral\nvaluation of the qbit polarization portfolio.\n"
    },
    {
        "paper_id": 1004.1053,
        "authors": "Ulrich Kirchner",
        "title": "Managing Derivative Exposure",
        "comments": "8 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an approach to derivative exposure management based on subjective\nand implied probabilities. We suggest to maximize the valuation difference\nsubject to risk constraints and propose a class of risk measures derived from\nthe subjective distribution. We illustrate this process with specific examples\nfor the two and three dimensional case. In these cases the optimization can be\nperformed graphically.\n"
    },
    {
        "paper_id": 1004.1136,
        "authors": "Rui Gon\\c{c}alves, Helena Ferreira and Alberto Pinto",
        "title": "Universality in DAX index returns fluctuations",
        "comments": "15 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In terms of the stock exchange returns, we compute the analytic expression of\nthe probability distributions F{DAX,+} and F{DAX,-} of the normalized positive\nand negative DAX (Germany) index daily returns r(t). Furthermore, we define the\nalpha re-scaled DAX daily index positive returns r(t)^alpha and negative\nreturns (-r(t))^alpha that we call, after normalization, the alpha positive\nfluctuations and alpha negative fluctuations. We use the Kolmogorov-Smirnov\nstatistical test, as a method, to find the values of alpha that optimize the\ndata collapse of the histogram of the alpha fluctuations with the\nBramwell-Holdsworth-Pinton (BHP) probability density function. The optimal\nparameters that we found are alpha+=0.50 and alpha-=0.48. Since the BHP\nprobability density function appears in several other dissimilar phenomena, our\nresults reveal universality in the stock exchange markets.\n"
    },
    {
        "paper_id": 1004.1138,
        "authors": "Rui Gon\\c{c}alves, Helena Ferreira and Alberto Pinto",
        "title": "Universal Fluctuations of the FTSE100",
        "comments": "7 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We compute the analytic expression of the probability distributions\nF{FTSE100,+} and F{FTSE100,-} of the normalized positive and negative FTSE100\n(UK) index daily returns r(t). Furthermore, we define the alpha re-scaled\nFTSE100 daily index positive returns r(t)^alpha and negative returns\n(-r(t))^alpha that we call, after normalization, the alpha positive\nfluctuations and alpha negative fluctuations. We use the Kolmogorov-Smirnov\nstatistical test, as a method, to find the values of alpha that optimize the\ndata collapse of the histogram of the alpha fluctuations with the\nBramwell-Holdsworth-Pinton (BHP) probability density function. The optimal\nparameters that we found are alpha+=0.55 and alpha-=0.55. Since the BHP\nprobability density function appears in several other dissimilar phenomena, our\nresults reveal universality in the stock exchange markets.\n"
    },
    {
        "paper_id": 1004.121,
        "authors": "Rui Gon\\c{c}alves, Helena Ferreira and Alberto Pinto",
        "title": "Universal Fluctuations of AEX index",
        "comments": "16 pages, 12 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2010.06.012",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We compute the analytic expression of the probability distributions F{AEX,+}\nand F{AEX,-} of the normalized positive and negative AEX (Netherlands) index\ndaily returns r(t). Furthermore, we define the \\alpha re-scaled AEX daily index\npositive returns r(t)^\\alpha and negative returns (-r(t))^\\alpha that we call,\nafter normalization, the \\alpha positive fluctuations and \\alpha negative\nfluctuations. We use the Kolmogorov-Smirnov statistical test, as a method, to\nfind the values of \\alpha that optimize the data collapse of the histogram of\nthe \\alpha fluctuations with the Bramwell-Holdsworth-Pinton (BHP) probability\ndensity function. The optimal parameters that we found are \\alpha+=0.46 and\n\\alpha-=0.43. Since the BHP probability density function appears in several\nother dissimilar phenomena, our results reveal universality in the stock\nexchange markets.\n"
    },
    {
        "paper_id": 1004.1489,
        "authors": "Michael Ludkovski and Hyekyung Min",
        "title": "Illiquidity Effects in Optimal Consumption-Investment Problems",
        "comments": "26 pages, submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the effect of liquidity freezes on an economic agent optimizing her\nutility of consumption in a perturbed Black-Scholes-Merton model. The single\nrisky asset follows a geometric Brownian motion but is subject to liquidity\nshocks, during which no trading is possible and stock dynamics are modified.\nThe liquidity regime is governed by a two-state Markov chain. We derive the\nasymptotic effect of such freezes on optimal consumption and investment\nschedules in the two cases of (i) small probability of liquidity shock; (ii)\nfast-scale liquidity regime switching. Explicit formulas are obtained for\nlogarithmic and hyperbolic utility maximizers on infinite horizon. We also\nderive the corresponding loss in utility and compare with a recent related\nfinite-horizon model of Diesinger, Kraft and Seifried (2009).\n"
    },
    {
        "paper_id": 1004.1522,
        "authors": "Stefan Reimann and Andreas Tupak",
        "title": "Dynamics on/in financial markets: dynamical decoupling and stylized\n  facts",
        "comments": "21 pages, 18 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Stylized facts can be regarded as constraints for any modeling attempt of\nprice dynamics on a financial market, in that an empirically reasonable model\nhas to reproduce these stylized facts at least qualitatively. The dynamics of\nmarket prices is modeled on a macro-level as the result of the dynamic coupling\nof two dynamical components. The degree of their dynamical decoupling is shown\nto have a significant impact on the stochastic properties of return trials such\nas the return distribution, volatility clustering, and the multifractal\nbehavior of time scales of asset returns. Particularly we observe a cross over\nin the return distribution from a Gaussian-like to a Levy-like shape when the\ndegree of decoupling increases. In parallel, the larger the degree of\ndecoupling is the more pronounced is volatility clustering. These findings\nsuggest that the considerations of time in an economic system, in general, and\nthe coupling of constituting processes is essential for understanding the\nbehavior of a financial market.\n"
    },
    {
        "paper_id": 1004.1574,
        "authors": "Yan Dolinsky",
        "title": "Shortfall Risk Approximations for American Options in the\n  multidimensional Black--Scholes Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that shortfall risks of American options in a sequence of multinomial\napproximations of the multidimensional Black--Scholes (BS) market converge to\nthe corresponding quantities for similar American options in the\nmultidimensional BS market with path dependent payoffs. In comparison to\nprevious papers we consider the multi assets case for which we use the weak\nconvergence approach.\n"
    },
    {
        "paper_id": 1004.1575,
        "authors": "Yan Dolinsky",
        "title": "Error Estimates for Multinomial Approximations of American Options in\n  Merton's Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive error estimates for multinomial approximations of American options\nin a multidimensional jump--diffusion Merton's model. We assume that the\npayoffs are Markovian and satisfy Lipschitz type conditions. Error estimates\nfor such type of approximations were not obtained before. Our main tool is the\nstrong approximations theorems for i.i.d. random vectors which were obtained\n[14]. For the multidimensional Black--Scholes model our results can be extended\nalso to a general path dependent payoffs which satisfy Lipschitz type\nconditions. For the case of multinomial approximations of American options for\nthe Black--Scholes model our estimates are a significant improvement of those\nwhich were obtained in [8] (for game options in a more general setup)\n"
    },
    {
        "paper_id": 1004.1576,
        "authors": "Yan Dolinsky",
        "title": "Limit Theorems for Partial Hedging Under Transaction Costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study shortfall risk minimization for American options with path dependent\npayoffs under proportional transaction costs in the Black--Scholes (BS) model.\nWe show that for this case the shortfall risk is a limit of similar terms in an\nappropriate sequence of binomial models. We also prove that in the continuous\ntime BS model for a given initial capital there exists a portfolio strategy\nwhich minimizes the shortfall risk. In the absence of transactions costs\n(complete markets) similar limit theorems were obtained in Dolinsky and Kifer\n(2008, 2010) for game options. In the presence of transaction costs the markets\nare no longer complete and additional machinery required. Shortfall risk\nminimization for American options under transaction costs was not studied\nbefore.\n"
    },
    {
        "paper_id": 1004.167,
        "authors": "Philip Z. Maymin and Zakhar G. Maymin",
        "title": "Any Regulation of Risk Increases Risk",
        "comments": "25 pages; forthcoming in Financial Markets and Portfolio Management",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that any objective risk measurement algorithm mandated by central\nbanks for regulated financial entities will result in more risk being taken on\nby those financial entities than would otherwise be the case. Furthermore, the\nrisks taken on by the regulated financial entities are far more systemically\nconcentrated than they would have been otherwise, making the entire financial\nsystem more fragile. This result leaves three directions for the future of\nfinancial regulation: continue regulating by enforcing risk measurement\nalgorithms at the cost of occasional severe crises, regulate more severely and\nsubjectively by fully nationalizing all financial entities, or abolish all\ncentral banking regulations including deposit insurance to let risk be\ndetermined by the entities themselves and, ultimately, by their depositors\nthrough voluntary market transactions rather than by the taxpayers through\nenforced government participation.\n"
    },
    {
        "paper_id": 1004.1726,
        "authors": "Andrew Ledvina and Ronnie Sircar",
        "title": "Dynamic Bertrand Oligopoly",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study continuous time Bertrand oligopolies in which a small number of\nfirms producing similar goods compete with one another by setting prices. We\nfirst analyze a static version of this game in order to better understand the\nstrategies played in the dynamic setting. Within the static game, we\ncharacterize the Nash equilibrium when there are $N$ players with heterogeneous\ncosts. In the dynamic game with uncertain market demand, firms of different\nsizes have different lifetime capacities which deplete over time according to\nthe market demand for their good. We setup the nonzero-sum stochastic\ndifferential game and its associated system of HJB partial differential\nequations in the case of linear demand functions. We characterize certain\nqualitative features of the game using an asymptotic approximation in the limit\nof small competition. The equilibrium of the game is further studied using\nnumerical solutions. We find that consumers benefit the most when a market is\nstructured with many firms of the same relative size producing highly\nsubstitutable goods. However, a large degree of substitutability does not\nalways lead to large drops in price, for example when two firms have a large\ndifference in their size.\n"
    },
    {
        "paper_id": 1004.1758,
        "authors": "Yadong Li",
        "title": "Consistent Valuation of Bespoke CDO Tranches",
        "comments": "21 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper describes a consistent and arbitrage-free pricing methodology for\nbespoke CDO tranches. The proposed method is a multi-factor extension to the\n(Li 2009) model, and it is free of the known flaws in the current standard\npricing method of base correlation mapping. This method assigns a distinct\nmarket factor to each liquid credit index and models the correlation between\nthese market factors explicitly. A low-dimensional semi-analytical Monte Carlo\nis shown to be very efficient in computing the PVs and risks of bespoke\ntranches. Numerical examples show that resulting bespoke tranche prices are\ngenerally in line with the current standard method of base correlation with TLP\nmapping. Practical issues such as model deltas and quanto adjustment are also\ndiscussed as numerical examples.\n"
    },
    {
        "paper_id": 1004.1759,
        "authors": "Yadong Li and Ariye Shater",
        "title": "Valuation Bound of Tranche Options",
        "comments": "19 pages, 9 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We performed a comprehensive analysis on the price bounds of CDO tranche\noptions, and illustrated that the CDO tranche option prices can be effectively\nbounded by the joint distribution of default time (JDDT) from a default time\ncopula. Systemic and idiosyncratic factors beyond the JDDT only contribute a\nlimited amount of pricing uncertainty. The price bounds of tranche option\nderived from a default time copula are often very narrow, especially for the\nsenior part of the capital structure where there is the most market interests\nfor tranche options. The tranche option bounds from a default time copula can\noften be computed semi-analytically without Monte Carlo simulation, therefore\nit is feasible and practical to price and risk manage senior CDO tranche\noptions using the price bounds from a default time copula only.\n  CDO tranche option pricing is important in a number of practical situations\nsuch as counterparty, gap or liquidation risk; the methodology described in\nthis paper can be very useful in the above described situations.\n"
    },
    {
        "paper_id": 1004.1804,
        "authors": "Fredrick Michael",
        "title": "Interacting Many-Investor Models, Opinion Formation and Price Formation\n  with Non-extensive Statistics",
        "comments": "10 pages, no figures. Written 2001-2002, revised 2008, submitted\n  2010. Typos corrected vr. 2.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We seek to utilize the nonextensive statistics to the microscopic modeling of\nthe interacting many-investor dynamics that drive the price changes in a\nmarket. The statistics of price changes are known to be fit well by the\nStudents-T and power-law distributions of the nonextensive statistics. We\ntherefore derive models of interacting investors that are based on the\nnonextensive statistics and which describe the excess demand and formation of\nprice.\n"
    },
    {
        "paper_id": 1004.1855,
        "authors": "Luca Capriotti and Mike Giles",
        "title": "Fast Correlation Greeks by Adjoint Algorithmic Differentiation",
        "comments": "5 pages, 2 figures",
        "journal-ref": "Risk Magazine, April 2010",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show how Adjoint Algorithmic Differentiation (AAD) allows an extremely\nefficient calculation of correlation Risk of option prices computed with Monte\nCarlo simulations. A key point in the construction is the use of binning to\nsimultaneously achieve computational efficiency and accurate confidence\nintervals. We illustrate the method for a copula-based Monte Carlo computation\nof claims written on a basket of underlying assets, and we test it numerically\nfor Portfolio Default Options. For any number of underlying assets or names in\na portfolio, the sensitivities of the option price with respect to all the\npairwise correlations is obtained at a computational cost which is at most 4\ntimes the cost of calculating the option value itself. For typical\napplications, this results in computational savings of several order of\nmagnitudes with respect to standard methods.\n"
    },
    {
        "paper_id": 1004.2106,
        "authors": "Masaaki Fukasawa",
        "title": "Asymptotic analysis for stochastic volatility: Edgeworth expansion",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The validity of an approximation formula for European option prices under a\ngeneral stochastic volatility model is proved in the light of the Edgeworth\nexpansion for ergodic diffusions. The asymptotic expansion is around the\nBlack-Scholes price and is uniform in bounded payoff func- tions. The result\nprovides a validation of an existing singular perturbation expansion formula\nfor the fast mean reverting stochastic volatility model.\n"
    },
    {
        "paper_id": 1004.2107,
        "authors": "Masaaki Fukasawa",
        "title": "Discretization error of Stochastic Integrals",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Asymptotic error distribution for approximation of a stochastic integral with\nrespect to continuous semimartingale by Riemann sum with general stochastic\npartition is studied. Effective discretization schemes of which asymptotic\nconditional mean-squared error attains a lower bound are constructed. Two\napplications are given; efficient delta hedging strategies with transaction\ncosts and effective discretization schemes for the Euler-Maruyama approximation\nare constructed.\n"
    },
    {
        "paper_id": 1004.2206,
        "authors": "Tianxiao Wang and Yufeng Shi",
        "title": "A maximum principle for forward-backward stochastic Volterra integral\n  equations and applications in finance",
        "comments": "28 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper formulates and studies a stochastic maximum principle for\nforward-backward stochastic Volterra integral equations (FBSVIEs in short),\nwhile the control area is assumed to be convex. Then a linear quadratic (LQ in\nshort) problem for backward stochastic Volterra integral equations (BSVIEs in\nshort) is present to illustrate the aforementioned optimal control problem.\nMotivated by the technical skills in solving above problem, a more convenient\nand briefer method for the unique solvability of M-solution for BSVIEs is\nproposed. At last, we will investigate a risk minimization problem by means of\nthe maximum principle for FBSVIEs. Closed-form optimal portfolio is obtained in\nsome special cases.\n"
    },
    {
        "paper_id": 1004.2248,
        "authors": "Peter Imkeller and Gon\\c{c}alo dos Reis and Jianing Zhang",
        "title": "Results on numerics for FBSDE with drivers of quadratic growth",
        "comments": "19 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of numerical approximation for forward-backward\nstochastic differential equations with drivers of quadratic growth (qgFBSDE).\nTo illustrate the significance of qgFBSDE, we discuss a problem of cross\nhedging of an insurance related financial derivative using correlated assets.\nFor the convergence of numerical approximation schemes for such systems of\nstochastic equations, path regularity of the solution processes is\ninstrumental. We present a method based on the truncation of the driver, and\nexplicitly exhibit error estimates as functions of the truncation height. We\ndiscuss a reduction method to FBSDE with globally Lipschitz continuous drivers,\nby using the Cole-Hopf exponential transformation. We finally illustrate our\nnumerical approximation methods by giving simulations for prices and optimal\nhedges of simple insurance derivatives.\n"
    },
    {
        "paper_id": 1004.2548,
        "authors": "Gareth W. Peters, Mario V. W\\\"uthrich, Pavel V. Shevchenko",
        "title": "Chain ladder method: Bayesian bootstrap versus classical bootstrap",
        "comments": null,
        "journal-ref": "Insurance: Mathematics and Economics (2010)",
        "doi": "10.1016/j.insmatheco.2010.03.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The intention of this paper is to estimate a Bayesian distribution-free chain\nladder (DFCL) model using approximate Bayesian computation (ABC) methodology.\nWe demonstrate how to estimate quantities of interest in claims reserving and\ncompare the estimates to those obtained from classical and credibility\napproaches. In this context, a novel numerical procedure utilising Markov chain\nMonte Carlo (MCMC), ABC and a Bayesian bootstrap procedure was developed in a\ntruly distribution-free setting. The ABC methodology arises because we work in\na distribution-free setting in which we make no parametric assumptions, meaning\nwe can not evaluate the likelihood point-wise or in this case simulate directly\nfrom the likelihood model. The use of a bootstrap procedure allows us to\ngenerate samples from the intractable likelihood without the requirement of\ndistributional assumptions, this is crucial to the ABC framework. The developed\nmethodology is used to obtain the empirical distribution of the DFCL model\nparameters and the predictive distribution of the outstanding loss liabilities\nconditional on the observed claims. We then estimate predictive Bayesian\ncapital estimates, the Value at Risk (VaR) and the mean square error of\nprediction (MSEP). The latter is compared with the classical bootstrap and\ncredibility methods.\n"
    },
    {
        "paper_id": 1004.2865,
        "authors": "Yadong Li and Ziyu Zheng",
        "title": "A Top-down Model for Cash CLO",
        "comments": "14 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a top-down model for cash CLO. This model can consistently price\ncash CLO tranches both within the same deal and across different deals.\nMeaningful risk measures for cash CLO tranches can also be defined and\ncomputed. This method is self-consistent, easy to implement and computationally\nefficient. It has the potential to bring the much needed pricing transparency\nto the cash CLO markets; and it could also greatly improve the risk management\nof cash instruments.\n"
    },
    {
        "paper_id": 1004.2947,
        "authors": "Stig Larsson, Carl Lindberg and Marcus Warfheimer",
        "title": "Optimal closing of a pair trade with a model containing jumps",
        "comments": "17 pages, 4 figures.",
        "journal-ref": "Appl. Math. 58 (2013), 249-268",
        "doi": "10.1007/s10492-013-0012-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A pair trade is a portfolio consisting of a long position in one asset and a\nshort position in another, and it is a widely applied investment strategy in\nthe financial industry. Recently, Ekstr\\\"om, Lindberg and Tysk studied the\nproblem of optimally closing a pair trading strategy when the difference of the\ntwo assets is modelled by an Ornstein-Uhlenbeck process. In this paper we study\nthe same problem, but the model is generalized to also include jumps. More\nprecisely we assume that the above difference is an Ornstein-Uhlenbeck type\nprocess, driven by a L\\'evy process of finite activity. We prove a verification\ntheorem and analyze a numerical method for the associated free boundary\nproblem. We prove rigorous error estimates, which are used to draw some\nconclusions from numerical simulations.\n"
    },
    {
        "paper_id": 1004.3067,
        "authors": "Eugen Perchik",
        "title": "Fundamental defect of the macroeconomic thinking as one of the main\n  causes of the crisis endured",
        "comments": "12 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main points of the first section of the article written by S.I.\nChernyshov, A.V. Voronin and S.A. Razumovsky arXiv:1003.4382), which deals with\nthe fundamental bases of the macroeconomic theory, have been analyzed. An\nincorrectness of the Harrod's model of the economical growth in its generally\naccepted interpretation was specifically considered. The inevitability of the\neconomic crisis has been shown to follow directly from the premises of this\nmodel. At the same time there is an opportunity to realize the damping\nstrategies.\n"
    },
    {
        "paper_id": 1004.3093,
        "authors": "Dapeng Cai and Takashi Gyoshin Nitta",
        "title": "Transversality Conditions for Higher Order Infinite Horizon Discrete\n  Time Optimization Problems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we examine higher order difference problems. Using the\n\"squeezing\" argument, we derive both Euler's condition and the transversality\ncondition. In order to derive the two conditions, two needed assumptions are\nidentified. A counterexample, in which the transversality condition is not\nsatisfied without the two assumptions, is also presented.\n"
    },
    {
        "paper_id": 1004.3106,
        "authors": "Christian Bender, Tommi Sottinen and Esko Valkeila",
        "title": "Fractional processes as models in stochastic finance",
        "comments": "To appear in Advanced Mathematical Methods for Finance (Eds. G. Di\n  Nunno and B. {\\O}ksendal Series in Mathematical Finance, Springer)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We survey some new progress on the pricing models driven by fractional\nBrownian motion \\cb{or} mixed fractional Brownian motion. In particular, we\ngive results on arbitrage opportunities, hedging, and option pricing in these\nmodels. We summarize some recent results on fractional Black & Scholes pricing\nmodel with transaction costs. We end the paper by giving some approximation\nresults and indicating some open problems related to the paper.\n"
    },
    {
        "paper_id": 1004.3229,
        "authors": "Bertrand M. Roehner",
        "title": "Fifteen years of econophysics: worries, hopes and prospects",
        "comments": "15 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This anniversary paper is an occasion to recall some of the events that\nshaped institutional econophysics. But in these thoughts about the evolution of\neconophysics in the last 15 years we also express some concerns. Our main worry\nconcerns the relinquishment of the simplicity requirement. Ever since the\ngroundbreaking experiments of Galileo some three centuries ago, the great\nsuccesses of physicists were largely due to the fact that they were able to\ndecompose complex phenomena into simpler ones. Remember that the first\nobservation of the effects of an electrical current was made by Alessandro\nVolta (1745-1827) on the leg of a frog! Clearly, to make sense this observation\nhad to be broken down into several separate effects. Nowadays, with computers\nbeing able to handle huge amounts of data and to simulate any stochastic\nprocess no matter how complicated, there is no longer any real need for such a\nsearch for simplicity. Why should one spend time and effort trying to break up\ncomplicated phenomena when it is possible to handle them globally? On this new\nroad there are several stumbling blocks, however. Do such global mathematical\ndescriptions lead to a real understanding? Do they produce building blocks\nwhich can be used elsewhere and thus make our knowledge and comprehension to\ngrow in a cumulative way? Should econophysics also adopt the \"globalized\"\nperspective that has been endorsed, developed and spread by the numerous\n\"Complexity Departments\" which sprang up during the last decade?\n"
    },
    {
        "paper_id": 1004.3299,
        "authors": "Erhan Bayraktar, Constantinos Kardaras, and Hao Xing",
        "title": "Valuation equations for stochastic volatility models",
        "comments": "Keywords: Stochastic volatility models, valuation equations,\n  Feynman-Kac theorem, strict local martingales, necessary and sufficient\n  conditions for uniqueness",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the valuation partial differential equation for European\ncontingent claims in a general framework of stochastic volatility models where\nthe diffusion coefficients may grow faster than linearly and degenerate on the\nboundaries of the state space. We allow for various types of model behavior:\nthe volatility process in our model can potentially reach zero and either stay\nthere or instantaneously reflect, and the asset-price process may be a strict\nlocal martingale. Our main result is a necessary and sufficient condition on\nthe uniqueness of classical solutions to the valuation equation: the value\nfunction is the unique nonnegative classical solution to the valuation equation\namong functions with at most linear growth if and only if the asset-price is a\nmartingale.\n"
    },
    {
        "paper_id": 1004.331,
        "authors": "Irmina Czarna and Zbigniew Palmowski",
        "title": "Dividend problem with Parisian delay for a spectrally negative L\\'evy\n  risk process",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider dividend problem for an insurance company whose\nrisk evolves as a spectrally negative L\\'{e}vy process (in the absence of\ndividend payments) when Parisian delay is applied. The objective function is\ngiven by the cumulative discounted dividends received until the moment of ruin\nwhen so-called barrier strategy is applied. Additionally we will consider two\npossibilities of delay. In the first scenario ruin happens when the surplus\nprocess stays below zero longer than fixed amount of time $\\zeta>0$. In the\nsecond case there is a time lag $d$ between decision of paying dividends and\nits implementation.\n"
    },
    {
        "paper_id": 1004.3525,
        "authors": "S. Cawston, L. Vostrikova",
        "title": "$F$-divergence minimal equivalent martingale measures and optimal\n  portfolios for exponential Levy models with a change-point",
        "comments": "31 pages, no figures",
        "journal-ref": "In R. Dalang, M. Dozzi, F. Russo (Editors). Stochastic analysis,\n  random fields and applications VI. Progress in Probability 67, 2013, 285-305",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study exponential Levy models with change-point which is a random\nvariable, independent from initial Levy processes. On canonical space with\ninitially enlarged filtration we describe all equivalent martingale measures\nfor change-point model and we give the conditions for the existence of\nf-divergence minimal equivalent martingale measure. Using the connection\nbetween utility maximisation and $f$-divergence minimisation, we obtain a\ngeneral formula for optimal strategy in change-point case for initially\nenlarged filtration and also for progressively enlarged filtration in the case\nof exponential utility. We illustrate our results considering the Black-Scholes\nmodel with change-point.\n"
    },
    {
        "paper_id": 1004.3577,
        "authors": "Stefan Geiss, Emmanuel Gobet",
        "title": "Fractional smoothness and applications in finance",
        "comments": "Chapter of AMAMEF book. 20 pages.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This overview article concerns the notion of fractional smoothness of random\nvariables of the form $g(X_T)$, where $X=(X_t)_{t\\in [0,T]}$ is a certain\ndiffusion process. We review the connection to the real interpolation theory,\ngive examples and applications of this concept. The applications in stochastic\nfinance mainly concern the analysis of discrete time hedging errors. We close\nthe review by indicating some further developments.\n"
    },
    {
        "paper_id": 1004.3758,
        "authors": "Yadong Li",
        "title": "A Dynamic Correlation Modelling Framework with Consistent Stochastic\n  Recovery",
        "comments": "22 pages, 9 figures, initial draft: Feb 26, 2009, presented to 2009\n  Quant Congress USA",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper describes a flexible and tractable bottom-up dynamic correlation\nmodelling framework with a consistent stochastic recovery specification. The\nstochastic recovery specification only models the first two moments of the spot\nrecovery rate as its higher moments have almost no contribution to the loss\ndistribution and CDO tranche pricing. Observing that only the joint\ndistribution of default indicators is needed to build the portfolio loss\ndistribution, we propose a generic class of default indicator copulas to model\nCDO tranches, which can be easily calibrated to index tranche prices across\nmultiple maturities. This correlation modelling framework has the unique\nadvantage that the joint distribution of default time and other dynamic\nproperties of the model can be changed separately from the loss distribution\nand tranche prices. After calibrating the model to index tranche prices,\nexisting top-down methods can be applied to the common factor process to\nconstruct very flexible systemic dynamics without changing the already\ncalibrated tranche prices. This modelling framework therefore combines the best\nfeatures of the bottom-up and top-down models: it is fully consistent with all\nthe single name market information and it admits very rich and flexible spread\ndynamics. Numerical results from a non-parametric implementation of this\nmodelling framework are also presented. The non-parametric implementation\nachieved fast and accurate calibration to the index tranches across multiple\nmaturities even under extreme market conditions. A conditional Markov chain\nmethod is also proposed to construct the systemic dynamics, which supports an\nefficient lattice pricing method for dynamic spread instruments. We also showed\nhow to price tranche options as an example of this fast lattice method.\n"
    },
    {
        "paper_id": 1004.383,
        "authors": "Gareth W. Peters and Balakrishnan Kannan and Ben Lasscock and Chris\n  Mellen",
        "title": "Model Selection and Adaptive Markov chain Monte Carlo for Bayesian\n  Cointegrated VAR model",
        "comments": "to appear journal Bayesian Analysis",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper develops a matrix-variate adaptive Markov chain Monte Carlo (MCMC)\nmethodology for Bayesian Cointegrated Vector Auto Regressions (CVAR). We\nreplace the popular approach to sampling Bayesian CVAR models, involving griddy\nGibbs, with an automated efficient alternative, based on the Adaptive\nMetropolis algorithm of Roberts and Rosenthal, (2009). Developing the adaptive\nMCMC framework for Bayesian CVAR models allows for efficient estimation of\nposterior parameters in significantly higher dimensional CVAR series than\npreviously possible with existing griddy Gibbs samplers. For a n-dimensional\nCVAR series, the matrix-variate posterior is in dimension $3n^2 + n$, with\nsignificant correlation present between the blocks of matrix random variables.\nWe also treat the rank of the CVAR model as a random variable and perform joint\ninference on the rank and model parameters. This is achieved with a Bayesian\nposterior distribution defined over both the rank and the CVAR model\nparameters, and inference is made via Bayes Factor analysis of rank.\nPractically the adaptive sampler also aids in the development of automated\nBayesian cointegration models for algorithmic trading systems considering\ninstruments made up of several assets, such as currency baskets. Previously the\nliterature on financial applications of CVAR trading models typically only\nconsiders pairs trading (n=2) due to the computational cost of the griddy\nGibbs. We are able to extend under our adaptive framework to $n >> 2$ and\ndemonstrate an example with n = 10, resulting in a posterior distribution with\nparameters up to dimension 310. By also considering the rank as a random\nquantity we can ensure our resulting trading models are able to adjust to\npotentially time varying market conditions in a coherent statistical framework.\n"
    },
    {
        "paper_id": 1004.3939,
        "authors": "William Wilson, Phil Birkin, Uwe Aickelin",
        "title": "Price Trackers Inspired by Immune Memory",
        "comments": "14 pages, 5 figures, 3 tables, 5th International Conference on\n  Artificial Immune Systems (ICARIS2006)",
        "journal-ref": "Proceedings of the 5th International Conference on Artificial\n  Immune Systems (ICARIS2006), Lecture Notes in Computer Science 4163,\n  p362-375, 2006",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we outline initial concepts for an immune inspired algorithm to\nevaluate price time series data. The proposed solution evolves a short term\npool of trackers dynamically through a process of proliferation and mutation,\nwith each member attempting to map to trends in price movements. Successful\ntrackers feed into a long term memory pool that can generalise across repeating\ntrend patterns. Tests are performed to examine the algorithm's ability to\nsuccessfully identify trends in a small data set. The influence of the long\nterm memory pool is then examined. We find the algorithm is able to identify\nprice trends presented successfully and efficiently.\n"
    },
    {
        "paper_id": 1004.4153,
        "authors": "Peter Tankov (CMAP, Ecole Polytechnique)",
        "title": "Improved Frechet bounds and model-free pricing of multi-asset options",
        "comments": "Replaced with revised version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Improved bounds on the copula of a bivariate random vector are computed when\npartial information is available, such as the values of the copula on a given\nsubset of $[0,1]^2$, or the value of a functional of the copula, monotone with\nrespect to the concordance order. These results are then used to compute\nmodel-free bounds on the prices of two-asset options which make use of extra\ninformation about the dependence structure, such as the price of another\ntwo-asset option.\n"
    },
    {
        "paper_id": 1004.4169,
        "authors": "Fabio Caccioli, Susanne Still, Matteo Marsili and Imre Kondor",
        "title": "Optimal Liquidation Strategies Regularize Portfolio Selection",
        "comments": "26 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of portfolio optimization in the presence of market\nimpact, and derive optimal liquidation strategies. We discuss in detail the\nproblem of finding the optimal portfolio under Expected Shortfall (ES) in the\ncase of linear market impact. We show that, once market impact is taken into\naccount, a regularized version of the usual optimization problem naturally\nemerges. We characterize the typical behavior of the optimal liquidation\nstrategies, in the limit of large portfolio sizes, and show how the market\nimpact removes the instability of ES in this context.\n"
    },
    {
        "paper_id": 1004.4272,
        "authors": "Ester Pantaleo, Michele Tumminello, Fabrizio Lillo and Rosario N.\n  Mantegna",
        "title": "When do improved covariance matrix estimators enhance portfolio\n  optimization? An empirical comparative study of nine estimators",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The use of improved covariance matrix estimators as an alternative to the\nsample estimator is considered an important approach for enhancing portfolio\noptimization. Here we empirically compare the performance of 9 improved\ncovariance estimation procedures by using daily returns of 90 highly\ncapitalized US stocks for the period 1997-2007. We find that the usefulness of\ncovariance matrix estimators strongly depends on the ratio between estimation\nperiod T and number of stocks N, on the presence or absence of short selling,\nand on the performance metric considered. When short selling is allowed,\nseveral estimation methods achieve a realized risk that is significantly\nsmaller than the one obtained with the sample covariance method. This is\nparticularly true when T/N is close to one. Moreover many estimators reduce the\nfraction of negative portfolio weights, while little improvement is achieved in\nthe degree of diversification. On the contrary when short selling is not\nallowed and T>N, the considered methods are unable to outperform the sample\ncovariance in terms of realized risk but can give much more diversified\nportfolios than the one obtained with the sample covariance. When T<N the use\nof the sample covariance matrix and of the pseudoinverse gives portfolios with\nvery poor performance.\n"
    },
    {
        "paper_id": 1004.44,
        "authors": "Vladimir Nikulin",
        "title": "Mean-Variance Hedging for Pricing European Options Under Assumption of\n  Non-continuous Trading",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a portfolio with call option and the corresponding underlying\nasset under the standard assumption that stock-market price represents a random\nvariable with lognormal distribution. Minimizing the variance (hedging risk) of\nthe portfolio on the date of maturity of the call option we find a fraction of\nthe asset per unit call option. As a direct consequence we derive the\nstatistically fair lookback call option price in explicit form. In contrast to\nthe famous Black-Scholes theory, any portfolio can not be regarded as risk-free\nbecause no additional transactions are supposed to be conducted over the life\nof the contract, but the sequence of independent portfolios will reduce risk to\nzero asymptotically. This property is illustrated in the experimental section\nusing a dataset of daily stock prices of 18 leading Australian companies for\nthe period of 3 years.\n"
    },
    {
        "paper_id": 1004.4402,
        "authors": "Junjie Wang, Shuigeng Zhou, Jihong Guan",
        "title": "Characteristics of Real Futures Trading Networks",
        "comments": "18 pages, 9 figures. Final version published in Physica A",
        "journal-ref": "Physica A, Volume 390, Issue 2, 15 January 2011, Pages 398-409",
        "doi": "10.1016/j.physa.2010.09.027",
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  Futures trading is the core of futures business, and it is considered as one\nof the typical complex systems. To investigate the complexity of futures\ntrading, we employ the analytical method of complex networks. First, we use\nreal trading records from the Shanghai Futures Exchange to construct futures\ntrading networks, in which nodes are trading participants, and two nodes have a\ncommon edge if the two corresponding investors appear simultaneously in at\nleast one trading record as a purchaser and a seller respectively. Then, we\nconduct a comprehensive statistical analysis on the constructed futures trading\nnetworks. Empirical results show that the futures trading networks exhibit\nfeatures such as scale-free behavior with interesting odd-even-degree\ndivergence in low-degree regions, small-world effect, hierarchical\norganization, power-law betweenness distribution, disassortative mixing, and\nshrinkage of both the average path length and the diameter as network size\nincreases. To the best of our knowledge, this is the first work that uses real\ndata to study futures trading networks, and we argue that the research results\ncan shed light on the nature of real futures business.\n"
    },
    {
        "paper_id": 1004.4522,
        "authors": "Ma{\\l}gorzata Snarska",
        "title": "Toy Model for Large Non-Symmetric Random Matrices",
        "comments": "5 pages, 3 figures, Proceedings of the 3rd Polish Symposium on Econo-\n  and Sociophysics, Wroclaw 2007,",
        "journal-ref": "Acta Physica Polonica A, 2008 Vol.114 Issue 3 p.555 - 559",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Non-symmetric rectangular correlation matrices occur in many problems in\neconomics. We test the method of extracting statistically meaningful\ncorrelations between input and output variables of large dimensionality and\nbuild a toy model for artificially included correlations in large random time\nseries.The results are then applied to analysis of polish macroeconomic data\nand can be used as an alternative to classical cointegration approach.\n"
    },
    {
        "paper_id": 1004.4526,
        "authors": "Mats Brod\\'en and Magnus Wiktorsson",
        "title": "Hedging Errors Induced by Discrete Trading Under an Adaptive Trading\n  Strategy",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Discrete time hedging in a complete diffusion market is considered. The hedge\nportfolio is rebalanced when the absolute difference between delta of the hedge\nportfolio and the derivative contract reaches a threshold level. The rate of\nconvergence of the expected squared hedging error as the threshold level\napproaches zero is analyzed. The results hinge to a great extent on a theorem\nstating that the difference between the hedge ratios normalized by the\nthreshold level tends to a triangular distribution as the threshold level tends\nto zero.\n"
    },
    {
        "paper_id": 1004.4592,
        "authors": "Philip Z. Maymin",
        "title": "Schizophrenic Representative Investors",
        "comments": "14 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Representative investors whose behaviour is modelled by a deterministic\nfinite automaton generate complexity both in the time series of each asset and\nin the cross-sectional correlation when the rule governing their behaviour is\nschizophrenic, meaning the investor must hold multiple seemingly contradictory\nbeliefs simultaneously, either by switching between two different rules at each\ntime step, or computing different responses to different assets.\n"
    },
    {
        "paper_id": 1004.4822,
        "authors": "Dorje C. Brody, Lane P. Hughston, Andrea Macrina",
        "title": "Modelling Information Flows in Financial Markets",
        "comments": null,
        "journal-ref": "\"Advanced Mathematical Methods for Finance\", p. 133-153, (Berlin:\n  Springer 2011)",
        "doi": "10.1007/978-3-642-18412-3_5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents an overview of information-based asset pricing. In this\napproach, an asset is defined by its cash-flow structure. The market is assumed\nto have access to \"partial\" information about future cash flows. Each cash flow\nis determined by a collection of independent market factors called X-factors.\nThe market filtration is generated by a set of information processes, each of\nwhich carries information about one of the X-factors, and eventually reveals\nthe X-factor. Each information process has two terms, one of which contains a\n\"signal\" about the associated X-factor, and the other of which represents\n\"market noise\". The price of an asset is given by the expectation of the\ndiscounted cash flows in the risk-neutral measure, conditional on the\ninformation provided by the market. When the market noise is modelled by a\nBrownian bridge one is able to construct explicit formulae for asset prices, as\nwell as semi-analytic expressions for the prices and greeks of options and\nderivatives. In particular, option price data can be used to determine the\ninformation flow-rate parameters implicit in the definitions of the information\nprocesses. One consequence of the modelling framework is a specific scheme of\nstochastic volatility and correlation processes. Instead of imposing a\nvolatility and correlation model upon the dynamics of a set of assets, one is\nable to deduce the dynamics of the volatilities and correlations of the asset\nprice movements from more primitive assumptions involving the associated cash\nflows. The paper concludes with an examination of situations involving\nasymmetric information. We present a simple model for informed traders and show\nhow this can be used as a basis for so-called statistical arbitrage. Finally,\nwe consider the problem of price formation in a heterogeneous market with\nmultiple agents.\n"
    },
    {
        "paper_id": 1004.4956,
        "authors": "Jianqing Fan, Yingying Li, Ke Yu",
        "title": "Vast Volatility Matrix Estimation using High Frequency Data for\n  Portfolio Selection",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Portfolio allocation with gross-exposure constraint is an effective method to\nincrease the efficiency and stability of selected portfolios among a vast pool\nof assets, as demonstrated in Fan et al (2008). The required high-dimensional\nvolatility matrix can be estimated by using high frequency financial data. This\nenables us to better adapt to the local volatilities and local correlations\namong vast number of assets and to increase significantly the sample size for\nestimating the volatility matrix. This paper studies the volatility matrix\nestimation using high-dimensional high-frequency data from the perspective of\nportfolio selection. Specifically, we propose the use of \"pairwise-refresh\ntime\" and \"all-refresh time\" methods proposed by Barndorff-Nielsen et al (2008)\nfor estimation of vast covariance matrix and compare their merits in the\nportfolio selection. We also establish the concentration inequalities of the\nestimates, which guarantee desirable properties of the estimated volatility\nmatrix in vast asset allocation with gross exposure constraints. Extensive\nnumerical studies are made via carefully designed simulations. Comparing with\nthe methods based on low frequency daily data, our methods can capture the most\nrecent trend of the time varying volatility and correlation, hence provide more\naccurate guidance for the portfolio allocation in the next time period. The\nadvantage of using high-frequency data is significant in our simulation and\nempirical studies, which consist of 50 simulated assets and 30 constituent\nstocks of Dow Jones Industrial Average index.\n"
    },
    {
        "paper_id": 1004.5014,
        "authors": "Fabio Caccioli and Matteo Marsili",
        "title": "On information efficiency and financial stability",
        "comments": "14 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a simple model of an asset market with informed and non-informed\nagents. In the absence of non-informed agents, the market becomes information\nefficient when the number of traders with different private information is\nlarge enough. Upon introducing non-informed agents, we find that the latter\ncontribute significantly to the trading activity if and only if the market is\n(nearly) information efficient. This suggests that information efficiency might\nbe a necessary condition for bubble phenomena, induced by the behavior of\nnon-informed traders, or conversely that throwing some sands in the gears of\nfinancial markets may curb the occurrence of bubbles.\n"
    },
    {
        "paper_id": 1004.5037,
        "authors": "Benjamin Jourdain, Bernard Lapeyre and Piergiacomo Sabino",
        "title": "Convenient Multiple Directions of Stratification",
        "comments": "21 pages, 11 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the use of multiple directions of stratification as a\nvariance reduction technique for Monte Carlo simulations of path-dependent\noptions driven by Gaussian vectors. The precision of the method depends on the\nchoice of the directions of stratification and the allocation rule within each\nstrata. Several choices have been proposed but, even if they provide variance\nreduction, their implementation is computationally intensive and not applicable\nto realistic payoffs, in particular not to Asian options with barrier.\nMoreover, all these previously published methods employ orthogonal directions\nfor multiple stratification. In this work we investigate the use of algorithms\nproducing convenient directions, generally non-orthogonal, combining a lower\ncomputational cost with a comparable variance reduction. In addition, we study\nthe accuracy of optimal allocation in terms of variance reduction compared to\nthe Latin Hypercube Sampling. We consider the directions obtained by the Linear\nTransformation and the Principal Component Analysis. We introduce a new\nprocedure based on the Linear Approximation of the explained variance of the\npayoff using the law of total variance. In addition, we exhibit a novel\nalgorithm that permits to correctly generate normal vectors stratified along\nnon-orthogonal directions. Finally, we illustrate the efficiency of these\nalgorithms in the computation of the price of different path-dependent options\nwith and without barriers in the Black-Scholes and in the Cox-Ingersoll-Ross\nmarkets.\n"
    },
    {
        "paper_id": 1004.5109,
        "authors": "Mehdi Lallouache, Aymen Jedidi and Anirban Chakraborti",
        "title": "Wealth distribution: To be or not to be a Gamma?",
        "comments": "7 pages, 4 figures in REVTeX format. Revised version. To appear in\n  \"Econophysics\", a special issue in Science and Culture (Kolkata, India) to\n  celebrate 15 years of Econophysics",
        "journal-ref": "Science and Culture (Kolkata, India) Volume 76 (9-10), 478 (2010)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review some aspects, especially those we can tackle analytically, of a\nminimal model of closed economy analogous to the kinetic theory model of ideal\ngases where the agents exchange wealth amongst themselves such that the total\nwealth is conserved, and each individual agent saves a fraction (0 < lambda <\n1) of wealth before transaction. We are interested in the special case where\nthe fraction lambda is constant for all the agents (global saving propensity)\nin the closed system. We show by moment calculations that the resulting wealth\ndistribution cannot be the Gamma distribution that was conjectured in Phys.\nRev. E 70, 016104 (2004). We also derive a form for the distribution at low\nwealth, which is a new result.\n"
    },
    {
        "paper_id": 1004.5169,
        "authors": "Andrey Sokolov, Andrew Melatos, Tien Kieu",
        "title": "Laplace transform analysis of a multiplicative asset transfer model",
        "comments": null,
        "journal-ref": "Physica A 389 (2010) 2782-2792",
        "doi": "10.1016/j.physa.2010.02.045",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze a simple asset transfer model in which the transfer amount is a\nfixed fraction $f$ of the giver's wealth. The model is analyzed in a new way by\nLaplace transforming the master equation, solving it analytically and\nnumerically for the steady-state distribution, and exploring the solutions for\nvarious values of $f\\in(0,1)$. The Laplace transform analysis is superior to\nagent-based simulations as it does not depend on the number of agents, enabling\nus to study entropy and inequality in regimes that are costly to address with\nsimulations. We demonstrate that Boltzmann entropy is not a suitable (e.g.\nnon-monotonic) measure of disorder in a multiplicative asset transfer system\nand suggest an asymmetric stochastic process that is equivalent to the asset\ntransfer model.\n"
    },
    {
        "paper_id": 1004.5192,
        "authors": "N. El Karoui (CMAP, LPMA), Mohamed M'Rad (CMAP, LAGA)",
        "title": "Stochastic Utilities With a Given Optimal Portfolio : Approach by\n  Stochastic Flows",
        "comments": "arXiv admin note: text overlap with arXiv:0904.2913 by other authors",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper generalizes the construction by stochastic flows of consistent\nutility processes introduced by M. Mrad and N. El Karoui in (2010). The\nutilities random fields are defined from a general class of processes denoted\nby $\\GX$. Making minimal assumptions and convex constraints on test-processes,\nwe construct by composing two stochastic flows of homeomorphisms, all the\nconsistent stochastic utilities whose the optimal-benchmark process is given,\nstrictly increasing in its initial condition. Proofs are essentially based on\nstochastic change of variables techniques.\n"
    },
    {
        "paper_id": 1004.5524,
        "authors": "Jocelyne Bion-Nadal and Magali Kervarec",
        "title": "Risk measuring under model uncertainty",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The framework of this paper is that of risk measuring under uncertainty,\nwhich is when no reference probability measure is given. To every regular\nconvex risk measure on ${\\cal C}_b(\\Omega)$, we associate a unique equivalence\nclass of probability measures on Borel sets, characterizing the riskless non\npositive elements of ${\\cal C}_b(\\Omega)$. We prove that the convex risk\nmeasure has a dual representation with a countable set of probability measures\nabsolutely continuous with respect to a certain probability measure in this\nclass.\n  To get these results we study the topological properties of the dual of the\nBanach space $L^1(c)$ associated to a capacity $c$.\n  As application we obtain that every $G$-expectation $\\E$ has a representation\nwith a countable set of probability measures absolutely continuous with respect\nto a probability measure $P$ such that $P(|f|)=0$ iff $\\E(|f|)=0$. We also\napply our results to the case of uncertain volatility.\n"
    },
    {
        "paper_id": 1004.5547,
        "authors": "Tian Qiu, Guang Chen, Li-Xin Zhong, Xiao-Wei Lei",
        "title": "Memory effect and multifractality of cross-correlations in financial\n  markets",
        "comments": "11 pages, 4 figures.",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2010.11.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An average instantaneous cross-correlation function is introduced to quantify\nthe interaction of the financial market of a specific time. Based on the daily\ndata of the American and Chinese stock markets, memory effect of the average\ninstantaneous cross-correlations is investigated over different price return\ntime intervals. Long-range time-correlations are revealed, and are found to\npersist up to a month-order magnitude of the price return time interval.\nMultifractal nature is investigated by a multifractal detrended fluctuation\nanalysis.\n"
    },
    {
        "paper_id": 1004.5559,
        "authors": "Mathias Beiglb\\\"ock, Walter Schachermayer, Bezirgen Veliyev",
        "title": "A Direct Proof of the Bichteler--Dellacherie Theorem and Connections to\n  Arbitrage",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give an elementary proof of the celebrated Bichteler-Dellacherie Theorem\nwhich states that the class of stochastic processes $S$ allowing for a useful\nintegration theory consists precisely of those processes which can be written\nin the form $S=M+A$, where $M$ is a local martingale and $A$ is a finite\nvariation process. In other words, $S$ is a good integrator if and only if it\nis a semi-martingale. We obtain this decomposition rather directly from an\nelementary discrete-time Doob-Meyer decomposition. By passing to convex\ncombinations we obtain a direct construction of the continuous time\ndecomposition, which then yields the desired decomposition. As a by-product of\nour proof we obtain a characterization of semi-martingales in terms of a\nvariant of \\emph{no free lunch}, thus extending a result from [DeSc94].\n"
    },
    {
        "paper_id": 1005.0051,
        "authors": "Ivan O. Kitov, Oleg I. Kitov",
        "title": "Crude oil and motor fuel: Fair price revisited",
        "comments": "8 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In April 2009, we introduced a model representing the evolution of motor fuel\nprice (a subcategory of the consumer price index of transportation) relative to\nthe overall CPI as a linear function of time. Under our framework, all price\ndeviations from the linear trend are transient and the price must promptly\nreturn to the trend. Specifically, the model predicted that \"the price for\nmotor fuel in the US will also grow by 50% by the end of 2009. Oil price is\nexpected to rise by ~50% as well, from its current value of ~$50 per barrel\".\nThe behavior of actual price has shown that this prediction is accurate in both\namplitude and trajectory shape. Hence, one can conclude that the concept of\nprice decomposition into a short-term (oscillating) and long-term (linear\ntrend) components is valid. According to the model, the price of motor fuel and\ncrude oil will be falling to the level of $30 per barrel during the next 5 to 8\nyears.\n"
    },
    {
        "paper_id": 1005.0182,
        "authors": "Marco Bartolozzi",
        "title": "A Multi Agent Model for the Limit Order Book Dynamics",
        "comments": "20 pages, 11 figures, in press European Physical Journal B (EPJB)",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2010-10406-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present work we introduce a novel multi-agent model with the aim to\nreproduce the dynamics of a double auction market at microscopic time scale\nthrough a faithful simulation of the matching mechanics in the limit order\nbook. The agents follow a noise decision making process where their actions are\nrelated to a stochastic variable, \"the market sentiment\", which we define as a\nmixture of public and private information. The model, despite making just few\nbasic assumptions over the trading strategies of the agents, is able to\nreproduce several empirical features of the high-frequency dynamics of the\nmarket microstructure not only related to the price movements but also to the\ndeposition of the orders in the book.\n"
    },
    {
        "paper_id": 1005.0194,
        "authors": "Michel Fliess (INRIA Saclay - Ile de France, LIX), C\\'edric Join\n  (INRIA Saclay - Ile de France, CRAN)",
        "title": "Delta Hedging in Financial Engineering: Towards a Model-Free Approach",
        "comments": "18th Mediterranean Conference on Control and Automation, Marrakech :\n  Morocco (2010)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Delta hedging, which plays a crucial r\\^ole in modern financial engineering,\nis a tracking control design for a \"risk-free\" management. We utilize the\nexistence of trends in financial time series (Fliess M., Join C.: A\nmathematical proof of the existence of trends in financial time series, Proc.\nInt. Conf. Systems Theory: Modelling, Analysis and Control, Fes, 2009. Online:\nhttp://hal.inria.fr/inria-00352834/en/) in order to propose a model-free\nsetting for delta hedging. It avoids most of the shortcomings encountered with\nthe now classic Black-Scholes-Merton framework. Several convincing computer\nsimulations are presented. Some of them are dealing with abrupt changes, i.e.,\njumps.\n"
    },
    {
        "paper_id": 1005.0211,
        "authors": "Ehsan Azmoodeh",
        "title": "On the fractional Black-Scholes market with transaction costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider fractional Black-Scholes market with proportional transaction\ncosts. When transaction costs are present, one trades periodically i.e. we have\nthe discrete trading with equidistance $n^{-1}$ between trading times. We\nderive a non trivial hedging error for a class of European options with convex\npayoff in the case when the transaction costs coefficients decrease as\n$n^{-(1-H)}$. We study the expected hedging error and asymptotic behavior of\nthe hedge as $H \\to 1/2$\n"
    },
    {
        "paper_id": 1005.0221,
        "authors": "Jean-Claude Juhel (CRIFP), Dominique Dufour (CRIFP)",
        "title": "A discussion of stock market speculation by Pierre-Joseph Proudhon",
        "comments": null,
        "journal-ref": "12th World Congress of Accounting Historians, Istanbul : Turkey\n  (2008)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The object of this contribution is to present the ideas behind the thinking\nof the French economist Pierre-Joseph Proudhon (1809-1865) in relation to the\ncauses and effects of Stock market speculation. It is based upon the works of\nthis author but particularly on his \"Manuel du sp\\'eculateur \\`a la Bourse\"\n(Stock Market Speculator Manual) edited in 1857 in Paris. Compared to the\nmarkets of today, however, the stock market described by Proudhon appears\nembryonic. Nevertheless it represents the location for transactions in\nfinancial assets, commodities, precious metals and even some transactions\ninvolving options. This contribution is organised in the following manner - the\nfirst section is devoted to the development of Proudhon's thought in relation\nto speculation. It is divided into two parts. The first part is dedicated to\nPierre-Joseph Proudhon's definitions of stock market speculation or gambling\nwith shares that for him served no purpose either from a human or economic\nperspective and was therefore condemnable and to be contrasted with\nentrepreneurial speculation that, even though it is a highly-risky activity,\ninvolves the spirit of enterprise and provides the lifeblood of economic\ngrowth. The second part allows us to present Pierre-Joseph Proudhon's\npropositions in relation to restricting the speculation that he considers\nobnoxious. The second section has two objectives: one part places in\nperspective the views of Proudhon and the characteristics of stock market\nactivity under the Second Empire whilst the other part examines current-day\naspects of the characteristics evoked by Proudhon. We are interested especially\nin the question of the regulation and that of the relevance today of certain\naccounting practices.\n"
    },
    {
        "paper_id": 1005.0279,
        "authors": "Vladimir Vovk",
        "title": "Rough paths in idealized financial markets",
        "comments": "21 pages, this version adds (in Appendix C) a reference to new\n  results in the foundations of game-theoretic probability based on Hardin and\n  Taylor's work on hat puzzles",
        "journal-ref": "Lithuanian Mathematical Journal 51(2):274-285, 2011",
        "doi": "10.1007/s10986-011-9125-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers possible price paths of a financial security in an\nidealized market. Its main result is that the variation index of typical price\npaths is at most 2, in this sense, typical price paths are not rougher than\ntypical paths of Brownian motion. We do not make any stochastic assumptions and\nonly assume that the price path is positive and right-continuous. The\nqualification \"typical\" means that there is a trading strategy (constructed\nexplicitly in the proof) that risks only one monetary unit but brings infinite\ncapital when the variation index of the realized price path exceeds 2. The\npaper also reviews some known results for continuous price paths and lists\nseveral open problems.\n"
    },
    {
        "paper_id": 1005.0313,
        "authors": "Ion Spanulescu, Victor A. Stoica and Ion Popescu",
        "title": "An Econophysics Model for the Currency Exchange with Commission",
        "comments": "15 pages, 4 figures, ENEC 2009",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper an econophysics model for the currency exchange operations with\ncommission is proposed. With this purpose some analogies and similarities of\nthe processes that take place in the frame of the electrochemical system made\nfrom electrodes sunk into a solution of electrolytes and the process of the\ncurrency exchange and determination of the international currency purchasing\npower have been used. Some contact phenomena at the electrode/electrolyte\nseparation surface, the physical principles of an electrochemical source\noperation and the determination of the sale attractiveness or the \"potential\"\nof the currency that is to be exchanged are also introduced and analyzed.\n"
    },
    {
        "paper_id": 1005.0378,
        "authors": "Emeric Balogh, Ingve Simonsen, Balint Zs. Nagy, and Zoltan Neda",
        "title": "Persistent collective trend in stock markets",
        "comments": "LaTeX 9 pages, 7 figures",
        "journal-ref": "Phys. Rev. E 82, 066113 (2010)",
        "doi": "10.1103/PhysRevE.82.066113",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Empirical evidence is given for a significant difference in the collective\ntrend of the share prices during the stock index rising and falling periods.\nData on the Dow Jones Industrial Average and its stock components are studied\nbetween 1991 and 2008. Pearson-type correlations are computed between the\nstocks and averaged over stock-pairs and time. The results indicate a general\ntrend: whenever the stock index is falling the stock prices are changing in a\nmore correlated manner than in case the stock index is ascending. A thorough\nstatistical analysis of the data shows that the observed difference is\nsignificant, suggesting a constant-fear factor among stockholders.\n"
    },
    {
        "paper_id": 1005.0496,
        "authors": "Edward Hoyle, Lane P. Hughston, Andrea Macrina",
        "title": "Stable-1/2 Bridges and Insurance",
        "comments": "To appear in: Advances in Mathematics of Finance (A. Palczewski and\n  L. Stettner, editors.), Banach Center Publications, Polish Academy of\n  Science, Institute of Mathematics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a class of non-life reserving models using a stable-1/2 random\nbridge to simulate the accumulation of paid claims, allowing for an essentially\narbitrary choice of a priori distribution for the ultimate loss. Taking an\ninformation-based approach to the reserving problem, we derive the process of\nthe conditional distribution of the ultimate loss. The \"best-estimate ultimate\nloss process\" is given by the conditional expectation of the ultimate loss. We\nderive explicit expressions for the best-estimate ultimate loss process, and\nfor expected recoveries arising from aggregate excess-of-loss reinsurance\ntreaties. Use of a deterministic time change allows for the matching of any\ninitial (increasing) development pattern for the paid claims. We show that\nthese methods are well-suited to the modelling of claims where there is a\nnon-trivial probability of catastrophic loss. The generalized inverse-Gaussian\n(GIG) distribution is shown to be a natural choice for the a priori ultimate\nloss distribution. For particular GIG parameter choices, the best-estimate\nultimate loss process can be written as a rational function of the paid-claims\nprocess. We extend the model to include a second paid-claims process, and allow\nthe two processes to be dependent. The results obtained can be applied to the\nmodelling of multiple lines of business or multiple origin years. The\nmulti-dimensional model has the property that the dimensionality of\ncalculations remains low, regardless of the number of paid-claims processes. An\nalgorithm is provided for the simulation of the paid-claims processes.\n"
    },
    {
        "paper_id": 1005.0728,
        "authors": "V. Abramov, F. Klebaner, R. Liptser",
        "title": "The Euler-Maruyama approximations for the CEV model",
        "comments": "13 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  The CEV model is given by the stochastic differential equation\n$X_t=X_0+\\int_0^t\\mu X_sds+\\int_0^t\\sigma (X^+_s)^pdW_s$, $\\frac{1}{2}\\le p<1$.\nIt features a non-Lipschitz diffusion coefficient and gets absorbed at zero\nwith a positive probability. We show the weak convergence of Euler-Maruyama\napproximations $X_t^n$ to the process $X_t$, $0\\le t\\le T$, in the Skorokhod\nmetric. We give a new approximation by continuous processes which allows to\nrelax some technical conditions in the proof of weak convergence in \\cite{HZa}\ndone in terms of discrete time martingale problem. We calculate ruin\nprobabilities as an example of such approximation. We establish that the ruin\nprobability evaluated by simulations is not guaranteed to converge to the\ntheoretical one, because the point zero is a discontinuity point of the\nlimiting distribution. To establish such convergence we use the Levy metric,\nand also confirm the convergence numerically. Although the result is given for\nthe specific model, our method works in a more general case of non-Lipschitz\ndiffusion with absorbtion.\n"
    },
    {
        "paper_id": 1005.0768,
        "authors": "Tom Fischer",
        "title": "No-arbitrage pricing under cross-ownership",
        "comments": "Excerpts and ideas from this paper have been presented at the\n  Scientific Conference of the German Association for Actuarial and Financial\n  Mathematics (DGVFM), Bremen, April 30, 2010. Some methods and systems derived\n  from this work have been subject to a provisional (successful) patent filing",
        "journal-ref": "Mathematical Finance. 24 (1), 97--124",
        "doi": "10.1111/j.1467-9965.2012.00526.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We generalize Merton's asset valuation approach to systems of multiple\nfinancial firms where cross-ownership of equities and liabilities is present.\nThe liabilities, which may include debts and derivatives, can be of differing\nseniority. We derive equations for the prices of equities and recovery claims\nunder no-arbitrage. An existence result and a uniqueness result are proven.\nExamples and an algorithm for the simultaneous calculation of all no-arbitrage\nprices are provided. A result on capital structure irrelevance for groups of\nfirms regarding externally held claims is discussed, as well as financial\nleverage and systemic risk caused by cross-ownership.\n"
    },
    {
        "paper_id": 1005.0877,
        "authors": "Gao-Feng Gu and Wei-Xing Zhou",
        "title": "Detrending moving average algorithm for multifractals",
        "comments": "13 pages, 3 figures, 2 tables. We provide the MATLAB codes for the\n  one-dimensional and two-dimensional MFDMA Algorithms",
        "journal-ref": "Physical Review E 82, 011136 (2010)",
        "doi": "10.1103/PhysRevE.82.011136",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The detrending moving average (DMA) algorithm is a widely used technique to\nquantify the long-term correlations of non-stationary time series and the\nlong-range correlations of fractal surfaces, which contains a parameter\n$\\theta$ determining the position of the detrending window. We develop\nmultifractal detrending moving average (MFDMA) algorithms for the analysis of\none-dimensional multifractal measures and higher-dimensional multifractals,\nwhich is a generalization of the DMA method. The performance of the\none-dimensional and two-dimensional MFDMA methods is investigated using\nsynthetic multifractal measures with analytical solutions for backward\n($\\theta=0$), centered ($\\theta=0.5$), and forward ($\\theta=1$) detrending\nwindows. We find that the estimated multifractal scaling exponent $\\tau(q)$ and\nthe singularity spectrum $f(\\alpha)$ are in good agreement with the theoretical\nvalues. In addition, the backward MFDMA method has the best performance, which\nprovides the most accurate estimates of the scaling exponents with lowest error\nbars, while the centered MFDMA method has the worse performance. It is found\nthat the backward MFDMA algorithm also outperforms the multifractal detrended\nfluctuation analysis (MFDFA). The one-dimensional backward MFDMA method is\napplied to analyzing the time series of Shanghai Stock Exchange Composite Index\nand its multifractal nature is confirmed.\n"
    },
    {
        "paper_id": 1005.1326,
        "authors": "Periklis Gogas and Ioannis Pragidis",
        "title": "GDP Trend Deviations and the Yield Spread: the Case of Five E.U.\n  Countries",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Several studies have established the predictive power of the yield curve in\nterms of real economic activity. In this paper we use data for a variety of\nE.U. countries: both EMU (Germany, France, Italy) and non-EMU members (Sweden\nand the U.K.). The data used range from 1991:Q1 to 2009:Q1. For each country,\nwe extract the long run trend and the cyclical component of real economic\nactivity, while the corresponding interbank interest rates of long and short\nterm maturities are used for the calculation of the country specific yield\nspreads. We also augment the models tested with non monetary policy variables:\nthe countries' unemployment rates and stock indices. The methodology employed\nin the effort to forecast real output, is a probit model of the inverse\ncumulative distribution function of the standard distribution, using several\nformal forecasting and goodness of fit evaluation tests. The results show that\nthe yield curve augmented with the non-monetary variables has significant\nforecasting power in terms of real economic activity but the results differ\nqualitatively between the individual economies examined raising non-trivial\npolicy implications.\n"
    },
    {
        "paper_id": 1005.1356,
        "authors": "Zongxia Liang and Jicheng Yao",
        "title": "Theoretical and numerical Analysis on Optimal dividend policy of an\n  insurance company with positive transaction cost and higher solvency",
        "comments": "30 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  Based on a point of view that solvency and security are first, this paper\nconsiders regular-singular stochastic optimal control problem of a large\ninsurance company facing positive transaction cost asked by reinsurer under\nsolvency constraint. The company controls proportional reinsurance and dividend\npay-out policy to maximize the expected present value of the dividend pay-outs\nuntil the time of bankruptcy. The paper aims at deriving the optimal retention\nratio, dividend payout level, explicit value function of the insurance company\nvia stochastic analysis and PDE methods. The results present the best\nequilibrium point between maximization of dividend pay-outs and minimization of\nrisks. The paper also gets a risk-based capital standard to ensure the capital\nrequirement of can cover the total given risk. We present numerical results to\nmake analysis how the model parameters, such as, volatility, premium rate, and\nrisk level, impact on risk-based capital standard, optimal retention ratio,\noptimal dividend payout level and the company's profit.\n"
    },
    {
        "paper_id": 1005.1357,
        "authors": "Shuqing Jiang, Zongxia Liang and Weiming Wu",
        "title": "Stock loan with Automatic termination clause, cap and margin",
        "comments": "30 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  This paper works out fair values of stock loan model with automatic\ntermination clause, cap and margin. This stock loan is treated as a generalized\nperpetual American option with possibly negative interest rate and some\nconstraints. Since it helps a bank to control the risk, the banks charge less\nservice fees compared to stock loans without any constraints. The automatic\ntermination clause, cap and margin are in fact a stop order set by the bank.\nMathematically, it is a kind of optimal stopping problems arising from the\npricing of financial products which is first revealed. We aim at establishing\nexplicitly the value of such a loan and ranges of fair values of key parameters\n: this loan size, interest rate, cap, margin and fee for providing such a\nservice and quantity of this automatic termination clause and relationships\namong these parameters as well as the optimal exercise times. We present\nnumerical results and make analysis about the model parameters and how they\nimpact on value of stock loan.\n"
    },
    {
        "paper_id": 1005.1358,
        "authors": "Zongxia Liang and Weiming Wu",
        "title": "Variational inequality method in stock loans",
        "comments": "14 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  In this paper we first introduce two new financial products:\n  stock loan and capped stock loan. Then we develop a pure variational\n  inequality method to establish explicitly the values of these stock loans.\n  Finally, we work out ranges of fair values of parameters associated with\n  the loans.\n"
    },
    {
        "paper_id": 1005.136,
        "authors": "Zongxia Liang and Jianping Huang",
        "title": "Optimal dividend and investing control of a insurance company with\n  higher solvency constraints",
        "comments": "31 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  This paper considers optimal control problem of a large insurance company\nunder a fixed insolvency probability. The company controls proportional\nreinsurance rate, dividend pay-outs and investing process to maximize the\nexpected present value of the dividend pay-outs until the time of bankruptcy.\nThis paper aims at describing the optimal return function as well as the\noptimal policy. As a by-product, the paper theoretically sets a risk-based\ncapital standard to ensure the capital requirement of can cover the total risk.\n"
    },
    {
        "paper_id": 1005.1361,
        "authors": "Zongxia Liang, Jicheng Yao",
        "title": "Optimization of dividend and reinsurance strategies under ruin\n  probability constraint",
        "comments": "31 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  This paper considers nonlinear regular-singular stochastic optimal control of\nlarge insurance company. The company controls the reinsurance rate and dividend\npayout process to maximize the expected present value of the dividend pay-outs\nuntil the time of bankruptcy. However, if the optimal dividend barrier is too\nlow to be acceptable, it will make the company result in bankruptcy soon.\nMoreover, although risk and return should be highly correlated, over-risking is\nnot a good recipe for high return, the supervisors of the company have to\nimpose their preferred risk level and additional charge on firm seeking\nservices beyond or lower than the preferred risk level. These indeed are\nnonlinear regular-singular stochastic optimal problems under ruin probability\nconstraints. This paper aims at solving this kind of the optimal problems, that\nis, deriving the optimal retention ratio,dividend payout level, optimal return\nfunction and optimal control strategy of the insurance company. As a\nby-product, the paper also sets a risk-based capital standard to ensure the\ncapital requirement of can cover the total given risk, and the effect of the\nrisk level on optimal retention ratio, dividend payout level and optimal\ncontrol strategy are also presented.\n"
    },
    {
        "paper_id": 1005.1476,
        "authors": "Peter Ruckdeschel, Nataliya Horbenko (Fraunhofer ITWM, Department of\n  Financial Mathematics, Dept. of Mathematics, Univerisity of Kaiserslautern)",
        "title": "Robust Estimators in Generalized Pareto Models",
        "comments": "26pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1080/02331888.2011.628022",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with optimally-robust parameter estimation in generalized\nPareto distributions (GPDs). These arise naturally in many situations where one\nis interested in the behavior of extreme events as motivated by the\nPickands-Balkema-de Haan extreme value theorem (PBHT). The application we have\nin mind is calculation of the regulatory capital required by Basel II for a\nbank to cover operational risk. In this context the tail behavior of the\nunderlying distribution is crucial. This is where extreme value theory enters,\nsuggesting to estimate these high quantiles parameterically using, e.g. GPDs.\nRobust statistics in this context offers procedures bounding the influence of\nsingle observations, so provides reliable inference in the presence of moderate\ndeviations from the distributional model assumptions, respectively from the\nmechanisms underlying the PBHT.\n"
    },
    {
        "paper_id": 1005.1705,
        "authors": "Xiaolin Luo and Pavel V. Shevchenko",
        "title": "A Short Tale of Long Tail Integration",
        "comments": null,
        "journal-ref": "Numerical Algorithms: Volume 56, Issue 4 (2011), Page 577",
        "doi": "10.1007/s11075-010-9406-9.",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Integration of the form $\\int_a^\\infty {f(x)w(x)dx} $, where $w(x)$ is either\n$\\sin (\\omega {\\kern 1pt} x)$ or $\\cos (\\omega {\\kern 1pt} x)$, is widely\nencountered in many engineering and scientific applications, such as those\ninvolving Fourier or Laplace transforms. Often such integrals are approximated\nby a numerical integration over a finite domain $(a,\\,b)$, leaving a truncation\nerror equal to the tail integration $\\int_b^\\infty {f(x)w(x)dx} $ in addition\nto the discretization error. This paper describes a very simple, perhaps the\nsimplest, end-point correction to approximate the tail integration, which\nsignificantly reduces the truncation error and thus increases the overall\naccuracy of the numerical integration, with virtually no extra computational\neffort. Higher order correction terms and error estimates for the end-point\ncorrection formula are also derived. The effectiveness of this one-point\ncorrection formula is demonstrated through several examples.\n"
    },
    {
        "paper_id": 1005.176,
        "authors": "Gleb Oshanin, Gregory Schehr",
        "title": "Two stock options at the races: Black-Scholes forecasts",
        "comments": "16 pages, 5 figures. Revised version: references have been added,\n  figure 4 has been modified. Accepted version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Suppose one buys two very similar stocks and is curious about how much, after\nsome time T, one of them will contribute to the overall asset, expecting, of\ncourse, that it should be around 1/2 of the sum. Here we examine this question\nwithin the classical Black and Scholes (BS) model, focusing on the evolution of\nthe probability density function P(w) of a random variable w =\na_T^{(1)}/(a_T^{(1)} + a_T^{(2)}) where a_T^{(1)} and a_T^{(2)} are the values\nof two (either European- or the Asian-style) options produced by two absolutely\nidentical BS stochastic equations. We show that within the realm of the BS\nmodel the behavior of P(w) is surprisingly different from common-sense-based\nexpectations. For the European-style options P(w) always undergoes a\ntransition, (when T approaches a certain threshold value), from a unimodal to a\nbimodal form with the most probable values being close to 0 and 1, and,\nstrikingly, w =1/2 being the least probable value. This signifies that the\nsymmetry between two options spontaneously breaks and just one of them\ncompletely dominates the sum. For path-dependent Asian-style options we observe\nthe same anomalous behavior, but only for a certain range of parameters.\nOutside of this range, P(w) is always a bell-shaped function with a maximum at\nw = 1/2.\n"
    },
    {
        "paper_id": 1005.1811,
        "authors": "A. Philip Dawid, Steven de Rooij, Glenn Shafer, Alexander Shen,\n  Nikolai Vereshchagin, and Vladimir Vovk",
        "title": "Insuring against loss of evidence in game-theoretic probability",
        "comments": "7 pages. This version (version 2) is identical to version 1 (May\n  2010). The most up-to-date version can be found at\n  http://www.probabilityandfinance.com/ (Working Paper 34). That version\n  includes an application to financial markets (in which case our result can be\n  used for insuring against loss of the accumulated capital); The\n  Game-Theoretic Probability and Finance Project, Working Paper 34",
        "journal-ref": "Statistics and Probability Letters 81, 157 - 162 (2011)",
        "doi": "10.1016/j.spl.2010.10.013",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the game-theoretic scenario of testing the performance of\nForecaster by Sceptic who gambles against the forecasts. Sceptic's current\ncapital is interpreted as the amount of evidence he has found against\nForecaster. Reporting the maximum of Sceptic's capital so far exaggerates the\nevidence. We characterize the set of all increasing functions that remove the\nexaggeration. This result can be used for insuring against loss of evidence.\n"
    },
    {
        "paper_id": 1005.1861,
        "authors": "Aleksandar Mijatovi\\'c and Mikhail Urusov",
        "title": "Deterministic criteria for the absence of arbitrage in one-dimensional\n  diffusion models",
        "comments": "20 pages; most results in this paper were contained in the first\n  version of submission 0905.3701; to appear in Finance & Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We obtain a deterministic characterisation of the \\emph{no free lunch with\nvanishing risk}, the \\emph{no generalised arbitrage} and the \\emph{no relative\narbitrage} conditions in the one-dimensional diffusion setting and examine how\nthese notions of no-arbitrage relate to each other.\n"
    },
    {
        "paper_id": 1005.1862,
        "authors": "Xinghua Zheng, Yingying Li",
        "title": "On the estimation of integrated covariance matrices of high dimensional\n  diffusion processes",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AOS939 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 6, 3121-3151",
        "doi": "10.1214/11-AOS939",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the estimation of integrated covariance (ICV) matrices of high\ndimensional diffusion processes based on high frequency observations. We start\nby studying the most commonly used estimator, the realized covariance (RCV)\nmatrix. We show that in the high dimensional case when the dimension $p$ and\nthe observation frequency $n$ grow in the same rate, the limiting spectral\ndistribution (LSD) of RCV depends on the covolatility process not only through\nthe targeting ICV, but also on how the covolatility process varies in time. We\nestablish a Mar\\v{c}enko--Pastur type theorem for weighted sample covariance\nmatrices, based on which we obtain a Mar\\v{c}enko--Pastur type theorem for RCV\nfor a class $\\mathcal{C}$ of diffusion processes. The results explicitly\ndemonstrate how the time variability of the covolatility process affects the\nLSD of RCV. We further propose an alternative estimator, the time-variation\nadjusted realized covariance (TVARCV) matrix. We show that for processes in\nclass $\\mathcal {C}$, the TVARCV possesses the desirable property that its LSD\ndepends solely on that of the targeting ICV through the Mar\\v{c}enko--Pastur\nequation, and hence, in particular, the TVARCV can be used to recover the\nempirical spectral distribution of the ICV by using existing algorithms.\n"
    },
    {
        "paper_id": 1005.1917,
        "authors": "Archil Gulisashvili, Josep Vives",
        "title": "Two-sided estimates for stock price distribution densities in\n  jump-diffusion models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider uncorrelated Stein-Stein, Heston, and Hull-White models and their\nperturbations by compound Poisson processes with jump amplitudes distributed\naccording to a double exponential law. Similar perturbations of the\nBlack-Scholes model were studied by S. Kou. For perturbed stochastic volatility\nmodels, we obtain two-sided estimates for the stock price distribution density\nand compare the tail behavior of this density before and after perturbation. It\nis shown that if the value of the parameter, characterizing the right tail of\nthe double exponential law, is small, then the stock price density in the\nperturbed model decays slower than the density in the original model. On the\nother hand, if the value of this parameter is large, then there are no\nsignificant changes in the behavior of the stock price distribution density.\n"
    },
    {
        "paper_id": 1005.2044,
        "authors": "Katarzyna Bolonek-Lason and Piotr Kosinski",
        "title": "Note on log-periodic description of 2008 financial crash",
        "comments": "13 pages, 7 figures; references and few comments added;",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.06.060",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the financial crash in 2008 for different financial markets from\nthe point of view of log-periodic function model. In particular, we consider\nDow Jones index, DAX index and Hang Seng index. We shortly discuss the possible\nrelation of the theory of critical phenomena in physics to financial markets.\n"
    },
    {
        "paper_id": 1005.2228,
        "authors": "Don McLeish",
        "title": "A general method for debiasing a Monte Carlo estimator",
        "comments": "11 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider a process, stochastic or deterministic, obtained by using a\nnumerical integration scheme, or from Monte-Carlo methods involving an\napproximation to an integral, or a Newton-Raphson iteration to approximate the\nroot of an equation. We will assume that we can sample from the distribution of\nthe process from time 0 to finite time n. We propose a scheme for unbiased\nestimation of the limiting value of the process, together with estimates of\nstandard error and apply this to examples including numerical integrals,\nroot-finding and option pricing in a Heston Stochastic Volatility model. This\nresults in unbiased estimators in place of biased ones i nmany potential\napplications.\n"
    },
    {
        "paper_id": 1005.2661,
        "authors": "Bohdan Yu. Kyshakevych, Anatoliy K. Prykarpatsky, Denis Blackmore,\n  Ivan P. Tverdokhlib",
        "title": "Statistically Optimal Strategy Analysis of a Competing Portfolio Market\n  with a Polyvariant Profit Function",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A competing market model with a polyvariant profit function that assumes\n\"zeitnot\" stock behavior of clients is formulated within the banking portfolio\nmedium and then analyzed from the perspective of devising optimal strategies.\nAn associated Markov process method for finding an optimal choice strategy for\nmonovariant and bivariant profit functions is developed. Under certain\nconditions on the bank \"promotional\" parameter with respect to the \"fee\" for a\nmissed share package transaction and at an asymptotically large enough\nportfolio volume, universal transcendental equations - determining the optimal\nshare package choice among competing strategies with monovariant and bivariant\nprofit functions - are obtained.\n"
    },
    {
        "paper_id": 1005.2862,
        "authors": "Carlo Marinelli, Stefano d'Addona, Svetlozar T. Rachev",
        "title": "Multivariate heavy-tailed models for Value-at-Risk estimation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For purposes of Value-at-Risk estimation, we consider several multivariate\nfamilies of heavy-tailed distributions, which can be seen as multidimensional\nversions of Paretian stable and Student's t distributions allowing different\nmarginals to have different tail thickness. After a discussion of relevant\nestimation and simulation issues, we conduct a backtesting study on a set of\nportfolios containing derivative instruments, using historical US stock price\ndata.\n"
    },
    {
        "paper_id": 1005.2979,
        "authors": "Theodoros Tsagaris, Ajay Jasra, Niall Adams",
        "title": "Robust and Adaptive Algorithms for Online Portfolio Selection",
        "comments": "16 pages, 5 figures, submitted to journal",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an online approach to portfolio selection. The motivation is\nwithin the context of algorithmic trading, which demands fast and recursive\nupdates of portfolio allocations, as new data arrives. In particular, we look\nat two online algorithms: Robust-Exponentially Weighted Least Squares (R-EWRLS)\nand a regularized Online minimum Variance algorithm (O-VAR). Our methods use\nsimple ideas from signal processing and statistics, which are sometimes\noverlooked in the empirical financial literature. The two approaches are\nevaluated against benchmark allocation techniques using 4 real datasets. Our\nmethods outperform the benchmark allocation techniques in these datasets, in\nterms of both computational demand and financial performance.\n"
    },
    {
        "paper_id": 1005.3454,
        "authors": "Constantinos Kardaras, Scott Robertson",
        "title": "Robust maximization of asymptotic growth",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP802 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 4, 1576-1610",
        "doi": "10.1214/11-AAP802",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper addresses the question of how to invest in a robust growth-optimal\nway in a market where the instantaneous expected return of the underlying\nprocess is unknown. The optimal investment strategy is identified using a\ngeneralized version of the principal eigenfunction for an elliptic second-order\ndifferential operator, which depends on the covariance structure of the\nunderlying process used for investing. The robust growth-optimal strategy can\nalso be seen as a limit, as the terminal date goes to infinity, of optimal\narbitrages in the terminology of Fernholz and Karatzas [Ann. Appl. Probab. 20\n(2010) 1179-1204].\n"
    },
    {
        "paper_id": 1005.3518,
        "authors": "Anindya S. Chakrabarti and Bikas K. Chakrabarti",
        "title": "Inequality reversal: effects of the savings propensity and correlated\n  returns",
        "comments": "15 pages, 5 figures",
        "journal-ref": "Physica A, 389 17 3572 (2010)",
        "doi": "10.1016/j.physa.2010.04.038",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the last decade, a large body of literature has been developed to explain\nthe universal features of inequality in terms of income and wealth. By now, it\nis established that the distributions of income and wealth in various economies\nshow a number of statistical regularities. There are several models to explain\nsuch static features of inequality in an unifying framework and the kinetic\nexchange models, in particular, provide one such framework. Here we focus on\nthe dynamic features of inequality. In the process of development and growth,\ninequality in an economy in terms of income and wealth follows a particular\npattern of rising in the initial stage followed by an eventual fall. This\ninverted U-shaped curve is known as the Kuznets Curve. We examine the\npossibilities of such behavior of an economy in the context of a generalized\nkinetic exchange model. It is shown that under some specific conditions, our\nmodel economy indeed shows inequality reversal.\n"
    },
    {
        "paper_id": 1005.3535,
        "authors": "Steven L. Heston, Robert A. Korajczyk, and Ronnie Sadka",
        "title": "Intraday Patterns in the Cross-section of Stock Returns",
        "comments": null,
        "journal-ref": "Forthcomming: Journal of Finance 65 (4), 2010 1369-1407",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by the literature on investment flows and optimal trading, we\nexamine intraday predictability in the cross-section of stock returns. We find\na striking pattern of return continuation at half-hour intervals that are exact\nmultiples of a trading day, and this effect lasts for at least 40 trading days.\nVolume, order imbalance, volatility, and bid-ask spreads exhibit similar\npatterns, but do not explain the return patterns. We also show that short-term\nreturn reversal is driven by temporary liquidity imbalances lasting less than\nan hour and bid-ask bounce. Timing trades can reduce execution costs by the\nequivalent of the effective spread.\n"
    },
    {
        "paper_id": 1005.3565,
        "authors": "Erhan Bayraktar and Song Yao",
        "title": "Quadratic Reflected BSDEs with Unbounded Obstacles",
        "comments": "Key Words: Quadratic reflected backward stochastic differential\n  equations, convex/concave generator, $\\th$-difference method, Legenre-Fenchel\n  duality, optimal stopping problems for quadratic $g$-evaluations, stability,\n  obstacle problems for semi-linear parabolic PDEs, viscosity solutions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we analyze a real-valued reflected backward stochastic\ndifferential equation (RBSDE) with an unbounded obstacle and an unbounded\nterminal condition when its generator $f$ has quadratic growth in the\n$z$-variable. In particular, we obtain existence, comparison, and stability\nresults, and consider the optimal stopping for quadratic $g$-evaluations. As an\napplication of our results we analyze the obstacle problem for semi-linear\nparabolic PDEs in which the non-linearity appears as the square of the\ngradient. Finally, we prove a comparison theorem for these obstacle problems\nwhen the generator is convex or concave in the $z$-variable.\n"
    },
    {
        "paper_id": 1005.3799,
        "authors": "Hassan Allouba and Victor Goodman",
        "title": "Market Price of Risk and Random Field Driven Models of Term Structure: A\n  Space-Time Change of Measure Look",
        "comments": "7 pages, 5/9 papers from my 2000-2006 collection (preprint version)",
        "journal-ref": "Finite and infinite dimensional analysis in honor of Leonard Gross\n  (New Orleans, LA, 2001), 37-44, Contemp. Math., 317, Amer. Math. Soc.,\n  Providence, RI, 2003",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  No-arbitrage models of term structure have the feature that the return on\nzero-coupon bonds is the sum of the short rate and the product of volatility\nand market price of risk. Well known models restrict the behavior of the market\nprice of risk so that it is not dependent on the type of asset being modeled.\nWe show that the models recently proposed by Goldstein and Santa-Clara and\nSornette, among others, allow the market price of risk to depend on\ncharacteristics of each asset, and we quantify this dependence. A key tool in\nour analysis is a very general space-time change of measure theorem, proved by\nthe first author in earlier work, and covers continuous orthogonal local\nmartingale measures including space-time white noise.\n"
    },
    {
        "paper_id": 1005.3956,
        "authors": "Baojun Bian, Sheng Miao, Harry Zheng",
        "title": "Smooth Value Functions for a Class of Nonsmooth Utility Maximization\n  Problems",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we prove that there exists a smooth classical solution to the\nHJB equation for a large class of constrained problems with utility functions\nthat are not necessarily differentiable or strictly concave. The value function\nis smooth if admissible controls satisfy an integrability condition or if it is\ncontinuous on the closure of its domain. The key idea is to work on the dual\ncontrol problem and the dual HJB equation. We construct a smooth, strictly\nconvex solution to the dual HJB equation and show that its conjugate function\nis a smooth, strictly concave solution to the primal HJB equation satisfying\nthe terminal and boundary conditions.\n"
    },
    {
        "paper_id": 1005.4417,
        "authors": "Lukasz Delong",
        "title": "Applications of time-delayed backward stochastic differential equations\n  to pricing, hedging and portfolio management",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we investigate novel applications of a new class of equations\nwhich we call time-delayed backward stochastic differential equations.\nTime-delayed BSDEs may arise in finance when we want to find an investment\nstrategy and an investment portfolio which should replicate a liability or meet\na target depending on the applied strategy or the past values of the portfolio.\nIn this setting, a managed investment portfolio serves simultaneously as the\nunderlying security on which the liability/target is contingent and as a\nreplicating portfolio for that liability/target. This is usually the case for\ncapital-protected investments and performance-linked pay-offs. We give examples\nof pricing, hedging and portfolio management problems (asset-liability\nmanagement problems) which could be investigated in the framework of\ntime-delayed BSDEs. Our motivation comes from life insurance and we focus on\nparticipating contracts and variable annuities. We derive the corresponding\ntime-delayed BSDEs and solve them explicitly or at least provide hints how to\nsolve them numerically. We give a financial interpretation of the theoretical\nfact that a time-delayed BSDE may not have a solution or may have multiple\nsolutions.\n"
    },
    {
        "paper_id": 1005.4456,
        "authors": "Volf Frishling and David G Maher",
        "title": "Some Remarks on T-copulas",
        "comments": "15 pages, 7 figures. Submitted to QMF2010",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We examine three methods of constructing correlated Student-$t$ random\nvariables. Our motivation arises from simulations that utilise heavy-tailed\ndistributions for the purposes of stress testing and economic capital\ncalculations for financial institutions. We make several observations regarding\nthe suitability of the three methods for this purpose.\n"
    },
    {
        "paper_id": 1005.4976,
        "authors": "Yonathan Schwarzkopf and J. Doyne Farmer",
        "title": "An empirical study of the tails of mutual fund size",
        "comments": "6 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The mutual fund industry manages about a quarter of the assets in the U.S.\nstock market and thus plays an important role in the U.S. economy. The question\nof how much control is concentrated in the hands of the largest players is best\nquantitatively discussed in terms of the tail behavior of the mutual fund size\ndistribution. We study the distribution empirically and show that the tail is\nmuch better described by a log-normal than a power law, indicating less\nconcentration than, for example, personal income. The results are highly\nstatistically significant and are consistent across fifteen years. This\ncontradicts a recent theory concerning the origin of the power law tails of the\ntrading volume distribution. Based on the analysis in a companion paper, the\nlog-normality is to be expected, and indicates that the distribution of mutual\nfunds remains perpetually out of equilibrium.\n"
    },
    {
        "paper_id": 1005.5006,
        "authors": "Giuseppe Toscani",
        "title": "Boltzmann legacy and wealth distribution",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We briefly review results on nonlinear kinetic equation of Boltzmann type\nwhich describe the evolution of wealth in a simple agents market. The\nmathematical structure of the underlying kinetic equations allows to use\nwell-known techniques of wide use in kinetic theory of rarefied gases to obtain\ninformation on the process of relaxation to a stationary profile, as well as to\nidentify simple interaction rules which are responsible of the formation of\nPareto tails.\n"
    },
    {
        "paper_id": 1005.5021,
        "authors": "Thomas Conlon, Heather J. Ruskin, Martin Crane",
        "title": "Random Matrix Theory and Fund of Funds Portfolio Optimisation",
        "comments": "17 Pages",
        "journal-ref": "Physica A 382(2), (2007) 565-576",
        "doi": "10.1016/j.physa.2007.04.039",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The proprietary nature of Hedge Fund investing means that it is common\npractise for managers to release minimal information about their returns. The\nconstruction of a Fund of Hedge Funds portfolio requires a correlation matrix\nwhich often has to be estimated using a relatively small sample of monthly\nreturns data which induces noise. In this paper random matrix theory (RMT) is\napplied to a cross-correlation matrix C, constructed using hedge fund returns\ndata. The analysis reveals a number of eigenvalues that deviate from the\nspectrum suggested by RMT. The components of the deviating eigenvectors are\nfound to correspond to distinct groups of strategies that are applied by hedge\nfund managers. The Inverse Participation ratio is used to quantify the number\nof components that participate in each eigenvector. Finally, the correlation\nmatrix is cleaned by separating the noisy part from the non-noisy part of C.\nThis technique is found to greatly reduce the difference between the predicted\nand realised risk of a portfolio, leading to an improved risk profile for a\nfund of hedge funds.\n"
    },
    {
        "paper_id": 1005.5082,
        "authors": "Yu-Min Yen",
        "title": "A Note on Sparse Minimum Variance Portfolios and Coordinate-Wise Descent\n  Algorithms",
        "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation 1",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this short report, we discuss how coordinate-wise descent algorithms can\nbe used to solve minimum variance portfolio (MVP) problems in which the\nportfolio weights are constrained by $l_{q}$ norms, where $1\\leq q \\leq 2$. A\nportfolio which weights are regularised by such norms is called a sparse\nportfolio (Brodie et al.), since these constraints facilitate sparsity (zero\ncomponents) of the weight vector. We first consider a case when the portfolio\nweights are regularised by a weighted $l_{1}$ and squared $l_{2}$ norm. Then\ntwo benchmark data sets (Fama and French 48 industries and 100 size and BM\nratio portfolios) are used to examine performances of the sparse portfolios.\nWhen the sample size is not relatively large to the number of assets, sparse\nportfolios tend to have lower out-of-sample portfolio variances, turnover\nrates, active assets, short-sale positions, but higher Sharpe ratios than the\nunregularised MVP. We then show some possible extensions; particularly we\nderive an efficient algorithm for solving an MVP problem in which assets are\nallowed to be chosen grouply.\n"
    },
    {
        "paper_id": 1005.5105,
        "authors": "Stefan Gerhold, Johannes Muhle-Karbe, and Walter Schachermayer",
        "title": "The dual optimizer for the growth-optimal portfolio under transaction\n  costs",
        "comments": "26 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the maximization of the long-term growth rate in the\nBlack-Scholes model under proportional transaction costs as in Taksar, Klass\nand Assaf [Math. Oper. Res. 13, 1988]. Similarly as in Kallsen and Muhle-Karbe\n[Ann. Appl. Probab., 20, 2010] for optimal consumption over an infinite\nhorizon, we tackle this problem by determining a shadow price, which is the\nsolution of the dual problem. It can be calculated explicitly up to determining\nthe root of a deterministic function. This in turn allows to explicitly compute\nfractional Taylor expansions, both for the no-trade region of the optimal\nstrategy and for the optimal growth rate.\n"
    },
    {
        "paper_id": 1005.5538,
        "authors": "Florian Steiger",
        "title": "The Impact of Credit Risk and Implied Volatility on Stock Returns",
        "comments": "JEL Classification: G10, G12, G17",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the possibility of using derivative-implied risk premia\nto explain stock returns. The rapid development of derivative markets has led\nto the possibility of trading various kinds of risks, such as credit and\ninterest rate risk, separately from each other. This paper uses credit default\nswaps and equity options to determine risk premia which are then used to form\nportfolios that are regressed against the returns of stock portfolios. It turns\nout that both, credit risk and implied volatility, have high explanatory power\nin regard to stock returns. Especially the returns of distressed stocks are\nhighly dependent on credit risk fluctuations. This finding leads to practical\nimplications, such as cross-hedging opportunities between equity and credit\ninstruments and potentially allows forecasting stock returns based on movements\nin the credit market.\n"
    },
    {
        "paper_id": 1005.5675,
        "authors": "Didier Sornette, Ryan Woodard, Maxim Fedorovsky, Stefan Reimann,\n  Hilary Woodard, Wei-Xing Zhou (The Financial Crisis Observatory)",
        "title": "The Financial Bubble Experiment: Advanced Diagnostics and Forecasts of\n  Bubble Terminations Volume II-Master Document",
        "comments": "Uploaded new version with names of 7 assets and link to original\n  assets document, where checksum can be verified",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This is the second installment of the Financial Bubble Experiment. Here we\nprovide the digital fingerprint of an electronic document in which we identify\n7 bubbles in 7 different global assets; for 4 of these assets, we present\nwindows of dates of the most likely ending time of each bubble. We will provide\nthat document of the original analysis on 1 November 2010.\n"
    },
    {
        "paper_id": 1006.0155,
        "authors": "Alessandro Andreoli, Francesco Caravenna, Paolo Dai Pra, Gustavo Posta",
        "title": "Scaling and multiscaling in financial series: a simple model",
        "comments": "32 pages, 5 figures. Substantial revision, following the referee's\n  suggestions. Version to appear in Adv. in Appl. Probab",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a simple stochastic volatility model which is analytically\ntractable, very easy to simulate and which captures some relevant stylized\nfacts of financial assets, including scaling properties. In particular, the\nmodel displays a crossover in the log-return distribution from power-law tails\n(small time) to a Gaussian behavior (large time), slow decay in the volatility\nautocorrelation and multiscaling of moments. Despite its few parameters, the\nmodel is able to fit several key features of the time series of financial\nindexes, such as the Dow Jones Industrial Average, with a remarkable accuracy.\n"
    },
    {
        "paper_id": 1006.031,
        "authors": "Aim\\'e Lachapelle (CEREMADE), Filippo Santambrogio (CEREMADE)",
        "title": "On the strategic use of risk and undesirable goods in multidimensional\n  screening",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A monopolist sells goods with possibly a characteristic consumers dislike\n(for instance, he sells random goods to risk averse agents), which does not\naffect the production costs. We investigate the question whether using\nundesirable goods is profitable to the seller. We prove that in general this\nmay be the case, depending on the correlation between agents types and\naversion. This is due to screening effects that outperform this aversion. We\nanalyze, in a continuous framework, both 1D and multidimensional cases.\n"
    },
    {
        "paper_id": 1006.0469,
        "authors": "David Zuckerman",
        "title": "Certifiably Pseudorandom Financial Derivatives",
        "comments": "17 pages. An extended abstract of this paper appeared in EC 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Arora, Barak, Brunnermeier, and Ge showed that taking computational\ncomplexity into account, a dishonest seller could strategically place lemons in\nfinancial derivatives to make them substantially less valuable to buyers. We\nshow that if the seller is required to construct derivatives of a certain form,\nthen this phenomenon disappears. In particular, we define and construct\npseudorandom derivative families, for which lemon placement only slightly\naffects the values of the derivatives. Our constructions use expander graphs.\nWe study our derivatives in a more general setting than Arora et al. In\nparticular, we analyze arbitrary tranches of the common collateralized debt\nobligations (CDOs) when the underlying assets can have significant\ndependencies.\n"
    },
    {
        "paper_id": 1006.0628,
        "authors": "S. V. Vikram and Sitabhra Sinha",
        "title": "Emergence of universal scaling in financial markets from mean-field\n  dynamics",
        "comments": "5 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.83.016101",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Collective phenomena with universal properties have been observed in many\ncomplex systems with a large number of components. Here we present a\nmicroscopic model of the emergence of scaling behavior in such systems, where\nthe interaction dynamics between individual components is mediated by a global\nvariable making the mean-field description exact. Using the example of\nfinancial markets, we show that asset price can be such a global variable with\nthe critical role of coordinating the actions of agents who are otherwise\nindependent. The resulting model accurately reproduces empirical properties\nsuch as the universal scaling of the price fluctuation and volume\ndistributions, long-range correlations in volatility and multiscaling.\n"
    },
    {
        "paper_id": 1006.0697,
        "authors": "Tiexin Guo",
        "title": "Recent progress in random metric theory and its applications to\n  conditional risk measures",
        "comments": "37 pages",
        "journal-ref": "Sci. China Ser. A, 2011, 54",
        "doi": "10.1007/s11425-011-4189-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this paper is to give a selective survey on recent progress in\nrandom metric theory and its applications to conditional risk measures. This\npaper includes eight sections. Section 1 is a longer introduction, which gives\na brief introduction to random metric theory, risk measures and conditional\nrisk measures. Section 2 gives the central framework in random metric theory,\ntopological structures, important examples, the notions of a random conjugate\nspace and the Hahn-Banach theorems for random linear functionals. Section 3\ngives several important representation theorems for random conjugate spaces.\nSection 4 gives characterizations for a complete random normed module to be\nrandom reflexive. Section 5 gives hyperplane separation theorems currently\navailable in random locally convex modules. Section 6 gives the theory of\nrandom duality with respect to the locally $L^{0}-$convex topology and in\nparticular a characterization for a locally $L^{0}-$convex module to be\n$L^{0}-$pre$-$barreled. Section 7 gives some basic results on $L^{0}-$convex\nanalysis together with some applications to conditional risk measures. Finally,\nSection 8 is devoted to extensions of conditional convex risk measures, which\nshows that every representable $L^{\\infty}-$type of conditional convex risk\nmeasure and every continuous $L^{p}-$type of convex conditional risk measure\n($1\\leq p<+\\infty$) can be extended to an $L^{\\infty}_{\\cal F}({\\cal E})-$type\nof $\\sigma_{\\epsilon,\\lambda}(L^{\\infty}_{\\cal F}({\\cal E}), L^{1}_{\\cal\nF}({\\cal E}))-$lower semicontinuous conditional convex risk measure and an\n$L^{p}_{\\cal F}({\\cal E})-$type of ${\\cal T}_{\\epsilon,\\lambda}-$continuous\nconditional convex risk measure ($1\\leq p<+\\infty$), respectively.\n"
    },
    {
        "paper_id": 1006.0768,
        "authors": "Fabien Guilbaud, Mohamed Mnif, Huy\\^en Pham",
        "title": "Numerical methods for an optimal order execution problem",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with numerical solutions to an impulse control problem\narising from optimal portfolio liquidation with bid-ask spread and market price\nimpact penalizing speedy execution trades. The corresponding dynamic\nprogramming (DP) equation is a quasi-variational inequality (QVI) with solvency\nconstraint satisfied by the value function in the sense of constrained\nviscosity solutions. By taking advantage of the lag variable tracking the time\ninterval between trades, we can provide an explicit backward numerical scheme\nfor the time discretization of the DPQVI. The convergence of this discrete-time\nscheme is shown by viscosity solutions arguments. An optimal quantization\nmethod is used for computing the (conditional) expectations arising in this\nscheme. Numerical results are presented by examining the behaviour of optimal\nliquidation strategies, and comparative performance analysis with respect to\nsome benchmark execution strategies. We also illustrate our optimal liquidation\nalgorithm on real data, and observe various interesting patterns of order\nexecution strategies. Finally, we provide some numerical tests of sensitivity\nwith respect to the bid/ask spread and market impact parameters.\n"
    },
    {
        "paper_id": 1006.0863,
        "authors": "Luis H. R. Alvarez, Jani Sainio",
        "title": "A Loan Portfolio Model Subject to Random Liabilities and Systemic Jump\n  Risk",
        "comments": "19 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend the Vasi\\v{c}ek loan portfolio model to a setting where liabilities\nfluctuate randomly and asset values may be subject to systemic jump risk. We\nderive the probability distribution of the percentage loss of a uniform\nportfolio and analyze its properties. We find that the impact of liability risk\nis ambiguous and depends on the correlation between the continuous aggregate\nfactor and the asset-liability ratio as well as on the default intensity. We\nalso find that systemic jump risk has a significant impact on the upper\npercentiles of the loss distribution and, therefore, on both the VaR-measure as\nwell as on the expected shortfall.\n"
    },
    {
        "paper_id": 1006.135,
        "authors": "Andrew Gordon Wilson, Zoubin Ghahramani",
        "title": "Copula Processes",
        "comments": "11 pages, 1 table, 1 figure. Submitted for publication. Since last\n  version: minor edits and reformatting",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We define a copula process which describes the dependencies between\narbitrarily many random variables independently of their marginal\ndistributions. As an example, we develop a stochastic volatility model,\nGaussian Copula Process Volatility (GCPV), to predict the latent standard\ndeviations of a sequence of random variables. To make predictions we use\nBayesian inference, with the Laplace approximation, and with Markov chain Monte\nCarlo as an alternative. We find both methods comparable. We also find our\nmodel can outperform GARCH on simulated and financial data. And unlike GARCH,\nGCPV can easily handle missing data, incorporate covariates other than time,\nand model a rich class of covariance structures.\n"
    },
    {
        "paper_id": 1006.1791,
        "authors": "Samantha Kleinberg, Petter N. Kolm and Bud Mishra",
        "title": "Investigating Causal Relationships in Stock Returns with Temporal Logic\n  Based Methods",
        "comments": "10 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We describe a new framework for causal inference and its application to\nreturn time series. In this system, causal relationships are represented as\nlogical formulas, allowing us to test arbitrarily complex hypotheses in a\ncomputationally efficient way. We simulate return time series using a common\nfactor model, and show that on this data the method described significantly\noutperforms Granger causality (a primary approach to this type of problem).\nFinally we apply the method to real return data, showing that the method can\ndiscover novel relationships between stocks. The approach described is a\ngeneral one that will allow combination of price and volume data with\nqualitative information at varying time scales (from interest rate\nannouncements, to earnings reports to news stories) shedding light on some of\nthe previously invisible common causes of seemingly correlated price movements.\n"
    },
    {
        "paper_id": 1006.1882,
        "authors": "Alexander M. Petersen, Fengzhong Wang, Shlomo Havlin and H. Eugene\n  Stanley",
        "title": "Market dynamics immediately before and after financial shocks:\n  quantifying the Omori, productivity and Bath laws",
        "comments": "16 pages, double column, 13 figures, 1 Table; Changes made in Version\n  2 in response to referee comments",
        "journal-ref": "Physical Review E 82, 036114 (2010)",
        "doi": "10.1103/PhysRevE.82.036114",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the cascading dynamics immediately before and immediately after 219\nmarket shocks. We define the time of a market shock T_{c} to be the time for\nwhich the market volatility V(T_{c}) has a peak that exceeds a predetermined\nthreshold. The cascade of high volatility \"aftershocks\" triggered by the \"main\nshock\" is quantitatively similar to earthquakes and solar flares, which have\nbeen described by three empirical laws --- the Omori law, the productivity law,\nand the Bath law. We analyze the most traded 531 stocks in U.S. markets during\nthe two-year period 2001-2002 at the 1-minute time resolution. We find\nquantitative relations between (i) the \"main shock\" magnitude M \\equiv \\log\nV(T_{c}) occurring at the time T_{c} of each of the 219 \"volatility quakes\"\nanalyzed, and (ii) the parameters quantifying the decay of volatility\naftershocks as well as the volatility preshocks. We also find that stocks with\nlarger trading activity react more strongly and more quickly to market shocks\nthan stocks with smaller trading activity. Our findings characterize the\ntypical volatility response conditional on M, both at the market and the\nindividual stock scale. We argue that there is potential utility in these three\nstatistical quantitative relations with applications in option pricing and\nvolatility trading.\n"
    },
    {
        "paper_id": 1006.1996,
        "authors": "Brad Baxter and Raymond Brummelhuis",
        "title": "Functionals of Exponential Brownian Motion and Divided Differences",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a surprising new application of classical approximation theory to\na fundamental asset-pricing model of mathematical finance. Specifically, we\ncalculate an analytic value for the correlation coefficient between exponential\nBrownian motion and its time average, and we find the use of divided\ndifferences greatly elucidates formulae, providing a path to several new\nresults. As applications, we find that this correlation coefficient is always\nat least $1/\\sqrt{2}$ and, via the Hermite--Genocchi integral relation,\ndemonstrate that all moments of the time average are certain divided\ndifferences of the exponential function. We also prove that these moments agree\nwith the somewhat more complex formulae obtained by Oshanin and Yor.\n"
    },
    {
        "paper_id": 1006.201,
        "authors": "David Br\\'ee, Damien Challet, and Pier Paolo Peirano",
        "title": "Prediction accuracy and sloppiness of log-periodic functions",
        "comments": "6 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that log-periodic power-law (LPPL) functions are intrinsically very\nhard to fit to time series. This comes from their sloppiness, the squared\nresiduals depending very much on some combinations of parameters and very\nlittle on other ones. The time of singularity that is supposed to give an\nestimate of the day of the crash belongs to the latter category. We discuss in\ndetail why and how the fitting procedure must take into account the sloppy\nnature of this kind of model. We then test the reliability of LPPLs on\nsynthetic AR(1) data replicating the Hang Seng 1987 crash and show that even\nthis case is borderline regarding predictability of divergence time. We finally\nargue that current methods used to estimate a probabilistic time window for the\ndivergence time are likely to be over-optimistic.\n"
    },
    {
        "paper_id": 1006.2012,
        "authors": "Ernst Eberlein, Zorana Grbac, Thorsten Schmidt",
        "title": "Discrete tenor models for credit risky portfolios driven by\n  time-inhomogeneous L\\'evy processes",
        "comments": "34 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The goal of this paper is to specify dynamic term structure models with\ndiscrete tenor structure for credit portfolios in a top-down setting driven by\ntime-inhomogeneous L\\'evy processes. We provide a new framework, conditions for\nabsence of arbitrage, explicit examples, an affine setup which includes\ncontagion and pricing formulas for STCDOs and options on STCDOs. A calibration\nto iTraxx data with an extended Kalman filter shows an excellent fit over the\nfull observation period. The calibration is done on a set of CDO tranche\nspreads ranging across six tranches and three maturities.\n"
    },
    {
        "paper_id": 1006.2057,
        "authors": "Juan C. Ferrero",
        "title": "The individual income distribution in Argentina in the period 2000-2009.\n  A unique source of non stationary data",
        "comments": "5 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The economic crisis in Argentina around year 2002 provides a unique\nopportunity for Econophysics studies. The available data on individual income\nare analyzed to show that they correspond to non stationary states. However,\nthe rather restricted size of the data survey imposes difficulties that must be\novercome through a careful analysis, for a reliable use. A new method of data\ntreatment is presented that could be helpful in theoretical studies.\n"
    },
    {
        "paper_id": 1006.2273,
        "authors": "Catherine Donnelly",
        "title": "Good-deal bounds in a regime-switching diffusion market",
        "comments": null,
        "journal-ref": "Applied Mathematical Finance (2011), 18(6), pp491-515",
        "doi": "10.1080/1350486X.2011.591156",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider option pricing in a regime-switching diffusion market. As the\nmarket is incomplete, there is no unique price for a derivative. We apply the\ngood-deal pricing bounds idea to obtain ranges for the price of a derivative.\nAs an illustration, we calculate the good-deal pricing bounds for a European\ncall option and we also examine the stability of these bounds when we change\nthe generator of the Markov chain which drives the regime-switching. We find\nthat the pricing bounds depend strongly on the choice of the generator.\n"
    },
    {
        "paper_id": 1006.2281,
        "authors": "Abdelkoddousse Ahdida (CERMICS), Aur\\'elien Alfonsi (CERMICS)",
        "title": "Exact and high order discretization schemes for Wishart processes and\n  their affine extensions",
        "comments": null,
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 3, 1025-1073",
        "doi": "10.1214/12-AAP863",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work deals with the simulation of Wishart processes and affine\ndiffusions on positive semidefinite matrices. To do so, we focus on the\nsplitting of the infinitesimal generator, in order to use composition\ntechniques as Ninomiya and Victoir or Alfonsi. Doing so, we have found a\nremarkable splitting for Wishart processes that enables us to sample exactly\nWishart distributions, without any restriction on the parameters. It is related\nbut extends existing exact simulation methods based on Bartlett's\ndecomposition. Moreover, we can construct high-order discretization schemes for\nWishart processes and second-order schemes for general affine diffusions. These\nschemes are in practice faster than the exact simulation to sample entire\npaths. Numerical results on their convergence are given.\n"
    },
    {
        "paper_id": 1006.2294,
        "authors": "Johannes Muhle-Karbe, Marcel Nutz",
        "title": "Small-Time Asymptotics of Option Prices and First Absolute Moments",
        "comments": "22 pages; forthcoming in 'Journal of Applied Probability'",
        "journal-ref": "J. Appl. Probab. 48 (2011) 1003-1020",
        "doi": "10.1239/jap/1324046015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the leading term in the small-time asymptotics of at-the-money call\noption prices when the stock price process $S$ follows a general martingale.\nThis is equivalent to studying the first centered absolute moment of $S$. We\nshow that if $S$ has a continuous part, the leading term is of order $\\sqrt{T}$\nin time $T$ and depends only on the initial value of the volatility.\nFurthermore, the term is linear in $T$ if and only if $S$ is of finite\nvariation. The leading terms for pure-jump processes with infinite variation\nare between these two cases; we obtain their exact form for stable-like small\njumps. To derive these results, we use a natural approximation of $S$ so that\ncalculations are necessary only for the class of L\\'evy processes.\n"
    },
    {
        "paper_id": 1006.2489,
        "authors": "Dmitry V. Vinogradov",
        "title": "Cumulant Approach of Arbitrary Truncated Levy Flight",
        "comments": "9 pages",
        "journal-ref": "Physica A 389 (2010) 5794-5800",
        "doi": "10.1016/j.physa.2010.09.014",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of an arbitrary truncated Levy flight description using the\nmethod of cumulant approach has been solved. The set of cumulants of the\ntruncated Levy distribution given the assumption of arbitrary truncation has\nbeen found. The influence of truncation shape on the truncated Levy flight\nproperties in the Gaussian and the Levy regimes has been investigated.\n"
    },
    {
        "paper_id": 1006.2555,
        "authors": "Yaroslav Ivanenko",
        "title": "Price as a matter of choice and nonstochastic randomness",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A version of indifference valuation of a European call option is proposed\nthat includes statistical regularities of nonstochastic randomness. Classical\nrelations (forward contract value and Black-Scholes formula) are obtained as\nparticular cases. We show that in the general case of nonstochastic randomness\nthe minimal expected profit of uncovered European option position is always\nnegative. A version of delta hedge is proposed.\n"
    },
    {
        "paper_id": 1006.2711,
        "authors": "Konstantinos Spiliopoulos and Richard B. Sowers",
        "title": "Recovery Rates in investment-grade pools of credit assets: A large\n  deviations analysis",
        "comments": "27 Pages, 3 Figures",
        "journal-ref": "Stochastic Processes and their Applications, Volume 121, Issue 12,\n  2011, pp. 2861- 2898",
        "doi": "10.1016/j.spa.2011.08.005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the effect of recovery rates on a pool of credit assets. We allow\nthe recovery rate to depend on the defaults in a general way. Using the theory\nof large deviations, we study the structure of losses in a pool consisting of a\ncontinuum of types. We derive the corresponding rate function and show that it\nhas a natural interpretation as the favored way to rearrange recoveries and\nlosses among the different types. Numerical examples are also provided.\n"
    },
    {
        "paper_id": 1006.2712,
        "authors": "Ronnie L. Loeffen and Pierre Patie",
        "title": "Absolute ruin in the Ornstein-Uhlenbeck type risk model",
        "comments": "17 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We start by showing that the finite-time absolute ruin probability in the\nclassical risk model with constant interest force can be expressed in terms of\nthe transition probability of a positive Ornstein-Uhlenbeck type process, say\nX. Our methodology applies to the case when the dynamics of the aggregate\nclaims process is a subordinator. From this expression, we easily deduce\nnecessary and sufficient conditions for the infinite-time absolute ruin to\noccur. We proceed by showing that, under some technical conditions, the\ntransition density of X admits a spectral type representation involving merely\nthe limiting distribution of the process. As a by-product, we obtain a series\nexpansions for the finite-time absolute ruin probability. On the way, we also\nderive, for the aforementioned risk process, the Laplace transform of the\nfirst-exit time from an interval from above. Finally, we illustrate our results\nby detailing some examples.\n"
    },
    {
        "paper_id": 1006.2862,
        "authors": "Andrey Sokolov, Tien Kieu, Andrew Melatos",
        "title": "A note on the theory of fast money flow dynamics",
        "comments": "accepted for publication in The European Physical Journal B",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2010-00223-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The gauge theory of arbitrage was introduced by Ilinski in\n[arXiv:hep-th/9710148] and applied to fast money flows in\n[arXiv:cond-mat/9902044]. The theory of fast money flow dynamics attempts to\nmodel the evolution of currency exchange rates and stock prices on short, e.g.\\\nintra-day, time scales. It has been used to explain some of the heuristic\ntrading rules, known as technical analysis, that are used by professional\ntraders in the equity and foreign exchange markets. A critique of some of the\nunderlying assumptions of the gauge theory of arbitrage was presented by\nSornette in [arXiv:cond-mat/9804045]. In this paper, we present a critique of\nthe theory of fast money flow dynamics, which was not examined by Sornette. We\ndemonstrate that the choice of the input parameters used in\n[arXiv:cond-mat/9902044] results in sinusoidal oscillations of the exchange\nrate, in conflict with the results presented in [arXiv:cond-mat/9902044]. We\nalso find that the dynamics predicted by the theory are generally unstable in\nmost realistic situations, with the exchange rate tending to zero or infinity\nexponentially.\n"
    },
    {
        "paper_id": 1006.2909,
        "authors": "Dorje C. Brody, Lane P. Hughston, and Andrea Macrina",
        "title": "Credit Risk, Market Sentiment and Randomly-Timed Default",
        "comments": "To appear in: Stochastic Analysis in 2010, Edited by D. Crisan,\n  Springer Verlag",
        "journal-ref": "\"Stochastic Analysis 2010\", p. 267-280 (Berlin: Springer 2011)",
        "doi": "10.1007/978-3-642-15358-7_13",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a model for the credit markets in which the random default times\nof bonds are assumed to be given as functions of one or more independent\n\"market factors\". Market participants are assumed to have partial information\nabout each of the market factors, represented by the values of a set of market\nfactor information processes. The market filtration is taken to be generated\njointly by the various information processes and by the default indicator\nprocesses of the various bonds. The value of a discount bond is obtained by\ntaking the discounted expectation of the value of the default indicator\nfunction at the maturity of the bond, conditional on the information provided\nby the market filtration. Explicit expressions are derived for the bond price\nprocesses and the associated default hazard rates. The latter are not given a\npriori as part of the model but rather are deduced and shown to be functions of\nthe values of the information processes. Thus the \"perceived\" hazard rates,\nbased on the available information, determine bond prices, and as perceptions\nchange so do the prices. In conclusion, explicit expressions are derived for\noptions on discount bonds, the values of which also fluctuate in line with the\nvicissitudes of market sentiment.\n"
    },
    {
        "paper_id": 1006.3096,
        "authors": "Eugene Kanzieper and Navinder Singh",
        "title": "Non-Hermitean Wishart random matrices (I)",
        "comments": "published version: 29 pages, 4 figures; references added",
        "journal-ref": "J. Math. Phys. 51: 103510,2010",
        "doi": "10.1063/1.3483455",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A non-Hermitean extension of paradigmatic Wishart random matrices is\nintroduced to set up a theoretical framework for statistical analysis of (real,\ncomplex and real quaternion) stochastic time series representing two \"remote\"\ncomplex systems. The first paper in a series provides a detailed spectral\ntheory of non-Hermitean Wishart random matrices composed of complex valued\nentries. The great emphasis is placed on an asymptotic analysis of the mean\neigenvalue density for which we derive, among other results, a complex-plane\nanalogue of the Marchenko-Pastur law. A surprising connection with a class of\nmatrix models previously invented in the context of quantum chromodynamics is\npointed out.\n"
    },
    {
        "paper_id": 1006.3224,
        "authors": "Erhan Bayraktar, Yu-Jui Huang, Qingshuo Song",
        "title": "Outperforming the market portfolio with a given probability",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP799 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 4, 1465-1494",
        "doi": "10.1214/11-AAP799",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our goal is to resolve a problem proposed by Fernholz and Karatzas [On\noptimal arbitrage (2008) Columbia Univ.]: to characterize the minimum amount of\ninitial capital with which an investor can beat the market portfolio with a\ncertain probability, as a function of the market configuration and time to\nmaturity. We show that this value function is the smallest nonnegative\nviscosity supersolution of a nonlinear PDE. As in Fernholz and Karatzas [On\noptimal arbitrage (2008) Columbia Univ.], we do not assume the existence of an\nequivalent local martingale measure, but merely the existence of a local\nmartingale deflator.\n"
    },
    {
        "paper_id": 1006.3337,
        "authors": "Vlad Bally and Stefano De Marco",
        "title": "Bounds on Stock Price probability distributions in Local-Stochastic\n  Volatility models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that in a large class of stochastic volatility models with additional\nskew-functions (local-stochastic volatility models) the tails of the cumulative\ndistribution of the log-returns behave as exp(-c|y|), where c is a positive\nconstant depending on time and on model parameters. We obtain this estimate\nproving a stronger result: using some estimates for the probability that Ito\nprocesses remain around a deterministic curve from Bally et al. '09, we lower\nbound the probability that the couple (X,V) remains around a two-dimensional\ncurve up to a given maturity, X being the log-return process and V its\ninstantaneous variance. Then we find the optimal curve leading to the bounds on\nthe terminal cdf. The method we rely on does not require inversion of\ncharacteristic functions but works for general coefficients of the underlying\nSDE (in particular, no affine structure is needed). Even though the involved\nconstants are less sharp than the ones derived for stochastic volatility models\nwith a particular structure, our lower bounds entail moment explosion, thus\nimplying that Black-Scholes implied volatility always displays wings in the\nconsidered class of models. In a second part of this paper, using Malliavin\ncalculus techniques, we show that an analogous estimate holds for the density\nof the log-returns as well.\n"
    },
    {
        "paper_id": 1006.334,
        "authors": "Antonis Papapantoleon and David Skovmand",
        "title": "Numerical methods for the L\\'evy LIBOR model",
        "comments": "10 pages, submitted to the Proceedings of the Conference on\n  High-performance computing applied to Finance. A longer paper with full\n  details will follow soon",
        "journal-ref": "In M.R. Guarracino et al. (Eds.), Euro-Par 2010 Workshops, LNCS\n  6586, pp. 463-470, Springer, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this work is to provide fast and accurate approximation schemes\nfor the Monte-Carlo pricing of derivatives in the L\\'evy LIBOR model of\nEberlein and \\\"Ozkan (2005). Standard methods can be applied to solve the\nstochastic differential equations of the successive LIBOR rates but the methods\nare generally slow. We propose an alternative approximation scheme based on\nPicard iterations. Our approach is similar in accuracy to the full numerical\nsolution, but with the feature that each rate is, unlike the standard method,\nevolved independently of the other rates in the term structure. This enables\nsimultaneous calculation of derivative prices of different maturities using\nparallel computing. We include numerical illustrations of the accuracy and\nspeed of our method pricing caplets.\n"
    },
    {
        "paper_id": 1006.3521,
        "authors": "Domenico Delli Gatti, Mauro Gallegati, Bruce Greenwald, Alberto Russo,\n  Joseph E. Stiglitz",
        "title": "Business fluctuations in a credit-network economy",
        "comments": null,
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, Vol: 370,\n  Issue: 1, 1 October 2006, pp: 68-74",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We model a network economy with three sectors: downstream firms, upstream\nfirms, and banks. Agents are linked by productive and credit relationships so\nthat the behavior of one agent influences the behavior of the others through\nnetwork connections. Credit interlinkages among agents are a source of\nbankruptcy diffusion: in fact, failure of fulfilling debt commitments would\nlead to bankruptcy chains. All in all, the bankruptcy in one sector can diffuse\nto other sectors through linkages creating a vicious cycle and bankruptcy\navalanches in the network economy. Our analysis show how the choices of credit\nsupply by both banks and firms are interrelated. While the initial impact of\nmonetary policy is on bank behaviour, we show the interactive play between the\nchoices made by banks, the choices made by firms in their role as providers of\ncredit, and the choices made by firms in their role as producers.\n"
    },
    {
        "paper_id": 1006.3708,
        "authors": "M. Patriarca, E. Heinsalu, R. Kitt, J. Kalda",
        "title": "Econophysics studies in Estonia",
        "comments": "Submitted to the special issue on \"Econophysics\" of the journal\n  Science & Culture (http://www.scienceandculture-isna.org/journal.htm), a\n  publication of the Indian Science News Association, established in 1935",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A short review of the econophysics research done in Estonia, devoted to the\n15th anniversary of the term \"econophysics\".\n"
    },
    {
        "paper_id": 1006.3923,
        "authors": "Diego Garlaschelli, Franco Ruzzenenti, Riccardo Basosi",
        "title": "Complex Networks and Symmetry I: A Review",
        "comments": "Final accepted version",
        "journal-ref": "Symmetry 2, no. 3, pp. 1683-1709 (2010)",
        "doi": "10.3390/sym2031683",
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  In this review we establish various connections between complex networks and\nsymmetry. While special types of symmetries (e.g., automorphisms) are studied\nin detail within discrete mathematics for particular classes of deterministic\ngraphs, the analysis of more general symmetries in real complex networks is far\nless developed. We argue that real networks, as any entity characterized by\nimperfections or errors, necessarily require a stochastic notion of invariance.\nWe therefore propose a definition of stochastic symmetry based on graph\nensembles and use it to review the main results of network theory from an\nunusual perspective. The results discussed here and in a companion paper show\nthat stochastic symmetry highlights the most informative topological properties\nof real networks, even in noisy situations unaccessible to exact techniques.\n"
    },
    {
        "paper_id": 1006.3956,
        "authors": "Sonia R. Bentes",
        "title": "Econophysics: A new discipline",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper debates the contribution of Econophysics to the economic or\nfinancial domains. Since the traditional approach performed by Economics or\nFinance has revealed to be insufficient in fully characterizing and explaining\nthe correspondingly phenomena, we discuss whether Econophysics can provide a\nnew insight onto these matters. Thus, an assessment is presented in order to\nweight its potential opportunities and limitations. This is particularly\nrelevant as it is widely recognized that during its yet short existence\nEconophysics has experienced a growing interest not only by physicists but also\nby economists in searching for new approaches that could help explaining\nexisting questions. In fact, many papers have been submitted, some books have\nbeen released, new journals have been published, several conferences have been\nheld, a site is maintained -- http://www.unifr.ch/econophysics where news,\nevents, book reviews, papers and a blog are exhibited; a 3-year licentiate\nstudies (University of Silesia [1]) and a B.Sc. course (University of Wroclaw\n[2]) have been created and also some Ph.D. thesis have been written. Therefore,\na fundamental question arises: Is this just a fad or is it something much more\nconsistent that will prevail? This is what this paper addresses.\n"
    },
    {
        "paper_id": 1006.407,
        "authors": "V.N. Katsikis and I.A. Polyrakis",
        "title": "Computation of vector sublattices and minimal lattice-subspaces of R^k.\n  Applications in finance",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we perform a computational study of Polyrakis algorithms\npresented in [12,13]. These algorithms are used for the determination of the\nvector sublattice and the minimal lattice-subspace generated by a finite set of\npositive vectors of R^k. The study demonstrates that our findings can be very\nuseful in the field of Economics, especially in completion by options of\nsecurity markets and portfolio insurance.\n"
    },
    {
        "paper_id": 1006.4083,
        "authors": "Teemu Pennanen",
        "title": "Convex duality in stochastic programming and mathematical finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes a general duality framework for the problem of minimizing\na convex integral functional over a space of stochastic processes adapted to a\ngiven filtration. The framework unifies many well-known duality frameworks from\noperations research and mathematical finance. The unification allows the\nextension of some useful techniques from these two fields to a much wider class\nof problems. In particular, combining certain finite-dimensional techniques\nfrom convex analysis with measure theoretic techniques from mathematical\nfinance, we are able to close the duality gap in some situations where\ntraditional topological arguments fail.\n"
    },
    {
        "paper_id": 1006.4382,
        "authors": "Venkat Venkatasubramanian",
        "title": "Fairness Is an Emergent Self-Organized Property of the Free Market for\n  Labor",
        "comments": null,
        "journal-ref": "Entropy 2010, 12(6), 1514-1531",
        "doi": "10.3390/e12061514",
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  The excessive compensation packages of CEOs of U.S. corporations in recent\nyears have brought to the foreground the issue of fairness in economics. The\nconventional wisdom is that the free market for labor, which determines the pay\npackages, cares only about efficiency and not fairness. We present an\nalternative theory that shows that an ideal free market environment also\npromotes fairness, as an emergent property resulting from the self-organizing\nmarket dynamics. Even though an individual employee may care only about his or\nher salary and no one else's, the collective actions of all the employees,\ncombined with the profit maximizing actions of all the companies, in a free\nmarket environment under budgetary constraints, lead towards a more fair\nallocation of wages, guided by Adam Smith's invisible hand of\nself-organization. By exploring deep connections with statistical\nthermodynamics, we show that entropy is the appropriate measure of fairness in\na free market environment which is maximized at equilibrium to yield the\nlognormal distribution of salaries as the fairest inequality of pay in an\norganization under ideal conditions.\n"
    },
    {
        "paper_id": 1006.4517,
        "authors": "Pekka Malo and Teemu Pennanen",
        "title": "Reduced form modeling of limit order markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes a parametric approach for stochastic modeling of limit\norder markets. The models are obtained by augmenting classical perfectly liquid\nmarket models by few additional risk factors that describe liquidity properties\nof the order book. The resulting models are easy to calibrate and to analyze\nusing standard techniques for multivariate stochastic processes. Despite their\nsimplicity, the models are able to capture several properties that have been\nfound in microstructural analysis of limit order markets. Calibration of a\ncontinuous-time three-factor model to Copenhagen Stock Exchange data exhibits\ne.g.\\ mean reversion in liquidity as well as the so called crowding out effect\nwhich influences subsequent mid-price moves. Our dynamic models are well suited\nalso for analyzing market resiliency after liquidity shocks.\n"
    },
    {
        "paper_id": 1006.4595,
        "authors": "P. L. Krapivsky and S. Redner",
        "title": "Wealth Distributions in Asset Exchange Models",
        "comments": "5 pages, 2 figures, revtex4 2-column format. To appear in\n  \"Econophysics\", a special issue in Science and Culture (Kolkata, India) to\n  celebrate 15 years of Econophysics. Trivial typos fixed for the final version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  How do individuals accumulate wealth as they interact economically? We\noutline the consequences of a simple microscopic model in which repeated\npairwise exchanges of assets between individuals build the wealth distribution\nof a population. This distribution is determined for generic exchange rules ---\ntransactions that involve a fixed amount or a fixed fraction of individual\nwealth, as well as random or greedy exchanges. In greedy multiplicative\nexchange, a continuously evolving power law wealth distribution arises, a\nfeature that qualitatively mimics empirical observations.\n"
    },
    {
        "paper_id": 1006.4767,
        "authors": "Andrea Pallavicini and Marco Tarenghi",
        "title": "Interest-Rate Modeling with Multiple Yield Curves",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The crisis that affected financial markets in the last years leaded market\npractitioners to revise well known basic concepts like the ones of discount\nfactors and forward rates. A single yield curve is not sufficient any longer to\ndescribe the market of interest rate products. On the other hand, using\ndifferent yield curves at the same time requires a reformulation of most of the\nbasic assumptions made in interest rate models. In this paper we discuss market\nevidences that led to the introduction of a series of different yield curves.\nWe then define a HJM framework based on a multi-curve approach, presenting also\na bootstrapping algorithm used to fit these different yield curves to market\nprices of plain-vanilla contracts such as basic Interest Rate Swaps (IRS) and\nForward Rate Agreements (FRA). We then show how our approach can be used in\npractice when pricing other interest rate products, such as forward starting\nIRS, plain-vanilla European Swaptions, Constant Maturity Swaps (CMS) and CMS\nspread options, with the final goal to investigate whether the market is\nactually using a multi-curve approach or not. We finally present some numerical\nexamples for a simple formulation of the framework which embeds by construction\nthe multi-curve structure; once the model is calibrated to market prices of\nplain-vanilla options, it can be used via a Monte Carlo simulation to price\nmore complicated exotic options.\n"
    },
    {
        "paper_id": 1006.4968,
        "authors": "Sebastian D\\\"ohler",
        "title": "Validation of credit default probabilities via multiple testing\n  procedures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We apply multiple testing procedures to the validation of estimated default\nprobabilities in credit rating systems. The goal is to identify rating classes\nfor which the probability of default is estimated inaccurately, while still\nmaintaining a predefined level of committing type I errors as measured by the\nfamilywise error rate (FWER) and the false discovery rate (FDR). For FWER, we\nalso consider procedures that take possible discreteness of the data resp. test\nstatistics into account. The performance of these methods is illustrated in a\nsimulation setting and for empirical default data.\n"
    },
    {
        "paper_id": 1006.5044,
        "authors": "Anindya S. Chakrabarti",
        "title": "Modelling savings behavior of agents in the kinetic exchange models of\n  market",
        "comments": "7 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Kinetic exchange models have been successful in explaining the shape of the\nincome/wealth distribution in the economies. However, such models usually make\nsome ad-hoc assumptions when it comes to determining the savings factor. Here,\nwe examine a few models in and out of the domain of standard neo-classical\neconomics to explain the savings behavior of the agents. A number of new\nresults are derived and the rest conform with those obtained earlier.\nConnections are established between the reinforcement choice and strategic\nchoice models with the usual kinetic exchange models.\n"
    },
    {
        "paper_id": 1006.5057,
        "authors": "Kasper Larsen, Hang Yu",
        "title": "Horizon dependence of utility optimizers in incomplete models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the utility maximization problem with changing time\nhorizons in the incomplete Brownian setting. We first show that the primal\nvalue function and the optimal terminal wealth are continuous with respect to\nthe time horizon $T$. Secondly, we exemplify that the expected utility stemming\nfrom applying the $T$-horizon optimizer on a shorter time horizon $S$, $S < T$,\nmay not converge as $S\\uparrow T$ to the $T$-horizon value. Finally, we provide\nnecessary and sufficient conditions preventing the existence of this\nphenomenon.\n"
    },
    {
        "paper_id": 1006.523,
        "authors": "Fr\\'ed\\'eric Abergel and Mauro Politi",
        "title": "Optimizing a basket against the efficient market hypothesis",
        "comments": "submitted to Quantitative Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The possibility that the collective dynamics of a set of stocks could lead to\na specific basket violating the efficient market hypothesis is investigated.\nPrecisely, we show that it is systematically possible to form a basket with a\nnon-trivial autocorrelation structure when the examined time scales are at the\norder of tens of seconds. Moreover, we show that this situation is persistent\nenough to allow some kind of forecasting.\n"
    },
    {
        "paper_id": 1006.5473,
        "authors": "Shubhabrata Das, Marie Kratz",
        "title": "Alarm System for Insurance Companies: A Strategy for Capital Allocation",
        "comments": "Keywords: alarm system, capital accumulation function, efficiency,\n  quantitative risk management, regulation, risk process, ruin probability. 29\n  pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One possible way of risk management for an insurance company is to develop an\nearly and appropriate alarm system before the possible ruin. The ruin is\ndefined through the status of the aggregate risk process, which in turn is\ndetermined by premium accumulation as well as claim settlement outgo for the\ninsurance company. The main purpose of this work is to design an effective\nalarm system, i.e. to define alarm times and to recommend augmentation of\ncapital of suitable magnitude at those points to prevent or reduce the chance\nof ruin. To draw a fair measure of effectiveness of alarm system, comparison is\ndrawn between an alarm system, with capital being added at the sound of every\nalarm, and the corresponding system without any alarm, but an equivalently\nhigher initial capital. Analytical results are obtained in general setup and\nthis is backed up by simulated performances with various types of loss severity\ndistributions. This provides a strategy for suitably spreading out the capital\nand yet addressing survivability concerns at satisfactory level.\n"
    },
    {
        "paper_id": 1006.549,
        "authors": "Reginald D. Smith",
        "title": "Is high-frequency trading inducing changes in market microstructure and\n  dynamics?",
        "comments": "21 pages, 10 figures, 2 tables; v2 corrected small omission (tilde)\n  in Eq. 8; v3 - changed NWSA to NWS (News Corp), explicitly stated TAQ sale\n  condition codes (and added a few) and trade correction indicator exclusions.\n  No substantive changes to graphs or conclusions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using high-frequency time series of stock prices and share volumes sizes from\nJanuary 2002-May 2009, this paper investigates whether the effects of the onset\nof high-frequency trading, most prominent since 2005, are apparent in the\ndynamics of the dollar traded volume. Indeed it is found in almost all of 14\nheavily traded stocks, that there has been an increase in the Hurst exponent of\ndollar traded volume from Gaussian noise in the earlier years to more\nself-similar dynamics in later years. This shift is linked both temporally to\nthe Reg NMS reforms allowing high-frequency trading to flourish as well as to\nthe declining average size of trades with smaller trades showing markedly\nhigher degrees of self-similarity.\n"
    },
    {
        "paper_id": 1006.5587,
        "authors": "Hideaki Aoyama, Yoshi Fujiwara, Yuichi Ikeda, Hiroshi Iyetomi, and\n  Wataru Souma",
        "title": "Econophysics on Real Economy -The First Decade of the Kyoto Econophysics\n  Group-",
        "comments": "6 pages in Phys.Rev. format. Minor typographical errors are corrected\n  in v3",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Research activities of Kyoto Econophysics Group is reviewed. Strong emphasis\nhas been placed on real economy. While the initial stage of research was a\nfirst high-definition data analysis on personal income, it soon progressed to\nfirm dynamics, growth rate distribution and establishment of Pareto's law and\nGibrat's law. It then led to analysis and simulation of firm dynamics on\neconomic network. Currently it covers a wide rage of dynamics of firms and\nfinancial institutions on complex network, using Japanese large-scale network\ndata, some of which are not available in other countries. Activities of this\ngroup for publicising and promoting understanding of econophysics is also\nreviewed.\n"
    },
    {
        "paper_id": 1006.5847,
        "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer, Oliver Grothe",
        "title": "Estimating correlation and covariance matrices by weighting of market\n  similarity",
        "comments": "8 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss a weighted estimation of correlation and covariance matrices from\nhistorical financial data. To this end, we introduce a weighting scheme that\naccounts for similarity of previous market conditions to the present one. The\nresulting estimators are less biased and show lower variance than either\nunweighted or exponentially weighted estimators. The weighting scheme is based\non a similarity measure which compares the current correlation structure of the\nmarket to the structures at past times. Similarity is then measured by the\nmatrix 2-norm of the difference of probe correlation matrices estimated for two\ndifferent times. The method is validated in a simulation study and tested\nempirically in the context of mean-variance portfolio optimization. In the\nlatter case we find an enhanced realized portfolio return as well as a reduced\nportfolio volatility compared to alternative approaches based on different\nstrategies and estimators.\n"
    },
    {
        "paper_id": 1007.0026,
        "authors": "Marco Bardoscia, Roberto Bellotti",
        "title": "A Dynamical Model for Forecasting Operational Losses",
        "comments": "30 pages, 3 figures, 2 tables",
        "journal-ref": "Physica A 391 (2012), pp. 2641-2655",
        "doi": "10.1016/j.physa.2011.12.046",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A novel dynamical model for the study of operational risk in banks and\nsuitable for the calculation of the Value at Risk (VaR) is proposed. The\nequation of motion takes into account the interactions among different bank's\nprocesses, the spontaneous generation of losses via a noise term and the\nefforts made by the bank to avoid their occurrence. Since the model is very\ngeneral, it can be tailored on the internal organizational structure of a\nspecific bank by estimating some of its parameters from historical operational\nlosses. The model is exactly solved in the case in which there are no causal\nloops in the matrix of couplings and it is shown how the solution can be\nexploited to estimate also the parameters of the noise. The forecasting power\nof the model is investigated by using a fraction $f$ of simulated data to\nestimate the parameters, showing that for $f = 0.75$ the VaR can be forecast\nwith an error $\\simeq 10^{-3}$.\n"
    },
    {
        "paper_id": 1007.0199,
        "authors": "Mauricio Junca",
        "title": "Optimal execution strategy in the presence of permanent price impact and\n  fixed transaction cost",
        "comments": null,
        "journal-ref": "Optim. Control Appl. and Meth. 33 (6):713-738.(2012)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a single risky financial asset model subject to price impact and\ntransaction cost over an infinite horizon. An investor needs to execute a long\nposition in the asset affecting the price of the asset and possibly incurring\nin fixed transaction cost. The objective is to maximize the discounted revenue\nobtained by this transaction. This problem is formulated first as an impulse\ncontrol problem and we characterize the value function using the viscosity\nsolutions framework. We also analyze the case where there is no transaction\ncost and how this formulation relates with a singular control problem. A\nviscosity solution characterization is provided in this case as well. We also\nestablish a connection between both formulations with zero fixed transaction\ncost. Numerical examples with different types of price impact conclude the\ndiscussion.\n"
    },
    {
        "paper_id": 1007.0461,
        "authors": "J.R. Iglesias",
        "title": "How simple regulations can greatly reduce inequality",
        "comments": "7 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many models of market dynamics make use of the idea of wealth exchanges among\neconomic agents. A simple analogy compares the wealth in a society with the\nenergy in a physical system, and the trade between agents to the energy\nexchange between molecules during collisions. However, while in physical\nsystems the equipartition of energy is valid, in most exchange models for\neconomic markets the system converges to a very unequal \"condensed\" state,\nwhere one or a few agents concentrate all the wealth of the society and the\nwide majority of agents shares zero or a very tiny fraction of the wealth. Here\nwe present an exchange model where the goal is not only to avoid condensation\nbut also to reduce the inequality; to carry out this objective the choice of\ninteracting agents is not at random, but follows an extremal dynamics regulated\nby the wealth of the agent. The wealth of the agent with the minimum capital is\nchanged at random and the difference between the ancient and the new wealth of\nthis poorest agent is taken from other agents, so establishing a regulatory\ntool for wealth redistribution. We compare different redistribution processes\nand conclude that a drastic reduction of the inequality can be obtained with\nvery simple regulations.\n"
    },
    {
        "paper_id": 1007.0472,
        "authors": "Dalibor Stys and Miroslav Valcihova",
        "title": "Georg de Buquoy - Founder of Mathematical Economy with South Bohemian\n  Roots",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Georg de Buquoy, Lord de Vaux, lived in Nove Hrady, Prague and Cerveny Hradek\nfor most of his productive life. From his extensive scientific contributions,\nboth theoretical and experimental, we expand here the discussion of his\ncontributions to mathematical economy. He is mainly celebrated as the first\npersons to define correctly net yield and describe method for its optimization,\nwhich was considered \"strikingly modern\" still in 1950. Buquoy's program was\n\"systematic overview of all theorems which affect maintenance and increase of\nnational wealth\" for which he correctly defined and mathematically expressed\nmany economic terms. The most striking feature of Buquoy's writing is that he\nwas also a very influential economic practitioner. He governed one of the\nwealthiest possessions in Bohemia, and perhaps in Austria, of his time. Thus\nhis economical thinking expands from the \"political part\", which is economy in\nmodern sense, to \"...sources of national wealth, or the technical part of\nnational economy ...\". The complexity of Buquoy's view has little match in\nmodern literature namely because the extent of data sources is hardly available\nin modern times. The article puts Buquoy's mathematical economy contributions\nin context to his mathematical physics thoughts and approaches. The last direct\ncitation of Buquoy's work comes from the year 2008.\n"
    },
    {
        "paper_id": 1007.0515,
        "authors": "Pranav Dandekar, Ashish Goel, Ramesh Govindan, Ian Post",
        "title": "Liquidity in Credit Networks: A Little Trust Goes a Long Way",
        "comments": "Version that appeared in ACM EC '11",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Credit networks represent a way of modeling trust between entities in a\nnetwork. Nodes in the network print their own currency and trust each other for\na certain amount of each other's currency. This allows the network to serve as\na decentralized payment infrastructure---arbitrary payments can be routed\nthrough the network by passing IOUs between trusting nodes in their respective\ncurrencies---and obviates the need for a common currency. Nodes can repeatedly\ntransact with each other and pay for the transaction using trusted currency. A\nnatural question to ask in this setting is: how long can the network sustain\nliquidity, i.e., how long can the network support the routing of payments\nbefore credit dries up? We answer this question in terms of the long term\nfailure probability of transactions for various network topologies and credit\nvalues.\n  We prove that the transaction failure probability is independent of the path\nalong which transactions are routed. We show that under symmetric transaction\nrates, the transaction failure probability in a number of well-known graph\nfamilies goes to zero as the size, density or credit capacity of the network\nincreases. We also show via simulations that even networks of small size and\ncredit capacity can route transactions with high probability if they are\nwell-connected. Further, we characterize a centralized currency system as a\nspecial type of a star network (one where edges to the root have infinite\ncredit capacity, and transactions occur only between leaf nodes) and compute\nthe steady-state transaction failure probability in a centralized system. We\nshow that liquidity in star networks, complete graphs and Erd\\\"{o}s-R\\'{e}nyi\nnetworks is comparable to that in equivalent centralized currency systems; thus\nwe do not lose much liquidity in return for their robustness and decentralized\nproperties.\n"
    },
    {
        "paper_id": 1007.061,
        "authors": "Samuel N. Cohen",
        "title": "What risk measures are time consistent for all filtrations?",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study coherent risk measures which are time-consistent for multiple\nfiltrations. We show that a coherent risk measure is time-consistent for every\nfiltration if and only if it is one of four main types. Furthermore, if the\nrisk measure is strictly monotone it is linear, and if the reference\nprobability space is not atomic then it is either linear or an essential\nsupremum.\n"
    },
    {
        "paper_id": 1007.0691,
        "authors": "Dan Pirjol",
        "title": "Phase transition in a log-normal Markov functional model",
        "comments": "9 pages, 5 figures. v2: Added asymptotic expressions for the\n  convexity-adjusted Libors in the small and large volatility limits. v3: Added\n  one reference. Final version to appear in Journal of Mathematical Physics",
        "journal-ref": null,
        "doi": "10.1063/1.3526679",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive the exact solution of a one-dimensional Markov functional model\nwith log-normally distributed interest rates in discrete time. The model is\nshown to have two distinct limiting states, corresponding to small and\nasymptotically large volatilities, respectively. These volatility regimes are\nseparated by a phase transition at some critical value of the volatility. We\ninvestigate the conditions under which this phase transition occurs, and show\nthat it is related to the position of the zeros of an appropriately defined\ngenerating function in the complex plane, in analogy with the Lee-Yang theory\nof the phase transitions in condensed matter physics.\n"
    },
    {
        "paper_id": 1007.1631,
        "authors": "Dario Maldarella, Lorenzo Pareschi",
        "title": "Price dynamics in financial markets: a kinetic approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The use of kinetic modelling based on partial differential equations for the\ndynamics of stock price formation in financial markets is briefly reviewed. The\nimportance of behavioral aspects in market booms and crashes and the role of\nagents' heterogeneity in emerging power laws for price distributions is\nemphasized and discussed.\n"
    },
    {
        "paper_id": 1007.1706,
        "authors": "Thorsten Schmidt and Jerzy Zabczyk",
        "title": "CDO term structure modelling with Levy processes and the relation to\n  market models",
        "comments": "16 pages",
        "journal-ref": "International Journal of Theoretical and Applied Finance, 15 (1),\n  2012",
        "doi": "10.1142/S0219024911006462",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the modelling of collateralized debt obligations (CDOs).\nWe propose a top-down model via forward rates generalizing Filipovi\\'c,\nOverbeck and Schmidt (2009) to the case where the forward rates are driven by a\nfinite dimensional L\\'evy process. The contribution of this work is twofold: we\nprovide conditions for absence of arbitrage in this generalized framework.\nFurthermore, we study the relation to market models by embedding them in the\nforward rate framework in spirit of Brace, Gatarek and Musiela (1997).\n"
    },
    {
        "paper_id": 1007.1908,
        "authors": "Anda Gheorghiu, Anca Gheorghiu, Ion Spanulescu",
        "title": "Target market risk evaluation",
        "comments": "10 pages, 15 figures, Conference ENEC2009, Bucharest, Romania",
        "journal-ref": "Econophysics, New Economy and Complexity, ISSN:2065-2550, II-nd\n  section (New Economy), pp.113-130",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  After the shocking series of bankruptcies started in 2008, the public does\nnot trust anymore the classical methods of assessing business risks. The global\neconomic severe downturn caused demand for both developed and emerging\neconomies' exports to drop and the crisis became truly global. However, this\ncurrent crisis offers opportunities for those companies able to play well their\ncards. Entering new markets has always been a hazardous entrepreneurial\nattempt, but also a rewarding one, in the case of success. The paper presents a\nnew indicator meant for assessing the prospective of success or failure for a\ncompany trying to enter a new market by using an associative strategy. In order\nto take the right decision concerning the optimal market entry strategy,\nmarketers may use a software application, \"AnBilant\", created by a research\nteam from Hyperion University.\n"
    },
    {
        "paper_id": 1007.2352,
        "authors": "Austin Gerig and David Michayluk",
        "title": "Automated Liquidity Provision and the Demise of Traditional Market\n  Making",
        "comments": "22 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Traditional market makers are losing their importance as automated systems\nhave largely assumed the role of liquidity provision in markets. We update the\nmodel of Glosten and Milgrom (1985) to analyze this new world: we add multiple\nsecurities and introduce an automated market maker who uses the relationships\nbetween securities to price order flow. This new automated participant\ntransacts the majority of orders, sets prices that are more efficient, and\nincreases informed and decreases uninformed traders' transaction costs. These\nresults can explain the recent dominance of high frequency trading in US\nmarkets and the corresponding increase in trading volume and decrease in\ntransaction costs for US stocks.\n"
    },
    {
        "paper_id": 1007.2593,
        "authors": "Michael Kearns, Alex Kulesza, Yuriy Nevmyvaka",
        "title": "Empirical Limitations on High Frequency Trading Profitability",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Addressing the ongoing examination of high-frequency trading practices in\nfinancial markets, we report the results of an extensive empirical study\nestimating the maximum possible profitability of the most aggressive such\npractices, and arrive at figures that are surprisingly modest. By \"aggressive\"\nwe mean any trading strategy exclusively employing market orders and relatively\nshort holding periods. Our findings highlight the tension between execution\ncosts and trading horizon confronted by high-frequency traders, and provide a\ncontrolled and large-scale empirical perspective on the high-frequency debate\nthat has heretofore been absent. Our study employs a number of novel empirical\nmethods, including the simulation of an \"omniscient\" high-frequency trader who\ncan see the future and act accordingly.\n"
    },
    {
        "paper_id": 1007.2817,
        "authors": "R. Vilela Mendes and Maria Jo\\~ao Oliveira",
        "title": "The fractional volatility model: No-arbitrage, leverage and risk\n  measures",
        "comments": "12 pages latex",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on a criterium of mathematical simplicity and consistency with\nempirical market data, a stochastic volatility model has been obtained with the\nvolatility process driven by fractional noise. Depending on whether the\nstochasticity generators of log-price and volatility are independent or are the\nsame, two versions of the model are obtained with different leverage behavior.\nHere, the no-arbitrage and incompleteness properties of the model are studied.\nSome risk measures are also discussed in this framework.\n"
    },
    {
        "paper_id": 1007.2968,
        "authors": "Leunglung Chan and Eckhard Platen",
        "title": "Exact Pricing and Hedging Formulas of Long Dated Variance Swaps under a\n  $3/2$ Volatility Model",
        "comments": "23 pages, 5 figures",
        "journal-ref": "Journal of Computational and Applied Mathematics (2015), pp.\n  181-196",
        "doi": "10.1016/j.cam.2014.09.032",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the pricing and hedging of variance swaps under a\n$3/2$ volatility model. Explicit pricing and hedging formulas of variance swaps\nare obtained under the benchmark approach, which only requires the existence of\nthe num\\'{e}raire portfolio. The growth optimal portfolio is the num\\'{e}raire\nportfolio and used as num\\'{e}raire together with the real world probability\nmeasure as pricing measure. This pricing concept provides minimal prices for\nvariance swaps even when an equivalent risk neutral probability measure does\nnot exist.\n"
    },
    {
        "paper_id": 1007.3316,
        "authors": "David German",
        "title": "Pricing in an equilibrium based model for a large investor",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a financial model with a non-trivial price impact effect. In this\nmodel we consider the interaction of a large investor trading in an illiquid\nsecurity, and a market maker who is quoting prices for this security. We assume\nthat the market maker quotes the prices such that by taking the other side of\nthe investor's demand, the market maker will arrive at maturity with the\nmaximal expected utility of the terminal wealth. Within this model we provide\nan explicit recursive pricing formula for an exponential utility function, as\nwell as an asymptotic expansion for the price for a \"small\" simple demand.\n"
    },
    {
        "paper_id": 1007.3347,
        "authors": "Jun-ichi Inoue, Naoya Sazuka, Enrico Scalas",
        "title": "On-line trading as a renewal process: Waiting time and inspection\n  paradox",
        "comments": "5 pages REVTeX format, 4 figures. To appear in \"Econophysics\", a\n  special issue in Science and Culture (Kolkata, India) to celebrate 15 years\n  of Econophysics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We briefly review our recent studies on stochastic processes modelling\ninternet on-line trading. We present a way to evaluate the average waiting time\nbetween the observation of the price in financial markets and the next price\nchange, especially in an on-line foreign exchange trading service for\nindividual customers via the internet. The basic method of our approach depends\non the so-called renewal-reward theorem. Assuming that the stochastic process\nmodelling the price change is a renewal process, we use the theorem to\ncalculate the average waiting time of the process. The so-called ``inspection\nparadox'' is discussed, which, in general, means that the average durations is\nshorter than the average waiting time.\n"
    },
    {
        "paper_id": 1007.3362,
        "authors": "Antonis Papapantoleon and David Skovmand",
        "title": "Picard approximation of stochastic differential equations and\n  application to LIBOR models",
        "comments": "22 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this work is to provide fast and accurate approximation schemes\nfor the Monte Carlo pricing of derivatives in LIBOR market models. Standard\nmethods can be applied to solve the stochastic differential equations of the\nsuccessive LIBOR rates but the methods are generally slow. Our contribution is\ntwofold. Firstly, we propose an alternative approximation scheme based on\nPicard iterations. This approach is similar in accuracy to the Euler\ndiscretization, but with the feature that each rate is evolved independently of\nthe other rates in the term structure. This enables simultaneous calculation of\nderivative prices of different maturities using parallel computing. Secondly,\nthe product terms occurring in the drift of a LIBOR market model driven by a\njump process grow exponentially as a function of the number of rates, quickly\nrendering the model intractable. We reduce this growth from exponential to\nquadratic using truncated expansions of the product terms. We include numerical\nillustrations of the accuracy and speed of our method pricing caplets,\nswaptions and forward rate agreements.\n"
    },
    {
        "paper_id": 1007.3601,
        "authors": "J. N. Leaw and S. A. Cheong",
        "title": "Strategic Insights From Playing the Quantum Tic-Tac-Toe",
        "comments": "20 pages, 3 figures, and 3 tables. LaTeX 2e using iopart class, and\n  braket, color, graphicx, multirow, subfig, url packages",
        "journal-ref": "Journal of Physics A: Mathematical and Theoretical, vol. 43, no.\n  45, 455304, 2010",
        "doi": "10.1088/1751-8113/43/45/455304",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we perform a minimalistic quantization of the classical game\nof tic-tac-toe, by allowing superpositions of classical moves. In order for the\nquantum game to reduce properly to the classical game, we require legal quantum\nmoves to be orthogonal to all previous moves. We also admit interference\neffects, by squaring the sum of amplitudes over all moves by a player to\ncompute his or her occupation level of a given site. A player wins when the\nsums of occupations along any of the eight straight lines we can draw in the $3\n\\times 3$ grid is greater than three. We play the quantum tic-tac-toe first\nrandomly, and then deterministically, to explore the impact different opening\nmoves, end games, and different combinations of offensive and defensive\nstrategies have on the outcome of the game. In contrast to the classical\ntic-tac-toe, the deterministic quantum game does not always end in a draw. In\ncontrast also to most classical two-player games of no chance, it is possible\nfor Player 2 to win. More interestingly, we find that Player 1 enjoys an\noverwhelming quantum advantage when he opens with a quantum move, but loses\nthis advantage when he opens with a classical move. We also find the quantum\nblocking move, which consists of a weighted superposition of moves that the\nopponent could use to win the game, to be very effective in denying the\nopponent his or her victory. We then speculate what implications these results\nmight have on quantum information transfer and portfolio optimization.\n"
    },
    {
        "paper_id": 1007.4264,
        "authors": "Marco Scarsini, Eilon Solan, Nicolas Vieille",
        "title": "Lowest Unique Bid Auctions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a class of auctions (Lowest Unique Bid Auctions) that have\nachieved a considerable success on the Internet. Bids are made in cents (of\neuro) and every bidder can bid as many numbers as she wants. The lowest unique\nbid wins the auction. Every bid has a fixed cost, and once a participant makes\na bid, she gets to know whether her bid was unique and whether it was the\nlowest unique. Information is updated in real time, but every bidder sees only\nwhat's relevant to the bids she made. We show that the observed behavior in\nthese auctions differs considerably from what theory would prescribe if all\nbidders were fully rational. We show that the seller makes money, which would\nnot be the case with rational bidders, and some bidders win the auctions quite\noften. We describe a possible strategy for these bidders.\n"
    },
    {
        "paper_id": 1007.4361,
        "authors": "Jean-Pierre Fouque, Sebastian Jaimungal, Matthew Lorig",
        "title": "Spectral Decomposition of Option Prices in Fast Mean-Reverting\n  Stochastic Volatility Models",
        "comments": null,
        "journal-ref": "SIAM J. Finan. Math. 2, (2011) pp. 665-691",
        "doi": "10.1137/100803614",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using spectral decomposition techniques and singular perturbation theory, we\ndevelop a systematic method to approximate the prices of a variety of options\nin a fast mean-reverting stochastic volatility setting. Four examples are\nprovided in order to demonstrate the versatility of our method. These include:\nEuropean options, up-and-out options, double-barrier knock-out options, and\noptions which pay a rebate upon hitting a boundary. For European options, our\nmethod is shown to produce option price approximations which are equivalent to\nthose developed in [5].\n  [5] Jean-Pierre Fouque, George Papanicolaou, and Sircar Ronnie. Derivatives\nin Financial Markets with Stochas- tic Volatility. Cambridge University Press,\n2000.\n"
    },
    {
        "paper_id": 1007.4366,
        "authors": "Jean-Pierre Fouque, Matthew Lorig",
        "title": "A Fast Mean-Reverting Correction to Heston's Stochastic Volatility Model",
        "comments": null,
        "journal-ref": "SIAM J. Finan. Math. 2, 221-254 (2011)",
        "doi": "10.1137/090761458",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a multi-scale stochastic volatility model in which a fast\nmean-reverting factor of volatility is built on top of the Heston stochastic\nvolatility model. A singular pertubative expansion is then used to obtain an\napproximation for European option prices. The resulting pricing formulas are\nsemi-analytic, in the sense that they can be expressed as integrals.\nDifficulties associated with the numerical evaluation of these integrals are\ndiscussed, and techniques for avoiding these difficulties are provided.\nOverall, it is shown that computational complexity for our model is comparable\nto the case of a pure Heston model, but our correction brings significant\nflexibility in terms of fitting to the implied volatility surface. This is\nillustrated numerically and with option data.\n"
    },
    {
        "paper_id": 1007.4372,
        "authors": "Ryuichi Nakajima and Masayuki Kumon and Akimichi Takemura and Kei\n  Takeuchi",
        "title": "Approximations and asymptotics of upper hedging prices in multinomial\n  models",
        "comments": null,
        "journal-ref": "Japan Journal of Industrial and Applied Mathematics 25 (2012) 1-21",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give an exposition and numerical studies of upper hedging prices in\nmultinomial models from the viewpoint of linear programming and the\ngame-theoretic probability of Shafer and Vovk. We also show that, as the number\nof rounds goes to infinity, the upper hedging price of a European option\nconverges to the solution of the Black-Scholes-Barenblatt equation.\n"
    },
    {
        "paper_id": 1007.5074,
        "authors": "Victor M. Yakovenko",
        "title": "Statistical mechanics approach to the probability distribution of money",
        "comments": "11 pages, 4 figures. This is an invited chapter to the book \"New\n  approaches to monetary theory: Interdisciplinary perspectives\", edited by\n  Heiner Ganssmann, to be published by Routledge in 2011, proceedings of the\n  workshop \"Money - Interdisciplinary Perspectives\", Department of Sociology,\n  Free University of Berlin, 25-27 June 2009",
        "journal-ref": "\"New Approaches to Monetary Theory: Interdisciplinary\n  Perspectives\", ed. by Heiner Ganssmann, ISBN 978-0-415-59525-4, Routledge\n  (2011), pp 104-123, Ch. 7",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This Chapter reviews statistical models for the probability distribution of\nmoney developed in the econophysics literature since the late 1990s. In these\nmodels, economic transactions are modeled as random transfers of money between\nthe agents in payment for goods and services. Starting from the initially equal\ndistribution of money, the system spontaneously develops a highly unequal\ndistribution of money analogous to the Boltzmann-Gibbs distribution of energy\nin physics. Boundary conditions are crucial for achieving a stationary\ndistribution. When debt is permitted, it destabilizes the system, unless some\nsort of limit is imposed on maximal debt.\n"
    },
    {
        "paper_id": 1007.5274,
        "authors": "Achilles D. Speliotopoulos",
        "title": "Volatilities That Change with Time: The Temporal Behavior of the\n  Distribution of Stock-Market Prices",
        "comments": "54 pages with 6 figures, and 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  While the use of volatilities is pervasive throughout finance, our ability to\ndetermine the instantaneous volatility of stocks is nascent. Here, we present a\nmethod for measuring the temporal behavior of stocks, and show that stock\nprices for 24 DJIA stocks follow a stochastic process that describes an\nefficiently priced stock while using a volatility that changes\ndeterministically with time. We find that the often observed, abnormally large\nkurtoses are due to temporal variations in the volatility. Our method can\nresolve changes in volatility and drift of the stocks as fast as a single day\nusing daily close prices.\n"
    },
    {
        "paper_id": 1007.5353,
        "authors": "Archil Gulisashvili",
        "title": "Asymptotic equivalence in Lee's moment formulas for the implied\n  volatility and Piterbarg's conjecture",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The asymptotic behavior of the implied volatility associated with a general\ncall pricing function has been extensively studied in the last decade. The main\ntopics discussed in this paper are Lee's moment formulas for the implied\nvolatility, and Piterbarg's conjecture, describing how the implied volatility\nbehaves in the case where all the moments of the stock price are finite. We\nfind various conditions guaranteeing the existence of the limit in Lee's moment\nformulas. We also prove a modified version of Piterbarg's conjecture and\nprovide a non-restrictive sufficient condition for the validity of this\nconjecture in its original form. The asymptotic formulas obtained in the paper\nare applied to the implied volatility in the CEV model and in the Heston model\nperturbed by a compound Poisson process with double exponential law for jump\nsizes.\n"
    },
    {
        "paper_id": 1007.5376,
        "authors": "Zongxia Liang, Bin Sun",
        "title": "Optimal control of a big financial company with debt liability under\n  bankrupt probability constraints",
        "comments": "38 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  This paper considers an optimal control of a big financial company with debt\nliability under bankrupt probability constraints. The company, which faces\nconstant liability payments and has choices to choose various\nproduction/business policies from an available set of control policies with\ndifferent expected profits and risks, controls the business policy and dividend\npayout process to maximize the expected present value of the dividends until\nthe time of bankruptcy. However, if the dividend payout barrier is too low to\nbe acceptable, it may result in the company's bankruptcy soon. In order to\nprotect the shareholders' profits, the managements of the company impose a\nreasonable and normal constraint on their dividend strategy, that is, the\nbankrupt probability associated with the optimal dividend payout barrier should\nbe smaller than a given risk level within a fixed time horizon. This paper aims\nat working out the optimal control policy as well as optimal return function\nfor the company under bankrupt probability constraint by stochastic analysis,\nPDE methods and variational inequality approach. Moreover, we establish a\nrisk-based capital standard to ensure the capital requirement of can cover the\ntotal given risk by numerical analysis and give reasonable economic\ninterpretation for the results.\n"
    },
    {
        "paper_id": 1007.5413,
        "authors": "A. M. Avdeenko",
        "title": "Optimization of Financial Instrument Parcels in Stochastic Wavelet Model",
        "comments": "9 pages, 3 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To define oscillatory movements of securities market, we put in the non-local\nextension of Ito- equation for wavelet-images of random processes. It is\nproposed an algorithm of creation of evolutionary equation and a model of\nprediction of the most probable price movement path. It is carried out\nexperimental validation of findings.\n"
    },
    {
        "paper_id": 1007.5433,
        "authors": "Mikhail Voropaev",
        "title": "Analytical Framework for Credit Portfolios",
        "comments": "16 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Analytical, free of time consuming Monte Carlo simulations, framework for\ncredit portfolio systematic risk metrics calculations is presented. Techniques\nare described that allow calculation of portfolio-level systematic risk\nmeasures (standard deviation, VaR and Expected Shortfall) as well as allocation\nof risk down to individual transactions. The underlying model is the industry\nstandard multi-factor Merton-type model with arbitrary valuation function at\nhorizon (in contrast to the simplistic default-only case). High accuracy of the\nproposed analytical technique is demonstrated by benchmarking against Monte\nCarlo simulations.\n"
    },
    {
        "paper_id": 1008.0126,
        "authors": "Enkelejd Hashorva, Anthony G. Pakes, Qihe Tang",
        "title": "Asymptotics of Random Contractions",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": "10.1016/j.insmatheco.2010.08.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we discuss the asymptotic behaviour of random contractions\n$X=RS$, where $R$, with distribution function $F$, is a positive random\nvariable independent of $S\\in (0,1)$. Random contractions appear naturally in\ninsurance and finance. Our principal contribution is the derivation of the tail\nasymptotics of $X$ assuming that $F$ is in the max-domain of attraction of an\nextreme value distribution and the distribution function of $S$ satisfies a\nregular variation property. We apply our result to derive the asymptotics of\nthe probability of ruin for a particular discrete-time risk model. Further we\nquantify in our asymptotic setting the effect of the random scaling on the\nConditional Tail Expectations, risk aggregation, and derive the joint\nasymptotic distribution of linear combinations of random contractions.\n"
    },
    {
        "paper_id": 1008.0149,
        "authors": "Gareth W. Peters, Balakrishnan B. Kannan, Ben Lasscock, Chris Mellen\n  and Simon Godsill",
        "title": "Bayesian Cointegrated Vector Autoregression models incorporating\n  Alpha-stable noise for inter-day price movements via Approximate Bayesian\n  Computation",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a statistical model for pairs of traded assets, based on a\nCointegrated Vector Auto Regression (CVAR) Model. We extend standard CVAR\nmodels to incorporate estimation of model parameters in the presence of price\nseries level shifts which are not accurately modeled in the standard Gaussian\nerror correction model (ECM) framework. This involves developing a novel matrix\nvariate Bayesian CVAR mixture model comprised of Gaussian errors intra-day and\nAlpha-stable errors inter-day in the ECM framework. To achieve this we derive a\nnovel conjugate posterior model for the Scaled Mixtures of Normals (SMiN CVAR)\nrepresentation of Alpha-stable inter-day innovations. These results are\ngeneralized to asymmetric models for the innovation noise at inter-day\nboundaries allowing for skewed Alpha-stable models.\n  Our proposed model and sampling methodology is general, incorporating the\ncurrent literature on Gaussian models as a special subclass and also allowing\nfor price series level shifts either at random estimated time points or known a\npriori time points. We focus analysis on regularly observed non-Gaussian level\nshifts that can have significant effect on estimation performance in\nstatistical models failing to account for such level shifts, such as at the\nclose and open of markets. We compare the estimation accuracy of our model and\nestimation approach to standard frequentist and Bayesian procedures for CVAR\nmodels when non-Gaussian price series level shifts are present in the\nindividual series, such as inter-day boundaries. We fit a bi-variate\nAlpha-stable model to the inter-day jumps and model the effect of such jumps on\nestimation of matrix-variate CVAR model parameters using the likelihood based\nJohansen procedure and a Bayesian estimation. We illustrate our model and the\ncorresponding estimation procedures we develop on both synthetic and actual\ndata.\n"
    },
    {
        "paper_id": 1008.016,
        "authors": "Yong-Ping Ruan and Wei-Xing Zhou (ECUST)",
        "title": "Long-term correlations and multifractal nature in the intertrade\n  durations of a liquid Chinese stock and its warrant",
        "comments": "10 latex pages, 4 figures",
        "journal-ref": "Physica A 390 (9), 1646-1654 (2011)",
        "doi": "10.1016/j.physa.2011.01.001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Intertrade duration of equities is an important financial measure\ncharacterizing the trading activities, which is defined as the waiting time\nbetween successive trades of an equity. Using the ultrahigh-frequency data of a\nliquid Chinese stock and its associated warrant, we perform a comparative\ninvestigation of the statistical properties of their intertrade duration time\nseries. The distributions of the two equities can be better described by the\nshifted power-law form than the Weibull and their scaled distributions do not\ncollapse onto a single curve. Although the intertrade durations of the two\nequities have very different magnitude, their intraday patterns exhibit very\nsimilar shapes. Both detrended fluctuation analysis (DFA) and detrending moving\naverage analysis (DMA) show that the 1-min intertrade duration time series of\nthe two equities are strongly correlated. In addition, both multifractal\ndetrended fluctuation analysis (MFDFA) and multifractal detrending moving\naverage analysis (MFDMA) unveil that the 1-min intertrade durations possess\nmultifractal nature. However, the difference between the two singularity\nspectra of the two equities obtained from the MFDMA is much smaller than that\nfrom the MFDFA.\n"
    },
    {
        "paper_id": 1008.0401,
        "authors": "Jan Hendrik Witte and Christoph Reisinger",
        "title": "A Penalty Method for the Numerical Solution of Hamilton-Jacobi-Bellman\n  (HJB) Equations in Finance",
        "comments": "18 Pages, 4 Figures. This updated version has a slightly more\n  detailed introduction. In the current form, the paper will appear in SIAM\n  Journal on Numerical Analysis",
        "journal-ref": "SIAM J. Numer. Anal. 49(1), 213-231, 2011",
        "doi": "10.1137/100797606",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a simple and easy to implement method for the numerical solution\nof a rather general class of Hamilton-Jacobi-Bellman (HJB) equations. In many\ncases, the considered problems have only a viscosity solution, to which,\nfortunately, many intuitive (e.g. finite difference based) discretisations can\nbe shown to converge. However, especially when using fully implicit time\nstepping schemes with their desirable stability properties, one is still faced\nwith the considerable task of solving the resulting nonlinear discrete system.\nIn this paper, we introduce a penalty method which approximates the nonlinear\ndiscrete system to first order in the penalty parameter, and we show that an\niterative scheme can be used to solve the penalised discrete problem in\nfinitely many steps. We include a number of examples from mathematical finance\nfor which the described approach yields a rigorous numerical scheme and present\nnumerical results.\n"
    },
    {
        "paper_id": 1008.0758,
        "authors": "Carmen Pellicer-Lostao, Ricardo Lopez-Ruiz",
        "title": "A Chaotic Approach to Market Dynamics",
        "comments": "17 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Economy is demanding new models, able to understand and predict the evolution\nof markets. To this respect, Econophysics is offering models of markets as\ncomplex systems, such as the gas-like model, able to predict money\ndistributions observed in real economies. However, this model reveals some\ntechnical hitches to explain the power law (Pareto) distribution, observed in\nindividuals with high incomes. Here, non linear dynamics is introduced in the\ngas-like model. The results obtained demonstrate that a chaotic gas-like model\ncan reproduce the two money distributions observed in real economies\n(Exponential and Pareto). Moreover, it is able to control the transition\nbetween them. This may give some insight of the micro-level causes that\noriginate unfair distributions of money in a global society. Ultimately, the\nchaotic model makes obvious the inherent instability of asymmetric scenarios,\nwhere sinks of wealth appear in the market and doom it to complete inequality.\n"
    },
    {
        "paper_id": 1008.0836,
        "authors": "Sam Howison, Christoph Reisinger, Jan Hendrik Witte",
        "title": "The Effect of Non-Smooth Payoffs on the Penalty Approximation of\n  American Options",
        "comments": "34 Pages, 10 Figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article combines various methods of analysis to draw a comprehensive\npicture of penalty approximations to the value, hedge ratio, and optimal\nexercise strategy of American options. While convergence of the penalised\nsolution for sufficiently smooth obstacles is well established in the\nliterature, sharp rates of convergence and particularly the effect of gradient\ndiscontinuities (i.e., the omni-present `kinks' in option payoffs) on this rate\nhave not been fully analysed so far. This effect becomes important not least\nwhen using penalisation as a numerical technique. We use matched asymptotic\nexpansions to characterise the boundary layers between exercise and hold\nregions, and to compute first order corrections for representative payoffs on a\nsingle asset following a diffusion or jump-diffusion model. Furthermore, we\ndemonstrate how the viscosity theory framework in [Jakobsen, 2006] can be\napplied to this setting to derive upper and lower bounds on the value. In a\nsmall extension to [Bensoussan & Lions, 1982], we derive weak convergence rates\nalso for option sensitivities for convex payoffs under jump-diffusion models.\nFinally, we outline applications of the results, including accuracy\nimprovements by extrapolation.\n"
    },
    {
        "paper_id": 1008.1032,
        "authors": "Abhimanyu Mitra and Sidney I. Resnick",
        "title": "Modeling total expenditure on warranty claims",
        "comments": "31 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We approximate the distribution of total expenditure of a retail company over\nwarranty claims incurred in a fixed period [0, T], say the following quarter.\nWe consider two kinds of warranty policies, namely, the non-renewing free\nreplacement warranty policy and the non-renewing pro-rata warranty policy. Our\napproximation holds under modest assumptions on the distribution of the sales\nprocess of the warranted item and the nature of arrivals of warranty claims. We\npropose a method of using historical data to statistically estimate the\nparameters of the approximate distribution. Our methodology is applied to the\nwarranty claims data from a large car manufacturer for a single car model and\nmodel year.\n"
    },
    {
        "paper_id": 1008.1108,
        "authors": "Pavel V. Shevchenko",
        "title": "Calculation of aggregate loss distributions",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 5(2), pp. 3-40, 2010",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Estimation of the operational risk capital under the Loss Distribution\nApproach requires evaluation of aggregate (compound) loss distributions which\nis one of the classic problems in risk theory. Closed-form solutions are not\navailable for the distributions typically used in operational risk. However\nwith modern computer processing power, these distributions can be calculated\nvirtually exactly using numerical methods. This paper reviews numerical\nalgorithms that can be successfully used to calculate the aggregate loss\ndistributions. In particular Monte Carlo, Panjer recursion and Fourier\ntransformation methods are presented and compared. Also, several closed-form\napproximations based on moment matching and asymptotic result for heavy-tailed\ndistributions are reviewed.\n"
    },
    {
        "paper_id": 1008.1846,
        "authors": "Hector Zenil and Jean-Paul Delahaye",
        "title": "An algorithmic information-theoretic approach to the behaviour of\n  financial markets",
        "comments": "Forthcoming in the Journal of Economic Surveys, special issue on\n  Nonlinearity, Complexity and Randomness. 25 pages. 7 figures. 9 tables.\n  Latest version fixes the glitches on the tables related to the distribution\n  from Turing machines (using 4 states as claimed, and not only 2 as before),\n  added 2 new references and other minor changes. UK English version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using frequency distributions of daily closing price time series of several\nfinancial market indexes, we investigate whether the bias away from an\nequiprobable sequence distribution found in the data, predicted by algorithmic\ninformation theory, may account for some of the deviation of financial markets\nfrom log-normal, and if so for how much of said deviation and over what\nsequence lengths. We do so by comparing the distributions of binary sequences\nfrom actual time series of financial markets and series built up from purely\nalgorithmic means. Our discussion is a starting point for a further\ninvestigation of the market as a rule-based system with an 'algorithmic'\ncomponent, despite its apparent randomness, and the use of the theory of\nalgorithmic probability with new tools that can be applied to the study of the\nmarket price phenomenon. The main discussion is cast in terms of assumptions\ncommon to areas of economics in agreement with an algorithmic view of the\nmarket.\n"
    },
    {
        "paper_id": 1008.196,
        "authors": "Caglar Tuncay",
        "title": "Is an historical economic crisis upcoming?",
        "comments": "2 figs",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, the time chart of Dow Jones Industrial Average (DJIA) index is\nanalyzed and approach of recession time term is predicted, which may be\nhallmark of a worldwide economic crisis. However, the methods used for the\nprediction will be disclosed a few years from now. On the other hand, this work\nwill be updated by the author frequently once in every few months where no\nrevisions will be made on the previous uploads and a timestamp will designate\neach part. Thus, the time evolution of the crisis can be followed and the\nprediction may be verified by the readers in time.\n"
    },
    {
        "paper_id": 1008.2104,
        "authors": "Stefan Gerhold",
        "title": "Moment Explosion in the LIBOR Market Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the LIBOR market model, forward interest rates are log-normal under their\nrespective forward measures. This note shows that their distributions under the\nother forward measures of the tenor structure have approximately log-normal\ntails.\n"
    },
    {
        "paper_id": 1008.2179,
        "authors": "Victor M. Yakovenko",
        "title": "Statistical mechanics of money, debt, and energy consumption",
        "comments": "6 pages, 4 figures, invited paper to the journal \"Science and\n  Culture\" for a special issue on Econophysics; located at\n  http://www.scienceandculture-isna.org/sep-oct-2010.htm",
        "journal-ref": "Science and Culture 76 (9-10), 430-436 (2010)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We briefly review statistical models for the probability distribution of\nmoney developed in the econophysics literature since the late 1990s. In these\nmodels, economic transactions are modeled as random transfers of money between\nthe agents in payment for goods and services. We focus on conceptual\nfoundations for this approach, on the issues of money conservation and debt,\nand present new results for the energy consumption distribution around the\nworld.\n"
    },
    {
        "paper_id": 1008.2226,
        "authors": "Steven N. Evans and Alexandru Hening",
        "title": "Non-existence of Markovian time dynamics for graphical models of\n  correlated default",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Filiz et al. (2008) proposed a model for the pattern of defaults seen among a\ngroup of firms at the end of a given time period. The ingredients in the model\nare a graph, where the vertices correspond to the firms and the edges describe\nthe network of interdependencies between the firms, a parameter for each vertex\nthat captures the individual propensity of that firm to default, and a\nparameter for each edge that captures the joint propensity of the two connected\nfirms to default. The correlated default model can be re-rewritten as a\nstandard Ising model on the graph by identifying the set of defaulting firms in\nthe default model with the set of sites in the Ising model for which the spin\nis +1. We ask whether there is a suitable continuous time Markov chain taking\nvalues in the subsets of the vertex set such that the initial state of the\nchain is the empty set, each jump of the chain involves the inclusion of a\nsingle extra vertex, the distribution of the chain at some fixed time horizon\ntime is the one given by the default model, and the distribution of the chain\nfor other times is described by a probability distribution in the same family\nas the default model. We show for three simple but financially natural special\ncases that this is not possible outside of the trivial case where there is\ncomplete independence between the firms.\n"
    },
    {
        "paper_id": 1008.2292,
        "authors": "Marius Hofert, Frederic Vrins",
        "title": "Sibuya copulas",
        "comments": "23 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The standard intensity-based approach for modeling defaults is generalized by\nmaking the deterministic term structure of the survival probability stochastic\nvia a common jump process. The survival copula of the vector of default times\nis derived and it is shown to be explicit and of the functional form as dealt\nwith in the work of Sibuya. Besides the parameters of the jump process, the\nmarginal survival functions of the default times appear in the copula. Sibuya\ncopulas therefore allow for functional parameters and asymmetries. Due to the\njump process in the construction, they allow for a singular component.\nDepending on the parameters, they may also be extreme-value copulas or\nLevy-frailty copulas. Further, Sibuya copulas are easy to sample in any\ndimension. Properties of Sibuya copulas including positive lower orthant\ndependence, tail dependence, and extremal dependence are investigated. An\napplication to pricing first-to-default contracts is outlined and further\ngeneralizations of this copula class are addressed.\n"
    },
    {
        "paper_id": 1008.2421,
        "authors": "Jeff Hamrick, Yifei Huang, Constantinos Kardaras, Murad Taqqu",
        "title": "Maximum penalized quasi-likelihood estimation of the diffusion function",
        "comments": "17 pages, 4 figures, revised version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a maximum penalized quasi-likelihood estimator for estimating in a\nnonparametric way the diffusion function of a diffusion process, as an\nalternative to more traditional kernel-based estimators. After developing a\nnumerical scheme for computing the maximizer of the penalized maximum\nquasi-likelihood function, we study the asymptotic properties of our estimator\nby way of simulation. Under the assumption that overnight London Interbank\nOffered Rates (LIBOR); the USD/EUR, USD/GBP, JPY/USD, and EUR/USD nominal\nexchange rates; and 1-month, 3-month, and 30-year Treasury bond yields are\ngenerated by diffusion processes, we use our numerical scheme to estimate the\ndiffusion function.\n"
    },
    {
        "paper_id": 1008.2663,
        "authors": "Ljudmila A. Bordag, Anna Mikaelyan",
        "title": "Models of self-financing hedging strategies in illiquid markets:\n  symmetry reductions and exact solutions",
        "comments": "17 pages, 3 figures",
        "journal-ref": "Lett. Math. Phys. 96, pp. 191-207, 2011",
        "doi": "10.1007/s11005-011-0463-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the general model of self-financing trading strategies in illiquid\nmarkets introduced by Schoenbucher and Wilmott, 2000. A hedging strategy in the\nframework of this model satisfies a nonlinear partial differential equation\n(PDE) which contains some function g(alpha). This function is deep connected to\nan utility function. We describe the Lie symmetry algebra of this PDE and\nprovide a complete set of reductions of the PDE to ordinary differential\nequations (ODEs). In addition we are able to describe all types of functions\ng(alpha) for which the PDE admits an extended Lie group. Two of three special\ntype functions lead to models introduced before by different authors, one is\nnew. We clarify the connection between these three special models and the\ngeneral model for trading strategies in illiquid markets. We study with the Lie\ngroup analysis the new special case of the PDE describing the self-financing\nstrategies. In both, the general model and the new special model, we provide\nthe optimal systems of subalgebras and study the complete set of reductions of\nthe PDEs to different ODEs. In all cases we are able to provide explicit\nsolutions to the new special model. In one of the cases the solutions describe\npower derivative products.\n"
    },
    {
        "paper_id": 1008.3276,
        "authors": "Bruno Bouchard, Erik Taflin",
        "title": "No-arbitrage of second kind in countable markets with proportional\n  transaction costs",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP825 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 2, 427-454",
        "doi": "10.1214/11-AAP825",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by applications to bond markets, we propose a multivariate\nframework for discrete time financial markets with proportional transaction\ncosts and a countable infinite number of tradable assets. We show that the\nno-arbitrage of second kind property (NA2 in short), recently introduced by\nRasonyi for finite-dimensional markets, allows us to provide a closure property\nfor the set of attainable claims in a very natural way, under a suitable\nefficient friction condition. We also extend to this context the equivalence\nbetween NA2 and the existence of many (strictly) consistent price systems.\n"
    },
    {
        "paper_id": 1008.3427,
        "authors": "Hristo S. Sendov, Ying Wang, and Ricardas Zitikis",
        "title": "Log-supermodularity of weight functions and the loading monotonicity of\n  weighted insurance premiums",
        "comments": "17 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper is motivated by a problem concerning the monotonicity of insurance\npremiums with respect to their loading parameter: the larger the parameter, the\nlarger the insurance premium is expected to be. This property, usually called\nloading monotonicity, is satisfied by premiums that appear in the literature.\nThe increased interest in constructing new insurance premiums has raised a\nquestion as to what weight functions would produce loading-monotonic premiums.\nIn this paper we demonstrate a decisive role of log-supermodularity in\nanswering this question. As a consequence, we establish - at a stroke - the\nloading monotonicity of a number of well-known insurance premiums and offer a\nhost of further weight functions, and consequently of premiums, thus\nillustrating the power of the herein suggested methodology for constructing\nloading-monotonic insurance premiums.\n"
    },
    {
        "paper_id": 1008.365,
        "authors": "Tim Leung and Michael Ludkovski",
        "title": "Optimal Timing to Purchase Options",
        "comments": "24 pages, 6 figures; http://dx.doi.org/10.1137/100809386",
        "journal-ref": "SIAM J. Finan. Math. 2(1): 768-793, 2011",
        "doi": "10.1137/100809386",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the optimal timing of derivative purchases in incomplete markets. In\nour model, an investor attempts to maximize the spread between her model price\nand the offered market price through optimally timing her purchase. Both the\ninvestor and the market value the options by risk-neutral expectations but\nunder different equivalent martingale measures representing different market\nviews. The structure of the resulting optimal stopping problem depends on the\ninteraction between the respective market price of risk and the option payoff.\nIn particular, a crucial role is played by the delayed purchase premium that is\nrelated to the stochastic bracket between the market price and the buyer's risk\npremia. Explicit characterization of the purchase timing is given for two\nrepresentative classes of Markovian models: (i) defaultable equity models with\nlocal intensity; (ii) diffusion stochastic volatility models. Several numerical\nexamples are presented to illustrate the results. Our model is also applicable\nto the optimal rolling of long-dated options and sequential buying and selling\nof options.\n"
    },
    {
        "paper_id": 1008.3718,
        "authors": "William T. Shaw",
        "title": "Monte Carlo Portfolio Optimization for General Investor Risk-Return\n  Objectives and Arbitrary Return Distributions: a Solution for Long-only\n  Portfolios",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop the idea of using Monte Carlo sampling of random portfolios to\nsolve portfolio investment problems. In this first paper we explore the need\nfor more general optimization tools, and consider the means by which\nconstrained random portfolios may be generated. A practical scheme for the\nlong-only fully-invested problem is developed and tested for the classic QP\napplication. The advantage of Monte Carlo methods is that they may be extended\nto risk functions that are more complicated functions of the return\ndistribution, and that the underlying return distribution may be computed\nwithout the classical Gaussian limitations. The optimization of quadratic\nrisk-return functions, VaR, CVaR, may be handled in a similar manner to\nvariability ratios such as Sortino and Omega, or mathematical constructions\nsuch as expected utility and its behavioural finance extensions.\nRobustification is also possible. Grid computing technology is an excellent\nplatform for the development of such computations due to the intrinsically\nparallel nature of the computation, coupled to the requirement to transmit only\nsmall packets of data over the grid. We give some examples deploying\nGridMathematica, in which various investor risk preferences are optimized with\ndiffering multivariate distributions. Good comparisons with established results\nin Mean-Variance and CVaR optimization are obtained when ``edge-vertex-biased''\nsampling methods are employed to create random portfolios. We also give an\napplication to Omega optimization.\n"
    },
    {
        "paper_id": 1008.3722,
        "authors": "{\\L}ukasz Delong",
        "title": "BSDEs with time-delayed generators of a moving average type with\n  applications to non-monotone preferences",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider backward stochastic differential equations with\ntime-delayed generators of a moving average type. The classical framework with\nlinear generators depending on $(Y(t),Z(t))$ is extended and we investigate\nlinear generators depending on $(\\frac{1}{t}\\int_0^tY(s)ds,\n\\frac{1}{t}\\int_0^tZ(s)ds)$. We derive explicit solutions to the corresponding\ntime-delayed BSDEs and we investigate in detail main properties of the\nsolutions. An economic motivation for dealing with the BSDEs with the\ntime-delayed generators of the moving average type is given. We argue that such\nequations may arise when we face the problem of dynamic modelling of\nnon-monotone preferences. We model a disappointment effect under which the\npresent pay-off is compared with the past expectations and a volatility\naversion which causes the present pay-off to be penalized by the past exposures\nto the volatility risk.\n"
    },
    {
        "paper_id": 1008.3746,
        "authors": "Takashi Shinzato and Muneki Yasuda",
        "title": "Belief Propagation Algorithm for Portfolio Optimization Problems",
        "comments": "5 pages, 2 figures, to submit to EPL",
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0134968",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The typical behavior of optimal solutions to portfolio optimization problems\nwith absolute deviation and expected shortfall models using replica analysis\nwas pioneeringly estimated by S. Ciliberti and M. M\\'ezard [Eur. Phys. B. 57,\n175 (2007)]; however, they have not yet developed an approximate derivation\nmethod for finding the optimal portfolio with respect to a given return set. In\nthis study, an approximation algorithm based on belief propagation for the\nportfolio optimization problem is presented using the Bethe free energy\nformalism, and the consistency of the numerical experimental results of the\nproposed algorithm with those of replica analysis is confirmed. Furthermore,\nthe conjecture of H. Konno and H. Yamazaki, that the optimal solutions with the\nabsolute deviation model and with the mean-variance model have the same typical\nbehavior, is verified using replica analysis and the belief propagation\nalgorithm.\n"
    },
    {
        "paper_id": 1008.384,
        "authors": "Yu.A.Kuperin, M.M.Morozova",
        "title": "Statistical and Multifractal Properties of the Time Series Generated by\n  a Modified Minority Game",
        "comments": "18 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper it was developed a modification of the known multiagent model\nMinority Game, designed to simulate the behavior of traders in financial\nmarkets and the resulting price dynamics on the abstract resource. The model\nwas implemented in the form of software. The modified version of Minority Game\nwas investigated with the aim of reproducing the basic properties of real\nfinancial time series. It was proved that such properties as the clustering of\nvolatility, the Levy distribution and multifractality are inherent for\ngenerated by this version of the Minority Game time series of prices.\n"
    },
    {
        "paper_id": 1008.388,
        "authors": "Arnaud Gocsei, Fouad Sahel",
        "title": "Analysis of the sensitivity to discrete dividends : A new approach for\n  pricing vanillas",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The incorporation of a dividend yield in the classical option pricing model\nof Black- Scholes results in a minor modification of the Black-Scholes formula,\nsince the lognormal dynamic of the underlying asset is preserved. However,\nmarket makers prefer to work with cash dividends with fixed value instead of a\ndividend yield. Since there is no closed-form solution for the price of a\nEuropean Call in this case, many methods have been proposed in the literature\nto approximate it. Here, we present a new approach. We derive an exact analytic\nformula for the sensitivity to dividends of an European option. We use this\nresult to elaborate a proxy which possesses the same Taylor expansion around 0\nwith respect to the dividends as the exact price. The obtained approximation is\nvery fast to compute (the same complexity than the usual Black-Scholes formula)\nand numerical tests show the extreme accuracy of the method for all practical\ncases.\n"
    },
    {
        "paper_id": 1008.4611,
        "authors": "Mykhaylo Shkolnikov",
        "title": "Large systems of diffusions interacting through their ranks",
        "comments": "17 pages, 0 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the limiting behaviour of the empirical measure of a system of\ndiffusions interacting through their ranks when the number of diffusions tends\nto infinity. We prove that the limiting dynamics is given by a McKean-Vlasov\nevolution equation. Moreover, we show that in a wide range of cases the\nevolution of the cumulative distribution function under the limiting dynamics\nis governed by the generalized porous medium equation with convection. The\nuniqueness theory for the latter is used to establish the uniqueness of\nsolutions of the limiting McKean-Vlasov equation and the law of large numbers\nfor the corresponding systems of interacting diffusions. The implications of\nthe results for rank-based models of capital distributions in financial markets\nare also explained.\n"
    },
    {
        "paper_id": 1008.4841,
        "authors": "Peng Zhang",
        "title": "Path Integral and Asian Options",
        "comments": "12 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we analytically study the problem of pricing an arithmetically\naveraged Asian option in the path integral formalism. By a trick about the\nDirac delta function, the measure of the path integral is defined by an\neffective action functional whose potential term is an exponential function.\nThis path integral is evaluated by use of the Feynman-Kac theorem. After\nworking out some auxiliary integrations involving Bessel and Whittaker\nfunctions, we arrive at the spectral expansion for the value of Asian options.\n"
    },
    {
        "paper_id": 1008.5055,
        "authors": "Masaaki Fukasawa",
        "title": "Normalization for Implied Volatility",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study specific nonlinear transformations of the Black-Scholes implied\nvolatility to show remarkable properties of the volatility surface. Model-free\nbounds on the implied volatility skew are given. Pricing formulas for the\nEuropean options which are written in terms of the implied volatility are\ngiven. In particular, we prove elegant formulas for the fair strikes of the\nvariance swap and the gamma swap.\n"
    },
    {
        "paper_id": 1008.5058,
        "authors": "Mohamed Mnif",
        "title": "Optimal insurance demand under marked point processes shocks: a dynamic\n  programming duality approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the stochastic control problem of maximizing expected utility from\nterminal wealth under a non-bankruptcy constraint. The wealth process is\nsubject to shocks produced by a general marked point process. The problem of\nthe agent is to derive the optimal insurance strategy which allows \"lowering\"\nthe level of the shocks. This optimization problem is related to a suitable\ndual stochastic control problem in which the delicate boundary constraints\ndisappear. We characterize the dual value function as the unique viscosity\nsolution of the corresponding a Hamilton Jacobi Bellman Variational Inequality\n(HJBVI in short).\n"
    },
    {
        "paper_id": 1008.5373,
        "authors": "Zhaosong Lu and Yong Zhang",
        "title": "Penalty Decomposition Methods for Rank Minimization",
        "comments": "This paper has been withdrawn by the author",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider general rank minimization problems with rank\nappearing in either objective function or constraint. We first establish that a\nclass of special rank minimization problems has closed-form solutions. Using\nthis result, we then propose penalty decomposition methods for general rank\nminimization problems in which each subproblem is solved by a block coordinate\ndescend method. Under some suitable assumptions, we show that any accumulation\npoint of the sequence generated by the penalty decomposition methods satisfies\nthe first-order optimality conditions of a nonlinear reformulation of the\nproblems. Finally, we test the performance of our methods by applying them to\nthe matrix completion and nearest low-rank correlation matrix problems. The\ncomputational results demonstrate that our methods are generally comparable or\nsuperior to the existing methods in terms of solution quality.\n"
    },
    {
        "paper_id": 1009.0299,
        "authors": "Alexander Kiselev and Lenya Ryzhik",
        "title": "A simple model for asset price bubble formation and collapse",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a simple stochastic differential equation for modeling bubbles in\nsocial context. A prime example is bubbles in asset pricing, but similar\nmechanisms may control a range of social phenomena driven by psychological\nfactors (for example, popularity of rock groups, or a number of students\npursuing a given major). Our goal is to study the simplest possible model in\nwhich every term has a clear meaning and which demonstrates several key\nbehaviors. The main factors that enter are tendency of mean reversion to a\nstable value, speculative social response triggered by trend following and\nrandom fluctuations. The interplay of these three forces may lead to bubble\nformation and collapse. Numerical simulations show that the equation has\ndistinct regimes depending on the values of the parameters. We perform rigorous\nanalysis of the weakly random regime, and study the role of change in\nfundamentals in igniting the bubble.\n"
    },
    {
        "paper_id": 1009.0635,
        "authors": "Mohamed Mnif",
        "title": "Numerical methods for optimal insurance demand under marked point\n  processes shocks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with numerical solutions of maximizing expected utility from\nterminal wealth under a non-bankruptcy constraint. The wealth process is\nsubject to shocks produced by a general marked point process. The problem of\nthe agent is to derive the optimal insurance strategy which allows \"lowering\"\nthe level of the shocks. This optimization problem is related to a suitable\ndual stochastic control problem in which the delicate boundary constraints\ndisappear. In Mnif \\cite{mnif10}, the dual value function is characterized as\nthe unique viscosity solution of the corresponding Hamilton Jacobi Bellman\nVariational Inequality (HJBVI in short). We characterize the optimal insurance\nstrategy by the solution of the variational inequality which we solve\nnumerically by using an algorithm based on policy iterations.\n"
    },
    {
        "paper_id": 1009.0769,
        "authors": "Songzi Du, Yair Livne",
        "title": "Chaos and Unraveling in Matching Markets",
        "comments": "39 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study how information perturbations can destabilize two-sided matching\nmarkets. In our model, agents arrive on the market over two periods, while\nagents in the first period do not know the types of those arriving later.\nAgents already present in the market may match early or wait for the small\ngroup of new entrants. Despite the lack of discounting or risk aversion, this\nperturbation creates incentives to match early and leave the market before the\nnew agents arrive. These incentives do not disappear as the market gets large.\nMoreover, we identify a new adverse phenomenon in this setting: as markets get\nlarge the probability of \\emph{chaos} -- where no early matching scheme for\nexisting agents is robust to pairwise deviations -- approaches 1. These results\nare independent of the distribution of agents' types and robust to asymmetries\nbetween the two sides of the market. Our findings thus suggest that matching\nmarkets are extremely sensitive to institutional details and uncertainty.\n"
    },
    {
        "paper_id": 1009.0932,
        "authors": "Erhan Bayraktar, Yu-Jui Huang",
        "title": "On the Multi-Dimensional Controller and Stopper Games",
        "comments": "Key words: Controller-stopper games, weak dynamic programming\n  principle, viscosity solutions, robust optimal stopping, stopping strategies.\n  35 pages. Final version. To appear in the SIAM Journal on Control and\n  Optimization",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a zero-sum stochastic differential controller-and-stopper game in\nwhich the state process is a controlled diffusion evolving in a\nmulti-dimensional Euclidean space. In this game, the controller affects both\nthe drift and the volatility terms of the state process. Under appropriate\nconditions, we show that the game has a value and the value function is the\nunique viscosity solution to an obstacle problem for a Hamilton-Jacobi-Bellman\nequation.\n"
    },
    {
        "paper_id": 1009.0972,
        "authors": "Sitabhra Sinha",
        "title": "Are large complex economic systems unstable ?",
        "comments": "5 pages, 2 figures, to appear in special issue on Econophysics of\n  \"Science & Culture\"",
        "journal-ref": "Science and Culture, 76 (2010) 454-458",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Although classical economic theory is based on the concept of stable\nequilibrium, real economic systems appear to be always out of equilibrium.\nIndeed, they share many of the dynamical features of other complex systems,\ne.g., ecological food-webs. We focus on the relation between increasing\ncomplexity of the economic network and its stability with respect to small\nperturbations in the dynamical variables associated with the constituent nodes.\nInherent delays and multiple time-scales suggest that economic systems will be\nmore likely to exhibit instabilities as their complexity is increased even\nthough the speed at which transactions are conducted has increased many-fold\nthrough technological developments. Analogous to the birth of nonlinear\ndynamics from Poincare's work on the question of whether the solar system is\nstable, we suggest that similar theoretical developments may arise from efforts\nby econophysicists to understand the mechanisms by which instabilities arise in\nthe economy.\n"
    },
    {
        "paper_id": 1009.11,
        "authors": "R\\'emy Chicheportiche, Jean-Philippe Bouchaud",
        "title": "The joint distribution of stock returns is not elliptical",
        "comments": "12 figures",
        "journal-ref": "Int. J. Theo. Appl. Fin., 15, 3, 2012, p12500",
        "doi": "10.1142/S0219024912500197",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using a large set of daily US and Japanese stock returns, we test in detail\nthe relevance of Student models, and of more general elliptical models, for\ndescribing the joint distribution of returns. We find that while Student\ncopulas provide a good approximation for strongly correlated pairs of stocks,\nsystematic discrepancies appear as the linear correlation between stocks\ndecreases, that rule out all elliptical models. Intuitively, the failure of\nelliptical models can be traced to the inadequacy of the assumption of a single\nvolatility mode for all stocks. We suggest several ideas of methodological\ninterest to efficiently visualise and compare different copulas. We identify\nthe rescaled difference with the Gaussian copula and the central value of the\ncopula as strongly discriminating observables. We insist on the need to shun\naway from formal choices of copulas with no financial interpretation.\n"
    },
    {
        "paper_id": 1009.1105,
        "authors": "S. Drozdz, J. Kwapien, J. Speth",
        "title": "Coherent Patterns in Nuclei and in Financial Markets",
        "comments": null,
        "journal-ref": "AIP Conf.Proc. 1261:256-264,2010",
        "doi": "10.1063/1.3479354",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the area of traditional physics the atomic nucleus belongs to the most\ncomplex systems. It involves essentially all elements that characterize\ncomplexity including the most distinctive one whose essence is a permanent\ncoexistence of coherent patterns and of randomness. From a more\ninterdisciplinary perspective, these are the financial markets that represent\nan extreme complexity. Here, based on the matrix formalism, we set some\nparallels between several characteristics of complexity in the above two\nsystems. We, in particular, refer to the concept - historically originating\nfrom nuclear physics considerations - of the random matrix theory and\ndemonstrate its utility in quantifying characteristics of the coexistence of\nchaos and collectivity also for the financial markets. In this later case we\nshow examples that illustrate mapping of the matrix formulation into the\nconcepts originating from the graph theory. Finally, attention is drawn to some\nnovel aspects of the financial coherence which opens room for speculation if\nanalogous effects can be detected in the atomic nuclei or in other strongly\ninteracting Fermi systems.\n"
    },
    {
        "paper_id": 1009.1269,
        "authors": "Zongxia Liang, Lin He, Jiaoling Wu",
        "title": "Optimal Dividend and reinsurance strategy of a Property Insurance\n  Company under Catastrophe Risk",
        "comments": "22 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  We consider an optimal control problem of a property insurance company with\nproportional reinsurance strategy. The insurance business brings in catastrophe\nrisk, such as earthquake and flood. The catastrophe risk could be partly\nreduced by reinsurance. The management of the company controls the reinsurance\nrate and dividend payments process to maximize the expected present value of\nthe dividends before bankruptcy. This is the first time to consider the\ncatastrophe risk in property insurance model, which is more realistic. We\nestablish the solution of the problem by the mixed singular-regular control of\njump diffusions. We first derive the optimal retention ratio, the optimal\ndividend payments level, the optimal return function and the optimal control\nstrategy of the property insurance company, then the impacts of the catastrophe\nrisk and key model parameters on the optimal return function and the optimal\ncontrol strategy of the company are discussed.\n"
    },
    {
        "paper_id": 1009.1446,
        "authors": "Aseem Brahma, Sanmay Das and Malik Magdon-Ismail",
        "title": "Comparing Prediction Market Structures, With an Application to Market\n  Making",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Ensuring sufficient liquidity is one of the key challenges for designers of\nprediction markets. Various market making algorithms have been proposed in the\nliterature and deployed in practice, but there has been little effort to\nevaluate their benefits and disadvantages in a systematic manner. We introduce\na novel experimental design for comparing market structures in live trading\nthat ensures fair comparison between two different microstructures with the\nsame trading population. Participants trade on outcomes related to a\ntwo-dimensional random walk that they observe on their computer screens. They\ncan simultaneously trade in two markets, corresponding to the independent\nhorizontal and vertical random walks. We use this experimental design to\ncompare the popular inventory-based logarithmic market scoring rule (LMSR)\nmarket maker and a new information based Bayesian market maker (BMM). Our\nexperiments reveal that BMM can offer significant benefits in terms of price\nstability and expected loss when controlling for liquidity; the caveat is that,\nunlike LMSR, BMM does not guarantee bounded loss. Our investigation also\nelucidates some general properties of market makers in prediction markets. In\nparticular, there is an inherent tradeoff between adaptability to market shocks\nand convergence during market equilibrium.\n"
    },
    {
        "paper_id": 1009.2168,
        "authors": "Marcel Nutz",
        "title": "Random G-expectations",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP885 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 5, 1755-1777",
        "doi": "10.1214/12-AAP885",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct a time-consistent sublinear expectation in the setting of\nvolatility uncertainty. This mapping extends Peng's G-expectation by allowing\nthe range of the volatility uncertainty to be stochastic. Our construction is\npurely probabilistic and based on an optimal control formulation with\npath-dependent control sets.\n"
    },
    {
        "paper_id": 1009.2329,
        "authors": "Gabriele La Spada, J. Doyne Farmer and Fabrizio Lillo",
        "title": "Tick size and price diffusion",
        "comments": "To be published in the \"Proceedings of Econophys-Kolkata V\n  International Workshop on \"Econophysics of Order-driven Markets\" March 9-13,\n  2010, The New Economic Windows series of Springer-Verlag Italia\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A tick size is the smallest increment of a security price. It is clear that\nat the shortest time scale on which individual orders are placed the tick size\nhas a major role which affects where limit orders can be placed, the bid-ask\nspread, etc. This is the realm of market microstructure and there is a vast\nliterature on the role of tick size on market microstructure. However, tick\nsize can also affect price properties at longer time scales, and relatively\nless is known about the effect of tick size on the statistical properties of\nprices. The present paper is divided in two parts. In the first we review the\neffect of tick size change on the market microstructure and the diffusion\nproperties of prices. The second part presents original results obtained by\ninvestigating the tick size changes occurring at the New York Stock Exchange\n(NYSE). We show that tick size change has three effects on price diffusion.\nFirst, as already shown in the literature, tick size affects price return\ndistribution at an aggregate time scale. Second, reducing the tick size\ntypically leads to an increase of volatility clustering. We give a possible\nmechanistic explanation for this effect, but clearly more investigation is\nneeded to understand the origin of this relation. Third, we explicitly show\nthat the ability of the subordination hypothesis in explaining fat tails of\nreturns and volatility clustering is strongly dependent on tick size. While for\nlarge tick sizes the subordination hypothesis has significant explanatory\npower, for small tick sizes we show that subordination is not the main driver\nof these two important stylized facts of financial market.\n"
    },
    {
        "paper_id": 1009.2631,
        "authors": "M. Abel and D.L. Shepelyansky",
        "title": "Google matrix of business process management",
        "comments": "submitted to European Journal of Physics B",
        "journal-ref": "Eur. Phys. J. B v.84, p.493 (2011)",
        "doi": "10.1140/epjb/e2010-10710-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Development of efficient business process models and determination of their\ncharacteristic properties are subject of intense interdisciplinary research.\nHere, we consider a business process model as a directed graph. Its nodes\ncorrespond to the units identified by the modeler and the link direction\nindicates the causal dependencies between units. It is of primary interest to\nobtain the stationary flow on such a directed graph, which corresponds to the\nsteady-state of a firm during the business process. Following the ideas\ndeveloped recently for the World Wide Web, we construct the Google matrix for\nour business process model and analyze its spectral properties. The importance\nof nodes is characterized by Page-Rank and recently proposed CheiRank and\n2DRank, respectively. The results show that this two-dimensional ranking gives\na significant information about the influence and communication properties of\nbusiness model units. We argue that the Google matrix method, described here,\nprovides a new efficient tool helping companies to make their decisions on how\nto evolve in the exceedingly dynamic global market.\n"
    },
    {
        "paper_id": 1009.2696,
        "authors": "Frantisek Slanina",
        "title": "A contribution to the systematics of stochastic volatility models",
        "comments": "15 pages, no figures",
        "journal-ref": "Physica A, 389 (2010) 3230-3239",
        "doi": "10.1016/j.physa.2010.03.044",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We compare systematically several classes of stochastic volatility models of\nstock market fluctuations. We show that the long-time return distribution is\neither Gaussian or develops a power-law tail, while the short-time return\ndistribution has generically a stretched-exponential form, but can assume also\nan algebraic decay, in the family of models which we call ``GARCH''-type. The\nintermediate regime is found in the exponential Ornstein-Uhlenbeck process. We\ncalculate also the decay of the autocorrelation function of volatility.\n"
    },
    {
        "paper_id": 1009.2721,
        "authors": "Volker Nannen",
        "title": "Convergence of Income Growth Rates in Evolutionary Agent-Based Economics",
        "comments": "5 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a heterogeneous agent-based economic model where economic agents\nhave strictly bounded rationality and where income allocation strategies evolve\nthrough selective imitation. Income is calculated by a Cobb-Douglas type\nproduction function, and selection of strategies for imitation depends on the\nincome growth rate they generate. We show that under these conditions, when an\nagent adopts a new strategy, the effect on its income growth rate is\nimmediately visible to other agents, which allows a group of imitating agents\nto quickly adapt their strategies when needed.\n"
    },
    {
        "paper_id": 1009.2743,
        "authors": "S.Cordier, L.Pareschi, C.Piatecki",
        "title": "Mesoscopic modelling of financial markets",
        "comments": null,
        "journal-ref": "Journal of Statistical Physics, 134, 1, (2009), 161-184",
        "doi": "10.1007/s10955-008-9667-z",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive a mesoscopic description of the behavior of a simple financial\nmarket where the agents can create their own portfolio between two investment\nalternatives: a stock and a bond. The model is derived starting from the\nLevy-Levy-Solomon microscopic model (Econ. Lett., 45, (1994), 103--111) using\nthe methods of kinetic theory and consists of a linear Boltzmann equation for\nthe wealth distribution of the agents coupled with an equation for the price of\nthe stock. From this model, under a suitable scaling, we derive a Fokker-Planck\nequation and show that the equation admits a self-similar lognormal behavior.\nSeveral numerical examples are also reported to validate our analysis.\n"
    },
    {
        "paper_id": 1009.2782,
        "authors": "Jin Feng, Jean-Pierre Fouque, Rohini Kumar",
        "title": "Small-time asymptotics for fast mean-reverting stochastic volatility\n  models",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP801 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 4, 1541-1575",
        "doi": "10.1214/11-AAP801",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study stochastic volatility models in regimes where the\nmaturity is small, but large compared to the mean-reversion time of the\nstochastic volatility factor. The problem falls in the class of\naveraging/homogenization problems for nonlinear HJB-type equations where the\n\"fast variable\" lives in a noncompact space. We develop a general argument\nbased on viscosity solutions which we apply to the two regimes studied in the\npaper. We derive a large deviation principle, and we deduce asymptotic prices\nfor out-of-the-money call and put options, and their corresponding implied\nvolatilities. The results of this paper generalize the ones obtained in Feng,\nForde and Fouque [SIAM J. Financial Math. 1 (2010) 126-141] by a moment\ngenerating function computation in the particular case of the Heston model.\n"
    },
    {
        "paper_id": 1009.2896,
        "authors": "Yaroslav Ivanenko",
        "title": "On the nature of financial leverage",
        "comments": "5 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The article presents a translation of some widespread financial terminology\ninto the language of decision theory. For instance, financial leverage can be\nregarded as an object of choice or a decision. We show how the optics of\ndecision theory allows perceiving the recently introduced metrics of\nsee-through-leverage, which proved to be very useful in understanding the\nphenomenology of the recent economic crisis. The importance for practical\ndecision making of specification of the statistical regularity of the random\nphenomena at hand as well as of the rationality class of the decision maker is\ndiscussed.\n"
    },
    {
        "paper_id": 1009.2928,
        "authors": "Jean-Philippe Bouchaud (CFM)",
        "title": "The endogenous dynamics of markets: price impact and feedback loops",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review the evidence that the erratic dynamics of markets is to a large\nextent of endogenous origin, i.e. determined by the trading activity itself and\nnot due to the rational processing of exogenous news. In order to understand\nwhy and how prices move, the joint fluctuations of order flow and liquidity -\nand the way these impact prices - become the key ingredients. Impact is\nnecessary for private information to be reflected in prices, but by the same\ntoken, random fluctuations in order flow necessarily contribute to the\nvolatility of markets. Our thesis is that the latter contribution is in fact\ndominant, resulting in a decoupling between prices and fundamental values, at\nleast on short to medium time scales. We argue that markets operate in a regime\nof vanishing revealed liquidity, but large latent liquidity, which would\nexplain their hyper-sensitivity to fluctuations. More precisely, we identify a\ndangerous feedback loop between bid-ask spread and volatility that may lead to\nmicro-liquidity crises and price jumps. We discuss several other unstable\nfeedback loops that should be relevant to account for market crises: imitation,\nunwarranted quantitative models, pro-cyclical regulation, etc.\n"
    },
    {
        "paper_id": 1009.2973,
        "authors": "Miao Xu, Charles Knessl",
        "title": "On a free boundary problem for an American put option under the CEV\n  process",
        "comments": "14 pages, 0 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an American put option under the CEV process. This corresponds to\na free boundary problem for a PDE. We show that this free bondary satisfies a\nnonlinear integral equation, and analyze it in the limit of small $\\rho$ = $2r/\n\\sigma^2$, where $r$ is the interest rate and $\\sigma$ is the volatility. We\nuse perturbation methods to find that the free boundary behaves differently for\nfive ranges of time to expiry.\n"
    },
    {
        "paper_id": 1009.3247,
        "authors": "Chao Zhu",
        "title": "Optimal control of risk process in a regime-switching environment",
        "comments": "Keywords: Regime switching diffusion, continuity of the value\n  function, exit time control, viscosity solution",
        "journal-ref": null,
        "doi": "10.1016/j.automatica.2011.03.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is concerned with cost optimization of an insurance company. The\nsurplus of the insurance company is modeled by a controlled regime switching\ndiffusion, where the regime switching mechanism provides the fluctuations of\nthe random environment. The goal is to find an optimal control that minimizes\nthe total cost up to a stochastic exit time. A weaker sufficient condition than\nthat of (Fleming and Soner 2006, Section V.2) for the continuity of the value\nfunction is obtained. Further, the value function is shown to be a viscosity\nsolution of a Hamilton-Jacobian-Bellman equation.\n"
    },
    {
        "paper_id": 1009.3361,
        "authors": "Chris Kenyon",
        "title": "Completing CVA and Liquidity: Firm-Level Positions and Collateralized\n  Trades",
        "comments": "19 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Bilateral CVA as currently implement has the counterintuitive effect of\nprofiting from one's own widening CDS spreads, i.e. increased risk of default,\nin practice. The unified picture of CVA and liquidity introduced by Morini &\nPrampolini 2010 has contributed to understanding this. However, there are two\nsignificant omissions for practical implementation that come from the same\nsource, i.e. positions not booked in usual position-keeping systems. The first\nomission is firm-level positions that change value upon firm default. An\nexample is Goodwill which is a line item on balance sheets and typically\nwritten down to zero on default. Another example would be firm Equity. The\nsecond omission relates to collateralized positions. When these positions are\nout of the money in future, which has a positive probability, they will require\nfunding that cannot be secured using the position itself. These contingent\nfuture funding positions are usually not booked in any position-keeping system.\nWe show here how to include these two types of positions and thus help to\ncomplete the unified picture of CVA and liquidity.\n  For a particular large complex financial institution that profited $2.5B from\nspread widening we show that including Goodwill would have resulted in a $4B\nloss under conservative assumptions. Whilst we cannot make a similar assessment\nfor its collateralized derivative portfolio we calculate both the funding costs\nand the CVA from own default for a range of swaps and find that CVA was a\npositive contribution in the examples.\n"
    },
    {
        "paper_id": 1009.3479,
        "authors": "Peter Ove Christensen and Kasper Larsen",
        "title": "Incomplete Continuous-time Securities Markets with Stochastic Income\n  Volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an incomplete continuous-time securities market with uncertainty generated\nby Brownian motions, we derive closed-form solutions for the equilibrium\ninterest rate and market price of risk processes. The economy has a finite\nnumber of heterogeneous exponential utility investors, who receive partially\nunspanned income and can trade continuously on a finite time-interval in a\nmoney market account and a single risky security. Besides establishing the\nexistence of an equilibrium, our main result shows that if the investors'\nunspanned income has stochastic countercyclical volatility, the resulting\nequilibrium can display both lower interest rates and higher risk premia\ncompared to the Pareto efficient equilibrium in an otherwise identical complete\nmarket.\n"
    },
    {
        "paper_id": 1009.355,
        "authors": "Ricardo Lopez-Ruiz",
        "title": "Exponential wealth distribution in different discrete economic models",
        "comments": "1 page; Communication presented in ECIT 2010, Nant (France), Setember\n  (2010)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Exponential distribution is ubiquitous in the framework of multi-agent\nsystems. An alternative approach with an economic motivation to derive the\nexponential distribution in the framework of iterations in the space of\ndistributions is disclosed.\n"
    },
    {
        "paper_id": 1009.3556,
        "authors": "Thomas J. Emmerling",
        "title": "Perpetual Cancellable American Call Option",
        "comments": "26 pages, 4 figures, Keywords: Game options, Israeli options,\n  American call option",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the valuation of a generalized American-style option\nknown as a Game-style call option in an infinite time horizon setting. The\nspecifications of this contract allow the writer to terminate the call option\nat any point in time for a fixed penalty amount paid directly to the holder.\nValuation of a perpetual Game-style put option was addressed by Kyprianou\n(2004) in a Black-Scholes setting on a non-dividend paying asset. Here, we\nundertake a similar analysis for the perpetual call option in the presence of\ndividends and find qualitatively different explicit representations for the\nvalue function depending on the relationship between the interest rate and\ndividend yield. Specifically, we find that the value function is not convex\nwhen $r>d$. Numerical results show the impact this phenomenon has upon the vega\nof the option.\n"
    },
    {
        "paper_id": 1009.3638,
        "authors": "Nikolaus Rab and Richard Warnung",
        "title": "Scaling portfolio volatility and calculating risk contributions in the\n  presence of serial cross-correlations",
        "comments": "26 pages, 3 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In practice daily volatility of portfolio returns is transformed to longer\nholding periods by multiplying by the square-root of time which assumes that\nreturns are not serially correlated. Under this assumption this procedure of\nscaling can also be applied to contributions to volatility of the assets in the\nportfolio. Close prices are often used to calculate the profit and loss of a\nportfolio. Trading at exchanges located in distant time zones this can lead to\nsignificant serial cross-correlations of the closing-time returns of the assets\nin the portfolio. These serial correlations cause the square-root-of-time rule\nto fail. Moreover volatility contributions in this setting turn out to be\nmisleading due to non-synchronous correlations. We address this issue and\nprovide alternative procedures for scaling volatility and calculating risk\ncontributions for arbitrary holding periods.\n"
    },
    {
        "paper_id": 1009.3753,
        "authors": "Yu Feng, Matus Medo, Liang Zhang, Yi-Cheng Zhang",
        "title": "Transaction fees and optimal rebalancing in the growth-optimal portfolio",
        "comments": "17 pages, 7 figures",
        "journal-ref": "Physica A 390, 1635-1645 (2011)",
        "doi": "10.1016/j.physa.2010.12.031",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The growth-optimal portfolio optimization strategy pioneered by Kelly is\nbased on constant portfolio rebalancing which makes it sensitive to transaction\nfees. We examine the effect of fees on an example of a risky asset with a\nbinary return distribution and show that the fees may give rise to an optimal\nperiod of portfolio rebalancing. The optimal period is found analytically in\nthe case of lognormal returns. This result is consequently generalized and\nnumerically verified for broad return distributions and returns generated by a\nGARCH process. Finally we study the case when investment is rebalanced only\npartially and show that this strategy can improve the investment long-term\ngrowth rate more than optimization of the rebalancing period.\n"
    },
    {
        "paper_id": 1009.376,
        "authors": "Damiano Brigo, Claudio Nordio",
        "title": "Liquidity-adjusted Market Risk Measures with Stochastic Holding Period",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Within the context of risk integration, we introduce in risk measurement\nstochastic holding period (SHP) models. This is done in order to obtain a\n`liquidity-adjusted risk measure' characterized by the absence of a fixed time\nhorizon. The underlying assumption is that - due to changes on market liquidity\nconditions - one operates along an `operational time' to which the P&L process\nof liquidating a market portfolio is referred. This framework leads to a\nmixture of distributions for the portfolio returns, potentially allowing for\nskewness, heavy tails and extreme scenarios. We analyze the impact of possible\ndistributional choices for the SHP. In a multivariate setting, we hint at the\npossible introduction of dependent SHP processes, which potentially lead to non\nlinear dependence among the P&L processes and therefore to tail dependence\nacross assets in the portfolio, although this may require drastic choices on\nthe SHP distributions. We also find that increasing dependence as measured by\nKendall's tau through common SHP's appears to be unfeasible. We finally discuss\npotential developments following future availability of market data.\n"
    },
    {
        "paper_id": 1009.381,
        "authors": "Dorje C. Brody and Yan Tai Law",
        "title": "Asset pricing with random information flow",
        "comments": "19 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the information-based approach to asset pricing the market filtration is\nmodelled explicitly as a superposition of signals concerning relevant market\nfactors and independent noise. The rate at which the signal is revealed to the\nmarket then determines the overall magnitude of asset volatility. By letting\nthis information flow rate random, we obtain an elementary stochastic\nvolatility model within the information-based approach. Such an extension is\neconomically justified on account of the fact that in real markets information\nflow rates are rarely measurable. Effects of having a random information flow\nrate is investigated in detail in the context of a simple model setup.\nSpecifically, the price process of the asset is derived, and its characteristic\nbehaviours are revealed via simulation studies. The price of a European-style\noption is worked out, showing that the model has a sufficient flexibility to\nfit volatility surface. As an extension of the random information flow model,\nprice manipulation is considered. A simple model is used to show how the\nskewness of the manipulated and unmanipulated price processes take opposite\nsignature.\n"
    },
    {
        "paper_id": 1009.4142,
        "authors": "Magda Schiegl",
        "title": "About the Justification of Experience Rating: Bonus Malus System and a\n  new Poisson Mixture Model",
        "comments": "ASTIN Colloquium, Manchester 2008",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The claim experience of the past is a very important information to calculate\nthe fair price of an insurance contract. In a lot of European countries for\ninstance the prices for motor car insurance depend on the number of claims the\ndriver has reported to the insurance company during the last years. Classically\nthese prices are calculated on the basis of a mixed Poisson model with a gamma\nmixing distribution. The mixing distribution models the car drivers' qualities\nacross the insured portfolio. This is just one example for experience rating.\nIn the classical context the price is equal to the expectation of the Bayesian\nposterior distribution.\n  In some lines of business (especially third party liability and lines with\nexposure to extreme weather events) we that the real world data cannot be\ndescribed well enough by the classical Poisson - gamma model. Therefore we\ninvestigate the influence of the mixing distribution on the posterior\ndistribution conditional on the experienced number of claims. This enables the\napplication of other - more risk adequate premium principles than the\nexpectation principle. We introduce the inverse - gamma distribution as a new\nmixing distribution to model claim numbers and compare it to the classical\ngamma distribution. In both cases a closed analytic representation of the mixed\ndistribution can be found: In the classic case the well known negative binomial\ndistribution, in our new one a representation using the Bessel functions.\nAdditionally we present numerical results about the tail behaviour of the mixed\nPoisson - inverse - gamma distribution. Finally we introduce the concept of\nresolution. It enables us to decide if the classification of risk groups via\nthe number of experienced claims is a risk adequate procedure.\n"
    },
    {
        "paper_id": 1009.4143,
        "authors": "Magda Schiegl",
        "title": "On the Savety Loading for Chain Ladder Estimates: A Monte Carlo\n  Simulation Study",
        "comments": null,
        "journal-ref": "ASTIN Bulletin, Vol. 32, No.1, 2002, pp. 107 - 128",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A method for analysing the risk of taking a too low reserve level by use of\nChain Ladder method is developed. We give an answer to the question of how much\nsafety loading in terms of the Chain Ladder standard error has to be added to\nthe Chain Ladder reserve in order to reach a specified security level in loss\nreserving. This is an important question in the framework of integrated risk\nmanagement of an insurance company. Furthermore we investigate the relative\nbias of Chain Ladder estimators. We use Monte Carlo simulation technique as\nwell as the collective model of risk theory in each cell of run-off table. We\nanalyse deviation between Chain Ladder reserves and Monte Carlo simulated\nreserves statistically. Our results document dependency on claim number and\nclaim size distribution types and parameters.\n"
    },
    {
        "paper_id": 1009.4146,
        "authors": "Magda Schiegl",
        "title": "A three dimensional stochastic Model for Claim Reserving",
        "comments": "ASTIN Colloquium, Helsinki 2009",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Within the Solvency II framework the insurance industry requires a realistic\nmodelling of the risk processes relevant for its business. Every insurance\ncompany should be capable of running a holistic risk management process to meet\nthis challenge. For property and casualty (P&C) insurance companies the risk\nadequate modelling of the claim reserves is a very important topic as this\nliabilities determine up to 70% percent of the balance sum. We propose a three\ndimensional (3D) stochastic model for claim reserving. It delivers consistently\nthe reserve's distribution function as well as the distributions of all parts\nof it that are needed for accounting and controlling. The calibration methods\nfor the model are well known from data analysis and they are applicable in an\npractitioner environment. We evaluate the model numerically by the help of\nMonte Carlo (MC) simulation. Classical actuarial reserve models are two\ndimensional (2D). They lead to an estimation algorithm that is applied on a 2D\nmatrix, the run off triangle. Those methods (for instance the Chain - Ladder or\nthe Bornhuetter - Ferguson method) are widely used in practice nowadays and\ngive rise to several problems: They estimate the reserves' expectation and some\nof them - under very restriction assumptions - the variance. They provide no\ninformation about the tail of the reserve's distribution, what would be most\nimportant for risk calculation, for assessing the insurance company's financial\nstability and economic situation. Additionally, due to the projection of the\nclaim process into a two dimensional space the results are very often distorted\nand dependent on the kind of projection. Therefore we extend the classical 2D\nmodels to a 3D space because we find inconsistencies generated by inadequate\nprojections into the 2D spaces.\n"
    },
    {
        "paper_id": 1009.4211,
        "authors": "J. E. Figueroa-L\\'opez, R. Gong, and C. Houdr\\'e",
        "title": "Small-time expansions of the distributions, densities, and option prices\n  of stochastic volatility models with L\\'evy jumps",
        "comments": "Final version to appear in Stochastic Processes and their\n  Applications",
        "journal-ref": null,
        "doi": "10.1016/j.spa.2012.01.013",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a stochastic volatility model with L\\'evy jumps for a log-return\nprocess $Z=(Z_{t})_{t\\geq 0}$ of the form $Z=U+X$, where $U=(U_{t})_{t\\geq 0}$\nis a classical stochastic volatility process and $X=(X_{t})_{t\\geq 0}$ is an\nindependent L\\'evy process with absolutely continuous L\\'evy measure $\\nu$.\nSmall-time expansions, of arbitrary polynomial order, in time-$t$, are obtained\nfor the tails $\\bbp(Z_{t}\\geq z)$, $z>0$, and for the call-option prices\n$\\bbe(e^{z+Z_{t}}-1)_{+}$, $z\\neq 0$, assuming smoothness conditions on the\n{\\PaleGrey density of $\\nu$} away from the origin and a small-time large\ndeviation principle on $U$. Our approach allows for a unified treatment of\ngeneral payoff functions of the form $\\phi(x){\\bf 1}_{x\\geq{}z}$ for smooth\nfunctions $\\phi$ and $z>0$. As a consequence of our tail expansions, the\npolynomial expansions in $t$ of the transition densities $f_{t}$ are also\n{\\Green obtained} under mild conditions.\n"
    },
    {
        "paper_id": 1009.4489,
        "authors": "Franco Ruzzenenti, Diego Garlaschelli, Riccardo Basosi",
        "title": "Complex Networks and Symmetry II: Reciprocity and Evolution of World\n  Trade",
        "comments": "Final accepted version",
        "journal-ref": "Symmetry 2, no. 3, pp. 1710-1744 (2010)",
        "doi": "10.3390/sym2031710",
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  We exploit the symmetry concepts developed in the companion review of this\narticle to introduce a stochastic version of link reversal symmetry, which\nleads to an improved understanding of the reciprocity of directed networks. We\napply our formalism to the international trade network and show that a strong\nembedding in economic space determines particular symmetries of the network,\nwhile the observed evolution of reciprocity is consistent with a symmetry\nbreaking taking place in production space. Our results show that networks can\nbe strongly affected by symmetry-breaking phenomena occurring in embedding\nspaces, and that stochastic network symmetries can successfully suggest, or\nrule out, possible underlying mechanisms.\n"
    },
    {
        "paper_id": 1009.4587,
        "authors": "Yu.A. Kuperin, P.A. Poloskov",
        "title": "Analytical and Numerical Approaches to Pricing the Path-Dependent\n  Options with Stochastic Volatility",
        "comments": "16 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper new analytical and numerical approaches to valuating\npath-dependent options of European type have been developed. The model of\nstochastic volatility as a basic model has been chosen. For European options we\ncould improve the path integral method, proposed B. Baaquie, and generalized it\nto the case of path-dependent options, where the payoff function depends on the\nhistory of changes in the underlying asset. The dependence of the implied\nvolatility on the parameters of the stochastic volatility model has been\nstudied. It is shown that with proper choice of model parameters one can\naccurately reproduce the actual behavior of implied volatility. As a\nconsequence, it can assess more accurately the value of options. It should be\nnoted that the methods developed here allow evaluating options with any payoff\nfunction.\n"
    },
    {
        "paper_id": 1009.4683,
        "authors": "Victor Boyarshinov and Malik Magdon-Ismail",
        "title": "Efficient Computation of Optimal Trading Strategies",
        "comments": "45 pages; working paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Given the return series for a set of instruments, a \\emph{trading strategy}\nis a switching function that transfers wealth from one instrument to another at\nspecified times. We present efficient algorithms for constructing (ex-post)\ntrading strategies that are optimal with respect to the total return, the\nSterling ratio and the Sharpe ratio. Such ex-post optimal strategies are useful\nanalysis tools. They can be used to analyze the \"profitability of a market\" in\nterms of optimal trading; to develop benchmarks against which real trading can\nbe compared; and, within an inductive framework, the optimal trades can be used\nto to teach learning systems (predictors) which are then used to identify\nfuture trading opportunities.\n"
    },
    {
        "paper_id": 1009.4785,
        "authors": "Romain Allez, Jean-Philippe Bouchaud",
        "title": "Individual and collective stock dynamics: intra-day seasonalities",
        "comments": "9 pages, 7 figures",
        "journal-ref": "New J. Phys. 13 025010 (2011)",
        "doi": "10.1088/1367-2630/13/2/025010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We establish several new stylised facts concerning the intra-day\nseasonalities of stock dynamics. Beyond the well known U-shaped pattern of the\nvolatility, we find that the average correlation between stocks increases\nthroughout the day, leading to a smaller relative dispersion between stocks.\nSomewhat paradoxically, the kurtosis (a measure of volatility surprises)\nreaches a minimum at the open of the market, when the volatility is at its\npeak. We confirm that the dispersion kurtosis is a markedly decreasing function\nof the index return. This means that during large market swings, the\nidiosyncratic component of the stock dynamics becomes sub-dominant. In a\nnutshell, early hours of trading are dominated by idiosyncratic or sector\nspecific effects with little surprises, whereas the influence of the market\nfactor increases throughout the day, and surprises become more frequent.\n"
    },
    {
        "paper_id": 1009.4818,
        "authors": "Christian Bayer, Peter Friz, Ronnie Loeffen",
        "title": "Semi-Closed Form Cubature and Applications to Financial Diffusion Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Cubature methods, a powerful alternative to Monte Carlo due to\nKusuoka~[Adv.~Math.~Econ.~6, 69--83, 2004] and\nLyons--Victoir~[Proc.~R.~Soc.\\\\Lond.~Ser.~A 460, 169--198, 2004], involve the\nsolution to numerous auxiliary ordinary differential equations. With focus on\nthe Ninomiya-Victoir algorithm~[Appl.~Math.~Fin.~15, 107--121, 2008], which\ncorresponds to a concrete level $5$ cubature method, we study some parametric\ndiffusion models motivated from financial applications, and exhibit structural\nconditions under which all involved ODEs can be solved explicitly and\nefficiently. We then enlarge the class of models for which this technique\napplies, by introducing a (model-dependent) variation of the Ninomiya-Victoir\nmethod. Our method remains easy to implement; numerical examples illustrate the\nsavings in computation time.\n"
    },
    {
        "paper_id": 1009.4835,
        "authors": "Vincenzo Liberatore",
        "title": "Financial LPPL Bubbles with Mean-Reverting Noise in the Frequency Domain",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The log-periodic power law (LPPL) is a model of asset prices during\nendogenous bubbles. A major open issue is to verify the presence of LPPL in\nprice sequences and to estimate the LPPL parameters. Estimation is complicated\nby the fact that daily LPPL returns are typically orders of magnitude smaller\nthan measured price returns, suggesting that noise obscures the underlying LPPL\ndynamics. However, if noise is mean-reverting, it would quickly cancel out over\nsubsequent measurements. In this paper, we attempt to reject mean-reverting\nnoise from price sequences by exploiting frequency-domain properties of LPPL\nand of mean reversion. First, we calculate the spectrum of mean-reverting \\ou\nnoise and devise estimators for the noise's parameters. Then, we derive the\nLPPL spectrum by breaking it down into its two main characteristics of power\nlaw and of log-periodicity. We compare price spectra with noise spectra during\nhistorical bubbles. In general, noise was strong also at low frequencies and,\neven if LPPL underlied price dynamics, LPPL would be obscured by noise.\n"
    },
    {
        "paper_id": 1009.4843,
        "authors": "Chao Zhang and Lu Huang",
        "title": "A quantum model for the stock market",
        "comments": "Final accepted version by Physica A. 13 pages and 3 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2010.09.008",
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  Beginning with several basic hypotheses of quantum mechanics, we give a new\nquantum model in econophysics. In this model, we define wave functions and\noperators of the stock market to establish the Schr\\\"odinger equation for the\nstock price. Based on this theoretical framework, an example of a driven\ninfinite quantum well is considered, in which we use a cosine distribution to\nsimulate the state of stock price in equilibrium. After adding an external\nfield into the Hamiltonian to analytically calculate the wave function, the\ndistribution and the average value of the rate of return are shown.\n"
    },
    {
        "paper_id": 1009.4884,
        "authors": "El Hadj Aly Dia (LAMA), Damien Lamberton (LAMA)",
        "title": "Connecting discrete and continuous lookback or hindsight options in\n  exponential L\\'evy models",
        "comments": "31 pp",
        "journal-ref": "Advances in Applied Probability 43, 4 (2011) 1136-1165",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by the pricing of lookback options in exponential L\\'evy models, we\nstudy the difference between the continuous and discrete supremum of L\\'evy\nprocesses. In particular, we extend the results of Broadie et al. (1999) to\njump-diffusion models. We also derive bounds for general exponential L\\'evy\nmodels.\n"
    },
    {
        "paper_id": 1009.4886,
        "authors": "El Hadj Aly Dia (LAMA)",
        "title": "Error bounds for small jumps of L\\'evy processes",
        "comments": "21 pp",
        "journal-ref": "Advances in Applied Probability (2013) 30",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The pricing of options in exponential Levy models amounts to the computation\nof expectations of functionals of Levy processes. In many situations,\nMonte-Carlo methods are used. However, the simulation of a Levy process with\ninfinite Levy measure generally requires either to truncate small jumps or to\nreplace them by a Brownian motion with the same variance. We will derive bounds\nfor the errors generated by these two types of approximation.\n"
    },
    {
        "paper_id": 1009.5075,
        "authors": "Gani Aldashev and Timoteo Carletti and Simone Righi",
        "title": "Adaptive Expectations, Confirmatory Bias, and Informational Efficiency",
        "comments": null,
        "journal-ref": "2011), Follies subdued: Informational Efficiency under Adaptive\n  Expectations and Confirmatory Bias, in Journal of Economic Behavior and\n  Organization, volume 80, Issue 1, pp. 110-121",
        "doi": "10.1016/j.jebo.2011.03.001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the informational efficiency of a market with a single traded asset.\nThe price initially differs from the fundamental value, about which the agents\nhave noisy private information (which is, on average, correct). A fraction of\ntraders revise their price expectations in each period. The price at which the\nasset is traded is public information. The agents' expectations have an\nadaptive component and a social-interactions component with confirmatory bias.\nWe show that, taken separately, each of the deviations from rationality worsen\nthe information efficiency of the market. However, when the two biases are\ncombined, the degree of informational inefficiency of the market (measured as\nthe deviation of the long-run market price from the fundamental value of the\nasset) can be non-monotonic both in the weight of the adaptive component and in\nthe degree of the confirmatory bias. For some ranges of parameters, two biases\ntend to mitigate each other's effect, thus increasing the informational\nefficiency.\n"
    },
    {
        "paper_id": 1009.5129,
        "authors": "Mikhail Martynov, Olga Rozanova",
        "title": "A certain estimate of volatility through return for stochastic\n  volatility models",
        "comments": "9 pages, 4 figures, submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the dependence of volatility on the stock price in the stochastic\nvolatility framework on the example of the Heston model. To be more specific,\nwe consider the conditional expectation of variance (square of volatility)\nunder fixed stock price return as a function of the return and time. The\nbehavior of this function depends on the initial stock price return\ndistribution density. In particular, we show that the graph of the conditional\nexpectation of variance is convex downwards near the mean value of the stock\nprice return. For the Gaussian distribution this effect is strong, but it\nweakens and becomes negligible as the decay of distribution at infinity slows\ndown.\n"
    },
    {
        "paper_id": 1009.5401,
        "authors": "Norbert Jobst and Dirk Tasche",
        "title": "Capital allocation for credit portfolios under normal and stressed\n  market conditions",
        "comments": "13 pages, minor updates",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  If the probability of default parameters (PDs) fed as input into a credit\nportfolio model are estimated as through-the-cycle (TTC) PDs stressed market\nconditions have little impact on the results of the capital calculations\nconducted with the model. At first glance, this is totally different if the PDs\nare estimated as point-in-time (PIT) PDs. However, it can be argued that the\nreflection of stressed market conditions in input PDs should correspond to the\nuse of reduced correlation parameters or even the removal of correlations in\nthe model. Additionally, the confidence levels applied for the capital\ncalculations might be made reflective of the changing market conditions. We\ninvestigate the interplay of PIT PDs, correlations, and confidence levels in a\ncredit portfolio model in more detail and analyse possible designs of\ncapital-levelling policies. Our findings may of interest to banks that want to\ncombine their approaches to capital measurement and allocation with active\nportfolio management that, by its nature, needs to be reflective of current\nmarket conditions.\n"
    },
    {
        "paper_id": 1009.5495,
        "authors": "Yu.A.Kuperin, P.A.Poloskov",
        "title": "American Options Pricing under Stochastic Volatility: Approximation of\n  the Early Exercise Surface and Monte Carlo Simulations",
        "comments": "10 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this study was to develop methods for evaluating the\nAmerican-style option prices when the volatility of the underlying asset is\ndescribed by a stochastic process. As part of this problem were developed\ntechniques for modeling the early exercise surface of the American option.\nThese methods of present work are compared to the complexity of modeling and\ncomputation speed. The paper presents the semi-analytic expression for the\nprice of American options with stochastic volatility. The results of numerical\ncomputations and their calibration are also presented. The obtained results\nwere compared with results excluding the effect of volatility smile.\n"
    },
    {
        "paper_id": 1009.5499,
        "authors": "D. Maldarella, L. Pareschi",
        "title": "Kinetic models for socio-economic dynamics of speculative markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce a simple model for a financial market\ncharacterized by a single stock or good and an interplay between two different\ntraders populations, chartists and fundamentalists, which determine the price\ndynamic of the stock. The model has been inspired by the microscopic\nLux-Marchesi model (T.Lux, M.Marchesi, Nature 397, (1999), 498--500). The\nintroduction of kinetic equations permits to study the asymptotic behavior of\nthe investments and the price distributions and to characterize the regimes of\nlognormal behavior and the formation of power law tails.\n"
    },
    {
        "paper_id": 1009.58,
        "authors": "Yiting Zhang, Gladys Hui Ting Lee, Jian Cheng Wong, Jun Liang Kok,\n  Manamohan Prusty, and Siew Ann Cheong",
        "title": "Will the US Economy Recover in 2010? A Minimal Spanning Tree Study",
        "comments": "elsarticle class, includes amsmath.sty, graphicx.sty and url.sty. 68\n  pages, 16 figures, 8 tables. Abridged version of the manuscript presented at\n  the Econophysics Colloquim 2010, incorporating reviewer comments",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.01.020",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We calculated the cross correlations between the half-hourly times series of\nthe ten Dow Jones US economic sectors over the period February 2000 to August\n2008, the two-year intervals 2002--2003, 2004--2005, 2008--2009, and also over\n11 segments within the present financial crisis, to construct minimal spanning\ntrees (MSTs) of the US economy at the sector level. In all MSTs, a core-fringe\nstructure is found, with consumer goods, consumer services, and the industrials\nconsistently making up the core, and basic materials, oil and gas, healthcare,\ntelecommunications, and utilities residing predominantly on the fringe. More\nimportantly, we find that the MSTs can be classified into two distinct,\nstatistically robust, topologies: (i) star-like, with the industrials at the\ncenter, associated with low-volatility economic growth; and (ii) chain-like,\nassociated with high-volatility economic crisis. Finally, we present\nstatistical evidence, based on the emergence of a star-like MST in Sep 2009,\nand the MST staying robustly star-like throughout the Greek Debt Crisis, that\nthe US economy is on track to a recovery.\n"
    },
    {
        "paper_id": 1009.5806,
        "authors": "Grzegorz Ha{\\l}aj",
        "title": "Density quantization method in the optimal portfolio choice with partial\n  observation of stochastic volatility",
        "comments": "33 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Computational aspects of the optimal consumption and investment with the\npartially observed stochastic volatility of the asset prices are considered.\nThe new quantization approach to filtering - density quantization - is\nintroduced which reduces the original infinite dimensional state space of the\nproblem to the finite quantization set. The density quantization is embedded\ninto the numerical algorithm to solve the dynamic programming equation related\nto the portfolio optimization.\n"
    },
    {
        "paper_id": 1009.583,
        "authors": "Jo\\~ao P. da Cruz and Pedro G. Lind",
        "title": "Self-organized criticality in a network of economic agents with finite\n  consumption",
        "comments": null,
        "journal-ref": "Physica A 391 1445-1452 (2012)",
        "doi": "10.1016/j.physa.2011.11.012",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a simple model for addressing the controversy in the study of\nfinancial systems, sometimes taken as brownian-like processes and other as\ncritical systems with fluctuations of arbitrary magnitude. The model considers\na collection of economical agents which establish trade connections among them\naccording to basic economical principles properly translated into physical\nproperties and interaction. With our model we are able to reproduce the\nevolution of macroscopic quantities (indices) and to correctly retrieve the\ncommon exponent value characterizing several indices in financial markets,\nrelating it to the underlying topology of connections.\n"
    },
    {
        "paper_id": 1009.5973,
        "authors": "Daniel Sevcovic",
        "title": "On a numerical approximation scheme for construction of the early\n  exercise boundary for a class of nonlinear Black-Scholes equations",
        "comments": null,
        "journal-ref": "In: A. Bartel, M. Brunk, M. Gunther, S. Schops and M. Striebel\n  (eds.) Proccedings of the 16th European Conference on Mathematics for\n  Industry, July 26-30, 2010, Wuppertal, Germany, Springer Verlag, Berlin,\n  Heidelberg, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this paper is to construct the early exercise boundary for a\nclass of nonlinear Black--Scholes equations with a nonlinear volatility\ndepending on the option price. We review a method how to transform the problem\ninto a solution of a time depending nonlinear parabolic equation defined on a\nfixed domain. Results of numerical computation of the early exercise boundary\nfor various nonlinear Black--Scholes equations are also presented.\n"
    },
    {
        "paper_id": 1009.6157,
        "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer, Thomas Guhr",
        "title": "Statistical causes for the Epps effect in microstructure noise",
        "comments": "8 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present two statistical causes for the distortion of correlations on\nhigh-frequency financial data. We demonstrate that the asynchrony of trades as\nwell as the decimalization of stock prices has a large impact on the decline of\nthe correlation coefficients towards smaller return intervals (Epps effect).\nThese distortions depend on the properties of the time series and are of purely\nstatistical origin. We are able to present parameter-free compensation methods,\nwhich we validate in a model setup. Furthermore, the compensation methods are\napplied to high-frequency empirical data from the NYSE's TAQ database. A major\nfraction of the Epps effect can be compensated. The contribution of the\npresented causes is particularly high for stocks that are traded at low prices.\n"
    },
    {
        "paper_id": 1010.0027,
        "authors": "Harbir Lamba",
        "title": "How sensitive are equilibrium pricing models to real-world distortions?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In both finance and economics, quantitative models are usually studied as\nisolated mathematical objects --- most often defined by very strong simplifying\nassumptions concerning rationality, efficiency and the existence of\ndisequilibrium adjustment mechanisms. This raises the important question of how\nsensitive such models might be to real-world effects that violate the\nassumptions. We show how the consequences of rational behavior caused by\nperverse incentives, as well as various irrational tendencies identified by\nbehavioral economists, can be systematically and consistently introduced into\nan agent-based model for a financial asset. This generates a class of models\nwhich, in the special case where such effects are absent, reduces to geometric\nBrownian motion --- the usual equilibrium pricing model. Thus we are able to\nnumerically perturb a widely-used equilibrium pricing model market and\ninvestigate its stability. The magnitude of such perturbations in real markets\ncan be estimated and the simulations imply that this is far outside the\nstability region of the equilibrium solution, which is no longer observed.\nIndeed the price fluctuations generated by endogenous dynamics, are in good\ngeneral agreement with the excess kurtosis and heteroskedasticity of actual\nasset prices. The methodology is presented within the context of a financial\nmarket. However, there are close links to concepts and theories from both\nmicro- and macro-economics including rational expectations, Soros' theory of\nreflexivity, and Minsky's theory of financial instability.\n"
    },
    {
        "paper_id": 1010.008,
        "authors": "Patrick Cheridito, Ying Hu (IRMAR)",
        "title": "Optimal consumption and investment in incomplete markets with general\n  constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study an optimal consumption and investment problem in a possibly\nincomplete market with general, not necessarily convex, stochastic constraints.\nWe give explicit solutions for investors with exponential, logarithmic and\npower utility. Our approach is based on martingale methods which rely on recent\nresults on the existence and uniqueness of solutions to BSDEs with drivers of\nquadratic growth.\n"
    },
    {
        "paper_id": 1010.009,
        "authors": "Pavel V. Shevchenko",
        "title": "Holder-extendible European option: corrections and extensions",
        "comments": null,
        "journal-ref": "The ANZIAM Journal 56 (2015) 359-372",
        "doi": "10.1017/S1446181115000097",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial contracts with options that allow the holder to extend the contract\nmaturity by paying an additional fixed amount found many applications in\nfinance. Closed-form solutions for the price of these options have appeared in\nthe literature for the case when the contract underlying asset follows a\ngeometric Brownian motion with the constant interest rate, volatility, and\nnon-negative \"dividend\" yield. In this paper, the option price is derived for\nthe case of the underlying asset that follows a geometric Brownian motion with\nthe time-dependent drift and volatility which is important to use the solutions\nin real life applications. The formulas are derived for the drift that may\ninclude non-negative or negative \"dividend\" yield. The latter case results in a\nnew solution type that has not been studied in the literature. Several\ntypographical errors in the formula for the holder-extendible put, typically\nrepeated in textbooks and software, are corrected.\n"
    },
    {
        "paper_id": 1010.0208,
        "authors": "Xavier Calbet, Jose-Luis Lopez and Ricardo Lopez-Ruiz",
        "title": "Equilibrium distributions and relaxation times in gas-like economic\n  models: an analytical derivation",
        "comments": "8 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.83.036108",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A step by step procedure to derive analytically the exact dynamical evolution\nequations of the probability density functions (PDF) of well known kinetic\nwealth exchange economic models is shown. This technique gives a dynamical\ninsight into the evolution of the PDF, e.g., allowing the calculation of its\nrelaxation times. Their equilibrium PDFs can also be calculated by finding its\nstationary solutions. This gives as a result an integro-differential equation,\nwhich can be solved analytically in some cases and numerically in others. This\nshould provide some guidance into the type of probability density functions\nthat can be derived from particular economic agent exchange rules, or for that\nmatter, any other kinetic model of gases with particular collision physics.\n"
    },
    {
        "paper_id": 1010.041,
        "authors": "Jiankui He and Michael W. Deem",
        "title": "Structure and Response in the World Trade Network",
        "comments": "4 pages, 4 figures, to appear in Phys. Rev. Lett",
        "journal-ref": null,
        "doi": "10.1103/PhysRevLett.105.198701",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We examine how the structure of the world trade network has been shaped by\nglobalization and recessions over the last 40 years. We show that by treating\nthe world trade network as an evolving system, theory predicts the trade\nnetwork is more sensitive to evolutionary shocks and recovers more slowly from\nthem now than it did 40 years ago, due to structural changes in the world trade\nnetwork induced by globalization. We also show that recession-induced change to\nthe world trade network leads to an \\emph{increased} hierarchical structure of\nthe global trade network for a few years after the recession.\n"
    },
    {
        "paper_id": 1010.0627,
        "authors": "Stefan Gerhold, Johannes Muhle-Karbe, Walter Schachermayer",
        "title": "Asymptotics and Duality for the Davis and Norman Problem",
        "comments": "17 pages; to appear in Stochastics (A Special Issue for Mark Davis'\n  Festschrift)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit the problem of maximizing expected logarithmic utility from\nconsumption over an infinite horizon in the Black-Scholes model with\nproportional transaction costs, as studied in the seminal paper of Davis and\nNorman [Math. Operation Research, 15, 1990]. Similarly to Kallsen and\nMuhle-Karbe [Ann. Appl. Probab., 20, 2010], we tackle this problem by\ndetermining a shadow price, that is, a frictionless price process with values\nin the bid-ask spread which leads to the same optimization problem. However, we\nuse a different parametrization, which facilitates computation and\nverification. Moreover, for small transaction costs, we determine fractional\nTaylor expansions of arbitrary order for the boundaries of the no-trade region\nand the value function. This extends work of Janecek and Shreve [Finance\nStoch., 8, 2004], who determined the leading terms of these power series.\n"
    },
    {
        "paper_id": 1010.0829,
        "authors": "Edward Hoyle",
        "title": "Information-based models for finance and insurance",
        "comments": "Imperial College London, PhD Thesis",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In financial markets, the information that traders have about an asset is\nreflected in its price. The arrival of new information then leads to price\nchanges. The `information-based framework' of Brody, Hughston and Macrina (BHM)\nisolates the emergence of information, and examines its role as a driver of\nprice dynamics. This approach has led to the development of new models that\ncapture a broad range of price behaviour. This thesis extends the work of BHM\nby introducing a wider class of processes for the generation of the market\nfiltration. In the BHM framework, each asset is associated with a collection of\nrandom cash flows. The asset price is the sum of the discounted expectations of\nthe cash flows. Expectations are taken with respect (i) an appropriate measure,\nand (ii) the filtration generated by a set of so-called information processes\nthat carry noisy or imperfect market information about the cash flows. To model\nthe flow of information, we introduce a class of processes termed L\\'evy random\nbridges (LRBs), generalising the Brownian and gamma information processes of\nBHM. Conditioned on its terminal value, an LRB is identical in law to a L\\'evy\nbridge. We consider in detail the case where the asset generates a single cash\nflow $X_T$ at a fixed date $T$. The flow of information about $X_T$ is modelled\nby an LRB with random terminal value $X_T$. An explicit expression for the\nprice process is found by working out the discounted conditional expectation of\n$X_T$ with respect to the natural filtration of the LRB. New models are\nconstructed using information processes related to the Poisson process, the\nCauchy process, the stable-1/2 subordinator, the variance-gamma process, and\nthe normal inverse-Gaussian process. These are applied to the valuation of\ncredit-risky bonds, vanilla and exotic options, and non-life insurance\nliabilities.\n"
    },
    {
        "paper_id": 1010.0854,
        "authors": "C. Anteneodo and S. M. Duarte Queiros",
        "title": "On low-sampling-rate Kramers-Moyal coefficients",
        "comments": "9 pages, 4 figures",
        "journal-ref": "Phys. Rev. E 82, 041122 (2010) [8 pages]",
        "doi": "10.1103/PhysRevE.82.041122",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the impact of the sampling interval on the estimation of\nKramers-Moyal coefficients. We obtain the finite-time expressions of these\ncoefficients for several standard processes. We also analyze extreme situations\nsuch as the independence and no-fluctuation limits that constitute useful\nreferences. Our results aim at aiding the proper extraction of information in\ndata-driven analysis.\n"
    },
    {
        "paper_id": 1010.1212,
        "authors": "Wolfgang Putschoegl",
        "title": "On Calibrating Stochastic Volatility Models with time-dependent\n  Parameters",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider stochastic volatility models using piecewise constant parameters.\nWe suggest a hybrid optimization algorithm for fitting the models to a\nvolatility surface and provide some numerical results. Finally, we provide an\noutlook on how to further improve the calibration procedure.\n"
    },
    {
        "paper_id": 1010.1372,
        "authors": "Bhojnarine R. Rambharat, Anthony E. Brockwell",
        "title": "Sequential Monte Carlo pricing of American-style options under\n  stochastic volatility models",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS286 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Statistics Vol. 4, No. 1, 222-265 (2010)",
        "doi": "10.1214/09-AOAS286",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new method to price American-style options on underlying\ninvestments governed by stochastic volatility (SV) models. The method does not\nrequire the volatility process to be observed. Instead, it exploits the fact\nthat the optimal decision functions in the corresponding dynamic programming\nproblem can be expressed as functions of conditional distributions of\nvolatility, given observed data. By constructing statistics summarizing\ninformation about these conditional distributions, one can obtain high quality\napproximate solutions. Although the required conditional distributions are in\ngeneral intractable, they can be arbitrarily precisely approximated using\nsequential Monte Carlo schemes. The drawback, as with many Monte Carlo schemes,\nis potentially heavy computational demand. We present two variants of the\nalgorithm, one closely related to the well-known least-squares Monte Carlo\nalgorithm of Longstaff and Schwartz [The Review of Financial Studies 14 (2001)\n113-147], and the other solving the same problem using a \"brute force\" gridding\napproach. We estimate an illustrative SV model using Markov chain Monte Carlo\n(MCMC) methods for three equities. We also demonstrate the use of our algorithm\nby estimating the posterior distribution of the market price of volatility risk\nfor each of the three equities.\n"
    },
    {
        "paper_id": 1010.1413,
        "authors": "Yong Tao",
        "title": "Competitive market for multiple firms and economic crisis",
        "comments": "17 pages; 3 figures",
        "journal-ref": "Phys. Rev. E 82, 036118 (2010)",
        "doi": "10.1103/PhysRevE.82.036118",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The origin of economic crises is a key problem for economics. We present a\nmodel of long-run competitive markets to show that the multiplicity of\nbehaviors in an economic system, over a long time scale, emerge as statistical\nregularities (perfectly competitive markets obey Bose-Einstein statistics and\npurely monopolistic-competitive markets obey Boltzmann statistics) and that how\ninteraction among firms influences the evolutionary of competitive markets. It\nhas been widely accepted that perfect competition is most efficient. Our study\nshows that the perfectly competitive system, as an extreme case of competitive\nmarkets, is most efficient but not stable, and gives rise to economic crises as\nsociety reaches full employment. In the economic crisis revealed by our model,\nmany firms condense (collapse) into the lowest supply level (zero supply,\nnamely bankruptcy status), in analogy to Bose-Einstein condensation. This\ncurious phenomenon arises because perfect competition (homogeneous\ncompetitions) equals symmetric (indistinguishable) investment direction, a fact\nabhorred by nature. Therefore, we urge the promotion of monopolistic\ncompetition (heterogeneous competitions) rather than perfect competition. To\nprovide early warning of economic crises, we introduce a resolving index of\ninvestment, which approaches zero in the run-up to an economic crisis. On the\nother hand, our model discloses, as a profound conclusion, that the\ntechnological level for a long-run social or economic system is proportional to\nthe freedom (disorder) of this system; in other words, technology equals the\nentropy of system. As an application of this new concept, we give a possible\nanswer to the Needham question: \"Why was it that despite the immense\nachievements of traditional China it had been in Europe and not in China that\nthe scientific and industrial revolutions occurred?\"\n"
    },
    {
        "paper_id": 1010.1617,
        "authors": "Agnieszka Janek, Tino Kluge, Rafal Weron, Uwe Wystup",
        "title": "FX Smile in the Heston Model",
        "comments": "Chapter prepared for the 2nd edition of Statistical Tools for Finance\n  and Insurance, P.Cizek, W.Haerdle, R.Weron (eds.), Springer-Verlag,\n  forthcoming in 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Heston model stands out from the class of stochastic volatility (SV)\nmodels mainly for two reasons. Firstly, the process for the volatility is\nnon-negative and mean-reverting, which is what we observe in the markets.\nSecondly, there exists a fast and easily implemented semi-analytical solution\nfor European options. In this article we adapt the original work of Heston\n(1993) to a foreign exchange (FX) setting. We discuss the computational aspects\nof using the semi-analytical formulas, performing Monte Carlo simulations,\nchecking the Feller condition, and option pricing with FFT. In an empirical\nstudy we show that the smile of vanilla options can be reproduced by suitably\ncalibrating three out of five model parameters.\n"
    },
    {
        "paper_id": 1010.1689,
        "authors": "Dongsheng Lu and Frank Juan",
        "title": "An Efficient, Distributable, Risk Neutral Framework for CVA Calculation",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The importance of counterparty credit risk to the derivative contracts was\ndemonstrated consistently throughout the financial crisis of 2008. Accurate\nvaluation of Credit value adjustment (CVA) is essential to reflect the economic\nvalues of these risks. In the present article, we reviewed several different\napproaches for calculating CVA, and compared the advantage and disadvantage for\neach method. We also introduced an more efficient and scalable computational\nframework for this calculation.\n"
    },
    {
        "paper_id": 1010.1961,
        "authors": "Constantinos Kardaras",
        "title": "A time before which insiders would not undertake risk",
        "comments": "12 pages - improved second version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A continuous-path semimartingale market model with wealth processes\ndiscounted by a riskless asset is considered. The numeraire portfolio is the\nunique strictly positive wealth process that, when used as a benchmark to\ndenominate all other wealth, makes all wealth processes local martingales. It\nis assumed that the numeraire portfolio exists and that its wealth increases to\ninfinity as time goes to infinity. Under this setting, an initial enlargement\nof the filtration is performed, by including the overall minimum of the\nnumeraire portfolio. It is established that all nonnegative wealth processes,\nwhen stopped at the time of the overall minimum of the numeraire portfolio,\nbecome local martingales in the enlarged filtration. This implies that\nrisk-averse insider traders would refrain from investing in the risky assets\nbefore that time. A partial converse to the previous result is also established\nin the case of complete markets, showing that the time of the overall minimum\nof the numeraire portfolio is in a certain sense unique in rendering\nundesirable the act of undertaking risky positions before it. The\naforementioned results shed light to the importance of the numeraire portfolio\nas an indicator of overall market performance.\n"
    },
    {
        "paper_id": 1010.1994,
        "authors": "F. Chami Figueira (1), N.J. Moura Jr (2) and Marcelo B. Ribeiro (1)\n  ((1) Federal University of Rio de Janeiro-UFRJ, (2) Brazilian Institute for\n  Geography ans Statistics-IBGE)",
        "title": "The Gompertz-Pareto Income Distribution",
        "comments": "13 pages, 5 figures, LaTeX. Accepted for publication in \"Physica A\"",
        "journal-ref": "Physica A 390 (2011) 689-698",
        "doi": "10.1016/j.physa.2010.10.014",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work analyzes the Gompertz-Pareto distribution (GPD) of personal income,\nformed by the combination of the Gompertz curve, representing the overwhelming\nmajority of the economically less favorable part of the population of a\ncountry, and the Pareto power law, which describes its tiny richest part.\nEquations for the Lorenz curve, Gini coefficient and the percentage share of\nthe Gompertzian part relative to the total income are all written in this\ndistribution. We show that only three parameters, determined by linear data\nfitting, are required for its complete characterization. Consistency checks are\ncarried out using income data of Brazil from 1981 to 2007 and they lead to the\nconclusion that the GPD is consistent and provides a coherent and simple\nanalytical tool to describe personal income distribution data.\n"
    },
    {
        "paper_id": 1010.2048,
        "authors": "Gabjin Oh, Cheoljun Eom, Fengzhong Wang, Woo-Sung Jung, H. Eugene\n  Stanley, Seunghwan Kim",
        "title": "Statistical Properties of Cross-Correlation in the Korean Stock Market",
        "comments": null,
        "journal-ref": "Eur. Phys. J. B 79, 55-60 (2011)",
        "doi": "10.1140/epjb/e2010-90492-x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the statistical properties of the correlation matrix between\nindividual stocks traded in the Korean stock market using the random matrix\ntheory (RMT) and observe how these affect the portfolio weights in the\nMarkowitz portfolio theory. We find that the distribution of the correlation\nmatrix is positively skewed and changes over time. We find that the eigenvalue\ndistribution of original correlation matrix deviates from the eigenvalues\npredicted by the RMT, and the largest eigenvalue is 52 times larger than the\nmaximum value among the eigenvalues predicted by the RMT. The $\\beta_{473}$\ncoefficient, which reflect the largest eigenvalue property, is 0.8, while one\nof the eigenvalues in the RMT is approximately zero. Notably, we show that the\nentropy function $E(\\sigma)$ with the portfolio risk $\\sigma$ for the original\nand filtered correlation matrices are consistent with a power-law function,\n$E(\\sigma) \\sim \\sigma^{-\\gamma}$, with the exponent $\\gamma \\sim 2.92$ and\nthose for Asian currency crisis decreases significantly.\n"
    },
    {
        "paper_id": 1010.2061,
        "authors": "R. Tsekov",
        "title": "Brownian markets",
        "comments": null,
        "journal-ref": "Chin. Phys. Lett. 30 (2013) 088901",
        "doi": "10.1088/0256-307X/30/8/088901",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial market dynamics is rigorously studied via the exact generalized\nLangevin equation. Assuming market Brownian self-similarity, the market return\nrate memory and autocorrelation functions are derived, which exhibit an\noscillatory-decaying behavior with a long-time tail, similar to empirical\nobservations. Individual stocks are also described via the generalized Langevin\nequation. They are classified by their relation to the market memory as heavy,\nneutral and light stocks, possessing different kinds of autocorrelation\nfunctions.\n"
    },
    {
        "paper_id": 1010.211,
        "authors": "Matheus R. Grasselli and Cesar G. Velez",
        "title": "Stock loans in incomplete markets",
        "comments": "13 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A stock loan is a contract whereby a stockholder uses shares as collateral to\nborrow money from a bank or financial institution. In Xia and Zhou (2007), this\ncontract is modeled as a perpetual American option with a time varying strike\nand analyzed in detail within a risk--neutral framework. In this paper, we\nextend the valuation of such loans to an incomplete market setting, which takes\ninto account the natural trading restrictions faced by the client. When the\nmaturity of the loan is infinite, we use a time--homogeneous utility\nmaximization problem to obtain an exact formula for the value of the loan fee\nto be charged by the bank. For loans of finite maturity, we characterize the\nfee using variational inequality techniques. In both cases we show analytically\nhow the fee varies with the model parameters and illustrate the results\nnumerically.\n"
    },
    {
        "paper_id": 1010.2184,
        "authors": "L. Spadafora, G. P. Berman, F. Borgonovi",
        "title": "Do your volatility smiles take care of extreme events?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the Black-Scholes context we consider the probability distribution\nfunction (PDF) of financial returns implied by volatility smile and we study\nthe relation between the decay of its tails and the fitting parameters of the\nsmile. We show that, considering a scaling law derived from data, it is\npossible to get a new fitting procedure of the volatility smile that considers\nalso the exponential decay of the real PDF of returns observed in the financial\nmarkets. Our study finds application in the Risk Management activities where\nthe tails characterization of financial returns PDF has a central role for the\nrisk estimation.\n"
    },
    {
        "paper_id": 1010.2576,
        "authors": "Nikolai Dokuchaev",
        "title": "On detecting the dependence of time series",
        "comments": null,
        "journal-ref": "Communications in Statistics - Theory and Methods. 2012, Volume\n  41, Issue 5. pp. 934-942",
        "doi": "10.1080/03610926.2010.530373",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This short note suggests a heuristic method for detecting the dependence of\nrandom time series that can be used in the case when this dependence is\nrelatively weak and such that the traditional methods are not effective. The\nmethod requires to compare some special functionals on the sample\ncharacteristic functions with the same functionals computed for the benchmark\ntime series with a known degree of correlation. Some experiments for financial\ntime series are presented.\n"
    },
    {
        "paper_id": 1010.2865,
        "authors": "Rudra P. Jena, Kyoung-Kuk Kim, and Hao Xing",
        "title": "Long-term and blow-up behaviors of exponential moments in\n  multi-dimensional affine diffusions",
        "comments": "36 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers multi-dimensional affine processes with continuous\nsample paths. By analyzing the Riccati system, which is associated with affine\nprocesses via the transform formula, we fully characterize the regions of\nexponents in which exponential moments of a given process do not explode at any\ntime or explode at a given time. In these two cases, we also compute the\nlong-term growth rate and the explosion rate for exponential moments. These\nresults provide a handle to study implied volatility asymptotics in models\nwhere returns of stock prices are described by affine processes whose\nexponential moments do not have an explicit formula.\n"
    },
    {
        "paper_id": 1010.2981,
        "authors": "Andrzej Jarosz",
        "title": "Hermitian and non-Hermitian covariance estimators for multivariate\n  Gaussian and non-Gaussian assets from random matrix theory",
        "comments": "56 pages, 86 figures, 348 equations, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The random matrix theory method of planar Gaussian diagrammatic expansion is\napplied to find the mean spectral density of the Hermitian equal-time and\nnon-Hermitian time-lagged cross-covariance estimators, firstly in the form of\nmaster equations for the most general multivariate Gaussian system, secondly\nfor seven particular toy models of the true covariance function. For the\nsimplest one of these models, the existing result is shown to be incorrect and\nthe right one is presented, moreover its generalizations are accomplished to\nthe exponentially-weighted moving average estimator as well as two non-Gaussian\ndistributions, Student t and free Levy. The paper revolves around applications\nto financial complex systems, and the results constitute a sensitive probe of\nthe true correlations present there.\n"
    },
    {
        "paper_id": 1010.3225,
        "authors": "R\\'emi Lemoy, Eric Bertin, Pablo Jensen",
        "title": "Socio-economic utility and chemical potential",
        "comments": "6 pages, 3 figures, final version",
        "journal-ref": "EPL 93, 38002 (2011)",
        "doi": "10.1209/0295-5075/93/38002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In statistical physics, the conservation of particle number results in the\nequalization of the chemical potential throughout a system at equilibrium. In\ncontrast, the homogeneity of utility in socio-economic models is usually\nthought to rely on the competition between individuals, leading to Nash\nequilibrium. We show that both views can be reconciled by introducing a notion\nof chemical potential in a wide class of socio-economic models, and by relating\nit in a direct way to the equilibrium value of the utility. This approach also\nallows the dependence of utility across the system to be determined when agents\ntake decisions in a probabilistic way. Numerical simulations of a urban\neconomic model also suggest that our result is valid beyond the initially\nconsidered class of solvable models.\n"
    },
    {
        "paper_id": 1010.3401,
        "authors": "Bikas K. Chakrabarti and Anirban Chakraborti",
        "title": "Fifteen Years of Econophysics Research",
        "comments": "6 pages. A special issue in Science and Culture (Kolkata, India),\n  Guest Eds. B.K. Chakrabarti and A. Chakraborti, Volume 76 (9-10) 2010",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Econophysics is a new research field, which makes an attempt to bring\neconomics in the fold of natural sciences or specifically attempts for a\n\"physics of economics\". The term Econophysics was formally born in Kolkata in\n1995. The entry on Econophysics in The New Palgrave Dictionary of Economics,\n2nd Ed., Vol 2, Macmillan, NY (2008), pp 729-732, begins with \"... the term\n'econophysics' was neologized in 1995 at the second Statphys- Kolkata\nconference in Kolkata (formerly Calcutta), India ...\". The Econophysics\nresearch therefore formally completes fifteen years of research by the end of\nthis year! The importance and proliferation of the interdisciplinary research\nof Econophysics is highlighted in the special issue of Science & Culture, which\npresents a collection of twenty nine papers (giving country wise perspectives,\nreviews of the recent developments and original research communications),\nwritten by more than forty renowned experts in physics, mathematics or\neconomics, from all over the world. We present here the list of contents and\nthe editorial. The manuscript files are available at\nhttp://fiquant.mas.ecp.fr/chakraboa for preview. This special issue will be\npublished online at http://www.scienceandculture-isna.org/journal.htm, at the\nend of October 2010.\n"
    },
    {
        "paper_id": 1010.382,
        "authors": "Peng Zhang",
        "title": "Morse Potential, Contour Integrals, and Asian Options",
        "comments": "13 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Completeness of the eigenfunctions of a quantum mechanical system is crucial\nfor its probability interpretation. By using the method of contour integral we\ngive properly normalized eigenfunctions for both discrete and continuum\nspectrum of the Morse potential, and explicitly prove the completeness\nrelation. As an application we use our spectral decomposition formula to study\nthe problem of the pricing of an Asian option traded in financial markets.\n"
    },
    {
        "paper_id": 1010.4053,
        "authors": "Harry Zheng",
        "title": "A la Carte of Correlation Models: Which One to Choose?",
        "comments": "12 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a copula contagion mixture model for correlated\ndefault times. The model includes the well known factor, copula, and contagion\nmodels as its special cases. The key advantage of such a model is that we can\nstudy the interaction of different models and their pricing impact.\nSpecifically, we model the marginal default times to follow some contagion\nintensity processes coupled with copula dependence structure. We apply the\ntotal hazard construction method to generate ordered default times and\nnumerically compare the pricing impact of different models on basket CDSs and\nCDOs in the presence of exponential decay and counterparty risk.\n"
    },
    {
        "paper_id": 1010.4055,
        "authors": "Nicholas Westray and Harry Zheng",
        "title": "Constrained NonSmooth Utility Maximization on the Positive Real Line",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We maximize the expected utility of terminal wealth in an incomplete market\nwhere there are cone constraints on the investor's portfolio process and the\nutility function is not assumed to be strictly concave or differentiable. We\nestablish the existence of the optimal solutions to the primal and dual\nproblems and their dual relationship. We simplify the present proofs in this\narea and extend the existing duality theory to the constrained nonsmooth\nsetting.\n"
    },
    {
        "paper_id": 1010.4226,
        "authors": "Khalil al Dayri, Emmanuel Bacry, Jean-Francois Muzy",
        "title": "The nature of price returns during periods of high market activity",
        "comments": "17 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By studying all the trades and best bids/asks of ultra high frequency\nsnapshots recorded from the order books of a basket of 10 futures assets, we\nbring qualitative empirical evidence that the impact of a single trade depends\non the intertrade time lags. We find that when the trading rate becomes faster,\nthe return variance per trade or the impact, as measured by the price variation\nin the direction of the trade, strongly increases. We provide evidence that\nthese properties persist at coarser time scales. We also show that the spread\nvalue is an increasing function of the activity. This suggests that order books\nare more likely empty when the trading rate is high.\n"
    },
    {
        "paper_id": 1010.4322,
        "authors": "Erhan Bayraktar, Ross Kravitz",
        "title": "On the Stability of Utility Maximization Problems",
        "comments": "Keywords: Utility maximization, incomplete markets, stability, convex\n  analysis for functions from $L^0$ to $L^0$, convex compactness, continuous\n  semimartingales",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we extend the stability results of [4]}. Our utility\nmaximization problem is defined as an essential supremum of conditional\nexpectations of the terminal values of wealth processes, conditioned on the\nfiltration at the stopping time $\\tau$. To establish our results, we extend the\nclassical results of convex analysis to maps from $L^0$ to $L^0$. The notion of\nconvex compactness introduced in [7] plays an important role in our analysis.\n"
    },
    {
        "paper_id": 1010.4339,
        "authors": "Tomasz R. Bielecki and Igor Cialenco and Zhao Zhang",
        "title": "Dynamic Coherent Acceptability Indices and their Applications to Finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present a theoretical framework for studying coherent\nacceptability indices in a dynamic setup. We study dynamic coherent\nacceptability indices and dynamic coherent risk measures, and we establish a\nduality between them. We derive a representation theorem for dynamic coherent\nrisk measures in terms of so called dynamically consistent sequence of sets of\nprobability measures. Based on these results, we give a specific construction\nof dynamic coherent acceptability indices. We also provide examples of dynamic\ncoherent acceptability indices, both abstract and also some that generalize\nselected classical financial measures of portfolio performance.\n"
    },
    {
        "paper_id": 1010.4384,
        "authors": "Damir Filipovi\\'c, Lane P. Hughston, Andrea Macrina",
        "title": "Conditional Density Models for Asset Pricing",
        "comments": "To appear in International Journal of Theoretical and Applied\n  Finance, Volume 15, Number 1 (2012), Special Issue on Financial Derivatives\n  and Risk Management",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We model the dynamics of asset prices and associated derivatives by\nconsideration of the dynamics of the conditional probability density process\nfor the value of an asset at some specified time in the future. In the case\nwhere the price process is driven by Brownian motion, an associated \"master\nequation\" for the dynamics of the conditional probability density is derived\nand expressed in integral form. By a \"model\" for the conditional density\nprocess we mean a solution to the master equation along with the specification\nof (a) the initial density, and (b) the volatility structure of the density.\nThe volatility structure is assumed at any time and for each value of the\nargument of the density to be a functional of the history of the density up to\nthat time. In practice one specifies the functional modulo sufficient\nparametric freedom to allow for the input of additional option data apart from\nthat implicit in the initial density. The scheme is sufficiently flexible to\nallow for the input of various types of data depending on the nature of the\noptions market and the class of valuation problem being undertaken. Various\nexamples are studied in detail, with exact solutions provided in some cases.\n"
    },
    {
        "paper_id": 1010.4406,
        "authors": "Gareth W. Peters, Aaron D. Byrnes and Pavel V. Shevchenko",
        "title": "Impact of Insurance for Operational Risk: Is it worthwhile to insure or\n  be insured for severe losses?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Under the Basel II standards, the Operational Risk (OpRisk) advanced\nmeasurement approach allows a provision for reduction of capital as a result of\ninsurance mitigation of up to 20%. This paper studies the behaviour of\ndifferent insurance policies in the context of capital reduction for a range of\npossible extreme loss models and insurance policy scenarios in a multi-period,\nmultiple risk settings. A Loss Distributional Approach (LDA) for modelling of\nthe annual loss process, involving homogeneous compound Poisson processes for\nthe annual losses, with heavy tailed severity models comprised of alpha-stable\nseverities is considered. There has been little analysis of such models to date\nand it is believed, insurance models will play more of a role in OpRisk\nmitigation and capital reduction in future. The first question of interest is\nwhen would it be equitable for a bank or financial institution to purchase\ninsurance for heavy tailed OpRisk losses under different insurance policy\nscenarios? The second question then pertains to Solvency II and addresses what\nthe insurers capital would be for such operational risk scenarios under\ndifferent policy offerings. In addition we consider the insurers perspective\nwith respect to fair premium as a percentage above the expected annual claim\nfor each insurance policy. The intention being to address questions related to\nVaR reduction under Basel II, SCR under Solvency II and fair insurance premiums\nin OpRisk for different extreme loss scenarios. In the process we provide\nclosed form solutions for the distribution of loss process and claims process\nin an LDA structure as well as closed form analytic solutions for the Expected\nShortfall, SCR and MCR under Basel II and Solvency II. We also provide closed\nform analytic solutions for the annual loss distribution of multiple risks\nincluding insurance mitigation.\n"
    },
    {
        "paper_id": 1010.4831,
        "authors": "B. Dupoyet and H.R. Fiebig and D.P. Musgrove",
        "title": "Replicating financial market dynamics with a simple self-organized\n  critical lattice model",
        "comments": "20 pages, 33 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.04.017",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We explore a simple lattice field model intended to describe statistical\nproperties of high frequency financial markets. The model is relevant in the\ncross-disciplinary area of econophysics. Its signature feature is the emergence\nof a self-organized critical state. This implies scale invariance of the model,\nwithout tuning parameters. Prominent results of our simulation are time series\nof gains, prices, volatility, and gains frequency distributions, which all\ncompare favorably to features of historical market data. Applying a standard\nGARCH(1,1) fit to the lattice model gives results that are almost\nindistinguishable from historical NASDAQ data.\n"
    },
    {
        "paper_id": 1010.4917,
        "authors": "Lisa Borland and Yoan Hassid",
        "title": "Market panic on different time-scales",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Cross-sectional signatures of market panic were recently discussed on daily\ntime scales in [1], extended here to a study of cross-sectional properties of\nstocks on intra-day time scales. We confirm specific intra-day patterns of\ndispersion and kurtosis, and find that the correlation across stocks increases\nin times of panic yielding a bimodal distribution for the sum of signs of\nreturns. We also find that there is memory in correlations, decaying as a power\nlaw with exponent 0.05. During the Flash-Crash of May 6 2010, we find a drastic\nincrease in dispersion in conjunction with increased correlations. However, the\nkurtosis decreases only slightly in contrast to findings on daily time-scales\nwhere kurtosis drops drastically in times of panic. Our study indicates that\nthis difference in behavior is result of the origin of the panic-inducing\nvolatility shock: the more correlated across stocks the shock is, the more the\nkurtosis will decrease; the more idiosyncratic the shock, the lesser this\neffect and kurtosis is positively correlated with dispersion. We also find that\nthere is a leverage effect for correlations: negative returns tend to precede\nan increase in correlations. A stock price feed-back model with skew in\nconjunction with a correlation dynamics that follows market volatility explains\nour observations nicely.\n"
    },
    {
        "paper_id": 1010.4987,
        "authors": "Daniel Fernholz, Ioannis Karatzas",
        "title": "On optimal arbitrage",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP642 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 4, 1179-1204",
        "doi": "10.1214/09-AAP642",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a Markovian model for a financial market, we characterize the best\narbitrage with respect to the market portfolio that can be achieved using\nnonanticipative investment strategies, in terms of the smallest positive\nsolution to a parabolic partial differential inequality; this is determined\nentirely on the basis of the covariance structure of the model. The solution is\nintimately related to properties of strict local martingales and is used to\ngenerate the investment strategy which realizes the best possible arbitrage.\nSome extensions to non-Markovian situations are also presented.\n"
    },
    {
        "paper_id": 1010.4988,
        "authors": "Pablo Azcue, Nora Muler",
        "title": "Optimal investment policy and dividend payment strategy in an insurance\n  company",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP643 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 4, 1253-1302",
        "doi": "10.1214/09-AAP643",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider in this paper the optimal dividend problem for an insurance\ncompany whose uncontrolled reserve process evolves as a classical\nCram\\'{e}r--Lundberg process. The firm has the option of investing part of the\nsurplus in a Black--Scholes financial market. The objective is to find a\nstrategy consisting of both investment and dividend payment policies which\nmaximizes the cumulative expected discounted dividend pay-outs until the time\nof bankruptcy. We show that the optimal value function is the smallest\nviscosity solution of the associated second-order integro-differential\nHamilton--Jacobi--Bellman equation. We study the regularity of the optimal\nvalue function. We show that the optimal dividend payment strategy has a band\nstructure. We find a method to construct a candidate solution and obtain a\nverification result to check optimality. Finally, we give an example where the\noptimal dividend strategy is not barrier and the optimal value function is not\ntwice continuously differentiable.\n"
    },
    {
        "paper_id": 1010.4989,
        "authors": "J. Kallsen, J. Muhle-Karbe",
        "title": "On using shadow prices in portfolio optimization with transaction costs",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP648 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 4, 1341-1358",
        "doi": "10.1214/09-AAP648",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In frictionless markets, utility maximization problems are typically solved\neither by stochastic control or by martingale methods. Beginning with the\nseminal paper of Davis and Norman [Math. Oper. Res. 15 (1990) 676--713],\nstochastic control theory has also been used to solve various problems of this\ntype in the presence of proportional transaction costs. Martingale methods, on\nthe other hand, have so far only been used to derive general structural\nresults. These apply the duality theory for frictionless markets typically to a\nfictitious shadow price process lying within the bid-ask bounds of the real\nprice process. In this paper, we show that this dual approach can actually be\nused for both deriving a candidate solution and verification in Merton's\nproblem with logarithmic utility and proportional transaction costs. In\nparticular, we determine the shadow price process.\n"
    },
    {
        "paper_id": 1010.499,
        "authors": "Jean Jacod, Viktor Todorov",
        "title": "Do price and volatility jump together?",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP654 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 4, 1425-1469",
        "doi": "10.1214/09-AAP654",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a process $X_t$, which is observed on a finite time interval\n$[0,T]$, at discrete times $0,\\Delta_n,2\\Delta_n,\\ldots.$ This process is an\nIt\\^{o} semimartingale with stochastic volatility $\\sigma_t^2$. Assuming that\n$X$ has jumps on $[0,T]$, we derive tests to decide whether the volatility\nprocess has jumps occurring simultaneously with the jumps of $X_t$. There are\ntwo different families of tests for the two possible null hypotheses (common\njumps or disjoint jumps). They have a prescribed asymptotic level as the mesh\n$\\Delta_n$ goes to $0$. We show on some simulations that these tests perform\nreasonably well even in the finite sample case, and we also put them in use on\nS&P 500 index data.\n"
    },
    {
        "paper_id": 1010.5136,
        "authors": "Frederic Abergel, Aymen Jedidi",
        "title": "A Mathematical Approach to Order Book Modeling",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by the desire to bridge the gap between the microscopic description\nof price formation (agent-based modeling) and the stochastic differential\nequations approach used classically to describe price evolution at macroscopic\ntime scales, we present a mathematical study of the order book as a\nmultidimensional continuous-time Markov chain and derive several mathematical\nresults in the case of independent Poissonian arrival times. In particular, we\nshow that the cancellation structure is an important factor ensuring the\nexistence of a stationary distribution and the exponential convergence towards\nit. We also prove, by means of the functional central limit theorem (FCLT),\nthat the rescaled-centered price process converges to a Brownian motion. We\nillustrate the analysis with numerical simulation and comparison against market\ndata.\n"
    },
    {
        "paper_id": 1010.5154,
        "authors": "Yong Tao",
        "title": "How to predict and avert economic crisis",
        "comments": "4 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our study shows that many firms would accumulate at zero output level\n(namely, Bankruptcy status) if a perfectly competitive market reaches full\nemployment (namely, those people who should obtain employment have obtained\nemployment). As a result, appearance of economic crisis is determined by two\npoints; that is, (a). Stock market approaches perfect competition; (b). Society\nreaches full employment. The empirical research of these two points would lead\nto early warning of economic crisis. Moreover, it is a surprise that the state\nof economic crisis would be a feasible equilibrium within the framework of the\nArrow-Debreu model. That means that we can not understand the origin of\neconomic crisis within the framework of modern economics, for example, the\ngeneral equilibrium theory.\n"
    },
    {
        "paper_id": 1010.5171,
        "authors": "Georg Mainik and Ludger R\\\"uschendorf",
        "title": "Ordering of multivariate probability distributions with respect to\n  extreme portfolio losses",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new notion of stochastic ordering is introduced to compare multivariate\nstochastic risk models with respect to extreme portfolio losses. In the\nframework of multivariate regular variation comparison criteria are derived in\nterms of ordering conditions on the spectral measures, which allows for\nanalytical or numerical verification in practical applications. Additional\ncomparison criteria in terms of further stochastic orderings are derived. The\napplication examples include worst case and best case scenarios, elliptically\ncontoured distributions, and multivariate regularly varying models with Gumbel,\nArchimedean, and Galambos copulas.\n"
    },
    {
        "paper_id": 1010.5203,
        "authors": "Matthew Lorig",
        "title": "Time-Changed Fast Mean-Reverting Stochastic Volatility Models",
        "comments": null,
        "journal-ref": "International Journal of Theoretical and Applied Finance Vol. 14,\n  No. 8 (2011) 1355-1383",
        "doi": "10.1142/S0219024911006875",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a class of randomly time-changed fast mean-reverting stochastic\nvolatility models and, using spectral theory and singular perturbation\ntechniques, we derive an approximation for the prices of European options in\nthis setting. Three examples of random time-changes are provided and the\nimplied volatility surfaces induced by these time-changes are examined as a\nfunction of the model parameters. Three key features of our framework are that\nwe are able to incorporate jumps into the price process of the underlying\nasset, allow for the leverage effect, and accommodate multiple factors of\nvolatility, which operate on different time-scales.\n"
    },
    {
        "paper_id": 1010.5648,
        "authors": "Natalia Destefano and Alexandre Souto Martinez",
        "title": "The additive property of the inconsistency degree in intertemporal\n  decision making through the generalization of psychophysical laws",
        "comments": "23 pages and 1 table",
        "journal-ref": "Physica A 390 (2011) 1763--1772",
        "doi": "10.1016/j.physa.2011.01.016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Intertemporal decision making involves choices among options whose effects\noccur at different moments. These choices are influenced not only by the effect\nof rewards value perception at different moments, but also by the time\nperception effect. One of the main difficulties that affect standard\nexperiments involving intertemporal choices is the simultaneity of both effects\non time discounting. In this paper, we unify the psycophysical laws and\ndiscount value functions using the one-parameter exponential and logaritmic\nfunctions from nonextensive statistical mechanics. Also, we propose to measure\nthe degree of inconsistency. This quantity allow us to discriminate both\neffects of time and value perception on discounting process and, by\nintegration, obtain other main quantities like impulsivity and discount\nfunctions.\n"
    },
    {
        "paper_id": 1010.5653,
        "authors": "Mustafa Keskin, Bayram Deviren and Yusuf Kocakaplan",
        "title": "Topology of the correlation networks among major currencies using\n  hierarchical structure methods",
        "comments": "10 Pages,7 figures,1 table",
        "journal-ref": "Physica A, in publication, 2010",
        "doi": "10.1016/j.physa.2010.10.041",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We studied the topology of correlation networks among 34 major currencies\nusing the concept of a minimal spanning tree and hierarchical tree for the full\nyears of 2007-2008 when major economic turbulence occurred. We used the USD (US\nDollar) and the TL (Turkish Lira) as numeraires in which the USD was the major\ncurrency and the TL was the minor currency. We derived a hierarchical\norganization and constructed minimal spanning trees (MSTs) and hierarchical\ntrees (HTs) for the full years of 2007, 2008 and for the 2007-2008 periods. We\nperformed a technique to associate a value of reliability to the links of MSTs\nand HTs by using bootstrap replicas of data. We also used the average linkage\ncluster analysis for obtaining the hierarchical trees in the case of the TL as\nthe numeraire. These trees are useful tools for understanding and detecting the\nglobal structure, taxonomy and hierarchy in financial data. We illustrated how\nthe minimal spanning trees and their related hierarchical trees developed over\na period of time. From these trees we identified different clusters of\ncurrencies according to their proximity and economic ties. The clustered\nstructure of the currencies and the key currency in each cluster were obtained\nand we found that the clusters matched nicely with the geographical regions of\ncorresponding countries in the world such as Asia or Europe. As expected the\nkey currencies were generally those showing major economic activity.\n"
    },
    {
        "paper_id": 1010.5808,
        "authors": "Michal Barski, Jerzy Zabczyk",
        "title": "Heath-Jarrow-Morton-Musiela equation with linear volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper is concerned with the problem of existence of solutions for the\nHeath-Jarrow-Morton equation with linear volatility. Necessary conditions and\nsufficient conditions for the existence of weak solutions and strong solutions\nare provided. It is shown that the key role is played by the logarithmic growth\nconditions of the Laplace exponent.\n"
    },
    {
        "paper_id": 1010.581,
        "authors": "Micha{\\l} Barski",
        "title": "Quantile hedging for basket derivatives",
        "comments": "30 pages",
        "journal-ref": "Applicationes Mathematicae, 2012, 39,1, 103-127",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of quantile hedging for basket derivatives in the Black-Scholes\nmodel with correlation is considered. Explicit formulas for the probability\nmaximizing function and the cost reduction function are derived. Applicability\nof the results for the widely traded derivatives as digital, quantos,\noutperformance and spread options is shown.\n"
    },
    {
        "paper_id": 1010.6026,
        "authors": "Delphine Lautier and Franck Raynaud",
        "title": "Statistical properties of derivatives: a journey in term structures",
        "comments": "8 pages, 8 figures, 2 tables",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.01.018",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article presents an empirical study of thirteen derivative markets for\ncommodity and financial assets. It compares the statistical properties of\nfutures contracts's daily returns at different maturities, from 1998 to 2010\nand for delivery dates up to 120 months. The analysis of the fourth first\nmoments of the distribution shows that the mean and variance of the commodities\nfollow a scaling behavior in the maturity dimension. The comparison of the\ntails of the probability distribution according to the expiration dates also\nshows that there is a segmentation in the fat tails exponent term structure\nabove the L'evy stable region. Finally, the test of the robustness of the\ninverse cubic law in the maturity dimension shows that there are two regimes of\nextreme events for derivative markets, reminding of a phase diagram with a\ntransition value at the 18th delivery month.\n"
    },
    {
        "paper_id": 1010.605,
        "authors": "Anca Gheorghiu, Anda Gheorghiu",
        "title": "Entering New Markets-a Challenge in Times of Crisis",
        "comments": "10 pages, 3 tables, 5 figures",
        "journal-ref": "Proceedings of the 3rd World Congress on the Advancement of\n  Scholarly Research in Science, Economics, Law and Culture, New York, Addleton\n  Academic Publishers, S.U.A. (pag.41-53) ISBN 978-1-935494-04-1, 2009, 25-29\n  august",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  After September 2008, the advanced economies severe decline caused demand for\nemerging economies' exports to drop and the crisis became truly global, much\ndeeper and broader than expected. In these times of global depression, most\ncountries and companies are affected, some more than others. The financial\ncrisis has turned out to be much deeper and broader than expected. Entering new\nmarkets has always been a hazardous entrepreneurial attempt, but also a\nrewarding one, in the case of success. The paper aims to asses the market entry\nrisk of a company trying to make a good acquisition, to buy shares of another\ncompany, activating in a foreign country. For this purpose, the case of\nElectroputere S.A., the old Romanian producer of railway equipment, has been\nchosen. The data were collected from the records of Bucharest Stock Exchange.\nAfter two years from the acquisition, one can draw a conclusion whether the\nstrategy of the investor was a good one or a waste of money.\n"
    },
    {
        "paper_id": 1011.0248,
        "authors": "Ting Wang and Virginia R. Young",
        "title": "Hedging Pure Endowments with Mortality Derivatives",
        "comments": "33 Pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In recent years, a market for mortality derivatives began developing as a way\nto handle systematic mortality risk, which is inherent in life insurance and\nannuity contracts. Systematic mortality risk is due to the uncertain\ndevelopment of future mortality intensities, or {\\it hazard rates}. In this\npaper, we develop a theory for pricing pure endowments when hedging with a\nmortality forward is allowed. The hazard rate associated with the pure\nendowment and the reference hazard rate for the mortality forward are\ncorrelated and are modeled by diffusion processes. We price the pure endowment\nby assuming that the issuing company hedges its contract with the mortality\nforward and requires compensation for the unhedgeable part of the mortality\nrisk in the form of a pre-specified instantaneous Sharpe ratio. The major\nresult of this paper is that the value per contract solves a linear partial\ndifferential equation as the number of contracts approaches infinity. One can\nrepresent the limiting price as an expectation under an equivalent martingale\nmeasure. Another important result is that hedging with the mortality forward\nmay raise or lower the price of this pure endowment comparing to its price\nwithout hedging, as determined in Bayraktar et al. [2009]. The market price of\nthe reference mortality risk and the correlation between the two portfolios\njointly determine the cost of hedging. We demonstrate our results using\nnumerical examples.\n"
    },
    {
        "paper_id": 1011.0423,
        "authors": "Robert Viragh",
        "title": "A note comprising a negative resolution of the Efficient Market\n  Hypothesis",
        "comments": "2 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This note comprises a negative resolution of the Efficient Market Hypothesis.\n"
    },
    {
        "paper_id": 1011.0458,
        "authors": "Wanfeng Yan, Ryan Woodard, Didier Sornette",
        "title": "Leverage Bubble",
        "comments": "14pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Leverage is strongly related to liquidity in a market and lack of liquidity\nis considered a cause and/or consequence of the recent financial crisis. A\nrepurchase agreement is a financial instrument where a security is sold\nsimultaneously with an agreement to buy it back at a later date. Repurchase\nagreements (repos) market size is a very important element in calculating the\noverall leverage in a financial market. Therefore, studying the behavior of\nrepos market size can help to understand a process that can contribute to the\nbirth of a financial crisis. We hypothesize that herding behavior among large\ninvestors led to massive over-leveraging through the use of repos, resulting in\na bubble (built up over the previous years) and subsequent crash in this market\nin early 2008. We use the Johansen-Ledoit-Sornette (JLS) model of rational\nexpectation bubbles and behavioral finance to study the dynamics of the repo\nmarket that led to the crash. The JLS model qualifies a bubble by the presence\nof characteristic patterns in the price dynamics, called log-periodic power law\n(LPPL) behavior. We show that there was significant LPPL behavior in the market\nbefore that crash and that the predicted range of times predicted by the model\nfor the end of the bubble is consistent with the observations.\n"
    },
    {
        "paper_id": 1011.0748,
        "authors": "Takero Ibuki, Jun-ichi Inoue",
        "title": "Response of double-auction markets to instantaneous Selling-Buying\n  signals with stochastic Bid-Ask spread",
        "comments": "27 pages, 66 figures, using svjour3.cls",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Statistical properties of order-driven double-auction markets with Bid-Ask\nspread are investigated through the dynamical quantities such as response\nfunction. We first attempt to utilize the so-called {\\it\nMadhavan-Richardson-Roomans model} (MRR for short) to simulate the stochastic\nprocess of the price-change in empirical data sets (say, EUR/JPY or USD/JPY\nexchange rates) in which the Bid-Ask spread fluctuates in time. We find that\nthe MRR theory apparently fails to simulate so much as the qualitative\nbehaviour ('non-monotonic' behaviour) of the response function $R(l)$ ($l$\ndenotes the difference of times at which the response function is evaluated)\ncalculated from the data. Especially, we confirm that the stochastic nature of\nthe Bid-Ask spread causes apparent deviations from a linear relationship\nbetween the $R(l)$ and the auto-correlation function $C(l)$, namely, $R(l)\n\\propto -C(l)$. To make the microscopic model of double-auction markets having\nstochastic Bid-Ask spread, we use the minority game with a finite market\nhistory length and find numerically that appropriate extension of the game\nshows quite similar behaviour of the response function to the empirical\nevidence. We also reveal that the minority game modeling with the adaptive\n('annealed') look-up table reproduces the non-linear relationship $R(l) \\propto\n-f(C(l))$ ($f(x)$ stands for a non-linear function leading to\n'$\\lambda$-shapes') more effectively than the fixed (`quenched') look-up table\ndoes.\n"
    },
    {
        "paper_id": 1011.0828,
        "authors": "Nicola Moreni and Andrea Pallavicini",
        "title": "Parsimonious HJM Modelling for Multiple Yield-Curve Dynamics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a long time interest-rate models were built on a single yield curve used\nboth for discounting and forwarding. However, the crisis that has affected\nfinancial markets in the last years led market players to revise this\nassumption and accommodate basis-swap spreads, whose remarkable widening can no\nlonger be neglected. In recent literature we find many proposals of multi-curve\ninterest-rate models, whose calibration would typically require market quotes\nfor all yield curves. At present this is not possible since most of the quotes\nare missing or extremely illiquid. Thanks to a suitable extension of the HJM\nframework, we propose a parsimonious model based on observed rates that deduces\nyield-curve dynamics from a single family of Markov processes. Furthermore, we\ndetail a specification of the model reporting numerical examples of calibration\nto quoted market data.\n"
    },
    {
        "paper_id": 1011.1011,
        "authors": "Iacopo Mastromatteo, Matteo Marsili and Patrick Zoi",
        "title": "Financial correlations at ultra-high frequency: theoretical models and\n  empirical estimation",
        "comments": "22 pages, 8 figures, 1 table, version to appear in EPJ B",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2011-10865-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A detailed analysis of correlation between stock returns at high frequency is\ncompared with simple models of random walks. We focus in particular on the\ndependence of correlations on time scales - the so-called Epps effect. This\nprovides a characterization of stochastic models of stock price returns which\nis appropriate at very high frequency.\n"
    },
    {
        "paper_id": 1011.1175,
        "authors": "L.Z.J.Liang, D.Lemmens and J. Tempere",
        "title": "Generalized pricing formulas for stochastic volatility jump diffusion\n  models applied to the exponential Vasicek model",
        "comments": "9 pages, 2 figures, 1 table",
        "journal-ref": "Eur. Phys. J. B 75, 335-342 (2010)",
        "doi": "10.1140/epjb/e2010-00109-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Path integral techniques for the pricing of financial options are mostly\nbased on models that can be recast in terms of a Fokker-Planck differential\nequation and that, consequently, neglect jumps and only describe drift and\ndiffusion. We present a method to adapt formulas for both the path-integral\npropagators and the option prices themselves, so that jump processes are taken\ninto account in conjunction with the usual drift and diffusion terms. In\nparticular, we focus on stochastic volatility models, such as the exponential\nVasicek model, and extend the pricing formulas and propagator of this model to\nincorporate jump diffusion with a given jump size distribution. This model is\nof importance to include non-Gaussian fluctuations beyond the Black-Scholes\nmodel, and moreover yields a lognormal distribution of the volatilities, in\nagreement with results from superstatistical analysis. The results obtained in\nthe present formalism are checked with Monte Carlo simulations.\n"
    },
    {
        "paper_id": 1011.1234,
        "authors": "Dmitry Lesnik",
        "title": "Storage option an Analytic approach",
        "comments": "Conference Energy Finance / INREC 2010, Oct. 2010, Essen, Germany. 47\n  pages Marcus Evans Conference: 3rd Annual Quantitative Analysis of\n  Commodities, 24th - 25th May 2012, London",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The mathematical problem of the static storage optimisation is formulated and\nsolved by means of a variational analysis. The solution obtained in implicit\nform is shedding light on the most important features of the optimal exercise\nstrategy. We show how the solution depends on different constraint types\nincluding carry cost and cycling constraint. We investigate the relation\nbetween intrinsic and stochastic solutions. In particular we give another proof\nthat the stochastic problem has a \"bang-bang\" optimal exercise strategy. We\nalso show why the optimal stochastic exercise decision is always close to the\nintrinsic one. In the second half we develop a perturbation analysis to solve\nthe stochastic optimisation problem. The obtained approximate solution allows\nus to estimate the time value of the storage option. In particular we find an\nanswer to rather academic question of asymptotic time value for the mean\nreversion parameter approaching zero or infinity. We also investigate the\ndifferences between swing and storage problems. The analytical results are\ncompared with numerical valuations and found to be in a good agreement.\n"
    },
    {
        "paper_id": 1011.1329,
        "authors": "Serguei Pergamenchtchikov (LMRS), Zeitouny Omar (LMRS)",
        "title": "Ruin probability in the presence of risky investments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an insurance company in the case when the premium rate is a\nbounded non-negative random function $c_\\zs{t}$ and the capital of the\ninsurance company is invested in a risky asset whose price follows a geometric\nBrownian motion with mean return $a$ and volatility $\\sigma>0$. If\n$\\beta:=2a/\\sigma^2-1>0$ we find exact the asymptotic upper and lower bounds\nfor the ruin probability $\\Psi(u)$ as the initial endowment $u$ tends to\ninfinity, i.e. we show that $C_*u^{-\\beta}\\le\\Psi(u)\\le C^*u^{-\\beta}$ for\nsufficiently large $u$. Moreover if $c_\\zs{t}=c^*e^{\\gamma t}$ with $\\gamma\\le\n0$ we find the exact asymptotics of the ruin probability, namely $\\Psi(u)\\sim\nu^{-\\beta}$. If $\\beta\\le 0$, we show that $\\Psi(u)=1$ for any $u\\ge 0$.\n"
    },
    {
        "paper_id": 1011.1475,
        "authors": "Hassan Allouba and Ramiro Fontes",
        "title": "Applications of the quadratic covariation differentiation theory:\n  variants of the Clark-Ocone and Stroock's formulas",
        "comments": "25 pages, 3 appendices. See expanded abstract. This article gives one\n  of several types of applications of the theory in my 2006 article (whose\n  preprint version is arXiv:1005.4357). Minor typos fixed. To Appear in\n  Stochastic Analysis and Applications",
        "journal-ref": "Stochastic Analysis and Applications, 29 (2011), no. 6, 1111-1135",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a 2006 article (\\cite{A1}), Allouba gave his quadratic covariation\ndifferentiation theory for It\\^o's integral calculus. He defined the derivative\nof a semimartingale with respect to a Brownian motion as the time derivative of\ntheir quadratic covariation and a generalization thereof. He then obtained a\nsystematic differentiation theory containing a fundamental theorem of\nstochastic calculus relating this derivative to It\\^o's integral, a\ndifferential stochastic chain rule, a differential stochastic mean value\ntheorem, and other differentiation rules. Here, we use this differentiation\ntheory to obtain variants of the Clark-Ocone and Stroock formulas, with and\nwithout change of measure. We prove our variants of the Clark-Ocone formula\nunder $L^{2}$-type conditions; with no Malliavin calculus, without the use of\nweak distributional or Radon-Nikodym type derivatives, and without the\nsignificant machinery of the Hida-Malliavin calculus. Unlike Malliavin or\nHida-Malliavin calculi, the form of our variant of the Clark-Ocone formula\nunder change of measure is as simple as it is under no change of measure, and\nwithout requiring any further differentiability conditions on the Girsanov\ntransform integrand beyond Novikov's condition. This is due to the invariance\nunder change of measure of the first author's derivative in \\cite{A1}. The\nformulations and proofs are natural applications of the differentiation theory\nin \\cite{A1} and standard It\\^o integral calculus. Iterating our Clark-Ocone\nformula, we obtain variants of Stroock's formula. We illustrate the\napplicability of these formulas by easily, and without Hida-Malliavin methods,\nobtaining the representation of the Brownian indicator\n$F=\\mathbb{I}_{[K,\\infty)}(W_{T})$, which is not standard Malliavin\ndifferentiable, and by applying them to digital options in finance. We then\nidentify the chaos expansion of the Brownian indicator.\n"
    },
    {
        "paper_id": 1011.1796,
        "authors": "Fabio Sigrist and Werner A. Stahel",
        "title": "Using The Censored Gamma Distribution for Modeling Fractional Response\n  Variables with an Application to Loss Given Default",
        "comments": null,
        "journal-ref": null,
        "doi": "10.2143/AST.41.2.2136992",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Regression models for limited continuous dependent variables having a\nnon-negligible probability of attaining exactly their limits are presented. The\nmodels differ in the number of parameters and in their flexibility. Fractional\ndata being a special case of limited dependent data, the models also apply to\nvariables that are a fraction or a proportion. It is shown how to fit these\nmodels and they are applied to a Loss Given Default dataset from insurance to\nwhich they provide a good fit.\n"
    },
    {
        "paper_id": 1011.2385,
        "authors": "Stanislaw Drozdz, Jaroslaw Kwapien, Pawel Oswiecimka, Rafal Rak",
        "title": "The foreign exchange market: return distributions, multifractality,\n  anomalous multifractality and Epps effect",
        "comments": null,
        "journal-ref": "New J. Phys. 12, 105003 (2010)",
        "doi": "10.1088/1367-2630/12/10/105003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a systematic study of various statistical characteristics of\nhigh-frequency returns from the foreign exchange market. This study is based on\nsix exchange rates forming two triangles: EUR-GBP-USD and GBP-CHF-JPY. It is\nshown that the exchange rate return fluctuations for all the pairs considered\nare well described by the nonextensive statistics in terms of q-Gaussians.\nThere exist some small quantitative variations in the nonextensivity\nq-parameter values for different exchange rates and this can be related to the\nimportance of a given exchange rate in the world's currency trade. Temporal\ncorrelations organize the series of returns such that they develop the\nmultifractal characteristics for all the exchange rates with a varying degree\nof symmetry of the singularity spectrum f(alpha) however. The most symmetric\nspectrum is identified for the GBP/USD. We also form time series of triangular\nresidual returns and find that the distributions of their fluctuations develop\ndisproportionately heavier tails as compared to small fluctuations which\nexcludes description in terms of q-Gaussians. The multifractal characteristics\nfor these residual returns reveal such anomalous properties like negative\nsingularity exponents and even negative singularity spectra. Such anomalous\nmultifractal measures have so far been considered in the literature in\nconnection with the diffusion limited aggregation and with turbulence. We find\nthat market inefficiency on short time scales leads to the occurrence of the\nEpps effect on much longer time scales. Although the currency market is much\nmore liquid than the stock markets and it has much larger transaction\nfrequency, the building-up of correlations takes up to several hours - time\nthat does not differ much from what is observed in the stock markets. This may\nsuggest that non-synchronicity of transactions is not the unique source of the\nobserved effect.\n"
    },
    {
        "paper_id": 1011.2651,
        "authors": "Philipp Doersek, Josef Teichmann",
        "title": "A Semigroup Point Of View On Splitting Schemes For Stochastic (Partial)\n  Differential Equations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct normed spaces of real-valued functions with controlled growth on\npossibly infinite-dimensional state spaces such that semigroups of positive,\nbounded operators $(P_t)_{t\\ge 0}$ thereon with $\\lim_{t\\to 0+}P_t f(x)=f(x)$\nare in fact strongly continuous. This result applies to prove optimal rates of\nconvergence of splitting schemes for stochastic (partial) differential\nequations with linearly growing characteristics and for sets of functions with\ncontrolled growth. Applications are general Da Prato-Zabczyk type equations and\nthe HJM equations from interest rate theory.\n"
    },
    {
        "paper_id": 1011.267,
        "authors": "Boris Podobnik, Davor Horvatic, Alexander M. Petersen, Branko\n  Uro\\v{s}evi\\'c, H. Eugene Stanley",
        "title": "Bankruptcy risk model and empirical tests",
        "comments": "8 pages, 8 figures",
        "journal-ref": "PNAS October 26, 2010 vol. 107 no. 43 18325-18330",
        "doi": "10.1073/pnas.1011942107",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the size dependence and temporal stability of firm bankruptcy risk\nin the US economy by applying Zipf scaling techniques. We focus on a single\nrisk factor-the debt-to-asset ratio R-in order to study the stability of the\nZipf distribution of R over time. We find that the Zipf exponent increases\nduring market crashes, implying that firms go bankrupt with larger values of R.\nBased on the Zipf analysis, we employ Bayes's theorem and relate the\nconditional probability that a bankrupt firm has a ratio R with the conditional\nprobability of bankruptcy for a firm with a given R value. For 2,737 bankrupt\nfirms, we demonstrate size dependence in assets change during the bankruptcy\nproceedings. Prepetition firm assets and petition firm assets follow Zipf\ndistributions but with different exponents, meaning that firms with smaller\nassets adjust their assets more than firms with larger assets during the\nbankruptcy process. We compare bankrupt firms with nonbankrupt firms by\nanalyzing the assets and liabilities of two large subsets of the US economy:\n2,545 Nasdaq members and 1,680 New York Stock Exchange (NYSE) members. We find\nthat both assets and liabilities follow a Pareto distribution. The finding is\nnot a trivial consequence of the Zipf scaling relationship of firm size\nquantified by employees-although the market capitalization of Nasdaq stocks\nfollows a Pareto distribution, the same distribution does not describe NYSE\nstocks. We propose a coupled Simon model that simultaneously evolves both\nassets and debt with the possibility of bankruptcy, and we also consider the\npossibility of firm mergers.\n"
    },
    {
        "paper_id": 1011.2674,
        "authors": "Boris Podobnik, Davor Horvatic, Alexander M. Petersen, H. Eugene\n  Stanley",
        "title": "Cross-correlations between volume change and price change",
        "comments": "7 pages, 5 figures",
        "journal-ref": "PNAS December 29, 2009 vol. 106 no. 52 22079-22084",
        "doi": "10.1073/pnas.0911983106",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In finance, one usually deals not with prices but with growth rates $R$,\ndefined as the difference in logarithm between two consecutive prices. Here we\nconsider not the trading volume, but rather the volume growth rate $\\tilde R$,\nthe difference in logarithm between two consecutive values of trading volume.\nTo this end, we use several methods to analyze the properties of volume changes\n$|\\tilde R|$, and their relationship to price changes $|R|$. We analyze\n$14,981$ daily recordings of the S\\&P 500 index over the 59-year period\n1950--2009, and find power-law {\\it cross-correlations\\/} between $|R|$ and\n$|\\tilde R|$ using detrended cross-correlation analysis (DCCA). We introduce a\njoint stochastic process that models these cross-correlations. Motivated by the\nrelationship between $| R|$ and $|\\tilde R|$, we estimate the tail exponent\n${\\tilde\\alpha}$ of the probability density function $P(|\\tilde R|) \\sim\n|\\tilde R|^{-1 -\\tilde\\alpha}$ for both the S\\&P 500 index as well as the\ncollection of 1819 constituents of the New York Stock Exchange Composite index\non 17 July 2009. As a new method to estimate $\\tilde\\alpha$, we calculate the\ntime intervals $\\tau_q$ between events where $\\tilde R>q$. We demonstrate that\n$\\bar\\tau_q$, the average of $\\tau_q$, obeys $\\bar \\tau_q \\sim\nq^{\\tilde\\alpha}$. We find $\\tilde \\alpha \\approx 3$. Furthermore, by\naggregating all $\\tau_q$ values of 28 global financial indices, we also observe\nan approximate inverse cubic law.\n"
    },
    {
        "paper_id": 1011.2827,
        "authors": "Xiaolin Luo and Pavel V. Shevchenko",
        "title": "Markov chain Monte Carlo estimation of default and recovery: dependent\n  via the latent systematic factor",
        "comments": "39 pages including 5 tables and 7 figures",
        "journal-ref": "Journal of Credit Risk 9(3), pp. 41-76, 2013",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is a well known fact that recovery rates tend to go down when the number\nof defaults goes up in economic downturns. We demonstrate how the loss given\ndefault model with the default and recovery dependent via the latent systematic\nrisk factor can be estimated using Bayesian inference methodology and Markov\nchain Monte Carlo method. This approach is very convenient for joint estimation\nof all model parameters and latent systematic factors. Moreover, all relevant\nuncertainties are easily quantified. Typically available data are annual\naverages of defaults and recoveries and thus the datasets are small and\nparameter uncertainty is significant. In this case Bayesian approach is\nsuperior to the maximum likelihood method that relies on a large sample limit\nGaussian approximation for the parameter uncertainty. As an example, we\nconsider a homogeneous portfolio with one latent factor. However, the approach\ncan be easily extended to deal with non-homogenous portfolios and several\nlatent factors.\n"
    },
    {
        "paper_id": 1011.2882,
        "authors": "Ryan Woodard, Didier Sornette, Maxim Fedorovsky",
        "title": "The Financial Bubble Experiment: Advanced Diagnostics and Forecasts of\n  Bubble Terminations, Volume III",
        "comments": "27 assets and final analysis posted; see complete report at\n  http://www.er.ethz.ch/fco/index",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This is the third installment of the Financial Bubble Experiment. Here we\nprovide the digital fingerprint of an electronic document in which we identify\n27 bubbles in 27 different global assets; for 25 of these assets, we present\nwindows of dates of the most likely ending time of each bubble. We will provide\nthat document of the original analysis on 2 May 2011.\n"
    },
    {
        "paper_id": 1011.2958,
        "authors": "Marcel Nutz, H. Mete Soner",
        "title": "Superhedging and Dynamic Risk Measures under Volatility Uncertainty",
        "comments": "31 pages; forthcoming in 'SIAM Journal on Control and Optimization'",
        "journal-ref": "SIAM Journal of Control and Optimization, 50/4, 2065--2089, (2012)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider dynamic sublinear expectations (i.e., time-consistent coherent\nrisk measures) whose scenario sets consist of singular measures corresponding\nto a general form of volatility uncertainty. We derive a c\\`adl\\`ag nonlinear\nmartingale which is also the value process of a superhedging problem. The\nsuperhedging strategy is obtained from a representation similar to the optional\ndecomposition. Furthermore, we prove an optional sampling theorem for the\nnonlinear martingale and characterize it as the solution of a second order\nbackward SDE. The uniqueness of dynamic extensions of static sublinear\nexpectations is also studied.\n"
    },
    {
        "paper_id": 1011.3225,
        "authors": "Daniel J. Fenn, Mason A. Porter, Stacy Williams, Mark McDonald, Neil\n  F. Johnson, and Nick S. Jones",
        "title": "Temporal Evolution of Financial Market Correlations",
        "comments": "15 pages, 10 figures, 1 table. Accepted for publication in Phys. Rev.\n  E. v2 includes additional sections",
        "journal-ref": "Physical Review E, Vol. 84, No. 2: 026109 (2011)",
        "doi": "10.1103/PhysRevE.84.026109",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate financial market correlations using random matrix theory and\nprincipal component analysis. We use random matrix theory to demonstrate that\ncorrelation matrices of asset price changes contain structure that is\nincompatible with uncorrelated random price changes. We then identify the\nprincipal components of these correlation matrices and demonstrate that a small\nnumber of components accounts for a large proportion of the variability of the\nmarkets that we consider. We then characterize the time-evolving relationships\nbetween the different assets by investigating the correlations between the\nasset price time series and principal components. Using this approach, we\nuncover notable changes that occurred in financial markets and identify the\nassets that were significantly affected by these changes. We show in particular\nthat there was an increase in the strength of the relationships between several\ndifferent markets following the 2007--2008 credit and liquidity crisis.\n"
    },
    {
        "paper_id": 1011.3246,
        "authors": "Matti Koivu and Teemu Pennanen",
        "title": "Reduced form models of bond portfolios",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive simple return models for several classes of bond portfolios. With\nonly one or two risk factors our models are able to explain most of the return\nvariations in portfolios of fixed rate government bonds, inflation linked\ngovernment bonds and investment grade corporate bonds. The underlying risk\nfactors have natural interpretations which make the models well suited for risk\nmanagement and portfolio design.\n"
    },
    {
        "paper_id": 1011.3247,
        "authors": "Chantal Labb\\'e, Bruno R\\'emillard and Jean-Fran\\c{c}ois Renaud",
        "title": "A simple discretization scheme for nonnegative diffusion processes, with\n  applications to option pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A discretization scheme for nonnegative diffusion processes is proposed and\nthe convergence of the corresponding sequence of approximate processes is\nproved using the martingale problem framework. Motivations for this scheme come\ntypically from finance, especially for path-dependent option pricing. The\nscheme is simple: one only needs to find a nonnegative distribution whose mean\nand variance satisfy a simple condition to apply it. Then, for virtually any\n(path-dependent) payoff, Monte Carlo option prices obtained from this scheme\nwill converge to the theoretical price. Examples of models and diffusion\nprocesses for which the scheme applies are provided.\n"
    },
    {
        "paper_id": 1011.3355,
        "authors": "Damiano Brigo, Massimo Morini",
        "title": "Dangers of Bilateral Counterparty Risk: the fundamental impact of\n  closeout conventions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the practical consequences of the bilateral counterparty risk\nadjustment. We point out that past literature assumes that, at the moment of\nthe first default, a risk-free closeout amount will be used. We argue that the\nlegal (ISDA) documentation suggests in many points that a substitution closeout\nshould be used. This would take into account the risk of default of the\nsurvived party. We show how the bilateral counterparty risk adjustment changes\nstrongly when a substitution closeout amount is considered. We model the two\nextreme cases of default independence and co-monotonicity, which highlight pros\nand cons of both risk free and substitution closeout formulations, and allow us\nto interpret the outcomes as dramatic consequences on default contagion.\nFinally, we analyze the situation when collateral is present.\n"
    },
    {
        "paper_id": 1011.3599,
        "authors": "Marie Bernhart, Peter Tankov and Xavier Warin",
        "title": "A finite dimensional approximation for pricing moving average options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a method for pricing American options whose pay-off depends on the\nmoving average of the underlying asset price. The method uses a finite\ndimensional approximation of the infinite-dimensional dynamics of the moving\naverage process based on a truncated Laguerre series expansion. The resulting\nproblem is a finite-dimensional optimal stopping problem, which we propose to\nsolve with a least squares Monte Carlo approach. We analyze the theoretical\nconvergence rate of our method and present numerical results in the\nBlack-Scholes framework.\n"
    },
    {
        "paper_id": 1011.3685,
        "authors": "Yuhong Xu",
        "title": "Multidimensional dynamic risk measure via conditional g-expectation",
        "comments": "37 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with multidimensional dynamic risk measures induced by\nconditional $g$-expectations. A notion of multidimensional $g$-expectation is\nproposed to provide a multidimensional version of nonlinear expectations. By a\ntechnical result on explicit expressions for the comparison theorem, uniqueness\ntheorem and viability on a rectangle of solutions to multidimensional backward\nstochastic differential equations, some necessary and sufficient conditions are\ngiven for the constancy, monotonicity, positivity, homogeneity and\ntranslatability properties of multidimensional conditional $g$-expectations and\nmultidimensional dynamic risk measures; we prove that a multidimensional\ndynamic $g$-risk measure is nonincreasingly convex if and only if the generator\n$g$ satisfies a quasi-monotone increasingly convex condition. A general dual\nrepresentation is given for the multidimensional dynamic convex $g$-risk\nmeasure in which the penalty term is expressed more precisely. It is shown that\nmodel uncertainty leads to the convexity of risk measures. As to applications,\nwe show how this multidimensional approach can be applied to measure the\ninsolvency risk of a firm with interacted subsidiaries; optimal risk sharing\nfor $\\protect\\gamma $-tolerant $g$-risk measures is investigated. Insurance\n$g$-risk measure and other ways to induce $g$-risk measures are also studied at\nthe end of the paper.\n"
    },
    {
        "paper_id": 1011.3707,
        "authors": "Dion Harmon, Blake Stacey, Yavni Bar-Yam and Yaneer Bar-Yam",
        "title": "Networks of Economic Market Interdependence and Systemic Risk",
        "comments": "9 pages, 2 compound figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The dynamic network of relationships among corporations underlies cascading\neconomic failures including the current economic crisis, and can be inferred\nfrom correlations in market value fluctuations. We analyze the time dependence\nof the network of correlations to reveal the changing relationships among the\nfinancial, technology, and basic materials sectors with rising and falling\nmarkets and resource constraints. The financial sector links otherwise weakly\ncoupled economic sectors, particularly during economic declines. Such links\nincrease economic risk and the extent of cascading failures. Our results\nsuggest that firewalls between financial services for different sectors would\nreduce systemic risk without hampering economic growth.\n"
    },
    {
        "paper_id": 1011.3736,
        "authors": "Sam Howison, Daniel Schwarz",
        "title": "Risk-Neutral Pricing of Financial Instruments in Emission Markets: A\n  Structural Approach",
        "comments": "Section 5 in this version is new and contains an asymptotic analysis\n  of the problem under consideration",
        "journal-ref": "Siam J. Financial Math., 3, pp. 709-739, 2012; Siam Review, 57(1),\n  pp. 95-127, 2015",
        "doi": "10.1137/100815219; 10.1137/140987365",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a novel approach to the pricing of financial instruments in\nemission markets, for example, the EU ETS. The proposed structural model is\npositioned between existing complex full equilibrium models and pure reduced\nform models. Using an exogenously specified demand for a polluting good it\ngives a causal explanation for the accumulation of CO2 emissions and takes into\naccount the feedback effect from the cost of carbon to the rate at which the\nmarket emits CO2. We derive a forward-backward stochastic differential equation\nfor the price process of the allowance certificate and solve the associated\nsemilinear partial differential equation numerically. We also show that\nderivatives written on the allowance certificate satisfy a linear partial\ndifferential equation. The model is extended to emission markets with multiple\ncompliance periods and we analyse the impact different intertemporal connecting\nmechanisms, such as borrowing, banking and withdrawal, have on the allowance\nprice.\n"
    },
    {
        "paper_id": 1011.3834,
        "authors": "Carlos E. Laciana and Santiago L. Rovere",
        "title": "Ising-like agent-based technology diffusion model: adoption patterns vs.\n  seeding strategies",
        "comments": "23 pages and 5 figures",
        "journal-ref": "Physica A 390: 1139 (2011)",
        "doi": "10.1016/j.physa.2010.11.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The well-known Ising model used in statistical physics was adapted to a\nsocial dynamics context to simulate the adoption of a technological innovation.\nThe model explicitly combines (a) an individual's perception of the advantages\nof an innovation and (b) social influence from members of the decision-maker's\nsocial network. The micro-level adoption dynamics are embedded into an\nagent-based model that allows exploration of macro-level patterns of technology\ndiffusion throughout systems with different configurations (number and\ndistributions of early adopters, social network topologies). In the present\nwork we carry out many numerical simulations. We find that when the gap between\nthe individual's perception of the options is high, the adoption speed\nincreases if the dispersion of early adopters grows. Another test was based on\nchanging the network topology by means of stochastic connections to a common\nopinion reference (hub), which resulted in an increment in the adoption speed.\nFinally, we performed a simulation of competition between options for both\nregular and small world networks.\n"
    },
    {
        "paper_id": 1011.3975,
        "authors": "V.M. Belyaev",
        "title": "Cumulant Expansion and Monthly Sum Derivative",
        "comments": "8 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Cumulant expansion is used to derive accurate closed-form approximation for\nMonthly Sum Options in case of constant volatility model. Payoff of Monthly Sum\nOption is based on sum of $N$ caped (and probably floored) returns. It is\nnoticed, that $1/\\sqrt{N}$ can be used as a small parameter in Edgeworth\nexpansion. First two leading terms of this expansion are calculated here. It is\nshown that the suggest closed-form approximation is in a good agreement with\nnumerical results for typical mode parameters.\n"
    },
    {
        "paper_id": 1011.4336,
        "authors": "Kyu-Min Lee, Jae-Suk Yang, Gunn Kim, Jaesung Lee, Kwang-Il Goh, and\n  In-mook Kim",
        "title": "Impact of the topology of global macroeconomic network on the spreading\n  of economic crises",
        "comments": "25 pages, 11 figures, Supplementary Information available upon\n  request",
        "journal-ref": "PLoS ONE 6(3): e18443 (2011)",
        "doi": "10.1371/journal.pone.0018443",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Throughout economic history, the global economy has experienced recurring\ncrises. The persistent recurrence of such economic crises calls for an\nunderstanding of their generic features rather than treating them as singular\nevents. The global economic system is a highly complex system and can best be\nviewed in terms of a network of interacting macroeconomic agents. In this\nregard, from the perspective of collective network dynamics, here we explore\nhow the topology of global macroeconomic network affects the patterns of\nspreading of economic crises. Using a simple toy model of crisis spreading, we\ndemonstrate that an individual country's role in crisis spreading is not only\ndependent on its gross macroeconomic capacities, but also on its local and\nglobal connectivity profile in the context of the world economic network. We\nfind that on one hand clustering of weak links at the regional scale can\nsignificantly aggravate the spread of crises, but on the other hand the current\nnetwork structure at the global scale harbors a higher tolerance of extreme\ncrises compared to more \"globalized\" random networks. These results suggest\nthat there can be a potential hidden cost in the ongoing globalization movement\ntowards establishing less-constrained, trans-regional economic links between\ncountries, by increasing the vulnerability of global economic system to extreme\ncrises.\n"
    },
    {
        "paper_id": 1011.4404,
        "authors": "Ole Peters",
        "title": "The time resolution of the St. Petersburg paradox",
        "comments": "20 pages, 1 figure",
        "journal-ref": "Phil. Trans. R. Soc. A, vol. 369 no. 1956 4913--4931",
        "doi": "10.1098/rsta.2011.0065",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A resolution of the St. Petersburg paradox is presented. In contrast to the\nstandard resolution, utility is not required. Instead, the time-average\nperformance of the lottery is computed. The final result can be phrased\nmathematically identically to Daniel Bernoulli's resolution, which uses\nlogarithmic utility, but is derived using a conceptually different argument.\nThe advantage of the time resolution is the elimination of arbitrary utility\nfunctions.\n"
    },
    {
        "paper_id": 1011.4499,
        "authors": "G. Liang, T. Lyons, Z. Qian",
        "title": "A Functional Approach to FBSDEs and Its Application in Optimal\n  Portfolios",
        "comments": "26 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In Liang et al (2009), the current authors demonstrated that BSDEs can be\nreformulated as functional differential equations, and as an application, they\nsolved BSDEs on general filtered probability spaces. In this paper the authors\ncontinue the study of functional differential equations and demonstrate how\nsuch approach can be used to solve FBSDEs. By this approach the equations can\nbe solved in one direction altogether rather than in a forward and backward\nway. The solutions of FBSDEs are then employed to construct the weak solutions\nto a class of BSDE systems (not necessarily scalar) with quadratic growth, by a\nnonlinear version of Girsanov's transformation. As the solving procedure is\nconstructive, the authors not only obtain the existence and uniqueness theorem,\nbut also really work out the solutions to such class of BSDE systems with\nquadratic growth. Finally an optimal portfolio problem in incomplete markets is\nsolved based on the functional differential equation approach and the nonlinear\nGirsanov's transformation.\n"
    },
    {
        "paper_id": 1011.4547,
        "authors": "Josh Gray and Konstantin Palamarchuk",
        "title": "Calibration of One- and Two-Factor Models For Valuation of Energy\n  Multi-Asset Derivative Contracts",
        "comments": "MikTeX 2.7, 18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study historical calibration of one- and two-factor models that are known\nto describe relatively well the dynamics of energy underlyings such as spot and\nindex natural gas or oil prices at different physical locations or regional\npower prices. We take into account uneven frequency of data due to weekends,\nholidays, and possible missing data. We study the case when several one- and\ntwo-factor models are used in the joint model with correlated model factors and\npresent examples of joint calibration for daily natural gas prices at several\nlocations in the US and for regional hourly power prices.\n"
    },
    {
        "paper_id": 1011.4732,
        "authors": "Masahiko Egami and Kazutoshi Yamazaki",
        "title": "Solving Optimal Dividend Problems via Phase-type Fitting Approximation\n  of Scale Functions",
        "comments": "33 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The optimal dividend problem by De Finetti (1957) has been recently\ngeneralized to the spectrally negative L\\'evy model where the implementation of\noptimal strategies draws upon the computation of scale functions and their\nderivatives. This paper proposes a phase-type fitting approximation of the\noptimal strategy. We consider spectrally negative L\\'evy processes with\nphase-type jumps as well as meromorphic L\\'evy processes (Kuznetsov et al.,\n2010a), and use their scale functions to approximate the scale function for a\ngeneral spectrally negative L\\'evy process. We obtain analytically the\nconvergence results and illustrate numerically the effectiveness of the\napproximation methods using examples with the spectrally negative L\\'evy\nprocess with i.i.d. Weibull-distributed jumps, the \\beta-family and CGMY\nprocess.\n"
    },
    {
        "paper_id": 1011.4795,
        "authors": "Michael Schmutz, Thomas Z\\\"urcher",
        "title": "Static replications with traffic light options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is well known that any sufficiently regular one-dimensional payoff\nfunction has an explicit static hedge by bonds, forward contracts and lots of\nvanilla options. We show that the natural extension of the corresponding\nrepresentation leads to a static hedge based on the same instruments along with\ntraffic light options, which have recently been introduced in the market. One\nbig advantage of these replication strategies is the easy structure of the\nhedge. Hence, traffic light options are particularly powerful building blocks\nfor more complicated bivariate options. While it is well known that the second\nstrike derivative of non-discounted prices of vanilla options are related to\nthe risk-neutral density of the underlying asset price in the corresponding\nabsolutely continuous settings, similar statements hold for traffic light\noptions in sufficiently regular bivariate settings.\n"
    },
    {
        "paper_id": 1011.483,
        "authors": "Stefan Gerhold",
        "title": "The Hartman-Watson Distribution revisited: Asymptotics for Pricing Asian\n  Options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Barrieu, Rouault, and Yor [J. Appl. Probab. 41 (2004)] determined asymptotics\nfor the logarithm of the distribution function of the Hartman-Watson\ndistribution. We determine the asymptotics of the density. This refinement can\nbe applied to the pricing of Asian options in the Black-Scholes model.\n"
    },
    {
        "paper_id": 1011.4991,
        "authors": "Jun Ye, Tiantian Li",
        "title": "Optimal mean-variance investment strategy under value-at-risk\n  constraints",
        "comments": "20 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is devoted to study the effects arising from imposing a\nvalue-at-risk (VaR) constraint in mean-variance portfolio selection problem for\nan investor who receives a stochastic cash flow which he/she must then invest\nin a continuous-time financial market. For simplicity, we assume that there is\nonly one investment opportunity available for the investor, a risky stock.\nUsing techniques of stochastic linear-quadratic (LQ) control, the optimal\nmean-variance investment strategy with and without VaR constraint are derived\nexplicitly in closed forms, based on solution of corresponding\nHamilton-Jacobi-Bellman (HJB) equation. Furthermore, some numerical examples\nare proposed to show how the addition of the VaR constraint affects the optimal\nstrategy.\n"
    },
    {
        "paper_id": 1011.502,
        "authors": "Ines Kahloul, Anouar Ben Mabrouk and Slah-Eddine Hallara",
        "title": "Wavelet-Based Prediction for Governance, Diversification and Value\n  Creation Variables",
        "comments": "22 pages",
        "journal-ref": "International Research Journal of Finance and Economics, 60\n  (2010), pp. 15-28",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the possibility of completing data bases of a sample of governance,\ndiversification and value creation variables by providing a well adapted method\nto reconstruct the missing parts in order to obtain a complete sample to be\napplied for testing the ownership-structure/diversification relationship. It\nconsists of a dynamic procedure based on wavelets. A comparison with Neural\nNetworks, the most used method, is provided to prove the efficiency of the\nhere-developed one. The empirical tests are conducted on a set of French firms.\n"
    },
    {
        "paper_id": 1011.5187,
        "authors": "Carmen Pellicer-Lostao and Ricardo Lopez-Ruiz",
        "title": "Transition from Exponential to Power Law Distributions in a Chaotic\n  Market",
        "comments": "12 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1142/S0129183111016038",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Economy is demanding new models, able to understand and predict the evolution\nof markets. To this respect, Econophysics offers models of markets as complex\nsystems, that try to comprehend macro-, system-wide states of the economy from\nthe interaction of many agents at micro-level. One of these models is the\ngas-like model for trading markets. This tries to predict money distributions\nin closed economies and quite simply, obtains the ones observed in real\neconomies. However, it reveals technical hitches to explain the power law\ndistribution, observed in individuals with high incomes. In this work, non\nlinear dynamics is introduced in the gas-like model in way that an effort to\novercome these flaws. A particular chaotic dynamics is used to break the\npairing symmetry of agents $(i,j)\\Leftrightarrow(j,i)$. The results demonstrate\nthat a \"chaotic gas-like model\" can reproduce the Exponential and Power law\ndistributions observed in real economies. Moreover, it controls the transition\nbetween them. This may give some insight of the micro-level causes that\noriginate unfair distributions of money in a global society. Ultimately, the\nchaotic model makes obvious the inherent instability of asymmetric scenarios,\nwhere sinks of wealth appear and doom the market to extreme inequality.\n"
    },
    {
        "paper_id": 1011.5343,
        "authors": "Wanfeng Yan, Ryan Woodard, Didier Sornette",
        "title": "Inferring Fundamental Value and Crash Nonlinearity from Bubble\n  Calibration",
        "comments": "23 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Identifying unambiguously the presence of a bubble in an asset price remains\nan unsolved problem in standard econometric and financial economic approaches.\nA large part of the problem is that the fundamental value of an asset is, in\ngeneral, not directly observable and it is poorly constrained to calculate.\nFurther, it is not possible to distinguish between an exponentially growing\nfundamental price and an exponentially growing bubble price. We present a\nseries of new models based on the Johansen-Ledoit-Sornette (JLS) model, which\nis a flexible tool to detect bubbles and predict changes of regime in financial\nmarkets. Our new models identify the fundamental value of an asset price and\ncrash nonlinearity from a bubble calibration. In addition to forecasting the\ntime of the end of a bubble, the new models can also estimate the fundamental\nvalue and the crash nonlinearity. Besides, the crash nonlinearity obtained in\nthe new models presents a new approach to possibly identify the dynamics of a\ncrash after a bubble. We test the models using data from three historical\nbubbles ending in crashes from different markets. They are: the Hong Kong Hang\nSeng index 1997 crash, the S&P 500 index 1987 crash and the Shanghai Composite\nindex 2009 crash. All results suggest that the new models perform very well in\ndescribing bubbles, forecasting their ending times and estimating fundamental\nvalue and the crash nonlinearity. The performance of the new models is tested\nunder both the Gaussian and non-Gaussian residual assumption. Under the\nGaussian residual assumption, nested hypotheses with the Wilks statistics are\nused and the p-values suggest that models with more parameters are necessary.\nUnder non-Gaussian residual assumption, we use a bootstrap method to get type I\nand II errors of the hypotheses. All tests confirm that the generalized JLS\nmodels provide useful improvements over the standard JLS model.\n"
    },
    {
        "paper_id": 1011.565,
        "authors": "Ron T. L. Chan and Simon Hubbert",
        "title": "A Numerical Study of Radial Basis Function Based Methods for Options\n  Pricing under the One Dimension Jump-diffusion Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  The aim of this chapter is to show how option prices in jump-diffusion models\ncan be computed using meshless methods based on Radial Basis Function (RBF)\ninterpolation. The RBF technique is demonstrated by solving the partial\nintegro-differential equation (PIDE) in one-dimension for the American put and\nthe European vanilla call/put options on dividend-paying stocks in the Merton\nand Kou jump-diffusion models. The radial basis function we select is the Cubic\nSpline. We also propose a simple numerical algorithm for finding a finite\ncomputational range of an improper integral term in the PIDE so that the\naccuracy of approximation of the integral can be improved. Moreover, the\nsolution functions of the PIDE are approximated explicitly by RBFs which have\nexact forms so we can easily compute the global integral by any kind of\nnumerical quadrature. Finally, we will not only show numerically that our\nscheme is second order accurate in both spatial and time variables in a\nEuropean case but also second order accurate in spatial variables and first\norder accurate in time variables in an American case.\n"
    },
    {
        "paper_id": 1011.5714,
        "authors": "Nicolas Perry (IRCCyN), Alain Bernard (IRCCyN)",
        "title": "Cost objective PLM and CE",
        "comments": null,
        "journal-ref": "Concurrent Engineering 2003: the Vision for the Future Generation\n  in Research and Applications, Ricardo Jardim-Goncalves, Jianzhong Chia,\n  Adolfo Steiger-Garcao (Ed.) (2003) p.817-822",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Concurrent engineering taking into account product life-cycle factors seems\nto be one of the industrial challenges of the next years. Cost estimation and\nmanagement are two main strategic tasks that imply the possibility of managing\ncosts at the earliest stages of product development. This is why it is\nindispensable to let people from economics and from industrial engineering\ncollaborates in order to find the best solution for enterprise progress for\neconomical factors mastering. The objective of this paper is to present who we\ntry to adapt costing methods in a PLM and CE point of view to the new\nindustrial context and configuration in order to give pertinent decision aid\nfor product and process choices. A very important factor is related to cost\nmanagement problems when developing new products. A case study is introduced\nthat presents how product development actors have referenced elements to\nproduct life-cycle costs and impacts, how they have an idea bout economical\nindicators when taking decisions during the progression of the project of\nproduct development.\n"
    },
    {
        "paper_id": 1011.5715,
        "authors": "Alain Bernard (IRCCyN), Nicolas Perry (IRCCyN), Jean-Charles Delplace,\n  Serge Gabriel",
        "title": "Quotation for the Value Added Assessment during Product Development and\n  Production Processes",
        "comments": null,
        "journal-ref": "Methods and Tools for Co-Operative and Integrated Design (2004)\n  pp.35-43",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This communication is based on an original approach linking economical\nfactors to technical and methodological ones. This work is applied to the\ndecision process for mix production. This approach is relevant for costing\ndriving systems. The main interesting point is that the quotation factors\n(linked to time indicators for each step of the industrial process) allow the\ncomplete evaluation and control of, on the one hand, the global balance of the\ncompany for a six-month period and, on the other hand, the reference values for\neach step of the process cycle of the parts. This approach is based on a\ncomplete numerical traceability and control of the processes (design and\nmanufacturing of the parts and tools, mass production). This is possible due to\nnumerical models and to feedback loops for cost indicator analysis at design\nand production levels. Quotation is also the base for the design requirements\nand for the choice and the configuration of the production process. The\nreference values of the quotation generate the base reference parameters of the\nprocess steps and operations. The traceability of real values (real time\nconsuming, real consumable) is mainly used for a statistic feedback to the\nquotation application. The industrial environment is a steel sand casting\ncompany with a wide mix product and the application concerns both design and\nmanufacturing. The production system is fully automated and integrates\ndifferent products at the same time.\n"
    },
    {
        "paper_id": 1011.5716,
        "authors": "Nicolas Perry (IRCCyN), Magali Mauchand, Alain Bernard (IRCCyN)",
        "title": "Costs Models in Design and Manufacturing of Sand Casting Products",
        "comments": null,
        "journal-ref": "Advances in Integrated Design and Manufacturing in Mechanical\n  Engineering (2005) pp",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the early phases of the product life cycle, the costs controls became a\nmajor decision tool in the competitiveness of the companies due to the world\ncompetition. After defining the problems related to this control difficulties,\nwe will present an approach using a concept of cost entity related to the\ndesign and realization activities of the product. We will try to apply this\napproach to the fields of the sand casting foundry. This work will highlight\nthe enterprise modelling difficulties (limits of a global cost modelling) and\nsome specifics limitations of the tool used for this development. Finally we\nwill discuss on the limits of a generic approach.\n"
    },
    {
        "paper_id": 1011.5792,
        "authors": "Juri Hinz, Alex Novikov",
        "title": "On fair pricing of emission-related derivatives",
        "comments": "Published in at http://dx.doi.org/10.3150/09-BEJ242 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2010, Vol. 16, No. 4, 1240-1261",
        "doi": "10.3150/09-BEJ242",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Tackling climate change is at the top of many agendas. In this context,\nemission trading schemes are considered as promising tools. The regulatory\nframework for an emission trading scheme introduces a market for emission\nallowances and creates a need for risk management by appropriate financial\ncontracts. In this work, we address logical principles underlying their\nvaluation.\n"
    },
    {
        "paper_id": 1011.581,
        "authors": "Pierre-Alain Reigneron, Romain Allez and Jean-Philippe Bouchaud",
        "title": "Principal Regression Analysis and the index leverage effect",
        "comments": "10 pages, 7 figures",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, 390 (2011)",
        "doi": "10.1016/j.physa.2011.04.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit the index leverage effect, that can be decomposed into a\nvolatility effect and a correlation effect. We investigate the latter using a\nmatrix regression analysis, that we call `Principal Regression Analysis' (PRA)\nand for which we provide some analytical (using Random Matrix Theory) and\nnumerical benchmarks. We find that downward index trends increase the average\ncorrelation between stocks (as measured by the most negative eigenvalue of the\nconditional correlation matrix), and makes the market mode more uniform. Upward\ntrends, on the other hand, also increase the average correlation between stocks\nbut rotates the corresponding market mode {\\it away} from uniformity. There are\ntwo time scales associated to these effects, a short one on the order of a\nmonth (20 trading days), and a longer time scale on the order of a year. We\nalso find indications of a leverage effect for sectorial correlations as well,\nwhich reveals itself in the second and third mode of the PRA.\n"
    },
    {
        "paper_id": 1011.5978,
        "authors": "Victor G. Gorshkov, Anastassia M. Makarieva, Bai-Lian Li",
        "title": "Comprehending environmental and economic sustainability: Comparative\n  analysis of stability principles in the biosphere and free market economy",
        "comments": "51 pages, 6 figures",
        "journal-ref": "Annals of the New York Academy of Sciences, 1195, E1-E18, 2010",
        "doi": "10.1111/j.1749-6632.2009.05400.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using the formalism of Lyapunov potential function it is shown that the\nstability principles for biomass in the ecosystem and for employment in\neconomics are mathematically similar. The ecosystem is found to have a stable\nand an unstable stationary state with high (forest) and low (grasslands)\nbiomass, respectively. In economics, there is a stable stationary state with\nhigh employment, which corresponds to mass production of conventional goods\nsold at low cost price, and an unstable stationary state with lower employment,\nwhich corresponds to production of novel goods appearing in the course of\ntechnological progress. An additional stable stationary state is described for\neconomics, the one corresponding to very low employment in production of life\nessentials such as energy and raw materials. In this state the civilization\ncurrently pays 10% of global GDP for energy produced by a negligible minority\nof the working population (currently ~0.2%) and sold at prices greatly\nexceeding the cost price by 40 times. It is shown that economic ownership over\nenergy sources is equivalent to equating measurable variables of different\ndimensions (stores and fluxes), which leads to effective violation of the laws\nof energy and matter conservation.\n"
    },
    {
        "paper_id": 1011.5983,
        "authors": "Danilo Delpini, Giacomo Bormetti",
        "title": "Minimal model of financial stylized facts",
        "comments": "9 pages, 5 figures and 3 tables",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.83.041111",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we afford the statistical characterization of a linear\nStochastic Volatility Model featuring Inverse Gamma stationary distribution for\nthe instantaneous volatility. We detail the derivation of the moments of the\nreturn distribution, revealing the role of the Inverse Gamma law in the\nemergence of fat tails, and of the relevant correlation functions. We also\npropose a systematic methodology for estimating the parameters, and we describe\nthe empirical analysis of the Standard & Poor 500 index daily returns,\nconfirming the ability of the model to capture many of the established stylized\nfact as well as the scaling properties of empirical distributions over\ndifferent time horizons.\n"
    },
    {
        "paper_id": 1011.5986,
        "authors": "Andreas H. Hamel, Frank Heyde, Birgit Rudloff",
        "title": "Set-valued risk measures for conical market models",
        "comments": null,
        "journal-ref": "Mathematics and Financial Economics 5 (1), 1 - 28, (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Set-valued risk measures on $L^p_d$ with $0 \\leq p \\leq \\infty$ for conical\nmarket models are defined, primal and dual representation results are given.\nThe collection of initial endowments which allow to super-hedge a multivariate\nclaim are shown to form the values of a set-valued sublinear (coherent) risk\nmeasure. Scalar risk measures with multiple eligible assets also turn out to be\na special case within the set-valued framework.\n"
    },
    {
        "paper_id": 1011.6097,
        "authors": "Tristan Fletcher, Zakria Hussain and John Shawe-Taylor",
        "title": "Currency Forecasting using Multiple Kernel Learning with Financially\n  Motivated Features",
        "comments": "To be presented at NIPS 2010 workshop: New Directions in Multiple\n  Kernel Learning",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Multiple Kernel Learning (MKL) is used to replicate the signal combination\nprocess that trading rules embody when they aggregate multiple sources of\nfinancial information when predicting an asset's price movements. A set of\nfinancially motivated kernels is constructed for the EURUSD currency pair and\nis used to predict the direction of price movement for the currency over\nmultiple time horizons. MKL is shown to outperform each of the kernels\nindividually in terms of predictive accuracy. Furthermore, the kernel\nweightings selected by MKL highlights which of the financial features\nrepresented by the kernels are the most informative for predictive tasks.\n"
    },
    {
        "paper_id": 1011.6284,
        "authors": "Stefan Kerbl",
        "title": "Regulatory Medicine Against Financial Market Instability: What Helps And\n  What Hurts?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Do we know if a short selling ban or a Tobin Tax result in more stable asset\nprices? Or do they in fact make things worse? Just like medicine regulatory\nmeasures in financial markets aim at improving an already complex system. And\njust like medicine these interventions can cause side effects which are even\nharder to assess when taking the interplay with other measures into account. In\nthis paper an agent based stock market model is built that tries to find\nanswers to the questions above. In a stepwise procedure regulatory measures are\nintroduced and their implications on market liquidity and stability examined.\nParticularly, the effects of (i) a ban of short selling (ii) a mandatory risk\nlimit, i.e. a Value-at-Risk limit, (iii) an introduction of a Tobin Tax, i.e.\ntransaction tax on trading, and (iv) any arbitrary combination of the measures\nare observed and discussed. The model is set up to incorporate non-linear\nfeedback effects of leverage and liquidity constraints leading to fire sales\nand escape dynamics. In its unregulated version the model outcome is capable of\nreproducing stylised facts of asset returns like fat tails and clustered\nvolatility. Introducing regulatory measures shows that only a mandatory risk\nlimit is beneficial from every perspective, while a short selling ban - though\nreducing volatility - increases tail risk. The contrary holds true for a Tobin\nTax: it reduces the occurrence of crashes but increases volatility.\nFurthermore, the interplay of measures is not negligible: measures block each\nother and a well chosen combination can mitigate unforeseen side effects.\nConcerning the Tobin Tax the findings indicate that an overdose can do severe\nharm.\n"
    },
    {
        "paper_id": 1011.6402,
        "authors": "Rama Cont and Arseniy Kukanov and Sasha Stoikov",
        "title": "The Price Impact of Order Book Events",
        "comments": null,
        "journal-ref": "JOURNAL OF FINANCIAL ECONOMETRICS (Winter 2014) 12 (1): 47-88",
        "doi": "10.1093/jjfinec/nbt003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the price impact of order book events - limit orders, market orders\nand cancelations - using the NYSE TAQ data for 50 U.S. stocks. We show that,\nover short time intervals, price changes are mainly driven by the order flow\nimbalance, defined as the imbalance between supply and demand at the best bid\nand ask prices. Our study reveals a linear relation between order flow\nimbalance and price changes, with a slope inversely proportional to the market\ndepth. These results are shown to be robust to seasonality effects, and stable\nacross time scales and across stocks. We argue that this linear price impact\nmodel, together with a scaling argument, implies the empirically observed\n\"square-root\" relation between price changes and trading volume. However, the\nrelation between price changes and trade volume is found to be noisy and less\nrobust than the one based on order flow imbalance.\n"
    },
    {
        "paper_id": 1011.6532,
        "authors": "K.J. in 't Hout and K. Volders",
        "title": "Stability of central finite difference schemes for the Heston PDE",
        "comments": null,
        "journal-ref": "Numer. Algor. 60, 115-133 (2012)",
        "doi": "10.1007/s11075-011-9514-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper deals with stability in the numerical solution of the prominent\nHeston partial differential equation from mathematical finance. We study the\nwell-known central second-order finite difference discretization, which leads\nto large semi-discrete systems with non-normal matrices A. By employing the\nlogarithmic spectral norm we prove practical, rigorous stability bounds. Our\ntheoretical stability results are illustrated by ample numerical experiments.\n"
    },
    {
        "paper_id": 1012.0199,
        "authors": "Y. Malevergne, A. Saichev and D. Sornette",
        "title": "Zipf's law and maximum sustainable growth",
        "comments": "42 pages, 3 figures",
        "journal-ref": "Journal of Economic Dynamics and Control 37 (6), 1195-1212 (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Zipf's law states that the number of firms with size greater than S is\ninversely proportional to S. Most explanations start with Gibrat's rule of\nproportional growth but require additional constraints. We show that Gibrat's\nrule, at all firm levels, yields Zipf's law under a balance condition between\nthe effective growth rate of incumbent firms (which includes their possible\ndemise) and the growth rate of investments in entrant firms. Remarkably, Zipf's\nlaw is the signature of the long-term optimal allocation of resources that\nensures the maximum sustainable growth rate of an economy.\n"
    },
    {
        "paper_id": 1012.0249,
        "authors": "Nataliya Horbenko, Peter Ruckdeschel, Taehan Bae",
        "title": "Robust Estimation of Operational Risk",
        "comments": "14 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  According to the Loss Distribution Approach, the operational risk of a bank\nis determined as 99.9% quantile of the respective loss distribution, covering\nunexpected severe events. The 99.9% quantile can be considered a tail event. As\nsupported by the Pickands-Balkema-de Haan Theorem, tail events exceeding some\nhigh threshold are usually modeled by a Generalized Pareto Distribution (GPD).\nEstimation of GPD tail quantiles is not a trivial task, in particular if one\ntakes into account the heavy tails of this distribution, the possibility of\nsingular outliers, and, moreover, the fact that data is usually pooled among\nseveral sources. Moreover, if, as is frequently the case, operational losses\nare pooled anonymously, relevance of the fitting data for the respective bank\nis not self-evident. In such situations, robust methods may provide stable\nestimates when classical methods already fail. In this paper, optimally-robust\nprocedures MBRE, OMSE, RMXE are introduced to the application domain of\noperational risk. We apply these procedures to parameter estimation of a GPD at\ndata from Algorithmics Inc. To better understand these results, we provide\nsupportive diagnostic plots adjusted for this context: influence plots,\noutlyingness plots, and QQ plots with robust confidence bands.\n"
    },
    {
        "paper_id": 1012.0348,
        "authors": "Tomas Bokes",
        "title": "A unified approach to determining the early exercise boundary position\n  at expiry for American style of general class of derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present a new method for calculating the limit of early\nexercise boundary at expiry. We price American style of general derivative\nusing a formula expressed as a sum of the value of European style of derivative\nand so called American premium. We use the latter expression to calculate an\nanalytic formula for limit of early exercise boundary at expiry. Method applied\non American style plain vanilla, Asian and lookback options yields identical\nresults with already known values. Results for selected American style of\nderivative strategies are compared with limits calculated by the PSOR method.\n"
    },
    {
        "paper_id": 1012.0349,
        "authors": "Martin D. Gould and Mason A. Porter and Stacy Williams and Mark\n  McDonald and Daniel J. Fenn and Sam D. Howison",
        "title": "Limit Order Books",
        "comments": "42 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Limit order books (LOBs) match buyers and sellers in more than half of the\nworld's financial markets. This survey highlights the insights that have\nemerged from the wealth of empirical and theoretical studies of LOBs. We\nexamine the findings reported by statistical analyses of historical LOB data\nand discuss how several LOB models provide insight into certain aspects of the\nmechanism. We also illustrate that many such models poorly resemble real LOBs\nand that several well-established empirical facts have yet to be reproduced\nsatisfactorily. Finally, we identify several key unresolved questions about\nLOBs.\n"
    },
    {
        "paper_id": 1012.0475,
        "authors": "Emmanuel Schertzer, Yadong Li, Umer Khan",
        "title": "The Impossible Trio in CDO Modeling",
        "comments": "12 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that stochastic recovery always leads to counter-intuitive behaviors\nin the risk measures of a CDO tranche - namely, continuity on default and\npositive credit spread risk cannot be ensured simultaneously. We then propose a\nsimple recovery variance regularization method to control the magnitude of\nnegative credit spread risk while preserving the continuity on default.\n"
    },
    {
        "paper_id": 1012.0754,
        "authors": "Patrick Cheridito, Alexander Wugalter",
        "title": "Pricing and Hedging in Affine Models with Possibility of Default",
        "comments": "25 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a general framework for the simultaneous modeling of equity,\ngovernment bonds, corporate bonds and derivatives. Uncertainty is generated by\na general affine Markov process. The setting allows for stochastic volatility,\njumps, the possibility of default and correlation between different assets. We\nshow how to calculate discounted complex moments by solving a coupled system of\ngeneralized Riccati equations. This yields an efficient method to compute\nprices of power payoffs. European calls and puts as well as binaries and\nasset-or-nothing options can be priced with the fast Fourier transform methods\nof Carr and Madan (1999) and Lee (2005). Other European payoffs can be\napproximated with a linear combination of government bonds, power payoffs and\nvanilla options. We show the results to be superior to using only government\nbonds and power payoffs or government bonds and vanilla options. We also give\nconditions for European continent claims in our framework to be replicable if\nenough financial instruments are liquidly tradable and study dynamic hedging\nstrategies. As an example we discuss a Heston-type stochastic volatility model\nwith possibility of default and stochastic interest rates.\n"
    },
    {
        "paper_id": 1012.0843,
        "authors": "Xin Guo, Robert A Jarrow, Adrien de Larrard",
        "title": "The economic default time and the Arcsine law",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper develops a structural credit risk model to characterize the\ndifference between the economic and recorded default times for a firm. Recorded\ndefault occurs when default is recorded in the legal system. The economic\ndefault time is the last time when the firm is able to pay off its debt prior\nto the legal default time. It has been empirically documented that these two\ntimes are distinct (see Guo, Jarrow, and Lin (2008)). In our model, the\nprobability distribution for the time span between economic and recorded\ndefaults follows a mixture of Arcsine Laws, which is consistent with the\nresults contained in Guo, Jarrow, and Lin. In addition, we show that the\nclassical structural model is a limiting case of our model as the time period\nbetween debt repayment dates goes to zero. As a corollary, we show how the firm\nvalue process's parameters can be estimated using the tail index and\ncorrelation structure of the firm's return.\n"
    },
    {
        "paper_id": 1012.1037,
        "authors": "Abass Sagna (LAP)",
        "title": "Pricing of barrier options by marginal functional quantization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is devoted to the pricing of Barrier options by optimal quadratic\nquantization method. From a known useful representation of the premium of\nbarrier options one deduces an algorithm similar to one used to estimate\nnonlinear filter using quadratic optimal functional quantization. Some\nnumerical tests are fulfilled in the Black-Scholes model and in a local\nvolatility model and a comparison to the so called Brownian Bridge method is\nalso done.\n"
    },
    {
        "paper_id": 1012.1188,
        "authors": "Christian Hilbe",
        "title": "Equilibrium notions and framing effects",
        "comments": "15 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Experimental economics has repeatedly demonstrated that the Nash equilibrium\nmakes inaccurate predictions for a vast set of games. Instead, several\nalternative theoretical concepts predict behavior that is much more in tune\nwith observed data, with the quantal response equilibrium as the most prominent\nexample. However, here we show that this equilibrium notion itself, like any\nother concept that varies smoothly with the payoffs, is necessarily subject to\nframing effects: If the same economic problem is represented in a different but\nequivalent way, the predicted results will differ. As a consequence, we argue\nthat tools and methods that are successful in explaining human behavior in\nlaboratory experiments may be unsuitable for doing theory.\n"
    },
    {
        "paper_id": 1012.1412,
        "authors": "Nikolai Dokuchaev",
        "title": "Controlled options: derivatives with added flexibility",
        "comments": "23 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper introduces a limit version of multiple stopping options such that\nthe holder selects dynamically a weight function that control the distribution\nof the payments (benefits) over time. In applications for commodities and\nenergy trading, a control process can represent the quantity that can be\npurchased by a fixed price at current time. In another example, the control\nrepresents the weight of the integral in a modification of the Asian option.\nThe pricing for these options requires to solve a stochastic control problem.\nSome existence results and pricing rules are obtained via modifications of\nparabolic Bellman equations.\n"
    },
    {
        "paper_id": 1012.1535,
        "authors": "Joerg Vorbrink",
        "title": "Financial markets with volatility uncertainty",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate financial markets under model risk caused by uncertain\nvolatilities. For this purpose we consider a financial market that features\nvolatility uncertainty. To have a mathematical consistent framework we use the\nnotion of G-expectation and its corresponding G-Brownian motion recently\nintroduced by Peng (2007). Our financial market consists of a riskless asset\nand a risky stock with price process modeled by a geometric G-Brownian motion.\nWe adapt the notion of arbitrage to this more complex situation and consider\nstock price dynamics which exclude arbitrage opportunities. Due to volatility\nuncertainty the market is not complete any more. We establish the interval of\nno-arbitrage prices for general European contingent claims and deduce explicit\nresults in a Markovian setting.\n"
    },
    {
        "paper_id": 1012.1793,
        "authors": "Dorje C. Brody, Lane P. Hughston, and Ewan Mackie",
        "title": "Rational term structure models with geometric Levy martingales",
        "comments": "expanded version, including general discussion on L\\'evy interest\n  rate models",
        "journal-ref": "Stochastics 84, 719-740 (2012)",
        "doi": "10.1080/17442508.2012.689835",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the \"positive interest\" models of Flesaker-Hughston, the nominal discount\nbond system is determined by a one-parameter family of positive martingales. In\nthe present paper we extend this analysis to include a variety of distributions\nfor the martingale family, parameterised by a function that determines the\nbehaviour of the market risk premium. These distributions include jump and\ndiffusion characteristics that generate various properties for discount bond\nreturns. For example, one can generate skewness and excess kurtosis in the bond\nreturns by choosing the martingale family to be given by (a) exponential gamma\nprocesses, or (b) exponential variance gamma processes. The models are\n\"rational\" in the sense that the discount bond price is given by a ratio of\nweighted sums of positive martingales. Our findings lead to semi-analytical\nformulae for the prices of options on discount bonds. A number of general\nresults concerning L\\'evy interest rate models are presented as well.\n"
    },
    {
        "paper_id": 1012.1878,
        "authors": "Jiro Akahori, Andrea Macrina",
        "title": "Heat Kernel Interest Rate Models with Time-Inhomogeneous Markov\n  Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a heat kernel approach for the development of stochastic pricing\nkernels. The kernels are constructed by positive propagators, which are driven\nby time-inhomogeneous Markov processes. We multiply such a propagator with a\npositive, time-dependent and decreasing weight function, and integrate the\nproduct over time. The result is a so-called weighted heat kernel that by\nconstruction is a supermartingale with respect to the filtration generated by\nthe time-inhomogeneous Markov processes. As an application, we show how this\nframework naturally fits the information-based asset pricing framework where\ntime-inhomogeneous Markov processes are utilized to model partial information\nabout random economic factors. We present examples of pricing kernel models\nwhich lead to analytical formulae for bond prices along with explicit\nexpressions for the associated interest rate and market price of risk.\nFurthermore, we also address the pricing of fixed-income derivatives within\nthis framework.\n"
    },
    {
        "paper_id": 1012.216,
        "authors": "Fuzhou Gong, Deqing Zhou",
        "title": "Insider Trading in the Market with Rational Expected Price",
        "comments": "37 pages, 21 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Kyle (1985) builds a pioneering and influential model, in which an insider\nwith long-lived private information submits an optimal order in each period\ngiven the market maker's pricing rule. An inconsistency exists to some extent\nin the sense that the ``constant pricing rule \" actually assumes an adaptive\nexpected price with pricing rule given before insider making the decision, and\nthe ``market efficiency\" condition, however, assumes a rational expected price\nand implies that the pricing rule can be influenced by insider's strategy. We\nloosen the ``constant pricing rule \" assumption by taking into account\nsufficiently the insider's strategy has on pricing rule. According to the\ncharacteristic of the conditional expectation of the informed profits, three\ndifferent models vary with insider's attitudes regarding to risk are presented.\nCompared to Kyle (1985), the risk-averse insider in Model 1 can obtain larger\nguaranteed profits, the risk-neutral insider in Model 2 can obtain a larger ex\nante expectation of total profits across all periods and the risk-seeking\ninsider in Model 3 can obtain larger risky profits. Moreover, the limit\nbehaviors of the three models when trading frequency approaches infinity are\ngiven, showing that Model 1 acquires a strong-form efficiency, Model 2 acquires\nthe Kyle's (1985) continuous equilibrium, and Model 3 acquires an equilibrium\nwith information released at an increasing speed.\n"
    },
    {
        "paper_id": 1012.2279,
        "authors": "Jiang Zhang and You-Gui Wang",
        "title": "Size-Dependency of Income Distributions and Its Implications",
        "comments": "4 figures, 4 pages",
        "journal-ref": "Chinese Physics Letters, 2011,28(2):038901",
        "doi": "10.1088/0256-307X/28/3/038901",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper highlights the size-dependency of income distributions, i.e. the\nincome distribution curves versus the population of a country systematically.\nBy using the generalized Lotka-Volterra model to fit the empirical income data\nin the United States during 1996-2007, we found an important parameter\n$\\lambda$ can scale with a $\\beta$ power of the size (population) of U.S. in\nthat year. We pointed out that the size-dependency of the income distributions,\nwhich is a very important property but seldom addressed by previous studies,\nhas two non-trivial implications: (1) the allometric growth pattern, i.e. the\npower law relationship between population and GDP in different years, which can\nbe mathematically derived from the size-dependent income distributions and also\nsupported by the empirical data; (2) the connection with the anomalous scaling\nfor the probability density function in critical phenomena since the re-scaled\nform of the income distributions has the exactly same mathematical expression\nfor the limit distribution of the sum of many correlated random variables\nasymptotically.\n"
    },
    {
        "paper_id": 1012.2848,
        "authors": "Attilio Meucci",
        "title": "Fully Flexible Views: Theory and Practice",
        "comments": "2008",
        "journal-ref": "A. Meucci (2008) \"Fully Flexible Views: Theory and Practice\",\n  Risk, 21 (10) p. 97-102",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a unified methodology to input non-linear views from any number of\nusers in fully general non-normal markets, and perform, among others,\nstress-testing, scenario analysis, and ranking allocation. We walk the reader\nthrough the theory and we detail an extremely efficient algorithm to easily\nimplement this methodology under fully general assumptions. As it turns out, no\nrepricing is ever necessary, hence the methodology can be readily applied to\nbooks with complex derivatives. We also present an analytical solution, useful\nfor benchmarking, which per se generalizes notable previous results. Code\nillustrating this methodology in practice is available at\nhttp://www.mathworks.com/matlabcentral/fileexchange/21307\n"
    },
    {
        "paper_id": 1012.3102,
        "authors": "Sergio Pulido",
        "title": "The fundamental theorem of asset pricing, the hedging problem and\n  maximal claims in financial markets with short sales prohibitions",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP914 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 1, 54-75",
        "doi": "10.1214/12-AAP914",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper consists of two parts. In the first part we prove the fundamental\ntheorem of asset pricing under short sales prohibitions in continuous-time\nfinancial models where asset prices are driven by nonnegative, locally bounded\nsemimartingales. A key step in this proof is an extension of a well-known\nresult of Ansel and Stricker. In the second part we study the hedging problem\nin these models and connect it to a properly defined property of \"maximality\"\nof contingent claims.\n"
    },
    {
        "paper_id": 1012.3234,
        "authors": "Tim Siu-Tang Leung and Kazutoshi Yamazaki",
        "title": "American Step-Up and Step-Down Default Swaps under Levy Models",
        "comments": "35 pages, 5 figures",
        "journal-ref": "Quantitative Finance, 13(1): 137-157, 2013",
        "doi": "10.1080/14697688.2012.730624",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the valuation of a class of default swaps with the\nembedded option to switch to a different premium and notional principal anytime\nprior to a credit event. These are early exercisable contracts that give the\nprotection buyer or seller the right to step-up, step-down, or cancel the swap\nposition. The pricing problem is formulated under a structural credit risk\nmodel based on Levy processes. This leads to the analytic and numerical studies\nof several optimal stopping problems subject to early termination due to\ndefault. In a general spectrally negative Levy model, we rigorously derive the\noptimal exercise strategy. This allows for instant computation of the credit\nspread under various specifications. Numerical examples are provided to examine\nthe impacts of default risk and contractual features on the credit spread and\nexercise strategy.\n"
    },
    {
        "paper_id": 1012.4118,
        "authors": "Sergey V. Tsirel, Askar Akaev, Alexey Fomin, Andrey V. Korotayev",
        "title": "Log-Periodic Oscillation Analysis and Possible Burst of the \"Gold\n  Bubble\" in April - June 2011",
        "comments": "15 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This working paper analyzes the gold price dynamics on the basis of\nmethodology developed by Didier Sornette. Our calculations indicate that this\ndynamics is close to the one of the \"bubbles\" studied by Sornette and that the\nmost probable timing of the \"burst of the gold bubble\" is April - June 2011.\nThe obtained result has been additionally checked with two different methods.\nFirst of all, we have compared the pattern of changes of the forecasted timing\nof the gold bubble crash with the retrospective changes of forecasts of the oil\nbubble crash (that took place in July 2008). This comparison indicates that the\nperiod when the timing of the crash tended to change is close to the end, and\nthe burst of the gold bubble is the most probable in May or June 2011.\nSecondly, we used the estimates of critical time for the hyperbolic trend (that\nhas been shown in our previous publications to be typical for many\nsocioeconomic processes). Our calculations with this method also indicate May -\nJune 2011 as the most probable time of the burst of the gold bubble. Naturally,\nthis forecast should not be regarded as an exact prediction as this implies the\nstability of the finance policies of the USA, European Union, and China,\nwhereas a significant intervention of giant players (like the Federal Reserve\nSystem, or the Central Bank of China) could affect the course of the exchange\ngame in a rather significant way. We also analyze possible consequences of the\nburst of the \"gold bubble\".\n"
    },
    {
        "paper_id": 1012.4291,
        "authors": "J. A. Bergstra and C. A. Middelburg",
        "title": "Preliminaries to an investigation of reduced product set finance",
        "comments": "32 pages",
        "journal-ref": "JKAU: Islamic Economics, 24(1):175-210, 2011",
        "doi": "10.4197/Islec.24-1.7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Principles of financial product synthesis from a few basic financial products\nconstitute an interesting research topic inspired by Islamic finance. We make\nan effort to answer general questions that should be answered before starting\nto investigate the main issues concerning this topic with the formalization of\nfinancial products and principles of financial product synthesis. We also\noutline the outcome of some preparatory explorations, which have been conducted\nwith the purpose to form a reasonable preliminary picture of the details of\nfinancial products that are relevant to the study of the principles of\nfinancial product synthesis.\n"
    },
    {
        "paper_id": 1012.4446,
        "authors": "Dirk Helbing and Stefano Balietti",
        "title": "Fundamental and Real-World Challenges in Economics",
        "comments": "16 pages",
        "journal-ref": "Science and Culture, Vol.76, No. 9-10 September-October 2010,\n  Special Issue on 15 Years of Econophysics Research",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the same way as the Hilbert Program was a response to the foundational\ncrisis of mathematics, this article tries to formulate a research program for\nthe socio-economic sciences. The aim of this contribution is to stimulate\nresearch in order to close serious knowledge gaps in mainstream economics that\nthe recent financial and economic crisis has revealed. By identifying weak\npoints of conventional approaches in economics, we identify the scientific\nproblems which need to be addressed. We expect that solving these questions\nwill bring scientists in a position to give better decision support and policy\nadvice. We also indicate, what kinds of insights can be contributed by\nscientists from other research fields such as physics, biology, computer and\nsocial science. In order to make a quick progress and gain a systemic\nunderstanding of the whole interconnected socio-economic-environmental system,\nusing the data, information and computer systems available today and in the\nnear future, we suggest a multi-disciplinary collaboration as most promising\nresearch approach.\n"
    },
    {
        "paper_id": 1012.4674,
        "authors": "Alex Langnau, Daniel Cangemi",
        "title": "Marking Systemic Portfolio Risk with Application to the Correlation Skew\n  of Equity Baskets",
        "comments": "Correlation skew, Systemic Risk, Merton jump model, equity basket",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The downside risk of a portfolio of (equity)assets is generally substantially\nhigher than the downside risk of its components. In particular in times of\ncrises when assets tend to have high correlation, the understanding of this\ndifference can be crucial in managing systemic risk of a portfolio. In this\npaper we generalize Merton's option formula in the presence jumps to the\nmulti-asset case. It is shown how common jumps across assets provide an\nintuitive and powerful tool to describe systemic risk that is consistent with\ndata. The methodology provides a new way to mark and risk-manage systemic risk\nof portfolios in a systematic way.\n"
    },
    {
        "paper_id": 1012.4976,
        "authors": "Christoph Reisinger and Jan Hendrik Witte",
        "title": "On the Use of Policy Iteration as an Easy Way of Pricing American\n  Options",
        "comments": "18 Pages, 1 Figure. This is a substantially extended version, with\n  much more specific results on the behaviour of the algorithm",
        "journal-ref": "SIAM J. Finan. Math. 3(1), 459-478, 2012",
        "doi": "10.1137/110823328",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we demonstrate that policy iteration, introduced in the\ncontext of HJB equations in [Forsyth & Labahn, 2007], is an extremely simple\ngeneric algorithm for solving linear complementarity problems resulting from\nthe finite difference and finite element approximation of American options. We\nshow that, in general, O(N) is an upper and lower bound on the number of\niterations needed to solve a discrete LCP of size N. If embedded in a class of\nstandard discretisations with M time steps, the overall complexity of American\noption pricing is indeed only O(N(M+N)), and, therefore, for M N, identical to\nthe pricing of European options, which is O(MN). We also discuss the numerical\nproperties and robustness with respect to model parameters in relation to\npenalty and projected relaxation methods.\n"
    },
    {
        "paper_id": 1012.5832,
        "authors": "W. Ross Morrow and Steven J. Skerlos",
        "title": "On the Existence of Bertrand-Nash Equilibrium Prices Under Logit Demand",
        "comments": "39 Pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  This article presents a proof of the existence of Bertrand-Nash equilibrium\nprices with multi-product firms and under the Logit model of demand that does\nnot rely on restrictive assumptions on product characteristics, firm\nhomogeneity or symmetry, product costs, or linearity of the utility function.\nThe proof is based on conditions for the indirect utility function, fixed-point\nequations derived from the first-order conditions, and a direct analysis of the\nsecond-order conditions resulting in the uniqueness of profit-maximizing\nprices. Several subsequent results also demonstrate that price equilibrium\nunder the Logit model of demand cannot adequately describe multi-product\npricing.\n"
    },
    {
        "paper_id": 1012.5896,
        "authors": "Abhijit Kar Gupta",
        "title": "Punctuated Equilibrium and Power Law in Economic Dynamics",
        "comments": "7 pages, 3 figs",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An interesting toy model has recently been proposed on Schumpeterian economic\ndynamics by Thurner {\\it et al.} following the idea of economist Joseph\nSchumpeter. Punctuated equilibrium dynamics is shown to emerge from this model\nand some detail analyses of the time series indicate SOC kind of behaviours.\nThe focus in the present work is to toss the idea whether the dynamics can\nreally be like a self organized critical (SOC) type. This study indicates that\nit is necessary to incorporate the concepts of 'fitness' and 'selection' in\nsuch a model in the line of the biological evolutionary model by Bak and\nSneppen in order to obtain power law and thus SOC behaviour.\n"
    },
    {
        "paper_id": 1012.5932,
        "authors": "Juan C. Ferrero",
        "title": "An statistical analysis of stratification and inequity in the income\n  distribution",
        "comments": "22 pages, 3 figures",
        "journal-ref": "The European Physical Journal B, Volume 80, Issue 2, 2011,\n  pp.255-261",
        "doi": "10.1140/epjb/e2011-11018-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The analysis of the USA 2001 income distribution shows that it can be\ndescribed by at least two main components, which obey the generalized Tsallis\nstatistics with different values of the q parameter. Theoretical calculations\nusing the gas kinetics model with a distributed saving propensity factor and\ntwo ensembles reproduce the empirical data and provide further information on\nthe structure of the distribution, which shows a clear stratification. This\nstratification is amenable to different interpretations, which are analyzed.\nThe distribution function is invariant with the average individual income,\nwhich implies that the inequity of the distribution cannot be modified by\nincreasing the total income.\n"
    },
    {
        "paper_id": 1012.5986,
        "authors": "Tetsuya Takaishi",
        "title": "Bayesian estimation of GARCH model with an adaptive proposal density",
        "comments": "10 pages, IDT 2009",
        "journal-ref": "New Advances in Intelligent Decision Technologies, SCI 199, (2009)\n  pp. 635-643",
        "doi": "10.1007/978-3-642-00909-9_61",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A Bayesian estimation of a GARCH model is performed for US Dollar/Japanese\nYen exchange rate by the Metropolis-Hastings algorithm with a proposal density\ngiven by the adaptive construction scheme. In the adaptive construction scheme\nthe proposal density is assumed to take a form of a multivariate Student's\nt-distribution and its parameters are evaluated by using the sampled data and\nupdated adaptively during Markov Chain Monte Carlo simulations. We find that\nthe autocorrelation times between the data sampled by the adaptive construction\nscheme are considerably reduced. We conclude that the adaptive construction\nscheme works efficiently for the Bayesian inference of the GARCH model.\n"
    },
    {
        "paper_id": 1101.0079,
        "authors": "Christoph Moehr",
        "title": "Market-consistent valuation of insurance liabilities by cost of capital",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates market-consistent valuation of insurance liabilities\nin the context of, for instance, Solvency II and to some extent IFRS 4. We\npropose an explicit and consistent framework for the valuation of insurance\nliabilities which incorporates the Solvency II approach as a special case.\n  The proposed framework is based on dynamic replication over multiple\n(one-year) time periods by a portfolio of assets with reliable market prices,\nallowing for \"limited liability\" in the sense that the replication can in\ngeneral not always be continued. The asset portfolio consist of two parts: (1)\nassets whose market price defines the value of the insurance liabilities, and\n(2) capital funds used to cover risk which cannot be replicated. The capital\nfunds give rise to capital costs; the main exogenous input of the framework is\nthe condition on when the investment of the capital funds is acceptable.\n  We investigate existence of the value and show that the exact calculation of\nthe value has to be done recursively backwards in time, starting at the end of\nthe lifetime of the insurance liabilities. The main question only partially\nconsidered in this paper is the uniqueness of the value. We derive upper bounds\non the value and, for the special case of replication by risk-free one-year\nzero-coupon bonds, explicit recursive formulas for calculating the value.\n  Valuation in Solvency II and IFRS 4 is based on representing the value as a\nsum of a \"best estimate\" and a \"risk margin\". In our framework, it turns out\nthat this split is not natural. Nonetheless, we show that a split can be\nconstructed as a simplification, and that it provides an upper bound on the\nvalue under suitable conditions. We illustrate the general results by\nexplicitly calculating the value for a simple example.\n"
    },
    {
        "paper_id": 1101.0184,
        "authors": "David Wakyiku",
        "title": "Testing the Capital Asset Pricing Model (CAPM) on the Uganda Stock\n  Exchange",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the validity of the Capital Asset Pricing Model (CAPM) on\nthe Ugandan stock market using monthly stock returns from 10 of the 11\ncompanies listed on the Uganda Stock Exchange (USE), for the period 1st March\n2007 to 10th November 2009. Due to the absence of readily available Uganda\nStock Exchange(USE) data, and the placement of daily price lists in pdf only,\non the USE website: http://www.use.or.ug, the article also discusses the\nprocedures taken to mine the data needed. The securities were all put in one\nportfolio in order to diversify away the firm-specific part of returns thereby\nenhancing the precision of the beta estimates. This paper should be of interest\nto both Ugandan and non-Ugandan investors and market researchers. While many\ndeveloping countries have legal restrictions against foreign participation in\ncapital and money markets, this is not so in Uganda, where it has become part\nof government policy to encourage foreign capital in flow, inorder to stimulate\nthe development of the small and underdeveloped markets.\n  The Black, Jensen, and Scholes (1972) CAPM version is examined in this\narticle. This version predicts a non zero-beta rate, along with the relation of\nhigher returns to higher risk. The estimated zero-beta rate obtained is not\nstatistically different from zero, and the estimated portfolio beta coefficient\nis statistically significant, providing evidence that the traditional form of\nCAPM holds on the USE, albeit having a beta coefficient that is not good at\nexplaining the relationship between risk and return.\n"
    },
    {
        "paper_id": 1101.024,
        "authors": "Andrew Gordon Wilson, Zoubin Ghahramani",
        "title": "Generalised Wishart Processes",
        "comments": "14 pages, 4 figures, 1 table. Submitted for publication",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a stochastic process with Wishart marginals: the generalised\nWishart process (GWP). It is a collection of positive semi-definite random\nmatrices indexed by any arbitrary dependent variable. We use it to model\ndynamic (e.g. time varying) covariance matrices. Unlike existing models, it can\ncapture a diverse class of covariance structures, it can easily handle missing\ndata, the dependent variable can readily include covariates other than time,\nand it scales well with dimension; there is no need for free parameters, and\noptional parameters are easy to interpret. We describe how to construct the\nGWP, introduce general procedures for inference and predictions, and show that\nit outperforms its main competitor, multivariate GARCH, even on financial data\nthat especially suits GARCH. We also show how to predict the mean of a\nmultivariate process while accounting for dynamic correlations.\n"
    },
    {
        "paper_id": 1101.0446,
        "authors": "Ying Shen, Chuancun Yin, Kam Chuen Yuen",
        "title": "Alternative approach to the optimality of the threshold strategy for\n  spectrally negative Levy processes",
        "comments": "16 pages",
        "journal-ref": "Acta Mathematicae Applicatae Sinica, English Series Vol. 29, No. 4\n  (2013) 705-716",
        "doi": "10.1007/s10255-013-0248-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider the optimal dividend problem for an insurance company whose\nuncontrolled surplus precess evolves as a spectrally negative Levy process. We\nassume that dividends are paid to the shareholders according to admissible\nstrategies whose dividend rate is bounded by a constant. The objective is to\nfind a dividend policy so as to maximize the expected discounted value of\ndividends which are paid to the shareholders until the company is ruined.\nKyprianou, Loeffen and Perez [28] have shown that a refraction strategy (also\ncalled threshold strategy) forms an optimal strategy under the condition that\nthe Levy measure has a completely monotone density. In this paper, we propose\nan alternative approach to this optimal problem.\n"
    },
    {
        "paper_id": 1101.0945,
        "authors": "Paolo Guasoni, Constantinos Kardaras, Scott Robertson, Hao Xing",
        "title": "Abstract, Classic, and Explicit Turnpikes",
        "comments": "36 pages. Revised version. Certain technical conditions on utility\n  have been removed and a new example has been added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Portfolio turnpikes state that, as the investment horizon increases, optimal\nportfolios for generic utilities converge to those of isoelastic utilities.\nThis paper proves three kinds of turnpikes. In a general semimartingale\nsetting, the abstract turnpike states that optimal final payoffs and portfolios\nconverge under their myopic probabilities. In diffusion models with several\nassets and a single state variable, the classic turnpike demonstrates that\noptimal portfolios converge under the physical probability; meanwhile the\nexplicit turnpike identifies the limit of finite-horizon optimal portfolios as\na long-run myopic portfolio defined in terms of the solution of an ergodic HJB\nequation.\n"
    },
    {
        "paper_id": 1101.0975,
        "authors": "Marie Bernhart, Huy\\^en Pham, Peter Tankov and Xavier Warin",
        "title": "Swing Options Valuation: a BSDE with Constrained Jumps Approach",
        "comments": "6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new probabilistic method for solving a class of impulse\ncontrol problems based on their representations as Backward Stochastic\nDifferential Equations (BSDEs for short) with constrained jumps. As an example,\nour method is used for pricing Swing options. We deal with the jump constraint\nby a penalization procedure and apply a discrete-time backward scheme to the\nresulting penalized BSDE with jumps. We study the convergence of this numerical\nmethod, with respect to the main approximation parameters: the jump intensity\n$\\lambda$, the penalization parameter $p > 0$ and the time step. In particular,\nwe obtain a convergence rate of the error due to penalization of order\n$(\\lambda p)^{\\alpha - \\frac{1}{2}}, \\forall \\alpha \\in \\left(0,\n\\frac{1}{2}\\right)$. Combining this approach with Monte Carlo techniques, we\nthen work out the valuation problem of (normalized) Swing options in the Black\nand Scholes framework. We present numerical tests and compare our results with\na classical iteration method.\n"
    },
    {
        "paper_id": 1101.1148,
        "authors": "Winston Buckley and Garfield Brown and Mario Marshall",
        "title": "A Mispricing Model of Stocks Under Asymmetric Information",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend the theory of asymmetric information in mispricing models for\nstocks following geometric Brownian motion to constant relative risk averse\ninvestors. Mispricing follows a continuous mean--reverting Ornstein--Uhlenbeck\nprocess. Optimal portfolios and maximum expected log--linear utilities from\nterminal wealth for informed and uninformed investors are derived. We obtain\nanalogous but more general results which nests those of Guasoni (2006) as a\nspecial case of the relative risk aversion approaching one.\n"
    },
    {
        "paper_id": 1101.1707,
        "authors": "Ricardo Hausmann and Cesar A. Hidalgo",
        "title": "The Network Structure of Economic Output",
        "comments": null,
        "journal-ref": "Journal of Economic Growth (2011) 16:309-342",
        "doi": "10.1007/s10997-011-9071-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Much of the analysis of economic growth has focused on the study of aggregate\noutput. Here, we deviate from this tradition and look instead at the structure\nof output embodied in the network connecting countries to the products that\nthey export.We characterize this network using four structural features: the\nnegative relationship between the diversification of a country and the average\nubiquity of its exports, and the non-normal distributions for product ubiquity,\ncountry diversification and product co-export. We model the structure of the\nnetwork by assuming that products require a large number of non-tradable\ninputs, or capabilities, and that countries differ in the completeness of the\nset of capabilities they have. We solve the model assuming that the probability\nthat a country has a capability and that a product requires a capability are\nconstant and calibrate it to the data to find that it accounts well for all of\nthe network features except for the heterogeneity in the distribution of\ncountry diversification. In the light of the model, this is evidence of a large\nheterogeneity in the distribution of capabilities across countries. Finally, we\nshow that the model implies that the increase in diversification that is\nexpected from the accumulation of a small number of capabilities is small for\ncountries that have a few of them and large for those with many. This implies\nthat the forces that help drive divergence in product diversity increase with\nthe complexity of the global economy when capabilities travel poorly.\n"
    },
    {
        "paper_id": 1101.1847,
        "authors": "M. Cristelli, L. Pietronero, A. Zaccaria",
        "title": "Critical Overview of Agent-Based Models for Economics",
        "comments": "51 pages, 9 figures, Proceedings of the School of Physics \"E. Fermi\",\n  course CLXXVI, 2010, Varenna",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an overview of some representative Agent-Based Models in\nEconomics. We discuss why and how agent-based models represent an important\nstep in order to explain the dynamics and the statistical properties of\nfinancial markets beyond the Classical Theory of Economics. We perform a\nschematic analysis of several models with respect to some specific key\ncategories such as agents' strategies, price evolution, number of agents, etc.\nIn the conclusive part of this review we address some open questions and future\nperspectives and highlight the conceptual importance of some usually neglected\ntopics, such as non-stationarity and the self-organization of financial\nmarkets.\n"
    },
    {
        "paper_id": 1101.2968,
        "authors": "Keita Owari",
        "title": "Duality in Robust Utility Maximization with Unbounded Claim via a Robust\n  Extension of Rockafellar's Theorem",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the convex duality method for robust utility maximization in the\npresence of a random endowment. When the underlying price process is a locally\nbounded semimartingale, we show that the fundamental duality relation holds\ntrue for a wide class of utility functions on the whole real line and unbounded\nrandom endowment. To obtain this duality, we prove a robust version of\nRockafellar's theorem on convex integral functionals and apply Fenchel's\ngeneral duality theorem.\n"
    },
    {
        "paper_id": 1101.3071,
        "authors": "Daniel Sevcovic and Martin Takac",
        "title": "Sensitivity analysis of the early exercise boundary for American style\n  of Asian options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we analyze American style of floating strike Asian call options\nbelonging to the class of financial derivatives whose payoff diagram depends\nnot only on the underlying asset price but also on the path average of\nunderlying asset prices over some predetermined time interval. The mathematical\nmodel for the option price leads to a free boundary problem for a parabolic\npartial differential equation. Applying fixed domain transformation and\ntransformation of variables we develop an efficient numerical algorithm based\non a solution to a non-local parabolic partial differential equation for the\ntransformed variable representing the synthesized portfolio. For various types\nof averaging methods we investigate the dependence of the early exercise\nboundary on model parameters.\n"
    },
    {
        "paper_id": 1101.3107,
        "authors": "Zhenya Yan",
        "title": "Financial Rogue Waves Appearing in the Coupled Nonlinear Volatility and\n  Option Pricing Model",
        "comments": "7 pages, 4 figures",
        "journal-ref": "Phys. Lett. A 375 (2011) 4274 (Changed Title: Vector Financial\n  Rogue Waves)",
        "doi": "10.1016/j.physleta.2011.09.026",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The coupled nonlinear volatility and option pricing model presented recently\nby Ivancevic is investigated, which generates a leverage effect, i.e., stock\nvolatility is (negatively) correlated to stock returns, and can be regarded as\na coupled nonlinear wave alternative of the Black-Scholes option pricing model.\nIn this short report, we analytically propose the two-component financial rogue\nwaves of the coupled nonlinear volatility and option pricing model without an\nembedded w-learning. Moreover, we exhibit their dynamical behaviors for chosen\ndifferent parameters. The two-component financial rogue wave solutions may be\nused to describe the possible physical mechanisms for the rogue wave phenomena\nand to further excite the possibility of relative researches and potential\napplications of rogue waves in the financial markets and other related fields.\n"
    },
    {
        "paper_id": 1101.3228,
        "authors": "Gilles Pag\\`es (PMA), Benedikt Wilbertz (PMA)",
        "title": "GPGPUs in computational finance: Massive parallel computing for American\n  style options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The pricing of American style and multiple exercise options is a very\nchallenging problem in mathematical finance. One usually employs a Least-Square\nMonte Carlo approach (Longstaff-Schwartz method) for the evaluation of\nconditional expectations which arise in the Backward Dynamic Programming\nprinciple for such optimal stopping or stochastic control problems in a\nMarkovian framework. Unfortunately, these Least-Square Monte Carlo approaches\nare rather slow and allow, due to the dependency structure in the Backward\nDynamic Programming principle, no parallel implementation; whether on the Monte\nCarlo levelnor on the time layer level of this problem. We therefore present in\nthis paper a quantization method for the computation of the conditional\nexpectations, that allows a straightforward parallelization on the Monte Carlo\nlevel. Moreover, we are able to develop for AR(1)-processes a further\nparallelization in the time domain, which makes use of faster memory structures\nand therefore maximizes parallel execution. Finally, we present numerical\nresults for a CUDA implementation of this methods. It will turn out that such\nan implementation leads to an impressive speed-up compared to a serial CPU\nimplementation.\n"
    },
    {
        "paper_id": 1101.3422,
        "authors": "E. Bacry, S. Delattre, M. Hoffmann and J.F. Muzy",
        "title": "Modeling microstructure noise with mutually exciting point processes",
        "comments": "31 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new stochastic model for the variations of asset prices at the\ntick-by-tick level in dimension 1 (for a single asset) and 2 (for a pair of\nassets). The construction is based on marked point processes and relies on\nlinear self and mutually exciting stochastic intensities as introduced by\nHawkes. We associate a counting process with the positive and negative jumps of\nan asset price. By coupling suitably the stochastic intensities of upward and\ndownward changes of prices for several assets simultaneously, we can reproduce\nmicrostructure noise (i.e. strong microscopic mean reversion at the level of\nseconds to a few minutes) and the Epps effect (i.e. the decorrelation of the\nincrements in microscopic scales) while preserving a standard Brownian\ndiffusion behaviour on large scales. More effectively, we obtain analytical\nclosed-form formulae for the mean signature plot and the correlation of two\nprice increments that enable to track across scales the effect of the\nmean-reversion up to the diffusive limit of the model. We show that the\ntheoretical results are consistent with empirical fits on futures Euro-Bund and\nEuro-Bobl in several situations.\n"
    },
    {
        "paper_id": 1101.3572,
        "authors": "Alexander M. G. Cox, David Hobson and Jan Obloj",
        "title": "Utility theory front to back - inferring utility from agents' choices",
        "comments": "40 pages, 5 figures; corrected a mistake in a proof of one result and\n  other minor updates",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We pursue an inverse approach to utility theory and consumption & investment\nproblems. Instead of specifying an agent's utility function and deriving her\nactions, we assume we observe her actions (i.e. her consumption and investment\nstrategies) and ask if it is possible to derive a utility function for which\nthe observed behaviour is optimal. We work in continuous time both in a\ndeterministic and stochastic setting. In the deterministic setup, we find that\nthere are infinitely many utility functions generating a given consumption\npattern. In the stochastic setting of the Black-Scholes complete market it\nturns out that the consumption and investment strategies have to satisfy a\nconsistency condition (PDE) if they are to come from a classical utility\nmaximisation problem. We show further that important characteristics of the\nagent such as her attitude towards risk (e.g. DARA) can be deduced directly\nfrom her consumption/investment choices.\n"
    },
    {
        "paper_id": 1101.3617,
        "authors": "Anindya S. Chakrabarti",
        "title": "An almost linear stochastic map related to the particle system models of\n  social sciences",
        "comments": "16 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.06.080",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a stochastic map model of economic dynamics. In the last decade,\nan array of observations in economics has been investigated in the econophysics\nliterature, a major example being the universal features of inequality in terms\nof income and wealth. Another area of inquiry is the formation of opinion in a\nsociety. The proposed model attempts to produce positively skewed distributions\nand the power law distributions as has been observed in the real data of income\nand wealth. Also, it shows a non-trivial phase transition in the opinion of a\nsociety (opinion formation). A number of physical models also generates similar\nresults. In particular, the kinetic exchange models have been especially\nsuccessful in this regard. Therefore, we compare the results obtained from\nthese two approaches and discuss a number of new features and drawbacks of this\nmodel.\n"
    },
    {
        "paper_id": 1101.3713,
        "authors": "Ling Zhi Liang and Damiaan Lemmens and Jacques Tempere",
        "title": "Path integral approach to the pricing of timer options with the\n  Duru-Kleinert time transformation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, a time substitution as used by Duru and Kleinert in their\ntreatment of the hydrogen atom with path integrals is performed to price timer\noptions under stochastic volatility models. We present general pricing formulas\nfor both the perpetual timer call options and the finite time-horizon timer\ncall options. These general results allow us to find closed-form pricing\nformulas for both the perpetual and the finite time-horizon timer options under\nthe 3/2 stochastic volatility model as well as under the Heston stochastic\nvolatility model. For the treatment of timer option under the 3/2 model we will\nrely on the path integral for the Morse potential, with the Heston model we\nwill rely on the Kratzer potential.\n"
    },
    {
        "paper_id": 1101.3926,
        "authors": "Damiano Brigo, Agostino Capponi, Andrea Pallavicini, Vasileios\n  Papatheodorou",
        "title": "Collateral Margining in Arbitrage-Free Counterparty Valuation Adjustment\n  including Re-Hypotecation and Netting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper generalizes the framework for arbitrage-free valuation of\nbilateral counterparty risk to the case where collateral is included, with\npossible re-hypotecation. We analyze how the payout of claims is modified when\ncollateral margining is included in agreement with current ISDA documentation.\nWe then specialize our analysis to interest-rate swaps as underlying portfolio,\nand allow for mutual dependences between the default times of the investor and\nthe counterparty and the underlying portfolio risk factors. We use\narbitrage-free stochastic dynamical models, including also the effect of\ninterest rate and credit spread volatilities. The impact of re-hypotecation, of\ncollateral margining frequency and of dependencies on the bilateral\ncounterparty risk adjustment is illustrated with a numerical example.\n"
    },
    {
        "paper_id": 1101.3974,
        "authors": "Guanghui Huang, Jianping Wan, Cheng Chen",
        "title": "An Active Margin System and its Application in Chinese Margin Lending\n  Market",
        "comments": "27 pages, 2 figures, 5 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In order to protect brokers from customer defaults in a volatile market, an\nactive margin system is proposed for the transactions of margin lending in\nChina. The probability of negative return under the condition that collaterals\nare liquidated in a falling market is used to measure the risk associated with\nmargin loans, and a recursive algorithm is proposed to calculate this\nprobability under a Markov chain model. The optimal maintenance margin ratio\ncan be given under the constraint of the proposed risk measurement for a\nspecified amount of initial margin. An example of such a margin system is\nconstructed and applied to $26,800$ margin loans of 134 stocks traded on the\nShanghai Stock Exchange. The empirical results indicate that the proposed\nmethod is an operational method for brokers to set margin system with a clearly\nspecified target of risk control.\n"
    },
    {
        "paper_id": 1101.4093,
        "authors": "Rui Menezes and Andreia Dioniso",
        "title": "Globalization and long-run co-movements in the stock market for the G7:\n  an application of VECM under structural breaks",
        "comments": "10 pages, 1 figure, 5 tables, submitted to Chinese Science Bulletin",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper analyzes the process of long-run co-movements and stock market\nglobalization on the basis of cointegration tests and vector error correction\n(VEC) models. The cointegration tests used here allow for structural breaks to\nbe explicitly modeled and breakpoints to be computed on a relative-time basis.\nThe data used in our empirical analysis were drawn from Datastream and comprise\nthe natural logarithms of relative stock market indexes since 1973 for the G7\ncountries. The main results point to the conclusion that significant causal\ncointegration effects occur in this context and that there is a long-run\nequilibrium relationship that governs the worldwide process of market\nintegration. Globalization, however, is a complex adjustment process and in\nmany cases there is only evidence of weak market integration which means that\nnon-proportional price transmission occurs in the market along with\nproportional changes. The worldwide markets, as expected, appear to be driven\nin general by the US stock market.\n"
    },
    {
        "paper_id": 1101.4437,
        "authors": "Ph. Barbe (CNRS), W.P. McCormick (UGA)",
        "title": "Ruin probabilities in tough times - Part 1 - Heavy-traffic approximation\n  for fractionally integrated random walks in the domain of attraction of a\n  nonGaussian stable distribution",
        "comments": "52 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by applications to insurance mathematics, we prove some\nheavy-traffic limit theorems for process which encompass the fractionally\nintegrated random walk as well as some FARIMA processes, when the innovations\nare in the domain of attraction of a nonGaussian stable distribution.\n"
    },
    {
        "paper_id": 1101.4548,
        "authors": "Ole Peters and Alexander Adamou",
        "title": "Leverage efficiency",
        "comments": "8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Peters (2011a) defined an optimal leverage which maximizes the time-average\ngrowth rate of an investment held at constant leverage. It was hypothesized\nthat this optimal leverage is attracted to 1, such that, e.g., leveraging an\ninvestment in the market portfolio cannot yield long-term outperformance. This\nplaces a strong constraint on the stochastic properties of prices of traded\nassets, which we call \"leverage efficiency.\" Market conditions that deviate\nfrom leverage efficiency are unstable and may create leverage-driven bubbles.\nHere we expand on the hypothesis and its implications. These include a theory\nof noise that explains how systemic stability rules out smooth price changes at\nany pricing frequency; a resolution of the so-called equity premium puzzle; a\nprotocol for central bank interest rate setting to avoid leverage-driven price\ninstabilities; and a method for detecting fraudulent investment schemes by\nexploiting differences between the stochastic properties of their prices and\nthose of legitimately-traded assets. To submit the hypothesis to a rigorous\ntest we choose price data from different assets: the S&P500 index, Bitcoin,\nBerkshire Hathaway Inc., and Bernard L. Madoff Investment Securities LLC.\nAnalysis of these data supports the hypothesis.\n"
    },
    {
        "paper_id": 1101.4674,
        "authors": "Anca Gheorghiu and Ion Sp\\^anulescu",
        "title": "Macrostate Parameter and Investment Risk Diagrams for 2008 and 2009",
        "comments": "8 pages, 7 figures, 17 references, ENEC 2010, pp.47-54",
        "journal-ref": "ENEC 2010, ISSN 2065-2550",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper are made some considerations of the application of\nphenomenological thermodynamics in risk analysis for the transaction on\nfinancial markets, using the concept of economic entropy and the macrostate\nparameter introduced by us in a previous works [15,16]. The investment risk\ndiagrams for a number of Romanian listed companies in 2008 and 2009 years were\ncalculed. Also, the evolution of the macrostate parameter during financial and\neconomic crisis in Romania are studied.\n"
    },
    {
        "paper_id": 1101.4675,
        "authors": "Anca Gheorghiu, Ion Spanulescu, Anda Gheorghiu",
        "title": "Econophysical Approaches for the Direct Foreign Investments",
        "comments": "14 pages, 5 figures, ENEC 2008",
        "journal-ref": "ENEC 2008, ISSN 2065-2550, pp.25-38",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper will be applied some principles and methods from econophysics\nin the case of the direct foreign investitions (D.F.I.), particularised for the\nGreenfield type, and mixed firms of trade and industrial production (Joint\nVentures). To this aim will be used some similarities and parallelisms between\nthe mentioned economic domains and some phenomena and processes from physics,\nespecially from thermodynamics, solid state physics (the grow of crystals and\nthin policrystalline layers etc.), electromagnetism etc.\n"
    },
    {
        "paper_id": 1101.468,
        "authors": "Ion Spanulescu, Ion Popescu, Victor Stoica, Anca Gheorghiu, Victor\n  Velter",
        "title": "An Econophysics Model for the Stock-Markets' Analysis and Diagnosis",
        "comments": "10 pages, 4 figures, ENEC 2010, pp. 99-108",
        "journal-ref": "ENEC 2010, ISSN 2065-2550",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present an econophysic model for the description of shares\ntransactions in a capital market. For introducing the fundamentals of this\nmodel we used an analogy between the electrical field produced by a system of\ncharges and the overall of economic and financial information of the shares\ntransactions from the stock-markets. An energetic approach of the rate\nvariation for the shares traded on the financial markets was proposed and\nstudied.\n"
    },
    {
        "paper_id": 1101.5475,
        "authors": "St\\'ephane Chr\\'etien and Juan-Pablo Ortega",
        "title": "Multivariate GARCH estimation via a Bregman-proximal trust-region method",
        "comments": "35 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The estimation of multivariate GARCH time series models is a difficult task\nmainly due to the significant overparameterization exhibited by the problem and\nusually referred to as the \"curse of dimensionality\". For example, in the case\nof the VEC family, the number of parameters involved in the model grows as a\npolynomial of order four on the dimensionality of the problem. Moreover, these\nparameters are subjected to convoluted nonlinear constraints necessary to\nensure, for instance, the existence of stationary solutions and the positive\nsemidefinite character of the conditional covariance matrices used in the model\ndesign. So far, this problem has been addressed in the literature only in low\ndimensional cases with strong parsimony constraints. In this paper we propose a\ngeneral formulation of the estimation problem in any dimension and develop a\nBregman-proximal trust-region method for its solution. The Bregman-proximal\napproach allows us to handle the constraints in a very efficient and natural\nway by staying in the primal space and the Trust-Region mechanism stabilizes\nand speeds up the scheme. Preliminary computational experiments are presented\nand confirm the very good performances of the proposed approach.\n"
    },
    {
        "paper_id": 1101.5849,
        "authors": "Masaaki Fujii, Akihiko Takahashi",
        "title": "Derivative Pricing under Asymmetric and Imperfect Collateralization and\n  CVA",
        "comments": "revised, 34 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The importance of collateralization through the change of funding cost is now\nwell recognized among practitioners. In this article, we have extended the\nprevious studies of collateralized derivative pricing to more generic\nsituation, that is asymmetric and imperfect collateralization with the\nassociated counter party credit risk. By introducing the collateral coverage\nratio, our framework can handle these issues in an unified manner. Although the\nresultant pricing formula becomes non-linear FBSDE and cannot be solve exactly,\nthe fist order approximation is provided using Gateaux derivative. We have\nshown that it allows us to decompose the price of generic contract into three\nparts: market benchmark, bilateral credit value adjustment (CVA), and the\ncollateral cost adjustment (CCA) independent from the credit risk. We have\nstudied each term closely, and demonstrated the significant impact of\nasymmetric collateralization through CCA using the numerical examples.\n"
    },
    {
        "paper_id": 1102.0224,
        "authors": "Cassio Neri and Lorenz Schneider",
        "title": "A Family of Maximum Entropy Densities Matching Call Option Prices",
        "comments": "22 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the position of the Buchen-Kelly density in a family of\nentropy maximising densities which all match European call option prices for a\ngiven maturity observed in the market. Using the Legendre transform which links\nthe entropy function and the cumulant generating function, we show that it is\nboth the unique continuous density in this family and the one with the greatest\nentropy. We present a fast root-finding algorithm that can be used to calculate\nthe Buchen-Kelly density, and give upper boundaries for three different\ndiscrepancies that can be used as convergence criteria. Given the call prices,\narbitrage-free digital prices at the same strikes can only move within upper\nand lower boundaries given by left and right call spreads. As the number of\ncall prices increases, these bounds become tighter, and we give two examples\nwhere the densities converge to the Buchen-Kelly density in the sense of\nrelative entropy when we use centered call spreads as proxies for digital\nprices. As pointed out by Breeden and Litzenberger, in the limit a continuous\nset of call prices completely determines the density.\n"
    },
    {
        "paper_id": 1102.0312,
        "authors": "Robert W. Easton",
        "title": "Dynamics of a Service Economy Driven by Random Transactions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Agents buy and sell services. All services are of equal quality. Buyers\nchoose sellers at random. Monetary and fiscal policies are imposed by a central\nbank and a central government. Credit is supplied by a commercial banking\nsystem. Propensities to buy, sell, and lend depend on account balances,\ninterest rates, tax rates and loan default rates. Computer simulations track\nweekly sales, loans, account balances, commercial bank profits, solvency and\ncompliance with reserve requirements, and government debt.\n  The model of this economy is fully specified by a computer program. The\nprogram allows the user to explore the effects of parameter changes. Monetary\nand fiscal policies are implemented by choices of parameters such as interest\nrates and reserve requirements, and government tax and spending rates. Credit\nsupply, consumer confidence, and loan default rates strongly affect the\nbehavior of the economy in terms of sales.\n"
    },
    {
        "paper_id": 1102.0346,
        "authors": "Kasper Larsen, Gordan \\v{Z}itkovi\\'c",
        "title": "On utility maximization under convex portfolio constraints",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP850 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 2, 665-692",
        "doi": "10.1214/12-AAP850",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a utility-maximization problem in a general semimartingale\nfinancial model, subject to constraints on the number of shares held in each\nrisky asset. These constraints are modeled by predictable convex-set-valued\nprocesses whose values do not necessarily contain the origin; that is, it may\nbe inadmissible for an investor to hold no risky investment at all. Such a\nsetup subsumes the classical constrained utility-maximization problem, as well\nas the problem where illiquid assets or a random endowment are present. Our\nmain result establishes the existence of optimal trading strategies in such\nmodels under no smoothness requirements on the utility function. The result\nalso shows that, up to attainment, the dual optimization problem can be posed\nover a set of countably-additive probability measures, thus eschewing the need\nfor the usual finitely-additive enlargement.\n"
    },
    {
        "paper_id": 1102.0683,
        "authors": "Michel Fliess (LIX), C\\'edric Join (INRIA Saclay - Ile de France,\n  CRAN), Fr\\'ed\\'eric Hatt",
        "title": "Volatility made observable at last",
        "comments": null,
        "journal-ref": "3\\`emes Journ\\'ees Identification et Mod\\'elisation\n  Exp\\'erimentale, Douai : France (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Cartier-Perrin theorem, which was published in 1995 and is expressed in\nthe language of nonstandard analysis, permits, for the first time perhaps, a\nclear-cut mathematical definition of the volatility of a financial asset. It\nyields as a byproduct a new understanding of the means of returns, of the beta\ncoefficient, and of the Sharpe and Treynor ratios. New estimation techniques\nfrom automatic control and signal processing, which were already successfully\napplied in quantitative finance, lead to several computer experiments with some\nquite convincing forecasts.\n"
    },
    {
        "paper_id": 1102.0687,
        "authors": "Angelo Carollo, Gabriella Vaglica, Fabrizio Lillo and Rosario N.\n  Mantegna",
        "title": "Trading activity and price impact in parallel markets: SETS vs. off-book\n  market at the London Stock Exchange",
        "comments": "16 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We empirically study the trading activity in the electronic on-book segment\nand in the dealership off-book segment of the London Stock Exchange,\ninvestigating separately the trading of active market members and of other\nmarket participants which are non-members. We find that (i) the volume\ndistribution of off-book transactions has a significantly fatter tail than the\none of on-book transactions, (ii) groups of members and non-members can be\nclassified in categories according to their trading profile (iii) there is a\nstrong anticorrelation between the daily inventory variation of a market member\ndue to the on-book market transactions and inventory variation due to the\noff-book market transactions with non-members, and (iv) the autocorrelation of\nthe sign of the orders of non-members in the off-book market is slowly\ndecaying. We also analyze the on-book price impact function over time, both for\npositive and negative lags, of the electronic trades and of the off-book\ntrades. The unconditional impact curves are very different for the electronic\ntrades and the off-book trades. Moreover there is a small dependence of impact\non the volume for the on-book electronic trades, while the shape and magnitude\nof impact function of off-book transactions strongly depend on volume.\n"
    },
    {
        "paper_id": 1102.0938,
        "authors": "Lisa R. Goldberg, Michael Y. Hayes, Ola Mahmoud",
        "title": "Minimizing Shortfall",
        "comments": null,
        "journal-ref": "Quantitative Finance, iFirst, 1-13, 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper describes an empirical study of shortfall optimization with Barra\nExtreme Risk. We compare minimum shortfall to minimum variance portfolios in\nthe US, UK, and Japanese equity markets using Barra Style Factors (Value,\nGrowth, Momentum, etc.). We show that minimizing shortfall generally improves\nperformance over minimizing variance, especially during down-markets, over the\nperiod 1985-2010. The outperformance of shortfall is due to intuitive tilts\ntowards protective factors like Value, and away from aggressive factors like\nGrowth and Momentum. The outperformance is largest for the shortfall that\nmeasures overall asymmetry rather than the extreme losses.\n"
    },
    {
        "paper_id": 1102.1099,
        "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer",
        "title": "A Copula Approach on the Dynamics of Statistical Dependencies in the US\n  Stock Market",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.06.032",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the statistical dependency structure of the S&P 500 constituents\nin the 4-year period from 2007 to 2010 using intraday data from the New York\nStock Exchange's TAQ database. With a copula-based approach, we find that the\nstatistical dependencies are very strong in the tails of the marginal\ndistributions. This tail dependence is higher than in a bivariate Gaussian\ndistribution, which is implied in the calculation of many correlation\ncoefficients. We compare the tail dependence to the market's average\ncorrelation level as a commonly used quantity and disclose an nearly linear\nrelation.\n"
    },
    {
        "paper_id": 1102.1186,
        "authors": "Berdjane Belkacem, Serguei Pergamenchtchikov (LMRS)",
        "title": "Optimal consumption and investment for markets with random coefficients",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an optimal investment and consumption problem for a Black-Scholes\nfinancial market with stochastic coefficients driven by a diffusion process. We\nassume that an agent makes consumption and investment decisions based on CRRA\nutility functions. The dynamical programming approach leads to an investigation\nof the Hamilton Jacobi Bellman (HJB) equation which is a highly non linear\npartial differential equation (PDE) of the second oder. By using the Feynman -\nKac representation we prove uniqueness and smoothness of the solution.\nMoreover, we study the optimal convergence rate of the iterative numerical\nschemes for both the value function and the optimal portfolio. We show, that in\nthis case, the optimal convergence rate is super geometrical, i.e. is more\nrapid than any geometrical one. We apply our results to a stochastic volatility\nfinancial market.\n"
    },
    {
        "paper_id": 1102.1339,
        "authors": "Leonidas Sandoval Junior and Italo De Paula Franca",
        "title": "Correlation of financial markets in times of crisis",
        "comments": "33 pages, 46 figures",
        "journal-ref": "Physica A 391 (2012) 187--208",
        "doi": "10.1016/j.physa.2011.07.023",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using the eigenvalues and eigenvectors of correlations matrices of some of\nthe main financial market indices in the world, we show that high volatility of\nmarkets is directly linked with strong correlations between them. This means\nthat markets tend to behave as one during great crashes. In order to do so, we\ninvestigate several financial market crises that occurred in the years 1987\n(Black Monday), 1989 (Russian crisis), 2001 (Burst of the dot-com bubble and\nSeptember 11), and 2008 (Subprime Mortgage Crisis), which mark some of the\nlargest downturns of financial markets in the last three decades.\n"
    },
    {
        "paper_id": 1102.1348,
        "authors": "Sylvestre Burgos, M.B. Giles",
        "title": "The computation of Greeks with multilevel Monte Carlo",
        "comments": "Technical Report (December 2010)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the use of the multilevel Monte Carlo technique in the context of\nthe calculation of Greeks. The pathwise sensitivity analysis differentiates the\npath evolution and reduces the payoff's smoothness. This leads to new\nchallenges: the inapplicability of pathwise sensitivities to non-Lipschitz\npayoffs often makes the use of naive algorithms impossible. These challenges\ncan be addressed in three different ways: payoff smoothing using conditional\nexpectations of the payoff before maturity; approximating the previous\ntechnique with path splitting for the final timestep; using of a hybrid\ncombination of pathwise sensitivity and the Likelihood Ratio Method. We\ninvestigate the strengths and weaknesses of these alternatives in different\nmultilevel Monte Carlo settings.\n"
    },
    {
        "paper_id": 1102.1624,
        "authors": "Iacopo Mastromatteo, Matteo Marsili",
        "title": "On the criticality of inferred models",
        "comments": "6 pages, 2 figures, version to appear in JSTAT",
        "journal-ref": "J. Stat. Mech. (2011) P10012",
        "doi": "10.1088/1742-5468/2011/10/P10012",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Advanced inference techniques allow one to reconstruct the pattern of\ninteraction from high dimensional data sets. We focus here on the statistical\nproperties of inferred models and argue that inference procedures are likely to\nyield models which are close to a phase transition. On one side, we show that\nthe reparameterization invariant metrics in the space of probability\ndistributions of these models (the Fisher Information) is directly related to\nthe model's susceptibility. As a result, distinguishable models tend to\naccumulate close to critical points, where the susceptibility diverges in\ninfinite systems. On the other, this region is the one where the estimate of\ninferred parameters is most stable. In order to illustrate these points, we\ndiscuss inference of interacting point processes with application to financial\ndata and show that sensible choices of observation time-scales naturally yield\nmodels which are close to criticality.\n"
    },
    {
        "paper_id": 1102.1713,
        "authors": "J. M. Pellon-Diaz, A. Aragones-Munoz, A. Sandoval-Villalbazo, A.\n  Diaz-Reynoso",
        "title": "Gaussian Noise Effects on the Evolution of Wealth in a Closed System of\n  n-Economies",
        "comments": "7 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on the stochastic model proposed by Patriarca-Kaski-Chakraborti that\ndescribes the exchange of wealth between $n$ economic agents, we analyze the\nevolution of the corresponding economies under the assumption of a Gaussian\nbackground, modeling the exchange parameter $\\epsilon$. We demonstrate, that\nwithin Gaussian noise, the variance of the resulting wealth distribution will\nsignificantly decrease, and the equilibrium state is reached faster than in the\ncase of a uniform distributed $\\epsilon$ parameter. Also, we show that the\nsystem with Gaussian noise strongly resembles a deterministic system which is\nsolved by means of a Z-Transform based technique.\n"
    },
    {
        "paper_id": 1102.1851,
        "authors": "Ivan Kitov, Oleg Kitov",
        "title": "The Australian Phillips curve and more",
        "comments": "25 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A quantitative model is presented linking the rate of inflation and\nunemployment to the change in the level of labor force. The link between the\ninvolved variables is a linear one with all coefficients of individual and\ngeneralized models obtained empirically. To achieve the best fit between\nmeasured and predicted time series cumulative curves are used as a simplified\nversion of the 1-D boundary elements method. All models for Australia are\nsimilar to those obtained for the US, France, Japan and other developed\ncountries and thus validate the concept and related quantitative model.\n"
    },
    {
        "paper_id": 1102.205,
        "authors": "Rosanna Coviello (LAGA), Cristina Di Girolami (ENSTA ParisTech, Luiss\n  Guido Carli), Francesco Russo (ENSTA ParisTech, INRIA Rocquencourt)",
        "title": "On stochastic calculus related to financial assets without\n  semimartingales",
        "comments": null,
        "journal-ref": "Bulletin des Sciences Math\\'ematiques 135 (2011) 733-774",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper does not suppose a priori that the evolution of the price of a\nfinancial asset is a semimartingale. Since possible strategies of investors are\nself-financing, previous prices are forced to be finite quadratic variation\nprocesses. The non-arbitrage property is not excluded if the class\n$\\mathcal{A}$ of admissible strategies is restricted. The classical notion of\nmartingale is replaced with the notion of $\\mathcal{A}$-martingale. A calculus\nrelated to $\\mathcal{A}$-martingales with some examples is developed. Some\napplications to no-arbitrage, viability, hedging and the maximization of the\nutility of an insider are expanded. We finally revisit some no arbitrage\nconditions of Bender-Sottinen-Valkeila type.\n"
    },
    {
        "paper_id": 1102.2138,
        "authors": "Kun Guo (CAS), Wei-Xing Zhou (ECUST), Si-Wei Cheng (CAS), Didier\n  Sornette (ETH Zurich)",
        "title": "The US stock market leads the Federal funds rate and Treasury bond\n  yields",
        "comments": "12 pages, 7 figures, 1 table",
        "journal-ref": "PLoS ONE 6 (8), e22794 (2011)",
        "doi": "10.1371/journal.pone.0022794",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using a recently introduced method to quantify the time varying lead-lag\ndependencies between pairs of economic time series (the thermal optimal path\nmethod), we test two fundamental tenets of the theory of fixed income: (i) the\nstock market variations and the yield changes should be anti-correlated; (ii)\nthe change in central bank rates, as a proxy of the monetary policy of the\ncentral bank, should be a predictor of the future stock market direction. Using\nboth monthly and weekly data, we found very similar lead-lag dependence between\nthe S&P500 stock market index and the yields of bonds inside two groups: bond\nyields of short-term maturities (Federal funds rate (FFR), 3M, 6M, 1Y, 2Y, and\n3Y) and bond yields of long-term maturities (5Y, 7Y, 10Y, and 20Y). In all\ncases, we observe the opposite of (i) and (ii). First, the stock market and\nyields move in the same direction. Second, the stock market leads the yields,\nincluding and especially the FFR. Moreover, we find that the short-term yields\nin the first group lead the long-term yields in the second group before the\nfinancial crisis that started mid-2007 and the inverse relationship holds\nafterwards. These results suggest that the Federal Reserve is increasingly\nmindful of the stock market behavior, seen at key to the recovery and health of\nthe economy. Long-term investors seem also to have been more reactive and\nmindful of the signals provided by the financial stock markets than the Federal\nReserve itself after the start of the financial crisis. The lead of the S&P500\nstock market index over the bond yields of all maturities is confirmed by the\ntraditional lagged cross-correlation analysis.\n"
    },
    {
        "paper_id": 1102.224,
        "authors": "Duan Wang, Boris Podobnik, Davor Horvati\\'c, and H.Eugene Stanley",
        "title": "Quantifying and Modeling Long-Range Cross-Correlations in Multiple Time\n  Series with Applications to World Stock Indices",
        "comments": "Accepted by Phys. Rev. E",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.83.046121",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a modified time lag random matrix theory in order to study time\nlag cross-correlations in multiple time series. We apply the method to 48 world\nindices, one for each of 48 different countries. We find long-range power-law\ncross-correlations in the absolute values of returns that quantify risk, and\nfind that they decay much more slowly than cross-correlations between the\nreturns. The magnitude of the cross-correlations constitute \"bad news\" for\ninternational investment managers who may believe that risk is reduced by\ndiversifying across countries. We find that when a market shock is transmitted\naround the world, the risk decays very slowly. We explain these time lag\ncross-correlations by introducing a global factor model (GFM) in which all\nindex returns fluctuate in response to a single global factor. For each pair of\nindividual time series of returns, the cross-correlations between returns (or\nmagnitudes) can be modeled with the auto-correlations of the global factor\nreturns (or magnitudes). We estimate the global factor using principal\ncomponent analysis, which minimizes the variance of the residuals after\nremoving the global trend. Using random matrix theory, a significant fraction\nof the world index cross-correlations can be explained by the global factor,\nwhich supports the utility of the GFM. We demonstrate applications of the GFM\nin forecasting risks at the world level, and in finding uncorrelated individual\nindices. We find 10 indices are practically uncorrelated with the global factor\nand with the remainder of the world indices, which is relevant information for\nworld managers in reducing their portfolio risk. Finally, we argue that this\ngeneral method can be applied to a wide range of phenomena in which time series\nare measured, ranging from seismology and physiology to atmospheric geophysics.\n"
    },
    {
        "paper_id": 1102.2263,
        "authors": "I. Duarte, D. Pinheiro, A.A. Pinto, S.R. Pliska",
        "title": "Optimal Life Insurance Purchase, Consumption and Investment on a\n  financial market with multi-dimensional diffusive terms",
        "comments": "10 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce an extension to Merton's famous continuous time model of optimal\nconsumption and investment, in the spirit of previous works by Pliska and Ye,\nto allow for a wage earner to have a random lifetime and to use a portion of\nthe income to purchase life insurance in order to provide for his estate, while\ninvesting his savings in a financial market comprised of one risk-free security\nand an arbitrary number of risky securities driven by multi-dimensional\nBrownian motion. We then provide a detailed analysis of the optimal\nconsumption, investment, and insurance purchase strategies for the wage earner\nwhose goal is to maximize the expected utility obtained from his family\nconsumption, from the size of the estate in the event of premature death, and\nfrom the size of the estate at the time of retirement. We use dynamic\nprogramming methods to obtain explicit solutions for the case of discounted\nconstant relative risk aversion utility functions and describe new analytical\nresults which are presented together with the corresponding economic\ninterpretations.\n"
    },
    {
        "paper_id": 1102.2285,
        "authors": "Qingshuo Song",
        "title": "Approximating Functional of Local Martingale Under the Lack of\n  Uniqueness of Black-Scholes PDE",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  When the underlying stock price is a strict local martingale process under an\nequivalent local martingale measure, Black-Scholes PDE associated with an\nEuropean option may have multiple solutions. In this paper, we study an\napproximation for the smallest hedging price of such an European option. Our\nresults show that a class of rebate barrier options can be used for this\napproximation. Among of them, a specific rebate option is also provided with a\ncontinuous rebate function, which corresponds to the unique classical solution\nof the associated parabolic PDE. Such a construction makes existing numerical\nPDE techniques applicable for its computation. An asymptotic convergence rate\nis also studied when the knocked-out barrier moves to infinity under suitable\nconditions.\n"
    },
    {
        "paper_id": 1102.2412,
        "authors": "T. R. Hurd and Zhuowei Zhou",
        "title": "Statistical Inference for Time-changed Brownian Motion Credit Risk\n  Models",
        "comments": "21 pages, 3 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider structural credit modeling in the important special case where\nthe log-leverage ratio of the firm is a time-changed Brownian motion (TCBM)\nwith the time-change taken to be an independent increasing process. Following\nthe approach of Black and Cox, one defines the time of default to be the first\npassage time for the log-leverage ratio to cross the level zero. Rather than\nadopt the classical notion of first passage, with its associated numerical\nchallenges, we accept an alternative notion applicable for TCBMs called \"first\npassage of the second kind\". We demonstrate how statistical inference can be\nefficiently implemented in this new class of models. This allows us to compare\nthe performance of two versions of TCBMs, the variance gamma (VG) model and the\nexponential jump model (EXP), to the Black-Cox model. When applied to a 4.5\nyear long data set of weekly credit default swap (CDS) quotes for Ford Motor\nCo, the conclusion is that the two TCBM models, with essentially one extra\nparameter, can significantly outperform the classic Black-Cox model.\n"
    },
    {
        "paper_id": 1102.2515,
        "authors": "V. Zharkov",
        "title": "Adelic theory of stock market",
        "comments": "10 pages,15 figures, International Workshop \"Perm Winter School\",\n  Russia, Perm, 2011",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The p-adic theory of the stock market is presented. It is shown that the\nprice dynamics is very naturally described by the adelic function. The\nprocedure of derivation of the functional integral formulation of adelic type\nis derived from microscopic models using generalized supercoherent states.\n"
    },
    {
        "paper_id": 1102.262,
        "authors": "Dion Harmon, Marcus A. M. de Aguiar, David D. Chinellato, Dan Braha,\n  Irving R. Epstein and Yaneer Bar-Yam",
        "title": "Predicting economic market crises using measures of collective panic",
        "comments": "17 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Predicting panic is of critical importance in many areas of human and animal\nbehavior, notably in the context of economics. The recent financial crisis is a\ncase in point. Panic may be due to a specific external threat, or\nself-generated nervousness. Here we show that the recent economic crisis and\nearlier large single-day panics were preceded by extended periods of high\nlevels of market mimicry --- direct evidence of uncertainty and nervousness,\nand of the comparatively weak influence of external news. High levels of\nmimicry can be a quite general indicator of the potential for self-organized\ncrises.\n"
    },
    {
        "paper_id": 1102.3009,
        "authors": "Aleksey Kharevsky",
        "title": "Non - Randomness Stock Market Price Model",
        "comments": "8 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new model for the stock market price analysis is proposed. It is suggested\nto look at price as an everywhere discontinuous function of time of bounded\nvariation.\n"
    },
    {
        "paper_id": 1102.315,
        "authors": "Rudi Sch\\\"afer and Alexander F. R. Koivusalo",
        "title": "Dependence of defaults and recoveries in structural credit risk models",
        "comments": "19 pages, 11 figures",
        "journal-ref": "Economic Modelling 30 (2013) 1-9",
        "doi": "10.1016/j.econmod.2012.08.033",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The current research on credit risk is primarily focused on modeling default\nprobabilities. Recovery rates are often treated as an afterthought; they are\nmodeled independently, in many cases they are even assumed constant. This is\ndespite of their pronounced effect on the tail of the loss distribution. Here,\nwe take a step back, historically, and start again from the Merton model, where\ndefaults and recoveries are both determined by an underlying process. Hence,\nthey are intrinsically connected. For the diffusion process, we can derive the\nfunctional relation between expected recovery rate and default probability.\nThis relation depends on a single parameter only. In Monte Carlo simulations we\nfind that the same functional dependence also holds for jump-diffusion and\nGARCH processes. We discuss how to incorporate this structural recovery rate\ninto reduced form models, in order to restore essential structural information\nwhich is usually neglected in the reduced-form approach.\n"
    },
    {
        "paper_id": 1102.3218,
        "authors": "Oleksii Mostovyi",
        "title": "On the Stability the Least Squares Monte Carlo",
        "comments": "9 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider Least Squares Monte Carlo (LSM) algorithm, which is proposed by\nLongstaff and Schwartz (2001) for pricing American style securities. This\nalgorithm is based on the projection of the value of continuation onto a\ncertain set of basis functions via the least squares problem. We analyze the\nstability of the algorithm when the number of exercise dates increases and\nprove that, if the underlying process for the stock price is continuous, then\nthe regression problem is ill-conditioned for small values of the time\nparameter.\n"
    },
    {
        "paper_id": 1102.3534,
        "authors": "Alberto Elices and Eduard Gim\\'enez",
        "title": "Applying hedging strategies to estimate model risk and provision\n  calculation",
        "comments": "32 pages, 9 figures, accepted for publication in Quantitative Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper introduces a relative model risk measure of a product priced with\na given model, with respect to another reference model for which the market is\nassumed to be driven. This measure allows comparing products valued with\ndifferent models (pricing hypothesis) under a homogeneous framework which\nallows concluding which model is the closest to the reference. The relative\nmodel risk measure is defined as the expected shortfall of the hedging strategy\nat a given time horizon for a chosen significance level. The reference model\nhas been chosen to be Heston calibrated to market for a given time horizon\n(this reference model should be chosen to be a market proxy). The method is\napplied to estimate and compare this relative model risk measure under\nvolga-vanna and Black-Scholes models for double-no-touch options and a\nportfolio of forward fader options.\n"
    },
    {
        "paper_id": 1102.3541,
        "authors": "Alberto Elices and Eduard Gim\\'enez",
        "title": "Weighted Monte Carlo: Calibrating the Smile and Preserving Martingale\n  Condition",
        "comments": "6 pages, 6 figures",
        "journal-ref": "Risk Magazine, Vol. 19, No. 5, May 2006",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Weighted Monte Carlo prices exotic options calibrating the probabilities of\npreviously generated paths by a regular Monte Carlo to fit a set of option\npremiums. When only vanilla call and put options and forward prices are\nconsidered, the Martingale condition might not be preserved. This paper shows\nthat this is indeed the case and overcomes the problem by adding additional\nsynthetic options. A robust, fast and easy-to-implement calibration algorithm\nis presented. The results are illustrated with a geometric cliquet option which\nshows how the price impact can be significant.\n"
    },
    {
        "paper_id": 1102.3582,
        "authors": "Gareth W. Peters, Pavel Shevchenko, Mark Young, Wendy Yip",
        "title": "Analytic Loss Distributional Approach Model for Operational Risk from\n  the alpha-Stable Doubly Stochastic Compound Processes and Implications for\n  Capital Allocation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Under the Basel II standards, the Operational Risk (OpRisk) advanced\nmeasurement approach is not prescriptive regarding the class of statistical\nmodel utilised to undertake capital estimation. It has however become well\naccepted to utlise a Loss Distributional Approach (LDA) paradigm to model the\nindividual OpRisk loss process corresponding to the Basel II Business\nline/event type. In this paper we derive a novel class of doubly stochastic\nalpha-stable family LDA models. These models provide the ability to capture the\nheavy tailed loss process typical of OpRisk whilst also providing analytic\nexpressions for the compound process annual loss density and distributions as\nwell as the aggregated compound process annual loss models. In particular we\ndevelop models of the annual loss process in two scenarios. The first scenario\nconsiders the loss process with a stochastic intensity parameter, resulting in\nan inhomogeneous compound Poisson processes annually. The resulting arrival\nprocess of losses under such a model will have independent counts over\nincrements within the year. The second scenario considers discretization of the\nannual loss process into monthly increments with dependent time increments as\ncaptured by a Binomial process with a stochastic probability of success\nchanging annually. Each of these models will be coupled under an LDA framework\nwith heavy-tailed severity models comprised of $\\alpha$-stable severities for\nthe loss amounts per loss event. In this paper we will derive analytic results\nfor the annual loss distribution density and distribution under each of these\nmodels and study their properties.\n"
    },
    {
        "paper_id": 1102.3702,
        "authors": "Olfa Zaafrane and Anouar Ben Mabrouk",
        "title": "A dynamic hybrid model based on wavelets and fuzzy regression for time\n  series estimation",
        "comments": "15 pages, 15 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper, a fuzzy logic based method is combined with wavelet\ndecomposition to develop a step-by-step dynamic hybrid model for the estimation\nof financial time series. Empirical tests on fuzzy regression, wavelet\ndecomposition as well as the new hybrid model are conducted on the well known\n$SP500$ index financial time series. The empirical tests show an efficiency of\nthe hybrid model.\n"
    },
    {
        "paper_id": 1102.3712,
        "authors": "Joanna Janczura, Rafal Weron",
        "title": "Black swans or dragon kings? A simple test for deviations from the power\n  law",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1140/epjst/e2012-01563-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a simple test for deviations from power law tails, which is based\non the asymptotic properties of the empirical distribution function. We use\nthis test to answer the question whether great natural disasters, financial\ncrashes or electricity price spikes should be classified as dragon kings or\n'only' as black swans.\n"
    },
    {
        "paper_id": 1102.3857,
        "authors": "Tzahi Yavin, Hu Zhang, Eugene Wang and Michael A. Clayton",
        "title": "Transition Probability Matrix Methodology for Incremental Risk Charge",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  As part of Basel II's incremental risk charge (IRC) methodology, this paper\nsummarizes our extensive investigations of constructing transition probability\nmatrices (TPMs) for unsecuritized credit products in the trading book. The\nobjective is to create monthly or quarterly TPMs with predefined sectors and\nratings that are consistent with the bank's Basel PDs. Constructing a TPM is\nnot a unique process. We highlight various aspects of three types of\nuncertainties embedded in different construction methods: 1) the available\nhistorical data and the bank's rating philosophy; 2) the merger of one-year\nBasel PD and the chosen Moody's TPMs; and 3) deriving a monthly or quarterly\nTPM when the generator matrix does not exist. Given the fact that TPMs and\nspecifically their PDs are the most important parameters in IRC, it is our view\nthat banks may need to make discretionary choices regarding their methodology,\nwith uncertainties well understood and managed.\n"
    },
    {
        "paper_id": 1102.39,
        "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer, Thomas Guhr",
        "title": "A Random Matrix Approach to Credit Risk",
        "comments": "Fully revised version; 15 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We estimate generic statistical properties of a structural credit risk model\nby considering an ensemble of correlation matrices. This ensemble is set up by\nRandom Matrix Theory. We demonstrate analytically that the presence of\ncorrelations severely limits the effect of diversification in a credit\nportfolio if the correlations are not identically zero. The existence of\ncorrelations alters the tails of the loss distribution considerably, even if\ntheir average is zero. Under the assumption of randomly fluctuating\ncorrelations, a lower bound for the estimation of the loss distribution is\nprovided.\n"
    },
    {
        "paper_id": 1102.3928,
        "authors": "Micha{\\l} Barski",
        "title": "Integral representations of risk functions for basket derivatives",
        "comments": "25 pages",
        "journal-ref": "Applicationes Mathematicae, 2012, 39, 489-514",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The risk minimizing problem\n$\\mathbf{E}[l((H-X_T^{x,\\pi})^{+})]\\overset{\\pi}{\\longrightarrow}\\min$ in the\nmultidimensional Black-Scholes framework is studied. Specific formulas for the\nminimal risk function and the cost reduction function for basket derivatives\nare shown. Explicit integral representations for the risk functions for\n$l(x)=x$ and $l(x)=x^p$, with $p>1$ for digital, quantos, outperformance and\nspread options are derived.\n"
    },
    {
        "paper_id": 1102.3956,
        "authors": "Ph. Barbe (CNRS), W.P. McCormick (UGA)",
        "title": "Ruin probabilities in tough times - Part 2 - Heavy-traffic approximation\n  for fractionally differentiated random walks in the domain of attraction of a\n  nonGaussian stable distribution",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by applications to insurance mathematics, we prove some\nheavy-traffic limit theorems for processes which encompass the fractionally\ndifferentiated random walk as well as some FARIMA processes, when the\ninnovations are in the domain of attraction of a nonGaussian stable\ndistribution.\n"
    },
    {
        "paper_id": 1102.4055,
        "authors": "Ronnie Loeffen, Irmina Czarna, Zbigniew Palmowski",
        "title": "Parisian ruin probability for spectrally negative L\\'{e}vy processes",
        "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ404 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 599-609",
        "doi": "10.3150/11-BEJ404",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note we give, for a spectrally negative Levy process, a compact\nformula for the Parisian ruin probability, which is defined by the probability\nthat the process exhibits an excursion below zero, with a length that exceeds a\ncertain fixed period r. The formula involves only the scale function of the\nspectrally negative Levy process and the distribution of the process at time r.\n"
    },
    {
        "paper_id": 1102.4076,
        "authors": "G. Livan, S. Alfarano, E. Scalas",
        "title": "The fine structure of spectral properties for random correlation\n  matrices: an application to financial markets",
        "comments": "21 pages, 10 figures",
        "journal-ref": "Phys. Rev. E 84, 016113 (2011)",
        "doi": "10.1103/PhysRevE.84.016113",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study some properties of eigenvalue spectra of financial correlation\nmatrices. In particular, we investigate the nature of the large eigenvalue\nbulks which are observed empirically, and which have often been regarded as a\nconsequence of the supposedly large amount of noise contained in financial\ndata. We challenge this common knowledge by acting on the empirical correlation\nmatrices of two data sets with a filtering procedure which highlights some of\nthe cluster structure they contain, and we analyze the consequences of such\nfiltering on eigenvalue spectra. We show that empirically observed eigenvalue\nbulks emerge as superpositions of smaller structures, which in turn emerge as a\nconsequence of cross-correlations between stocks. We interpret and corroborate\nthese findings in terms of factor models, and and we compare empirical spectra\nto those predicted by Random Matrix Theory for such models.\n"
    },
    {
        "paper_id": 1102.4132,
        "authors": "Jinxia Zhu",
        "title": "Optimal dividend control for a generalized risk model with investment\n  incomes and debit interest",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates dividend optimization of an insurance corporation\nunder a more realistic model which takes into consideration refinancing or\ncapital injections. The model follows the compound Poisson framework with\ncredit interest for positive reserve, and debit interest for negative reserve.\nRuin occurs when the reserve drops below the critical value. The company\ncontrols the dividend pay-out dynamically with the objective to maximize the\nexpected total discounted dividends until ruin. We show that that the optimal\nstrategy is a band strategy and it is optimal to pay no dividends when the\nreserve is negative.\n"
    },
    {
        "paper_id": 1102.423,
        "authors": "Deepak Dhar, V. Sasidevan, Bikas K. Chakrabarti",
        "title": "Cooperation amongst competing agents in minority games",
        "comments": "7 pages, 5 eps figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.05.014",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a variation of the minority game. There are N agents. Each has to\nchoose between one of two alternatives everyday, and there is reward to each\nmember of the smaller group. The agents cannot communicate with each other, but\ntry to guess the choice others will make, based only the past history of number\nof people choosing the two alternatives. We describe a simple probabilistic\nstrategy using which the agents acting independently, can still maximize the\naverage number of people benefitting every day. The strategy leads to a very\nefficient utilization of resources, and the average deviation from the maximum\npossible can be made of order $(N^{\\epsilon})$, for any $\\epsilon >0$. We also\nshow that a single agent does not expect to gain by not following the strategy.\n"
    },
    {
        "paper_id": 1102.4489,
        "authors": "Carmine De Franco and Peter Tankov",
        "title": "Portfolio Insurance under a risk-measure constraint",
        "comments": "26 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the problem of portfolio insurance from the point of view of a fund\nmanager, who guarantees to the investor that the portfolio value at maturity\nwill be above a fixed threshold. If, at maturity, the portfolio value is below\nthe guaranteed level, a third party will refund the investor up to the\nguarantee. In exchange for this protection, the third party imposes a limit on\nthe risk exposure of the fund manager, in the form of a convex monetary risk\nmeasure. The fund manager therefore tries to maximize the investor's utility\nfunction subject to the risk measure constraint.We give a full solution to this\nnonconvex optimization problem in the complete market setting and show in\nparticular that the choice of the risk measure is crucial for the optimal\nportfolio to exist. Explicit results are provided for the entropic risk measure\n(for which the optimal portfolio always exists) and for the class of spectral\nrisk measures (for which the optimal portfolio may fail to exist in some\ncases).\n"
    },
    {
        "paper_id": 1102.4722,
        "authors": "Ulrich Kirchner, Caroline Zunckel",
        "title": "Measuring Portfolio Diversification",
        "comments": "9 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the market place, diversification reduces risk and provides protection\nagainst extreme events by ensuring that one is not overly exposed to individual\noccurrences. We argue that diversification is best measured by characteristics\nof the combined portfolio of assets and introduce a measure based on the\ninformation entropy of the probability distribution for the final portfolio\nasset value. For Gaussian assets the measure is a logarithmic function of the\nvariance and combining independent Gaussian assets of equal variance adds an\namount to the diversification. The advantages of this measure include that it\nnaturally extends to any type of distribution and that it takes all moments\ninto account. Furthermore, it can be used in cases of undefined weights\n(zero-cost assets) or moments. We present examples which apply this measure to\nderivative overlays.\n"
    },
    {
        "paper_id": 1102.4819,
        "authors": "Silvio M. Duarte Queiros, Evaldo M. F. Curado, Fernando D. Nobre",
        "title": "Minding impacting events in a model of stochastic variance",
        "comments": "18 pages, 5 figures, 1 table. To published in PLoS one",
        "journal-ref": "PLoS ONE 6(3): e18149 (2011)",
        "doi": "10.1371/journal.pone.0018149",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a generalisation of the well-known ARCH process, widely used for\ngenerating uncorrelated stochastic time series with long-term non-Gaussian\ndistributions and long-lasting correlations in the (instantaneous) standard\ndeviation exhibiting a clustering profile. Specifically, inspired by the fact\nthat in a variety of systems impacting events are hardly forgot, we split the\nprocess into two different regimes: a first one for regular periods where the\naverage volatility of the fluctuations within a certain period of time is below\na certain threshold and another one when the local standard deviation\noutnumbers it. In the former situation we use standard rules for\nheteroscedastic processes whereas in the latter case the system starts\nrecalling past values that surpassed the threshold. Our results show that for\nappropriate parameter values the model is able to provide fat tailed\nprobability density functions and strong persistence of the instantaneous\nvariance characterised by large values of the Hurst exponent is greater than\n0.8, which are ubiquitous features in complex systems.\n"
    },
    {
        "paper_id": 1102.4864,
        "authors": "Alexander F. R. Koivusalo and Rudi Sch\\\"afer",
        "title": "Calibration of structural and reduced-form recovery models",
        "comments": "15 pages",
        "journal-ref": "Journal of Credit Risk 8(4), 31-51 (2012)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In recent years research on credit risk modelling has mainly focused on\ndefault probabilities. Recovery rates are usually modelled independently, quite\noften they are even assumed constant. Then, however, the structural connection\nbetween recovery rates and default probabilities is lost and the tails of the\nloss distribution can be underestimated considerably. The problem of\nunderestimating tail losses becomes even more severe, when calibration issues\nare taken into account. To demonstrate this we choose a Merton-type structural\nmodel as our reference system. Diffusion and jump-diffusion are considered as\nunderlying processes. We run Monte Carlo simulations of this model and\ncalibrate different recovery models to the simulation data. For simplicity, we\ntake the default probabilities directly from the simulation data. We compare a\nreduced-form model for recoveries with a constant recovery approach. In\naddition, we consider a functional dependence between recovery rates and\ndefault probabilities. This dependence can be derived analytically for the\ndiffusion case. We find that the constant recovery approach drastically and\nsystematically underestimates the tail of the loss distribution. The\nreduced-form recovery model shows better results, when all simulation data is\nused for calibration. However, if we restrict the simulation data used for\ncalibration, the results for the reduced-form model deteriorate. We find the\nmost reliable and stable results, when we make use of the functional dependence\nbetween recovery rates and default probabilities.\n"
    },
    {
        "paper_id": 1102.5075,
        "authors": "Traian A Pirvu and Huayue Zhang",
        "title": "Utility Indifference Pricing: A Time Consistent Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the optimal portfolio selection problem in a dynamic\nmulti-period stochastic framework with regime switching. The risk preferences\nare of exponential (CARA) type with an absolute coefficient of risk aversion\nwhich changes with the regime. The market model is incomplete and there are two\nrisky assets: one tradable and one non-tradable. In this context, the optimal\ninvestment strategies are time inconsistent. Consequently, the subgame perfect\nequilibrium strategies are considered. The utility indifference prices of a\ncontingent claim written on the risky assets are computed via an indifference\nvaluation algorithm. By running numerical experiments, we examine how these\nprices vary in response to changes in model parameters.\n"
    },
    {
        "paper_id": 1102.5078,
        "authors": "Yang Li and Traian A Pirvu",
        "title": "On Mean-Variance Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the mean variance portfolio management problem. We\nexamine portfolios which contain both primary and derivative securities. The\nchallenge in this context is due to portfolio's nonlinearities. The delta-gamma\napproximation is employed to overcome it. Thus, the optimization problem is\nreduced to a well posed quadratic program. The methodology developed in this\npaper can be also applied to pricing and hedging in incomplete markets.\n"
    },
    {
        "paper_id": 1102.5126,
        "authors": "Mark Davis and Sebastien Lleo",
        "title": "Jump-Diffusion Risk-Sensitive Asset Management II: Jump-Diffusion Factor\n  Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we extend earlier work on the jump-diffusion risk-sensitive\nasset management problem [SIAM J. Fin. Math. (2011) 22-54] by allowing jumps in\nboth the factor process and the asset prices, as well as stochastic volatility\nand investment constraints. In this case, the HJB equation is a partial\nintegro-differential equation (PIDE). By combining viscosity solutions with a\nchange of notation, a policy improvement argument and classical results on\nparabolic PDEs we prove that the HJB PIDE admits a unique smooth solution. A\nverification theorem concludes the resolution of this problem.\n"
    },
    {
        "paper_id": 1102.5287,
        "authors": "Samuel N. Cohen",
        "title": "Representing filtration consistent nonlinear expectations as\n  $g$-expectations in general probability spaces",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider filtration consistent nonlinear expectations in probability\nspaces satisfying only the usual conditions and separability. Under a\ndomination assumption, we demonstrate that these nonlinear expectations can be\nexpressed as the solutions to Backward Stochastic Differential Equations with\nLipschitz continuous drivers, where both the martingale and the driver terms\nare permitted to jump, and the martingale representation is infinite\ndimensional. To establish this result, we show that this domination condition\nis sufficient to guarantee that the comparison theorem for BSDEs will hold, and\nwe generalise the nonlinear Doob-Meyer decomposition of Peng to a general\ncontext.\n"
    },
    {
        "paper_id": 1102.5405,
        "authors": "Oleg Kitov, Ivan Kitov",
        "title": "Inflation and unemployment in Switzerland: from 1970 to 2050",
        "comments": "21 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An empirical model is presented linking inflation and unemployment rate to\nthe change in the level of labour force in Switzerland. The involved variables\nare found to be cointegrated and we estimate lagged linear deterministic\nrelationships using the method of cumulative curves, a simplified version of\nthe 1D Boundary Elements Method. The model yields very accurate predictions of\nthe inflation rate on a three year horizon. The results are coherent with the\nmodels estimated previously for the US, Japan, France and other developed\ncountries and provide additional validation of our quantitative framework based\nsolely on labour force. Finally, given the importance of inflation forecasts\nfor the Swiss monetary policy, we present a prediction extended into 2050 based\non official projections of the labour force level.\n"
    },
    {
        "paper_id": 1102.5431,
        "authors": "Mohamed Boutahar (GREQAM)",
        "title": "Testing for change in mean of heteroskedastic time series",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider a Lagrange Multiplier-type test (LM) to detect\nchange in the mean of time series with heteroskedasticity of unknown form. We\nderive the limiting distribution under the null, and prove the consistency of\nthe test against the alternative of either an abrupt or smooth changes in the\nmean. We perform also some Monte Carlo simulations to analyze the size\ndistortion and the power of the proposed test. We conclude that for moderate\nsample size, the test has a good performance. We finally carry out an empirical\napplication using the daily closing level of the S&P 500 stock index, in order\nto illustrate the usefulness of the proposed test.\n"
    },
    {
        "paper_id": 1102.5457,
        "authors": "J. Doyne Farmer, Austin Gerig, Fabrizio Lillo, and Henri Waelbroeck",
        "title": "How efficiency shapes market impact",
        "comments": "34 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a theory for the market impact of large trading orders, which we\ncall metaorders because they are typically split into small pieces and executed\nincrementally. Market impact is empirically observed to be a concave function\nof metaorder size, i.e., the impact per share of large metaorders is smaller\nthan that of small metaorders. We formulate a stylized model of an algorithmic\nexecution service and derive a fair pricing condition, which says that the\naverage transaction price of the metaorder is equal to the price after trading\nis completed. We show that at equilibrium the distribution of trading volume\nadjusts to reflect information, and dictates the shape of the impact function.\nThe resulting theory makes empirically testable predictions for the functional\nform of both the temporary and permanent components of market impact. Based on\nthe commonly observed asymptotic distribution for the volume of large trades,\nit says that market impact should increase asymptotically roughly as the square\nroot of metaorder size, with average permanent impact relaxing to about two\nthirds of peak impact.\n"
    },
    {
        "paper_id": 1102.5501,
        "authors": "Jocelyne Bion-Nadal and Giulia Di Nunno",
        "title": "Extension theorems for linear operators on $L_\\infty$ and application to\n  price systems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an $L_\\infty$-framework, we present a few extension theorems for linear\noperators. We focus the attention on majorant preserving and sandwich\npreserving types of extensions. These results are then applied to the study of\nprice systems derived by a reasonable restriction of the class of equivalent\nmartingale measures applicable. First we consider equivalent martingale\nmeasures with bounds on densities and the corresponding prices bounded by\nlinear minorant and majorant. Then we consider prices bounded by bid-ask\ndynamics. Finally we study price systems consistent with no-good-deal pricing\nmeasures for given bounds on the Sharpe ratio. Within this study we introduce\nthe definition of dynamic no-good-deal pricing measure.\n"
    },
    {
        "paper_id": 1102.5525,
        "authors": "Mikhail Martynov, Olga Rozanova",
        "title": "Arbitrage hedging strategy and one more explanation of the volatility\n  smile",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an explicit hedging strategy, which enables to prove arbitrageness\nof market incorporating at least two assets depending on the same random\nfactor. The implied Black-Scholes volatility, computed taking into account the\nform of the graph of the option price, related to our strategy, demonstrates\nthe \"skewness\" inherent to the observational data.\n"
    },
    {
        "paper_id": 1102.5665,
        "authors": "William T. Shaw",
        "title": "Risk, VaR, CVaR and their associated Portfolio Optimizations when Asset\n  Returns have a Multivariate Student T Distribution",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show how to reduce the problem of computing VaR and CVaR with Student T\nreturn distributions to evaluation of analytical functions of the moments. This\nallows an analysis of the risk properties of systems to be carefully attributed\nbetween choices of risk function (e.g. VaR vs CVaR); choice of return\ndistribution (power law tail vs Gaussian) and choice of event frequency, for\nrisk assessment. We exploit this to provide a simple method for portfolio\noptimization when the asset returns follow a standard multivariate T\ndistribution. This may be used as a semi-analytical verification tool for more\ngeneral optimizers, and for practical assessment of the impact of fat tails on\nasset allocation for shorter time horizons.\n"
    },
    {
        "paper_id": 1102.5747,
        "authors": "Corina-Maria Ene, Anda Gheorghiu, Cristina Burghelea, Anca Gheorghiu",
        "title": "The Conflict between Economic Development and Planetary Ecosystem in the\n  Context of Sustainable Development",
        "comments": "6 pages, 8 figures, 6-th IASME/WSEAS International Conference on\n  Energy & Environment (EE'11), Cambridge, 2011",
        "journal-ref": "6-th IASME/WSEAS International Conference on Energy & Environment\n  (EE'11), Cambridge, UK, February 23-25, 2011,ISSN 1792-8230,ISBN\n  978-960-474-274-5, pp. 266-271",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The green area of economy is the key of healthy living. It is necessary to\nconvene economic and ecologic framework to establish a market attentive to\ndrastic reduction of emissions damaging our climate and landscapes in rural\nareas, to the protection of biological diversity of the planet, to stop\nproducing nuclear waste, etc. This paper tries to demonstrate human concern for\na waste recycling economy that will provide new jobs, will create economic and\nsocial stability and will ensure a healthier and cleaner environment. Green\nEconomy and its support system (planetary ecosystem) won't be in conflict\nanymore. Green Economy will be able to support economic progress for future.\n"
    },
    {
        "paper_id": 1102.5752,
        "authors": "Corina-Maria Ene, Anda Gheorghiu, Anca Gheorghiu",
        "title": "A Theoretical Approach for Dynamic Modelling of Sustainable Development",
        "comments": "5 pages, 3 figures, 6th IASME/WSEAS International Conference on\n  Energy and Environment (EE'11), Cambridge, UK, February 23-25, 2011",
        "journal-ref": "6th IASME/WSEAS International Conference on Energy and Environment\n  (EE'11), Cambridge, UK, February 23-25, 2011, ISSN 1792-8230, ISBN\n  978-960-474-274-5, pp. 261-265",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article presents a theoretical model for a dynamic system based on\nsustainable development. Due to the relatively absence of theoretical studies\nand practical issues in the area of sustainable development, Romania aspires to\nthe principles of sustainable development. Based on the concept as a process in\nwhich economic, social, political and natural environment are combined in order\nto sustain planet management, our goal is to promote an economic tool for\nRomanian decision-makers in order to evaluate scenarios and planning options.\n"
    },
    {
        "paper_id": 1103.0606,
        "authors": "Xiaolin Luo and Pavel V. Shevchenko",
        "title": "Bayesian Model Choice of Grouped t-copula",
        "comments": null,
        "journal-ref": "Methodology and Computing in Applied Probability. 14(4) 1097-1119",
        "doi": "10.1007/s11009-011-9220-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One of the most popular copulas for modeling dependence structures is\nt-copula. Recently the grouped t-copula was generalized to allow each group to\nhave one member only, so that a priori grouping is not required and the\ndependence modeling is more flexible. This paper describes a Markov chain Monte\nCarlo (MCMC) method under the Bayesian inference framework for estimating and\nchoosing t-copula models. Using historical data of foreign exchange (FX) rates\nas a case study, we found that Bayesian model choice criteria overwhelmingly\nfavor the generalized t-copula. In addition, all the criteria also agree on the\nsecond most likely model and these inferences are all consistent with classical\nlikelihood ratio tests. Finally, we demonstrate the impact of model choice on\nthe conditional Value-at-Risk for portfolios of six major FX rates.\n"
    },
    {
        "paper_id": 1103.0647,
        "authors": "Enrico Scalas",
        "title": "A class of CTRWs: Compound fractional Poisson processes",
        "comments": "23 pages. To be published in a World Scientific book edited by Ralf\n  Metzler",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This chapter is an attempt to present a mathematical theory of compound\nfractional Poisson processes. The chapter begins with the characterization of a\nwell-known L\\'evy process: The compound Poisson process. The semi-Markov\nextension of the compound Poisson process naturally leads to the compound\nfractional Poisson process, where the Poisson counting process is replaced by\nthe Mittag-Leffler counting process also known as fractional Poisson process.\nThis process is no longer Markovian and L\\'evy. However, several analytical\nresults are available and some of them are discussed here. The functional limit\nof the compound Poisson process is an $\\alpha$-stable L\\'evy process, whereas\nin the case of the compound fractional Poisson process, one gets an\n$\\alpha$-stable L\\'evy process subordinated to the fractional Poisson process.\n"
    },
    {
        "paper_id": 1103.0717,
        "authors": "Jo\\~ao P. da Cruz and Pedro G. Lind",
        "title": "The dynamics of financial stability in complex networks",
        "comments": null,
        "journal-ref": "Eur. Phys. J. B (2012) 85: 256",
        "doi": "10.1140/epjb/e2012-20984-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We address the problem of banking system resilience by applying\noff-equilibrium statistical physics to a system of particles, representing the\neconomic agents, modelled according to the theoretical foundation of the\ncurrent banking regulation, the so called Merton-Vasicek model. Economic agents\nare attracted to each other to exchange `economic energy', forming a network of\ntrades. When the capital level of one economic agent drops below a minimum, the\neconomic agent becomes insolvent. The insolvency of one single economic agent\naffects the economic energy of all its neighbours which thus become susceptible\nto insolvency, being able to trigger a chain of insolvencies (avalanche). We\nshow that the distribution of avalanche sizes follows a power-law whose\nexponent depends on the minimum capital level. Furthermore, we present evidence\nthat under an increase in the minimum capital level, large crashes will be\navoided only if one assumes that agents will accept a drop in business levels,\nwhile keeping their trading attitudes and policies unchanged. The alternative\nassumption, that agents will try to restore their business levels, may lead to\nthe unexpected consequence that large crises occur with higher probability.\n"
    },
    {
        "paper_id": 1103.0893,
        "authors": "Gregor Wergen, Miro Bogner and Joachim Krug",
        "title": "Record statistics for biased random walks, with an application to\n  financial data",
        "comments": "16 pages, 7 figures",
        "journal-ref": "Phys. Rev. E 83, 051109 (2011)",
        "doi": "10.1103/PhysRevE.83.051109",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the occurrence of record-breaking events in random walks with\nasymmetric jump distributions. The statistics of records in symmetric random\nwalks was previously analyzed by Majumdar and Ziff and is well understood.\nUnlike the case of symmetric jump distributions, in the asymmetric case the\nstatistics of records depends on the choice of the jump distribution. We\ncompute the record rate $P_n(c)$, defined as the probability for the $n$th\nvalue to be larger than all previous values, for a Gaussian jump distribution\nwith standard deviation $\\sigma$ that is shifted by a constant drift $c$. For\nsmall drift, in the sense of $c/\\sigma \\ll n^{-1/2}$, the correction to\n$P_n(c)$ grows proportional to arctan$(\\sqrt{n})$ and saturates at the value\n$\\frac{c}{\\sqrt{2} \\sigma}$. For large $n$ the record rate approaches a\nconstant, which is approximately given by\n$1-(\\sigma/\\sqrt{2\\pi}c)\\textrm{exp}(-c^2/2\\sigma^2)$ for $c/\\sigma \\gg 1$.\nThese asymptotic results carry over to other continuous jump distributions with\nfinite variance. As an application, we compare our analytical results to the\nrecord statistics of 366 daily stock prices from the Standard & Poors 500\nindex. The biased random walk accounts quantitatively for the increase in the\nnumber of upper records due to the overall trend in the stock prices, and after\ndetrending the number of upper records is in good agreement with the symmetric\nrandom walk. However the number of lower records in the detrended data is\nsignificantly reduced by a mechanism that remains to be identified.\n"
    },
    {
        "paper_id": 1103.0894,
        "authors": "Fuzhou Gong, Hong Liu",
        "title": "Inside Trading, Public Disclosure and Imperfect Competition",
        "comments": "35 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present a multi-period trading model in the style of Kyle\n(1985)'s inside trading model, by assuming that there are at least two insiders\nin the market with long-lived private information, under the requirement that\neach insider publicly discloses his stock trades after the fact. Based on this\nmodel, we study the influences of \"public disclosure\" and \"competition among\ninsiders\" on the trading behaviors of insiders. We find that the \"competition\namong insiders\" leads to higher effective price and lower insiders' profits,\nand the \"public disclosure\" makes each insider play a mixed strategy in every\nround except the last one. An interesting find is that as the total number of\nauctions goes to infinity, the market depth and the trading intensity at the\nfirst auction are all constants with the requirement of \"public disclosure\",\nwhile the market depth at the first auction goes to zero and the trading\nintensity of the first period goes to infinity without the requirement of\n\"public disclosure\".Moreover, we give the exact speed of the revelation of the\nprivate information, and show that all information is revealed immediately and\nthe market depth goes to infinity immediately as trading happens infinitely\nfrequently.\n"
    },
    {
        "paper_id": 1103.1006,
        "authors": "Alexander Alvarez, Sebastian Ferrando and Pablo Olivares (Ryerson\n  University, Toronto)",
        "title": "Arbitrage and Hedging in a non probabilistic framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper studies the concepts of hedging and arbitrage in a non\nprobabilistic framework. It provides conditions for non probabilistic arbitrage\nbased on the topological structure of the trajectory space and makes\nconnections with the usual notion of arbitrage. Several examples illustrate the\nnon probabilistic arbitrage as well perfect replication of options under\ncontinuous and discontinuous trajectories, the results can then be applied in\nprobabilistic models path by path. The approach is related to recent financial\nmodels that go beyond semimartingales, we remark on some of these connections\nand provide applications of our results to some of these models.\n"
    },
    {
        "paper_id": 1103.105,
        "authors": "Yuanyuan Sui and Helin Wu",
        "title": "Inf-convolution of g_\\Gamma-solution and its applications",
        "comments": "arXiv admin note: text overlap with arXiv:1011.1976",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A risk-neutral method is always used to price and hedge contingent claims in\ncomplete market, but another method based on utility maximization or risk\nminimization is wildly used in more general case. One can find all kinds of\nspecial risk measure in literature. In this paper, instead of using market\nmodified risk measure, we use a kind of risk measure induced by\ng_\\Gamma-solution or the minimal solution of a Constrained Backward Stochastic\nDifferential Equation (CBSDE) directly when constraints on wealth and portfolio\nprocess comes to our consideration. Such g_\\Gamma-solution and the risk measure\ngenerated by it is well defined on appropriate space under suitable conditions.\nWe adopt the inf-convolution of convex risk measures to solve some optimization\nproblem. A dynamic version risk measures defined through g_\\Gamma-solution and\nsome similar results about optimal problem can be got in our new framework and\nby our new approach.\n"
    },
    {
        "paper_id": 1103.1165,
        "authors": "Yan Dolinsky",
        "title": "Hedging of Game Options With the Presence of Transaction Costs",
        "comments": "22 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the problem of super-replication for game options under proportional\ntransaction costs. We consider a multidimensional continuous time model, in\nwhich the discounted stock price process satisfies the conditional full support\nproperty. We show that the super-replication price is the cheapest cost of a\ntrivial super-replication strategy. This result is an extension of previous\npapers (see [3] and [7]) which considered only European options. In these\npapers the authors showed that with the presence of proportional transaction\ncosts the super--replication price of a European option is given in terms of\nthe concave envelope of the payoff function. In the present work we prove that\nfor game options the super-replication price is given by a game variant analog\nof the standard concave envelope term. The treatment of game options is more\ncomplicated and requires additional tools. We combine the theory of consistent\nprice systems together with the theory of extended weak convergence which was\ndeveloped in [1]. The second theory is essential in dealing with hedging which\ninvolves stopping times, like in the case of game options.\n"
    },
    {
        "paper_id": 1103.1243,
        "authors": "Tiziano Squartini, Giorgio Fagiolo, Diego Garlaschelli",
        "title": "Randomizing world trade. I. A binary network analysis",
        "comments": "See also the companion paper (part II): arXiv:1103.1249\n  [physics.soc-ph], published as Phys. Rev. E 84, 046118 (2011)",
        "journal-ref": "Phys. Rev. E 84, 046117 (2011)",
        "doi": "10.1103/PhysRevE.84.046117",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The international trade network (ITN) has received renewed multidisciplinary\ninterest due to recent advances in network theory. However, it is still unclear\nwhether a network approach conveys additional, nontrivial information with\nrespect to traditional international-economics analyses that describe world\ntrade only in terms of local (first-order) properties. In this and in a\ncompanion paper, we employ a recently proposed randomization method to assess\nin detail the role that local properties have in shaping higher-order patterns\nof the ITN in all its possible representations (binary/weighted,\ndirected/undirected, aggregated/disaggregated by commodity) and across several\nyears. Here we show that, remarkably, the properties of all binary projections\nof the network can be completely traced back to the degree sequence, which is\ntherefore maximally informative. Our results imply that explaining the observed\ndegree sequence of the ITN, which has not received particular attention in\neconomic theory, should instead become one the main focuses of models of trade.\n"
    },
    {
        "paper_id": 1103.1249,
        "authors": "Tiziano Squartini, Giorgio Fagiolo, Diego Garlaschelli",
        "title": "Randomizing world trade. II. A weighted network analysis",
        "comments": "See also the companion paper (Part I): arXiv:1103.1243\n  [physics.soc-ph], published as Phys. Rev. E 84, 046117 (2011)",
        "journal-ref": "Phys. Rev. E 84, 046118 (2011)",
        "doi": "10.1103/PhysRevE.84.046118",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on the misleading expectation that weighted network properties always\noffer a more complete description than purely topological ones, current\neconomic models of the International Trade Network (ITN) generally aim at\nexplaining local weighted properties, not local binary ones. Here we complement\nour analysis of the binary projections of the ITN by considering its weighted\nrepresentations. We show that, unlike the binary case, all possible weighted\nrepresentations of the ITN (directed/undirected, aggregated/disaggregated)\ncannot be traced back to local country-specific properties, which are therefore\nof limited informativeness. Our two papers show that traditional macroeconomic\napproaches systematically fail to capture the key properties of the ITN. In the\nbinary case, they do not focus on the degree sequence and hence cannot\ncharacterize or replicate higher-order properties. In the weighted case, they\ngenerally focus on the strength sequence, but the knowledge of the latter is\nnot enough in order to understand or reproduce indirect effects.\n"
    },
    {
        "paper_id": 1103.146,
        "authors": "Aleksandar Mijatovic and Martijn R. Pistorius",
        "title": "On the drawdown of completely asymmetric Levy processes",
        "comments": "applications added, 26 pages, 3 figures, to appear in SPA",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The {\\em drawdown} process $Y$ of a completely asymmetric L\\'{e}vy process\n$X$ is equal to $X$ reflected at its running supremum $\\bar{X}$: $Y = \\bar{X} -\nX$. In this paper we explicitly express in terms of the scale function and the\nL\\'{e}vy measure of $X$ the law of the sextuple of the first-passage time of\n$Y$ over the level $a>0$, the time $\\bar{G}_{\\tau_a}$ of the last supremum of\n$X$ prior to $\\tau_a$, the infimum $\\unl X_{\\tau_a}$ and supremum $\\ovl\nX_{\\tau_a}$ of $X$ at $\\tau_a$ and the undershoot $a - Y_{\\tau_a-}$ and\novershoot $Y_{\\tau_a}-a$ of $Y$ at $\\tau_a$. As application we obtain explicit\nexpressions for the laws of a number of functionals of drawdowns and rallies in\na completely asymmetric exponential L\\'{e}vy model.\n"
    },
    {
        "paper_id": 1103.1501,
        "authors": "Ricardo Lopez-Ruiz, Jose-Luis Lopez, Xavier Calbet",
        "title": "Exponential wealth distribution: a new approach from functional\n  iteration theory",
        "comments": "6 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Exponential distribution is ubiquitous in the framework of multi-agent\nsystems. Usually, it appears as an equilibrium state in the asymptotic time\nevolution of statistical systems. It has been explained from very different\nperspectives. In statistical physics, it is obtained from the principle of\nmaximum entropy. In the same context, it can also be derived without any\nconsideration about information theory, only from geometrical arguments under\nthe hypothesis of equiprobability in phase space. Also, several multi-agent\neconomic models based on mappings, with random, deterministic or chaotic\ninteractions, can give rise to the asymptotic appearance of the exponential\nwealth distribution. An alternative approach to this problem in the framework\nof iterations in the space of distributions has been recently presented.\nConcretely, the new iteration given by $ f_{n+1}(x) =\n\\int\\int_{u+v>x}{f_n(u)f_n(v)\\over u+v} dudv.$. It is found that the\nexponential distribution is a stable fixed point of the former functional\niteration equation. From this point of view, it is easily understood why the\nexponential wealth distribution (or by extension, other kind of distributions)\nis asymptotically obtained in different multi-agent economic models.\n"
    },
    {
        "paper_id": 1103.1526,
        "authors": "Fei Ren and Wei-Xing Zhou",
        "title": "Analysis of trade packages in Chinese stock market",
        "comments": "23 pages, 5 figures, 8 tables",
        "journal-ref": "Quantitative Finance 13 (7), 1071-1089 (2013)",
        "doi": "10.1080/14697688.2013.765957",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper conducts an empirically study on the trade package composed of a\nsequence of consecutive purchases or sales of 23 stocks in Chinese stock\nmarket. We investigate the probability distributions of the execution time, the\nnumber of trades and the total trading volume of trade packages, and analyze\nthe possible scaling relations between them. Quantitative differences are\nobserved between the institutional and individual investors. The trading\nprofile of trade packages is investigated to reveal the preference of large\ntrades on trading volumes and transaction time of the day, and the different\nprofiles of two types of investors imply that institutions may be more informed\nthan individuals. We further analyze the price impacts of both the entire trade\npackages and the individual transactions inside trade packages. We find the\nprice impact of trade packages is nonnegligible over the period of the\nexecution time and it may have a power-law relation with the total trading\nvolume. The price impact of the transactions inside trade packages displays a\nU-shaped profile with respect to the time $t$ of the day, and also shows a\npower-law dependence on their trading volumes. The trading volumes of the\ntransactions inside trade packages made by institutions have a stronger impact\non current returns, but the following price reversals persist over a relatively\nshorter horizon in comparison with those by individuals.\n"
    },
    {
        "paper_id": 1103.1652,
        "authors": "Larry Epstein and Shaolin Ji",
        "title": "Ambiguous Volatility, Possibility and Utility in Continuous Time",
        "comments": "39 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper formulates a model of utility for a continuous time framework that\ncaptures the decision-maker's concern with ambiguity about both the drift and\nvolatility of the driving process. At a technical level, the analysis requires\na significant departure from existing continuous time modeling because it\ncannot be done within a probability space framework. This is because ambiguity\nabout volatility leads invariably to a set of nonequivalent priors, that is, to\npriors that disagree about which scenarios are possible.\n"
    },
    {
        "paper_id": 1103.1689,
        "authors": "Jos\\'e Bento and Morteza Ibrahimi and Andrea Montanari",
        "title": "Information Theoretic Limits on Learning Stochastic Differential\n  Equations",
        "comments": "6 pages, 2 figures, conference version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider the problem of learning the drift coefficient of a stochastic\ndifferential equation from a sample path. In this paper, we assume that the\ndrift is parametrized by a high dimensional vector. We address the question of\nhow long the system needs to be observed in order to learn this vector of\nparameters. We prove a general lower bound on this time complexity by using a\ncharacterization of mutual information as time integral of conditional\nvariance, due to Kadota, Zakai, and Ziv. This general lower bound is applied to\nspecific classes of linear and non-linear stochastic differential equations. In\nthe linear case, the problem under consideration is the one of learning a\nmatrix of interaction coefficients. We evaluate our lower bound for ensembles\nof sparse and dense random matrices. The resulting estimates match the\nqualitative behavior of upper bounds achieved by computationally efficient\nprocedures.\n"
    },
    {
        "paper_id": 1103.1729,
        "authors": "Damir Filipovi\\'c, Robert Kremslehner, Alexander Muermann",
        "title": "Optimal Investment and Premium Policies under Risk Shifting and Solvency\n  Regulation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Limited liability creates a conflict of interests between policyholders and\nshareholders of insurance companies. It provides shareholders with incentives\nto increase the risk of the insurer's assets and liabilities which, in turn,\nmight reduce the value policyholders attach to and premiums they are willing to\npay for insurance coverage. We characterize Pareto optimal investment and\npremium policies in this context and provide necessary and sufficient\nconditions for their existence and uniqueness. We then identify investment and\npremium policies under the risk shifting problem if shareholders cannot\ncredibly commit to an investment strategy before policies are sold and premiums\nare paid. Last, we analyze the effect of solvency regulation, such as Solvency\nII or the Swiss Solvency Test, on the agency cost of the risk shifting problem\nand calibrate our model to a non-life insurer average portfolio.\n"
    },
    {
        "paper_id": 1103.1755,
        "authors": "Zuo Quan Xu, Xun Yu Zhou",
        "title": "Optimal stopping under probability distortion",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP838 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 1, 251-282",
        "doi": "10.1214/11-AAP838",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We formulate an optimal stopping problem for a geometric Brownian motion\nwhere the probability scale is distorted by a general nonlinear function. The\nproblem is inherently time inconsistent due to the Choquet integration\ninvolved. We develop a new approach, based on a reformulation of the problem\nwhere one optimally chooses the probability distribution or quantile function\nof the stopped state. An optimal stopping time can then be recovered from the\nobtained distribution/quantile function, either in a straightforward way for\nseveral important cases or in general via the Skorokhod embedding. This\napproach enables us to solve the problem in a fairly general manner with\ndifferent shapes of the payoff and probability distortion functions. We also\ndiscuss economical interpretations of the results. In particular, we justify\nseveral liquidation strategies widely adopted in stock trading, including those\nof \"buy and hold\", \"cut loss or take profit\", \"cut loss and let profit run\" and\n\"sell on a percentage of historical high\".\n"
    },
    {
        "paper_id": 1103.1992,
        "authors": "Leonidas Sandoval Junior and Italo De Paula Franca",
        "title": "Shocks in financial markets, price expectation, and damped harmonic\n  oscillators",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using a modified damped harmonic oscillator model equivalent to a model of\nmarket dynamics with price expectations, we analyze the reaction of financial\nmarkets to shocks. In order to do this, we gather data from indices of a\nvariety of financial markets for the 1987 Black Monday, the Russian crisis of\n1998, the crash after September 11th (2001), and the recent downturn of markets\ndue to the subprime mortgage crisis in the USA (2008). Analyzing those data we\nwere able to establish the amount by which each market felt the shocks, a\ndampening factor which expresses the capacity of a market of absorving a shock,\nand also a frequency related with volatility after the shock. The results gauge\nthe efficiency of different markets in recovering from such shocks, and measure\nsome level of dependence between them. We also show, using the correlation\nmatrices between the indices used, that financial markets are now much more\nconnected than they were two decades ago.\n"
    },
    {
        "paper_id": 1103.2001,
        "authors": "D. D. Han, J. H. Qian, Y. G. Ma",
        "title": "Emergence of double scaling law in complex system",
        "comments": "6 pages, 6 figures, 2 tables",
        "journal-ref": "Europhys.Lett.94:28006,2011",
        "doi": "10.1209/0295-5075/94/28006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a stochastic model to explain a double power-law distribution\nwhich exhibits two different Paretian behaviors in the upper and the lower tail\nand widely exists in social and economic systems. The model incorporates\nfitness consideration and noise fluctuation. We find that if the number of\nvariables (e.g. the degree of nodes in complex networks or people's incomes)\ngrows exponentially, normal distributed fitness coupled with exponentially\nincreasing variable is responsible for the emergence of the double power-law\ndistribution. Fluctuations do not change the result qualitatively but\ncontribute to the second-part scaling exponent. The evolution of Chinese\nairline network is taken as an example to show a nice agreement with our\nstochastic model.\n"
    },
    {
        "paper_id": 1103.2013,
        "authors": "Masaaki Fukasawa",
        "title": "Conservative delta hedging under transaction costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Explicit robust hedging strategies for convex or concave payoffs under a\ncontinuous semimartingale model with uncertainty and small transaction costs\nare constructed. In an asymptotic sense, the upper and lower bounds of the\ncumulative volatility enable us to super-hedge convex and concave payoffs\nrespectively. The idea is a combination of Mykland's conservative delta hedging\nand Leland's enlarging volatility. We use a specific sequence of stopping times\nas rebalancing dates, which can be superior to equidistant one even when there\nis no model uncertainty. A central limit theorem for the super-hedging error as\nthe coefficient of linear transaction costs tends to zero is proved. The mean\nsquared error is also studied.\n"
    },
    {
        "paper_id": 1103.2214,
        "authors": "Steffen Bohn (PMA)",
        "title": "The slippage paradox",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Buying or selling assets leads to transaction costs for the investor. On one\nhand, it is well know to all market practionaires that the transaction costs\nare positive on average and present therefore systematic loss. On the other\nhand, for every trade, there is a buy side and a sell side, the total amount of\nasset and the total amount of cash is conserved. I show, that the apparently\nparadoxical observation of systematic loss of all participants is intrinsic to\nthe trading process since it corresponds to a correlation of outstanding orders\nand price changes.\n"
    },
    {
        "paper_id": 1103.2234,
        "authors": "Jos\\`e T. Lunardi, Salvatore Miccich\\`e, Fabrizio Lillo, Rosario N.\n  Mantegna, Mauro Gallegati",
        "title": "Do firms share the same functional form of their growth rate\n  distribution? A new statistical test",
        "comments": "17 pages, 3 figures, 2 tables",
        "journal-ref": "JEDC 39 140-164 (2014)",
        "doi": "10.1016/j.jedc.2013.11.010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new statistical test of the hypothesis that a balanced panel\nof firms have the same growth rate distribution or, more generally, that they\nshare the same functional form of growth rate distribution. We applied the test\nto European Union and US publicly quoted manufacturing firms data, considering\nfunctional forms belonging to the Subbotin family of distributions. While our\nhypotheses are rejected for the vast majority of sets at the sector level, we\ncannot rejected them at the subsector level, indicating that homogenous panels\nof firms could be described by a common functional form of growth rate\ndistribution.\n"
    },
    {
        "paper_id": 1103.231,
        "authors": "Martin Keller-Ressel and Claus Griessler",
        "title": "Convex order of discrete, continuous and predictable quadratic variation\n  & applications to options on variance",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a square-integrable semimartingale and investigate the convex\norder relations between its discrete, continuous and predictable quadratic\nvariation. As the main results, we show that if the semimartingale has\nconditionally independent increments and symmetric jump measure, then its\ndiscrete realized variance dominates its quadratic variation in increasing\nconvex order. The results have immediate applications to the pricing of options\non realized variance. For a class of models including time-changed Levy models\nand Sato processes with symmetric jumps our results show that options on\nvariance are typically underpriced, if quadratic variation is substituted for\nthe discretely sampled realized variance.\n"
    },
    {
        "paper_id": 1103.2567,
        "authors": "Marco Bianchetti and Mattia Carlicchi",
        "title": "Interest Rates After The Credit Crunch: Multiple-Curve Vanilla\n  Derivatives and SABR",
        "comments": "26 pages, 13 color figures, 6 tables; revised typos",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a quantitative study of the markets and models evolution across\nthe credit crunch crisis. In particular, we focus on the fixed income market\nand we analyze the most relevant empirical evidences regarding the divergences\nbetween Libor and OIS rates, the explosion of Basis Swaps spreads, and the\ndiffusion of collateral agreements and CSA-discounting, in terms of credit and\nliquidity effects. We also review the new modern pricing approach prevailing\namong practitioners, based on multiple yield curves reflecting the different\ncredit and liquidity risk of Libor rates with different tenors and the\novernight discounting of cash flows originated by derivative transactions under\ncollateral with daily margination. We report the classical and modern\nno-arbitrage pricing formulas for plain vanilla interest rate derivatives, and\nthe multiple-curve generalization of the market standard SABR model with\nstochastic volatility. We then report the results of an empirical analysis on\nrecent market data comparing pre- and post-credit crunch pricing methodologies\nand showing the transition of the market practice from the classical to the\nmodern framework. In particular, we prove that the market of Interest Rate\nSwaps has abandoned since March 2010 the classical Single-Curve pricing\napproach, typical of the pre-credit crunch interest rate world, and has adopted\nthe modern Multiple-Curve CSA approach, thus incorporating credit and liquidity\neffects into market prices. The same analysis is applied to European\nCaps/Floors, finding that the full transition to the modern Multiple-Curve CSA\napproach has retarded up to August 2010. Finally, we show the robustness of the\nSABR model to calibrate the market volatility smile coherently with the new\nmarket evidences.\n"
    },
    {
        "paper_id": 1103.2577,
        "authors": "Zhi-Qiang Jiang and Wei-Xing Zhou",
        "title": "Multifractal detrending moving average cross-correlation analysis",
        "comments": "15 pages, 4 figures, 2 matlab codes for MF-X-DMA and MF-X-DFA",
        "journal-ref": "Physical Review E 84, 016106 (2011)",
        "doi": "10.1103/PhysRevE.84.016106",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There are a number of situations in which several signals are simultaneously\nrecorded in complex systems, which exhibit long-term power-law\ncross-correlations. The multifractal detrended cross-correlation analysis\n(MF-DCCA) approaches can be used to quantify such cross-correlations, such as\nthe MF-DCCA based on detrended fluctuation analysis (MF-X-DFA) method. We\ndevelop in this work a class of MF-DCCA algorithms based on the detrending\nmoving average analysis, called MF-X-DMA. The performances of the MF-X-DMA\nalgorithms are compared with the MF-X-DFA method by extensive numerical\nexperiments on pairs of time series generated from bivariate fractional\nBrownian motions, two-component autoregressive fractionally integrated moving\naverage processes and binomial measures, which have theoretical expressions of\nthe multifractal nature. In all cases, the scaling exponents $h_{xy}$ extracted\nfrom the MF-X-DMA and MF-X-DFA algorithms are very close to the theoretical\nvalues. For bivariate fractional Brownian motions, the scaling exponent of the\ncross-correlation is independent of the cross-correlation coefficient between\ntwo time series and the MF-X-DFA and centered MF-X-DMA algorithms have\ncomparative performance, which outperform the forward and backward MF-X-DMA\nalgorithms. We apply these algorithms to the return time series of two stock\nmarket indexes and to their volatilities. For the returns, the centered\nMF-X-DMA algorithm gives the best estimates of $h_{xy}(q)$ since its\n$h_{xy}(2)$ is closest to 0.5 as expected, and the MF-X-DFA algorithm has the\nsecond best performance. For the volatilities, the forward and backward\nMF-X-DMA algorithms give similar results, while the centered MF-X-DMA and the\nMF-X-DFA algorithms fails to extract rational multifractal nature.\n"
    },
    {
        "paper_id": 1103.267,
        "authors": "Iead Rezek",
        "title": "Constrained Mixture Models for Asset Returns Modelling",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The estimation of asset return distributions is crucial for determining\noptimal trading strategies. In this paper we describe the constrained mixture\nmodel, based on a mixture of Gamma and Gaussian distributions, to provide an\naccurate description of price trends as being clearly positive, negative or\nranging while accounting for heavy tails and high kurtosis. The model is\nestimated in the Expectation Maximisation framework and model order estimation\nalso respects the model's constraints.\n"
    },
    {
        "paper_id": 1103.2914,
        "authors": "Santiago Moreno-Bromberg and Luca Taschini",
        "title": "Pollution permits, Strategic Trading and Dynamic Technology Adoption",
        "comments": "29 pages, 20 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper analyzes the dynamic incentives for technology adoption under a\ntransferable permits system, which allows for strategic trading on the permit\nmarket. Initially, firms can invest both in low-emitting production\ntechnologies and trade permits. In the model, technology adoption and allowance\nprice are generated endogenously and are inter-dependent. It is shown that the\nnon-cooperative permit trading game possesses a pure-strategy Nash equilibrium,\nwhere the allowance value reflects the level of uncovered pollution (demand),\nthe level of unused allowances (supply), and the technological status. These\nconditions are also satisfied when a price support instrument, which is\ncontingent on the adoption of the new technology, is introduced. Numerical\ninvestigation confirms that this policy generates a floating price floor for\nthe allowances, and it restores the dynamic incentives to invest. Given that\nthis policy comes at a cost, a criterion for the selection of a self-financing\npolicy (based on convex risk measures) is proposed and implemented.\n"
    },
    {
        "paper_id": 1103.3206,
        "authors": "Grzegorz Andruszkiewicz and Dorje C. Brody",
        "title": "Noise, risk premium, and bubble",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The existence of the pricing kernel is shown to imply the existence of an\nambient information process that generates market filtration. This information\nprocess consists of a signal component concerning the value of the random\nvariable X that can be interpreted as the timing of future cash demand, and an\nindependent noise component. The conditional expectation of the signal, in\nparticular, determines the market risk premium vector. An addition to the\nsignal of any term that is independent of X, which generates a drift in the\nnoise, is shown to change the drifts of price processes in the physical\nmeasure, without affecting the current asset price levels. Such a drift in the\nnoise term can induce anomalous price dynamics, and can be seen to explain the\nmechanism of observed phenomena of equity premium and financial bubbles.\n"
    },
    {
        "paper_id": 1103.3482,
        "authors": "Mauricio Junca",
        "title": "Stochastic impulse control on optimal execution with price impact and\n  transaction cost",
        "comments": "This paper has been withdrawn by the author",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a single risky financial asset model subject to price impact and\ntransaction cost over an finite time horizon. An investor needs to execute a\nlong position in the asset affecting the price of the asset and possibly\nincurring in fixed transaction cost. The objective is to maximize the\ndiscounted revenue obtained by this transaction. This problem is formulated as\nan impulse control problem and we characterize the value function using the\nviscosity solutions framework. We establish an associated optimal stopping\nproblem that provides bounds and in some cases the solution of the value\nfunction.\n"
    },
    {
        "paper_id": 1103.3639,
        "authors": "V. T. X. de Almeida and L. Moriconi",
        "title": "Option Pricing from Wavelet-Filtered Financial Series",
        "comments": "4 pages, 1 figure",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.05.030",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform wavelet decomposition of high frequency financial time series into\nlarge and small time scale components. Taking the FTSE100 index as a case\nstudy, and working with the Haar basis, it turns out that the small scale\ncomponent defined by most ($\\simeq$ 99.6%) of the wavelet coefficients can be\nneglected for the purpose of option premium evaluation. The relevance of the\nhugely compressed information provided by low-pass wavelet-filtering is related\nto the fact that the non-gaussian statistical structure of the original\nfinancial time series is essentially preserved for expiration times which are\nlarger than just one trading day.\n"
    },
    {
        "paper_id": 1103.4483,
        "authors": "S\\\"oren Christensen",
        "title": "A method for pricing American options using semi-infinite linear\n  programming",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1111/j.1467-9965.2012.00523.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new approach for the numerical pricing of American options.\nThe main idea is to choose a finite number of suitable excessive functions\n(randomly) and to find the smallest majorant of the gain function in the span\nof these functions. The resulting problem is a linear semi-infinite programming\nproblem, that can be solved using standard algorithms. This leads to good upper\nbounds for the original problem. For our algorithms no discretization of space\nand time and no simulation is necessary. Furthermore it is applicable even for\nhigh-dimensional problems. The algorithm provides an approximation of the value\nnot only for one starting point, but for the complete value function on the\ncontinuation set, so that the optimal exercise region and e.g. the Greeks can\nbe calculated. We apply the algorithm to (one- and) multidimensional diffusions\nand to L\\'evy processes, and show it to be fast and accurate.\n"
    },
    {
        "paper_id": 1103.4541,
        "authors": "Yuta Inoue and Takahiro Tsuchiya",
        "title": "Defaultable Bonds via HKA",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To construct a no-arbitrage defaultable bond market, we work on the state\nprice density framework. Using the heat kernel approach (HKA for short) with\nthe killing of a Markov process, we construct a single defaultable bond market\nthat enables an explicit expression of a defaultable bond and credit spread\nunder quadratic Gaussian settings. Some simulation results show that the model\nis not only tractable but realistic.\n"
    },
    {
        "paper_id": 1103.4934,
        "authors": "Richard Martin and Torsten Sch\\\"oneborn",
        "title": "Mean Reversion Pays, but Costs",
        "comments": "This is a longer version of an article published in RISK(24)2:84--89\n  (Feb.~2011)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A mean-reverting financial instrument is optimally traded by buying it when\nit is sufficiently below the estimated `mean level' and selling it when it is\nabove. In the presence of linear transaction costs, a large amount of value is\npaid away crossing bid-offers unless one devises a `buffer' through which the\nprice must move before a trade is done. In this paper, Richard Martin and\nTorsten Sch\\\"oneborn derive the optimal strategy and conclude that for low\ncosts the buffer width is proportional to the cube root of the transaction\ncost, determining the proportionality constant explicitly.\n"
    },
    {
        "paper_id": 1103.4943,
        "authors": "Thomas Conlon, John Cotter",
        "title": "An Empirical Analysis of Dynamic Multiscale Hedging using Wavelet\n  Decomposition",
        "comments": "To Appear: Journal of Futures Markets",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the hedging effectiveness of a dynamic moving window\nOLS hedging model, formed using wavelet decomposed time-series. The wavelet\ntransform is applied to calculate the appropriate dynamic minimum-variance\nhedge ratio for various hedging horizons for a number of assets. The\neffectiveness of the dynamic multiscale hedging strategy is then tested, both\nin- and out-of-sample, using standard variance reduction and expanded to\ninclude a downside risk metric, the time horizon dependent Value-at-Risk.\nMeasured using variance reduction, the effectiveness converges to one at longer\nscales, while a measure of VaR reduction indicates a portion of residual risk\nremains at all scales. Analysis of the hedge portfolio distributions indicate\nthat this unhedged tail risk is related to excess portfolio kurtosis found at\nall scales.\n"
    },
    {
        "paper_id": 1103.4947,
        "authors": "Nick Bush and Ben M. Hambly and Helen Haworth and Lei Jin and\n  Christoph Reisinger",
        "title": "Stochastic evolution equations in portfolio credit modelling with\n  applications to exotic credit products",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a structural credit model for a large portfolio of credit risky\nassets where the correlation is due to a market factor. By considering the\nlarge portfolio limit of this system we show the existence of a density process\nfor the asset values. This density evolves according to a stochastic partial\ndifferential equation and we establish existence and uniqueness for the\nsolution taking values in a suitable function space. The loss function of the\nportfolio is then a function of the evolution of this density at the default\nboundary. We develop numerical methods for pricing and calibration of the model\nto credit indices and consider its performance pre and post credit crunch.\nFinally, we give further examples illustrating the valuation of exotic credit\nproducts, specifically forward starting CDOs.\n"
    },
    {
        "paper_id": 1103.4965,
        "authors": "Aleksandar Mijatovi\\'c and Mikhail Urusov",
        "title": "A Note on Delta Hedging in Markets with Jumps",
        "comments": "16 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Modelling stock prices via jump processes is common in financial markets. In\npractice, to hedge a contingent claim one typically uses the so-called\ndelta-hedging strategy. This strategy stems from the Black--Merton--Scholes\nmodel where it perfectly replicates contingent claims. From the theoretical\nviewpoint, there is no reason for this to hold in models with jumps. However in\npractice the delta-hedging strategy is widely used and its potential\nshortcoming in models with jumps is disregarded since such models are typically\nincomplete and hence most contingent claims are non-attainable. In this note we\ninvestigate a complete model with jumps where the delta-hedging strategy is\nwell-defined for regular payoff functions and is uniquely determined via the\nrisk-neutral measure. In this setting we give examples of (admissible)\ndelta-hedging strategies with bounded discounted value processes, which\nnevertheless fail to replicate the respective bounded contingent claims. This\ndemonstrates that the deficiency of the delta-hedging strategy in the presence\nof jumps is not due to the incompleteness of the model but is inherent in the\ndiscontinuity of the trajectories.\n"
    },
    {
        "paper_id": 1103.5027,
        "authors": "Leonardo Ermann, Dima L.Shepelyansky",
        "title": "Google matrix of the world trade network",
        "comments": "14 pages, 13 figures. More detailed data and high definition figures\n  are available on the website:\n  http://www.quantware.ups-tlse.fr/QWLIB/tradecheirank/index.html",
        "journal-ref": "Acta Physica Polonica A, vol. 120 (6A), A-158 (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using the United Nations Commodity Trade Statistics Database\n[http://comtrade.un.org/db/] we construct the Google matrix of the world trade\nnetwork and analyze its properties for various trade commodities for all\ncountries and all available years from 1962 to 2009. The trade flows on this\nnetwork are classified with the help of PageRank and CheiRank algorithms\ndeveloped for the World Wide Web and other large scale directed networks. For\nthe world trade this ranking treats all countries on equal democratic grounds\nindependent of country richness. Still this method puts at the top a group of\nindustrially developed countries for trade in {\\it all commodities}. Our study\nestablishes the existence of two solid state like domains of rich and poor\ncountries which remain stable in time, while the majority of countries are\nshown to be in a gas like phase with strong rank fluctuations. A simple random\nmatrix model provides a good description of statistical distribution of\ncountries in two-dimensional rank plane. The comparison with usual ranking by\nexport and import highlights new features and possibilities of our approach.\n"
    },
    {
        "paper_id": 1103.5189,
        "authors": "B. Goswami, G. Ambika, N. Marwan and J. Kurths",
        "title": "On interrelations of recurrences and connectivity trends between stock\n  indices",
        "comments": "28 pages, 16 figures, submitted to Physica A",
        "journal-ref": "Physica A, 391, 4364 (2012)",
        "doi": "10.1016/j.physa.2012.04.018",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial data has been extensively studied for correlations using Pearson's\ncross-correlation coefficient {\\rho} as the point of departure. We employ an\nestimator based on recurrence plots --- the Correlation of Probability of\nRecurrence (CPR) --- to analyze connections between nine stock indices spread\nworldwide. We suggest a slight modification of the CPR approach in order to get\nmore robust results. We examine trends in CPR for an approximately 19-month\nwindow moved along the time series and compare them to {\\rho}. Binning CPR into\nthree levels of connectedness: strong, moderate and weak, we extract the trends\nin number of connections in each bin over time. We also look at the behavior of\nCPR during the Dot-Com bubble by shifting the time series to align their peaks.\nCPR mainly uncovers that the markets move in and out of periods of strong\nconnectivity erratically, instead of moving monotonously towards increasing\nglobal connectivity. This is in contrast to {\\rho}, which gives a picture of\never increasing correlation. CPR also exhibits that time shifted markets have\nhigh connectivity around the Dot-Com bubble of 2000. We stress on the\nimportance of significance testing in interpreting measures applied to field\ndata. CPR is more robust to significance testing. It has the additional\nadvantages of being robust to noise, and reliable for short time series lengths\nand low frequency of sampling. Further, it is more sensitive to changes than\n{\\rho} as it captures correlations between the essential dynamics of the\nunderlying systems.\n"
    },
    {
        "paper_id": 1103.5345,
        "authors": "Sebastian M. Krause, Stefan Bornholdt",
        "title": "Spin models as microfoundation of macroscopic financial market models",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Macroscopic price evolution models are commonly used for investment\nstrategies. There are first promising achievements in defining microscopic\nagent based models for the same purpose. Microscopic models allow a deeper\nunderstanding of mechanisms in the market than the purely phenomenological\nmacroscopic models, and thus bear the chance for better models for market\nregulation. We exemplify this strategy in a case study, deducing a macroscopic\nLangevin equation from a microscopic spin market model closely related to the\nIsing model. The interplay of the microscopic and the macroscopic view allows\nfor a better understanding of the microscopic model, as well, and may guide the\nconstruction of agent based market models as basis of macroscopic price models.\n"
    },
    {
        "paper_id": 1103.5408,
        "authors": "John Cotter and Kevin Dowd",
        "title": "Spectral Risk Measures with an Application to Futures Clearinghouse\n  Variation Margin Requirements",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper applies an AR(1)-GARCH (1, 1) process to detail the conditional\ndistributions of the return distributions for the S&P500, FT100, DAX, Hang\nSeng, and Nikkei225 futures contracts. It then uses the conditional\ndistribution for these contracts to estimate spectral risk measures, which are\ncoherent risk measures that reflect a user's risk-aversion function. It\ncompares these to more familiar VaR and Expected Shortfall (ES) measures of\nrisk, and also compares the precision and discusses the relative usefulness of\neach of these risk measures in setting variation margins that incorporate\ntime-varying market conditions. The goodness of fit of the model is confirmed\nby a variety of backtests.\n"
    },
    {
        "paper_id": 1103.5409,
        "authors": "Kevin Dowd and John Cotter",
        "title": "Exponential Spectral Risk Measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Spectral risk measures are attractive risk measures as they allow the user to\nobtain risk measures that reflect their subjective risk-aversion. This paper\nexamines spectral risk measures based on an exponential utility function, and\nfinds that these risk measures have nice intuitive properties. It also\ndiscusses how they can be estimated using numerical quadrature methods, and how\nconfidence intervals for them can be estimated using a parametric bootstrap.\nIllustrative results suggest that estimated exponential spectral risk measures\nobtained using such methods are quite precise in the presence of normally\ndistributed losses.\n"
    },
    {
        "paper_id": 1103.5411,
        "authors": "John Cotter and Jim Hanly",
        "title": "Hedging Effectiveness under Conditions of Asymmetry",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We examine whether hedging effectiveness is affected by asymmetry in the\nreturn distribution by applying tail specific metrics to compare the hedging\neffectiveness of short and long hedgers using crude oil futures contracts. The\nmetrics used include Lower Partial Moments (LPM), Value at Risk (VaR) and\nConditional Value at Risk (CVAR). Comparisons are applied to a number of\nhedging strategies including OLS and both Symmetric and Asymmetric GARCH\nmodels. Our findings show that asymmetry reduces in-sample hedging performance\nand that there are significant differences in hedging performance between short\nand long hedgers. Thus, tail specific performance metrics should be applied in\nevaluating hedging effectiveness. We also find that the Ordinary Least Squares\n(OLS) model provides consistently good performance across different measures of\nhedging effectiveness and estimation methods irrespective of the\ncharacteristics of the underlying distribution.\n"
    },
    {
        "paper_id": 1103.5412,
        "authors": "John Cotter and Fran\\c{c}ois Longin",
        "title": "Margin setting with high-frequency data1",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Both in practice and in the academic literature, models for setting margin\nrequirements in futures markets classically use daily closing price changes.\nHowever, as well documented by research on high-frequency data, financial\nmarkets have recently shown high intraday volatility, which could bring more\nrisk than expected. This paper tries to answer two questions relevant for\nmargin committees in practice: is it right to compute margin levels based on\nclosing prices and ignoring intraday dynamics? Is it justified to implement\nintraday margin calls? The paper focuses on the impact of intraday dynamics of\nmarket prices on daily margin levels. Daily margin levels are obtained in two\nways: first, by using daily price changes defined with different time-intervals\n(say from 3 pm to 3 pm on the following trading day instead of traditional\nclosing times); second, by using 5-minute and 1-hour price changes and scaling\nthe results to one day. Our empirical analysis uses the FTSE 100 futures\ncontract traded on LIFFE.\n"
    },
    {
        "paper_id": 1103.5414,
        "authors": "John Cotter and Simon Stevenson",
        "title": "Modeling Long Memory in REITs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One stylized feature of financial volatility impacting the modeling process\nis long memory. This paper examines long memory for alternative risk measures,\nobserved absolute and squared returns for Daily REITs and compares the findings\nfor a non- REIT equity index. The paper utilizes a variety of tests for long\nmemory finding evidence that REIT volatility does display persistence, in\ncontrast to the actual return series. Trading volume is found to be strongly\nassociated with long memory. The results do however suggest differences in the\nfindings with regard to REITs in comparison to the broader equity sector which\nmay be due to relatively thin trading during the sample period.\n"
    },
    {
        "paper_id": 1103.5416,
        "authors": "John Cotter",
        "title": "Minimum Capital Requirement Calculations for UK Futures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Key to the imposition of appropriate minimum capital requirements on a daily\nbasis requires accurate volatility estimation. Here, measures are presented\nbased on discrete estimation of aggregated high frequency UK futures\nrealisations underpinned by a continuous time framework. Squared and absolute\nreturns are incorporated into the measurement process so as to rely on the\nquadratic variation of a diffusion process and be robust in the presence of fat\ntails. The realized volatility estimates incorporate the long memory property.\nThe dynamics of the volatility variable are adequately captured. Resulting\nrescaled returns are applied to minimum capital requirement calculations.\n"
    },
    {
        "paper_id": 1103.5417,
        "authors": "John Cotter and Simon Stevenson",
        "title": "Uncovering Volatility Dynamics in Daily REIT Returns",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using a time-varying approach, this paper examines the dynamics of volatility\nin the REIT sector. The results highlight the attractiveness and suitability of\nusing GARCH based approaches in the modeling of daily REIT volatility. The\npaper examines the influencing factors on REIT volatility, documenting the\nreturn and volatility linkages between REIT sub-sectors and also examines the\ninfluence of other US equity series. The results contrast with previous studies\nof monthly REIT volatility. Linkages within the REIT sector and with related\nsectors such as value stocks are diminished, while the general influence of\nmarket sentiment, coming through the large cap indices is enhanced. This would\nindicate that on a daily basis general market sentiment plays a more\nfundamental role than more intuitive relationships within the capital markets.\n"
    },
    {
        "paper_id": 1103.5418,
        "authors": "John Cotter",
        "title": "Tail Behaviour of the Euro",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper empirically analyses risk in the Euro relative to other\ncurrencies. Comparisons are made between a sub period encompassing the final\ntransitional stage to full monetary union with a sub period prior to this.\nStability in the face of speculative attack is examined using Extreme Value\nTheory to obtain estimates of tail exchange rate changes. The findings are\nencouraging. The Euro's common risk measures do not deviate substantially from\nother currencies. Also, the Euro is stable in the face of speculative pressure.\nFor example, the findings consistently show the Euro being less risky than the\nYen, and having similar inherent risk to the Deutsche Mark, the currency that\nit is essentially replacing.\n"
    },
    {
        "paper_id": 1103.5555,
        "authors": "Dong-Ming Song, Michele Tumminello, Wei-Xing Zhou and Rosario N.\n  Mantegna",
        "title": "Evolution of worldwide stock markets, correlation structure and\n  correlation based graphs",
        "comments": "8 pages, 11 figures",
        "journal-ref": "Physical Review E 84 (2), 026108 (2011)",
        "doi": "10.1103/PhysRevE.84.026108",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the daily correlation present among market indices of stock\nexchanges located all over the world in the time period Jan 1996 - Jul 2009. We\ndiscover that the correlation among market indices presents both a fast and a\nslow dynamics. The slow dynamics reflects the development and consolidation of\nglobalization. The fast dynamics is associated with critical events that\noriginate in a specific country or region of the world and rapidly affect the\nglobal system. We provide evidence that the short term timescale of correlation\namong market indices is less than 3 trading months (about 60 trading days). The\naverage values of the non diagonal elements of the correlation matrix,\ncorrelation based graphs and the spectral properties of the largest eigenvalues\nand eigenvectors of the correlation matrix are carrying information about the\nfast and slow dynamics of correlation of market indices. We introduce a measure\nof mutual information based on link co-occurrence in networks, in order to\ndetect the fast dynamics of successive changes of correlation based graphs in a\nquantitative way.\n"
    },
    {
        "paper_id": 1103.5575,
        "authors": "Johannes Temme",
        "title": "Power Utility Maximization in Discrete-Time and Continuous-Time\n  Exponential Levy Models",
        "comments": "18 pages, to appear in Mathematical Methods of Operations Research.\n  The final publication is available at springerlink.com",
        "journal-ref": null,
        "doi": "10.1007/s00186-012-0388-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider power utility maximization of terminal wealth in a 1-dimensional\ncontinuous-time exponential Levy model with finite time horizon. We discretize\nthe model by restricting portfolio adjustments to an equidistant discrete time\ngrid. Under minimal assumptions we prove convergence of the optimal\ndiscrete-time strategies to the continuous-time counterpart. In addition, we\nprovide and compare qualitative properties of the discrete-time and\ncontinuous-time optimizers.\n"
    },
    {
        "paper_id": 1103.5649,
        "authors": "John Cotter",
        "title": "Varying the VaR for Unconditional and Conditional Environments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Accurate forecasting of risk is the key to successful risk management\ntechniques. Using the largest stock index futures from twelve European bourses,\nthis paper presents VaR measures based on their unconditional and conditional\ndistributions for single and multi-period settings. These measures underpinned\nby extreme value theory are statistically robust explicitly allowing for\nfat-tailed densities. Conditional tail estimates are obtained by adjusting the\nunconditional extreme value procedure with GARCH filtered returns. The\nconditional modelling results in iid returns allowing for the use of a simple\nand efficient multi-period extreme value scaling law. The paper examines the\nproperties of these distinct conditional and unconditional trading models. The\npaper finds that the biases inherent in unconditional single and multi-period\nestimates assuming normality extend to the conditional setting.\n"
    },
    {
        "paper_id": 1103.5651,
        "authors": "John Cotter",
        "title": "Uncovering Long Memory in High Frequency UK Futures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Accurate volatility modelling is paramount for optimal risk management\npractices. One stylized feature of financial volatility that impacts the\nmodelling process is long memory explored in this paper for alternative risk\nmeasures, observed absolute and squared returns for high frequency intraday UK\nfutures. Volatility series for three different asset types, using stock index,\ninterest rate and bond futures are analysed. Long memory is strongest for the\nbond contract. Long memory is always strongest for the absolute returns series\nand at a power transformation of k < 1. The long memory findings generally\nincorporate intraday periodicity. The APARCH model incorporating seven related\nGARCH processes generally models the futures series adequately documenting\nARCH, GARCH and leverage effects.\n"
    },
    {
        "paper_id": 1103.5653,
        "authors": "John Cotter and Kevin Dowd",
        "title": "Extreme Spectral Risk Measures: An Application to Futures Clearinghouse\n  Margin Requirements",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper applies the Extreme-Value (EV) Generalised Pareto distribution to\nthe extreme tails of the return distributions for the S&P500, FT100, DAX, Hang\nSeng, and Nikkei225 futures contracts. It then uses tail estimators from these\ncontracts to estimate spectral risk measures, which are coherent risk measures\nthat reflect a user's risk-aversion function. It compares these to VaR and\nExpected Shortfall (ES) risk measures, and compares the precision of their\nestimators. It also discusses the usefulness of these risk measures in the\ncontext of clearinghouses setting initial margin requirements, and compares\nthese to the SPAN measures typically used. Keywords: Spectral risk measures,\nExpected Shortfall, Value at Risk, Extreme Value\n"
    },
    {
        "paper_id": 1103.5655,
        "authors": "John Cotter and Fran\\c{c}ois Longin",
        "title": "Implied correlation from VaR",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Value at risk (VaR) is a risk measure that has been widely implemented by\nfinancial institutions. This paper measures the correlation among asset price\nchanges implied from VaR calculation. Empirical results using US and UK equity\nindexes show that implied correlation is not constant but tends to be higher\nfor events in the left tails (crashes) than in the right tails (booms).\n"
    },
    {
        "paper_id": 1103.5656,
        "authors": "john cotter",
        "title": "Modelling catastrophic risk in international equity markets: An extreme\n  value approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This letter uses the Block Maxima Extreme Value approach to quantify\ncatastrophic risk in international equity markets. Risk measures are generated\nfrom a set threshold of the distribution of returns that avoids the pitfall of\nusing absolute returns for markets exhibiting diverging levels of risk. From an\napplication to leading markets, the letter finds that the Nikkei is more prone\nto catastrophic risk than the FTSE and Dow Jones Indexes.\n"
    },
    {
        "paper_id": 1103.5659,
        "authors": "kevin dowd and john cotter",
        "title": "U.S. Core Inflation: A Wavelet Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes the use of wavelet methods to estimate U.S. core\ninflation. It explains wavelet methods and suggests they are ideally suited to\nthis task. Comparisons are made with traditional CPI-based and regression-based\nmeasures for their performance in following trend inflation and predicting\nfuture inflation. Results suggest that wavelet-based measures perform better,\nand sometimes much better, than the traditional approaches. These results\nsuggest that wavelet methods are a promising avenue for future research on core\ninflation.\n"
    },
    {
        "paper_id": 1103.566,
        "authors": "John Cotter and Simon Stevenson",
        "title": "Multivariate Modeling of Daily REIT Volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines volatility in REITs using a multivariate GARCH based\nmodel. The Multivariate VAR-GARCH technique documents the return and volatility\nlinkages between REIT sub-sectors and also examines the influence of other US\nequity series. The motivation is for investors to incorporate time-varyng\nvolatility and correlations in their portfolio selection. The results\nillustrate the differences in results when higher frequency daily data is\ntested in comparison to the monthly data that has been commonly used in the\nexisting literature. The linkages both within the REIT sector and between REITs\nand related sectors such as value stocks are weaker than commonly found in\nmonthly studies. The broad market would appear to be more influential in the\ndaily case.\n"
    },
    {
        "paper_id": 1103.5661,
        "authors": "john cotter and kevin dowd",
        "title": "The tail risks of FX return distributions: a comparison of the returns\n  associated with limit orders and market orders",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper measures and compares the tail risks of limit and market orders\nusing Extreme Value Theory. The analysis examines realised tail outcomes using\nthe Dealing 2000-2 electronic broking system based on completed transactions\nrather than the more common analysis of indicative quotes. In general, limit\nand market orders exhibit broadly similar tail behaviour, but limit orders have\nsignificantly heavier tails and larger tail quantiles than market orders.\n"
    },
    {
        "paper_id": 1103.5664,
        "authors": "john cotter and kevin dowd",
        "title": "Intra-Day Seasonality in Foreign Exchange Market Transactions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the intra-day seasonality of transacted limit and market\norders in the DEM/USD foreign exchange market. Empirical analysis of completed\ntransactions data based on the Dealing 2000-2 electronic inter-dealer broking\nsystem indicates significant evidence of intraday seasonality in returns and\nreturn volatilities under usual market conditions. Moreover, analysis of\nrealised tail outcomes supports seasonality for extraordinary market conditions\nacross the trading day.\n"
    },
    {
        "paper_id": 1103.5665,
        "authors": "Kevin Dowd and John Cotter",
        "title": "Evaluating the Precision of Estimators of Quantile-Based Risk Measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the precision of estimators of Quantile-Based Risk\nMeasures (Value at Risk, Expected Shortfall, Spectral Risk Measures). It first\naddresses the question of how to estimate the precision of these estimators,\nand proposes a Monte Carlo method that is free of some of the limitations of\nexisting approaches. It then investigates the distribution of risk estimators,\nand presents simulation results suggesting that the common practice of relying\non asymptotic normality results might be unreliable with the sample sizes\ncommonly available to them. Finally, it investigates the relationship between\nthe precision of different risk estimators and the distribution of underlying\nlosses (or returns), and yields a number of useful conclusions.\n"
    },
    {
        "paper_id": 1103.5666,
        "authors": "john cotter and kevin dowd",
        "title": "Estimating financial risk measures for futures positions: a\n  non-parametric approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents non-parametric estimates of spectral risk measures\napplied to long and short positions in 5 prominent equity futures contracts. It\nalso compares these to estimates of two popular alternative measures, the\nValue-at-Risk (VaR) and Expected Shortfall (ES). The spectral risk measures are\nconditioned on the coefficient of absolute risk aversion, and the latter two\nare conditioned on the confidence level. Our findings indicate that all risk\nmeasures increase dramatically and their estimators deteriorate in precision\nwhen their respective conditioning parameter increases. Results also suggest\nthat estimates of spectral risk measures and their precision levels are of\ncomparable orders of magnitude as those of more conventional risk measures.\nRunning head: financial risk measures for futures positions\n"
    },
    {
        "paper_id": 1103.5668,
        "authors": "kevin dowd and john cotter",
        "title": "Spectral Risk Measures and the Choice of Risk Aversion Function",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Spectral risk measures are attractive risk measures as they allow the user to\nobtain risk measures that reflect their risk-aversion functions. To date there\nhas been very little guidance on the choice of risk-aversion functions\nunderlying spectral risk measures. This paper addresses this issue by examining\ntwo popular risk aversion functions, based on exponential and power utility\nfunctions respectively. We find that the former yields spectral risk measures\nwith nice intuitive properties, but the latter yields spectral risk measures\nthat can have perverse properties. More work therefore needs to be done before\nwe can be sure that arbitrary but respectable utility functions will always\nyield 'well-behaved' spectral risk measures.\n"
    },
    {
        "paper_id": 1103.5672,
        "authors": "Kevin Dowd, John Cotter, Chris Humphrey and Margaret Woods",
        "title": "How Unlucky is 25-Sigma?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One of the more memorable moments of last summer's credit crunch came when\nthe CFO of Goldman Sachs, David Viniar, announced in August that Goldman's\nflagship GEO hedge fund had lost 27% of its value since the start of the year.\nAs Mr. Viniar explained, \"We were seeing things that were 25-standard deviation\nmoves, several days in a row.\"\n"
    },
    {
        "paper_id": 1103.5674,
        "authors": "Kevin Dowd, John Cotter and Ghulam Sorwar",
        "title": "Spectral Risk Measures: Properties and Limitations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Spectral risk measures (SRMs) are risk measures that take account of user\nriskaversion, but to date there has been little guidance on the choice of\nutility function underlying them. This paper addresses this issue by examining\nalternative approaches based on exponential and power utility functions. A\nnumber of problems are identified with both types of spectral risk measure. The\ngeneral lesson is that users of spectral risk measures must be careful to\nselect utility functions that fit the features of the particular problems they\nare dealing with, and should be especially careful when using power SRMs.\n"
    },
    {
        "paper_id": 1103.5703,
        "authors": "Jose-Luis Lopez, Ricardo Lopez-Ruiz and Xavier Calbet",
        "title": "Exponential wealth distribution in a random market. A rigorous\n  explanation",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In simulations of some economic gas-like models, the asymptotic regime shows\nan exponential wealth distribution, independently of the initial wealth\ndistribution given to the system. The appearance of this statistical\nequilibrium for this type of gas-like models is explained in a rigorous\nanalytical way.\n"
    },
    {
        "paper_id": 1103.5722,
        "authors": "Nicola Cufaro Petroni and Piergiacomo Sabino",
        "title": "Multidimensional Quasi-Monte Carlo Malliavin Greeks",
        "comments": "22 pages, 6 figures",
        "journal-ref": "Decisions in Economics and Finance, 2013, vol. 36, p. 199-224",
        "doi": "10.1007/s10203-011-0125-z",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the use of Malliavin calculus in order to calculate the Greeks\nof multidimensional complex path-dependent options by simulation. For this\npurpose, we extend the formulas employed by Montero and Kohatsu-Higa to the\nmultidimensional case. The multidimensional setting shows the convenience of\nthe Malliavin Calculus approach over different techniques that have been\npreviously proposed. Indeed, these techniques may be computationally expensive\nand do not provide flexibility for variance reduction. In contrast, the\nMalliavin approach exhibits a higher flexibility by providing a class of\nfunctions that return the same expected value (the Greek) with different\naccuracies. This versatility for variance reduction is not possible without the\nuse of the generalized integral by part formula of Malliavin Calculus. In the\nmultidimensional context, we find convenient formulas that permit to improve\nthe localization technique, introduced in Fourni\\'e et al and reduce both the\ncomputational cost and the variance. Moreover, we show that the parameters\nemployed for variance reduction can be obtained \\textit{on the flight} in the\nsimulation. We illustrate the efficiency of the proposed procedures, coupled\nwith the enhanced version of Quasi-Monte Carlo simulations as discussed in\nSabino, for the numerical estimation of the Deltas of call, digital Asian-style\nand Exotic basket options with a fixed and a floating strike price in a\nmultidimensional Black-Scholes market.\n"
    },
    {
        "paper_id": 1103.5962,
        "authors": "John Cotter, Kevin Dowd and Wyn Morgan",
        "title": "Extreme Measures of Agricultural Financial Risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Risk is an inherent feature of agricultural production and marketing and\naccurate measurement of it helps inform more efficient use of resources. This\npaper examines three tail quantile-based risk measures applied to the\nestimation of extreme agricultural financial risk for corn and soybean\nproduction in the US: Value at Risk (VaR), Expected Shortfall (ES) and Spectral\nRisk Measures (SRMs). We use Extreme Value Theory (EVT) to model the tail\nreturns and present results for these three different risk measures using\nagricultural futures market data. We compare the estimated risk measures in\nterms of their size and precision, and find that they are all considerably\nhigher than normal estimates; they are also quite uncertain, and become more\nuncertain as the risks involved become more extreme.\n"
    },
    {
        "paper_id": 1103.5965,
        "authors": "John Cotter",
        "title": "Scaling conditional tail probability and quantile estimators",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a novel procedure for scaling relatively high frequency tail\nprobability and quantile estimates for the conditional distribution of returns.\n"
    },
    {
        "paper_id": 1103.5966,
        "authors": "John Cotter and Jim Hanly",
        "title": "Hedging: Scaling and the Investor Horizon",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the volatility and covariance dynamics of cash and\nfutures contracts that underlie the Optimal Hedge Ratio (OHR) across different\nhedging time horizons. We examine whether hedge ratios calculated over a short\nterm hedging horizon can be scaled and successfully applied to longer term\nhorizons. We also test the equivalence of scaled hedge ratios with those\ncalculated directly from lower frequency data and compare them in terms of\nhedging effectiveness. Our findings show that the volatility and covariance\ndynamics may differ considerably depending on the hedging horizon and this\ngives rise to significant differences between short term and longer term\nhedges. Despite this, scaling provides good hedging outcomes in terms of risk\nreduction which are comparable to those based on direct estimation.\n"
    },
    {
        "paper_id": 1103.5968,
        "authors": "John Cotter and Jim Hanly",
        "title": "Time Varying Risk Aversion: An Application to Energy Hedging",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Risk aversion is a key element of utility maximizing hedge strategies;\nhowever, it has typically been assigned an arbitrary value in the literature.\nThis paper instead applies a GARCH-in-Mean (GARCH-M) model to estimate a\ntime-varying measure of risk aversion that is based on the observed risk\npreferences of energy hedging market participants. The resulting estimates are\napplied to derive explicit risk aversion based optimal hedge strategies for\nboth short and long hedgers. Out-of-sample results are also presented based on\na unique approach that allows us to forecast risk aversion, thereby estimating\nhedge strategies that address the potential future needs of energy hedgers. We\nfind that the risk aversion based hedges differ significantly from simpler OLS\nhedges. When implemented in-sample, risk aversion hedges for short hedgers\noutperform the OLS hedge ratio in a utility based comparison.\n"
    },
    {
        "paper_id": 1103.5971,
        "authors": "Karl Case, John Cotter and Stuart Gabriel",
        "title": "Housing risk and return: Evidence from a housing asset-pricing model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the risk-return relationship in determination of\nhousing asset pricing. In so doing, the paper evaluates behavioral hypotheses\nadvanced by Case and Shiller (1988, 2002, 2009) in studies of boom and\npost-boom housing markets. The paper specifies and tests a multi-factor housing\nasset pricing model. In that model, we evaluate whether the market factor as\nwell as other measures of risk, including idiosyncratic risk, momentum, and MSA\nsize effects, have explanatory power for metropolitan-specific housing returns.\nFurther, we test the robustness of the asset pricing results to inclusion of\ncontrols for socioeconomic variables commonly represented in the house price\nliterature, including changes in employment, affordability, and foreclosure\nincidence. We find a sizable and statistically significant influence of the\nmarket factor on MSA house price returns. Moreover we show that market betas\nhave varied substantially over time. Also, results are largely robust to the\ninclusion of other explanatory variables, including standard measures of risk\nand other housing market fundamentals. Additional tests of model validity using\nthe Fama-MacBeth framework offer further strong support of a positive risk and\nreturn relationship in housing. Our findings are supportive of the application\nof a housing investment risk-return framework in explanation of variation in\nmetro-area cross-section and time-series US house price returns. Further,\nresults strongly corroborate Case-Shiller survey research indicating the\nimportance of speculative forces in the determination of U.S. housing returns.\n"
    },
    {
        "paper_id": 1103.5972,
        "authors": "John Cotter and Richard Roll",
        "title": "A Comparative Anatomy of REITs and Residential Real Estate Indexes:\n  Returns, Risks and Distributional Characteristics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Real Estate Investment Trusts (REITs) are the only truly liquid assets\nrelated to real estate investments. We study the behavior of U.S. REITs over\nthe past three decades and document their return characteristics. REITs have\nsomewhat less market risk than equity; their betas against a broad market index\naverage about .65. Decomposing their covariances into principal components\nreveals several strong factors. REIT characteristics differ to some extent from\nthose of the S&P/Case-Shiller (SCS) residential real estate indexes. This is\npartly attributable to methods of index construction. Our examination of REITs\nsuggests that investment in real estate is far more risky than what might be\ninferred from the widely-followed SCS series. REITs, unlike SCS series are\nforward looking, and this helps them in the prediction of SCS returns. REIT\nforecasts of SCS returns are reasonably precise over a number of periods.\n"
    },
    {
        "paper_id": 1103.5973,
        "authors": "John Cotter and Jim Hanly",
        "title": "A Utility Based Approach to Energy Hedging",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A key issue in the estimation of energy hedges is the hedgers' attitude\ntowards risk which is encapsulated in the form of the hedgers' utility\nfunction. However, the literature typically uses only one form of utility\nfunction such as the quadratic when estimating hedges. This paper addresses\nthis issue by estimating and applying energy market based risk aversion to\ncommonly applied utility functions including log, exponential and quadratic,\nand we incorporate these in our hedging frameworks. We find significant\ndifferences in the optimal hedge strategies based on the utility function\nchosen.\n"
    },
    {
        "paper_id": 1103.5976,
        "authors": "John Cotter",
        "title": "Absolute Return Volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The use of absolute return volatility has many modelling benefits says John\nCotter. An illustration is given for the market risk measure, minimum capital\nrequirements.\n"
    },
    {
        "paper_id": 1103.5978,
        "authors": "David Blake, John Cotter and Kevin Dowd",
        "title": "Financial Risks and the Pension Protection Fund: Can it Survive Them?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper discusses the financial risks faced by the UK Pension Protection\nFund (PPF) and what, if anything, it can do about them. It draws lessons from\nthe regulatory regimes under which other financial institutions, such as banks\nand insurance companies, operate and asks why pension funds are treated\ndifferently. It also reviews the experience with other government-sponsored\ninsurance schemes, such as the US Pension Benefit Guaranty Corporation, upon\nwhich the PPF is modelled. We conclude that the PPF will live under the\npermanent risk of insolvency as a consequence of the moral hazard, adverse\nselection, and, especially, systemic risks that it faces.\n"
    },
    {
        "paper_id": 1103.5994,
        "authors": "Oleg Kitov, Ivan Kitov",
        "title": "A win-win monetary policy in Canada",
        "comments": "25 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Lucas critique has exposed the problem of the trade-off between changes\nin monetary policy and structural breaks in economic time series. The search\nfor and characterisation of such breaks has been a major econometric task ever\nsince. We have developed an integral technique similar to CUSUM using an\nempirical model quantitatively linking the rate of inflation and unemployment\nto the change in the level of labour force in Canada. Inherently, our model\nbelongs to the class of Phillips curve models, and the link between the\ninvolved variables is a linear one with all coefficients of individual and\ngeneralized models obtained by empirical calibration. To achieve the best LSQ\nfit between measured and predicted time series cumulative curves are used as a\nsimplified version of the 1-D boundary elements (integral) method. The distance\nbetween the cumulative curves (in L2 metrics) is very sensitive to structural\nbreaks since it accumulates true differences and suppresses uncorrelated noise\nand systematic errors. Our previous model of inflation and unemployment in\nCanada is enhanced by the introduction of structural breaks and is validated by\nnew data in the past and future. The most exiting finding is that the\nintroduction of inflation targeting as a new monetary policy in 1991 resulted\nin a structural break manifested in a lowered rate of price inflation\naccompanied by a substantial fall in the rate of unemployment. Therefore, the\nnew monetary policy in Canada is a win-win one.\n"
    },
    {
        "paper_id": 1103.6143,
        "authors": "Guglielmo D'Amico and Filippo Petroni",
        "title": "A semi-Markov model for price returns",
        "comments": null,
        "journal-ref": "Physica A, 391, 4867-4876, 2012",
        "doi": "10.1016/j.physa.2012.05.040",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the high frequency price dynamics of traded stocks by a model of\nreturns using a semi-Markov approach. More precisely we assume that the\nintraday return are described by a discrete time homogeneous semi-Markov\nprocess and the overnight returns are modeled by a Markov chain. Based on this\nassumptions we derived the equations for the first passage time distribution\nand the volatility autocorreletion function. Theoretical results have been\ncompared with empirical findings from real data. In particular we analyzed high\nfrequency data from the Italian stock market from first of January 2007 until\nend of December 2010. The semi-Markov hypothesis is also tested through a\nnonparametric test of hypothesis.\n"
    },
    {
        "paper_id": 1104.0308,
        "authors": "J. A. Bergstra, C. A. Middelburg",
        "title": "An Application Specific Informal Logic for Interest Prohibition Theory",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Interest prohibition theory concerns theoretical aspects of interest\nprohibition. We attempt to lay down some aspects of interest prohibition theory\nwrapped in a larger framework of informal logic. The reason for this is that\ninterest prohibition theory has to deal with a variety of arguments which is so\nwide that a limitation to so-called correct arguments in advance is\ncounterproductive. We suggest that an application specific informal logic must\nbe developed for dealing with the principles of interest prohibition theory.\n"
    },
    {
        "paper_id": 1104.0322,
        "authors": "Dan Pirjol",
        "title": "Explosive behavior in a log-normal interest rate model",
        "comments": "20 pages, 5 figures. Revised version published in IJTAF",
        "journal-ref": "International Journal of Theoretical and Applied Finance, vol. 16,\n  p.1350023 (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an interest rate model with log-normally distributed rates in the\nterminal measure in discrete time. Such models are used in financial practice\nas parametric versions of the Markov functional model, or as approximations to\nthe log-normal Libor market model. We show that the model has two distinct\nregimes, at high and low volatilities, with different qualitative behavior. The\ntwo regimes are separated by a sharp transition, which is similar to a phase\ntransition in condensed matter physics. We study the behavior of the model in\nthe large volatility phase, and discuss the implications of the phase\ntransition for the pricing of interest rate derivatives. In the large\nvolatility phase, certain expectation values and convexity adjustments have an\nexplosive behavior. For sufficiently low volatilities the caplet smile is\nlog-normal to a very good approximation, while in the large volatility phase\nthe model develops a non-trivial caplet skew. The phenomenon discussed here\nimposes thus an upper limit on the volatilities for which the model behaves as\nintended.\n"
    },
    {
        "paper_id": 1104.0359,
        "authors": "Takashi Kato",
        "title": "Theoretical Sensitivity Analysis for Quantitative Operational Risk\n  Management",
        "comments": "21 pages, 1 figure, 4 tables, forthcoming in International Journal of\n  Theoretical and Applied Finance (IJTAF)",
        "journal-ref": "International Journal of Theoretical and Applied Finance, Vol.20,\n  No.5 (2017), 23 pages",
        "doi": "10.1142/S0219024917500327",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the asymptotic behavior of the difference between the values at risk\nVaR(L) and VaR(L+S) for heavy tailed random variables L and S for application\nin sensitivity analysis of quantitative operational risk management within the\nframework of the advanced measurement approach of Basel II (and III). Here L\ndescribes the loss amount of the present risk profile and S describes the loss\namount caused by an additional loss factor. We obtain different types of\nresults according to the relative magnitudes of the thicknesses of the tails of\nL and S. In particular, if the tail of S is sufficiently thinner than the tail\nof L, then the difference between prior and posterior risk amounts VaR(L+S) -\nVaR(L) is asymptotically equivalent to the expectation (expected loss) of S.\n"
    },
    {
        "paper_id": 1104.0508,
        "authors": "Alexander Cherny and Damir Filipovi\\'c",
        "title": "Concave Distortion Semigroups",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem behind this paper is the proper measurement of the degree of\nquality/acceptability/distance to arbitrage of trades. We are narrowing the\nclass of coherent acceptability indices introduced by Cherny and Madan (2007)\nby imposing an additional mathematical property. For this, we introduce the\nnotion of a concave distortion semigroup as a family $(\\Psi_t)_{t\\ge0}$ of\nconcave increasing functions $[0,1]\\to[0,1]$ satisfying the semigroup property\n$$ \\Psi_s\\circ\\Psi_t=\\Psi_{s+t},\\quad s,t\\ge0. $$ The goal of the paper is the\ninvestigation of these semigroups with regard to the following aspects:\nrepresentation of distortion semigroups; properties of distortion semigroups\ndesirable from the economical or mathematical perspective; determining which\nconcave distortions belong to some distortion semigroup.\n"
    },
    {
        "paper_id": 1104.0587,
        "authors": "Bence Toth, Zoltan Eisler, Fabrizio Lillo, Julien Kockelkoren,\n  Jean-Philippe Bouchaud, J. Doyne Farmer",
        "title": "How does the market react to your order flow?",
        "comments": "22 pages, 5+9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an empirical study of the intertwined behaviour of members in a\nfinancial market. Exploiting a database where the broker that initiates an\norder book event can be identified, we decompose the correlation and response\nfunctions into contributions coming from different market participants and\nstudy how their behaviour is interconnected. We find evidence that (1) brokers\nare very heterogeneous in liquidity provision -- some are consistently\nliquidity providers while others are consistently liquidity takers. (2) The\nbehaviour of brokers is strongly conditioned on the actions of {\\it other}\nbrokers. In contrast brokers are only weakly influenced by the impact of their\nown previous orders. (3) The total impact of market orders is the result of a\nsubtle compensation between the same broker pushing the price in one direction\nand the liquidity provision of other brokers pushing it in the opposite\ndirection. These results enforce the picture of market dynamics being the\nresult of the competition between heterogeneous participants interacting to\nform a complicated market ecology.\n"
    },
    {
        "paper_id": 1104.0761,
        "authors": "Mathias Beiglboeck, Johannes Muhle-Karbe, Johannes Temme",
        "title": "Utility Maximization, Risk Aversion, and Stochastic Dominance",
        "comments": "14 pages, 1 figure, to appear in Mathematics and Financial Economics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider an investor trading dynamically to maximize expected utility from\nterminal wealth. Our aim is to study the dependence between her risk aversion\nand the distribution of the optimal terminal payoff.\n  Economic intuition suggests that high risk aversion leads to a rather\nconcentrated distribution, whereas lower risk aversion results in a higher\naverage payoff at the expense of a more widespread distribution.\n  Dybvig and Wang [J. Econ. Theory, 2011, to appear] find that this idea can\nindeed be turned into a rigorous mathematical statement in one-period models.\nMore specifically, they show that lower risk aversion leads to a payoff which\nis larger in terms of second order stochastic dominance.\n  In the present study, we extend their results to (weakly) complete\ncontinuous-time models. We also complement an ad-hoc counterexample of Dybvig\nand Wang, by showing that these results are \"fragile\", in the sense that they\nfail in essentially any model, if the latter is perturbed on a set of\narbitrarily small probability. On the other hand, we establish that they hold\nfor power investors in models with (conditionally) independent increments.\n"
    },
    {
        "paper_id": 1104.0777,
        "authors": "Jean-Philippe Timsit and Annick Castiaux",
        "title": "If Entry Strategy and Money go Together, What is the Right Side of the\n  Coin?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The goal of this study is to determine which strategic model, either IO or\nRBV, allows firms to generate the highest performance on a competitive market.\nContrasting with classical studies that mobilize analyses as VARCOMP, we deploy\na multi-agent system simulating the behavior of firms adopting RBV or IO\nstrategic models. For an equivalent proportion of both strategic orientations,\nwe study the instant and total performances of the firms on hypercompetitive\nmarkets. We show that the performance of best-performing IO firms, measured by\nthe ROA, is higher in the short term, but that RBV firms obtain an average\nhigher sustained performance, in the long term. Moreover, when they are in\ncompetition with IO firms on a highly profitable and competitive market, RBV\nfirms which dare to enter such markets obtained generally the highest\nperformance.\n"
    },
    {
        "paper_id": 1104.1773,
        "authors": "Kay Giesecke, Konstantinos Spiliopoulos, Richard B. Sowers",
        "title": "Default clustering in large portfolios: Typical events",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP845 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 1, 348-385",
        "doi": "10.1214/12-AAP845",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a dynamic point process model of correlated default timing in a\nportfolio of firms, and analyze typical default profiles in the limit as the\nsize of the pool grows. In our model, a firm defaults at a stochastic intensity\nthat is influenced by an idiosyncratic risk process, a systematic risk process\ncommon to all firms, and past defaults. We prove a law of large numbers for the\ndefault rate in the pool, which describes the \"typical\" behavior of defaults.\n"
    },
    {
        "paper_id": 1104.1855,
        "authors": "Masaaki Fujii, Akihiko Takahashi",
        "title": "Collateralized CDS and Default Dependence",
        "comments": "16pages, 2 fugures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we have studied the pricing of a continuously collateralized\nCDS. We have made use of the \"survival measure\" to derive the pricing formula\nin a straightforward way. As a result, we have found that there exists\nirremovable trace of the counter party as well as the investor in the price of\nCDS through their default dependence even under the perfect collateralization,\nalthough the hazard rates of the two parties are totally absent from the\npricing formula. As an important implication, we have also studied the\nsituation where the investor enters an offsetting back-to-back trade with\nanother counter party. We have provided simple numerical examples to\ndemonstrate the change of a fair CDS premium according to the strength of\ndefault dependence among the relevant names, and then discussed its possible\nimplications for the risk management of the central counter parties.\n"
    },
    {
        "paper_id": 1104.2124,
        "authors": "Michel Fliess (LIX), C\\'edric Join (CRAN, INRIA Saclay - Ile de\n  France), Fr\\'ed\\'eric Hatt",
        "title": "Is a probabilistic modeling really useful in financial engineering? -\n  A-t-on vraiment besoin d'un mod\\`ele probabiliste en ing\\'enierie\n  financi\\`ere ?",
        "comments": "Conf\\'erence M\\'editerran\\'eenne sur l'Ing\\'enierie S\\^ure des\n  Syst\\`emes Complexes, MISC 2011, Agadir : Maroc (2011)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new standpoint on financial time series, without the use of any\nmathematical model and of probabilistic tools, yields not only a rigorous\napproach of trends and volatility, but also efficient calculations which were\nalready successfully applied in automatic control and in signal processing. It\nis based on a theorem due to P. Cartier and Y. Perrin, which was published in\n1995. The above results are employed for sketching a dynamical portfolio and\nstrategy management, without any global optimization technique. Numerous\ncomputer simulations are presented.\n"
    },
    {
        "paper_id": 1104.2187,
        "authors": "R. Lopez-Ruiz, E. Shivanian, S. Abbasbandy and J.L. Lopez",
        "title": "A Generalized Continuous Model for Random Markets",
        "comments": "11 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A generalized continuous economic model is proposed for random markets. In\nthis model, agents interact by pairs and exchange their money in a random way.\nA parameter controls the effectiveness of the transactions between the agents.\nWe show in a rigorous way that this type of markets reach their asymptotic\nequilibrium on the exponential wealth distribution.\n"
    },
    {
        "paper_id": 1104.2308,
        "authors": "Aleksey Kharevsky",
        "title": "Non - Randomness Stock Market Price Model (Amended)",
        "comments": "Typos on pages 6 and 7 of the earlier version has been corrected",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new model for the stock market price analysis is proposed. It is suggested\nto look at price as an everywhere discontinuous function of time of bounded\nvariation.\n"
    },
    {
        "paper_id": 1104.2344,
        "authors": "Michael Coopersmith",
        "title": "Interest Rates and Inflation",
        "comments": "3 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A relation between interest rates and inflation is presented using a two\ncomponent economic model and a simple general principle. Preliminary results\nindicate a remarkable similarity to classical economic theories, in particular\nthat of Wicksell.\n"
    },
    {
        "paper_id": 1104.2471,
        "authors": "J. A. Bergstra, C. A. Middelburg",
        "title": "Interest prohibition and financial product innovation",
        "comments": "9 pages",
        "journal-ref": "Finance Islamique: Regard(s) sur une Finance Alternative, pages\n  274--284, Mazars Hadj Ali, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give a rough sketch of the Judaic, Greek, Islamic and Christian positions\nin the matter of interest prohibition during the last few millennia and discuss\nthe way in which interest prohibition is dealt with in Islamic finance, the\nproblems with authority-based arguments for interest prohibition, and the\nprospects of interest prohibition with the advent of electronic money.\n"
    },
    {
        "paper_id": 1104.2606,
        "authors": "Agata Fronczak and Piotr Fronczak",
        "title": "Statistical mechanics of the international trade network",
        "comments": "6 pages, 2 figures",
        "journal-ref": "Phys. Rev. E 85, 056113 (2012)",
        "doi": "10.1103/PhysRevE.85.056113",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Analyzing real data on international trade covering the time interval\n1950-2000, we show that in each year over the analyzed period the network is a\ntypical representative of the ensemble of maximally random weighted networks,\nwhose directed connections (bilateral trade volumes) are only characterized by\nthe product of the trading countries' GDPs. It means that time evolution of\nthis network may be considered as a continuous sequence of equilibrium states,\ni.e. quasi-static process. This, in turn, allows one to apply the linear\nresponse theory to make (and also verify) simple predictions about the network.\nIn particular, we show that bilateral trade fulfills fluctuation-response\ntheorem, which states that the average relative change in import (export)\nbetween two countries is a sum of relative changes in their GDPs. Yearly\nchanges in trade volumes prove that the theorem is valid.\n"
    },
    {
        "paper_id": 1104.2625,
        "authors": "Tomasz R. Bielecki, Igor Cialenco, Ismail Iyigunler",
        "title": "Counterparty Risk and the Impact of Collateralization in CDS Contracts",
        "comments": "27 pages, 2 Figures. Forthcoming in Robert Elliott Festschrift",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the counterparty risk embedded in CDS contracts, in presence of a\nbilateral margin agreement. First, we investigate the pricing of collateralized\ncounterparty risk and we derive the bilateral Credit Valuation Adjustment\n(CVA), unilateral Credit Valuation Adjustment (UCVA) and Debt Valuation\nAdjustment (DVA). We propose a model for the collateral by incorporating all\nrelated factors such as the thresholds, haircuts and margin period of risk. We\nderive the dynamics of the bilateral CVA in a general form with related jump\nmartingales. We also introduce the Spread Value Adjustment (SVA) indicating the\ncounterparty risk adjusted spread. Counterparty risky and the counterparty\nrisk-free spread dynamics are derived and the dynamics of the SVA is found as a\nconsequence. We finally employ a Markovian copula model for default intensities\nand illustrate our findings with numerical results.\n"
    },
    {
        "paper_id": 1104.3328,
        "authors": "Bernard Bercu, Frederic Proia",
        "title": "A sharp analysis on the asymptotic behavior of the Durbin-Watson\n  statistic for the first-order autoregressive process",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this paper is to provide a sharp analysis on the asymptotic\nbehavior of the Durbin-Watson statistic. We focus our attention on the\nfirst-order autoregressive process where the driven noise is also given by a\nfirst-order autoregressive process. We establish the almost sure convergence\nand the asymptotic normality for both the least squares estimator of the\nunknown parameter of the autoregressive process as well as for the serial\ncorrelation estimator associated to the driven noise. In addition, the almost\nsure rates of convergence of our estimates are also provided. It allows us to\nestablish the almost sure convergence and the asymptotic normality for the\nDurbin-Watson statistic. Finally, we propose a new bilateral statistical test\nfor residual autocorrelation.\n"
    },
    {
        "paper_id": 1104.3583,
        "authors": "Alexander M. G. Cox, Jiajie Wang",
        "title": "Root's barrier: Construction, optimality and applications to variance\n  options",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP857 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 3, 859-894",
        "doi": "10.1214/12-AAP857",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent work of Dupire and Carr and Lee has highlighted the importance of\nunderstanding the Skorokhod embedding originally proposed by Root for the\nmodel-independent hedging of variance options. Root's work shows that there\nexists a barrier from which one may define a stopping time which solves the\nSkorokhod embedding problem. This construction has the remarkable property,\nproved by Rost, that it minimizes the variance of the stopping time among all\nsolutions. In this work, we prove a characterization of Root's barrier in terms\nof the solution to a variational inequality, and we give an alternative proof\nof the optimality property which has an important consequence for the\nconstruction of subhedging strategies in the financial context.\n"
    },
    {
        "paper_id": 1104.3616,
        "authors": "Wei-Xing Zhou (ECUST), Guo-Hua Mu (ECUST), Wei Chen (SZSE), Didier\n  Sornette (ETH Zurich)",
        "title": "Strategies used as spectroscopy of financial markets reveal new stylized\n  facts",
        "comments": "13 pages including 5 figures and 1 table",
        "journal-ref": "PLoS ONE 6 (9), e24391 (2011)",
        "doi": "10.1371/journal.pone.0024391",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new set of stylized facts quantifying the structure of financial\nmarkets. The key idea is to study the combined structure of both investment\nstrategies and prices in order to open a qualitatively new level of\nunderstanding of financial and economic markets. We study the detailed order\nflow on the Shenzhen Stock Exchange of China for the whole year of 2003. This\nenormous dataset allows us to compare (i) a closed national market (A-shares)\nwith an international market (B-shares), (ii) individuals and institutions and\n(iii) real investors to random strategies with respect to timing that share\notherwise all other characteristics. We find that more trading results in\nsmaller net return due to trading frictions. We unveiled quantitative power\nlaws with non-trivial exponents, that quantify the deterioration of performance\nwith frequency and with holding period of the strategies used by investors.\nRandom strategies are found to perform much better than real ones, both for\nwinners and losers. Surprising large arbitrage opportunities exist, especially\nwhen using zero-intelligence strategies. This is a diagnostic of possible\ninefficiencies of these financial markets.\n"
    },
    {
        "paper_id": 1104.401,
        "authors": "David Hobson, Martin Klimmek",
        "title": "Model independent hedging strategies for variance swaps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A variance swap is a derivative with a path-dependent payoff which allows\ninvestors to take positions on the future variability of an asset. In the\nidealised setting of a continuously monitored variance swap written on an asset\nwith continuous paths it is well known that the variance swap payoff can be\nreplicated exactly using a portfolio of puts and calls and a dynamic position\nin the asset. This fact forms the basis of the VIX contract.\n  But what if we are in the more realistic setting where the contract is based\non discrete monitoring, and the underlying asset may have jumps? We show that\nit is possible to derive model-independent, no-arbitrage bounds on the price of\nthe variance swap, and corresponding sub- and super-replicating strategies.\nFurther, we characterise the optimal bounds. The form of the hedges depends\ncrucially on the kernel used to define the variance swap.\n"
    },
    {
        "paper_id": 1104.4234,
        "authors": "Mauro Politi, Taisei Kaizoji, Enrico Scalas",
        "title": "Full characterization of the fractional Poisson process",
        "comments": "4 figures, paper submitted to PRL",
        "journal-ref": null,
        "doi": "10.1209/0295-5075/96/20004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The fractional Poisson process (FPP) is a counting process with independent\nand identically distributed inter-event times following the Mittag-Leffler\ndistribution. This process is very useful in several fields of applied and\ntheoretical physics including models for anomalous diffusion. Contrary to the\nwell-known Poisson process, the fractional Poisson process does not have\nstationary and independent increments. It is not a L\\'evy process and it is not\na Markov process. In this letter, we present formulae for its\nfinite-dimensional distribution functions, fully characterizing the process.\nThese exact analytical results are compared to Monte Carlo simulations.\n"
    },
    {
        "paper_id": 1104.4249,
        "authors": "Tilman Dette, Scott Pauls, Daniel N. Rockmore",
        "title": "Robustness and Contagion in the International Financial Network",
        "comments": "18 pages, 7 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The recent financial crisis of 2008 and the 2011 indebtedness of Greece\nhighlight the importance of understanding the structure of the global financial\nnetwork. In this paper we set out to analyze and characterize this network, as\ncaptured by the IMF Coordinated Portfolio Investment Survey (CPIS), in two\nways. First, through an adaptation of the \"error and attack\" methodology [1],\nwe show that the network is of the \"robust-yet-fragile\" type, a topology found\nin a wide variety of evolved networks. We compare these results against four\ncommon null-models, generated only from first-order statistics of the empirical\ndata. In addition, we suggest a fifth, log-normal model, which generates\nnetworks that seem to match the empirical one more closely. Still, this model\ndoes not account for several higher order network statistics, which reenforces\nthe added value of the higher-order analysis. Second, using loss-given-default\ndynamics [2], we model financial interdependence and potential cascading of\nfinancial distress through the network. Preliminary simulations indicate that\ndefault by a single relatively small country like Greece can be absorbed by the\nnetwork, but that default in combination with defaults of other PIGS countries\n(Portugal, Ireland, and Spain) could lead to a massive extinction cascade in\nthe global economy.\n"
    },
    {
        "paper_id": 1104.438,
        "authors": "N. Foti, S. Pauls, Daniel N. Rockmore",
        "title": "Stability of the World Trade Web over Time - An Extinction Analysis",
        "comments": "20 pages, 6 Figures, 3 Tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The World Trade Web (WTW) is a weighted network whose nodes correspond to\ncountries with edge weights reflecting the value of imports and/or exports\nbetween countries. In this paper we introduce to this macroeconomic system the\nnotion of extinction analysis, a technique often used in the analysis of\necosystems, for the purposes of investigating the robustness of this network.\nIn particular, we subject the WTW to a principled set of in silico \"knockout\nexperiments,\" akin to those carried out in the investigation of food webs, but\nsuitably adapted to this macroeconomic network. Broadly, our experiments show\nthat over time the WTW moves to a \"robust yet fragile\" configuration where it\nis robust to random failures but fragile under targeted attack. This change in\nstability is highly correlated with the connectance (edge density) of the\nnetwork. Moreover, there is evidence of a sharp change in the structure of the\nnetwork in the 1960s and 1970s, where most measures of robustness rapidly\nincrease before resuming a declining trend. We interpret these results in the\ncontext in the post-World War II move towards globalization. Globalization\ncoincides with the sharp increase in robustness but also with a rise in those\nmeasures (e.g., connectance and trade imbalances) which correlate with\ndecreases in robustness. The peak of robustness is reached after the onset of\nglobalization policy but before the negative impacts are substantial. These\nanalyses depend on a simple model of dynamics that rebalances the trade flow\nupon network perturbation, the most dramatic of which is node deletion. More\nsubtle and textured forms of perturbation lead to the definition of other\nmeasures of node importance as well as vulnerability. We anticipate that\nexperiments and measures like these can play an important role in the\nevaluation of the stability of economic systems.\n"
    },
    {
        "paper_id": 1104.4548,
        "authors": "Yuri Imamura and Katsuya Takagi",
        "title": "Semi-Static Hedging Based on a Generalized Reflection Principle on a\n  Multi Dimensional Brownian Motion",
        "comments": "Asia-Pacific Financial Markets, online first",
        "journal-ref": null,
        "doi": "10.1007/s10690-012-9159-7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  On a multi-assets Black-Scholes economy, we introduce a class of barrier\noptions. In this model we apply a generalized reflection principle in a context\nof the finite reflection group acting on a Euclidean space to give a valuation\nformula and the semi-static hedge.\n"
    },
    {
        "paper_id": 1104.4596,
        "authors": "Rama Cont, Adrien De Larrard",
        "title": "Price dynamics in a Markovian limit order market",
        "comments": "18 pages, 5 figures",
        "journal-ref": "SIAM Journal on Financial Mathematics, Vol 4, No 1, 1-25 (2013)",
        "doi": "10.1137/110856605",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose and study a simple stochastic model for the dynamics of a limit\norder book, in which arrivals of market order, limit orders and order\ncancellations are described in terms of a Markovian queueing system. Through\nits analytical tractability, the model allows to obtain analytical expressions\nfor various quantities of interest such as the distribution of the duration\nbetween price changes, the distribution and autocorrelation of price changes,\nand the probability of an upward move in the price, {\\it conditional} on the\nstate of the order book. We study the diffusion limit of the price process and\nexpress the volatility of price changes in terms of parameters describing the\narrival rates of buy and sell orders and cancelations. These analytical results\nprovide some insight into the relation between order flow and price dynamics in\norder-driven markets.\n"
    },
    {
        "paper_id": 1104.4716,
        "authors": "D. Horvath, R. Pincak",
        "title": "From the currency rate quotations onto strings and brane world scenarios",
        "comments": "SORS Research a.s, 040 01 Kosice, Slovak Republic, 28 pages, 10\n  figures",
        "journal-ref": "Physica A 391 (2012) 5172-5188",
        "doi": "10.1016/j.physa.2012.06.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the paper, we study numerically the projections of the real exchange rate\ndynamics onto the string-like topology. Our approach is inspired by the\ncontemporary movements in the string theory. The string map of data is defined\nhere by the boundary conditions, characteristic length, real valued and the\nmethod of redistribution of information. As a practical matter, this map\nrepresents the detrending and data standardization procedure. We introduced\nmaps onto 1-end-point and 2-end-point open strings that satisfy the Dirichlet\nand Neumann boundary conditions. The questions of the choice of\nextra-dimensions, symmetries, duality and ways to the partial compactification\nare discussed. Subsequently, we pass to higher dimensional and more complex\nobjects. The 2D-Brane was suggested which incorporated bid-ask spreads.\nPolarization by the spread was considered which admitted analyzing arbitrage\nopportunities on the market where transaction costs are taken into account. The\nmodel of the rotating string which naturally yields calculation of angular\nmomentum is suitable for tracking of several currency pairs. The systematic way\nwhich allows one suggest more structured maps suitable for a simultaneous study\nof several currency pairs was analyzed by means of the G\\^{a}teaux generalized\ndifferential calculus. The effect of the string and brane maps on test data was\nstudied by comparing their mean statistical characteristics. The study revealed\nnotable differences between topologies. We review the dependence on the\ncharacteristic string length, mean fluctuations and properties of the\nintra-string statistics. The study explores the coupling of the string\namplitude and volatility.\n"
    },
    {
        "paper_id": 1104.5131,
        "authors": "Lokman Abbas-Turki (LAMA), Bernard Lapeyre (CERMICS)",
        "title": "American Options Based on Malliavin Calculus and Nonparametric Variance\n  Reduction Methods",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is devoted to pricing American options using Monte Carlo and the\nMalliavin calculus. Unlike the majority of articles related to this topic, in\nthis work we will not use localization fonctions to reduce the variance. Our\nmethod is based on expressing the conditional expectation E[f(St)/Ss] using the\nMalliavin calculus without localization. Then the variance of the estimator of\nE[f(St)/Ss] is reduced using closed formulas, techniques based on a\nconditioning and a judicious choice of the number of simulated paths. Finally,\nwe perform the stopping times version of the dynamic programming algorithm to\ndecrease the bias. On the one hand, we will develop the Malliavin calculus\ntools for exponential multi-dimensional diffusions that have deterministic and\nno constant coefficients. On the other hand, we will detail various\nnonparametric technics to reduce the variance. Moreover, we will test the\nnumerical efficiency of our method on a heterogeneous CPU/GPU multi-core\nmachine.\n"
    },
    {
        "paper_id": 1104.5272,
        "authors": "Younes Kchia and Martin Larsson",
        "title": "Credit contagion and risk management with multiple non-ordered defaults",
        "comments": "This paper has been withdrawn by the authors because some of the main\n  results have significant overlap with others available in the literature",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The classical reduced-form and filtration expansion framework in credit risk\nis extended to the case of multiple, non-ordered defaults, assuming that\nconditional densities of the default times exist. Intensities and pricing\nformulas are derived, revealing how information driven default contagion arises\nin these models. We then analyze the impact of ordering the default times\nbefore expanding the filtration. While not important for pricing, the effect is\nsignificant in the context of risk management, and becomes even more pronounced\nfor highly correlated and asymmetrically distributed defaults. Finally, we\nprovide a general scheme for constructing and simulating the default times,\ngiven that a model for the conditional densities has been chosen.\n"
    },
    {
        "paper_id": 1104.5326,
        "authors": "Damir Filipovi\\'c and Eberhard Mayerhofer and Paul Schneider",
        "title": "Density Approximations for Multivariate Affine Jump-Diffusion Processes",
        "comments": null,
        "journal-ref": "Journal of Econometrics,Volume 176, Issue 2, October 2013, Pages\n  93-111",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce closed-form transition density expansions for multivariate\naffine jump-diffusion processes. The expansions rely on a general approximation\ntheory which we develop in weighted Hilbert spaces for random variables which\npossess all polynomial moments. We establish parametric conditions which\nguarantee existence and differentiability of transition densities of affine\nmodels and show how they naturally fit into the approximation framework.\nEmpirical applications in credit risk, likelihood inference, and option pricing\nhighlight the usefulness of our expansions. The approximations are extremely\nfast to evaluate, and they perform very accurately and numerically stable.\n"
    },
    {
        "paper_id": 1104.5393,
        "authors": "Vic Norton",
        "title": "Notional portfolios and normalized linear returns",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The vector of periodic, compound returns of a typical investment portfolio is\nalmost never a convex combination of the return vectors of the securities in\nthe portfolio. As a result the ex post version of Harry Markowitz's \"standard\nmean-variance portfolio selection model\" does not apply to compound return\ndata. We propose using notional portfolios and normalized linear returns to\nremedy this problem.\n"
    },
    {
        "paper_id": 1105.0042,
        "authors": "Agostino Capponi and Jose E. Figueroa-Lopez",
        "title": "Dynamic Portfolio Optimization with a Defaultable Security and Regime\n  Switching",
        "comments": "40 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a portfolio optimization problem in a defaultable market with\nfinitely-many economical regimes, where the investor can dynamically allocate\nher wealth among a defaultable bond, a stock, and a money market account. The\nmarket coefficients are assumed to depend on the market regime in place, which\nis modeled by a finite state continuous time Markov process. We rigorously\ndeduce the dynamics of the defaultable bond price process in terms of a Markov\nmodulated stochastic differential equation. Then, by separating the utility\nmaximization problem into the pre-default and post-default scenarios, we deduce\ntwo coupled Hamilton-Jacobi-Bellman equations for the post and pre-default\noptimal value functions and show a novel verification theorem for their\nsolutions. We obtain explicit optimal investment strategies and value functions\nfor an investor with logarithmic utility. We finish with an economic analysis\nin the case of a market with two regimes and homogenous transition rates, and\nshow the impact of the default intensities and loss rates on the optimal\nstrategies and value functions.\n"
    },
    {
        "paper_id": 1105.0068,
        "authors": "Lucia Caramellino, Giorgio Ferrari, Roberta Piersimoni",
        "title": "Power Series Representations for European Option Prices under Stochastic\n  Volatility Models",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the context of stochastic volatility models, we study representation\nformulas in terms of expectations for the power series' coefficients associated\nto the call price-function. As in a recent paper by Antonelli and Scarlatti the\nexpansion is done w.r.t. the correlation between the noises driving the\nunderlying asset price process and the volatility process. We first obtain\nexpressions for the power series' coefficients from the generalized Hull and\nWhite formula obtained by Elisa Al\\`os. Afterwards, we provide representations\nturning out from the approach for the sensitivity problem tackled by Malliavin\ncalculus techniques, and these allow to handle not only vanilla options.\nFinally, we show the numerical performance of the associated Monte Carlo\nestimators for several stochastic volatility models.\n"
    },
    {
        "paper_id": 1105.0238,
        "authors": "Masahiko Egami, Tim S. T. Leung and Kazutoshi Yamazaki",
        "title": "Default Swap Games Driven by Spectrally Negative Levy Processes",
        "comments": "34pages, 4 figures",
        "journal-ref": "Stochastic Processes and their Applications Volume 123, Issue 2,\n  2013, Pages 347--384",
        "doi": "10.1016/j.spa.2012.09.008",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies game-type credit default swaps that allow the protection\nbuyer and seller to raise or reduce their respective positions once prior to\ndefault. This leads to the study of an optimal stopping game subject to early\ndefault termination. Under a structural credit risk model based on spectrally\nnegative Levy processes, we apply the principles of smooth and continuous fit\nto identify the equilibrium exercise strategies for the buyer and the seller.\nWe then rigorously prove the existence of the Nash equilibrium and compute the\ncontract value at equilibrium. Numerical examples are provided to illustrate\nthe impacts of default risk and other contractual features on the players'\nexercise timing at equilibrium.\n"
    },
    {
        "paper_id": 1105.0247,
        "authors": "Erhan Bayraktar and Michael Ludkovski",
        "title": "Liquidation in Limit Order Books with Controlled Intensity",
        "comments": "23 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a framework for solving optimal liquidation problems in limit\norder books. In particular, order arrivals are modeled as a point process whose\nintensity depends on the liquidation price. We set up a stochastic control\nproblem in which the goal is to maximize the expected revenue from liquidating\nthe entire position held. We solve this optimal liquidation problem for\npower-law and exponential-decay order book models and discuss several\nextensions. We also consider the continuous selling (or fluid) limit when the\ntrading units are ever smaller and the intensity is ever larger. This limit\nprovides an analytical approximation to the value function and the optimal\nsolution. Using techniques from viscosity solutions we show that the discrete\nstate problem and its optimal solution converge to the corresponding quantities\nin the continuous selling limit uniformly on compacts.\n"
    },
    {
        "paper_id": 1105.0284,
        "authors": "Damien Lamberton and Mohammed Mikou",
        "title": "Exercise Boundary of the American Put Near Maturity in an Exponential\n  L\\'evy Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the behavior of the critical price of an American put option near\nmaturity in the exponential L\\'evy model when the underlying stock pays\ndividends at a continuous rate. In particular, we prove that, in situations\nwhere the limit of the critical price is equal to the stock price, the rate of\nconvergence to the limit is linear if and only if the underlying L\\'evy process\nhas finite variation. In the case of infinite variation, a variety of rates of\nconvergence can be observed: we prove that, when the negative part of the\nL\\'evy measure exhibits an $\\alpha$-stable density near the origin, with\n$1<\\alpha<2$, the convergence rate is ruled by $\\theta^{1/\\alpha}|\\ln\n\\theta|^{1-\\frac{1}{\\alpha}}$, where $\\theta$ is time until maturity.\n"
    },
    {
        "paper_id": 1105.0745,
        "authors": "Bruno Bouchard, Marcel Nutz",
        "title": "Weak Dynamic Programming for Generalized State Constraints",
        "comments": "36 pages;forthcoming in 'SIAM Journal on Control and Optimization'",
        "journal-ref": "SIAM Journal on Control and Optimization, Vol. 50, No. 6, pp.\n  3344-3373, 2012",
        "doi": "10.1137/110852942",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a dynamic programming principle for stochastic optimal control\nproblems with expectation constraints. A weak formulation, using test functions\nand a probabilistic relaxation of the constraint, avoids restrictions related\nto a measurable selection but still implies the Hamilton-Jacobi-Bellman\nequation in the viscosity sense. We treat open state constraints as a special\ncase of expectation constraints and prove a comparison theorem to obtain the\nequation for closed state constraints.\n"
    },
    {
        "paper_id": 1105.0819,
        "authors": "Simone Pigolotti, Sebastian Bernhardsson, Jeppe Juul, Gorm Galster,\n  Pierpaolo Vivo",
        "title": "Equilibrium strategy and population-size effects in lowest unique bid\n  auctions",
        "comments": "6 pag. - 7 figs - added Supplementary Material. Changed affiliations.\n  Published version",
        "journal-ref": "Phys. Rev. Lett. 108, 088701 (2012)",
        "doi": "10.1103/PhysRevLett.108.088701",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In lowest unique bid auctions, $N$ players bid for an item. The winner is\nwhoever places the \\emph{lowest} bid, provided that it is also unique. We use a\ngrand canonical approach to derive an analytical expression for the equilibrium\ndistribution of strategies. We then study the properties of the solution as a\nfunction of the mean number of players, and compare them with a large dataset\nof internet auctions. The theory agrees with the data with striking accuracy\nfor small population size $N$, while for larger $N$ a qualitatively different\ndistribution is observed. We interpret this result as the emergence of two\ndifferent regimes, one in which adaptation is feasible and one in which it is\nnot. Our results question the actual possibility of a large population to adapt\nand find the optimal strategy when participating in a collective game.\n"
    },
    {
        "paper_id": 1105.0934,
        "authors": "Teemu Pennanen and Ari-Pekka Perkki\\\"o",
        "title": "Stochastic programs without duality gaps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies dynamic stochastic optimization problems parametrized by a\nrandom variable. Such problems arise in many applications in operations\nresearch and mathematical finance. We give sufficient conditions for the\nexistence of solutions and the absence of a duality gap. Our proof uses\nextended dynamic programming equations, whose validity is established under new\nrelaxed conditions that generalize certain no-arbitrage conditions from\nmathematical finance.\n"
    },
    {
        "paper_id": 1105.1267,
        "authors": "Peter Friz, Stefan Gerhold",
        "title": "Don't stay local - extrapolation analytics for Dupire's local volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A robust implementation of a Dupire type local volatility model is an\nimportant issue for every option trading floor. Typically, this (inverse)\nproblem is solved in a two step procedure : (i) a smooth parametrization of the\nimplied volatility surface; (ii) computation of the local volatility based on\nthe resulting call price surface. Point (i), and in particular how to\nextrapolate the implied volatility in extreme strike regimes not seen in the\nmarket, has been the subject of numerous articles, starting with Lee (Math.\nFinance, 2004). In the present paper we give direct analytic insights into the\nasymptotic behavior of local volatility at extreme strikes.\n"
    },
    {
        "paper_id": 1105.1488,
        "authors": "Nikolai Dokuchaev",
        "title": "The structure of optimal portfolio strategies for continuous time\n  markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper studies problem of continuous time optimal portfolio selection for\na incom- plete market diffusion model. It is shown that, under some mild\nconditions, near optimal strategies for investors with different performance\ncriteria can be constructed using a limited number of fixed processes (mutual\nfunds), for a market with a larger number of available risky stocks. In other\nwords, a dimension reduction is achieved via a relaxed version of the Mutual\nFund Theorem.\n"
    },
    {
        "paper_id": 1105.1694,
        "authors": "Bence Toth, Yves Lemperiere, Cyril Deremble, Joachim de Lataillade,\n  Julien Kockelkoren, Jean-Philippe Bouchaud",
        "title": "Anomalous price impact and the critical nature of liquidity in financial\n  markets",
        "comments": "16 pages, 7 figures",
        "journal-ref": "Physical Review X 1, 021006 (2011)",
        "doi": "10.1103/PhysRevX.1.021006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a dynamical theory of market liquidity that predicts that the\naverage supply/demand profile is V-shaped and {\\it vanishes} around the current\nprice. This result is generic, and only relies on mild assumptions about the\norder flow and on the fact that prices are (to a first approximation)\ndiffusive. This naturally accounts for two striking stylized facts: first,\nlarge metaorders have to be fragmented in order to be digested by the liquidity\nfunnel, leading to long-memory in the sign of the order flow. Second, the\nanomalously small local liquidity induces a breakdown of linear response and a\ndiverging impact of small orders, explaining the \"square-root\" impact law, for\nwhich we provide additional empirical support. Finally, we test our arguments\nquantitatively using a numerical model of order flow based on the same minimal\ningredients.\n"
    },
    {
        "paper_id": 1105.1767,
        "authors": "D. Pinheiro, A. A. Pinto, S. Z. Xanthopoulos, A. N. Yannacopoulos",
        "title": "A projected gradient dynamical system modeling the dynamics of\n  bargaining",
        "comments": "31 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a projected gradient dynamical system as a model for a bargaining\nscheme for an asset for which the two interested agents have personal\nvaluations which do not initially coincide. The personal valuations are formed\nusing subjective beliefs concerning the future states of the world and the\nreservation prices are calculated using expected utility theory. The agents are\nnot rigid concerning their subjective probabilities and are willing to update\nthem under the pressure to reach finally an agreement concerning the asset. The\nproposed projected dynamical system, on the space of probability measures,\nprovides a model for the evolution of the agents beliefs during the bargaining\nperiod and is constructed so that agreement is reached under the minimum\npossible deviation of both agents from their initial beliefs. The convergence\nresults are shown using techniques from convex dynamics and Lyapunov function\ntheory.\n"
    },
    {
        "paper_id": 1105.1812,
        "authors": "Diederik Aerts and Sandro Sozzo",
        "title": "Contextual Risk and Its Relevance in Economics",
        "comments": "6 pages, 2 figures",
        "journal-ref": "Journal of Engineering Science and Technology Review, 4, pp.\n  241-245, 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Uncertainty in economics still poses some fundamental problems illustrated,\ne.g., by the Allais and Ellsberg paradoxes. To overcome these difficulties,\neconomists have introduced an interesting distinction between 'risk' and\n'ambiguity' depending on the existence of a (classical Kolmogorovian)\nprobabilistic structure modeling these uncertainty situations. On the other\nhand, evidence of everyday life suggests that 'context' plays a fundamental\nrole in human decisions under uncertainty. Moreover, it is well known from\nphysics that any probabilistic structure modeling contextual interactions\nbetween entities structurally needs a non-Kolmogorovian quantum-like framework.\nIn this paper we introduce the notion of 'contextual risk' with the aim of\nmodeling a substantial part of the situations in which usually only 'ambiguity'\nis present. More precisely, we firstly introduce the essentials of an\noperational formalism called 'the hidden measurement approach' in which\nprobability is introduced as a consequence of fluctuations in the interaction\nbetween entities and contexts. Within the hidden measurement approach we\npropose a 'sphere model' as a mathematical tool for situations in which\ncontextual risk occurs. We show that a probabilistic model of this kind is\nnecessarily non-Kolmogorovian, hence it requires either the formalism of\nquantum mechanics or a generalization of it. This insight is relevant, for it\nexplains the presence of quantum or, better, quantum-like, structures in\neconomics, as suggested by some authors, and can serve to solve the\naforementioned paradoxes.\n"
    },
    {
        "paper_id": 1105.1814,
        "authors": "Diederik Aerts and Sandro Sozzo",
        "title": "A Contextual Risk Model for the Ellsberg Paradox",
        "comments": "6 pages, 1 figure",
        "journal-ref": "Journal of Engineering Science and Technology Review, 4, pp.\n  246-250, 2012",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Allais and Ellsberg paradoxes show that the expected utility hypothesis\nand Savage's Sure-Thing Principle are violated in real life decisions. The\npopular explanation in terms of 'ambiguity aversion' is not completely\naccepted. On the other hand, we have recently introduced a notion of\n'contextual risk' to mathematically capture what is known as 'ambiguity' in the\neconomics literature. Situations in which contextual risk occurs cannot be\nmodeled by Kolmogorovian classical probabilistic structures, but a\nnon-Kolmogorovian framework with a quantum-like structure is needed. We prove\nin this paper that the contextual risk approach can be applied to the Ellsberg\nparadox, and elaborate a 'sphere model' within our 'hidden measurement\nformalism' which reveals that it is the overall conceptual landscape that is\nresponsible of the disagreement between actual human decisions and the\npredictions of expected utility theory, which generates the paradox. This\nresult points to the presence of a 'quantum conceptual layer' in human thought\nwhich is superposed to the usually assumed 'classical logical layer'.\n"
    },
    {
        "paper_id": 1105.2122,
        "authors": "Geoff Willis",
        "title": "Why Money Trickles Up - Wealth & Income Distributions",
        "comments": "45 pages of text, 36 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper combines ideas from classical economics and modern finance with\nthe general Lotka-Volterra models of Levy & Solomon to provide straightforward\nexplanations of wealth and income distributions. Using a simple and realistic\neconomic formulation, the distributions of both wealth and income are fully\nexplained. Both the power tail and the log-normal like body are fully captured.\nIt is of note that the full distribution, including the power law tail, is\ncreated via the use of absolutely identical agents. It is further demonstrated\nthat a simple scheme of compulsory saving could eliminate poverty at little\ncost to the taxpayer.\n"
    },
    {
        "paper_id": 1105.2123,
        "authors": "Geoff Willis",
        "title": "The Bowley Ratio",
        "comments": "6 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper gives a simple algebraic description, and background justification,\nfor the Bowley Ratio, the relative returns to labour and capital, in a simple\neconomy.\n"
    },
    {
        "paper_id": 1105.2414,
        "authors": "Fuzhou Gong, Hong Liu",
        "title": "Impact of heterogenous prior beliefs and disclosed insider trades",
        "comments": "35 pages, 16 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present a multi-period trading model by assuming that\ntraders face not only asymmetric information but also heterogenous prior\nbeliefs, under the requirement that the insider publicly disclose his stock\ntrades after the fact. We show that there is an equilibrium in which the\nirrational insider camouflages his trades with a noise component so that his\nprivate information is revealed slowly and linearly whenever he is\noverconfident or underconfident. We also investigate the relationship between\nthe heterogeneous beliefs and the trade intensity in the presence of trade\ndisclosure, and show that the weights on asymmetric information and\nheterogeneous prior beliefs are opposite in sign and they change alternatively\nin the next period. Under the requirement of disclosure, the irrational insider\ntrades more aggressively and leads to smaller market depth. Moreover, the\nco-existence of \"public disclosure requirement\" and \"heterogeneous prior\nbeliefs\" leads to the fluctuant multi-period expected profits and a larger\ntotal expected trading volume which is positively related to the degree of\nheterogeneity. More importantly, even public disclosure may lead to negative\nprofits of the irrational insider's in some periods, inside trading remains\nprofitable from the whole trading period.\n"
    },
    {
        "paper_id": 1105.29,
        "authors": "Jan Aldert Bergstra",
        "title": "Dialectical Roots for Interest Prohibition Theory",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is argued that arguments for strict prohibition of interests must be based\non the use of arguments from authority. This is carried out by first making a\nsurvey of so-called dialectical roots for interest prohibition and then\ndemonstrating that for at least one important positive interest bearing\nfinancial product, the savings account with interest, its prohibition cannot be\ninferred from a match with any of these root cases.\n"
    },
    {
        "paper_id": 1105.2956,
        "authors": "Vic Norton",
        "title": "Adjusted Closing Prices",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Historical returns depend on historical closing prices and distributions. We\ndescribe how to compute adjusted closing prices from closing price/distribution\ndata with an emphasis on spreadsheet implementation. Then the growth of a\nsecurity from one date to another (1 + total return) is just the ratio of the\ncorresponding adjusted closing prices.\n"
    },
    {
        "paper_id": 1105.2968,
        "authors": "Karol Przanowski",
        "title": "Banking retail consumer finance data generator - credit scoring data\n  repository",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  This paper presents two cases of random banking data generators based on\nmigration matrices and scoring rules. The banking data generator is a new hope\nin researches of finding the proving method of comparisons of various credit\nscoring techniques. There is analyzed the influence of one cyclic\nmacro--economic variable on stability in the time account and client\ncharacteristics. Data are very useful for various analyses to understand in the\nbetter way the complexity of the banking processes and also for students and\ntheir researches. There are presented very interesting conclusions for crisis\nbehavior, namely that if a crisis is impacted by many factors, both customer\ncharacteristics: application and behavioral; then there is very difficult to\nindicate these factors in the typical scoring analysis and the crisis is\neverywhere, in every kind of risk reports.\n"
    },
    {
        "paper_id": 1105.3115,
        "authors": "Olivier Gu\\'eant and Charles-Albert Lehalle and Joaquin Fernandez\n  Tapia",
        "title": "Dealing with the Inventory Risk. A solution to the market making problem",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/s11579-012-0087-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Market makers continuously set bid and ask quotes for the stocks they have\nunder consideration. Hence they face a complex optimization problem in which\ntheir return, based on the bid-ask spread they quote and the frequency at which\nthey indeed provide liquidity, is challenged by the price risk they bear due to\ntheir inventory. In this paper, we consider a stochastic control problem\nsimilar to the one introduced by Ho and Stoll and formalized mathematically by\nAvellaneda and Stoikov. The market is modeled using a reference price $S_t$\nfollowing a Brownian motion with standard deviation $\\sigma$, arrival rates of\nbuy or sell liquidity-consuming orders depend on the distance to the reference\nprice $S_t$ and a market maker maximizes the expected utility of its P&L over a\nfinite time horizon. We show that the Hamilton-Jacobi-Bellman equations\nassociated to the stochastic optimal control problem can be transformed into a\nsystem of linear ordinary differential equations and we solve the market making\nproblem under inventory constraints. We also shed light on the asymptotic\nbehavior of the optimal quotes and propose closed-form approximations based on\na spectral characterization of the optimal quotes.\n"
    },
    {
        "paper_id": 1105.318,
        "authors": "Jose E. Figueroa-Lopez and Martin Forde",
        "title": "The small-maturity smile for exponential Levy models",
        "comments": "25 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive a small-time expansion for out-of-the-money call options under an\nexponential Levy model, using the small-time expansion for the distribution\nfunction given in Figueroa-Lopez & Houdre (2009), combined with a change of\nnum\\'eraire via the Esscher transform. In particular, we quantify find that the\neffect of a non-zero volatility $\\sigma$ of the Gaussian component of the\ndriving L\\'{e}vy process is to increase the call price by $1/2\\sigma^2 t^2\ne^{k}\\nu(k)(1+o(1))$ as $t \\to 0$, where $\\nu$ is the L\\'evy density. Using the\nsmall-time expansion for call options, we then derive a small-time expansion\nfor the implied volatility, which sharpens the first order estimate given in\nTankov (2010). Our numerical results show that the second order approximation\ncan significantly outperform the first order approximation. Our results are\nalso extended to a class of time-changed L\\'evy models. We also consider a\nsmall-time, small log-moneyness regime for the CGMY model, and apply this\napproach to the small-time pricing of at-the-money call options.\n"
    },
    {
        "paper_id": 1105.3228,
        "authors": "Yuri Biondi, Pierpaolo Giannoccolo and Serge Galam",
        "title": "The formation of share market prices under heterogeneous beliefs and\n  common knowledge",
        "comments": "22 pages, 9 figures",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, Volume 391,\n  Issue 22, 15 November 2012, Pages 5532-5545",
        "doi": "10.1016/j.physa.2012.06.015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial economic models often assume that investors know (or agree on) the\nfundamental value of the shares of the firm, easing the passage from the\nindividual to the collective dimension of the financial system generated by the\nShare Exchange over time. Our model relaxes that heroic assumption of one\nunique \"true value\" and deals with the formation of share market prices through\nthe dynamic formation of individual and social opinions (or beliefs) based upon\na fundamental signal of economic performance and position of the firm, the\nforecast revision by heterogeneous individual investors, and their social mood\nor sentiment about the ongoing state of the market pricing process. Market\nclearing price formation is then featured by individual and group dynamics that\nmake its collective dimension irreducible to its individual level. This dynamic\nholistic approach can be applied to better understand the market exuberance\ngenerated by the Share Exchange over time.\n"
    },
    {
        "paper_id": 1105.3297,
        "authors": "Jan Baldeaux",
        "title": "Exact Simulation of the 3/2 Model",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper discusses the exact simulation of the stock price process\nunderlying the 3/2 model. Using a result derived by Craddock and Lennox using\nLie Symmetry Analysis, we adapt the Broadie-Kaya algorithm for the simulation\nof affine processes to the 3/2 model. We also discuss variance reduction\ntechniques and find that conditional Monte Carlo techniques combined with\nquasi-Monte Carlo point sets result in significant variance reductions.\n"
    },
    {
        "paper_id": 1105.3359,
        "authors": "Viorel Costeanu and Dan Pirjol",
        "title": "Asymptotic Expansion for the Normal Implied Volatility in Local\n  Volatility Models",
        "comments": "29 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the dynamics of the normal implied volatility in a local volatility\nmodel, using a small-time expansion in powers of maturity T. At leading order\nin this expansion, the asymptotics of the normal implied volatility is similar,\nup to a different definition of the moneyness, to that of the log-normal\nvolatility. This relation is preserved also to order O(T) in the small-time\nexpansion, and differences with the log-normal case appear first at O(T^2). The\nresults are illustrated on a few examples of local volatility models with\nanalytical local volatility, finding generally good agreement with exact or\nnumerical solutions. We point out that the asymptotic expansion can fail if\napplied naively for models with nonanalytical local volatility, for example\nwhich have discontinuous derivatives. Using perturbation theory methods, we\nshow that the ATM normal implied volatility for such a model contains a term ~\n\\sqrt{T}, with a coefficient which is proportional with the jump of the\nderivative.\n"
    },
    {
        "paper_id": 1105.3594,
        "authors": "Francesco Cesarone, Andrea Scozzari, Fabio Tardella",
        "title": "Portfolio selection problems in practice: a comparison between linear\n  and quadratic optimization models",
        "comments": null,
        "journal-ref": "Computational Management Science, Vol. 12(3), pag. 345-370 (2015,\n  published version)",
        "doi": "10.1007/s10287-014-0210-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Several portfolio selection models take into account practical limitations on\nthe number of assets to include and on their weights in the portfolio. We\npresent here a study of the Limited Asset Markowitz (LAM), of the Limited Asset\nMean Absolute Deviation (LAMAD) and of the Limited Asset Conditional\nValue-at-Risk (LACVaR) models, where the assets are limited with the\nintroduction of quantity and cardinality constraints. We propose a completely\nnew approach for solving the LAM model, based on reformulation as a Standard\nQuadratic Program and on some recent theoretical results. With this approach we\nobtain optimal solutions both for some well-known financial data sets used by\nseveral other authors, and for some unsolved large size portfolio problems. We\nalso test our method on five new data sets involving real-world capital market\nindices from major stock markets. Our computational experience shows that,\nrather unexpectedly, it is easier to solve the quadratic LAM model with our\nalgorithm, than to solve the linear LACVaR and LAMAD models with CPLEX, one of\nthe best commercial codes for mixed integer linear programming (MILP) problems.\nFinally, on the new data sets we have also compared, using out-of-sample\nanalysis, the performance of the portfolios obtained by the Limited Asset\nmodels with the performance provided by the unconstrained models and with that\nof the official capital market indices.\n"
    },
    {
        "paper_id": 1105.3918,
        "authors": "Aleksandar Mijatovi\\'c and Mikhail Urusov",
        "title": "A note on a paper by Wong and Heyde",
        "comments": "To appear in Journal of Applied Probability, 11 pages",
        "journal-ref": "J. Appl. Probab. 48 (2011) 811-819",
        "doi": "10.1239/jap/1316796916",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note we re-examine the analysis of the paper \"On the martingale\nproperty of stochastic exponentials\" by B. Wong and C.C. Heyde, Journal of\nApplied Probability, 41(3):654-664, 2004. Some counterexamples are presented\nand alternative formulations are discussed.\n"
    },
    {
        "paper_id": 1105.4519,
        "authors": "Laurent E. Calvet and Veronika Czellar",
        "title": "State-Observation Sampling and the Econometrics of Learning Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In nonlinear state-space models, sequential learning about the hidden state\ncan proceed by particle filtering when the density of the observation\nconditional on the state is available analytically (e.g. Gordon et al., 1993).\nThis condition need not hold in complex environments, such as the\nincomplete-information equilibrium models considered in financial economics. In\nthis paper, we make two contributions to the learning literature. First, we\nintroduce a new filtering method, the state-observation sampling (SOS) filter,\nfor general state-space models with intractable observation densities. Second,\nwe develop an indirect inference-based estimator for a large class of\nincomplete-information economies. We demonstrate the good performance of these\ntechniques on an asset pricing model with investor learning applied to over 80\nyears of daily equity returns.\n"
    },
    {
        "paper_id": 1105.4567,
        "authors": "Alessandro Ramponi",
        "title": "Fourier Transform Methods for Regime-Switching Jump-Diffusions and the\n  Pricing of Forward Starting Options",
        "comments": "25 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider a jump-diffusion dynamic whose parameters are\ndriven by a continuous time and stationary Markov Chain on a finite state space\nas a model for the underlying of European contingent claims. For this class of\nprocesses we firstly outline the Fourier transform method both in log-price and\nlog-strike to efficiently calculate the value of various types of options and\nas a concrete example of application, we present some numerical results within\na two-state regime switching version of the Merton jump-diffusion model. Then\nwe develop a closed-form solution to the problem of pricing a Forward Starting\nOption and use this result to approximate the value of such a derivative in a\ngeneral stochastic volatility framework.\n"
    },
    {
        "paper_id": 1105.4789,
        "authors": "Alex Langnau, Yanko Punchev",
        "title": "Stochastic Price Dynamics Implied By the Limit Order Book",
        "comments": "Limit order book, limit orders, volatility smile, jump process,\n  double-exponential jump process, impatience rate, jump diffusion",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present a novel approach to the determination of fat tails\nin financial data by studying the information contained in the limit order\nbook. In an order-driven market buyers and sellers may submit limit orders,\nwhich are executed when the price touches a pre-specified lower, respectively\nhigher, limit-price. We show that, in equilibrium, the collection of all such\norders - the limit order book - implies a volatility smile, similar to\nobservations from option pricing in the Black-Scholes model. We also show how a\njump-diffusion process can be explicitly inferred to account for the volatility\nsmile.\n"
    },
    {
        "paper_id": 1105.5082,
        "authors": "Stefano Ciliberti, Jean-Philippe Bouchaud, Marc Potters",
        "title": "Erratum for: Smile dynamics -- a theory of the implied leverage effect",
        "comments": "Erratum to \"Smile dynamics -- a theory of the implied leverage\n  effect\", Wilmott Journal Volume 1, Issue 2, pages 87-94, April 2009",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We correct a mistake in the published version of our paper. Our new\nconclusion is that the \"implied leverage effect\" for single stocks is\nunderestimated by option markets for short maturities and overestimated for\nlong maturities, while it is always overestimated for OEX options, except for\nthe shortest maturities where the revised theory and data match perfectly.\n"
    },
    {
        "paper_id": 1105.5416,
        "authors": "Marcell Stippinger and B\\'alint Vet\\H{o} and \\'Eva R\\'acz and Zsolt\n  Bihary",
        "title": "Analytic results and weighted Monte Carlo simulations for CDO pricing",
        "comments": "12 pages, 9 figures",
        "journal-ref": "EPJ B 85(2):51 11p (2012)",
        "doi": "10.1140/epjb/e2011-20429-x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We explore the possibilities of importance sampling in the Monte Carlo\npricing of a structured credit derivative referred to as Collateralized Debt\nObligation (CDO). Modeling a CDO contract is challenging, since it depends on a\npool of (typically about 100) assets, Monte Carlo simulations are often the\nonly feasible approach to pricing. Variance reduction techniques are therefore\nof great importance. This paper presents an exact analytic solution using\nLaplace-transform and MC importance sampling results for an easily tractable\nintensity-based model of the CDO, namely the compound Poissonian. Furthermore\nanalytic formulae are derived for the reweighting efficiency. The computational\ngain is appealing, nevertheless, even in this basic scheme, a phase transition\ncan be found, rendering some parameter regimes out of reach. A\nmodel-independent transform approach is also presented for CDO pricing.\n"
    },
    {
        "paper_id": 1105.5439,
        "authors": "Brian Tivnan, Matthew Koehler, Matthew McMahon, Matthew Olson, Neal\n  Rothleder, Rajani Shenoy",
        "title": "Adding to the Regulator's Toolbox: Integration and Extension of Two\n  Leading Market Models",
        "comments": "13 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  As demonstrated during the recent financial crisis, regulators require\nadditional analytical tools to assess systemic risk in the financial sector.\nThis paper describes one such tool; namely a novel market modeling and analysis\ncapability. Our model builds upon two leading market models: one which\nemphasizes market micro-structure and another which emphasizes an ecology of\ntrading strategies. We address a limitation of market modeling, namely the\nconsideration of only one dominant trading strategy (i.e., long positions). Our\nmodel aligns closely with several widely held stylized facts of financial\nmarkets. And a final contribution of this work stems from our empirical\nanalysis of the fractal nature of both empirical markets and our market model.\n"
    },
    {
        "paper_id": 1105.5503,
        "authors": "Geoff Willis",
        "title": "Pricing, liquidity and the control of dynamic systems in finance and\n  economics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper discusses various practical consequences of treating economics and\nfinance as an inherently dynamic and chaotic system. On the theoretical side\nthis looks at the general applicability of the market-making pricing approach\nto economics in general. The paper also discuses the consequences of the\nendogenous creation of liquidity and the role of liquidity as a state variable.\nOn the practical side, proposals are made for reducing chaotic behaviour in\nboth housing markets and stock markets.\n"
    },
    {
        "paper_id": 1105.5717,
        "authors": "Robert Jarrow, Younes Kchia and Philip Protter",
        "title": "Is there a bubble in LinkedIn's stock price?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent academic work has developed a method to determine, in real time, if a\ngiven stock is exhibiting a price bubble. Currently there is speculation in the\nfinancial press concerning the existence of a price bubble in the aftermath of\nthe recent IPO of LinkedIn. We analyze stock price tick data from the short\nlifetime of this stock through May 24, 2011, and we find that LinkedIn has a\nprice bubble.\n"
    },
    {
        "paper_id": 1105.585,
        "authors": "Gareth W. Peters, Mark Briers, Pavel V. Shevchenko and Arnaud Doucet",
        "title": "Calibration and filtering for multi factor commodity models with\n  seasonality: incorporating panel data from futures contracts",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We examine a general multi-factor model for commodity spot prices and futures\nvaluation. We extend the multi-factor long-short model in Schwartz and Smith\n(2000) and Yan (2002) in two important aspects: firstly we allow for both the\nlong and short term dynamic factors to be mean reverting incorporating\nstochastic volatility factors and secondly we develop an additive structural\nseasonality model. Then a Milstein discretized non-linear stochastic volatility\nstate space representation for the model is developed which allows for futures\nand options contracts in the observation equation. We then develop numerical\nmethodology based on an advanced Sequential Monte Carlo algorithm utilising\nParticle Markov chain Monte Carlo to perform calibration of the model jointly\nwith the filtering of the latent processes for the long-short dynamics and\nvolatility factors. In this regard we explore and develop a novel methodology\nbased on an adaptive Rao-Blackwellised version of the Particle Markov chain\nMonte Carlo methodology. In doing this we deal accurately with the\nnon-linearities in the state-space model which are therefore introduced into\nthe filtering framework. We perform analysis on synthetic and real data for oil\ncommodities.\n"
    },
    {
        "paper_id": 1105.5891,
        "authors": "Lunchao Hu, Kailan Tian, Xin Wang and Jiang Zhang",
        "title": "The \"S\" Curve Relationship between Export Diversity and Economic Size of\n  Countries",
        "comments": "16 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.08.048",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The highly detailed international trade data among all countries in the world\nduring 1971-2000 shows that the kinds of export goods and the logarithmic GDP\n(gross domestic production) of a country has an S-shaped relationship. This\nindicates all countries can be divided into three stages accordingly. First,\nthe poor countries always export very few kinds of products as we expect.\nSecond, once the economic size (GDP) of a country is beyond a threshold, its\nexport diversity may increase dramatically. However, this is not the case for\nrich countries because a ceiling on the export diversity is observed when their\nGDPs are higher than another threshold. This pattern is very stable for\ndifferent years although the concrete parameters of the fitting sigmoid\nfunctions may change with time. In addition, we also discussed other\nrelationships such as import diversity with respect to logarithmic GDP,\ndiversity of exporters with respect to the number of export goods etc., all of\nthese relationships show S-shaped or power law patterns. Although this paper\ndoes not explain the origin of the S-shaped curve, it may provide a basic\nempirical fact and insights for economic diversity.\n"
    },
    {
        "paper_id": 1105.5954,
        "authors": "Jan Hendrik Witte and Christoph Reisinger",
        "title": "Penalty Methods for the Solution of Discrete HJB Equations -- Continuous\n  Control and Obstacle Problems",
        "comments": "31 Pages, 7 Figures",
        "journal-ref": "SIAM J. Numer. Anal. 50(2), 595-625, 2012",
        "doi": "10.1137/110835840",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present a novel penalty approach for the numerical solution\nof continuously controlled HJB equations and HJB obstacle problems. Our results\ninclude estimates of the penalisation error for a class of penalty terms, and\nwe show that variations of Newton's method can be used to obtain globally\nconvergent iterative solvers for the penalised equations. Furthermore, we\ndiscuss under what conditions local quadratic convergence of the iterative\nsolvers can be expected. We include numerical results demonstrating the\ncompetitiveness of our methods.\n"
    },
    {
        "paper_id": 1105.6265,
        "authors": "Andrzej Buda",
        "title": "Hierarchical structure in phonographic market",
        "comments": "10 pages, 3 figures, 2 tables, 2 pictures, presented at FENS 2010 in\n  Warsaw, chapter of book \"Life-time Of Correlation And Its Application (volume\n  1)\"",
        "journal-ref": "A. Buda, A. Jarynowski, Life-time Of Correlation And Its\n  Application (volume 1), Wydawnictwo Niezalezne, Wroclaw 2010, ISBN\n  978-83915272-9-0",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I find a topological arrangement of assets traded in a phonographic market\nwhich has associated a meaningful economic taxonomy. I continue using the\nMinimal Spanning Tree and the Life-time Of Correlations between assets, but now\noutside the stock markets. This is the first attempt to use these methods on\nphonographic market where we have artists instead of stocks. The value of an\nartist is defined by record sales. The graph is obtained starting from the\nmatrix of correlations coefficient computed between the world's most popular 30\nartists by considering the synchronous time evolution of the difference of the\nlogarithm of weekly record sales. This method provides the hierarchical\nstructure of phonographic market and information on which music genre is\nmeaningful according to customers.\n"
    },
    {
        "paper_id": 1105.6272,
        "authors": "Andrzej Buda",
        "title": "Life time of correlation between stocks prices on established and\n  emerging markets",
        "comments": "17 pages, 9 figures, 1 table; presented at FENS conference in Wroclaw\n  2007 and Rzeszow 208; chapter in book: \"Life-time Of Correlation And Its\n  Application (volume 1)\"",
        "journal-ref": "A. Buda, A. Jarynowski,Life-time Of Correlation And Its\n  Application (volume 1), Wydawnictwo Niezalezne, Wroclaw 2010, ISBN\n  978-83915272-9-0",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The correlation coefficient between stocks depends on price history and\nincludes information on hierarchical structure in financial markets. It is\nuseful for portfolio selection and estimation of risk. I introduce the Life\nTime of Correlation between stocks prices to know how far we should investigate\nthe price history to obtain the optimal durability of correlation. I carry out\nmy research on emerging (Poland) and established markets (in the USA, Great\nBritain and Germany). Other methods, including the Minimum Spanning Trees, tree\nhalf-life, decomposition of correlations and the Epps effect are also\ndiscussed.\n"
    },
    {
        "paper_id": 1106.002,
        "authors": "J. D. Kandilarov and D. Sevcovic",
        "title": "Comparison of Two Numerical Methods for Computation of American Type of\n  the Floating Strike Asian Option",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a numerical approach for solving the free boundary problem for the\nBlack-Scholes equation for pricing American style of floating strike Asian\noptions. A fixed domain transformation of the free boundary problem into a\nparabolic equation defined on a fixed spatial domain is performed. As a result\na nonlinear time-dependent term is involved in the resulting equation. Two new\nnumerical algorithms are proposed. In the first algorithm a predictor-corrector\nscheme is used. The second one is based on the Newton method. Computational\nexperiments, confirming the accuracy of the algorithms are presented and\ndiscussed.\n"
    },
    {
        "paper_id": 1106.0039,
        "authors": "Mauro Politi, Nicolas Millot, Anirban Chakraborti",
        "title": "The near-extreme density of intraday log-returns",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.05.029",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The extreme event statistics plays a very important role in the theory and\npractice of time series analysis. The reassembly of classical theoretical\nresults is often undermined by non-stationarity and dependence between\nincrements. Furthermore, the convergence to the limit distributions can be\nslow, requiring a huge amount of records to obtain significant statistics, and\nthus limiting its practical applications. Focussing, instead, on the closely\nrelated density of \"near-extremes\" -- the distance between a record and the\nmaximal value -- can render the statistical methods to be more suitable in the\npractical applications and/or validations of models. We apply this recently\nproposed method in the empirical validation of an adapted financial market\nmodel of the intraday market fluctuations.\n"
    },
    {
        "paper_id": 1106.0123,
        "authors": "Masaaki Fujii, Akihiko Takahashi",
        "title": "Analytical Approximation for Non-linear FBSDEs with Perturbation Scheme",
        "comments": "Final revision for publication, including supplementary contents to\n  the published version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we have presented a simple analytical approximation scheme for\ngeneric non-linear FBSDEs. By treating the interested system as the linear\ndecoupled FBSDE perturbed with non-linear generator and feedback terms, we have\nshown that it is possible to carry out a recursive approximation to an\narbitrarily higher order, where the required calculations in each order are\nequivalent to those for standard European contingent claims. We have also\napplied the perturbative method to the PDE framework following the so-called\nFour Step Scheme. The method is found to render the original non-linear PDE\ninto a series of standard parabolic linear PDEs. Due to the equivalence of the\ntwo approaches, it is also possible to derive approximate analytic solution for\nthe non-linear PDE by applying the asymptotic expansion to the corresponding\nprobabilistic model. Two simple examples are provided to demonstrate how the\nperturbation works and show its accuracy relative to known numerical\ntechniques. The method presented in this paper may be useful for various\nimportant problems which have eluded analytical treatment so far.\n"
    },
    {
        "paper_id": 1106.0296,
        "authors": "T. Clemson, T. S. Evans",
        "title": "The Emergence of Leadership in Social Networks",
        "comments": "22 pages (as in Physica A but with a few extra references to\n  supplementary material) plus 11 pages of supplementary material not in\n  Physica A version",
        "journal-ref": "Physica A 391 (2012) 1434-1444",
        "doi": "10.1016/j.physa.2011.11.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a networked version of the minority game in which agents can choose\nto follow the choices made by a neighbouring agent in a social network. We show\nthat for a wide variety of networks a leadership structure always emerges, with\nmost agents following the choice made by a few agents. We find a suitable\nparameterisation which highlights the universal aspects of the behaviour and\nwhich also indicates where results depend on the type of social network.\n"
    },
    {
        "paper_id": 1106.039,
        "authors": "Stanislaw Drozdz, Jaroslaw Kwapien, Andreas A. Ioannides",
        "title": "Asymmetric random matrices: What do we need them for?",
        "comments": null,
        "journal-ref": "Acta Phys. Pol. B 42, 987-999 (2011)",
        "doi": "10.5506/APhysPolB.42.987",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Complex systems are typically represented by large ensembles of observations.\nCorrelation matrices provide an efficient formal framework to extract\ninformation from such multivariate ensembles and identify in a quantifiable way\npatterns of activity that are reproducible with statistically significant\nfrequency compared to a reference chance probability, usually provided by\nrandom matrices as fundamental reference. The character of the problem and\nespecially the symmetries involved must guide the choice of random matrices to\nbe used for the definition of a baseline reference. For standard correlation\nmatrices this is the Wishart ensemble of symmetric random matrices. The real\nworld complexity however often shows asymmetric information flows and therefore\nmore general correlation matrices are required to adequately capture the\nasymmetry. Here we first summarize the relevant theoretical concepts. We then\npresent some examples of human brain activity where asymmetric time-lagged\ncorrelations are evident and hence highlight the need for further theoretical\ndevelopments.\n"
    },
    {
        "paper_id": 1106.0562,
        "authors": "David carf\\'i",
        "title": "Financial Lie groups",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we see the evolution of a capitalized financial event e, with\nrespect to a capitalization factor f, as the exponential map of a suitably\ndefined Lie group G(f,e), supported by the half-space of capitalized financial\nevents having the same capital sign of e. The Lie group G(f,e) depends upon the\ncapitalization factor f and on the event e itself. After the extension of the\ndefinition of exponential map of a Lie group, we shall eliminate the dependence\non the financial event e, recognizing the presence of essentially one unique\nfinancial Lie semigroup, supported by the entire space of capitalized financial\nevents, determined by the capitalization factor f.\n"
    },
    {
        "paper_id": 1106.0866,
        "authors": "Antonis Papapantoleon, John Schoenmakers, David Skovmand",
        "title": "Efficient and accurate log-L\\'evy approximations to L\\'evy driven LIBOR\n  models",
        "comments": "32 pages, 21 figures. Added an example of a path-dependent option\n  (sticky ratchet caplet). Forthcoming in the Journal of Computational Finance",
        "journal-ref": "Journal of Computational Finance 2012, Vol. 15, No. 4, 3-44",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The LIBOR market model is very popular for pricing interest rate derivatives,\nbut is known to have several pitfalls. In addition, if the model is driven by a\njump process, then the complexity of the drift term is growing exponentially\nfast (as a function of the tenor length). In this work, we consider a\nL\\'evy-driven LIBOR model and aim at developing accurate and efficient\nlog-L\\'evy approximations for the dynamics of the rates. The approximations are\nbased on truncation of the drift term and Picard approximation of suitable\nprocesses. Numerical experiments for FRAs, caps, swaptions and sticky ratchet\ncaps show that the approximations perform very well. In addition, we also\nconsider the log-L\\'evy approximation of annuities, which offers good\napproximations for high volatility regimes.\n"
    },
    {
        "paper_id": 1106.1395,
        "authors": "Jochen Zahn",
        "title": "Utility based pricing and hedging of jump diffusion processes with a\n  view to applications",
        "comments": "23 pages, v2: published",
        "journal-ref": "International Journal of Theoretical and Applied Finance 15 (2012)\n  1250052",
        "doi": "10.1142/S0219024912500525",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss utility based pricing and hedging of jump diffusion processes with\nemphasis on the practical applicability of the framework. We point out two\ndifficulties that seem to limit this applicability, namely drift dependence and\nessential risk aversion independence. We suggest to solve these by a\nre-interpretation of the framework. This leads to the notion of an implied\ndrift. We also present a heuristic derivation of the marginal indifference\nprice and the marginal optimal hedge that might be useful in numerical\ncomputations.\n"
    },
    {
        "paper_id": 1106.1401,
        "authors": "Mardavij Roozbehani, Munther A Dahleh, and Sanjoy K Mitter",
        "title": "Volatility of Power Grids under Real-Time Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper proposes a framework for modeling and analysis of the dynamics of\nsupply, demand, and clearing prices in power system with real-time retail\npricing and information asymmetry. Real-time retail pricing is characterized by\npassing on the real-time wholesale electricity prices to the end consumers, and\nis shown to create a closed-loop feedback system between the physical layer and\nthe market layer of the power system. In the absence of a carefully designed\ncontrol law, such direct feedback between the two layers could increase\nvolatility and lower the system's robustness to uncertainty in demand and\ngeneration. A new notion of generalized price-elasticity is introduced, and it\nis shown that price volatility can be characterized in terms of the system's\nmaximal relative price elasticity, defined as the maximal ratio of the\ngeneralized price-elasticity of consumers to that of the producers. As this\nratio increases, the system becomes more volatile, and eventually, unstable. As\nnew demand response technologies and distributed storage increase the\nprice-elasticity of demand, the architecture under examination is likely to\nlead to increased volatility and possibly instability. This highlights the need\nfor assessing architecture systematically and in advance, in order to optimally\nstrike the trade-offs between volatility, economic efficiency, and system\nreliability.\n"
    },
    {
        "paper_id": 1106.1415,
        "authors": "Wei Li, Fengzhong Wang, Shlomo Havlin, H. Eugene Stanley",
        "title": "Financial factor influence on scaling and memory of trading volume in\n  stock market",
        "comments": "17 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.84.046112",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the daily trading volume volatility of 17,197 stocks in the U.S.\nstock markets during the period 1989--2008 and analyze the time return\nintervals $\\tau$ between volume volatilities above a given threshold q. For\ndifferent thresholds q, the probability density function P_q(\\tau) scales with\nmean interval <\\tau> as P_q(\\tau)=<\\tau>^{-1}f(\\tau/<\\tau>) and the tails of\nthe scaling function can be well approximated by a power-law f(x)~x^{-\\gamma}.\nWe also study the relation between the form of the distribution function\nP_q(\\tau) and several financial factors: stock lifetime, market capitalization,\nvolume, and trading value. We find a systematic tendency of P_q(\\tau)\nassociated with these factors, suggesting a multi-scaling feature in the volume\nreturn intervals. We analyze the conditional probability P_q(\\tau|\\tau_0) for\n$\\tau$ following a certain interval \\tau_0, and find that P_q(\\tau|\\tau_0)\ndepends on \\tau_0 such that immediately following a short/long return interval\na second short/long return interval tends to occur. We also find indications\nthat there is a long-term correlation in the daily volume volatility. We\ncompare our results to those found earlier for price volatility.\n"
    },
    {
        "paper_id": 1106.1577,
        "authors": "Serge Galam",
        "title": "Market efficiency, anticipation and the formation of bubbles-crashes",
        "comments": "22 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A dynamical model is introduced for the formation of a bullish or bearish\ntrends driving an asset price in a given market. Initially, each agent decides\nto buy or sell according to its personal opinion, which results from the\ncombination of its own private information, the public information and its own\nanalysis. It then adjusts such opinion through the market as it observes\nsequentially the behavior of a group of random selection of other agents. Its\nchoice is then determined by a local majority rule including itself. Whenever\nthe selected group is at a tie, i.e., it is undecided on what to do, the choice\nis determined by the local group belief with respect to the anticipated trend\nat that time. These local adjustments create a dynamic that leads the market\nprice formation. In case of balanced anticipations the market is found to be\nefficient in being successful to make the \"right price\" to emerge from the\nsequential aggregation of all the local individual informations which all\ntogether contain the fundamental value. However, when a leading optimistic\nbelief prevails, the same efficient market mechanisms are found to produce a\nbullish dynamic even though most agents have bearish private informations. The\nmarket yields then a wider and wider discrepancy between the fundamental value\nand the market value, which in turn creates a speculative bubble. Nevertheless,\nthere exists a limit in the growing of the bubble where private opinions take\nover again and at once invert the trend, originating a sudden bearish trend.\nMoreover, in the case of a drastic shift in the collective expectations, a huge\ndrop in price levels may also occur extremely fast and puts the market out of\ncontrol, it is a market crash.\n"
    },
    {
        "paper_id": 1106.1702,
        "authors": "Santiago Moreno-Bromberg and Traian Pirvu and Anthony R\\'eveillac",
        "title": "CRRA Utility Maximization under Risk Constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the problem of optimal investment with CRRA (constant,\nrelative risk aversion) preferences, subject to dynamic risk constraints on\ntrading strategies. The market model considered is continuous in time and\nincomplete. the prices of financial assets are modeled by It\\^o processes. The\ndynamic risk constraints, which are time and state dependent, are generated by\nrisk measures. Optimal trading strategies are characterized by a quadratic\nBSDE. Within the class of \\textit{time consistent distortion risk measures}, a\nthree-fund separation result is established. Numerical results emphasize the\neffects of imposing risk constraints on trading.\n"
    },
    {
        "paper_id": 1106.1774,
        "authors": "David Carf{\\i}",
        "title": "Fibrations of financial events",
        "comments": null,
        "journal-ref": "Proceedings of the International Geometry Center (Prooceeding of\n  the International Conference \"Geometry in Odessa 2009\", Odessa, 25 - 30 May\n  2009) vol. 2 n. 3 (2009) pg. 7-18 ISSN 2072-9812\n  http://proceedings.d-omega.org/",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we shall prove that the plane of financial events, introduced\nand applied to financial problems by the author himself (see [2], [3] and [4])\ncan be considered as a fibration in two different ways. The first one, the\nnatural one, reveals itself to be isomorphic to the tangent- bundle of the real\nline, when the last one is considered as a differentiable manifold in the\nnatural way; the second one is a fibration induced by the status of compound\ninterest capitalization at a given rate i in the interval ] - 1, \\rightarrow [.\nMoreover, in the paper we define on the first fibration an affine connection,\nalso in this case induced by the status of compound interest at a given rate i.\nThe final goal of this paper is the awareness that all the effects determined\nby the status of compound interest are nothing but the consequences of the fact\nthat the space of financial events is a fibration endowed with a particular\naffine connection, so they are consequences of purely geometric properties, at\nlast, depending upon the curvature determined by the connection upon the\nfibration. A natural preorder upon the set of fibers of the second fibration is\nconsidered. Some remarks about the applicability to economics and finance of\nthe theories presented in the paper and about the possible developments are\nmade in the directions followed in papers [1], [5], [6], [7], [8] of the\nauthor.\n"
    },
    {
        "paper_id": 1106.1999,
        "authors": "Abhishek Kumar, Ashwin Waikos and Siddhartha P. Chakrabarty",
        "title": "Pricing of average strike Asian call option using numerical PDE methods",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, a standard PDE for the pricing of arithmetic average strike\nAsian call option is presented. A Crank-Nicolson Implicit Method and a Higher\nOrder Compact finite difference scheme for this pricing problem is derived.\nBoth these schemes were implemented for various values of risk free rate and\nvolatility. The option prices for the same set of values of risk free rate and\nvolatility was also computed using Monte Carlo simulation. The comparative\nresults of the two numerical PDE methods shows close match with the Monte Carlo\nresults, with the Higher Order Compact scheme exhibiting a better match. To the\nbest of our knowledge, this is the first work to use the numerical PDE approach\nfor pricing Asian call options with average strike.\n"
    },
    {
        "paper_id": 1106.2095,
        "authors": "Yan Dolinsky and Halil Mete Soner",
        "title": "Duality and Convergence for Binomial Markets with Friction",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove limit theorems for the super-replication cost of European options in\na Binomial model with friction. The examples covered are markets with\nproportional transaction costs and the illiquid markets. The dual\nrepresentation for the super-replication cost in these models are obtained and\nused to prove the limit theorems. In particular, the existence of the liquidity\npremium for the continuous time limit of the model proposed in [6] is proved.\nHence, this paper extends the previous convergence result of [13] to the\ngeneral non-Markovian case. Moreover, the special case of small transaction\ncosts yields, in the continuous limit, the $G$-expectation of Peng as earlier\nproved by Kusuoka in [14].\n"
    },
    {
        "paper_id": 1106.2342,
        "authors": "Edward Hoyle and Levent Ali Menguturk",
        "title": "Archimedean Survival Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Archimedean copulas are popular in the world of multivariate modelling as a\nresult of their breadth, tractability, and flexibility. A. J. McNeil and J.\nNe\\v{s}lehov\\'a (2009) showed that the class of Archimedean copulas coincides\nwith the class of multivariate $\\ell_1$-norm symmetric distributions. Building\nupon their results, we introduce a class of multivariate Markov processes that\nwe call `Archimedean survival processes' (ASPs). An ASP is defined over a\nfinite time interval, is equivalent in law to a multivariate gamma process, and\nits terminal value has an Archimedean survival copula. There exists a bijection\nfrom the class of ASPs to the class of Archimedean copulas. We provide various\ncharacterisations of ASPs, and a generalisation.\n"
    },
    {
        "paper_id": 1106.2478,
        "authors": "Matheus R Grasselli and Tsunehiro Tsujimoto",
        "title": "Calibration of Chaotic Models for Interest Rates",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we calibrate chaotic models for interest rates to market data\nusing a polynomial-exponential parametrization for the chaos coefficients. We\nidentify a subclass of one-variable models that allow us to introduce\ncomplexity from higher order chaos in a controlled way while retaining\nconsiderable analytic tractability. In particular we derive explicit\nexpressions for bond and option prices in a one-variable third chaos model in\nterms of elementary combinations of normal density and cumulative distribution\nfunctions. We then compare the calibration performance of chaos models with\nthat of well-known benchmark models. For term structure calibration we find\nthat chaos models are comparable to the Svensson model, with the advantage of\nguaranteed positivity and consistency with a dynamic stochastic evolution of\ninterest rates. For calibration to option data, chaos models outperform the\nHull and White and rational lognormal models and are comparable to LIBOR market\nmodels.\n"
    },
    {
        "paper_id": 1106.2601,
        "authors": "Vikram Dhillon",
        "title": "Knowledge Dispersion Index for Measuring Intellectual Capital",
        "comments": "Submitted to Innocentive",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  In this paper we propose a novel index to quantify and measure the flow of\ninformation on macro and micro scales. We discuss the implications of this\nindex for knowledge management fields and also as intellectual capital that can\nthus be utilized by entrepreneurs. We explore different function and human\noriented metrics that can be used at micro-scales to process the flow of\ninformation. We present a table of about 23 metrics, such as change in IT\ninventory and percentage of employees with advanced degrees, that can be used\nat micro scales to wholly quantify knowledge dispersion as intellectual\ncapital. At macro scales we split the economy in an industrial and consumer\nsector where the flow of information in each determines how fast an economy is\ngoing to grow and how overall an economy will perform given the aggregate\ndemand. Lastly, we propose a model for knowledge dispersion based on graph\ntheory and show how corrections in the flow become self-evident. Through the\nprincipals of flow conservation and capacity constrains we also speculate how\nthis flow might seeks some equilibrium and exhibit self-correction codes. This\nproposed model allows us to account for perturbations in form of local noise,\nevolution of networks, provide robustness against local damage from lower\nnodes, and help determine the underlying classification into network\nsuper-families.\n"
    },
    {
        "paper_id": 1106.2685,
        "authors": "Aleksejus Kononovicius and Vygintas Gontis",
        "title": "Agent based reasoning for the non-linear stochastic models of long-range\n  memory",
        "comments": "10 pages, 3 figures",
        "journal-ref": "Physica A 391 (2012), pp. 1309-1314",
        "doi": "10.1016/j.physa.2011.08.061",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend Kirman's model by introducing variable event time scale. The\nproposed flexible time scale is equivalent to the variable trading activity\nobserved in financial markets. Stochastic version of the extended Kirman's\nagent based model is compared to the non-linear stochastic models of long-range\nmemory in financial markets. Agent based model providing matching macroscopic\ndescription serves as a microscopic reasoning of the earlier proposed\nstochastic model exhibiting power law statistics.\n"
    },
    {
        "paper_id": 1106.2781,
        "authors": "Runhuan Feng, Hans Volkmer, Shuaiqi Zhang, and Chao Zhu",
        "title": "Optimal Dividend Payments for the Piecewise-Deterministic Poisson Risk\n  Model",
        "comments": "Key Words: Piecewise-deterministic compound Poisson model, optimal\n  stochastic control, HJB equation, quasi-variational inequality, threshold\n  strategy, barrier strategy",
        "journal-ref": null,
        "doi": "10.1080/03461238.2013.846277",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the optimal dividend payment problem in\npiecewise-deterministic compound Poisson risk models. The objective is to\nmaximize the expected discounted dividend payout up to the time of ruin. We\nprovide a comparative study in this general framework of both restricted and\nunrestricted payment schemes, which were only previously treated separately in\ncertain special cases of risk models in the literature. In the case of\nrestricted payment scheme, the value function is shown to be a classical\nsolution of the corresponding HJB equation, which in turn leads to an optimal\nrestricted payment policy known as the threshold strategy. In the case of\nunrestricted payment scheme, by solving the associated integro-differential\nquasi-variational inequality, we obtain the value function as well as an\noptimal unrestricted dividend payment scheme known as the barrier strategy.\nWhen claim sizes are exponentially distributed, we provide easily verifiable\nconditions under which the threshold and barrier strategies are optimal\nrestricted and unrestricted dividend payment policies, respectively. The main\nresults are illustrated with several examples, including a new example\nconcerning regressive growth rates.\n"
    },
    {
        "paper_id": 1106.2791,
        "authors": "Brahim Brahimi, Djamel Meraghni, and Abdelhakim Necir",
        "title": "Distortion risk measures for sums of dependent losses",
        "comments": "Accepted 25 October 2010, Journal Afrika Statistika Vol. 5, N9, 2010,\n  page 260--267",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss two distinct approaches, for distorting risk measures of sums of\ndependent random variables, which preserve the property of coherence. The\nfirst, based on distorted expectations, operates on the survival function of\nthe sum. The second, simultaneously applies the distortion on the survival\nfunction of the sum and the dependence structure of risks, represented by\ncopulas. Our goal is to propose risk measures that take into account the\nfluctuations of losses and possible correlations between risk components.\n"
    },
    {
        "paper_id": 1106.2882,
        "authors": "Andrei N. Soklakov",
        "title": "Learning, investments and derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The recent crisis and the following flight to simplicity put most derivative\nbusinesses around the world under considerable pressure. We argue that the\ntraditional modeling techniques must be extended to include product design. We\npropose a quantitative framework for creating products which meet the challenge\nof being optimal from the investors point of view while remaining relatively\nsimple and transparent.\n"
    },
    {
        "paper_id": 1106.298,
        "authors": "Roman Muraviev",
        "title": "Additive habit formation: Consumption in incomplete markets with random\n  endowments",
        "comments": "To appear in Mathematics and Financial Economics",
        "journal-ref": "Mathematics and Financial Economics 5(2), 67--99, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a detailed characterization of the optimal consumption stream for\nthe additive habit-forming utility maximization problem, in a framework of\ngeneral discrete-time incomplete markets and random endowments. This\ncharacterization allows us to derive the monotonicity and concavity of the\noptimal consumption as a function of wealth, for several important classes of\nincomplete markets and preferences. These results yield a deeper understanding\nof the fine structure of the optimal consumption and provide a further\ntheoretical support for the classical conjectures of Keynes (1936).\n"
    },
    {
        "paper_id": 1106.3006,
        "authors": "Roman Muraviev",
        "title": "Exponential utility with non-negative consumption",
        "comments": "Submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We offer mathematical tractability and new insights for a framework of\nexponential utility with non-negative consumption, a constraint often omitted\nin the literature giving rise to economically unviable solutions. Specifically,\nusing the Kuhn-Tucker theorem and the notion of aggregate state price density\n(Malamud and Trubowitz (2007)), we provide a solution to this problem in the\nsetting of both complete and incomplete markets (with random endowments). Then,\nwe exploit this result to provide an explicit characterization of complete\nmarket heterogeneous equilibria. Furthermore, we construct concrete examples of\nmodels admitting multiple (including infinitely many) equilibria. By using\nCramer's large deviation theorem, we study the asymptotics of equilibrium zero\ncoupon bonds. Lastly, we conduct a study of the precautionary savings motive in\nincomplete markets.\n"
    },
    {
        "paper_id": 1106.3016,
        "authors": "Remy Chicheportiche and Jean-Philippe Bouchaud",
        "title": "Goodness-of-Fit tests with Dependent Observations",
        "comments": "26 pages",
        "journal-ref": "J. Stat. Mech. (2011) P09003",
        "doi": "10.1088/1742-5468/2011/09/P09003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit the Kolmogorov-Smirnov and Cram\\'er-von Mises goodness-of-fit\n(GoF) tests and propose a generalisation to identically distributed, but\ndependent univariate random variables. We show that the dependence leads to a\nreduction of the \"effective\" number of independent observations. The\ngeneralised GoF tests are not distribution-free but rather depend on all the\nlagged bivariate copulas. These objects, that we call \"self-copulas\", encode\nall the non-linear temporal dependences. We introduce a specific, log-normal\nmodel for these self-copulas, for which a number of analytical results are\nderived. An application to financial time series is provided. As is well known,\nthe dependence is to be long-ranged in this case, a finding that we confirm\nusing self-copulas. As a consequence, the acceptance rates for GoF tests are\nsubstantially higher than if the returns were iid random variables.\n"
    },
    {
        "paper_id": 1106.3025,
        "authors": "Roman Muraviev",
        "title": "Market selection with learning and catching up with the Joneses",
        "comments": "To appear in Finance and Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the market selection hypothesis in complete financial markets,\npopulated by heterogeneous agents. We allow for a rich structure of\nheterogeneity: individuals may differ in their beliefs concerning the economy,\ninformation and learning mechanism, risk aversion, impatience and 'catching up\nwith Joneses' preferences. We develop new techniques for studying the long-run\nbehavior of such economies, based on the Strassen's functional law of iterated\nlogarithm. In particular, we explicitly determine an agent's survival index and\nshow how the latter depends on the agent's characteristics. We use these\nresults to study the long-run behavior of the equilibrium interest rate and the\nmarket price of risk.\n"
    },
    {
        "paper_id": 1106.3273,
        "authors": "Marcel Nutz",
        "title": "A Quasi-Sure Approach to the Control of Non-Markovian Stochastic\n  Differential Equations",
        "comments": "27 pages",
        "journal-ref": "Electronic Journal of Probability, Vol. 17, No. 23, pp. 1-23, 2012",
        "doi": "10.1214/EJP.v17-1892",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study stochastic differential equations (SDEs) whose drift and diffusion\ncoefficients are path-dependent and controlled. We construct a value process on\nthe canonical path space, considered simultaneously under a family of singular\nmeasures, rather than the usual family of processes indexed by the controls.\nThis value process is characterized by a second order backward SDE, which can\nbe seen as a non-Markovian analogue of the Hamilton-Jacobi-Bellman partial\ndifferential equation. Moreover, our value process yields a generalization of\nthe G-expectation to the context of SDEs.\n"
    },
    {
        "paper_id": 1106.3279,
        "authors": "Olivier Gu\\'eant, Charles-Albert Lehalle, Joaquin Fernandez Tapia",
        "title": "Optimal Portfolio Liquidation with Limit Orders",
        "comments": "Submitted, in revision",
        "journal-ref": null,
        "doi": "10.1137/110850475",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper addresses the optimal scheduling of the liquidation of a portfolio\nusing a new angle. Instead of focusing only on the scheduling aspect like\nAlmgren and Chriss, or only on the liquidity-consuming orders like Obizhaeva\nand Wang, we link the optimal trade-schedule to the price of the limit orders\nthat have to be sent to the limit order book to optimally liquidate a\nportfolio. Most practitioners address these two issues separately: they compute\nan optimal trading curve and they then send orders to the markets to try to\nfollow it. The results obtained here solve simultaneously the two problems. As\nin a previous paper that solved the \"intra-day market making problem\", the\ninteractions of limit orders with the market are modeled via a Poisson process\npegged to a diffusive \"fair price\" and a Hamilton-Jacobi-Bellman equation is\nused to solve the problem involving both non-execution risk and price risk.\nBacktests are carried out to exemplify the use of our results, both on long\nperiods of time (for the entire liquidation process) and on slices of 5 minutes\n(to follow a given trading curve).\n"
    },
    {
        "paper_id": 1106.3455,
        "authors": "Jitka Janov\\'a",
        "title": "Applications of a constrained mechanics methodology in economics",
        "comments": null,
        "journal-ref": "Eur. J. Phys. 32 (2011) 1443-1463",
        "doi": "10.1088/0143-0807/32/6/001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper presents instructive interdisciplinary applications of constrained\nmechanics calculus in economics on a level appropriate for the undergraduate\nphysics education. The aim of the paper is: 1. to meet the demand for\nillustrative examples suitable for presenting the background of the highly\nexpanding research field of econophysics even on the undergraduate level and 2.\nto enable the students to understand deeper the principles and methods\nroutinely used in mechanics by looking at the well known methodology from the\ndifferent perspective of economics. Two constrained dynamic economic problems\nare presented using the economic terminology in an intuitive way. First, the\nPhillips model of business cycle is presented as a system of forced\noscillations and the general problem of two interacting economies is solved by\nthe nonholonomic dynamics approach. Second, the Cass-Koopmans-Ramsey model of\neconomical growth is solved as a variational problem with a velocity dependent\nconstraint using the vakonomic approach. The specifics of the solution\ninterpretation in economics compared to mechanics is discussed in detail, a\ndiscussion of the nonholonomic and vakonomic approaches to constrained problems\nin mechanics and economics is provided and an economic interpretation of the\nLagrange multipliers (possibly surprising for the students of physics) is\ncarefully explained. The paper can be used by the undergraduate students of\nphysics interested in interdisciplinary physics applications to get in touch\nwith current scientific approach to economics based on a physical background or\nby university teachers as an attractive supplement to the classical mechanics\nlessons.\n"
    },
    {
        "paper_id": 1106.3496,
        "authors": "Damiano Brigo, Cristin Buescu, Massimo Morini",
        "title": "Impact of the first to default time on Bilateral CVA",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We compare two different bilateral counterparty valuation adjustment (BVA)\nformulas. The first formula is an approximation and is based on subtracting the\ntwo unilateral Credit Valuation Adjustment (CVA)'s formulas as seen from the\ntwo different parties in the transaction. This formula is only a simplified\nrepresentation of bilateral risk and ignores that upon the first default\ncloseout proceedings are ignited. As such, it involves double counting. We\ncompare this formula with the fully specified bilateral risk formula, where the\nfirst to default time is taken into account. The latter correct formula depends\non default dependence between the two parties, whereas the simplified one does\nnot. We also analyze a candidate simplified formula in case the replacement\ncloseout is used upon default, following ISDA's recommendations, and we find\nthe simplified formula to be the same as in the risk free closeout case. We\nanalyze the error that is encountered when using the simplified formula in a\ncouple of simple products: a zero coupon bond, where the exposure is\nunidirectional, and an equity forward contract where exposure can go both ways.\nFor the latter case we adopt a bivariate exponential distribution due to Gumbel\nto model the joint default risk of the two parties in the deal. We present a\nnumber of realistic cases where the simplified formula differs considerably\nfrom the correct one.\n"
    },
    {
        "paper_id": 1106.3543,
        "authors": "David Carf\\'i and Daniele Schilir\\'o",
        "title": "A model of coopetitive game and the Greek crisis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present work we propose an original analytical model of coopetitive\ngame. We try to apply this analytical model of coopetition - based on game\ntheory and conceived at a macro level - to the Greek crisis, suggesting\nfeasible solutions in a cooperative perspective for the divergent interests\nwhich drive the economic policies in the euro area.\n"
    },
    {
        "paper_id": 1106.3562,
        "authors": "Hidemaro Suwa and Synge Todo",
        "title": "Geometric Allocation Approach for Transition Kernel of Markov Chain",
        "comments": "9 pages, 3 figures, submitted to proceedings of Eighth IMACS Seminar\n  on Monte Carlo Methods, to be published in Monte Carlo Methods and\n  Applications",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new geometric approach that constructs a transition kernel of\nMarkov chain. Our method always minimizes the average rejection rate and even\nreduce it to zero in many relevant cases, which cannot be achieved by\nconventional methods, such as the Metropolis-Hastings algorithm or the heat\nbath algorithm (Gibbs sampler). Moreover, the geometric approach makes it\npossible to find not only a reversible but also an irreversible solution of\nrejection-free transition probabilities. This is the first versatile method\nthat can construct an irreversible transition kernel in general cases. We\ndemonstrate that the autocorrelation time (asymptotic variance) of the Potts\nmodel becomes more than 6 times as short as that by the conventional\nMetropolis-Hastings algorithm. Our algorithms are applicable to almost all\nkinds of Markov chain Monte Carlo methods and will improve the efficiency.\n"
    },
    {
        "paper_id": 1106.3915,
        "authors": "Song Song and Peter J. Bickel",
        "title": "Large Vector Auto Regressions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One popular approach for nonstructural economic and financial forecasting is\nto include a large number of economic and financial variables, which has been\nshown to lead to significant improvements for forecasting, for example, by the\ndynamic factor models. A challenging issue is to determine which variables and\n(their) lags are relevant, especially when there is a mixture of serial\ncorrelation (temporal dynamics), high dimensional (spatial) dependence\nstructure and moderate sample size (relative to dimensionality and lags). To\nthis end, an \\textit{integrated} solution that addresses these three challenges\nsimultaneously is appealing. We study the large vector auto regressions here\nwith three types of estimates. We treat each variable's own lags different from\nother variables' lags, distinguish various lags over time, and is able to\nselect the variables and lags simultaneously. We first show the consequences of\nusing Lasso type estimate directly for time series without considering the\ntemporal dependence. In contrast, our proposed method can still produce an\nestimate as efficient as an \\textit{oracle} under such scenarios. The tuning\nparameters are chosen via a data driven \"rolling scheme\" method to optimize the\nforecasting performance. A macroeconomic and financial forecasting problem is\nconsidered to illustrate its superiority over existing estimators.\n"
    },
    {
        "paper_id": 1106.3921,
        "authors": "Song Song",
        "title": "Dynamic Large Spatial Covariance Matrix Estimation in Application to\n  Semiparametric Model Construction via Variable Clustering: the SCE approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To better understand the spatial structure of large panels of economic and\nfinancial time series and provide a guideline for constructing semiparametric\nmodels, this paper first considers estimating a large spatial covariance matrix\nof the generalized $m$-dependent and $\\beta$-mixing time series (with $J$\nvariables and $T$ observations) by hard thresholding regularization as long as\n${{\\log J \\, \\cx^*(\\ct)}}/{T} = \\Co(1)$ (the former scheme with some time\ndependence measure $\\cx^*(\\ct)$) or $\\log J /{T} = \\Co(1)$ (the latter scheme\nwith some upper bounded mixing coefficient). We quantify the interplay between\nthe estimators' consistency rate and the time dependence level, discuss an\nintuitive resampling scheme for threshold selection, and also prove a general\ncross-validation result justifying this. Given a consistently estimated\ncovariance (correlation) matrix, by utilizing its natural links with graphical\nmodels and semiparametrics, after \"screening\" the (explanatory) variables, we\nimplement a novel forward (and backward) label permutation procedure to cluster\nthe \"relevant\" variables and construct the corresponding semiparametric model,\nwhich is further estimated by the groupwise dimension reduction method with\nsign constraints. We call this the SCE (screen - cluster - estimate) approach\nfor modeling high dimensional data with complex spatial structure. Finally we\napply this method to study the spatial structure of large panels of economic\nand financial time series and find the proper semiparametric structure for\nestimating the consumer price index (CPI) to illustrate its superiority over\nthe linear models.\n"
    },
    {
        "paper_id": 1106.4502,
        "authors": "A. M. Avdeenko",
        "title": "Chaos structures. Multicurrency adviser on the basis of NSW model and\n  social-financial nets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Algorithm of multicurrency trading at the market of Forex is realized on the\nbasis of nonlinear stochastic wavelets. The distinctive feature of the\nalgorithm is the possibility of weakly- and strongly connected horizontal\nself-assemblies, as well as use of nested structures. On-line trading with\neight currency couples has shown high effectiveness and stability of the\nalgorithm. It is discussed the problem of possibility of excess profit earning\nin electronic markets via development of social-financial nets based on\nsynchronization of work of individual traders by means of proposed algorithm.\n"
    },
    {
        "paper_id": 1106.4509,
        "authors": "Amos Storkey",
        "title": "Machine Learning Markets",
        "comments": "Proceedings of the Fourteenth International Conference on Artificial\n  Intelligence and Statistics 2011",
        "journal-ref": "Journal of Machine Learning Research W&CP 15(AISTATS):716-724,\n  2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Prediction markets show considerable promise for developing flexible\nmechanisms for machine learning. Here, machine learning markets for\nmultivariate systems are defined, and a utility-based framework is established\nfor their analysis. This differs from the usual approach of defining static\nbetting functions. It is shown that such markets can implement model\ncombination methods used in machine learning, such as product of expert and\nmixture of expert approaches as equilibrium pricing models, by varying agent\nutility functions. They can also implement models composed of local potentials,\nand message passing methods. Prediction markets also allow for more flexible\ncombinations, by combining multiple different utility functions. Conversely,\nthe market mechanisms implement inference in the relevant probabilistic models.\nThis means that market mechanism can be utilized for implementing parallelized\nmodel building and inference for probabilistic modelling.\n"
    },
    {
        "paper_id": 1106.471,
        "authors": "G. Oshanin, Yu. Holovatch and G. Schehr",
        "title": "Proportionate vs disproportionate distribution of wealth of two\n  individuals in a tempered Paretian ensemble",
        "comments": "9 pages, 8 figures, to appear in Physica A",
        "journal-ref": "Physica A 390, 4340--4346 (2011)",
        "doi": "10.1016/j.physa.2011.06.067",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the distribution P(\\omega) of the random variable \\omega = x_1/(x_1\n+ x_2), where x_1 and x_2 are the wealths of two individuals selected at random\nfrom the same tempered Paretian ensemble characterized by the distribution\n\\Psi(x) \\sim \\phi(x)/x^{1 + \\alpha}, where \\alpha > 0 is the Pareto index and\n$\\phi(x)$ is the cut-off function. We consider two forms of \\phi(x): a bounded\nfunction \\phi(x) = 1 for L \\leq x \\leq H, and zero otherwise, and a smooth\nexponential function \\phi(x) = \\exp(-L/x - x/H). In both cases \\Psi(x) has\nmoments of arbitrary order.\n  We show that, for \\alpha > 1, P(\\omega) always has a unimodal form and is\npeaked at \\omega = 1/2, so that most probably x_1 \\approx x_2. For 0 < \\alpha <\n1 we observe a more complicated behavior which depends on the value of \\delta =\nL/H. In particular, for \\delta < \\delta_c - a certain threshold value -\nP(\\omega) has a three-modal (for a bounded \\phi(x)) and a bimodal M-shape (for\nan exponential \\phi(x)) form which signifies that in such ensembles the wealths\nx_1 and x_2 are disproportionately different.\n"
    },
    {
        "paper_id": 1106.473,
        "authors": "Yuan Xia",
        "title": "Multilevel Monte Carlo method for jump-diffusion SDEs",
        "comments": "36 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the extension of the multilevel Monte Carlo path simulation\nmethod to jump-diffusion SDEs. We consider models with finite rate activity,\nusing a jump-adapted discretisation in which the jump times are computed and\nadded to the standard uniform dis- cretisation times. The key component in\nmultilevel analysis is the calculation of an expected payoff difference between\na coarse path simulation and a fine path simulation with twice as many\ntimesteps. If the Poisson jump rate is constant, the jump times are the same on\nboth paths and the multilevel extension is relatively straightforward, but the\nimplementation is more complex in the case of state-dependent jump rates for\nwhich the jump times naturally differ.\n"
    },
    {
        "paper_id": 1106.4957,
        "authors": "Rosario Bartiromo",
        "title": "Maximum entropy distribution of stock price fluctuations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The principle of absence of arbitrage opportunities allows obtaining the\ndistribution of stock price fluctuations by maximizing its information entropy.\nThis leads to a physical description of the underlying dynamics as a random\nwalk characterized by a stochastic diffusion coefficient and constrained to a\ngiven value of the expected volatility, taking in this way into account the\ninformation provided by the existence of an option market. This model is\nvalidated by a comprehensive comparison with observed distributions of both\nprice return and diffusion coefficient. Expected volatility is the only\nparameter in the model and can be obtained by analysing option prices. We give\nan analytic formulation of the probability density function for price returns\nwhich can be used to extract expected volatility from stock option data. This\ndistribution is of high practical interest since it should be preferred to a\nGaussian when dealing with the problem of pricing derivative financial\ncontracts.\n"
    },
    {
        "paper_id": 1106.504,
        "authors": "Fabien Guilbaud (LPMA), Huyen Pham (LPMA, CREST)",
        "title": "Optimal High Frequency Trading with limit and market orders",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a framework for studying optimal market making policies in a limit\norder book (LOB). The bid-ask spread of the LOB is modelled by a Markov chain\nwith finite values, multiple of the tick size, and subordinated by the Poisson\nprocess of the tick-time clock. We consider a small agent who continuously\nsubmits limit buy/sell orders and submits market orders at discrete dates. The\nobjective of the market maker is to maximize her expected utility from revenue\nover a short term horizon by a tradeoff between limit and market orders, while\ncontrolling her inventory position. This is formulated as a mixed regime\nswitching regular/ impulse control problem that we characterize in terms of\nquasi-variational system by dynamic programming methods. In the case of a\nmean-variance criterion with martingale reference price or when the asset price\nfollows a Levy process and with exponential utility criterion, the dynamic\nprogramming system can be reduced to a system of simple equations involving\nonly the inventory and spread variables. Calibration procedures are derived for\nestimating the transition matrix and intensity parameters for the spread and\nfor Cox processes modelling the execution of limit orders. Several\ncomputational tests are performed both on simulated and real data, and\nillustrate the impact and profit when considering execution priority in limit\norders and market orders\n"
    },
    {
        "paper_id": 1106.5081,
        "authors": "Alessandro Fiori Maccioni (CRENoS and University of Sassari)",
        "title": "A Stochastic Model for the Analysis of Demographic Risk in Pay-As-You-Go\n  Pension Funds",
        "comments": "20 pages, 9 figures, 5 tables. Original paper available at:\n  http://sunshine.dma.unive.it/mmef/vol-3-2-2008.html",
        "journal-ref": "Mathemathical Methods in Economics and Finance, Vol. 3, No. 2, pp.\n  41-60, 2008",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This research presents an analysis of the demographic risk related to future\nmembership patterns in pension funds with restricted entrance, financed under a\npay-as-you-go scheme. The paper, therefore, proposes a stochastic model for\ninvestigating the behaviour of the demographic variable \"new entrants\" and the\ninfluence it exerts on the financial dynamics of such funds. Further\ninformation on pension funds of Italian professional categories and an\napplication to the Cassa Nazionale di Previdenza e Assistenza dei Dottori\nCommercialisti (CNPADC) are then provided.\n"
    },
    {
        "paper_id": 1106.5143,
        "authors": "L. F. Blazhyevskyi, V. S. Yanishevsky",
        "title": "The path integral representation kernel of evolution operator in\n  Merton-Garman model",
        "comments": "16 pages",
        "journal-ref": "Condens. Matter Phys., 2011, vol. 14, No. 2, 23001:1-16",
        "doi": "10.5488/CMP.14.23001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the framework of path integral the evolution operator kernel for the\nMerton-Garman Hamiltonian is constructed. Based on this kernel option formula\nis obtained, which generalizes the well-known Black-Scholes result. Possible\napproximation numerical schemes for path integral calculations are proposed.\n"
    },
    {
        "paper_id": 1106.5274,
        "authors": "Alessandro Fiori Maccioni",
        "title": "Endogenous Bubbles in Derivatives Markets: The Risk Neutral Valuation\n  Paradox",
        "comments": "21 pages. The second version presents the following upgrades:\n  improved precision in the definition of agents and their behaviour;\n  simplification in the notation of the probability measure; simplification in\n  section 4.1; addition of caveats in the conclusions. The results of the\n  second version remain unchanged",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper highlights the role of risk neutral investors in generating\nendogenous bubbles in derivatives markets. We find that a market for\nderivatives, which has all the features of a perfect market except completeness\nand has some risk neutral investors, can exhibit extreme price movements which\nrepresent a violation to the Gaussian random walk hypothesis. This can be\nviewed as a paradox because it contradicts wide-held conjectures about prices\nin informationally efficient markets with rational investors. Our findings\nimply that prices are not always good approximations of the fundamental values\nof derivatives, and that extreme price movements like price peaks or crashes\nmay have endogenous origin and happen with a higher-than-normal frequency.\n"
    },
    {
        "paper_id": 1106.5706,
        "authors": "Dorje C. Brody and Yan Tai Law",
        "title": "Theory of Information Pricing",
        "comments": "13 pages, 6 figures, references added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In financial markets valuable information is rarely circulated homogeneously,\nbecause of time required for information to spread. However, advances in\ncommunication technology means that the 'lifetime' of important information is\ntypically short. Hence, viewed as a tradable asset, information shares the\ncharacteristics of a perishable commodity: while it can be stored and\ntransmitted freely, its worth diminishes rapidly in time. In view of recent\ndevelopments where internet search engines and other information providers are\noffering information to financial institutions, the problem of pricing\ninformation is becoming increasingly important. With this in mind, a new\nformulation of utility-indifference argument is introduced and used as a basis\nfor pricing information. Specifically, we regard information as a quantity that\nconverts a prior distribution into a posterior distribution. The amount of\ninformation can then be quantified by relative entropy. The key to our utility\nindifference argument is to equate the maximised a posterior utility, after\npaying certain cost for the information, with the a posterior expectation of\nthe utility based on the a priori optimal strategy. This formulation leads to\none price for a given quantity of upside information; and another price for a\ngiven quantity of downside information. The ideas are illustrated by means of\nsimple examples.\n"
    },
    {
        "paper_id": 1106.5913,
        "authors": "Petr Jizba, Hagen Kleinert, Mohammad Shefaat",
        "title": "Renyi's information transfer between financial time series",
        "comments": "35 pages, 16 figure, RevTeX4, revised version with minor changes,\n  accepted to Physica A",
        "journal-ref": "Physica A 391 (2012) 2971-2989",
        "doi": "10.1016/j.physa.2011.12.064",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we quantify the statistical coherence between financial time\nseries by means of the Renyi entropy. With the help of Campbell's coding\ntheorem we show that the Renyi entropy selectively emphasizes only certain\nsectors of the underlying empirical distribution while strongly suppressing\nothers. This accentuation is controlled with Renyi's parameter q. To tackle the\nissue of the information flow between time series we formulate the concept of\nRenyi's transfer entropy as a measure of information that is transferred only\nbetween certain parts of underlying distributions. This is particularly\npertinent in financial time series where the knowledge of marginal events such\nas spikes or sudden jumps is of a crucial importance. We apply the Renyian\ninformation flow to stock market time series from 11 world stock indices as\nsampled at a daily rate in the time period 02.01.1990 - 31.12.2009.\nCorresponding heat maps and net information flows are represented graphically.\nA detailed discussion of the transfer entropy between the DAX and S&P500\nindices based on minute tick data gathered in the period from 02.04.2008 to\n11.09.2009 is also provided. Our analysis shows that the bivariate information\nflow between world markets is strongly asymmetric with a distinct information\nsurplus flowing from the Asia-Pacific region to both European and US markets.\nAn important yet less dramatic excess of information also flows from Europe to\nthe US. This is particularly clearly seen from a careful analysis of Renyi\ninformation flow between the DAX and S&P500 indices.\n"
    },
    {
        "paper_id": 1106.5929,
        "authors": "Mathias Beiglb\\\"ock and Pierre Henry-Labord\\`ere and Friedrich Penkner",
        "title": "Model-independent Bounds for Option Prices: A Mass Transport Approach",
        "comments": "Finance and Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we investigate model-independent bounds for exotic options\nwritten on a risky asset. Based on arguments from the theory of\nMonge-Kantorovich mass-transport we establish a dual version of the problem\nthat has a natural financial interpretation in terms of semi-static hedging. In\nparticular we prove that there is no duality gap.\n"
    },
    {
        "paper_id": 1106.6102,
        "authors": "Dan A. Iancu, Marek Petrik, Dharmashankar Subramanian",
        "title": "Tight Approximations of Dynamic Risk Measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper compares two different frameworks recently introduced in the\nliterature for measuring risk in a multi-period setting. The first corresponds\nto applying a single coherent risk measure to the cumulative future costs,\nwhile the second involves applying a composition of one-step coherent risk\nmappings. We summarize the relative strengths of the two methods, characterize\nseveral necessary and sufficient conditions under which one of the measurements\nalways dominates the other, and introduce a metric to quantify how close the\ntwo risk measures are.\n  Using this notion, we address the question of how tightly a given coherent\nmeasure can be approximated by lower or upper-bounding compositional measures.\nWe exhibit an interesting asymmetry between the two cases: the tightest\npossible upper-bound can be exactly characterized, and corresponds to a popular\nconstruction in the literature, while the tightest-possible lower bound is not\nreadily available. We show that testing domination and computing the\napproximation factors is generally NP-hard, even when the risk measures in\nquestion are comonotonic and law-invariant. However, we characterize conditions\nand discuss several examples where polynomial-time algorithms are possible. One\nsuch case is the well-known Conditional Value-at-Risk measure, which is further\nexplored in our companion paper [Huang, Iancu, Petrik and Subramanian, \"Static\nand Dynamic Conditional Value at Risk\" (2012)]. Our theoretical and algorithmic\nconstructions exploit interesting connections between the study of risk\nmeasures and the theory of submodularity and combinatorial optimization, which\nmay be of independent interest.\n"
    },
    {
        "paper_id": 1106.63,
        "authors": "Mine Caglar",
        "title": "Stock Price Processes with Infinite Source Poisson Agents",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct a general stochastic process and prove weak convergence results.\nIt is scaled in space and through the parameters of its distribution. We show\nthat our simplified scaling is equivalent to time scaling used frequently. The\nprocess is constructed as an integral with respect to a Poisson random measure\nwhich governs several parameters of trading agents in the context of stock\nprices. When the trading occurs more frequently and in smaller quantities, the\nlimit is a fractional Brownian motion. In contrast, a stable Levy motion is\nobtained if the rate of trading decreases while its effect rate increases.\n"
    },
    {
        "paper_id": 1107.0036,
        "authors": "A. Borodin, R. El-Yaniv, V. Gogan",
        "title": "Can We Learn to Beat the Best Stock",
        "comments": null,
        "journal-ref": "Journal Of Artificial Intelligence Research, Volume 21, pages\n  579-594, 2004",
        "doi": "10.1613/jair.1336",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A novel algorithm for actively trading stocks is presented. While traditional\nexpert advice and \"universal\" algorithms (as well as standard technical trading\nheuristics) attempt to predict winners or trends, our approach relies on\npredictable statistical relations between all pairs of stocks in the market.\nOur empirical results on historical markets provide strong evidence that this\ntype of technical trading can \"beat the market\" and moreover, can beat the best\nstock in the market. In doing so we utilize a new idea for smoothing critical\nparameters in the context of expert learning.\n"
    },
    {
        "paper_id": 1107.0164,
        "authors": "Alexandre Boumezoued, Yoboua Angoua, Laurent Devineau (SAF),\n  Jean-Philippe Boisseau",
        "title": "One-year reserve risk including a tail factor: closed formula and\n  bootstrap approaches",
        "comments": "48 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we detail the main simulation methods used in practice to\nmeasure one-year reserve risk, and describe the bootstrap method providing an\nempirical distribution of the Claims Development Result (CDR) whose variance is\nidentical to the closed-form expression of the prediction error proposed by\nW\\\"uthrich et al. (2008). In particular, we integrate the stochastic modeling\nof a tail factor in the bootstrap procedure. We demonstrate the equivalence\nwith existing analytical results and develop closed-form expressions for the\nerror of prediction including a tail factor. A numerical example is given at\nthe end of this study.\n"
    },
    {
        "paper_id": 1107.017,
        "authors": "Saoussen Ben Gamra (CEPN), Dominique Plihon (CEPN)",
        "title": "Revenue diversification in emerging market banks: implications for\n  financial performance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Shaped by structural forces of change, banking in emerging markets has\nrecently experienced a decline in its traditional activities, leading banks to\ndiversify into new business strategies. This paper examines whether the\nobserved shift into non-interest based activities improves financial\nperformance. Using a sample of 714 banks across 14 East-Asian and\nLatin-American countries over the post 1997-crisis changing structure, we find\nthat diversification gains are more than offset by the cost of increased\nexposure to the non-interest income, specifically by the trading income\nvolatility. But this diversification performance's effect is found to be no\nlinear with risk, and significantly not uniform among banks and across business\nlines. An implication of these findings is that banking institutions can reap\ndiversification benefits as long as they well-studied it depending on their\nspecific characteristics, competences and risk levels, and as they choose the\nright niche.\n"
    },
    {
        "paper_id": 1107.0183,
        "authors": "Christoph Frei, Markus Mocha and Nicholas Westray",
        "title": "BSDEs in Utility Maximization with BMO Market Price of Risk",
        "comments": "33 pages, 1 figure",
        "journal-ref": "Stochastic Process. Appl., 122 (6): 2486 - 2519, 2012",
        "doi": "10.1016/j.spa.2012.03.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article studies quadratic semimartingale BSDEs arising in power utility\nmaximization when the market price of risk is of BMO type. In a Brownian\nsetting we provide a necessary and sufficient condition for the existence of a\nsolution but show that uniqueness fails to hold in the sense that there exists\na continuum of distinct square-integrable solutions. This feature occurs since,\ncontrary to the classical Ito representation theorem, a representation of\nrandom variables in terms of stochastic exponentials is not unique. We study in\ndetail when the BSDE has a bounded solution and derive a new dynamic\nexponential moments condition which is shown to be the minimal sufficient\ncondition in a general filtration. The main results are complemented by several\ninteresting examples which illustrate their sharpness as well as important\nproperties of the utility maximization BSDE.\n"
    },
    {
        "paper_id": 1107.019,
        "authors": "Markus Mocha and Nicholas Westray",
        "title": "The Stability of the Constrained Utility Maximization Problem - A BSDE\n  Approach",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article studies the sensitivity of the power utility maximization\nproblem with respect to the investor's relative risk aversion, the statistical\nprobability measure, the investment constraints and the market price of risk.\nWe extend previous descriptions of the dual domain then exploit the link\nbetween the constrained utility maximization problem and continuous\nsemimartingale quadratic BSDEs to reduce questions on sensitivity to results on\nstability for such equations. This then allows us to prove appropriate\nconvergence of the primal and dual optimizers in the semimartingale topology.\n"
    },
    {
        "paper_id": 1107.048,
        "authors": "Askar Akaev, Alexei Fomin, and Andrey Korotayev",
        "title": "The Second Wave of the Global Crisis? A Log-Periodic Oscillation\n  Analysis of Commodity Price Series",
        "comments": "12 pages, 9 figures. This research has been supported by the\n  Presidium of the Russian Academy of Sciences (Project \"Complex System\n  Analysis and Mathematical Modeling of the World Dynamics\")",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article continues our analysis of the gold price dynamics that was\npublished in December 2010 (abs/1012.4118) and forecasted the possibility of\nthe \"burst of the gold bubble\" in April - June 2011. Our recent analysis\nsuggests the possibility of one more substantial fluctuation before the final\ncollapse in July 2011. On the other hand, in early 2011 we detected a number of\nother commodity bubbles and forecasted the start of their collapse in May -\nJune 2011. We demonstrate that this collapse has actually begun, which in\nconjunction with the forthcoming burst of the gold bubble suggests that the\nWorld System is entering a bifurcation zone bearing rather high risks of the\nsecond wave of the global financial-economic crisis. Indeed, on the one hand,\nit is obvious that such a collapse may lead to huge losses or even bankruptcies\nof many of the major participants of exchange games and their dependent firms\nand banks. Therefore, the immediate market reaction is likely to be entirely\nnegative. Negative impact on the market could well be amplified by numerous\npublications in the media and business press, drawing analogies with the events\nof the early 1980s and earlier similar events, as well as by losses of\nshareholders of bankrupt companies. On the other hand, investments in gold also\nlead to the diversion of funds from stock market investments and to the\nreduction in the production of goods and services. If at the time of the\ncollapse some promising areas of investment appear in the developed and / or\ndeveloping countries, the investment can move to those markets, which, on the\ncontrary, could contribute to the production of new goods and services and\naccelerate the way out of the crisis. It is also obvious that the decline of\nthe oil (and other energy/mineral resources) prices may contribute to\nacceleration of world economic growth rates and world economic recovery.\n"
    },
    {
        "paper_id": 1107.0838,
        "authors": "Wanfeng Yan, Ryan Woodard, Didier Sornette",
        "title": "Role of Diversification Risk in Financial Bubbles",
        "comments": "22 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an extension of the Johansen-Ledoit-Sornette (JLS) model to\ninclude an additional pricing factor called the \"Zipf factor\", which describes\nthe diversification risk of the stock market portfolio. Keeping all the\ndynamical characteristics of a bubble described in the JLS model, the new model\nprovides additional information about the concentration of stock gains over\ntime. This allows us to understand better the risk diversification and to\nexplain the investors' behavior during the bubble generation. We apply this new\nmodel to two famous Chinese stock bubbles, from August 2006 to October 2007\n(bubble 1) and from October 2008 to August 2009 (bubble 2). The Zipf factor is\nfound highly significant for bubble 1, corresponding to the fact that valuation\ngains were more concentrated on the large firms of the Shanghai index. It is\nlikely that the widespread acknowledgement of the 80-20 rule in the Chinese\nmedia and discussion forums led many investors to discount the risk of a lack\nof diversification, therefore enhancing the role of the Zipf factor. For bubble\n2, the Zipf factor is found marginally relevant, suggesting a larger weight of\nmarket gains on small firms. We interpret this result as the consequence of the\nresponse of the Chinese economy to the very large stimulus provided by the\nChinese government in the aftermath of the 2008 financial crisis.\n"
    },
    {
        "paper_id": 1107.0839,
        "authors": "Ulrich Horst and Santiago Moreno-Bromberg",
        "title": "Efficiency and Equilibria in Games of Optimal Derivative Design",
        "comments": "34 pages and 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper the problem of optimal derivative design, profit maximization\nand risk minimization under adverse selection when multiple agencies compete\nfor the business of a continuum of heterogenous agents is studied. The presence\nof ties in the agents' best-response correspondences yields discontinuous\npayoff functions for the agencies. These discontinuities are dealt with via\nefficient tie--breaking rules. In a first step, the model presented by Carlier,\nEkeland & Touzi (2007) of optimal derivative design by profit-maximizing\nagencies is extended to a multiple--firm setting, and results of Page &\nMonteiro (2003, 2007, 2008) are used to prove the existence of\n(mixed-strategies) Nash equilibria. On a second step we consider the more\ncomplex case of risk minimizing firms. Here the concept of socially efficient\nallocations is introduced, and existence of the latter is proved. It is also\nshown that in the particular case of the entropic risk measure, there exists an\nefficient \"fix--mix\" tie-breaking rule, in which case firms share the whole\nmarket over given proportions.\n"
    },
    {
        "paper_id": 1107.1078,
        "authors": "Frank Riedel",
        "title": "Finance Without Probabilistic Prior Assumptions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop the fundamental theorem of asset pricing in a probability-free\ninfinite-dimensional setup. We replace the usual assumption of a prior\nprobability by a certain continuity property in the state variable.\nProbabilities enter then endogenously as full support martingale measures\n(instead of equivalent martingale measures). A variant of the\nHarrison-Kreps-Theorem on viability and no arbitrage is shown. Finally, we show\nhow to embed the superhedging problem in a classical infinite-dimensional\nlinear programming problem.\n"
    },
    {
        "paper_id": 1107.1174,
        "authors": "Josep Perell\\'o, Mario Guti\\'errez-Roig, Jaume Masoliver",
        "title": "Scaling properties and universality of first-passage time probabilities\n  in financial markets",
        "comments": "7 pages, 5 figures",
        "journal-ref": "Phys. Rev. E 84, 066110 (2011)",
        "doi": "10.1103/PhysRevE.84.066110",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets provide an ideal frame for the study of crossing or\nfirst-passage time events of non-Gaussian correlated dynamics mainly because\nlarge data sets are available. Tick-by-tick data of six futures markets are\nherein considered resulting in fat tailed first-passage time probabilities. The\nscaling of the return with the standard deviation collapses the probabilities\nof all markets examined, and also for different time horizons, into single\ncurves, suggesting that first-passage statistics is market independent (at\nleast for high-frequency data). On the other hand, a very closely related\nquantity, the survival probability, shows, away from the center and tails of\nthe distribution, a hyperbolic $t^{-1/2}$ decay typical of a Markovian dynamics\nalbeit the existence of memory in markets. Modifications of the Weibull and\nStudent distributions are good candidates for the phenomenological description\nof first-passage time properties under certain regimes. The scaling strategies\nshown may be useful for risk control and algorithmic trading.\n"
    },
    {
        "paper_id": 1107.138,
        "authors": "Catherine Donnelly",
        "title": "Quantifying mortality risk in small defined-benefit pension schemes",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1080/03461238.2011.635803",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A risk of small defined-benefit pension schemes is that there are too few\nmembers to eliminate idiosyncratic mortality risk, that is there are too few\nmembers to effectively pool mortality risk. This means that when there are few\nmembers in the scheme, there is an increased risk of the liability value\ndeviating significantly from the expected liability value, as compared to a\nlarge scheme.\n  We quantify this risk through examining the coefficient of variation of a\nscheme's liability value relative to its expected value. We examine how the\ncoefficient of variation varies with the number of members and find that, even\nwith a few hundred members in the scheme, idiosyncratic mortality risk may\nstill be significant. Using a stochastic mortality model reduces the\nidiosyncratic mortality risk but at the cost of increasing the overall\nmortality risk in the scheme.\n  Next we quantify the amount of the mortality risk concentrated in the\nexecutive section of the scheme, where the executives receive a benefit that is\nhigher than the non-executive benefit. We use the Euler capital allocation\nprinciple to allocate the total standard deviation of the liability value\nbetween the executive and non-executive sections. We find that the proportion\nof the standard deviation allocated to the executive section is higher than is\nsuggested by an allocation based on the members' benefit amounts. While the\nresults are sensitive to the choice of mortality model, they do suggest that\nthe mortality risk of the scheme should be monitored and managed within the\nsections of a scheme, and not only on a scheme-wide basis.\n"
    },
    {
        "paper_id": 1107.1451,
        "authors": "Giacomo Bormetti and Sofia Cazzaniga",
        "title": "Multiplicative noise, fast convolution, and pricing",
        "comments": "19 pages, 16 figures",
        "journal-ref": "Quantitative Finance, 2012, 1-14 iFirst",
        "doi": "10.1080/14697688.2012.729857",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we detail the application of a fast convolution algorithm\ncomputing high dimensional integrals to the context of multiplicative noise\nstochastic processes. The algorithm provides a numerical solution to the\nproblem of characterizing conditional probability density functions at\narbitrary time, and we applied it successfully to quadratic and piecewise\nlinear diffusion processes. The ability in reproducing statistical features of\nfinancial return time series, such as thickness of the tails and scaling\nproperties, makes this processes appealing for option pricing. Since exact\nanalytical results are missing, we exploit the fast convolution as a numerical\nmethod alternative to the Monte Carlo simulation both in objective and risk\nneutral settings. In numerical sections we document how fast convolution\noutperforms Monte Carlo both in velocity and efficiency terms.\n"
    },
    {
        "paper_id": 1107.1607,
        "authors": "Christa Cuchiero and Josef Teichmann",
        "title": "Path properties and regularity of affine processes on general state\n  spaces",
        "comments": "final version for publication in seminaire de probabilite",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a new proof for regularity of affine processes on general state\nspaces by methods from the theory of Markovian semimartingales. On the way to\nthis result we also show that the definition of an affine process, namely as\nstochastically continuous time-homogeneous Markov process with exponential\naffine Fourier-Laplace transform, already implies the existence of a c\\`adl\\`ag\nversion. This was one of the last open issues in the fundaments of affine\nprocesses.\n"
    },
    {
        "paper_id": 1107.1617,
        "authors": "Laurence Carassus and Miklos Rasonyi",
        "title": "On optimal investment for a behavioural investor in multiperiod\n  incomplete market models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide easily verifiable conditions for the well-posedness of the optimal\ninvestment problem for a behavioral investor in an incomplete discrete-time\nmultiperiod financial market model, for the first time in the literature. Under\ntwo different sets of assumptions we also establish the existence of optimal\nstrategies.\n"
    },
    {
        "paper_id": 1107.1787,
        "authors": "Takashi Kato",
        "title": "An Optimal Execution Problem with a Geometric Ornstein-Uhlenbeck Price\n  Process",
        "comments": "21 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study an optimal execution problem in the presence of market impact where\nthe security price follows a geometric Ornstein-Uhlenbeck process, which\nimplies the mean-reverting property, and show that the optimal strategy is a\nmixture of initial/terminal block liquidation and gradual intermediate\nliquidation. The mean-reverting property describes a price recovery effect that\nis strongly related to the resilience of market impact, as described in several\npapers that have studied optimal execution in a limit order book (LOB) model.\nIt is interesting that despite the fact that the model in this paper is\ndifferent from the LOB model, the form of our optimal strategy is quite similar\nto those obtained for an LOB model. Moreover, we discuss what properties cause\ngradual liquidation as an optimal strategy by studying various cases and find\nout that not only \"convexity of market impact function\" but also \"price\nrecovery effect\" (or, in other words, transience of market impact) are\nessential to make a trader execute the security gradually to mitigate the\neffect of market impact.\n"
    },
    {
        "paper_id": 1107.1831,
        "authors": "Cristian Homescu",
        "title": "Adjoints and Automatic (Algorithmic) Differentiation in Computational\n  Finance",
        "comments": "23 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Two of the most important areas in computational finance: Greeks and,\nrespectively, calibration, are based on efficient and accurate computation of a\nlarge number of sensitivities. This paper gives an overview of adjoint and\nautomatic differentiation (AD), also known as algorithmic differentiation,\ntechniques to calculate these sensitivities. When compared to finite difference\napproximation, this approach can potentially reduce the computational cost by\nseveral orders of magnitude, with sensitivities accurate up to machine\nprecision. Examples and a literature survey are also provided.\n"
    },
    {
        "paper_id": 1107.1834,
        "authors": "Cristian Homescu",
        "title": "Implied Volatility Surface: Construction Methodologies and\n  Characteristics",
        "comments": "40 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The implied volatility surface (IVS) is a fundamental building block in\ncomputational finance. We provide a survey of methodologies for constructing\nsuch surfaces. We also discuss various topics which can influence the\nsuccessful construction of IVS in practice: arbitrage-free conditions in both\nstrike and time, how to perform extrapolation outside the core region, choice\nof calibrating functional and selection of numerical optimization algorithms,\nvolatility surface dynamics and asymptotics.\n"
    },
    {
        "paper_id": 1107.1895,
        "authors": "Traian A.Pirvu, Huayue Zhang",
        "title": "On Investment-Consumption with Regime-Switching",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a continuous time stochastic economy, this paper considers the problem of\nconsumption and investment in a financial market in which the representative\ninvestor exhibits a change in the discount rate. The investment opportunities\nare a stock and a riskless account. The market coefficients and discount factor\nswitches according to a finite state Markov chain. The change in the discount\nrate leads to time inconsistencies of the investor's decisions. The randomness\nin our model is driven by a Brownian motion and Markov chain. Following Ekeland\netc (2008) we introduce and characterize the equilibrium policies for power\nutility functions. Moreover, they are computed in closed form for logarithmic\nutility function. We show that a higher discount rate leads to a higher\nequilibrium consumption rate. Numerical experiments show the effect of both\ntime preference and risk aversion on the equilibrium policies.\n"
    },
    {
        "paper_id": 1107.2164,
        "authors": "Mikhail Voropaev",
        "title": "KISS approach to credit portfolio modeling",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A simple, yet reasonably accurate, analytical technique is proposed for\nmulti-factor structural credit portfolio models. The accuracy of the technique\nis demonstrated by benchmarking against Monte Carlo simulations. The approach\npresented here may be of high interest to practitioners looking for\ntransparent, intuitive, easy to implement and high performance credit portfolio\nmodel.\n"
    },
    {
        "paper_id": 1107.2346,
        "authors": "Miquel Montero",
        "title": "Parrondo-like behavior in continuous-time random walks with memory",
        "comments": "8 pages, 3 figures, revtex; enlarged and revised version",
        "journal-ref": "Phys. Rev. E 84, 051139 (2011)",
        "doi": "10.1103/PhysRevE.84.051139",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Continuous-Time Random Walk (CTRW) formalism can be adapted to encompass\nstochastic processes with memory. In this article we will show how the random\ncombination of two different unbiased CTRWs can give raise to a process with\nclear drift, if one of them is a CTRW with memory. If one identifies the other\none as noise, the effect can be thought as a kind of stochastic resonance. The\nultimate origin of this phenomenon is the same of the Parrondo's paradox in\ngame theory\n"
    },
    {
        "paper_id": 1107.2562,
        "authors": "Carlos Pedro Gon\\c{c}alves",
        "title": "Quantum Financial Economics - Risk and Returns",
        "comments": "18 pages; 5 figures; Based on talk given at the conference \"As\n  Ci\\^encias Sociais: Abordagens de Investiga\\c{c}\\~ao\" (Lisbon, 2011)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial volatility risk and its relation to a business cycle-related\nintrinsic time is addressed through a multiple round evolutionary quantum game\nequilibrium leading to turbulence and multifractal signatures in the financial\nreturns and in the risk dynamics. The model is simulated and the results are\ncompared with actual financial volatility data.\n"
    },
    {
        "paper_id": 1107.2716,
        "authors": "Erhan Bayraktar, Ross Kravitz",
        "title": "Stability of exponential utility maximization with respect to market\n  perturbations",
        "comments": "Final version. To appear in \"Stochastic Processes and Their\n  Applications\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the continuity of expected exponential utility maximization\nwith respect to perturbation of the Sharpe ratio of markets. By focusing only\non continuity, we impose weaker regularity conditions than those found in the\nliterature. Specifically, we require, in addition to the $V$-compactness\nhypothesis of Larsen and \\v{Z}itkovi\\'c (2007) (ArXiv: 0706.0474), a local\n$bmo$ hypothesis, a condition which is seen to always be trivially satisfied in\nthe setting of Larsen and \\v{Z}itkovi\\'c (2007). For markets of the form $S = M\n+ \\int \\lambda d<M>$, these conditions are simultaneously implied by the\nexistence of a uniform bound on the norm of $\\lambda \\cdot M$ in a suitable\n$bmo$ space.\n"
    },
    {
        "paper_id": 1107.2748,
        "authors": "Alessandro Gnoatto and Martino Grasselli",
        "title": "The explicit Laplace transform for the Wishart process",
        "comments": "Accepted on: Journal of Applied Probability 51(3), 2014",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive the explicit formula for the joint Laplace transform of the Wishart\nprocess and its time integral which extends the original approach of Bru. We\ncompare our methodology with the alternative results given by the variation of\nconstants method, the linearization of the Matrix Riccati ODE's and the\nRunge-Kutta algorithm. The new formula turns out to be fast and accurate.\n"
    },
    {
        "paper_id": 1107.2988,
        "authors": "Erhan Bayraktar, Yu-Jui Huang",
        "title": "Robust maximization of asymptotic growth under covariance uncertainty",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP887 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 5, 1817-1840",
        "doi": "10.1214/12-AAP887",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper resolves a question proposed in Kardaras and Robertson [Ann. Appl.\nProbab. 22 (2012) 1576-1610]: how to invest in a robust growth-optimal way in a\nmarket where precise knowledge of the covariance structure of the underlying\nassets is unavailable. Among an appropriate class of admissible covariance\nstructures, we characterize the optimal trading strategy in terms of a\ngeneralized version of the principal eigenvalue of a fully nonlinear elliptic\noperator and its associated eigenfunction, by slightly restricting the\ncollection of nondominated probability measures.\n"
    },
    {
        "paper_id": 1107.3095,
        "authors": "A. Johansen and I. Simonsen",
        "title": "Keynesian Economics After All",
        "comments": "Latex, 4 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is demonstrated that the US economy has on the long-term in reality been\ngoverned by the Keynesian approach to economics independent of the current\nofficial economical policy. This is done by calculating the two-point\ncorrelation function between the fluctuations of the DJIA and the US public\ndebt. We find that the origin of this condition is mainly related to the wars\nthat the USA has fought during the time period investigated. Wars mean a large\ninflux of public money into the economy, thus as a consequence creating a\nsignificant economical upturn in the DJIA. A reason for this straight-cut\nresult of our analysis, is that very few wars have been fought on US-territory\nand those that have, were in the 18th century, when the partial destruction of\ncities, factories, railways and so on, was more limited and with less effect on\nthe over-all economy.\n"
    },
    {
        "paper_id": 1107.3171,
        "authors": "Didier Sornette, Ryan Woodard, Wanfeng Yan, Wei-Xing Zhou",
        "title": "Clarifications to Questions and Criticisms on the\n  Johansen-Ledoit-Sornette Bubble Model",
        "comments": "27 pages, 3 figures",
        "journal-ref": "Physica A 392 (19), 4417-4428 (2013)",
        "doi": "10.1016/j.physa.2013.05.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Johansen-Ledoit-Sornette (JLS) model of rational expectation bubbles with\nfinite-time singular crash hazard rates has been developed to describe the\ndynamics of financial bubbles and crashes. It has been applied successfully to\na large variety of financial bubbles in many different markets. Having been\ndeveloped for more than one decade, the JLS model has been studied, analyzed,\nused and criticized by several researchers. Much of this discussion is helpful\nfor advancing the research. However, several serious misconceptions seem to be\npresent within this collective conversation both on theoretical and empirical\naspects. Several of these problems appear to stem from the fast evolution of\nthe literature on the JLS model and related works. In the hope of removing\npossible misunderstanding and of catalyzing useful future developments, we\nsummarize these common questions and criticisms concerning the JLS model and\noffer a synthesis of the existing state-of-the-art and best-practice advices.\n"
    },
    {
        "paper_id": 1107.3287,
        "authors": "B. Bieda, P. Chodorowski, and D. Grech",
        "title": "On the Zipf strategy for short-term investments in WIG20 futures",
        "comments": "13 pages, 6 figures, 1 table, presented at the 5-th FENS symposium on\n  Physics in Economic and Social Systems, Warsaw 2010",
        "journal-ref": null,
        "doi": "10.12693/APhysPolA.121.B-7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We apply the Zipf power law to financial time series of WIG20 index daily\nchanges (open-close). Thanks to the mapping of time series signal into the\nsequence of 2k+1 'spin-like' states, where k=0, 1/2, 1, 3/2, ..., we are able\nto describe any time series increments, with almost arbitrary accuracy, as the\none of such 'spin-like' states. This procedure leads in the simplest\nnon-trivial case (k = 1/2) to the binary data projection. More sophisticated\nprojections are also possible and mentioned in the article. The introduced\nformalism allows then to use Zipf power law to describe the intrinsic structure\nof time series. The fast algorithm for this implementation was constructed by\nus within Matlab^{TM} software. The method, called Zipf strategy, is then\napplied in the simplest case k = 1/2 to WIG 20 open and close daily data to\nmake short-term predictions for forthcoming index changes. The results of\nforecast effectiveness are presented with respect to different time window\nsizes and partition divisions (word lengths in Zipf language). Finally, the\nvarious investment strategies improving ROI (return of investment) for WIG20\nfutures are proposed. We show that the Zipf strategy is the appropriate and\nvery effective tool to make short-term predictions and therefore, to evaluate\nshort-term investments on the basis of historical stock index data. Our\nfindings support also the existence of long memory in financial data, exceeding\nthe known in literature 3 days span limit.\n"
    },
    {
        "paper_id": 1107.3293,
        "authors": "Lane P. Hughston, Francesco Mina",
        "title": "On the Representation of General Interest Rate Models as Square\n  Integrable Wiener Functionals",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the setting proposed by Hughston & Rafailidis (2005) we consider general\ninterest rate models in the case of a Brownian market information filtration\n$(\\mathcal{F}_t)_{t\\geq0}$. Let $X$ be a square-integrable\n$\\mathcal{F}_\\infty$-measurable random variable, and assume the non-degeneracy\ncondition that for all $t<\\infty$ the random variable $X$ is not\n$\\mathcal{F}_t$-measurable. Let ${\\sigma_t}$ denote the integrand appearing in\nthe representation of $X$ as a stochastic integral, write $\\pi_t$ for the\nconditional variance of $X$ at time $t$, and set $r_t = \\sigma^2_t / \\pi_t$.\nThen $\\pi_t$ is a potential, and as such can act as a model for a pricing\nkernel (or state price density), where $r_t$ is the associated interest rate.\nUnder the stated assumptions, we prove the following: (a) that the money market\naccount process defined by $B_t = \\exp (\\int_0^t r_s \\,ds)$ is finite almost\nsurely at all finite times; and (b) that the product of the money-market\naccount and the pricing kernel is a local martingale, and is a martingale\nprovided a certain integrability condition is satisfied. The fact that a\nmartingale is thus obtained shows that from any non-degenerate element of\nWiener space satisfying the integrability condition we can construct an\nassociated interest-rate model. The model thereby constructed is valid over an\ninfinite time horizon, with strictly positive interest, and satisfies the\nrelevant intertemporal relations associated with the absence of arbitrage. The\nresults thus stated pave the way for the use of Wiener chaos methods in\ninterest rate modelling, since any such square-integrable Wiener functional\nadmits a chaos expansion, the individual terms of which can be regarded as\nparametric degrees of freedom in the associated interest rate model to be fixed\nby calibration to appropriately liquid sectors of the interest rate derivatives\nmarkets.\n"
    },
    {
        "paper_id": 1107.3364,
        "authors": "Zoltan Eisler, Jean-Philippe Bouchaud, Julien Kockelkoren",
        "title": "Models for the impact of all order book events",
        "comments": "12 pages, 5 figures, to appear in the proceedings of Market\n  Microstructure - Confronting Many Viewpoints",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a general framework to describe the impact of different events in\nthe order book, that generalizes previous work on the impact of market orders.\nTwo different modeling routes can be considered, which are equivalent when only\nmarket orders are taken into account. One model posits that each event type has\na temporary impact (TIM). The \"history dependent impact\" model (HDIM), on the\nother hand, assumes that only price-changing events have a direct impact,\nitself modulated by the past history of all events through an \"influence\nmatrix\" that measures how much, on average, an event of a given type affects\nthe immediate impact of a price-changing event of the same sign in the future.\nWe find in particular that aggressive market orders tend to reduce the impact\nof further aggressive market orders of the same sign (and increase the impact\nof aggressive market orders of opposite sign). We discuss the relative merits\nof TIM and HDIM, in particular concerning their ability to reproduce accurately\nthe price diffusion pattern. We find that in spite of theoretical\ninconsistencies, TIM appears to fare better than HDIM when compared to\nempirical data. We ascribe this paradox to an uncontrolled approximation used\nto calibrate HDIMs, calling for further work on this issue.\n"
    },
    {
        "paper_id": 1107.3456,
        "authors": "Tomaso Aste, Ruggero Gramatica and T. Di Matteo",
        "title": "Exploring complex networks via topological embedding on surfaces",
        "comments": "18 pages, 7 figures",
        "journal-ref": "Physical Review E 86, 036109 (2012)",
        "doi": "10.1103/PhysRevE.86.036109",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We demonstrate that graphs embedded on surfaces are a powerful and practical\ntool to generate, characterize and simulate networks with a broad range of\nproperties. Remarkably, the study of topologically embedded graphs is\nnon-restrictive because any network can be embedded on a surface with\nsufficiently high genus. The local properties of the network are affected by\nthe surface genus which, for example, produces significant changes in the\ndegree distribution and in the clustering coefficient. The global properties of\nthe graph are also strongly affected by the surface genus which is constraining\nthe degree of interwoveness, changing the scaling properties from\nlarge-world-kind (small genus) to small- and ultra-small-world-kind (large\ngenus). Two elementary moves allow the exploration of all networks embeddable\non a given surface and naturally introduce a tool to develop a statistical\nmechanics description. Within such a framework, we study the properties of\ntopologically-embedded graphs at high and low `temperatures' observing the\nformation of increasingly regular structures by cooling the system. We show\nthat the cooling dynamics is strongly affected by the surface genus with the\nmanifestation of a glassy-like freezing transitions occurring when the amount\nof topological disorder is low.\n"
    },
    {
        "paper_id": 1107.3942,
        "authors": "Michele Tumminello, Fabrizio Lillo, Jyrki Piilo, Rosario N. Mantegna",
        "title": "Identification of clusters of investors from their real trading activity\n  in a financial market",
        "comments": "25 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/14/1/013041",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use statistically validated networks, a recently introduced method to\nvalidate links in a bipartite system, to identify clusters of investors trading\nin a financial market. Specifically, we investigate a special database allowing\nto track the trading activity of individual investors of the stock Nokia. We\nfind that many statistically detected clusters of investors show a very high\ndegree of synchronization in the time when they decide to trade and in the\ntrading action taken. We investigate the composition of these clusters and we\nfind that several of them show an over-expression of specific categories of\ninvestors.\n"
    },
    {
        "paper_id": 1107.4146,
        "authors": "Leonidas Sandoval Junior",
        "title": "A Map of the Brazilian Stock Market",
        "comments": null,
        "journal-ref": "Advances in Complex Systems 2, Vol. 15, No. 4 (2012) 1250042",
        "doi": "10.1142/S0219525912500427",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use the correlation matrix of stocks returns in order to create maps of\nthe S\\~ao Paulo Stock Exchange (BM&F-Bovespa), Brazil's main stock exchange.\nThe data reffer to the year 2010, and the correlations between stock returns\nlead to the construction of a minimum spanning tree and of asset graphs with a\nvariety of threshold values. The results are analised using techniques of\nnetwork theory.\n"
    },
    {
        "paper_id": 1107.421,
        "authors": "Paul Gassiat, Fausto Gozzi, Huy\\^en Pham",
        "title": "Investment/consumption problem in illiquid markets with regime-switching",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an illiquid financial market with different regimes modeled by a\ncontinuous-time finite-state Markov chain. The investor can trade a stock only\nat the discrete arrival times of a Cox process with intensity depending on the\nmarket regime. Moreover, the risky asset price is subject to liquidity shocks,\nwhich change its rate of return and volatility, and induce jumps on its\ndynamics. In this setting, we study the problem of an economic agent optimizing\nher expected utility from consumption under a non-bankruptcy constraint. By\nusing the dynamic programming method, we provide the characterization of the\nvalue function of this stochastic control problem in terms of the unique\nviscosity solution to a system of integro-partial differential equations. We\nnext focus on the popular case of CRRA utility functions, for which we can\nprove smoothness $C^2$ results for the value function. As an important\nbyproduct, this allows us to get the existence of optimal\ninvestment/consumption strategies characterized in feedback forms. We analyze a\nconvergent numerical scheme for the resolution to our stochastic control\nproblem, and we illustrate finally with some numerical experiments the effects\nof liquidity regimes in the investor's optimal decision.\n"
    },
    {
        "paper_id": 1107.4476,
        "authors": "Gabriele La Spada, Fabrizio Lillo",
        "title": "The effect of round-off error on long memory processes",
        "comments": "44 pages, 4 figures, 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study how the round-off (or discretization) error changes the statistical\nproperties of a Gaussian long memory process. We show that the autocovariance\nand the spectral density of the discretized process are asymptotically rescaled\nby a factor smaller than one, and we compute exactly this scaling factor.\nConsequently, we find that the discretized process is also long memory with the\nsame Hurst exponent as the original process. We consider the properties of two\nestimators of the Hurst exponent, namely the local Whittle (LW) estimator and\nthe Detrended Fluctuation Analysis (DFA). By using analytical considerations\nand numerical simulations we show that, in presence of round-off error, both\nestimators are severely negatively biased in finite samples. Under regularity\nconditions we prove that the LW estimator applied to discretized processes is\nconsistent and asymptotically normal. Moreover, we compute the asymptotic\nproperties of the DFA for a generic (i.e. non Gaussian) long memory process and\nwe apply the result to discretized processes.\n"
    },
    {
        "paper_id": 1107.4632,
        "authors": "Ronnie Sircar and Stephan Sturm",
        "title": "From Smile Asymptotics to Market Risk Measures",
        "comments": "24 pages, 4 figures",
        "journal-ref": "Math. Finance 25:2, 400-425 (2015)",
        "doi": "10.1111/mafi.12015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The left tail of the implied volatility skew, coming from quotes on\nout-of-the-money put options, can be thought to reflect the market's assessment\nof the risk of a huge drop in stock prices. We analyze how this market\ninformation can be integrated into the theoretical framework of convex monetary\nmeasures of risk. In particular, we make use of indifference pricing by dynamic\nconvex risk measures, which are given as solutions of backward stochastic\ndifferential equations (BSDEs), to establish a link between these two\napproaches to risk measurement. We derive a characterization of the implied\nvolatility in terms of the solution of a nonlinear PDE and provide a small\ntime-to-maturity expansion and numerical solutions. This procedure allows to\nchoose convex risk measures in a conveniently parametrized class, distorted\nentropic dynamic risk measures, which we introduce here, such that the\nasymptotic volatility skew under indifference pricing can be matched with the\nmarket skew. We demonstrate this in a calibration exercise to market implied\nvolatility data.\n"
    },
    {
        "paper_id": 1107.4881,
        "authors": "Martin Forde, Antoine Jacquier and Aleksandar Mijatovic",
        "title": "A note on essential smoothness in the Heston model",
        "comments": "5 pages; a version of this note is to appear in Finance & Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This note studies an issue relating to essential smoothness that can arise\nwhen the theory of large deviations is applied to a certain option pricing\nformula in the Heston model. The note identifies a gap, based on this issue, in\nthe proof of Corollary 2.4 in \\cite{FordeJacquier10} and describes how to\ncircumvent it. This completes the proof of Corollary 2.4 in\n\\cite{FordeJacquier10} and hence of the main result in \\cite{FordeJacquier10},\nwhich describes the limiting behaviour of the implied volatility smile in the\nHeston model far from maturity.\n"
    },
    {
        "paper_id": 1107.5122,
        "authors": "Jaehyung Choi",
        "title": "Spontaneous symmetry breaking of arbitrage",
        "comments": "23 pages, 6 figures; Published version",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications 391 (2012),\n  pp. 3206-3218",
        "doi": "10.1016/j.physa.2012.01.031",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce the concept of spontaneous symmetry breaking to arbitrage\nmodeling. In the model, the arbitrage strategy is considered as being in the\nsymmetry breaking phase and the phase transition between arbitrage mode and\nno-arbitrage mode is triggered by a control parameter. We estimate the control\nparameter for momentum strategy with real historical data. The momentum\nstrategy aided by symmetry breaking shows stronger performance and has a better\nrisk measure than the naive momentum strategy in U.S. and South Korean markets.\n"
    },
    {
        "paper_id": 1107.5373,
        "authors": "Shu-Heng Chen and Sai-Ping Li",
        "title": "Econophysics: Bridges over a Turbulent Current",
        "comments": "50 pages, to be published in a forthcoming special issue of\n  International Review of Financial Analysis",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this editorial guide for the special issue on econophysics, we give a\nunique review of this young but quickly growing discipline. A suggestive\ntaxonomy of the development is proposed by making a distinction between\nclassical econophysics and modern econophysics. For each of these two stages of\ndevelopment, we identify the key economic issues whose formulations and/or\ntreatments have been affected by physics or physicists, which includes value,\nbusiness fluctuations, economic growth, economic and financial time series, the\ndistribution of economic entities, interactions of economic agents, and\neconomic and social networks. The recent advancements in these issues of modern\neconophysics are demonstrated by nine articles selected from the papers\npresented at the Econophysics Colloquium 2010 held at Academia Sinica in\nTaipei.\n"
    },
    {
        "paper_id": 1107.542,
        "authors": "Oleksandr Piskun, Sergii Piskun",
        "title": "Recurrence Quantification Analysis of Financial Market Crashes and\n  Crises",
        "comments": "19 pages, 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets are systems with the complex behavior, that can be hardly\nanalyzed by means of linear methods. Recurrence Quantification Analysis (RQA)\nis a nonlinear methodology, which is able to work with the nonstationary and\nshort data series. Thus, we apply RQA for the studying of the critical events\non financial markets. For the present research, stock crashes of DJI 1929; DJI,\nNYSE and S&P500 1987; NASDAQ 2000; HSI 1994, 1997 and Spanish 1992, Portuguese\n1992, British 1992, German 1992, Italian 1992, Mexican 1994, Brazilian 1999,\nIndonesian 1997, Thai 1997, Malaysian 1997, Philippine 1997, Russian 1998,\nTurkish 2001, Argentine 2002 currency devaluations were taken. The recent world\nfinancial crisis of 2007-2010 was considered as well. The possibility of LAM\nmeasure to serve as a tool for the revealing, monitoring, analysing and\nprecursoring of financial bubbles, crises and crashes was asserted.\n"
    },
    {
        "paper_id": 1107.572,
        "authors": "Andreas L\\\"ohne, Birgit Rudloff",
        "title": "An algorithm for calculating the set of superhedging portfolios in\n  markets with transaction costs",
        "comments": "28 pages, 3 figures",
        "journal-ref": "International Journal of Theoretical and Applied Finance 17 (2)\n  1450012 (33 pages), (2014)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the explicit calculation of the set of superhedging portfolios of\ncontingent claims in a discrete-time market model for d assets with\nproportional transaction costs. The set of superhedging portfolios can be\nobtained by a recursive construction involving set operations, going backward\nin the event tree. We reformulate the problem as a sequence of linear vector\noptimization problems and solve it by adapting known algorithms. The\ncorresponding superhedging strategy can be obtained going forward in the tree.\nExamples are given involving multiple correlated assets and basket options.\nFurthermore, we relate existing algorithms for the calculation of the scalar\nsuperhedging price to the set-valued algorithm by a recent duality theory for\nvector optimization problems. The main contribution of the paper is to\nestablish the connection to linear vector optimization, which allows to solve\nnumerically multi-asset superhedging problems under transaction costs.\n"
    },
    {
        "paper_id": 1107.5728,
        "authors": "Stefania Vitali, James B. Glattfelder and Stefano Battiston",
        "title": "The network of global corporate control",
        "comments": "Main Text (10 pages, 3 figures and 1 table) and Supporting\n  Information (26 pages, 7 figures and 4 tables), 2nd version (with minor\n  comments, typos removed, detailed acknowledgement, better referencing of\n  Supporting Information)",
        "journal-ref": "PLoS ONE 6(10), e25995 (2011)",
        "doi": "10.1371/journal.pone.0025995",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The structure of the control network of transnational corporations affects\nglobal market competition and financial stability. So far, only small national\nsamples were studied and there was no appropriate methodology to assess control\nglobally. We present the first investigation of the architecture of the\ninternational ownership network, along with the computation of the control held\nby each global player. We find that transnational corporations form a giant\nbow-tie structure and that a large portion of control flows to a small\ntightly-knit core of financial institutions. This core can be seen as an\neconomic \"super-entity\" that raises new important issues both for researchers\nand policy makers.\n"
    },
    {
        "paper_id": 1107.5852,
        "authors": "Oleksii Mostovyi",
        "title": "Necessary and sufficient conditions in the problem of optimal investment\n  with intermediate consumption",
        "comments": "In this version the no-arbitrage assumption is changed from M\\neq\n  \\emptyset, where M denotes the set of locally equivalent martingale measures,\n  to Z\\neq \\emptyset, where Z denotes the set of equivalent martingale\n  deflators",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a problem of optimal investment with intermediate consumption in\nthe framework of an incomplete semimartingale model of a financial market. We\nshow that a necessary and sufficient condition for the validity of key\nassertions of the theory is that the value functions of the primal and dual\nproblems are finite\n"
    },
    {
        "paper_id": 1108.0077,
        "authors": "Wanfeng Yan, Reda Rebib, Ryan Woodard, Didier Sornette",
        "title": "Detection of Crashes and Rebounds in Major Equity Markets",
        "comments": "37 pages, 18 figures, 6 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets are well known for their dramatic dynamics and consequences\nthat affect much of the world's population. Consequently, much research has\naimed at understanding, identifying and forecasting crashes and rebounds in\nfinancial markets. The Johansen-Ledoit-Sornette (JLS) model provides an\noperational framework to understand and diagnose financial bubbles from\nrational expectations and was recently extended to negative bubbles and\nrebounds. Using the JLS model, we develop an alarm index based on an advanced\npattern recognition method with the aim of detecting bubbles and performing\nforecasts of market crashes and rebounds. Testing our methodology on 10 major\nglobal equity markets, we show quantitatively that our developed alarm performs\nmuch better than chance in forecasting market crashes and rebounds. We use the\nderived signal to develop elementary trading strategies that produce\nstatistically better performances than a simple buy and hold strategy.\n"
    },
    {
        "paper_id": 1108.0099,
        "authors": "Vladimir Filimonov, Didier Sornette",
        "title": "A Stable and Robust Calibration Scheme of the Log-Periodic Power Law\n  Model",
        "comments": null,
        "journal-ref": "Filimonov, V., Sornette, D. (2013). A Stable and Robust\n  Calibration Scheme of the Log-Periodic Power Law Model. Physica A, 392(17),\n  3698-3707",
        "doi": "10.1016/j.physa.2013.04.012",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a simple transformation of the formulation of the log-periodic\npower law formula of the Johansen-Ledoit-Sornette model of financial bubbles\nthat reduces it to a function of only three nonlinear parameters. The\ntransformation significantly decreases the complexity of the fitting procedure\nand improves its stability tremendously because the modified cost function is\nnow characterized by good smooth properties with in general a single minimum in\nthe case where the model is appropriate to the empirical data. We complement\nthe approach with an additional subordination procedure that slaves two of the\nnonlinear parameters to what can be considered to be the most crucial nonlinear\nparameter, the critical time $t_c$ defined as the end of the bubble and the\nmost probably time for a crash to occur. This further decreases the complexity\nof the search and provides an intuitive representation of the results of the\ncalibration. With our proposed methodology, metaheuristic searches are not\nlonger necessary and one can resort solely to rigorous controlled local search\nalgorithms, leading to dramatic increase in efficiency. Empirical tests on the\nShanghai Composite index (SSE) from January 2007 to March 2008 illustrate our\nfindings.\n"
    },
    {
        "paper_id": 1108.0188,
        "authors": "Eric Kemp-Benedict",
        "title": "Second-Order, Dissipative T\\^atonnement: Economic Interpretation and\n  2-Point Limit Cycles",
        "comments": "11 pages, 1 figure: First revision included a simple motivating model\n  that gives rise to a second-order dynamic, and fixed some minor typographical\n  errors; second revision includes a citation to Ostrom et al. paper that\n  reports experimental observations consistent with the motivating model",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes an alternative to the classical price-adjustment\nmechanism (called \"t\\^{a}tonnement\" after Walras) that is second-order in time.\nThe proposed mechanism, an analogue to the damped harmonic oscillator, provides\na dynamic equilibration process that depends only on local information. We show\nhow such a process can result from simple behavioural rules. The discrete-time\nform of the model can result in two-step limit cycles, but as the distance\ncovered by the cycle depends on the size of the damping, the proposed mechanism\ncan lead to both highly unstable and relatively stable behaviour, as observed\nin real economies.\n"
    },
    {
        "paper_id": 1108.0386,
        "authors": "Cristian F. Moukarzel",
        "title": "Multiplicative Asset Exchange with Arbitrary Return Distributions",
        "comments": "14 pages. Accepted for publication in JSTAT",
        "journal-ref": null,
        "doi": "10.1088/1742-5468/2011/08/P08023",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The conservative wealth-exchange process derived from trade interactions is\nmodeled as a multiplicative stochastic transference of value, where each\ninteraction multiplies the wealth of the poorest of the two intervening agents\nby a random gain eta=(1+kappa), with kappa a random return. Analyzing the\nkinetic equation for the wealth distribution P(w,t), general properties are\nderived for arbitrary return distributions pi(kappa). If the geometrical\naverage of the gain is larger than one, i.e. if <ln eta> >0, in the long time\nlimit a nontrivial equilibrium wealth distribution P(w) is attained. Whenever\n<ln eta> <0, on the other hand, Wealth Condensation occurs, meaning that a\nsingle agent gets the whole wealth in the long run. This concentration\nphenomenon happens even if the average return <kappa> of the poor agent is\npositive. In the stable phase, P(w) behaves as w^{(T-1)} for w -> 0, and we\nfind T exactly. This exponent is nonzero in the stable phase but goes to zero\non approach to the condensation interface. The exact wealth distribution can be\nobtained analytically for the particular case of Kelly betting, and it turns\nout to be exponential. We show, however, that our model is never reversible, no\nmatter what pi(kappa) is. In the condensing phase, the wealth of an agent with\nrelative rank x is found to be w(x,t) \\sim e^{x t <ln eta>} for finite times t.\nThe wealth distribution is consequently P(w) \\sim 1/w for finite times, while\nall wealth ends up in the hands of a single agent for large times. Numerical\nsimulations are carried out, and found to satisfactorily compare with the above\nmentioned analytic results.\n"
    },
    {
        "paper_id": 1108.0719,
        "authors": "Nikolai Dokuchaev",
        "title": "On martingale measures and pricing for continuous bond-stock market with\n  stochastic bond",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This papers addresses the stock option pricing problem in a continuous time\nmarket model where there are two stochastic tradable assets, and one of them is\nselected as a num\\'eraire. It is shown that the presence of arbitrarily small\nstochastic deviations in the evolution of the num\\'eraire process causes\nsignificant changes in the market properties. In particular, an equivalent\nmartingale measure is not unique for this market, and there are non-replicable\nclaims. The martingale prices and the hedging error can vary significantly and\ntake extreme values, for some extreme choices of the equivalent martingale\nmeasures. Some rational choices of the equivalent martingale measures are\nsuggested and discussed, including implied measures calculated from observed\nbond prices. This allows to calculate the implied market price of risk process.\n"
    },
    {
        "paper_id": 1108.0799,
        "authors": "Vladimir Vovk",
        "title": "Ito calculus without probability in idealized financial markets",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider idealized financial markets in which price paths of the traded\nsecurities are cadlag functions, imposing mild restrictions on the allowed size\nof jumps. We prove the existence of quadratic variation for typical price\npaths, where the qualification \"typical\" means that there is a trading strategy\nthat risks only one monetary unit and brings infinite capital if quadratic\nvariation does not exist. This result allows one to apply numerous known\nresults in pathwise Ito calculus to typical price paths; we give a brief\noverview of such results.\n"
    },
    {
        "paper_id": 1108.0837,
        "authors": "Philip Z. Maymin and Zakhar G. Maymin",
        "title": "Constructing the Best Trading Strategy: A New General Framework",
        "comments": "33 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new general framework for constructing the best trading\nstrategy for a given historical indicator. We construct the unique trading\nstrategy with the highest expected return. This optimal strategy may be\nimplemented directly, or its expected return may be used as a benchmark to\nevaluate how far away from the optimal other proposed strategies for the given\nindicators are. Separately, we also construct the unique trading strategy with\nthe highest information ratio. In the normal case, when the traded security\nreturn is near zero, and for reasonable correlations, the performance\ndifferences are economically insignificant. However, when the correlation\napproaches one, the trading strategy with the highest expected return\napproaches its maximum information ratio of 1.32 while the trading strategy\nwith the highest information ratio goes to infinity.\n"
    },
    {
        "paper_id": 1108.0945,
        "authors": "Constantinos Kardaras",
        "title": "On the closure in the Emery topology of semimartingale wealth-process\n  sets",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP872 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2013, Vol. 23, No. 4, 1355-1376",
        "doi": "10.1214/12-AAP872",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A wealth-process set is abstractly defined to consist of nonnegative\nc\\`{a}dl\\`{a}g processes containing a strictly positive semimartingale and\nsatisfying an intuitive re-balancing property. Under the condition of absence\nof arbitrage of the first kind, it is established that all wealth processes are\nsemimartingales and that the closure of the wealth-process set in the Emery\ntopology contains all \"optimal\" wealth processes.\n"
    },
    {
        "paper_id": 1108.0996,
        "authors": "Tze Leung Lai, Haipeng Xing, Zehao Chen",
        "title": "Mean--variance portfolio optimization when means and covariances are\n  unknown",
        "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS422 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2A, 798-823",
        "doi": "10.1214/10-AOAS422",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Markowitz's celebrated mean--variance portfolio optimization theory assumes\nthat the means and covariances of the underlying asset returns are known. In\npractice, they are unknown and have to be estimated from historical data.\nPlugging the estimates into the efficient frontier that assumes known\nparameters has led to portfolios that may perform poorly and have\ncounter-intuitive asset allocation weights; this has been referred to as the\n\"Markowitz optimization enigma.\" After reviewing different approaches in the\nliterature to address these difficulties, we explain the root cause of the\nenigma and propose a new approach to resolve it. Not only is the new approach\nshown to provide substantial improvements over previous methods, but it also\nallows flexible modeling to incorporate dynamic features and fundamental\nanalysis of the training sample of historical data, as illustrated in\nsimulation and empirical studies.\n"
    },
    {
        "paper_id": 1108.1035,
        "authors": "Naoyuki Ishimura and Daniel Sevcovic",
        "title": "On traveling wave solutions to Hamilton-Jacobi-Bellman equation with\n  inequality constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to construct and analyze solutions to a class of\nHamilton-Jacobi-Bellman equations with range bounds on the optimal response\nvariable. Using the Riccati transformation we derive and analyze a fully\nnonlinear parabolic partial differential equation for the optimal response\nfunction. We construct monotone traveling wave solutions and identify\nparametric regions for which the traveling wave solution has a positive or\nnegative wave speed.\n"
    },
    {
        "paper_id": 1108.1133,
        "authors": "Agostino Capponi and Martin Larsson",
        "title": "Default and Systemic Risk in Equilibrium",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a finite horizon continuous time market model, where risk averse\ninvestors maximize utility from terminal wealth by dynamically investing in a\nrisk-free money market account, a stock written on a default-free dividend\nprocess, and a defaultable bond, whose prices are determined via equilibrium.\nWe analyze financial contagion arising endogenously between the stock and the\ndefaultable bond via the interplay between equilibrium behavior of investors,\nrisk preferences and cyclicality properties of the default intensity. We find\nthat the equilibrium price of the stock experiences a jump at default, despite\nthat the default event has no causal impact on the dividend process. We\ncharacterize the direction of the jump in terms of a relation between investor\npreferences and the cyclicality properties of the default intensity. We conduct\nsimilar analysis for the market price of risk and for the investor wealth\nprocess, and determine how heterogeneity of preferences affects the exposure to\ndefault carried by different investors.\n"
    },
    {
        "paper_id": 1108.1167,
        "authors": "Stefan Gerhold, Paolo Guasoni, Johannes Muhle-Karbe, Walter\n  Schachermayer",
        "title": "Transaction Costs, Trading Volume, and the Liquidity Premium",
        "comments": "29 pages, 5 figures, to appear in \"Finance and Stochastics\". arXiv\n  admin note: text overlap with arXiv:1207.7330",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a market with one safe and one risky asset, an investor with a long\nhorizon, constant investment opportunities, and constant relative risk aversion\ntrades with small proportional transaction costs. We derive explicit formulas\nfor the optimal investment policy, its implied welfare, liquidity premium, and\ntrading volume. At the first order, the liquidity premium equals the spread,\ntimes share turnover, times a universal constant. Results are robust to\nconsumption and finite horizons. We exploit the equivalence of the transaction\ncost market to another frictionless market, with a shadow risky asset, in which\ninvestment opportunities are stochastic. The shadow price is also found\nexplicitly.\n"
    },
    {
        "paper_id": 1108.1216,
        "authors": "Antonis Papapantoleon",
        "title": "Computation of copulas by Fourier methods",
        "comments": "7 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide an integral representation for the (implied) copulas of dependent\nrandom variables in terms of their moment generating functions. The proof uses\nideas from Fourier methods for option pricing. This representation can be used\nfor a large class of models from mathematical finance, including L\\'evy and\naffine processes. As an application, we compute the implied copula of the NIG\nL\\'evy process which exhibits notable time-dependence.\n"
    },
    {
        "paper_id": 1108.1273,
        "authors": "Takuji Arai and Masaaki Fukasawa",
        "title": "Convex risk measures for good deal bounds",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study convex risk measures describing the upper and lower bounds of a good\ndeal bound, which is a subinterval of a no-arbitrage pricing bound. We call\nsuch a convex risk measure a good deal valuation and give a set of equivalent\nconditions for its existence in terms of market. A good deal valuation is\ncharacterized by several equivalent properties and in particular, we see that a\nconvex risk measure is a good deal valuation only if it is given as a risk\nindifference price. An application to shortfall risk measure is given. In\naddition, we show that the no-free-lunch (NFL) condition is equivalent to the\nexistence of a relevant convex risk measure which is a good deal valuation. The\nrelevance turns out to be a condition for a good deal valuation to be\nreasonable. Further we investigate conditions under which any good deal\nvaluation is relevant.\n"
    },
    {
        "paper_id": 1108.1632,
        "authors": "Bence Toth, Imon Palit, Fabrizio Lillo, J. Doyne Farmer",
        "title": "Why is order flow so persistent?",
        "comments": "42 pages, 15 figures",
        "journal-ref": "Journal of Economic Dynamics and Control 51, 218-239 (2015)",
        "doi": "10.1016/j.jedc.2014.10.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Order flow in equity markets is remarkably persistent in the sense that order\nsigns (to buy or sell) are positively autocorrelated out to time lags of tens\nof thousands of orders, corresponding to many days. Two possible explanations\nare herding, corresponding to positive correlation in the behavior of different\ninvestors, or order splitting, corresponding to positive autocorrelation in the\nbehavior of single investors. We investigate this using order flow data from\nthe London Stock Exchange for which we have membership identifiers. By\nformulating models for herding and order splitting, as well as models for\nbrokerage choice, we are able to overcome the distortion introduced by\nbrokerage. On timescales of less than a few hours the persistence of order flow\nis overwhelmingly due to splitting rather than herding. We also study the\nproperties of brokerage order flow and show that it is remarkably consistent\nboth cross-sectionally and longitudinally.\n"
    },
    {
        "paper_id": 1108.1688,
        "authors": "Eusebio Valero, Manuel Torrealba, Lucas Lacasa and Fran\\c{c}ois\n  Fraysse",
        "title": "Fast resolution of a single factor Heath-Jarrow-Morton model with\n  stochastic volatility",
        "comments": "submitted for publication",
        "journal-ref": "Journal of Computational and Applied Mathematics 236, 6, Pages\n  1637-1655 (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the single factor Heath-Jarrow-Morton model for the\ninterest rate curve with stochastic volatility. Its natural formulation,\ndescribed in terms of stochastic differential equations, is solved through\nMonte Carlo simulations, that usually involve rather large computation time,\ninefficient from a practical (financial) perspective. This model turns to be\nMarkovian in three dimensions and therefore it can be mapped into a 3D partial\ndifferential equations problem. We propose an optimized numerical method to\nsolve the 3D PDE model in both low computation time and reasonable accuracy, a\nfundamental criterion for practical purposes. The spatial and temporal\ndiscretization are performed using finite-difference and Crank-Nicholson\nschemes respectively, and the computational efficiency is largely increased\nperforming a scale analysis and using Alternating Direction Implicit schemes.\nSeveral numerical considerations such as convergence criteria or computation\ntime are analyzed and discussed.\n"
    },
    {
        "paper_id": 1108.191,
        "authors": "Alet Roux and Tomasz Zastawniak",
        "title": "American and Bermudan options in currency markets under proportional\n  transaction costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The pricing and hedging of a general class of options (including American,\nBermudan and European options) on multiple assets are studied in the context of\ncurrency markets where trading is subject to proportional transaction costs,\nand where the existence of a risk-free num\\'eraire is not assumed.\nConstructions leading to algorithms for computing the prices, optimal hedging\nstrategies and stopping times are presented for both long and short option\npositions in this setting, together with probabilistic (martingale)\nrepresentations for the option prices.\n"
    },
    {
        "paper_id": 1108.1951,
        "authors": "Dariusz Grech, Grzegorz Pamula",
        "title": "How much multifractality is included in monofractal signals?",
        "comments": "21 pages, 14 figures, 2 tables, extended and corrected list of\n  references",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the presence of residual multifractal background for\nmonofractal signals which appears due to the finite length of the signals and\n(or) due to the long memory the signals reveal. This phenomenon is investigated\nnumerically within the multifractal detrended fluctuation analysis (MF-DFA) for\nartificially generated time series. Next, the analytical formulas enabling to\ndescribe the multifractal content in such signals are provided. Final results\nare shown in the frequently used generalized Hurst exponent h(q) multifractal\nscenario and are presented as a function of time series length L and the\nautocorrelation exponent value {\\gamma}. The multifractal spectrum ({\\alpha}, f\n({\\alpha})) approach is also discussed. The obtained results may be significant\nin any practical application of multifractality, including financial data\nanalysis, because the \"true\" multifractal effect should be clearly separated\nfrom the so called \"multifractal noise\". Examples from finance in this context\nare given. The provided formulas may help to decide whether we do deal with the\nsignal of real multifractal origin or not.\n"
    },
    {
        "paper_id": 1108.2305,
        "authors": "Ji-Won Park, Chae Un Kim, and Walter Isard",
        "title": "Permit Allocation in Emissions Trading using the Boltzmann Distribution",
        "comments": "25 pages of main text, 3 figures, 3 tables",
        "journal-ref": "Physica A 2012",
        "doi": "10.1016/j.physa.2012.05.052",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In emissions trading, the initial allocation of permits is an intractable\nissue because it needs to be essentially fair to the participating countries.\nThere are many ways to distribute a given total amount of emissions permits\namong countries, but the existing distribution methods, such as auctioning and\ngrandfathering, have been debated. In this paper we describe a new method for\nallocating permits in emissions trading using the Boltzmann distribution. We\nintroduce the Boltzmann distribution to permit allocation by combining it with\nconcepts in emissions trading. We then demonstrate through empirical data\nanalysis how emissions permits can be allocated in practice among participating\ncountries. The new allocation method using the Boltzmann distribution describes\nthe most probable, natural, and unbiased distribution of emissions permits\namong multiple countries. Simple and versatile, this new method holds potential\nfor many economic and environmental applications.\n"
    },
    {
        "paper_id": 1108.2611,
        "authors": "A. Saichev and D. Sornette",
        "title": "Time-Bridge Estimators of Integrated Variance",
        "comments": "42 pages with 4 figures",
        "journal-ref": "The Journal of Investment Strategies 2 (2), 71-108 (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a set of log-price integrated variance estimators, equal to the\nsum of open-high-low-close bridge estimators of spot variances within $n$\nsubsequent time-step intervals. The main characteristics of some of the\nintroduced estimators is to take into account the information on the occurrence\ntimes of the high and low values. The use of the high's and low's of the bridge\nassociated with the original process makes the estimators significantly more\nefficient that the standard realized variance estimators and its\ngeneralizations. Adding the information on the occurrence times of the high and\nlow values improves further the efficiency of the estimators, much above those\nof the well-known realized variance estimator and those derived from the sum of\nGarman and Klass spot variance estimators. The exact analytical results are\nderived for the case where the underlying log-price process is an It\\^o\nstochastic process. Our results suggests more efficient ways to record\nfinancial prices at intermediate frequencies.\n"
    },
    {
        "paper_id": 1108.2623,
        "authors": "Dario Gasbarra, Jos\\'e Igor Morlanes, Esko Valkeila",
        "title": "Initial Enlargement in a Markov chain market model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Enlargement of filtrations is a classical topic in the general theory of\nstochastic processes. This theory has been applied to stochastic finance in\norder to analyze models with insider information. In this paper we study\ninitial enlargement in a Markov chain market model, introduced by R. Norberg.\nIn the enlargened filtration several things can happen: some of the jumps times\ncan be accessible or predictable, but in the orginal filtration all the jumps\ntimes are totally inaccessible. But even if the jumps times change to\naccessible or predictable, the insider does not necessarily have arbitrage\npossibilities.\n"
    },
    {
        "paper_id": 1108.2889,
        "authors": "Roman Muraviev",
        "title": "Additive habits with power utility: Estimates, asymptotics and\n  equilibrium",
        "comments": "Submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a power utility maximization problem with additive habits in a\nframework of discrete-time markets and random endowments. For certain classes\nof incomplete markets, we establish estimates for the optimal consumption\nstream in terms of the aggregate state price density, investigate the\nasymptotic behaviour of the propensity to consume (ratio of the consumption to\nthe wealth), as the initial endowment tends to infinity, and show that the\nlimit is the corresponding quantity in an artificial market. For complete\nmarkets, we concentrate on proving the existence of an Arrow-Debreu equilibrium\nin an economy inhabited by heterogeneous individuals who differ with respect to\ntheir risk-aversion coefficient, impatience rate and endowments stream, but\npossess the same degree of habit-formation. Finally, in a representative agent\nequilibrium, we compute explicitly the price of a zero coupon bond and the\nLucas tree equity, and study its dependence on the habit-formation parameter.\n"
    },
    {
        "paper_id": 1108.2937,
        "authors": "Laurent Schoeffel (CEA Saclay)",
        "title": "Statistical Methods for Estimating the non-random Content of Financial\n  Markets",
        "comments": "10 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For the pedestrian observer, financial markets look completely random with\nerratic and uncontrollable behavior. To a large extend, this is correct. At\nfirst approximation the difference between real price changes and the random\nwalk model is too small to be detected using traditional time series analysis.\nHowever, we show in the following that this difference between real financial\ntime series and random walks, as small as it is, is detectable using modern\nstatistical multivariate analysis, with several triggers encoded in trading\nsystems. This kind of analysis are based on methods widely used in nuclear\nphysics, with large samples of data and advanced statistical inference.\nConsidering the movements of the Euro future contract at high frequency, we\nshow that a part of the non-random content of this series can be inferred,\nnamely the trend-following content depending on volatility ranges.\n"
    },
    {
        "paper_id": 1108.3155,
        "authors": "Laurent Schoeffel (CEA Saclay)",
        "title": "About the non-random Content of Financial Markets",
        "comments": "11 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For the pedestrian observer, financial markets look completely random with\nerratic and uncontrollable behavior. To a large extend, this is correct. At\nfirst approximation the difference between real price changes and the random\nwalk model is too small to be detected using traditional time series analysis.\nHowever, we show in the following that this difference between real financial\ntime series and random walks, as small as it is, is detectable using modern\nstatistical multivariate analysis, with several triggers encoded in trading\nsystems. This kind of analysis are based on methods widely used in nuclear\nphysics, with large samples of data and advanced statistical inference.\nConsidering the movements of the Euro future contract at high frequency, we\nshow that a part of the non-random content of this series can be inferred,\nnamely the trend-following content depending on volatility ranges. Of course,\nthis is not a general proof of statistical inference, as we focus on one\nparticular example and the generality of the process can not be claimed.\nTherefore, we produce other examples on a completely different markets, largely\nuncorrelated to the Euro future, namely the DAX and Cacao future contracts. The\nsame procedure is followed using a trading system, based on the same\ningredients. We show that similar results can be obtained and we conclude that\nthis is an evidence that some invariants, as encoded in our system, have been\nidentified. They provide a kind of quantification of the non-random content of\nthe financial markets explored over a 10 years period of time.\n"
    },
    {
        "paper_id": 1108.3386,
        "authors": "Jos\\'e E. Figueroa-L\\'opez, Yankeng Luo, Cheng Ouyang",
        "title": "Small-time expansions for local jump-diffusion models with infinite jump\n  activity",
        "comments": "Published in at http://dx.doi.org/10.3150/13-BEJ518 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2014, Vol. 20, No. 3, 1165-1209",
        "doi": "10.3150/13-BEJ518",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a Markov process $X$, which is the solution of a stochastic\ndifferential equation driven by a L\\'{e}vy process $Z$ and an independent\nWiener process $W$. Under some regularity conditions, including non-degeneracy\nof the diffusive and jump components of the process as well as smoothness of\nthe L\\'{e}vy density of $Z$ outside any neighborhood of the origin, we obtain a\nsmall-time second-order polynomial expansion for the tail distribution and the\ntransition density of the process $X$. Our method of proof combines a recent\nregularizing technique for deriving the analog small-time expansions for a\nL\\'{e}vy process with some new tail and density estimates for jump-diffusion\nprocesses with small jumps based on the theory of Malliavin calculus, flow of\ndiffeomorphisms for SDEs, and time-reversibility. As an application, the\nleading term for out-of-the-money option prices in short maturity under a local\njump-diffusion model is also derived.\n"
    },
    {
        "paper_id": 1108.3552,
        "authors": "Winston Wei Dou, David Pollard, Harrison H. Zhou",
        "title": "Estimation in Functional Regression for General Exponential Families",
        "comments": "arXiv admin note: significant text overlap with arXiv:1001.3742",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies a class of exponential family models whose canonical\nparameters are specified as linear functionals of an unknown\ninfinite-dimensional slope function. The optimal minimax rates of convergence\nfor slope function estimation are established. The estimators that achieve the\noptimal rates are constructed by constrained maximum likelihood estimation with\nparameters whose dimension grows with sample size. A change-of-measure\nargument, inspired by Le Cam's theory of asymptotic equivalence, is used to\neliminate the bias caused by the non-linearity of exponential family models.\n"
    },
    {
        "paper_id": 1108.3998,
        "authors": "Antoine Jacquier, Martin Keller-Ressel and Aleksandar Mijatovic",
        "title": "Large deviations and stochastic volatility with jumps: asymptotic\n  implied volatility for affine models",
        "comments": "30 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Let $\\sigma_t(x)$ denote the implied volatility at maturity $t$ for a strike\n$K=S_0 e^{xt}$, where $x\\in\\bbR$ and $S_0$ is the current value of the\nunderlying. We show that $\\sigma_t(x)$ has a uniform (in $x$) limit as maturity\n$t$ tends to infinity, given by the formula\n$\\sigma_\\infty(x)=\\sqrt{2}(h^*(x)^{1/2}+(h^*(x)-x)^{1/2})$, for $x$ in some\ncompact neighbourhood of zero in the class of affine stochastic volatility\nmodels. The function $h^*$ is the convex dual of the limiting cumulant\ngenerating function $h$ of the scaled log-spot process. We express $h$ in terms\nof the functional characteristics of the underlying model. The proof of the\nlimiting formula rests on the large deviation behaviour of the scaled log-spot\nprocess as time tends to infinity. We apply our results to obtain the limiting\nsmile for several classes of stochastic volatility models with jumps used in\napplications (e.g. Heston with state-independent jumps, Bates with\nstate-dependent jumps and Barndorff-Nielsen-Shephard model).\n"
    },
    {
        "paper_id": 1108.4102,
        "authors": "Samuel Eleut\\'erio, Tanya Ara\\'ujo and R. Vilela Mendes",
        "title": "Portfolios and the market geometry",
        "comments": "13 pages 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A geometric analysis of the time series of returns has been performed in the\npast and it implied that the most of the systematic information of the market\nis contained in a space of small dimension. Here we have explored subspaces of\nthis space to find out the relative performance of portfolios formed from the\ncompanies that have the largest projections in each one of the subspaces. It\nwas found that the best performance portfolios are associated to some of the\nsmall eigenvalue subspaces and not to the dominant directions in the distances\nmatrix. This occurs in such a systematic fashion over an extended period\n(1990-2008) that it may not be a statistical accident.\n"
    },
    {
        "paper_id": 1108.4113,
        "authors": "A. Philip Dawid, Steven de Rooij, Peter Grunwald, Wouter M. Koolen,\n  Glenn Shafer, Alexander Shen, Nikolai Vereshchagin, and Vladimir Vovk",
        "title": "Probability-free pricing of adjusted American lookbacks",
        "comments": "28 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider an American option that pays G(X^*_t) when exercised at time t,\nwhere G is a positive increasing function, X^*_t := \\sup_{s\\le t}X_s, and X_s\nis the price of the underlying security at time s. Assuming zero interest\nrates, we show that the seller of this option can hedge his position by trading\nin the underlying security if he begins with initial capital\nX_0\\int_{X_0}^{\\infty}G(x)x^{-2}dx (and this is the smallest initial capital\nthat allows him to hedge his position). This leads to strategies for trading\nthat are always competitive both with a given strategy's current performance\nand, to a somewhat lesser degree, with its best performance so far. It also\nleads to methods of statistical testing that avoid sacrificing too much of the\nmaximum statistical significance that they achieve in the course of\naccumulating data.\n"
    },
    {
        "paper_id": 1108.4258,
        "authors": "Romain Allez, Jean-Philippe Bouchaud",
        "title": "Eigenvector dynamics: theory and some applications",
        "comments": "4 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a general framework to study the stability of the subspace spanned\nby $P$ consecutive eigenvectors of a generic symmetric matrix ${\\bf H}_0$, when\na small perturbation is added. This problem is relevant in various contexts,\nincluding quantum dissipation (${\\bf H}_0$ is then the Hamiltonian) and risk\ncontrol (in which case ${\\bf H}_0$ is the assets return correlation matrix). We\nspecialize our results for the case of a Gaussian Orthogonal ${\\bf H}_0$, or\nwhen ${\\bf H}_0$ is a correlation matrix. We illustrate the usefulness of our\nframework using financial data.\n"
    },
    {
        "paper_id": 1108.4393,
        "authors": "V.M. Belyaev",
        "title": "Pricing Variable Annuity Contracts with High-Water Mark Feature",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Variable annuities (VA) are popular insurance products. VAs provides the\ninsured with a guaranteed accumulation rate on their premium at maturity. In\naddition, the insured may receive extra benefit if returns of underlying funds\nare high enough. Here we consider a special case of VA with high-water mark\nfeature and Guaranteed Minimum payment reset. In Black-Scholes model for\nunderlying fund we derive explicit pricing formula for this type of contract.\nThe value of VA contracts depends on the time between observation dates.\nCorrections due to this effect are calculated and compared with Monte-Carlo\nresults. Good agreement between analytical formula and numerical calculations\nof VA values is demonstrated.\n"
    },
    {
        "paper_id": 1108.4886,
        "authors": "Maria B. Chiarolla, Giorgio Ferrari",
        "title": "Identifying the Free Boundary of a Stochastic, Irreversible Investment\n  Problem via the Bank-El Karoui Representation Theorem",
        "comments": "23 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a stochastic, continuous time model on a finite horizon for a firm\nthat produces a single good. We model the production capacity as an Ito\ndiffusion controlled by a nondecreasing process representing the cumulative\ninvestment. The firm aims to maximize its expected total net profit by choosing\nthe optimal investment process. That is a singular stochastic control problem.\nWe derive some first order conditions for optimality and we characterize the\noptimal solution in terms of the base capacity process, i.e. the unique\nsolution of a representation problem in the spirit of Bank and El Karoui\n(2004). We show that the base capacity is deterministic and it is identified\nwith the free boundary of the associated optimal stopping problem, when the\ncoefficients of the controlled diffusion are deterministic functions of time.\nThis is a novelty in the literature on finite horizon singular stochastic\ncontrol problems. As a subproduct this result allows us to obtain an integral\nequation for the free boundary, which we explicitly solve in the infinite\nhorizon case for a Cobb-Douglas production function and constant coefficients\nin the controlled capacity process.\n"
    },
    {
        "paper_id": 1108.5098,
        "authors": "Yuri A. Katz",
        "title": "Default risk modeling beyond the first-passage approximation:\n  Position-dependent killing",
        "comments": null,
        "journal-ref": "Physica A, 392 (2013) 1648",
        "doi": "10.1016/j.physa.2012.11.059",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Diffusion in a linear potential in the presence of position-dependent killing\nis used to mimic a default process. Different assumptions regarding transport\ncoefficients, initial conditions, and elasticity of the killing measure lead to\ndiverse models of bankruptcy. One \"stylized fact\" is fundamental for our\nconsideration: empirically default is a rather rare event, especially in the\ninvestment grade categories of credit ratings. Hence, the action of killing may\nbe considered as a small parameter. In a number of special cases we derive\nclosed-form expressions for the entire term structure of the cumulative\nprobability of default, its hazard rate and intensity. Comparison with\nhistorical data on global corporate defaults confirms applicability of the\nmodel-independent perturbation method for companies in the investment grade\ncategories of credit ratings and allows for\n"
    },
    {
        "paper_id": 1108.5264,
        "authors": "Abdelkoddousse Ahdida (CERMICS), Aur\\'elien Alfonsi (CERMICS)",
        "title": "A Mean-Reverting SDE on Correlation matrices",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a mean-reverting SDE whose solution is naturally defined on the\nspace of correlation matrices. This SDE can be seen as an extension of the\nwell-known Wright-Fisher diffusion. We provide conditions that ensure weak and\nstrong uniqueness of the SDE, and describe its ergodic limit. We also shed\nlight on a useful connection with Wishart processes that makes understand how\nwe get the full SDE. Then, we focus on the simulation of this diffusion and\npresent discretization schemes that achieve a second-order weak convergence.\nLast, we explain how these correlation processes could be used to model the\ndependence between financial assets.\n"
    },
    {
        "paper_id": 1108.556,
        "authors": "Bikramjit Das, Abhimanyu Mitra and Sidney Resnick",
        "title": "Living on the multi-dimensional edge: seeking hidden risks using regular\n  variation",
        "comments": "32 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Multivariate regular variation plays a role assessing tail risk in diverse\napplications such as finance, telecommunications, insurance and environmental\nscience. The classical theory, being based on an asymptotic model, sometimes\nleads to inaccurate and useless estimates of probabilities of joint tail\nregions. This problem can be partly ameliorated by using hidden regular\nvariation [Resnick, 2002, Mitra and Resnick, 2010]. We offer a more flexible\ndefinition of hidden regular variation that provides improved risk estimates\nfor a larger class of risk tail regions.\n"
    },
    {
        "paper_id": 1108.5596,
        "authors": "Laurent Schoeffel (CEA - Saclay)",
        "title": "Intermittency in Quantitative Finance",
        "comments": "8 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Factorial moments are convenient tools in nuclear physics to characterize the\nmultiplicity distributions when phase-space resolution ($\\Delta$) becomes\nsmall. For uncorrelated particle production within $\\Delta$, Gaussian\nstatistics holds and factorial moments $F_q$ are equal to unity for all orders\n$q$. Correlations between particles lead to a broadening of the multiplicity\ndistribution and to dynamical fluctuations. In this case, the factorial moments\nincrease above 1 with decreasing $\\Delta$. This corresponds to what can be\ncalled intermittency. In this letter, we show that a similar analysis can be\ndeveloped on financial price series, with an adequate definition of factorial\nmoments. An intermittent behavior can be extracted using moments of order 2\n($F_2$), illustrating a sensitivity to non-Gaussian fluctuations within time\nresolution below 4 hours. This confirms that correlations between price returns\nstart to play a role when the time resolution is below this threshold.\n"
    },
    {
        "paper_id": 1108.5725,
        "authors": "J.R. Iglesias and R.M.C. de Almeida",
        "title": "Entropy and equilibrium state of free market models",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1140/epjb/e2012-21036-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many recent models of trade dynamics use the simple idea of wealth exchanges\namong economic agents in order to obtain a stable or equilibrium distribution\nof wealth among the agents. In particular, a plain analogy compares the wealth\nin a society with the energy in a physical system, and the trade between agents\nto the energy exchange between molecules during collisions. In physical\nsystems, the energy exchange among molecules leads to a state of equipartition\nof the energy and to an equilibrium situation where the entropy is a maximum.\nOn the other hand, in the majority of exchange models, the system converges to\na very unequal condensed state, where one or a few agents concentrate all the\nwealth of the society while the wide majority of agents shares zero or almost\nzero fraction of the wealth. So, in those economic systems a minimum entropy\nstate is attained. We propose here an analytical model where we investigate the\neffects of a particular class of economic exchanges that minimize the entropy.\nBy solving the model we discuss the conditions that can drive the system to a\nstate of minimum entropy, as well as the mechanisms to recover a kind of\nequipartition of wealth.\n"
    },
    {
        "paper_id": 1108.594,
        "authors": "Mathieu Rosenbaum, Peter Tankov",
        "title": "Asymptotically optimal discretization of hedging strategies with jumps",
        "comments": "Published in at http://dx.doi.org/10.1214/13-AAP940 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 3, 1002-1048",
        "doi": "10.1214/13-AAP940",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we consider the hedging error due to discrete trading in models\nwith jumps. Extending an approach developed by Fukasawa [In Stochastic Analysis\nwith Financial Applications (2011) 331-346 Birkh\\\"{a}user/Springer Basel AG]\nfor continuous processes, we propose a framework enabling us to\n(asymptotically) optimize the discretization times. More precisely, a\ndiscretization rule is said to be optimal if for a given cost function, no\nstrategy has (asymptotically, for large cost) a lower mean square\ndiscretization error for a smaller cost. We focus on discretization rules based\non hitting times and give explicit expressions for the optimal rules within\nthis class.\n"
    },
    {
        "paper_id": 1108.5946,
        "authors": "Laurent Schoeffel (CEA - Saclay)",
        "title": "Factorial Moments in Complex Systems",
        "comments": "7 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Factorial moments are convenient tools in particle physics to characterize\nthe multiplicity distributions when phase-space resolution ($\\Delta$) becomes\nsmall. They include all correlations within the system of particles and\nrepresent integral characteristics of any correlation between these particles.\nIn this letter, we show a direct comparison between high energy physics and\nquantitative finance results. Both for physics and finance, we illustrate that\ncorrelations between particles lead to a broadening of the multiplicity\ndistribution and to dynamical fluctuations when the resolution becomes small\nenough. From the generating function of factorial moments, we make a prediction\non the gap probability for sequences of returns of positive or negative signs.\nThe gap is defined as the number of consecutive positive returns after a\nnegative return, thus this is a gap in negative return. Inversely for a gap in\npositive return. Then, the gap probability is shown to be exponentially\nsuppressed within the gap size. We confirm this prediction with data.\n"
    },
    {
        "paper_id": 1109.0119,
        "authors": "Alex J. Bladon, Esteban Moro, Tobias Galla",
        "title": "Individual impact of agent actions in financial markets",
        "comments": "11 pages, 7 figures, 3 tables",
        "journal-ref": "Phys. Rev. E 85, 036103 (2012)",
        "doi": "10.1103/PhysRevE.85.036103",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an analysis of the price impact associated with trades effected by\ndifferent financial firms. Using data from the Spanish Stock Market, we find a\nhigh degree of heterogeneity across different market members, both in the\ninstantaneous impact functions and in the time-dependent market response to\ntrades by individual members. This heterogeneity is statistically incompatible\nwith the existence of market-wide universal impact dynamics which apply\nuniformly to all trades and suggests that rather, market dynamics emerge from\nthe complex interaction of different behaviors of market participants. Several\npossible reasons for this are discussed, along with potential extensions one\nmay consider to increase the range of applicability of existing models of\nmarket impact.\n"
    },
    {
        "paper_id": 1109.0435,
        "authors": "Richard Pincak and Marian Repasan",
        "title": "The string prediction models as an invariants of time series in forex\n  market",
        "comments": "SORS Research a.s, 040 01 Kosice, Slovak Republic, 14 pages, 11\n  figures",
        "journal-ref": "Physica A 392 (2013) 6414-6426",
        "doi": "10.1016/j.physa.2013.07.048",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we apply a new approach of the string theory to the real\nfinancial market. It is direct extension and application of the work [1] into\nprediction of prices. The models are constructed with an idea of prediction\nmodels based on the string invariants (PMBSI). The performance of PMBSI is\ncompared to support vector machines (SVM) and artificial neural networks (ANN)\non an artificial and a financial time series. Brief overview of the results and\nanalysis is given. The first model is based on the correlation function as\ninvariant and the second one is an application based on the deviations from the\nclosed string/pattern form (PMBCS). We found the difference between these two\napproaches. The first model cannot predict the behavior of the forex market\nwith good efficiency in comparison with the second one which is, in addition,\nable to make relevant profit per year.\n"
    },
    {
        "paper_id": 1109.0465,
        "authors": "Raffaello Morales, T. Di Matteo, Ruggero Gramatica and Tomaso Aste",
        "title": "Dynamical Hurst exponent as a tool to monitor unstable periods in\n  financial time series",
        "comments": "13 pages",
        "journal-ref": "Physica A 391, 2012, 3180-3189",
        "doi": "10.1016/j.physa.2012.01.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the use of the Hurst exponent, dynamically computed over a\nmoving time-window, to evaluate the level of stability/instability of financial\nfirms. Financial firms bailed-out as a consequence of the 2007-2010 credit\ncrisis show a neat increase with time of the generalized Hurst exponent in the\nperiod preceding the unfolding of the crisis. Conversely, firms belonging to\nother market sectors, which suffered the least throughout the crisis, show\nopposite behaviors. These findings suggest the possibility of using the scaling\nbehavior as a tool to track the level of stability of a firm. In this paper, we\nintroduce a method to compute the generalized Hurst exponent which assigns\nlarger weights to more recent events with respect to older ones. In this way\nlarge fluctuations in the remote past are less likely to influence the recent\npast. We also investigate the scaling associated with the tails of the\nlog-returns distributions and compare this scaling with the scaling associated\nwith the Hurst exponent, observing that the processes underlying the price\ndynamics of these firms are truly multi-scaling.\n"
    },
    {
        "paper_id": 1109.0606,
        "authors": "Maria Letizia Bertotti and Giovanni Modanese",
        "title": "From microscopic taxation and redistribution models to macroscopic\n  income distributions",
        "comments": "12 pages, 4 figures. Version submitted to Physica A on Feb 15, 2011",
        "journal-ref": "Physica A 390 (2011) 3782-3793",
        "doi": "10.1016/j.physa.2011.06.008",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present here a general framework, expressed by a system of nonlinear\ndifferential equations, suitable for the modelling of taxation and\nredistribution in a closed (trading market) society. This framework allows to\ndescribe the evolution of the income distribution over the population and to\nexplain the emergence of collective features based on the knowledge of the\nindividual interactions. By making different choices of the framework\nparameters, we construct different models, whose long-time behavior is then\ninvestigated. Asymptotic stationary distributions are found, which enjoy\nsimilar properties as those observed in empirical distributions. In particular,\nthey exhibit power law tails of Pareto type and their Lorenz curves and Gini\nindices are consistent with some real world ones.\n"
    },
    {
        "paper_id": 1109.0642,
        "authors": "Leonidas Sandoval Junior",
        "title": "Pruning a Minimum Spanning Tree",
        "comments": null,
        "journal-ref": "Physica A 391 (2012) 2678-2711",
        "doi": "10.1016/j.physa.2011.12.052",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work employs some techniques in order to filter random noise from the\ninformation provided by minimum spanning trees obtained from the correlation\nmatrices of international stock market indices prior to and during times of\ncrisis. The first technique establishes a threshold above which connections are\nconsidered affected by noise, based on the study of random networks with the\nsame probability density distribution of the original data. The second\ntechnique is to judge the strengh of a connection by its survival rate, which\nis the amount of time a connection between two stock market indices endure. The\nidea is that true connections will survive for longer periods of time, and that\nrandom connections will not. That information is then combined with the\ninformation obtained from the first technique in order to create a smaller\nnetwork, where most of the connections are either strong or enduring in time.\n"
    },
    {
        "paper_id": 1109.0706,
        "authors": "Vladimir Vovk",
        "title": "Losing money with a high Sharpe ratio",
        "comments": "6 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A simple example shows that losing all money is compatible with a very high\nSharpe ratio (as computed after losing all money). However, the only way that\nthe Sharpe ratio can be high while losing money is that there is a period in\nwhich all or almost all money is lost. This note explores the best achievable\nSharpe and Sortino ratios for investors who lose money but whose one-period\nreturns are bounded below (or both below and above) by a known constant.\n"
    },
    {
        "paper_id": 1109.0738,
        "authors": "Matthew Lorig",
        "title": "Pricing Derivatives on Multiscale Diffusions: an Eigenfunction Expansion\n  Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using tools from spectral analysis, singular and regular perturbation theory,\nwe develop a systematic method for analytically computing the approximate price\nof a derivative-asset. The payoff of the derivative-asset may be\npath-dependent. Additionally, the process underlying the derivative may exhibit\nkilling (i.e. jump to default) as well as combined local/nonlocal stochastic\nvolatility. The nonlocal component of volatility is multiscale, in the sense\nthat it is driven by one fast-varying and one slow-varying factor. The\nflexibility of our modeling framework is contrasted by the simplicity of our\nmethod. We reduce the derivative pricing problem to that of solving a single\neigenvalue equation. Once the eigenvalue equation is solved, the approximate\nprice of a derivative can be calculated formulaically. To illustrate our\nmethod, we calculate the approximate price of three derivative-assets: a\nvanilla option on a defaultable stock, a path-dependent option on a\nnon-defaultable stock, and a bond in a short-rate model.\n"
    },
    {
        "paper_id": 1109.0828,
        "authors": "Joachim Kaldasch",
        "title": "The Product Life Cycle of Durable Goods",
        "comments": null,
        "journal-ref": "British Journal of Economics, Management & Trade 10(2): 1-17,\n  2015, Article no.BJEMT.20395",
        "doi": "10.9734/BJEMT/2015/20395",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A dynamic model of the product lifecycle of (nearly) homogeneous durables in\npolypoly markets is established. It describes the concurrent evolution of the\nunit sales and price of durable goods. The theory is based on the idea that the\nsales dynamics is determined by a meeting process of demanded with supplied\nproduct units. Taking advantage from the Bass model for first purchase and a\nlogistic model for repurchase the entire product lifecycle of a durable can be\nestablished. For the case of a fast growing supply the model suggests that the\nmean price of the good decreases according to a logistic law. Both, the\nestablished unit sales and price evolution are in agreement with the empirical\ndata studied in this paper. The presented approach discusses further the\ninterference of the diffusion process with the supply dynamics. The model\npredicts the occurrence of lost sales in the initial stages of the lifecycle\ndue to supply constraints. They are the origin for a retarded market\npenetration. The theory suggests that the imitation rate B indicating social\ncontagion in the Bass model has its maximum magnitude for the case of a large\namount of available units at introduction and a fast output increase. The\nempirical data of the investigated samples are in qualitative agreement with\nthis prediction.\n"
    },
    {
        "paper_id": 1109.0891,
        "authors": "Stefano Viaggiu, Andrea Lionetto, Leonardo Bargigli, Michele Longo",
        "title": "Statistical ensembles for money and debt",
        "comments": "Final version published on Physica A: Statistical Mechanics and its\n  Applications",
        "journal-ref": "Physica A 391/21 (2012), pp. 4839-4849",
        "doi": "10.1016/j.physa.2012.05.027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We build a statistical ensemble representation of two economic models\ndescribing respectively, in simplified terms, a payment system and a credit\nmarket. To this purpose we adopt the Boltzmann-Gibbs distribution where the\nrole of the Hamiltonian is taken by the total money supply (i.e. including\nmoney created from debt) of a set of interacting economic agents. As a result,\nwe can read the main thermodynamic quantities in terms of monetary ones. In\nparticular, we define for the credit market model a work term which is related\nto the impact of monetary policy on credit creation. Furthermore, with our\nformalism we recover and extend some results concerning the temperature of an\neconomic system, previously presented in the literature by considering only the\nmonetary base as conserved quantity. Finally, we study the statistical ensemble\nfor the Pareto distribution.\n"
    },
    {
        "paper_id": 1109.0897,
        "authors": "Budhi Arta Surya and Kazutoshi Yamazaki",
        "title": "Optimal Capital Structure with Scale Effects under Spectrally Negative\n  Levy Models",
        "comments": "26 pages",
        "journal-ref": "Int. J. Theor. Appl. Finan., Volume 17, Issue 02, March 2014",
        "doi": "10.1142/S0219024914500137",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The optimal capital structure model with endogenous bankruptcy was first\nstudied by Leland (1994) and Leland and Toft (1996), and was later extended to\nthe spectrally negative Levy model by Hilberink and Rogers (2002) and Kyprianou\nand Surya (2007). This paper incorporates the scale effects by allowing the\nvalues of bankruptcy costs and tax benefits to be dependent on the firm's asset\nvalue. By using the fluctuation identities for the spectrally negative Levy\nprocess, we obtain a candidate bankruptcy level as well as a sufficient\ncondition for optimality. The optimality holds in particular when,\nmonotonically in the asset value, the value of tax benefits is increasing, the\nloss amount at bankruptcy is increasing, and its proportion relative to the\nasset value is decreasing. The solution admits a semi-explicit form in terms of\nthe scale function. A series of numerical studies are given to analyze the\nimpacts of scale effects on the default strategy and the optimal capital\nstructure.\n"
    },
    {
        "paper_id": 1109.1075,
        "authors": "Panagiota Daskalopoulos and Paul M. N. Feehan",
        "title": "Existence, uniqueness, and global regularity for degenerate elliptic\n  obstacle problems in mathematical finance",
        "comments": "115 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Heston stochastic volatility process, which is widely used as an asset\nprice model in mathematical finance, is a paradigm for a degenerate diffusion\nprocess where the degeneracy in the diffusion coefficient is proportional to\nthe square root of the distance to the boundary of the half-plane. The\ngenerator of this process with killing, called the elliptic Heston operator, is\na second-order degenerate elliptic partial differential operator whose\ncoefficients have linear growth in the spatial variables and where the\ndegeneracy in the operator symbol is proportional to the distance to the\nboundary of the half-plane. With the aid of weighted Sobolev spaces, we prove\nexistence, uniqueness, and global regularity of solutions to stationary\nvariational inequalities and obstacle problems for the elliptic Heston operator\non unbounded subdomains of the half-plane. In mathematical finance, solutions\nto obstacle problems for the elliptic Heston operator correspond to value\nfunctions for perpetual American-style options on the underlying asset.\n"
    },
    {
        "paper_id": 1109.1167,
        "authors": "Thomas Kau\\^e Dal'Maso Peron and Francisco Aparecido Rodrigues",
        "title": "Collective behavior in financial market",
        "comments": "5 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial market is an example of complex system, which is characterized by a\nhighly intricate organization and the emergence of collective behavior. In this\npaper, we quantify this emergent dynamics in the financial market by using\nconcepts of network synchronization. We consider networks constructed by the\ncorrelation matrix of asset returns and study the time evolution of the phase\ncoherence among stock prices. It is verified that during financial crisis a\nsynchronous state emerges in the system, defining the market's direction.\nFurthermore, the paper proposes a statistical regression model able to identify\nthe topological features that mostly influence such an emergence. The\ncoefficients of the proposed model indicate that the average shortest path\nlength is the measurement most related to network synchronization. Therefore,\nduring economic crisis, the stock prices present a similar evolution, which\ntends to shorten the distances between stocks, indication a collective\ndynamics.\n"
    },
    {
        "paper_id": 1109.1213,
        "authors": "Fabio Caccioli, Thomas A. Catanach, J. Doyne Farmer",
        "title": "Heterogeneity, correlations and financial contagion",
        "comments": "15 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a model of contagion in financial networks recently introduced in\nthe literature, and we characterize the effect of a few features empirically\nobserved in real networks on the stability of the system. Notably, we consider\nthe effect of heterogeneous degree distributions, heterogeneous balance sheet\nsize and degree correlations between banks. We study the probability of\ncontagion conditional on the failure of a random bank, the most connected bank\nand the biggest bank, and we consider the effect of targeted policies aimed at\nincreasing the capital requirements of a few banks with high connectivity or\nbig balance sheets. Networks with heterogeneous degree distributions are shown\nto be more resilient to contagion triggered by the failure of a random bank,\nbut more fragile with respect to contagion triggered by the failure of highly\nconnected nodes. A power law distribution of balance sheet size is shown to\ninduce an inefficient diversification that makes the system more prone to\ncontagion events. A targeted policy aimed at reinforcing the stability of the\nbiggest banks is shown to improve the stability of the system in the regime of\nhigh average degree. Finally, disassortative mixing, such as that observed in\nreal banking networks, is shown to enhance the stability of the system.\n"
    },
    {
        "paper_id": 1109.1256,
        "authors": "Scott Willenbrock (University of Illinois at Urbana-Champaign)",
        "title": "Diversification Return, Portfolio Rebalancing, and the Commodity Return\n  Puzzle",
        "comments": "14 pages",
        "journal-ref": "Financial Analysts Journal, Volume 67, No. 4, 2011, p. 42-49",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Diversification return is an incremental return earned by a rebalanced\nportfolio of assets. The diversification return of a rebalanced portfolio is\noften incorrectly ascribed to a reduction in variance. We argue that the\nunderlying source of the diversification return is the rebalancing, which\nforces the investor to sell assets that have appreciated in relative value and\nbuy assets that have declined in relative value, as measured by their weights\nin the portfolio. In contrast, the incremental return of a buy-and-hold\nportfolio is driven by the fact that the assets that perform the best become a\ngreater fraction of the portfolio. We use these results to resolve two puzzles\nassociated with the Gorton and Rouwenhorst index of commodity futures, and\nthereby obtain a clear understanding of the source of the return of that index.\nDiversification return can be a significant source of return for any rebalanced\nportfolio of volatile assets.\n"
    },
    {
        "paper_id": 1109.1272,
        "authors": "Kay Giesecke, Konstantinos Spiliopoulos, Richard B. Sowers, Justin A.\n  Sirignano",
        "title": "Large Portfolio Asymptotics for Loss From Default",
        "comments": "arXiv admin note: text overlap with arXiv:1104.1773",
        "journal-ref": "Mathematical Finance, Volume 25, Number 1, 2015, pages 77-114",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove a law of large numbers for the loss from default and use it for\napproximating the distribution of the loss from default in large, potentially\nheterogenous portfolios. The density of the limiting measure is shown to solve\na non-linear SPDE, and the moments of the limiting measure are shown to satisfy\nan infinite system of SDEs. The solution to this system leads to %the solution\nto the SPDE through an inverse moment problem, and to the distribution of the\nlimiting portfolio loss, which we propose as an approximation to the loss\ndistribution for a large portfolio. Numerical tests illustrate the accuracy of\nthe approximation, and highlight its computational advantages over a direct\nMonte Carlo simulation of the original stochastic system.\n"
    },
    {
        "paper_id": 1109.1749,
        "authors": "Mitja Stadje, Antoon Pelsser",
        "title": "Time-Consistent and Market-Consistent Evaluations",
        "comments": null,
        "journal-ref": "Mathematical Finance, Vol. 24, No. 1 (January 2014), 25-65",
        "doi": "10.1111/mafi.12026",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider evaluation methods for payoffs with an inherent financial risk as\nencountered for instance for portfolios held by pension funds and insurance\ncompanies. Pricing such payoffs in a way consistent to market prices typically\ninvolves combining actuarial techniques with methods from mathematical finance.\nWe propose to extend standard actuarial principles by a new market-consistent\nevaluation procedure which we call `two step market evaluation.' This procedure\npreserves the structure of standard evaluation techniques and has many other\nappealing properties. We give a complete axiomatic characterization for two\nstep market evaluations. We show further that in a dynamic setting with a\ncontinuous stock prices process every evaluation which is time-consistent and\nmarket-consistent is a two step market evaluation. We also give\ncharacterization results and examples in terms of g-expectations in a\nBrownian-Poisson setting.\n"
    },
    {
        "paper_id": 1109.1751,
        "authors": "Antoon Pelsser",
        "title": "Time-Consistent Actuarial Valuations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent theoretical results establish that time-consistent valuations (i.e.\npricing operators) can be created by backward iteration of one-period\nvaluations. In this paper we investigate the continuous-time limits of\nwell-known actuarial premium principles when such backward iteration procedures\nare applied. We show that the one-period variance premiumprinciple converges to\nthe non-linear exponential indifference valuation. Furthermore, we study the\nconvergence of the one-period standard-deviation principle and establish that\nthe Cost-of-Capital principle, which is widely used by the insurance industry,\nconverges to the same limit as the standard-deviation principle. Finally, we\nstudy the connections between our time-consistent pricing operators, Good Deal\nBound pricing and pricing under model ambiguity.\n"
    },
    {
        "paper_id": 1109.2076,
        "authors": "Neil F. Johnson",
        "title": "Escalation, timing and severity of insurgent and terrorist events:\n  Toward a unified theory of future threats",
        "comments": "Working paper for seminar discussion",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I present a unified discussion of several recently published results\nconcerning the escalation, timing and severity of violent events in human\nconflicts and global terrorism, and set them in the wider context of real-world\nand cyber-based collective violence and illicit activity. I point out how the\nborders distinguishing between such activities are becoming increasingly\nblurred in practice -- from insurgency, terrorism, criminal gangs and\ncyberwars, through to the 2011 Arab Spring uprisings and London riots. I review\nthe robust empirical patterns that have been found, and summarize a minimal\nmechanistic model which can explain these patterns. I also explain why this\nmechanistic approach, which is inspired by non-equilibrium statistical physics,\nfits naturally within the framework of recent ideas within the social science\nliterature concerning analytical sociology. In passing, I flag the fundamental\nflaws in each of the recent critiques which have surfaced concerning the\nrobustness of these results and the realism of the underlying model mechanisms.\n"
    },
    {
        "paper_id": 1109.2327,
        "authors": "Vladimir Vovk",
        "title": "The efficient index hypothesis and its implications in the BSM model",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This note studies the behavior of an index I_t which is assumed to be a\ntradable security, to satisfy the BSM model dI_t/I_t = \\mu dt + \\sigma dW_t,\nand to be efficient in the following sense: we do not expect a prespecified\ntrading strategy whose value is almost surely always nonnegative to outperform\nthe index greatly. The efficiency of the index imposes severe restrictions on\nits growth rate; in particular, for a long investment horizon we should have\n\\mu\\approx r+\\sigma^2, where r is the interest rate. This provides another\npartial solution to the equity premium puzzle. All our mathematical results are\nextremely simple.\n"
    },
    {
        "paper_id": 1109.2557,
        "authors": "M. Krivko and M.V. Tretyakov",
        "title": "Numerical integration of Heath-Jarrow-Morton model of interest rates",
        "comments": "48 pages",
        "journal-ref": "IMA J. Numer. Anal. V. 34 (2014), pp. 147-196",
        "doi": "10.1093/imanum/drs058",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose and analyze numerical methods for the Heath-Jarrow-Morton (HJM)\nmodel. To construct the methods, we first discretize the infinite dimensional\nHJM equation in maturity time variable using quadrature rules for approximating\nthe arbitrage-free drift. This results in a finite dimensional system of\nstochastic differential equations (SDEs) which we approximate in the weak and\nmean-square sense using the general theory of numerical integration of SDEs.\nThe proposed numerical algorithms are computationally highly efficient due to\nthe use of high-order quadrature rules which allow us to take relatively large\ndiscretization steps in the maturity time without affecting overall accuracy of\nthe algorithms. Convergence theorems for the methods are proved. Results of\nsome numerical experiments with European-type interest rate derivatives are\npresented.\n"
    },
    {
        "paper_id": 1109.2631,
        "authors": "Antje Fruth and Torsten Schoeneborn and Mikhail Urusov",
        "title": "Optimal trade execution and price manipulation in order books with\n  time-varying liquidity",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In financial markets, liquidity is not constant over time but exhibits strong\nseasonal patterns. In this article we consider a limit order book model that\nallows for time-dependent, deterministic depth and resilience of the book and\ndetermine optimal portfolio liquidation strategies. In a first model variant,\nwe propose a trading dependent spread that increases when market orders are\nmatched against the order book. In this model no price manipulation occurs and\nthe optimal strategy is of the wait region - buy region type often encountered\nin singular control problems. In a second model, we assume that there is no\nspread in the order book. Under this assumption we find that price manipulation\ncan occur, depending on the model parameters. Even in the absence of classical\nprice manipulation there may be transaction triggered price manipulation. In\nspecific cases, we can state the optimal strategy in closed form.\n"
    },
    {
        "paper_id": 1109.2803,
        "authors": "Jo\\~ao P. da Cruz, Pedro G. Lind",
        "title": "The bounds of heavy-tailed return distributions in evolving complex\n  networks",
        "comments": null,
        "journal-ref": "Physics Letters A,Vol.377,3-4,p189-194,(2013)",
        "doi": "10.1016/j.physleta.2012.11.047",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the evolution of scale-free networks according to preferential\nattachment schemes and show the conditions for which the exponent\ncharacterizing the degree distribution is bounded by upper and lower values.\nOur framework is an agent model, presented in the context of economic networks\nof trades, which shows the emergence of critical behavior. Starting from a\nbrief discussion about the main features of the evolving network of trades, we\nshow that the logarithmic return distributions have bounded heavy-tails, and\nthe corresponding bounding exponent values can be derived. Finally, we discuss\nthese findings in the context of model risk.\n"
    },
    {
        "paper_id": 1109.2884,
        "authors": "Alan De Genaro Dario, Adilson Simonis",
        "title": "Properties of Doubly Stochastic Poisson Process with affine intensity",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper discusses properties of a Doubly Stochastic Poisson Process (DSPP)\nwhere the intensity process belongs to a class of affine diffusions. For any\nintensity process from this class we derive an analytical expression for\nprobability distribution functions of the corresponding DSPP. A specification\nof our results is provided in a particular case where the intensity is given by\none-dimensional Feller process and its parameters are estimated by Kalman\nfiltering for high frequency transaction data.\n"
    },
    {
        "paper_id": 1109.2945,
        "authors": "Maxim Bichuch and Stephan Sturm",
        "title": "Portfolio Optimization under Convex Incentive Schemes",
        "comments": "39 pages, 4 figures",
        "journal-ref": "Finance and Stochastics, 18:4, pp. 873-915 (2014)",
        "doi": "10.1007/s00780-014-0236-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the terminal wealth utility maximization problem from the point\nof view of a portfolio manager who is paid by an incentive scheme, which is\ngiven as a convex function $g$ of the terminal wealth. The manager's own\nutility function $U$ is assumed to be smooth and strictly concave, however the\nresulting utility function $U \\circ g$ fails to be concave. As a consequence,\nthe problem considered here does not fit into the classical portfolio\noptimization theory. Using duality theory, we prove wealth-independent\nexistence and uniqueness of the optimal portfolio in general (incomplete)\nsemimartingale markets as long as the unique optimizer of the dual problem has\na continuous law. In many cases, this existence and uniqueness result is\nindependent of the incentive scheme and depends only on the structure of the\nset of equivalent local martingale measures. As examples, we discuss (complete)\none-dimensional models as well as (incomplete) lognormal mixture and popular\nstochastic volatility models. We also provide a detailed analysis of the case\nwhere the unique optimizer of the dual problem does not have a continuous law,\nleading to optimization problems whose solvability by duality methods depends\non the initial wealth of the investor.\n"
    },
    {
        "paper_id": 1109.3069,
        "authors": "Daniel Bartz, Kerr Hatrick, Christian W. Hesse, Klaus-Robert M\\\"uller,\n  Steven Lemm",
        "title": "Directional Variance Adjustment: improving covariance estimates for\n  high-dimensional portfolio optimization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Robust and reliable covariance estimates play a decisive role in financial\nand many other applications. An important class of estimators is based on\nFactor models. Here, we show by extensive Monte Carlo simulations that\ncovariance matrices derived from the statistical Factor Analysis model exhibit\na systematic error, which is similar to the well-known systematic error of the\nspectrum of the sample covariance matrix. Moreover, we introduce the\nDirectional Variance Adjustment (DVA) algorithm, which diminishes the\nsystematic error. In a thorough empirical study for the US, European, and Hong\nKong market we show that our proposed method leads to improved portfolio\nallocation.\n"
    },
    {
        "paper_id": 1109.3488,
        "authors": "Andrew Clark and Jeff Kenyon",
        "title": "Using MOEAs To Outperform Stock Benchmarks In The Presence of Typical\n  Investment Constraints",
        "comments": "21 pages, Index Terms - multi-objective evolutionary algorithms\n  (MOEA), mean-variance optimization, financial constraints, multi-period MOEAs\n  Updated version of paper. Will appear in Journal of Investing in 2012",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Portfolio managers are typically constrained by turnover limits, minimum and\nmaximum stock positions, cardinality, a target market capitalization and\nsometimes the need to hew to a style (such as growth or value). In addition,\nportfolio managers often use multifactor stock models to choose stocks based\nupon their respective fundamental data.\n  We use multiobjective evolutionary algorithms (MOEAs) to satisfy the above\nreal-world constraints. The portfolios generated consistently outperform\ntypical performance benchmarks and have statistically significant asset\nselection.\n"
    },
    {
        "paper_id": 1109.3893,
        "authors": "Laszlo A. Vegh",
        "title": "Concave Generalized Flows with Applications to Market Equilibria",
        "comments": "Major revision. Instead of highest gain augmenting paths, we employ\n  the Fat-Path framework. Many parts simplified, running time for the linear\n  case improved",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a nonlinear extension of the generalized network flow model, with\nthe flow leaving an arc being an increasing concave function of the flow\nentering it, as proposed by Truemper and Shigeno. We give a polynomial time\ncombinatorial algorithm for solving corresponding flow maximization problems,\nfinding an epsilon-approximate solution in O(m(m+log n)log(MUm/epsilon))\narithmetic operations and value oracle queries, where M and U are upper bounds\non simple parameters. This also gives a new algorithm for linear generalized\nflows, an efficient, purely scaling variant of the Fat-Path algorithm by\nGoldberg, Plotkin and Tardos, not using any cycle cancellations.\n  We show that this general convex programming model serves as a common\nframework for several market equilibrium problems, including the linear Fisher\nmarket model and its various extensions. Our result immediately extends these\nmarket models to more general settings. We also obtain a combinatorial\nalgorithm for nonsymmetric Arrow-Debreu Nash bargaining, settling an open\nquestion by Vazirani.\n"
    },
    {
        "paper_id": 1109.3908,
        "authors": "Michail Anthropelos",
        "title": "Forward Exponential Performances: Pricing and Optimal Risk Sharing",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a Markovian stochastic volatility model, we consider financial agents\nwhose investment criteria are modelled by forward exponential performance\nprocesses. The problem of contingent claim indifference valuation is first\naddressed and a number of properties are proved and discussed. Special\nattention is given to the comparison between the forward exponential and the\nbackward exponential utility indifference valuation. In addition, we construct\nthe problem of optimal risk sharing in this forward setting and solve it when\nthe agents' forward performance criteria are exponential.\n"
    },
    {
        "paper_id": 1109.4032,
        "authors": "David \\v{S}i\\v{s}ka",
        "title": "Error estimates for finite difference approximations of American put\n  option price",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Finite difference approximations to multi-asset American put option price are\nconsidered. The assets are modelled as a multi-dimensional diffusion process\nwith variable drift and volatility. Approximation error of order one quarter\nwith respect to the time discretisation parameter and one half with respect to\nthe space discretisation parameter is proved by reformulating the corresponding\noptimal stopping problem as a solution of a degenerate Hamilton-Jacobi-Bellman\nequation. Furthermore, the error arising from restricting the discrete problem\nto a finite grid by reducing the original problem to a bounded domain is\nestimated.\n"
    },
    {
        "paper_id": 1109.4259,
        "authors": "Guglielmo D'Amico and Filippo Petroni",
        "title": "A semi-Markov model with memory for price changes",
        "comments": null,
        "journal-ref": "J. Stat. Mech. (2011) P12009",
        "doi": "10.1088/1742-5468/2011/12/P12009",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the high frequency price dynamics of traded stocks by a model of\nreturns using a semi-Markov approach. More precisely we assume that the\nintraday returns are described by a discrete time homogeneous semi-Markov which\ndepends also on a memory index. The index is introduced to take into account\nperiods of high and low volatility in the market. First of all we derive the\nequations governing the process and then theoretical results have been compared\nwith empirical findings from real data. In particular we analyzed high\nfrequency data from the Italian stock market from first of January 2007 until\nend of December 2010.\n"
    },
    {
        "paper_id": 1109.4372,
        "authors": "Caglar Tuncay",
        "title": "Analysis of the trends in the index of the Dow Jones Industrial Average\n  (DJIA) of the New York Stock Exchange (NYSE)",
        "comments": "21 pages, 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is hypothesized that price charts can be empirically decomposed into two\ncomponents as random and non random. The non random component, which can be\ntreated as approximately regular behavior of the prices (trend) in an epoch, is\na geometric line. Thus, the random component fluctuates around the non random\ncomponent with various amplitudes. Moreover, the shape of a trend in an epoch\nmay be different in another epoch. It is further hypothesized that statistical\nevidence can be found for various relations between several types of trends and\nthe direction of the next movements of the prices. These hypotheses are tested\non the historical data of the DJIA (Dow) and confirmed. Moreover, it is\nstatistically showed that a number of trends that have occurred in the near\npast course of the Dow can be utilized to presage the near future of the index.\nAs a result, upcoming of a recession in the DJIA, which may portend a worldwide\neconomic crisis, is predicted.\n"
    },
    {
        "paper_id": 1109.4383,
        "authors": "Ivan O. Kitov",
        "title": "Okun's law revisited. Is there structural unemployment in developed\n  countries?",
        "comments": "11 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Okun's law for the biggest developed countries is re-estimated using the most\nrecent data on real GDP per capita and the rate of unemployment. Our results\nshow that the change in unemployment rate can be predicted with a high\naccuracy. The link needs the introduction of a structural break which might be\ncaused by the change in monetary policy or/and in measurement units.\nStatistically, the link between the studied variables is characterized by the\ncoefficient of determination between 0.40 (Australia) and 0.84 (the USA). The\nresidual errors can be associated with measurement errors. The obtained results\nsuggest the absence of structural unemployment in the studied developed\ncountries.\n"
    },
    {
        "paper_id": 1109.4399,
        "authors": "Ivan Kitov, Oleg Kitov",
        "title": "Employment, unemployment and real economic growth",
        "comments": "15 pages, 17 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have modeled the employment/population ratio in the largest developed\ncountries. Our results show that the evolution of the employment rate since\n1970 can be predicted with a high accuracy by a linear dependence on the\nlogarithm of real GDP per capita. All empirical relationships estimated in this\nstudy need a structural break somewhere between 1975 and 1995. Such breaks\nmight be caused by revisions to monetary policy (e.g. inflation targeting)\nor/and changes in measurement units. Statistically, the link between measured\nand predicted rate of employment is characterized by the coefficient of\ndetermination from 0.84 (Australia) to 0.95 (Japan). The model residuals are\nlikely to be associated with measurement errors.\n"
    },
    {
        "paper_id": 1109.4422,
        "authors": "Chris Tofallis",
        "title": "Investment Volatility: A Critique of Standard Beta Estimation and a\n  Simple Way Forward",
        "comments": null,
        "journal-ref": "European Journal of Operational Research 187 (2008) 1358-1367",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Beta is a widely used quantity in investment analysis. We review the common\ninterpretations that are applied to beta in finance and show that the standard\nmethod of estimation - least squares regression - is inconsistent with these\ninterpretations. We present the case for an alternative beta estimator which is\nmore appropriate, as well as being easier to understand and to calculate.\nUnlike regression, the line fit we propose treats both variables in the same\nway. Remarkably, it provides a slope that is precisely the ratio of the\nvolatility of the investment's rate of return to the volatility of the market\nindex rate of return (or the equivalent excess rates of returns). Hence, this\nline fitting method gives an alternative beta, which corresponds exactly to the\nrelative volatility of an investment - which is one of the usual\ninterpretations attached to beta.\n"
    },
    {
        "paper_id": 1109.4726,
        "authors": "T. Kaizoji, M. Leiss, A. Saichev and D. Sornette",
        "title": "Super-exponential endogenous bubbles in an equilibrium model of rational\n  and noise traders",
        "comments": "43 pages including 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a model of super-exponential financial bubbles with two assets\n(risky and risk-free), in which rational investors and noise traders co-exist.\nRational investors form expectations on the return and risk of a risky asset\nand maximize their constant relative risk aversion expected utility with\nrespect to their allocation on the risky asset versus the risk-free asset.\nNoise traders are subjected to social imitation and follow momentum trading.\nAllowing for random time-varying herding propensity, we are able to reproduce\nseveral well-known stylized facts of financial markets such as a fat-tail\ndistribution of returns and volatility clustering. In particular, we observe\ntransient faster-than-exponential bubble growth with approximate log-periodic\nbehavior and give analytical arguments why this follows from our framework. The\nmodel accounts well for the behavior of traders and for the price dynamics that\ndeveloped during the dotcom bubble in 1995-2000. Momentum strategies are shown\nto be transiently profitable, supporting these strategies as enhancing herding\nbehavior.\n"
    },
    {
        "paper_id": 1109.4859,
        "authors": "Marco Lagi, Yavni Bar-Yam, Karla Z. Bertrand and Yaneer Bar-Yam",
        "title": "The Food Crises: A quantitative model of food prices including\n  speculators and ethanol conversion",
        "comments": "56 pages, 12 figures, reviewers listed",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent increases in basic food prices are severely impacting vulnerable\npopulations worldwide. Proposed causes such as shortages of grain due to\nadverse weather, increasing meat consumption in China and India, conversion of\ncorn to ethanol in the US, and investor speculation on commodity markets lead\nto widely differing implications for policy. A lack of clarity about which\nfactors are responsible reinforces policy inaction. Here, for the first time,\nwe construct a dynamic model that quantitatively agrees with food prices. The\nresults show that the dominant causes of price increases are investor\nspeculation and ethanol conversion. Models that just treat supply and demand\nare not consistent with the actual price dynamics. The two sharp peaks in\n2007/2008 and 2010/2011 are specifically due to investor speculation, while an\nunderlying upward trend is due to increasing demand from ethanol conversion.\nThe model includes investor trend following as well as shifting between\ncommodities, equities and bonds to take advantage of increased expected\nreturns. Claims that speculators cannot influence grain prices are shown to be\ninvalid by direct analysis of price setting practices of granaries. Both causes\nof price increase, speculative investment and ethanol conversion, are promoted\nby recent regulatory changes---deregulation of the commodity markets, and\npolicies promoting the conversion of corn to ethanol. Rapid action is needed to\nreduce the impacts of the price increases on global hunger.\n"
    },
    {
        "paper_id": 1109.5144,
        "authors": "Vladimir Vovk",
        "title": "The Capital Asset Pricing Model as a corollary of the Black-Scholes\n  model",
        "comments": "9 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a financial market in which two securities are traded: a stock\nand an index. Their prices are assumed to satisfy the Black-Scholes model.\nBesides assuming that the index is a tradable security, we also assume that it\nis efficient, in the following sense: we do not expect a prespecified\nself-financing trading strategy whose wealth is almost surely nonnegative at\nall times to outperform the index greatly. We show that, for a long investment\nhorizon, the appreciation rate of the stock has to be close to the interest\nrate (assumed constant) plus the covariance between the volatility vectors of\nthe stock and the index. This contains both a version of the Capital Asset\nPricing Model and our earlier result that the equity premium is close to the\nsquared volatility of the index.\n"
    },
    {
        "paper_id": 1109.5316,
        "authors": "Tim Leung and Qingshuo Song and Jie Yang",
        "title": "Outperformance Portfolio Optimization via the Equivalence of Pure and\n  Randomized Hypothesis Testing",
        "comments": "34 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1007/s00780-013-0213-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the portfolio problem of maximizing the outperformance probability\nover a random benchmark through dynamic trading with a fixed initial capital.\nUnder a general incomplete market framework, this stochastic control problem\ncan be formulated as a composite pure hypothesis testing problem. We analyze\nthe connection between this pure testing problem and its randomized\ncounterpart, and from latter we derive a dual representation for the maximal\noutperformance probability. Moreover, in a complete market setting, we provide\na closed-form solution to the problem of beating a leveraged exchange traded\nfund. For a general benchmark under an incomplete stochastic factor model, we\nprovide the Hamilton-Jacobi-Bellman PDE characterization for the maximal\noutperformance probability.\n"
    },
    {
        "paper_id": 1109.5512,
        "authors": "Keita Owari",
        "title": "On Admissible Strategies in Robust Utility Maximization",
        "comments": "Forthcoming in Mathematics and Financial Economics",
        "journal-ref": "Mathematics and Financial Economics, Vol. 6, No. 2, pp. 77-92,\n  2012",
        "doi": "10.1007/s11579-012-0068-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The existence of optimal strategy in robust utility maximization is addressed\nwhen the utility function is finite on the entire real line. A delicate problem\nin this case is to find a \"good definition\" of admissible strategies, so that\nan optimizer is obtained. Under suitable assumptions, especially a\ntime-consistency property of the set of probabilities which describes the model\nuncertainty, we show that an optimal strategy is obtained in the class of\nstrategies whose wealths are supermartingales under all local martingale\nmeasures having a finite generalized entropy with at least one of candidate\nmodels (probabilities).\n"
    },
    {
        "paper_id": 1109.5752,
        "authors": "Erhan Bayraktar and Arash Fahim",
        "title": "A Stochastic Approximation for Fully Nonlinear Free Boundary Parabolic\n  Problems",
        "comments": "To appear in the journal \"Numerical Methods for Partial Differential\n  Equations\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a stochastic numerical method for solving fully non-linear free\nboundary problems of parabolic type and provide a rate of convergence under\nreasonable conditions on the non-linearity.\n"
    },
    {
        "paper_id": 1109.5791,
        "authors": "Joachim Kaldasch",
        "title": "Dynamic Model of Markets of Homogenous Non-Durable",
        "comments": null,
        "journal-ref": "British Journal of Economics, Management & Trade 9(3): 1-12, 2015,\n  Article no.BJEMT.19254",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new microeconomic model is presented that aims at a description of the\nlong-term unit sales and price evolution of homogeneous non-durable goods in\npolypoly markets. It merges the product lifecycle approach with the price\ndispersion dynamics of homogeneous goods. The model predicts a minimum critical\nlifetime of non-durables in order to survive. Under the condition that the\nsupply side of the market evolves much faster than the demand side the theory\nsuggests that unsatisfied demands are present in the first stages of the\nlifecycle. With the growth of production capacities these demands disappear\naccompanied with a logistic decrease of the mean price of the good. The model\nis applied to electricity as a non-durable satisfying the model condition. The\npresented theory allows a deeper understanding of the sales and price dynamics\nof non-durables.\n"
    },
    {
        "paper_id": 1109.6154,
        "authors": "Zhi Guo and Eckhard Platen",
        "title": "The Small and Large Time Implied Volatilities in the Minimal Market\n  Model",
        "comments": "50 pages, 4 figures, typo on page 18 corrected",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper derives explicit formulas for both the small and large time limits\nof the implied volatility in the minimal market model. It is shown that\ninterest rates do impact on the implied volatility in the long run even though\nthey are negligible in the short time limit.\n"
    },
    {
        "paper_id": 1109.621,
        "authors": "Iacopo Mastromatteo, Elia Zarinelli, Matteo Marsili",
        "title": "Reconstruction of financial network for robust estimation of systemic\n  risk",
        "comments": "13 pages, 5 figures, version to appear in JSTAT",
        "journal-ref": "J. Stat. Mech. (2012) P03011",
        "doi": "10.1088/1742-5468/2012/03/P03011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we estimate the propagation of liquidity shocks through\ninterbank markets when the information about the underlying credit network is\nincomplete. We show that techniques such as Maximum Entropy currently used to\nreconstruct credit networks severely underestimate the risk of contagion by\nassuming a trivial (fully connected) topology, a type of network structure\nwhich can be very different from the one empirically observed. We propose an\nefficient message-passing algorithm to explore the space of possible network\nstructures, and show that a correct estimation of the network degree of\nconnectedness leads to more reliable estimations for systemic risk. Such\nalgorithm is also able to produce maximally fragile structures, providing a\npractical upper bound for the risk of contagion when the actual network\nstructure is unknown. We test our algorithm on ensembles of synthetic data\nencoding some features of real financial networks (sparsity and heterogeneity),\nfinding that more accurate estimations of risk can be achieved. Finally we find\nthat this algorithm can be used to control the amount of information regulators\nneed to require from banks in order to sufficiently constrain the\nreconstruction of financial networks.\n"
    },
    {
        "paper_id": 1109.6909,
        "authors": "Sebast{\\i}an Mart{\\i}nez Bustos, Jorgen Vitting Andersen, Michel\n  Miniconi, Andrzej Nowak, Magdalena Roszczynska-Kurasinska and David Bree",
        "title": "Pricing stocks with yardsticks and sentiments",
        "comments": "10 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Human decision making by professionals trading daily in the stock market can\nbe a daunting task. It includes decisions on whether to keep on investing or to\nexit a market subject to huge price swings, and how to price in news or rumors\nattributed to a specific stock. The question then arises how professional\ntraders, who specialize in daily buying and selling large amounts of a given\nstock, know how to properly price a given stock on a given day? Here we\nintroduce the idea that people use heuristics, or \"rules of thumb\", in terms of\n\"yard sticks\" from the performance of the other stocks in a stock index. The\nunder- /over-performance with respect to such a yard stick then signifies a\ngeneral negative/positive sentiment of the market participants towards a given\nstock. Using empirical data of the Dow Jones Industrial Average, stocks are\nshown to have daily performances with a clear tendency to cluster around the\nmeasures introduced by the yard sticks. We illustrate how sentiments, most\nlikely due to insider information, can influence the performance of a given\nstock over period of months, and in one case years.\n"
    },
    {
        "paper_id": 1110.0062,
        "authors": "Murphy Choy and Michelle L.F. Cheong",
        "title": "Identification of Demand through Statistical Distribution Modeling for\n  Improved Demand Forecasting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Demand functions for goods are generally cyclical in nature with\ncharacteristics such as trend or stochasticity. Most existing demand\nforecasting techniques in literature are designed to manage and forecast this\ntype of demand functions. However, if the demand function is lumpy in nature,\nthen the general demand forecasting techniques may fail given the unusual\ncharacteristics of the function. Proper identification of the underlying demand\nfunction and using the most appropriate forecasting technique becomes critical.\nIn this paper, we will attempt to explore the key characteristics of the\ndifferent types of demand function and relate them to known statistical\ndistributions. By fitting statistical distributions to actual past demand data,\nwe are then able to identify the correct demand functions, so that the the most\nappropriate forecasting technique can be applied to obtain improved forecasting\nresults. We applied the methodology to a real case study to show the reduction\nin forecasting errors obtained.\n"
    },
    {
        "paper_id": 1110.0159,
        "authors": "Guanghui Huang, Jing Xu, Wenting Xing",
        "title": "Hedging strategies with a put option and their failure rates",
        "comments": "10 pages, 1 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of stock hedging is reconsidered in this paper, where a put\noption is chosen from a set of available put options to hedge the market risk\nof a stock. A formula is proposed to determine the probability that the\npotential loss exceeds a predetermined level of Value-at-Risk, which is used to\nfind the optimal strike price and optimal hedge ratio. The assumptions that the\nchosen put option finishes in-the-money and the constraint of hedging budget is\nbinding are relaxed in this paper. A hypothesis test is proposed to determine\nwhether the failure rate of hedging strategy is greater than the predetermined\nlevel of risk. The performances of the proposed method and the method with\nthose two assumptions are compared through simulations. The results of\nsimulated investigations indicate that the proposed method is much more prudent\nthan the method with those two assumptions.\n"
    },
    {
        "paper_id": 1110.022,
        "authors": "Tim Leung and Peng Liu",
        "title": "Risk Premia and Optimal Liquidation of Credit Derivatives",
        "comments": "30 pages",
        "journal-ref": "International Journal of Theoretical and Applied Finance 2012",
        "doi": "10.1142/S0219024912500598",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the optimal timing to liquidate credit derivatives in a\ngeneral intensity-based credit risk model under stochastic interest rate. We\nincorporate the potential price discrepancy between the market and investors,\nwhich is characterized by risk-neutral valuation under different default risk\npremia specifications. We quantify the value of optimally timing to sell\nthrough the concept of delayed liquidation premium, and analyze the associated\nprobabilistic representation and variational inequality. We illustrate the\noptimal liquidation policy for both single-named and multi-named credit\nderivatives. Our model is extended to study the sequential buying and selling\nproblem with and without short-sale constraint.\n"
    },
    {
        "paper_id": 1110.0403,
        "authors": "Agostino Capponi, Jose Figueroa-Lopez, and Jeffrey Nisen",
        "title": "Pricing and Semimartingale Representations of Vulnerable Contingent\n  Claims in Regime-Switching Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using a suitable change of probability measure, we obtain a novel Poisson\nseries representation for the arbitrage- free price process of vulnerable\ncontingent claims in a regime-switching market driven by an underlying\ncontinuous- time Markov process. As a result of this representation, along with\na short-time asymptotic expansion of the claim's price process, we develop an\nefficient method for pricing claims whose payoffs may depend on the full path\nof the underlying Markov chain. The proposed approach is applied to price not\nonly simple European claims such as defaultable bonds, but also a new type of\npath-dependent claims that we term self-decomposable, as well as the important\nclass of vulnerable call and put options on a stock. We provide a detailed\nerror analysis and illustrate the accuracy and computational complexity of our\nmethod on several market traded instruments, such as defaultable bond prices,\nbarrier options, and vulnerable call options. Using again our Poisson series\nrepresentation, we show differentiability in time of the pre-default price\nfunction of European vulnerable claims, which enables us to rigorously deduce\nFeynman-Kac representations for the pre-default pricing function and new\nsemimartingale representations for the price process of the vulnerable claim\nunder both risk-neutral and objective probability measures.\n"
    },
    {
        "paper_id": 1110.0561,
        "authors": "Abhimanyu Mitra and Sidney I. Resnick",
        "title": "Modeling Multiple Risks: Hidden Domain of Attraction",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Hidden regular variation is a sub-model of multivariate regular variation and\nfacilitates accurate estimation of joint tail probabilities. We generalize the\nmodel of hidden regular variation to what we call hidden domain of attraction.\nWe exhibit examples that illustrate the need for a more general model and\ndiscuss detection and estimation techniques.\n"
    },
    {
        "paper_id": 1110.1006,
        "authors": "Laurent Schoeffel (CEA-Saclay)",
        "title": "Returns in futures markets and $\\nu=3$ t-distribution",
        "comments": "6 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The probability distribution of log-returns of financial time series, sampled\nat high frequency, is the basis for any further developments in quantitative\nfinance. In this letter, we present experimental results based on a large set\nof time series on futures. Then, we show that the t-distribution with $\\nu\n\\simeq 3$ gives a nice description of almost all data series. This appears to\nbe a quite general result that stays robust on a large set of any financial\ndata as well as on a wide range of sampling frequency of these data, below one\nhour.\n"
    },
    {
        "paper_id": 1110.1214,
        "authors": "Paolo Guasoni, Johannes Muhle-Karbe",
        "title": "Long Horizons, High Risk Aversion, and Endogeneous Spreads",
        "comments": "27 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For an investor with constant absolute risk aversion and a long horizon, who\ntrades in a market with constant investment opportunities and small\nproportional transaction costs, we obtain explicitly the optimal investment\npolicy, its implied welfare, liquidity premium, and trading volume. We identify\nthese quantities as the limits of their isoelastic counterparts for high levels\nof risk aversion. The results are robust with respect to finite horizons, and\nextend to multiple uncorrelated risky assets.\n  In this setting, we study a Stackelberg equilibrium, led by a risk-neutral,\nmonopolistic market maker who sets the spread as to maximize profits. The\nresulting endogenous spread depends on investment opportunities only, and is of\nthe order of a few percentage points for realistic parameter values.\n"
    },
    {
        "paper_id": 1110.1319,
        "authors": "Peter Cauwels and Didier Sornette",
        "title": "Quis pendit ipsa pretia: facebook valuation and diagnostic of a bubble\n  based on nonlinear demographic dynamics",
        "comments": "New version includes additional study of groupon, confirming our\n  conclusions with facebook on the existence of significant overvaluation in\n  the social network sector",
        "journal-ref": "Journal of Portfolio Management 38 (2), 56-66 (2012)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a novel methodology to determine the fundamental value of firms in\nthe social-networking sector based on two ingredients: (i) revenues and profits\nare inherently linked to its user basis through a direct channel that has no\nequivalent in other sectors; (ii) the growth of the number of users can be\ncalibrated with standard logistic growth models and allows for reliable\nextrapolations of the size of the business at long time horizons. We illustrate\nthe methodology with a detailed analysis of facebook, one of the biggest of the\nsocial-media giants. There is a clear signature of a change of regime that\noccurred in 2010 on the growth of the number of users, from a pure exponential\nbehavior (a paradigm for unlimited growth) to a logistic function with\nasymptotic plateau (a paradigm for growth in competition). We consider three\ndifferent scenarios, a base case, a high growth and an extreme growth scenario.\nUsing a discount factor of 5%, a profit margin of 29% and 3.5 USD of revenues\nper user per year yields a value of facebook of 15.3 billion USD in the base\ncase scenario, 20.2 billion USD in the high growth scenario and 32.9 billion\nUSD in the extreme growth scenario. According to our methodology, this would\nimply that facebook would need to increase its profit per user before the IPO\nby a factor of 3 to 6 in the base case scenario, 2.5 to 5 in the high growth\nscenario and 1.5 to 3 in the extreme growth scenario in order to meet the\ncurrent, widespread, high expectations. To prove the wider applicability of our\nmethodology, the analysis is repeated on Groupon, the well-known\ndeal-of-the-day website which is expected to go public in November 2011. The\nresults are in line with the facebook analysis. Customer growth will plateau.\nBy not taking this fundamental property of the growth process into\nconsideration, estimates of its IPO are wildly overpriced.\n"
    },
    {
        "paper_id": 1110.1436,
        "authors": "Rama Cont, Romain Deguest, Xuedong He",
        "title": "Loss-Based Risk Measures",
        "comments": "40 pages",
        "journal-ref": "Statistics and Risk Modeling, Vol 30, Issue 2, pages 133-167\n  (2013)",
        "doi": "10.1524/strm.2013.1132",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Starting from the requirement that risk measures of financial portfolios\nshould be based on their losses, not their gains, we define the notion of\nloss-based risk measure and study the properties of this class of risk\nmeasures. We characterize loss-based risk measures by a representation theorem\nand give examples of such risk measures. We then discuss the statistical\nrobustness of estimators of loss-based risk measures: we provide a general\ncriterion for qualitative robustness of risk estimators and compare this\ncriterion with sensitivity analysis of estimators based on influence functions.\nFinally, we provide examples of statistically robust estimators for loss-based\nrisk measures.\n"
    },
    {
        "paper_id": 1110.1522,
        "authors": "Junjie Wang, Shuigeng Zhou, Jihong Guan",
        "title": "Detecting Collusive Cliques in Futures Markets Based on Trading\n  Behaviors from Real Data",
        "comments": "13 pages, 5 figures and 3 tables. submitted to Neurocomputing",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In financial markets, abnormal trading behaviors pose a serious challenge to\nmarket surveillance and risk management. What is worse, there is an increasing\nemergence of abnormal trading events that some experienced traders constitute a\ncollusive clique and collaborate to manipulate some instruments, thus mislead\nother investors by applying similar trading behaviors for maximizing their\npersonal benefits. In this paper, a method is proposed to detect the hidden\ncollusive cliques involved in an instrument of future markets by first\ncalculating the correlation coefficient between any two eligible unified\naggregated time series of signed order volume, and then combining the connected\ncomponents from multiple sparsified weighted graphs constructed by using the\ncorrelation matrices where each correlation coefficient is over a\nuser-specified threshold. Experiments conducted on real order data from the\nShanghai Futures Exchange show that the proposed method can effectively detect\nsuspect collusive cliques. A tool based on the proposed method has been\ndeployed in the exchange as a pilot application for futures market surveillance\nand risk management.\n"
    },
    {
        "paper_id": 1110.1567,
        "authors": "Reza Farrahi Moghaddam and Fereydoun Farrahi Moghaddam and Mohamed\n  Cheriet",
        "title": "A Modified GHG Intensity Indicator: Toward a Sustainable Global Economy\n  based on a Carbon Border Tax and Emissions Trading",
        "comments": "Accepted for publication in Energy Policy (Elsevier)",
        "journal-ref": "Energy Policy, vol 57, pp. 363-380, 2013",
        "doi": "10.1016/j.enpol.2013.02.012",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It will be difficult to gain the agreement of all the actors on any proposal\nfor climate change management, if universality and fairness are not considered.\nIn this work, a universal measure of emissions to be applied at the\ninternational level is proposed, based on a modification of the Greenhouse Gas\nIntensity (GHG-INT) measure. It is hoped that the generality and low\nadministrative cost of this measure, which we call the Modified Greenhouse Gas\nIntensity measure (MGHG-INT), will eliminate any need to classify nations. The\ncore of the MGHG-INT is what we call the IHDI-adjusted Gross Domestic Product\n(IDHIGDP), based on the Inequality-adjusted Human Development Index (IHDI). The\nIDHIGDP makes it possible to propose universal measures, such as MGHG-INT. We\nalso propose a carbon border tax applicable at national borders, based on\nMGHG-INT and IDHIGDP. This carbon tax is supported by a proposed global\nEmissions Trading System (ETS). The proposed carbon tax is analyzed in a\nshort-term scenario, where it is shown that it can result in significant\nreduction in global emissions while keeping the economy growing at a positive\nrate. In addition to annual GHG emissions, cumulative GHG emissions over two\ndecades are considered with almost the same results.\n"
    },
    {
        "paper_id": 1110.1578,
        "authors": "Ole Peters",
        "title": "Menger 1934 revisited",
        "comments": "16 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Karl Menger's 1934 paper on the St. Petersburg paradox contains mathematical\nerrors that invalidate his conclusion that unbounded utility functions,\nspecifically Bernoulli's logarithmic utility, fail to resolve modified versions\nof the St. Petersburg paradox.\n"
    },
    {
        "paper_id": 1110.1727,
        "authors": "Laurent Schoeffel (CEA Saclay)",
        "title": "Time Scales in Futures Markets and Applications",
        "comments": "14 pages, 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:1108.5596 and arXiv:1108.5946",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The probability distribution of log-returns for financial time series,\nsampled at high frequency, is the basis for any further developments in\nquantitative finance. In this letter, we present experimental results based on\na large set of time series on futures. We show that the t-distribution with\n$\\nu \\simeq 3$ gives a nice description of almost all data series considered\nfor a time scale $\\Delta t$ below 1 hour. For $\\Delta t \\ge 8$ hours, the\nGaussian regime is reached. A particular focus has been put on the DAX and Euro\nfutures. This appears to be a quite general result that stays robust on a large\nset of futures, but not on any data sets. In this sense, this is not universal.\nA technique using factorial moments defined on a sequence of returns is\ndescribed and similar results for time scales are obtained. Let us note that\nfrom a fundamental point of view, there is no clear reason why DAX and Euro\nfutures should present similar behavior with respect to their return\ndistributions. Both are complex markets where many internal and external\nfactors interact at each instant to determine the transaction price. These\nfactors are certainly different for an index on a change parity (Euro) and an\nindex on stocks (DAX). Thus, this is striking that we can identify universal\nstatistical features in price fluctuations of these markets. This is really the\nadvantage of micro-structure analysis to prompt unified approaches of different\nkinds of markets. Finally, we examine the relation of power law distribution of\nreturns with another scaling behavior of the data encoded into the Hurst\nexponent. We have obtained $H=0.54 \\pm 0.04$ for DAX and $H=0.51 \\pm 0.03$ for\nEuro futures.\n"
    },
    {
        "paper_id": 1110.2075,
        "authors": "Abhijit Chakraborty, G. Mukherjee and S. S. Manna",
        "title": "Conservative self-organized extremal model for wealth distribution",
        "comments": "11 pages, 16 figures",
        "journal-ref": null,
        "doi": "10.1142/S0218348X12500156",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a detailed numerical analysis of the modified version of a\nconservative self-organized extremal model introduced by Pianegonda et. al. for\nthe distribution of wealth of the people in a society. Here the trading process\nhas been modified by the stochastic bipartite trading rule. More specifically\nin a trade one of the agents is necessarily the one with the globally minimal\nvalue of wealth, the other one being selected randomly from the neighbors of\nthe first agent. The pair of agents then randomly re-shuffle their entire\namount of wealth without saving. This model has most of the characteristics\nsimilar to the self-organized critical Bak-Sneppen model of evolutionary\ndynamics. Numerical estimates of a number of critical exponents indicate this\nmodel is likely to belong to a new universality class different from the well\nknown models in the literature. In addition the persistence time, which is the\ntime interval between two successive updates of wealth of an agent has been\nobserved to have a non-trivial power law distribution. An opposite version of\nthe model has also been studied where the agent with maximal wealth is selected\ninstead of the one with minimal wealth, which however, exhibits similar\nbehavior as the Minimal Wealth model.\n"
    },
    {
        "paper_id": 1110.226,
        "authors": "Xiao-Qian Sun, Xue-Qi Cheng, Hua-Wei Shen, Zhao-Yang Wang",
        "title": "Distinguishing manipulated stocks via trading network analysis",
        "comments": "18 pages, 7 figures",
        "journal-ref": "Physica A 390 (2011) 3427--3434",
        "doi": "10.1016/j.physa.2011.04.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Manipulation is an important issue for both developed and emerging stock\nmarkets. For the study of manipulation, it is critical to analyze investor\nbehavior in the stock market. In this paper, an analysis of the full\ntransaction records of over a hundred stocks in a one-year period is conducted.\nFor each stock, a trading network is constructed to characterize the relations\namong its investors. In trading networks, nodes represent investors and a\ndirected link connects a stock seller to a buyer with the total trade size as\nthe weight of the link, and the node strength is the sum of all edge weights of\na node. For all these trading networks, we find that the node degree and node\nstrength both have tails following a power-law distribution. Compared with\nnon-manipulated stocks, manipulated stocks have a high lower bound of the\npower-law tail, a high average degree of the trading network and a low\ncorrelation between the price return and the seller-buyer ratio. These findings\nmay help us to detect manipulated stocks.\n"
    },
    {
        "paper_id": 1110.2477,
        "authors": "Nan Zhang and Alet Roux and Tomasz Zastawniak",
        "title": "Parallel Binomial American Option Pricing with (and without) Transaction\n  Costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a parallel algorithm that computes the ask and bid prices of an\nAmerican option when proportional transaction costs apply to the trading of the\nunderlying asset. The algorithm computes the prices on recombining binomial\ntrees, and is designed for modern multi-core processors. Although parallel\noption pricing has been well studied, none of the existing approaches takes\ntransaction costs into consideration. The algorithm that we propose partitions\na binomial tree into blocks. In any round of computation a block is further\npartitioned into regions which are assigned to distinct processors. To minimise\nload imbalance the assignment of nodes to processors is dynamically adjusted\nbefore each new round starts. Synchronisation is required both within a round\nand between two successive rounds. The parallel speedup of the algorithm is\nproportional to the number of processors used. The parallel algorithm was\nimplemented in C/C++ via POSIX Threads, and was tested on a machine with 8\nprocessors. In the pricing of an American put option, the parallel speedup\nagainst an efficient sequential implementation was 5.26 using 8 processors and\n1500 time steps, achieving a parallel efficiency of 65.75%.\n"
    },
    {
        "paper_id": 1110.2573,
        "authors": "Oleksii Mostovyi",
        "title": "Optimal investment with intermediate consumption and random endowment",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a problem of optimal investment with intermediate consumption and\nrandom endowment in an incomplete semimartingale model of a financial market.\nWe establish the key assertions of the utility maximization theory assuming\nthat both primal and dual value functions are finite in the interiors of their\ndomains as well as that random endowment at maturity can be dominated by the\nterminal value of a self-financing wealth process. In order to facilitate\nverification of these conditions, we present alternative, but equivalent\nconditions, under which the conclusions of the theory hold.\n"
    },
    {
        "paper_id": 1110.2603,
        "authors": "Tom\\'a\\v{s} Tok\\'ar, Denis Horv\\'ath, Michal Hnatich",
        "title": "Multi-agent based analysis of financial data",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work the system of agents is applied to establish a model of the\nnonlinear distributed signal processing. The evolution of the system of the\nagents - by the prediction time scale diversified trend followers, has been\nstudied for the stochastic time-varying environments represented by the real\ncurrency-exchange time series. The time varying population and its statistical\ncharacteristics have been analyzed in the non-interacting and interacting\ncases. The outputs of our analysis are presented in the form of the mean\nlife-times, mean utilities and corresponding distributions. They show that\npopulations are susceptible to the strength and form of inter-agent\ninteraction. We believe that our results will be useful for the development of\nthe robust adaptive prediction systems.\n"
    },
    {
        "paper_id": 1110.2612,
        "authors": "Tom\\'a\\v{s} Tok\\'ar, Denis Horv\\'ath",
        "title": "Market inefficiency identified by both single and multiple currency\n  trends",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.06.038",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many studies have shown that there are good reasons to claim very low\npredictability of currency nevertheless, the deviations from true randomness\nexist which have potential predictive and prognostic power [J.James,\nQuantitative finance 3 (2003) C75-C77]. We analyze the local trends which are\nof the main focus of the technical analysis. In this article we introduced\nvarious statistical quantities examining role of single temporal discretized\ntrend or multitude of trends corresponding to different time delays. Our\nspecific analysis based on Euro-dollar currency pair data at the one minute\nfrequency suggests the importance of cumulative nonrandom effect of trends on\nthe forecasting performance.\n"
    },
    {
        "paper_id": 1110.3133,
        "authors": "Fei Ren and Li-Xin Zhong",
        "title": "Price impact asymmetry of institutional trading in Chinese stock market",
        "comments": "14 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.12.049",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The asymmetric price impact between the institutional purchases and sales of\n32 liquid stocks in Chinese stock markets in year 2003 is carefully studied. We\nanalyze the price impact in both drawup and drawdown trends with consecutive\npositive and negative daily price changes, and test the dependence of the price\nimpact asymmetry on the market condition. For most of the stocks institutional\nsales have a larger price impact than institutional purchases, and larger\nimpact of institutional purchases only exists in few stocks with primarily\nincreasing tendencies. We further study the mean return of trades surrounding\ninstitutional transactions, and find the asymmetric behavior also exists before\nand after institutional transactions. A new variable is proposed to investigate\nthe order book structure, and it can partially explain the price impact of\ninstitutional transactions. A linear regression for the price impact of\ninstitutional transactions further confirms our finding that institutional\nsales primarily have a larger price impact than institutional purchases in the\nbearish year 2003.\n"
    },
    {
        "paper_id": 1110.3224,
        "authors": "Peter Bank (Technische Universit\\\"at Berlin) and Dmitry Kramkov\n  (Carnegie Mellon and Oxford)",
        "title": "A model for a large investor trading at market indifference prices. I:\n  single-period case",
        "comments": "Shorten from 69 to 30 pages due to referees' requests; a part of the\n  previous version has been moved to \"The stochastic field of aggregate\n  utilities and its saddle conjugate\", arXiv:1310.7280",
        "journal-ref": "(2015) Finance and Stochastics, Volume 19, Issue 2, Pages 449-472",
        "doi": "10.1007/s00780-015-0258-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a single-period model for a large economic agent who trades with\nmarket makers at their utility indifference prices. A key role is played by a\npair of conjugate saddle functions associated with the description of Pareto\noptimal allocations in terms of the utility function of a representative market\nmaker.\n"
    },
    {
        "paper_id": 1110.3229,
        "authors": "Peter Bank, Dmitry Kramkov",
        "title": "A model for a large investor trading at market indifference prices. II:\n  Continuous-time case",
        "comments": "Published at http://dx.doi.org/10.1214/14-AAP1059 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 5, 2708-2742",
        "doi": "10.1214/14-AAP1059",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop from basic economic principles a continuous-time model for a large\ninvestor who trades with a finite number of market makers at their utility\nindifference prices. In this model, the market makers compete with their quotes\nfor the investor's orders and trade among themselves to attain Pareto optimal\nallocations. We first consider the case of simple strategies and then, in\nanalogy to the construction of stochastic integrals, investigate the transition\nto general continuous dynamics. As a result, we show that the model's evolution\ncan be described by a nonlinear stochastic differential equation for the market\nmakers' expected utilities.\n"
    },
    {
        "paper_id": 1110.3248,
        "authors": "Dmitry Kramkov (Carnegie Mellon and Oxford) and Silviu Predoiu\n  (Citigroup)",
        "title": "Integral representation of martingales motivated by the problem of\n  endogenous completeness in financial economics",
        "comments": "A stronger version of the main theorem is obtained. The \"financial\"\n  part of the previous version is removed",
        "journal-ref": "Stochastic Processes and their Applications, 124 (1), pages\n  81-100, 2014",
        "doi": "10.1016/j.spa.2013.06.017",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Let $\\mathbb{Q}$ and $\\mathbb{P}$ be equivalent probability measures and let\n$\\psi$ be a $J$-dimensional vector of random variables such that\n$\\frac{d\\mathbb{Q}}{d\\mathbb{P}}$ and $\\psi$ are defined in terms of a weak\nsolution $X$ to a $d$-dimensional stochastic differential equation. Motivated\nby the problem of \\emph{endogenous completeness} in financial economics we\npresent conditions which guarantee that every local martingale under\n$\\mathbb{Q}$ is a stochastic integral with respect to the $J$-dimensional\nmartingale $S_t \\set \\mathbb{E}^{\\mathbb{Q}}[\\psi|\\mathcal{F}_t]$. While the\ndrift $b=b(t,x)$ and the volatility $\\sigma = \\sigma(t,x)$ coefficients for $X$\nneed to have only minimal regularity properties with respect to $x$, they are\nassumed to be analytic functions with respect to $t$. We provide a\ncounter-example showing that this $t$-analyticity assumption for $\\sigma$\ncannot be removed.\n"
    },
    {
        "paper_id": 1110.325,
        "authors": "Peter Bank (Technische Universit\\\"at Berlin) and Dmitry Kramkov\n  (Carnegie Mellon and Oxford)",
        "title": "On a stochastic differential equation arising in a price impact model",
        "comments": "20 pages. Keywords: Clark-Ocone formula, large investor, Malliavin\n  derivative, Pareto allocation, price impact, Sobolev's embedding, stochastic\n  differential equation; a couple of minor editorial corrections to make it\n  identical to the paper accepted to Stochastic Processes and Their\n  Applications",
        "journal-ref": "Stochastic Processes and their Applications 123 (2013), 1160-1175",
        "doi": "10.1016/j.spa.2012.10.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide sufficient conditions for the existence and uniqueness of\nsolutions to a stochastic differential equation which arises in a price impact\nmodel. These conditions are stated as smoothness and boundedness requirements\non utility functions or Malliavin differentiability of payoffs and endowments.\n"
    },
    {
        "paper_id": 1110.3383,
        "authors": "Evan Hurwitz and Tshilidzi Marwala",
        "title": "Suitability of using technical indicators as potential strategies within\n  intelligent trading systems",
        "comments": "Paper Presented at the 2011 IEEE International Conference on Systems,\n  Man, and Cybernetics, Anchorage, Alaska, USA",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The potential of machine learning to automate and control nonlinear, complex\nsystems is well established. These same techniques have always presented\npotential for use in the investment arena, specifically for the managing of\nequity portfolios. In this paper, the opportunity for such exploitation is\ninvestigated through analysis of potential simple trading strategies that can\nthen be meshed together for the machine learning system to switch between. It\nis the eligibility of these strategies that is being investigated in this\npaper, rather than application. In order to accomplish this, the underlying\nassumptions of each trading system are explored, and data is created in order\nto evaluate the efficacy of these systems when trading on data with the\nunderlying patterns that they expect. The strategies are tested against a\nbuy-and-hold strategy to determine if the act of trading has actually produced\nany worthwhile results, or are simply facets of the underlying prices. These\nresults are then used to produce targeted returns based upon either a desired\nreturn or a desired risk, as both are required within the portfolio-management\nindustry. Results show a very viable opportunity for exploitation within the\naforementioned industry, with the Strategies performing well within their\nnarrow assumptions, and the intelligent system combining them to perform\nwithout assumptions.\n"
    },
    {
        "paper_id": 1110.346,
        "authors": "Francisco Rubio, Xavier Mestre, Daniel P. Palomar",
        "title": "Performance analysis and optimal selection of large mean-variance\n  portfolios under estimation risk",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1109/JSTSP.2012.2202634",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the consistency of sample mean-variance portfolios of arbitrarily\nhigh dimension that are based on Bayesian or shrinkage estimation of the input\nparameters as well as weighted sampling. In an asymptotic setting where the\nnumber of assets remains comparable in magnitude to the sample size, we provide\na characterization of the estimation risk by providing deterministic\nequivalents of the portfolio out-of-sample performance in terms of the\nunderlying investment scenario. The previous estimates represent a means of\nquantifying the amount of risk underestimation and return overestimation of\nimproved portfolio constructions beyond standard ones. Well-known for the\nlatter, if not corrected, these deviations lead to inaccurate and overly\noptimistic Sharpe-based investment decisions. Our results are based on recent\ncontributions in the field of random matrix theory. Along with the asymptotic\nanalysis, the analytical framework allows us to find bias corrections improving\non the achieved out-of-sample performance of typical portfolio constructions.\nSome numerical simulations validate our theoretical findings.\n"
    },
    {
        "paper_id": 1110.3546,
        "authors": "Piotr Berman, Bhaskar DasGupta, Lakshmi Kaligounder, Marek Karpinski",
        "title": "On the Computational Complexity of Measuring Global Stability of Banking\n  Networks",
        "comments": "to appear in Algorithmica",
        "journal-ref": "Algorithmica, 70(4), 595-647, 2014",
        "doi": "10.1007/s00453-013-9769-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Threats on the stability of a financial system may severely affect the\nfunctioning of the entire economy, and thus considerable emphasis is placed on\nthe analyzing the cause and effect of such threats. The financial crisis in the\ncurrent and past decade has shown that one important cause of instability in\nglobal markets is the so-called financial contagion, namely the spreading of\ninstabilities or failures of individual components of the network to other,\nperhaps healthier, components. This leads to a natural question of whether the\nregulatory authorities could have predicted and perhaps mitigated the current\neconomic crisis by effective computations of some stability measure of the\nbanking networks. Motivated by such observations, we consider the problem of\ndefining and evaluating stabilities of both homogeneous and heterogeneous\nbanking networks against propagation of synchronous idiosyncratic shocks given\nto a subset of banks. We formalize the homogeneous banking network model of\nNier et al. and its corresponding heterogeneous version, formalize the\nsynchronous shock propagation procedures, define two appropriate stability\nmeasures and investigate the computational complexities of evaluating these\nmeasures for various network topologies and parameters of interest. Our results\nand proofs also shed some light on the properties of topologies and parameters\nof the network that may lead to higher or lower stabilities.\n"
    },
    {
        "paper_id": 1110.3897,
        "authors": "S\\\"oren Christensen",
        "title": "Optimal decision under ambiguity for diffusion processes",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/s00186-012-0425-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider stochastic optimization problems for an ambiguity\naverse decision maker who is uncertain about the parameters of the underlying\nprocess. In a first part we consider problems of optimal stopping under drift\nambiguity for one-dimensional diffusion processes. Analogously to the case of\nordinary optimal stopping problems for one-dimensional Brownian motions we\nreduce the problem to the geometric problem of finding the smallest majorant of\nthe reward function in a two-parameter function space. In a second part we\nsolve optimal stopping problems when the underlying process may crash down.\nThese problems are reduced to one optimal stopping problem and one Dynkin game.\nExamples are discussed.\n"
    },
    {
        "paper_id": 1110.4119,
        "authors": "John Cotter, Stuart Gabriel and Richard Roll",
        "title": "Integration and Contagion in US Housing Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper explores integration and contagion among US metropolitan housing\nmarkets. The analysis applies Federal Housing Finance Agency (FHFA) house price\nrepeat sales indexes from 384 metropolitan areas to estimate a multi-factor\nmodel of U.S. housing market integration. It then identifies statistical jumps\nin metropolitan house price returns as well as MSA contemporaneous and lagged\njump correlations. Finally, the paper evaluates contagion in housing markets\nvia parametric assessment of MSA house price spatial dynamics.\n  A R-squared measure reveals an upward trend in MSA housing market integration\nover the 2000s to approximately .83 in 2010. Among California MSAs, the trend\nwas especially pronounced, as average integration increased from about .55 in\n1997 to close to .95 in 2008! The 2000s bubble period similarly was\ncharacterized by elevated incidence of statistical jumps in housing returns.\nAgain, jump incidence and MSA jump correlations were especially high in\nCalifornia. Analysis of contagion among California markets indicates that house\nprice returns in San Francisco often led those of surrounding communities; in\ncontrast, southern California MSA house price returns appeared to move largely\nin lock step.\n  The high levels of housing market integration evidenced in the analysis\nsuggest limited investor opportunity to diversify away MSA-specific housing\nrisk. Further, results suggest that macro and policy shocks propagate through a\nlarge number of MSA housing markets. Research findings are relevant to all\nmarket participants, including institutional investors in MBS as well as those\nwho regulate housing, the housing GSEs, mortgage lenders, and related financial\ninstitutions.\n"
    },
    {
        "paper_id": 1110.4312,
        "authors": "Thomas R. Hurd, James P. Gleeson",
        "title": "A framework for analyzing contagion in banking networks",
        "comments": "23 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A probabilistic framework is introduced that represents stylized banking\nnetworks and aims to predict the size of contagion events. In contrast to\nprevious work on random financial networks, which assumes independent\nconnections between banks, the possibility of disassortative edge probabilities\n(an above average tendency for small banks to link to large banks) is\nexplicitly incorporated. We give a probabilistic analysis of the default\ncascade triggered by shocking the network. We find that the cascade can be\nunderstood as an explicit iterated mapping on a set of edge probabilities that\nconverges to a fixed point. A cascade condition is derived that characterizes\nwhether or not an infinitesimal shock to the network can grow to a finite size\ncascade, in analogy to the basic reproduction number $R_0$ in epidemic\nmodeling. It provides an easily computed measure of the systemic risk inherent\nin a given banking network topology. An analytic formula is given for the\nfrequency of global cascades, derived from percolation theory on the random\nnetwork. Two simple examples are used to demonstrate that edge-assortativity\ncan have a strong effect on the level of systemic risk as measured by the\ncascade condition. Although the analytical methods are derived for infinite\nnetworks, large-scale Monte Carlo simulations are presented that demonstrate\nthe applicability of the results to finite-sized networks. Finally, we propose\na simple graph theoretic quantity, which we call \"graph-assortativity\", that\nseems to best capture systemic risk.\n"
    },
    {
        "paper_id": 1110.4411,
        "authors": "Andrew Gordon Wilson, David A. Knowles, Zoubin Ghahramani",
        "title": "Gaussian Process Regression Networks",
        "comments": "17 pages, 3 figures, 1 table. Submitted for publication",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new regression framework, Gaussian process regression networks\n(GPRN), which combines the structural properties of Bayesian neural networks\nwith the non-parametric flexibility of Gaussian processes. This model\naccommodates input dependent signal and noise correlations between multiple\nresponse variables, input dependent length-scales and amplitudes, and\nheavy-tailed predictive distributions. We derive both efficient Markov chain\nMonte Carlo and variational Bayes inference procedures for this model. We apply\nGPRN as a multiple output regression and multivariate volatility model,\ndemonstrating substantially improved performance over eight popular multiple\noutput (multi-task) Gaussian process models and three multivariate volatility\nmodels on benchmark datasets, including a 1000 dimensional gene expression\ndataset.\n"
    },
    {
        "paper_id": 1110.4455,
        "authors": "Tian Qiu, Guang Chen, Li-Xin Zhong, Xiao-Run Wu",
        "title": "Dynamics of Bid-ask Spread Return and Volatility of the Chinese Stock\n  Market",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.12.048",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Bid-ask spread is taken as an important measure of the financial market\nliquidity. In this article, we study the dynamics of the spread return and the\nspread volatility of four liquid stocks in the Chinese stock market, including\nthe memory effect and the multifractal nature. By investigating the\nautocorrelation function and the Detrended Fluctuation Analysis (DFA), we find\nthat the spread return is lack of long-range memory, while the spread\nvolatility is long-range time correlated. Moreover, by applying the\nMultifractal Detrended Fluctuation Analysis (MF-DFA), the spread return is\nobserved to possess a strong multifractality, which is similar to the dynamics\nof a variety of financial quantities. Differently from the spread return, the\nspread volatility exhibits a weak multifractal nature.\n"
    },
    {
        "paper_id": 1110.4477,
        "authors": "Won-Min Song, T. Di Matteo, Tomaso Aste",
        "title": "Hierarchical information clustering by means of topologically embedded\n  graphs",
        "comments": "33 Pages, 18 Figures, 5 Tables",
        "journal-ref": "PLoS ONE 7 (2012) e31929",
        "doi": "10.1371/journal.pone.0031929",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a graph-theoretic approach to extract clusters and hierarchies\nin complex data-sets in an unsupervised and deterministic manner, without the\nuse of any prior information. This is achieved by building topologically\nembedded networks containing the subset of most significant links and analyzing\nthe network structure. For a planar embedding, this method provides both the\nintra-cluster hierarchy, which describes the way clusters are composed, and the\ninter-cluster hierarchy which describes how clusters gather together. We\ndiscuss performance, robustness and reliability of this method by first\ninvestigating several artificial data-sets, finding that it can outperform\nsignificantly other established approaches. Then we show that our method can\nsuccessfully differentiate meaningful clusters and hierarchies in a variety of\nreal data-sets. In particular, we find that the application to gene expression\npatterns of lymphoma samples uncovers biologically significant groups of genes\nwhich play key-roles in diagnosis, prognosis and treatment of some of the most\nrelevant human lymphoid malignancies.\n"
    },
    {
        "paper_id": 1110.4506,
        "authors": "Carmen Pellicer-Lostao and Ricardo Lopez-Ruiz",
        "title": "Application of Chaotic Number Generators in Econophysics",
        "comments": "7 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Agent-based models have demonstrated their power and flexibility in\nEconophysics. However their major challenge is still to devise more realistic\nsimulation scenarios. The complexity of Economy makes appealing the idea of\nintroducing chaotic number generators as simulation engines in these models.\nChaos based number generators are easy to use and highly configurable. This\nmakes them just perfect for this application.\n"
    },
    {
        "paper_id": 1110.4516,
        "authors": "Mark J. Cathcart, Steven Morrison and Alexander J. McNeil",
        "title": "Calculating Variable Annuity Liability 'Greeks' Using Monte Carlo\n  Simulation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Hedging methods to mitigate the exposure of variable annuity products to\nmarket risks require the calculation of market risk sensitivities (or\n\"Greeks\"). The complex, path-dependent nature of these products means these\nsensitivities typically must be estimated by Monte Carlo simulation. Standard\nmarket practice is to measure such sensitivities using a \"bump and revalue\"\nmethod. As well as requiring multiple valuations, such approaches can be\nunreliable for higher order Greeks, e.g., gamma. In this article we investigate\nalternative estimators implemented within an advanced economic scenario\ngenerator model, incorporating stochastic interest-rates and stochastic equity\nvolatility. The estimators can also be easily generalized to work with the\naddition of equity jumps in this model.\n"
    },
    {
        "paper_id": 1110.4648,
        "authors": "Martin Goldberg",
        "title": "Anti-Robust and Tonsured Statistics",
        "comments": "18 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This describes a statistical technique called \"tonsuring\" for exploratory\ndata analysis in finance. Instead of rejecting \"outlier\" data that conflicts\nwith the model, this strips out \"inlier\" data to get a clearer picture of how\nthe market changes for larger moves.\n"
    },
    {
        "paper_id": 1110.4669,
        "authors": "Giuseppe Campolieti, Roman N. Makarov, Andrey Vasiliev",
        "title": "Bridge Copula Model for Option Pricing",
        "comments": "22 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present a new multi-asset pricing model, which is built upon\nnewly developed families of solvable multi-parameter single-asset diffusions\nwith a nonlinear smile-shaped volatility and an affine drift. Our multi-asset\npricing model arises by employing copula methods. In particular, all discounted\nsingle-asset price processes are modeled as martingale diffusions under a\nrisk-neutral measure. The price processes are so-called UOU diffusions and they\nare each generated by combining a variable (Ito) transformation with a measure\nchange performed on an underlying Ornstein-Uhlenbeck (Gaussian) process.\nConsequently, we exploit the use of a normal bridge copula for coupling the\nsingle-asset dynamics while reducing the distribution of the multi-asset price\nprocess to a multivariate normal distribution. Such an approach allows us to\nsimulate multidimensional price paths in a precise and fast manner and hence to\nprice path-dependent financial derivatives such as Asian-style and Bermudan\noptions using the Monte Carlo method. We also demonstrate how to successfully\ncalibrate our multi-asset pricing model by fitting respective equity option and\nasset market prices to the single-asset models and their return correlations\n(i.e. the copula function) using the least-square and maximum-likelihood\nestimation methods.\n"
    },
    {
        "paper_id": 1110.4784,
        "authors": "Ilaria Bordino, Stefano Battiston, Guido Caldarelli, Matthieu\n  Cristelli, Antti Ukkonen, Ingmar Weber",
        "title": "Web search queries can predict stock market volumes",
        "comments": "29 pages, 11 figures, 11 tables + Supporting Information",
        "journal-ref": null,
        "doi": "10.1371/journal.pone.0040014",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We live in a computerized and networked society where many of our actions\nleave a digital trace and affect other people's actions. This has lead to the\nemergence of a new data-driven research field: mathematical methods of computer\nscience, statistical physics and sociometry provide insights on a wide range of\ndisciplines ranging from social science to human mobility. A recent important\ndiscovery is that query volumes (i.e., the number of requests submitted by\nusers to search engines on the www) can be used to track and, in some cases, to\nanticipate the dynamics of social phenomena. Successful exemples include\nunemployment levels, car and home sales, and epidemics spreading. Few recent\nworks applied this approach to stock prices and market sentiment. However, it\nremains unclear if trends in financial markets can be anticipated by the\ncollective wisdom of on-line users on the web. Here we show that trading\nvolumes of stocks traded in NASDAQ-100 are correlated with the volumes of\nqueries related to the same stocks. In particular, query volumes anticipate in\nmany cases peaks of trading by one day or more. Our analysis is carried out on\na unique dataset of queries, submitted to an important web search engine, which\nenable us to investigate also the user behavior. We show that the query volume\ndynamics emerges from the collective but seemingly uncoordinated activity of\nmany users. These findings contribute to the debate on the identification of\nearly warnings of financial systemic risk, based on the activity of users of\nthe www.\n"
    },
    {
        "paper_id": 1110.4811,
        "authors": "Samuel N. Cohen and Lukasz Szpruch",
        "title": "A limit order book model for latency arbitrage",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a single security market based on a limit order book and two\ninvestors, with different speeds of trade execution. If the fast investor can\nfront-run the slower investor, we show that this allows the fast trader to\nobtain risk free profits, but that these profits cannot be scaled. We derive\nthe fast trader's optimal behaviour when she has only distributional knowledge\nof the slow trader's actions, with few restrictions on the possible prior\ndistributions. We also consider the slower trader's response to the presence of\na fast trader in a market, and the effects of the introduction of a `Tobin tax'\non financial transactions. We show that such a tax can lead to the elimination\nof profits from front-running strategies. Consequently, a Tobin tax can both\nincrease market efficiency and attract traders to a market.\n"
    },
    {
        "paper_id": 1110.4965,
        "authors": "F. Avram, Z. Palmowski, M. R. Pistorius",
        "title": "On Gerber-Shiu functions and optimal dividend distribution for a\n  L\\'{e}vy risk process in the presence of a penalty function",
        "comments": "Published at http://dx.doi.org/10.1214/14-AAP1038 in the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2015, Vol. 25, No. 4, 1868-1935",
        "doi": "10.1214/14-AAP1038",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper concerns an optimal dividend distribution problem for an insurance\ncompany whose risk process evolves as a spectrally negative L\\'{e}vy process\n(in the absence of dividend payments). The management of the company is assumed\nto control timing and size of dividend payments. The objective is to maximize\nthe sum of the expected cumulative discounted dividend payments received until\nthe moment of ruin and a penalty payment at the moment of ruin, which is an\nincreasing function of the size of the shortfall at ruin; in addition, there\nmay be a fixed cost for taking out dividends. A complete solution is presented\nto the corresponding stochastic control problem. It is established that the\nvalue-function is the unique stochastic solution and the pointwise smallest\nstochastic supersolution of the associated HJB equation. Furthermore, a\nnecessary and sufficient condition is identified for optimality of a single\ndividend-band strategy, in terms of a particular Gerber-Shiu function. A number\nof concrete examples are analyzed.\n"
    },
    {
        "paper_id": 1110.5144,
        "authors": "Zoltan Pap",
        "title": "Computing Economic Equilibria by a Homotopy Method",
        "comments": "12th IEEE International Symposium on Computational Intelligence and\n  Informatics",
        "journal-ref": null,
        "doi": "10.1109/CINTI.2011.6108488",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper the possibility of computing equilibrium in pure exchange and\nproduction economies by a homotopy method is investigated. The performance of\nthe algorithm is tested on examples with known equilibria taken from the\nliterature on general equilibrium models and numerical results are presented.\nIn computing equilibria, economy will be specified by excess demand function.\n"
    },
    {
        "paper_id": 1110.5197,
        "authors": "Federico Garzarelli, Matthieu Cristelli, Andrea Zaccaria, Luciano\n  Pietronero",
        "title": "Memory effects in stock price dynamics: evidences of technical trading",
        "comments": "21 pages, 8 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Technical trading represents a class of investment strategies for Financial\nMarkets based on the analysis of trends and recurrent patterns of price time\nseries. According standard economical theories these strategies should not be\nused because they cannot be profitable. On the contrary it is well-known that\ntechnical traders exist and operate on different time scales. In this paper we\ninvestigate if technical trading produces detectable signals in price time\nseries and if some kind of memory effect is introduced in the price dynamics.\nIn particular we focus on a specific figure called supports and resistances. We\nfirst develop a criterion to detect the potential values of supports and\nresistances. As a second step, we show that memory effects in the price\ndynamics are associated to these selected values. In fact we show that prices\nmore likely re-bounce than cross these values. Such an effect is a quantitative\nevidence of the so-called self-fulfilling prophecy that is the\nself-reinforcement of agents' belief and sentiment about future stock prices'\nbehavior.\n"
    },
    {
        "paper_id": 1110.5276,
        "authors": "Hansj\\\"org Albrecher, Corina Constantinescu, Zbigniew Palmowski, Georg\n  Regensburger and Markus Rosenkranz",
        "title": "Exact and asymptotic results for insurance risk models with\n  surplus-dependent premiums",
        "comments": null,
        "journal-ref": "SIAM Journal on Applied Mathematics 73 (2013) 47-66",
        "doi": "10.1137/110852000",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we develop a symbolic technique to obtain asymptotic\nexpressions for ruin probabilities and discounted penalty functions in renewal\ninsurance risk models when the premium income depends on the present surplus of\nthe insurance portfolio. The analysis is based on boundary problems for linear\nordinary differential equations with variable coefficients. The algebraic\nstructure of the Green's operators allows us to develop an intuitive way of\ntackling the asymptotic behavior of the solutions, leading to exponential-type\nexpansions and Cram\\'er-type asymptotics. Furthermore, we obtain closed-form\nsolutions for more specific cases of premium functions in the compound Poisson\nrisk model.\n"
    },
    {
        "paper_id": 1110.5283,
        "authors": "S.I.Melnyk and I.G.Tuluzov",
        "title": "Fundamental Measurements in Economics and in the Theory of Consciousness",
        "comments": "11 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new constructivist approach to modeling in economics and theory of\nconsciousness is proposed. The state of elementary object is defined as a set\nof its measurable consumer properties. A proprietor's refusal or consent for\nthe offered transaction is considered as a result of elementary economic\nmeasurement. Elementary (indivisible) technology, in which the object's\nconsumer values are variable, in this case can be formalized as a generalized\neconomic measurement. The algebra of such measurements has been constructed. It\nhas been shown that in the general case the quantum-mechanical formalism of the\ntheory of selective measurements is required for description of such\nconditions. The economic analogs of the elementary slit experiments in physics\nhave been created. The proposed approach can be also used for consciousness\nmodeling.\n"
    },
    {
        "paper_id": 1110.5288,
        "authors": "I. G. Tuluzov and S. I. Melnyk",
        "title": "Fundamental Measurements in Economics and in the Theory of Consciousness\n  (Manifestation of quantum-mechanical properties of economic objects in slit\n  measurements)",
        "comments": "10 pages, 4 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new constructivist approach to modeling in economics and theory of\nconsciousness is proposed. The state of elementary object is defined as a set\nof its measurable consumer properties. A proprietor's refusal or consent for\nthe offered transaction is considered as a result of elementary economic\nmeasurement. We were also able to obtain the classical interpretation of the\nquantum-mechanical law of addition of probabilities by introducing a number of\nnew notions. The principle of \"local equity\" assumes the transaction completed\n(regardless of the result) of the states of transaction partners are not\nchanged in connection with the reception of new information on proposed offers\nor adopted decisions (consent or refusal of the transaction). However it has no\nrelation to the paradoxes of quantum theory connected with non-local\ninteraction of entangled states. In the economic systems the mechanism of\nentangling has a classical interpretation, while the quantum-mechanical\nformalism of the description of states appears as a result of idealization of\nthe selection mechanism in the proprietor's consciousness.\n"
    },
    {
        "paper_id": 1110.535,
        "authors": "Diederik Aerts, Bart D'Hooghe and Sandro Sozzo",
        "title": "A Quantum-like Approach to the Stock Market",
        "comments": "12 pages, 1 figure",
        "journal-ref": "In M. D'Ariano, S.-M. Fei, E. Haven, B. Hiesmayr, G. Jaeger, A.\n  Khrennikov, J.-A. Larsson (Eds.), Foundations of Probability and Physics - 6,\n  AIP Conference Proceedings, 1424, pp. 495-506, 2012",
        "doi": "10.1063/1.3689002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Modern approaches to stock pricing in quantitative finance are typically\nfounded on the 'Black-Scholes model' and the underlying 'random walk\nhypothesis'. Empirical data indicate that this hypothesis works well in stable\nsituations but, in abrupt transitions such as during an economical crisis, the\nrandom walk model fails and alternative descriptions are needed. For this\nreason, several proposals have been recently forwarded which are based on the\nformalism of quantum mechanics. In this paper we apply the 'SCoP formalism',\nelaborated to provide an operational foundation of quantum mechanics, to the\nstock market. We argue that a stock market is an intrinsically contextual\nsystem where agents' decisions globally influence the market system and stocks\nprices, determining a nonclassical behavior. More specifically, we maintain\nthat a given stock does not generally have a definite value, e.g., a price, but\nits value is actualized as a consequence of the contextual interactions in the\ntrading process. This contextual influence is responsible of the\nnon-Kolmogorovian quantum-like behavior of the market at a statistical level.\nThen, we propose a 'sphere model' within our 'hidden measurement formalism'\nthat describes a buying/selling process of a stock and shows that it is\nintuitively reasonable to assume that the stock has not a definite price until\nit is traded. This result is relevant in our opinion since it provides a\ntheoretical support to the use of quantum models in finance.\n"
    },
    {
        "paper_id": 1110.5429,
        "authors": "Egil Ferkingstad, Anders L{\\o}land, Mathilde Wilhelmsen",
        "title": "Causal modeling and inference for electricity markets",
        "comments": null,
        "journal-ref": "Energy Economics (2011), 33(3):404-412",
        "doi": "10.1016/j.eneco.2010.10.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  How does dynamic price information flow among Northern European electricity\nspot prices and prices of major electricity generation fuel sources? We use\ntime series models combined with new advances in causal inference to answer\nthese questions. Applying our methods to weekly Nordic and German electricity\nprices, and oil, gas and coal prices, with German wind power and Nordic water\nreservoir levels as exogenous variables, we estimate a causal model for the\nprice dynamics, both for contemporaneous and lagged relationships. In\ncontemporaneous time, Nordic and German electricity prices are interlinked\nthrough gas prices. In the long run, electricity prices and British gas prices\nadjust themselves to establish the equlibrium price level, since oil, coal,\ncontinental gas and EUR/USD are found to be weakly exogenous.\n"
    },
    {
        "paper_id": 1110.5446,
        "authors": "Zbigniew Palmowski and Sebastian Baran",
        "title": "Optimizing expected utility of dividend payments for a Cram\\'er-Lundberg\n  risk proces",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of maximizing the discounted utility of dividend\npayments of an insurance company whose reserves are modeled as a classical\nCram\\'er-Lundberg risk process. We investigate this optimization problem under\nthe constraint that dividend rate is bounded. We prove that the value function\nfulfills the Hamilton-Jacobi-Bellman equation and we identify the optimal\ndividend strategy.\n"
    },
    {
        "paper_id": 1110.5516,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Entrepreneurship: what's happening?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Much has been said lately about entrepreneurship, so it seems important to\nleave here some personal analysis on this topic. The issues outlined here\nresult from a work in about a year in which because a personal and professional\nobligations it was doing some research on these issues. This is an interesting\ntopic that has not yet expired and on which there is much to research, do it is\nan area where there are many challenges.\n"
    },
    {
        "paper_id": 1110.5518,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Entrepreneurship: some considerations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work it is presented some considerations about entrepreneurship. Most\nof these questions are linked with Portuguese context. Portugal has some\nparticularities, namely because the asymmetries between the littoral and the\ninterior. This situation carried out some problems that complicate and prevent\nthe appearance of new innovated business. In a situation of crisis like that we\nhave today this context can become a really problem to solve some questions.\n"
    },
    {
        "paper_id": 1110.5534,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Agglomeration and Interregional Mobility of Labor in Portugal",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to analyze the relationship between inter-industry,\nintra-industry and inter-regional clustering and demand for labor by companies\nin Portugal. Is expected at the outset that there is more demand for work where\nthe agglomeration is greater. It should be noted, as a summary conclusion, the\nresults are consistent with the theoretical developments of the New Economic\nGeography, namely the demand for labor is greater where firms are better able\nto cluster that is where transport costs are lower and where there is a strong\nlinks \"backward and forward\" and strong economies of agglomeration.\n"
    },
    {
        "paper_id": 1110.5538,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "The Importance of Increasing Returns to Scale in the Process of\n  Agglomeration in Portugal: A Non-linear Empirical Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With this work we try to analyse the agglomeration process in the Portuguese\nregions, using the New Economic Geography models. In these models the base idea\nis that where has increasing returns to scale in the manufactured industry and\nlow transport costs, there is agglomeration. Of referring, as summary\nconclusion, that with this work the existence of increasing returns to scale\nand low transport cost, in the Portuguese regions, was proven and as such the\nexistence of agglomeration in Portugal.\n"
    },
    {
        "paper_id": 1110.5544,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "The Verdoorn Law in the Portuguese Regions: A Panel Data Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work aims to test the Verdoorn Law, with the alternative specifications\nof (1)Kaldor (1966), for five regions (NUTS II) Portuguese from 1986 to 1994\nand for the 28 NUTS III Portuguese in the period 1995 to 1999. Will, therefore,\nto analyze the existence of increasing returns to scale that characterize the\nphenomena of polarization with circular and cumulative causes and can explain\nthe processes of regional divergence. It is intended to test, even in this\nwork, the alternative interpretation of (2)Rowthorn (1975) Verdoorn's Law for\nthe same regions and periods. The results of this work will be complemented\nwith estimates of these relationships to other sectors of the economy than the\nindustry (primary and services sector), for each of the manufacturing\nindustries operating in the Portuguese regions and for the total economy of\neach region (3)(Martinho, 2011).\n"
    },
    {
        "paper_id": 1110.5548,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "An Alternative Use of the Verdoorn Law at the Portuguese NUTs II Level",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With this study we want to test the validity of the well known \"Verdoorn's\nLaw\" which considers the relationship between the growth of productivity and\noutput in the case of the Portuguese economy at a regional and sectoral levels\n(NUTs II) for the period 1995-1999. The importance of some additional variables\nin the original specification of Verdoorn's Law is also tested, such as, trade\nflows, capital accumulation and labour concentration. The main objective of the\nstudy is to confirm the presence of economies to scale that characterise the\npolarisation process with cumulative causation properties, explaining regional\ndivergence. By introducing new variables to the original specification of\nVerdoorn's Law we intend to examine how the economies to scale are influenced\nby the consideration of factors related to the Polarisation (Keynensian\ntradition) and Agglomeration (spatial economics tradition) phenomena. The\nresults obtained from the regression analysis based on panel estimation show\nthat the original specification of Verdoorn's Law is more robust and confirm\nthe presence of increasing economies to scale at both, regional and sectoral\nlevels. However, the additional variables related to trade flows, capital\naccumulation and labour concentration have few influence on the performance of\neconomies to scale (1)(Martinho, 2011).\n"
    },
    {
        "paper_id": 1110.5552,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Sectoral Convergence in Output Per Worker Between Portuguese Regions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to present a further contribution to the analysis of\nabsolute convergence (and), associated with the neoclassical theory, and\nconditional, associated with endogenous growth theory, of the sectoral\nproductivity at regional level. Presenting some empirical evidence of absolute\nconvergence of productivity for each of the economic sectors and industries in\neach of the regions of mainland Portugal (NUTS II and NUTS III) in the period\n1986 to 1994 and from 1995 to 1999. The finest spatial unit NUTS III is only\nconsidered for each of the economic sectors in the period 1995 to 1999. They\nare also presented empirical evidence of conditional convergence of\nproductivity, but only for each of the economic sectors of the NUTS II of\nPortugal, from 1995 to 1999. The structural variables used in the analysis of\nconditional convergence is the ratio of capital/output, the flow of\ngoods/output and location ratio. The main conclusions should be noted that the\nsigns of convergence are stronger in the first period than in the second and\nthat convergence is conditional, especially in industry and in all sectors\n(1)(Martinho, 2011).\n"
    },
    {
        "paper_id": 1110.5556,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Spatial Effects in Convergence of Portuguese Product",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study analyses, through cross-section estimation methods, the influence\nof spatial effects in the conditional product convergence in the parishes'\neconomies of mainland Portugal between 1991 and 2001 (the last year with data\navailable for this spatial disaggregation level). To analyse the data, Moran's\nI statistics is considered, and it is stated that product is subject to\npositive spatial autocorrelation (product develops in a similar manner to\nproduct in neighbouring regions). Taking into account the estimation results,\nit is stated that there are not indications of convergence (the population is\nin the littoral of Portugal) and it can be seen that spatial spillover effects,\nspatial lag (capturing spatial autocorrelation through a spatially lagged\ndependent variable) and spatial error (capturing spatial autocorrelation\nthrough a spatially lagged error term) condition the convergence of product of\nPortuguese parishes in the period under consideration (1)(Martinho, 2011).\n"
    },
    {
        "paper_id": 1110.5557,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Polarization Versus Agglomeration",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to analyze the processes of polarization and\nagglomeration, to explain the mechanisms and causes of these phenomena in order\nto identify similarities and differences. As the main implication of this study\nshould be noted that both process pretend to explain the concentration of\neconomic activity and population in certain places, through cumulative\nphenomena, but with different perspectives, in other words, the polarization\nwith a view of economic development and agglomeration with a perspective of\nspace.\n"
    },
    {
        "paper_id": 1110.5558,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Geographic Concentration in Portugal and Regional Specific Factors",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper pretends to analyze the importance which the natural advantages\nand local resources are in the manufacturing industry location, in relation\nwith the \"spillovers\" effects and industrial policies. To this, we estimate the\nRybczynski equation matrix for the various manufacturing industries in\nPortugal, at regional level (NUTS II) and for the period 1980 to 1999.\nEstimations are displayed with the model mentioned and for four different\nperiods, namely 1980 to 1985, from 1986 to 1994, from 1980 to 1994 and from\n1995 to 1999. The consideration of the various periods until 1994, aims to\ncapture the effects of our entrance at the, in that time, EEC (European\nEconomic Community) and the consideration of a period from 1995 is because the\nchange in methodology for compiling statistical data taken from this time in\nPortugal. As a summary conclusion, noted that the location of manufacturing in\nPortugal is still mostly explained by specific factors, with a tendency to\nincrease in some cases the explanation by these factors, having the effect\n\"spillovers\" and industrial policies little importance in this context.\n"
    },
    {
        "paper_id": 1110.5559,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Regional Agglomeration in Portugal: A Linear Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work aims to study the Portuguese regional agglomeration process, using\nthe linear form the New Economic Geography models that emphasize the importance\nof spatial factors (distance, costs of transport and communication) in\nexplaining of the concentration of economic activity in certain locations. In a\ntheoretical context, it is intended to explain the complementarily of\nclustering models, associated with the New Economic Geography, and polarization\nassociated with the Keynesian tradition, describing the mechanisms by which\nthese processes are based. As a summary conclusion, we can say which the\nagglomeration process shows some signs of concentration in Lisboa e Vale do\nTejo (which is evidence of regional divergence in Portugal) and the\nproductivity factor significantly improves the results that explain the\nregional clustering in Portugal (despite being ignored in the models of New\nEconomic Geography).\n"
    },
    {
        "paper_id": 1110.5564,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Analysis of Net Migration Between the Portuguese Regions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work aims mainly to present a project of research about the\nidentification of the determinants that affect the mobility of labor. The\nempirical part of the work will be performed for the NUTS II and NUTS III of\nPortugal, from 1996 to 2002 and for 1991 and 2001, respectively (given the\navailability of statistical data). As main conclusion it can be said, for the\nNUTS II (1996-2002), which is confirmed the existence of some labor mobility in\nPortugal and that regional mobility is mainly influenced positively by the\noutput growth and negatively by the unemployment rates and by the weight of the\nagricultural sector. NUTS III level (1991 and 2001) is something similar, but\nwith this level of spatial disaggregation (and in this period) the basic\nequipment (amenities), particularly in terms of availability of housing, are\nthe main determinants of migration.\n"
    },
    {
        "paper_id": 1110.5571,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Spatial Effects and Convergence Theory in the Portuguese Situation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study analyses, through cross-section estimation methods, the influence\nof spatial effects and human capital in the conditional productivity\nconvergence (product per worker) in the economic sectors of NUTs III of\nmainland Portugal between 1995 and 2002. To analyse the data, Moran's I\nstatistics is considered, and it is stated that productivity is subject to\npositive spatial autocorrelation (productivity develops in a similar manner to\nproductivity in neighbouring regions), above all, in agriculture and services.\nIndustry and the total of all sectors present indications that they are subject\nto positive spatial autocorrelation in productivity. On the other hand, it is\nstated that the indications of convergence, specifically bearing in mind the\nconcept of absolute convergence, are greater in industry. Taking into account\nthe estimation results, it is stated once again that the indications of\nconvergence are greater in industry, and it can be seen that spatial spillover\neffects, spatial lag (capturing spatial autocorrelation through a spatially\nredundant dependent variable) and spatial error (capturing spatial\nautocorrelation through a spatially redundant error term), as well as human\ncapital, condition the convergence of productivity in the various economic\nsectors of Portuguese region in the period under consideration (Martinho,\n2011).\n"
    },
    {
        "paper_id": 1110.5573,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Spatial Effects and Verdoorn Law in the Portuguese Context",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The consideration of spatial effects at a regional level is becoming\nincreasingly frequent and the work of Anselin (1988), among others, has\ncontributed to this. This study analyses, through cross-section estimation\nmethods, the influence of spatial effects in productivity (product per worker)\nin the NUTs III economic sectors of mainland Portugal from 1995 to 1999 and\nfrom 2000 to 2005 (taking in count the availability of data), considering the\nVerdoorn relationship. To analyse the data, by using Moran I statistics, it is\nstated that productivity is subject to a positive spatial autocorrelation\n(productivity of each of the regions develops in a similar manner to each of\nthe neighbouring regions), above all in services. The total of all sectors\npresent, also, indicators of being subject to positive autocorrelation in\nproductivity. Bearing in mind the results of estimations, it can been that the\neffects of spatial spillovers, spatial lags (measuring spatial autocorrelation\nthrough the spatially lagged dependent variable) and spatial error (measuring\nspatial autocorrelation through the spatially lagged error terms), influence\nthe Verdoorn relationship when it is applied to the economic sectors of\nPortuguese regions (Martinho, 2011).\n"
    },
    {
        "paper_id": 1110.5578,
        "authors": "Vitor Joao Pereira Domingues Martinho",
        "title": "Spatial Autocorrelation and Verdoorn Law in the Portuguese NUTs III",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study analyses, through cross-section estimation methods, the influence\nof spatial effects in productivity (product per worker), at economic sectors\nlevel of the NUTs III of mainland Portugal, from 1995 to 1999 and from 2000 to\n2005 (taking in count the data availability and the Portuguese and European\ncontext), considering the Verdoorn relationship. From the analyses of the data,\nby using Moran I statistics, it is stated that productivity is subject to a\npositive spatial autocorrelation (productivity of each of the regions develops\nin a similar manner to each of the neighbouring regions), above all in\nservices. The total sectors of all regional economy present, also, indicators\nof being subject to positive autocorrelation in productivity. Bearing in mind\nthe results of estimations, it can been that the effects of spatial spillovers,\nspatial lags (measuring spatial autocorrelation through the spatially lagged\ndependent variable) and spatial error (measuring spatial autocorrelation\nthrough the spatially lagged error terms), influence the Verdoorn relationship\nwhen it is applied to the economic sectors of Portuguese regions. The results\nobtained for the two periods are different, as expected, and are better in\nsecond period, because, essentially, the European and national public supports\n(Martinho, 2011).\n"
    },
    {
        "paper_id": 1110.5594,
        "authors": "Paul M. N. Feehan and Camelia A. Pop",
        "title": "Boundary-degenerate elliptic operators and Holder continuity for\n  solutions to variational equations and inequalities",
        "comments": "59 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Heston stochastic volatility process, which is widely used as an asset\nprice model in mathematical finance, is a paradigm for a degenerate diffusion\nprocess where the degeneracy in the diffusion coefficient is proportional to\nthe square root of the distance to the boundary of the half-plane. The\ngenerator of this process with killing, called the elliptic Heston operator, is\na second-order, degenerate-elliptic partial differential operator whose\ncoefficients have linear growth in the spatial variables and where the\ndegeneracy in the operator symbol is proportional to the distance to the\nboundary of the half-plane. With the aid of weighted Sobolev spaces, we prove\nsupremum bounds, a Harnack inequality, and H\\\"older continuity near the\nboundary for solutions to variational equations defined by the elliptic Heston\noperator, as well as H\\\"older continuity up to the boundary for solutions to\nvariational inequalities defined by the elliptic Heston operator. In\nmathematical finance, solutions to obstacle problems for the elliptic Heston\noperator correspond to value functions for perpetual American-style options on\nthe underlying asset.\n"
    },
    {
        "paper_id": 1110.5789,
        "authors": "Nicholas G. Polson and James G. Scott",
        "title": "An empirical test for Eurozone contagion using an asset-pricing model\n  with heavy-tailed stochastic volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes an empirical test of financial contagion in European\nequity markets during the tumultuous period of 2008-2011. Our analysis shows\nthat traditional GARCH and Gaussian stochastic-volatility models are unable to\nexplain two key stylized features of global markets during presumptive\ncontagion periods: shocks to aggregate market volatility can be sudden and\nexplosive, and they are associated with specific directional biases in the\ncross-section of country-level returns. Our model repairs this deficit by\nassuming that the random shocks to volatility are heavy-tailed and correlated\ncross-sectionally, both with each other and with returns. The fundamental\nconclusion of our analysis is that great care is needed in modeling volatility\nif one wishes to characterize the relationship between volatility and contagion\nthat is predicted by economic theory.\n  In analyzing daily data, we find evidence for significant contagion effects\nduring the major EU crisis periods of May 2010 and August 2011, where contagion\nis defined as excess correlation in the residuals from a factor model\nincorporating global and regional market risk factors. Some of this excess\ncorrelation can be explained by quantifying the impact of shocks to aggregate\nvolatility in the cross-section of expected returns - but only, it turns out,\nif one is extremely careful in accounting for the explosive nature of these\nshocks. We show that global markets have time-varying cross-sectional\nsensitivities to these shocks, and that high sensitivities strongly predict\nperiods of financial crisis. Moreover, the pattern of temporal changes in\ncorrelation structure between volatility and returns is readily interpretable\nin terms of the major events of the periods in question.\n"
    },
    {
        "paper_id": 1110.5846,
        "authors": "Thomas R. Hurd and Zhuowei Zhou",
        "title": "Two-factor capital structure models for equity and credit",
        "comments": "26 pages, 9 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend the now classic structural credit modeling approach of Black and\nCox to a class of \"two-factor\" models that unify equity securities such as\noptions written on the stock price, and credit products like bonds and credit\ndefault swaps. In our approach, the two sides of the stylized balance sheet of\na firm, namely the asset value and debt value, are assumed to follow a two\ndimensional Markov process. Amongst models of this type we find examples that\nlead to derivative pricing formulas that are capable of reproducing the main\nfeatures of well known equity models such as the variance gamma model, and at\nthe same time reproducing the stylized facts about default stemming from\nstructural models of credit risk. Moreover, in contrast to one-factor\nstructural models, these models allow for much more flexible dependence between\nequity and credit markets. Two main technical obstacles to efficient\nimplementation of these pricing formulas are overcome in our paper. The first\nobstacle stems from the barrier condition implied by the non-default of the\nfirm, and is overcome by the idea of time-changing Brownian motion in a way\nthat preserves the reflection principle for Brownian motion. The second\nobstacle is the difficulty of computing spread options: this is overcome by\nusing results in recent papers that make efficient use of the two dimensional\nFast Fourier Transform.\n"
    },
    {
        "paper_id": 1110.617,
        "authors": "Paul Lescot (LMRS)",
        "title": "Symmetries of the Black-Scholes equation",
        "comments": null,
        "journal-ref": "Methods Appl. Anal. 19, 2 (2012) 147--160",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We determine the algebra of isovectors for the Black--Scholes equation. As a\nconsequence, we obtain some previously unknown families of transformations on\nthe solutions.\n"
    },
    {
        "paper_id": 1110.6289,
        "authors": "Vladimir Cherny and Jan Obloj",
        "title": "Portfolio optimisation under non-linear drawdown constraints in a\n  semimartingale financial model",
        "comments": "Updated version to appear in Finance and Stochastics, 31 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A drawdown constraint forces the current wealth to remain above a given\nfunction of its maximum to date. We consider the portfolio optimisation problem\nof maximising the long-term growth rate of the expected utility of wealth\nsubject to a drawdown constraint, as in the original setup of Grossman and Zhou\n(1993). We work in an abstract semimartingale financial market model with a\ngeneral class of utility functions and drawdown constraints. We solve the\nproblem by showing that it is in fact equivalent to an unconstrained problem\nwith a suitably modified utility function. Both the value function and the\noptimal investment policy for the drawdown problem are given explicitly in\nterms of their counterparts in the unconstrained problem.\n"
    },
    {
        "paper_id": 1110.6322,
        "authors": "Joan del Castillo and Juan-Pablo Ortega",
        "title": "Hedging of time discrete auto-regressive stochastic volatility options",
        "comments": "25 pages, 3 color figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Numerous empirical proofs indicate the adequacy of the time discrete\nauto-regressive stochastic volatility models introduced by Taylor in the\ndescription of the log-returns of financial assets. The pricing and hedging of\ncontingent products that use these models for their underlying assets is a\nnon-trivial exercise due to the incomplete nature of the corresponding market.\nIn this paper we apply two volatility estimation techniques available in the\nliterature for these models, namely Kalman filtering and the\nhierarchical-likelihood approach, in order to implement various pricing and\ndynamical hedging strategies. Our study shows that the local risk minimization\nscheme developed by F\\\"ollmer, Schweizer, and Sondermann is particularly\nappropriate in this setup, especially for at and in the money options or for\nlow hedging frequencies.\n"
    },
    {
        "paper_id": 1110.6553,
        "authors": "Lawrence R. Thorne",
        "title": "Fat Tails Quantified and Resolved: A New Distribution to Reveal and\n  Characterize the Risk and Opportunity Inherent in Leptokurtic Data",
        "comments": "26 pages, 9 figures & 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I report a new statistical distribution formulated to confront the infamous,\nlong-standing, computational/modeling challenge presented by highly skewed\nand/or leptokurtic (\"fat- or heavy-tailed\") data. The distribution is\nstraightforward, flexible and effective. Even when working with far fewer data\npoints than are routinely required, it models non-Gaussian data samples, from\npeak center through far tails, within the context of a single probability\ndensity function (PDF) that is valid over an extremely broad range of\ndispersions and probability densities. The distribution is a precision tool to\ncharacterize the great risk and the great opportunity inherent in fat-tailed\ndata.\n"
    },
    {
        "paper_id": 1110.6679,
        "authors": "Y. Ikeda, H. Aoyama, Y. Fujiwara, H. Iyetomi, K. Ogimoto, W. Souma,\n  and H. Yoshikawa",
        "title": "Coupled Oscillator Model of the Business Cycle with Fluctuating Goods\n  Markets",
        "comments": "Presented at Econophysics 2011, the Yukawa Institute for Theoretical\n  Physics at Kyoto University. Submitted to Progress of Theoretical Physics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The sectoral synchronization observed for the Japanese business cycle in the\nIndices of Industrial Production data is an example of synchronization. The\nstability of this synchronization under a shock, e.g., fluctuation of supply or\ndemand, is a matter of interest in physics and economics. We consider an\neconomic system made up of industry sectors and goods markets in order to\nanalyze the sectoral synchronization observed for the Japanese business cycle.\nA coupled oscillator model that exhibits synchronization is developed based on\nthe Kuramoto model with inertia by adding goods markets, and analytic solutions\nof the stationary state and the coupling strength are obtained. We simulate the\neffects on synchronization of a sectoral shock for systems with different price\nelasticities and the coupling strengths. Synchronization is reproduced as an\nequilibrium solution in a nearest neighbor graph. Analysis of the order\nparameters shows that the synchronization is stable for a finite elasticity,\nwhereas the synchronization is broken and the oscillators behave like a giant\noscillator with a certain frequency additional to the common frequency for zero\nelasticity.\n"
    },
    {
        "paper_id": 1111.0389,
        "authors": "Mohammad Sharifzadeh, Simin Hojat",
        "title": "An analytical performance comparison of exchanged traded funds with\n  index funds: 2002-2010",
        "comments": "This paper has been submitted to the Journal of Asset Management",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Exchange Traded Funds (ETFs) have been gaining increasing popularity in the\ninvestment community as is evidenced by the high growth both in the number of\nETFs and their net assets since 2000. As ETFs are in nature similar to index\nmutual funds, in this paper we examined if this growing demand for ETFs can be\nexplained through their outperformance as compared to index mutual funds. We\nconsidered the population of all ETFs with inception dates prior to 2002 and\nthen for each ETF found all the passive index mutual funds that had the same\ninvestment style as the selected ETF and had inception date prior to 2002.\nWithin each investment style we matched every ETF with all the passive index\nfunds in that investment style and compared the performances of the matched\npairs in terms of Sharp Ratios and risk adjusted buy and hold total returns for\nthe period 2002-2010. We then applied the Wilcoxon signed rank test to examine\nif ETFs had better performances than index mutual funds during the sample\nperiod. Out of the 230 paired matches of all the styles, ETFs outperformed\nindex mutual funds in 134 of the times in terms of Sharpe Ratio, however, the\ntest of the hypothesis showed no statistically significant difference between\nETFs and index funds performances in terms of Sharpe ratio. Out of the 230\npaired matches of all the styles, ETFs outperformed index mutual funds in 125\nof the times in terms of risk adjusted buy and hold total return, however, the\ntest of hypothesis showed no statistically significant difference between ETFs\nand index funds performances in terms of risk adjusted buy and hold total\nreturn. These findings indicate there is statistically no significant\ndifference between ETFs and passive index mutual funds performances at the fund\nlevel and investors' choice between the two is related to product\ncharacteristics and tax advantages.\n"
    },
    {
        "paper_id": 1111.0818,
        "authors": "Ying Hu, Hanqing Jin and Xun Yu Zhou",
        "title": "Time-Inconsistent Stochastic Linear--Quadratic Control",
        "comments": "24 pages. To be submitted to SICON",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we formulate a general time-inconsistent stochastic\nlinear--quadratic (LQ) control problem. The time-inconsistency arises from the\npresence of a quadratic term of the expected state as well as a state-dependent\nterm in the objective functional. We define an equilibrium, instead of optimal,\nsolution within the class of open-loop controls, and derive a sufficient\ncondition for equilibrium controls via a flow of forward--backward stochastic\ndifferential equations. When the state is one dimensional and the coefficients\nin the problem are all deterministic, we find an explicit equilibrium control.\nAs an application, we then consider a mean-variance portfolio selection model\nin a complete financial market where the risk-free rate is a deterministic\nfunction of time but all the other market parameters are possibly stochastic\nprocesses. Applying the general sufficient condition, we obtain explicit\nequilibrium strategies when the risk premium is both deterministic and\nstochastic.\n"
    },
    {
        "paper_id": 1111.1113,
        "authors": "Jean-Philippe Bruneton",
        "title": "Copula-based Hierarchical Aggregation of Correlated Risks. The behaviour\n  of the diversification benefit in Gaussian and Lognormal Trees",
        "comments": "38 pages, 7 figures; Version 2: added contact information. Submitted\n  to Finance and Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The benefits of diversifying risks are difficult to estimate quantitatively\nbecause of the uncertainties in the dependence structure between the risks.\nAlso, the modelling of multidimensional dependencies is a non-trivial task.\nThis paper focuses on one such technique for portfolio aggregation, namely the\naggregation of risks within trees, where dependencies are set at each step of\nthe aggregation with the help of some copulas. We define rigorously this\nprocedure and then study extensively the Gaussian Tree of quite arbitrary size\nand shape, where individual risks are normal, and where the Gaussian copula is\nused. We derive exact analytical results for the diversification benefit of the\nGaussian tree as a function of its shape and of the dependency parameters.\n  Such a \"toy-model\" of an aggregation tree enables one to understand the basic\nphenomena's at play while aggregating risks in this way. In particular, it is\nshown that, for a fixed number of individual risks, \"thin\" trees diversify\nbetter than \"fat\" trees. Related to this, it is shown that hierarchical trees\nhave the natural tendency to lower the overall dependency with respect to the\ndependency parameter chosen at each step of the aggregation. We also show that\nthese results hold in more general cases outside the gaussian world, and apply\nnotably to more realistic portfolios (LogNormal trees). We believe that any\ninsurer or reinsurer using such a tool should be aware of these systematic\neffects, and that this awareness should strongly call for designing trees that\nadequately fit the business.\n  We finally address the issue of specifying the full joint distribution\nbetween the risks. We show that the hierarchical mechanism does not require nor\nspecify the joint distribution, but that the latter can be determined exactly\n(in the Gaussian case) by adding conditional independence hypotheses between\nthe risks and their sums.\n"
    },
    {
        "paper_id": 1111.1133,
        "authors": "Xi Luo",
        "title": "Recovering Model Structures from Large Low Rank and Sparse Covariance\n  Matrix Estimation",
        "comments": "35 pages, 3 figures. Presented at JSM 2011 and various invited\n  seminars since February, 2011. R package available from\n  http://cran.r-project.org/web/packages/lorec/index.html",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many popular statistical models, such as factor and random effects models,\ngive arise a certain type of covariance structures that is a summation of low\nrank and sparse matrices. This paper introduces a penalized approximation\nframework to recover such model structures from large covariance matrix\nestimation. We propose an estimator based on minimizing a non-likelihood loss\nwith separable non-smooth penalty functions. This estimator is shown to recover\nexactly the rank and sparsity patterns of these two components, and thus\npartially recovers the model structures. Convergence rates under various matrix\nnorms are also presented. To compute this estimator, we further develop a\nfirst-order iterative algorithm to solve a convex optimization problem that\ncontains separa- ble non-smooth functions, and the algorithm is shown to\nproduce a solution within O(1/t^2) of the optimal, after any finite t\niterations. Numerical performance is illustrated using simulated data and stock\nportfolio selection on S&P 100.\n"
    },
    {
        "paper_id": 1111.1331,
        "authors": "Damiano Brigo",
        "title": "Counterparty Risk FAQ: Credit VaR, PFE, CVA, DVA, Closeout, Netting,\n  Collateral, Re-hypothecation, WWR, Basel, Funding, CCDS and Margin Lending",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a dialogue on Counterparty Credit Risk touching on Credit Value at\nRisk (Credit VaR), Potential Future Exposure (PFE), Expected Exposure (EE),\nExpected Positive Exposure (EPE), Credit Valuation Adjustment (CVA), Debit\nValuation Adjustment (DVA), DVA Hedging, Closeout conventions, Netting clauses,\nCollateral modeling, Gap Risk, Re-hypothecation, Wrong Way Risk, Basel III,\ninclusion of Funding costs, First to Default risk, Contingent Credit Default\nSwaps (CCDS) and CVA restructuring possibilities through margin lending. The\ndialogue is in the form of a Q&A between a CVA expert and a newly hired\ncolleague.\n"
    },
    {
        "paper_id": 1111.1349,
        "authors": "Areski Cousin (SAF), Elena Di Bernadino (SAF)",
        "title": "On Multivariate Extensions of Value-at-Risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we introduce two alternative extensions of the classical\nunivariate Value-at-Risk (VaR) in a multivariate setting. The two proposed\nmultivariate VaR are vector-valued measures with the same dimension as the\nunderlying risk portfolio. The lower-orthant VaR is constructed from level sets\nof multivariate distribution functions whereas the upper-orthant VaR is\nconstructed from level sets of multivariate survival functions. Several\nproperties have been derived. In particular, we show that these risk measures\nboth satisfy the positive homogeneity and the translation invariance property.\nComparison between univariate risk measures and components of multivariate VaR\nare provided. We also analyze how these measures are impacted by a change in\nmarginal distributions, by a change in dependence structure and by a change in\nrisk level. Illustrations are given in the class of Archimedean copulas.\n"
    },
    {
        "paper_id": 1111.2038,
        "authors": "Lester Alfonso, Ricardo Mansilla, and Cesar A. Terrero-Escalante",
        "title": "On the scaling of the distribution of daily price fluctuations in\n  Mexican financial market index",
        "comments": "13 pages, 4 figures, 4 tables",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2012.01.023",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, a statistical analysis of log-return fluctuations of the IPC,\nthe Mexican Stock Market Index is presented. A sample of daily data covering\nthe period from $04/09/2000-04/09/2010$ was analyzed, and fitted to different\ndistributions. Tests of the goodness of fit were performed in order to\nquantitatively asses the quality of the estimation. Special attention was paid\nto the impact of the size of the sample on the estimated decay of the\ndistributions tail. In this study a forceful rejection of normality was\nobtained. On the other hand, the null hypothesis that the log-fluctuations are\nfitted to a $\\alpha$-stable L\\'evy distribution cannot be rejected at 5%\nsignificance level.\n"
    },
    {
        "paper_id": 1111.2091,
        "authors": "Noureddine El Karoui, Andrew E. B. Lim, and Gah-Yi Vahn",
        "title": "Performance-based regularization in mean-CVaR portfolio optimization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce performance-based regularization (PBR), a new approach to\naddressing estimation risk in data-driven optimization, to mean-CVaR portfolio\noptimization. We assume the available log-return data is iid, and detail the\napproach for two cases: nonparametric and parametric (the log-return\ndistribution belongs in the elliptical family). The nonparametric PBR method\npenalizes portfolios with large variability in mean and CVaR estimations. The\nparametric PBR method solves the empirical Markowitz problem instead of the\nempirical mean-CVaR problem, as the solutions of the Markowitz and mean-CVaR\nproblems are equivalent when the log-return distribution is elliptical. We\nderive the asymptotic behavior of the nonparametric PBR solution, which leads\nto insight into the effect of penalization, and justification of the parametric\nPBR method. We also show via simulations that the PBR methods produce efficient\nfrontiers that are, on average, closer to the population efficient frontier\nthan the empirical approach to the mean-CVaR problem, with less variability.\n"
    },
    {
        "paper_id": 1111.2169,
        "authors": "Dorje C. Brody, Lane P. Hughston, Ewan Mackie",
        "title": "General Theory of Geometric L\\'evy Models for Dynamic Asset Pricing",
        "comments": "20 pages, version to appear in Proceedings of the Royal Society\n  London A",
        "journal-ref": "Proc. R. Soc. A June 8, 2012 468 1778-1798",
        "doi": "10.1098/rspa.2011.0670",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The geometric L\\'evy model (GLM) is a natural generalisation of the geometric\nBrownian motion model (GBM) used in the derivation of the Black-Scholes\nformula. The theory of such models simplifies considerably if one takes a\npricing kernel approach. In one dimension, once the underlying L\\'evy process\nhas been specified, the GLM has four parameters: the initial price, the\ninterest rate, the volatility, and the risk aversion. The pricing kernel is the\nproduct of a discount factor and a risk aversion martingale. For GBM, the risk\naversion parameter is the market price of risk. For a GLM, this interpretation\nis not valid: the excess rate of return is a nonlinear function of the\nvolatility and the risk aversion. It is shown that for positive volatility and\nrisk aversion the excess rate of return above the interest rate is positive,\nand is increasing with respect to these variables. In the case of foreign\nexchange, Siegel's paradox implies that one can construct foreign exchange\nmodels for which the excess rate of return is positive both for the exchange\nrate and the inverse exchange rate. This condition is shown to hold for any\ngeometric L\\'evy model for foreign exchange in which volatility exceeds risk\naversion.\n"
    },
    {
        "paper_id": 1111.2462,
        "authors": "J. D. Deuschel, P. K. Friz, A. Jacquier, S. Violante",
        "title": "Marginal density expansions for diffusions and stochastic volatility,\n  part I: Theoretical Foundations",
        "comments": "2 figures; to appear in Comm. Pure Appl. Math",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Density expansions for hypoelliptic diffusions $(X^1,...,X^d)$ are revisited.\nIn particular, we are interested in density expansions of the projection\n$(X_T^1,...,X_T^l)$, at time $T>0$, with $l \\leq d$. Global conditions are\nfound which replace the well-known \"not-in-cutlocus\" condition known from\nheat-kernel asymptotics. Our small noise expansion allows for a \"second order\"\nexponential factor. As application, new light is shed on the Takanobu--Watanabe\nexpansion of Brownian motion and Levy's stochastic area. Further applications\ninclude tail and implied volatility asymptotics in some stochastic volatility\nmodels, discussed in a compagnion paper.\n"
    },
    {
        "paper_id": 1111.2584,
        "authors": "Zhuo Jin, George Yin, and Chao Zhu",
        "title": "Numerical Solutions of Optimal Risk Control and Dividend Optimization\n  Policies under A Generalized Singular Control Formulation",
        "comments": "Key words: Singular control, dividend policy, Markov chain\n  approximation, numerical method, reinsurance, regime switching",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper develops numerical methods for finding optimal dividend pay-out\nand reinsurance policies. A generalized singular control formulation of surplus\nand discounted payoff function are introduced, where the surplus is modeled by\na regime-switching process subject to both regular and singular controls. To\napproximate the value function and optimal controls, Markov chain approximation\ntechniques are used to construct a discrete-time controlled Markov chain with\ntwo components. The proofs of the convergence of the approximation sequence to\nthe surplus process and the value function are given. Examples of proportional\nand excess-of-loss reinsurance are presented to illustrate the applicability of\nthe numerical methods.\n"
    },
    {
        "paper_id": 1111.2683,
        "authors": "K. Milanov and O. Kounchev",
        "title": "Critical Analysis of the Binomial-Tree approach to Convertible Bonds in\n  the framework of Tsiveriotis-Fernandes model",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper we show that the Binomial-tree approach for pricing,\nhedging, and risk assessment of Convertible bonds in the framework of the\nTsiveriotis-Fernandes model has serious drawbacks. Key words: Convertible\nbonds, Binomial tree, Tsiveriotis-Fernandes model, Convertible bond pricing,\nConvertible bond Greeks, Convertible Arbitrage, Delta-hedging of Convertible\nbonds, Risk Assessment of Convertible bonds.\n"
    },
    {
        "paper_id": 1111.2846,
        "authors": "Vladimir Vovk",
        "title": "A simplified Capital Asset Pricing Model",
        "comments": "6 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a Black-Scholes market in which a number of stocks and an index\nare traded. The simplified Capital Asset Pricing Model is the conjunction of\nthe usual Capital Asset Pricing Model, or CAPM, and the statement that the\nappreciation rate of the index is equal to its squared volatility plus the\ninterest rate. (The mathematical statement of the conjunction is simpler than\nthat of the usual CAPM.) Our main result is that either we can outperform the\nindex or the simplified CAPM holds.\n"
    },
    {
        "paper_id": 1111.2976,
        "authors": "Boris Ettinger, Steven N. Evans, Alexandru Hening",
        "title": "Killed Brownian motion with a prescribed lifetime distribution and\n  models of default",
        "comments": "Published in at http://dx.doi.org/10.1214/12-AAP902 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 1, 1-33",
        "doi": "10.1214/12-AAP902",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The inverse first passage time problem asks whether, for a Brownian motion\n$B$ and a nonnegative random variable $\\zeta$, there exists a time-varying\nbarrier $b$ such that $\\mathbb{P}\\{B_s>b(s),0\\leq s\\leq\nt\\}=\\mathbb{P}\\{\\zeta>t\\}$. We study a \"smoothed\" version of this problem and\nask whether there is a \"barrier\" $b$ such that $\n\\mathbb{E}[\\exp(-\\lambda\\int_0^t\\psi(B_s-b(s))\\,ds)]=\\mathbb{P}\\{\\zeta >t\\}$,\nwhere $\\lambda$ is a killing rate parameter, and $\\psi:\\mathbb{R}\\to[0,1]$ is a\nnonincreasing function. We prove that if $\\psi$ is suitably smooth, the\nfunction $t\\mapsto \\mathbb{P}\\{\\zeta>t\\}$ is twice continuously differentiable,\nand the condition $0<-\\frac{d\\log\\mathbb{P}\\{\\zeta>t\\}}{dt}<\\lambda$ holds for\nthe hazard rate of $\\zeta$, then there exists a unique continuously\ndifferentiable function $b$ solving the smoothed problem. We show how this\nresult leads to flexible models of default for which it is possible to compute\nexpected values of contingent claims.\n"
    },
    {
        "paper_id": 1111.3035,
        "authors": "Andreas Hula",
        "title": "Sustainable Credit And Interest Rates",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With negative growth in real production in many countries and debt levels\nwhich become an increasing burden on developed societies, the calls for a\nchange in economic policy and even the monetary system become louder and\nincreasingly impatient. We research the consequences of a system of credit and\ndebt, that still allows for the expansion of credit and fundamentally retains\nmany features of the present monetary system, without the instability inherent\nin the present system.\n"
    },
    {
        "paper_id": 1111.3127,
        "authors": "Argimiro Arratia and Alejandra Caba\\~na",
        "title": "Tracing the temporal evolution of clusters in a financial stock market",
        "comments": "22 pages, 3 figures (submitted for publication)",
        "journal-ref": null,
        "doi": "10.1007/s10614-012-9327-x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a methodology for clustering financial time series of stocks'\nreturns, and a graphical set-up to quantify and visualise the evolution of\nthese clusters through time. The proposed graphical representation allows for\nthe application of well known algorithms for solving classical combinatorial\ngraph problems, which can be interpreted as problems relevant to portfolio\ndesign and investment strategies. We illustrate this graph representation of\nthe evolution of clusters in time and its use on real data from the Madrid\nStock Exchange market.\n"
    },
    {
        "paper_id": 1111.3263,
        "authors": "Aleksander Stanislavsky",
        "title": "Black-Scholes model under subordination",
        "comments": "8 pages",
        "journal-ref": "Physica A 318, 469(2003)",
        "doi": "10.1016/S0378-4371(02)01372-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider a new mathematical extension of the Black-Scholes\nmodel in which the stochastic time and stock share price evolution is described\nby two independent random processes. The parent process is Brownian, and the\ndirecting process is inverse to the totally skewed, strictly \\alpha-stable\nprocess. The subordinated process represents the Brownian motion indexed by an\nindependent, continuous and increasing process. This allows us to introduce the\nlong-term memory effects in the classical Black-Scholes model.\n"
    },
    {
        "paper_id": 1111.3757,
        "authors": "Dorje C. Brody, Lane P. Hughston",
        "title": "Interest Rates and Information Geometry",
        "comments": "20 pages, 3 figures",
        "journal-ref": "Proc. R. Soc. Lond. A (2001) 457, 1343-1363",
        "doi": "10.1098/rspa.2000.0722",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The space of probability distributions on a given sample space possesses\nnatural geometric properties. For example, in the case of a smooth parametric\nfamily of probability distributions on the real line, the parameter space has a\nRiemannian structure induced by the embedding of the family into the Hilbert\nspace of square-integrable functions, and is characterised by the Fisher-Rao\nmetric. In the nonparametric case the relevant geometry is determined by the\nspherical distance function of Bhattacharyya. In the context of term structure\nmodelling, we show that minus the derivative of the discount function with\nrespect to the maturity date gives rise to a probability density. This follows\nas a consequence of the positivity of interest rates. Therefore, by mapping the\ndensity functions associated with a given family of term structures to Hilbert\nspace, the resulting metrical geometry can be used to analyse the relationship\nof yield curves to one another. We show that the general arbitrage-free yield\ncurve dynamics can be represented as a process taking values in the convex\nspace of smooth density functions on the positive real line. It follows that\nthe theory of interest rate dynamics can be represented by a class of processes\nin Hilbert space. We also derive the dynamics for the central moments\nassociated with the distribution determined by the yield curve.\n"
    },
    {
        "paper_id": 1111.3856,
        "authors": "Vicky Henderson, Gechun Liang",
        "title": "A Multidimensional Exponential Utility Indifference Pricing Model with\n  Applications to Counterparty Risk",
        "comments": "29 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers exponential utility indifference pricing for a\nmultidimensional non-traded assets model subject to inter-temporal default\nrisk, and provides a semigroup approximation for the utility indifference\nprice. The key tool is the splitting method, whose convergence is proved based\non the Barles-Souganidis monotone scheme, and the convergence rate is derived\nbased on Krylov's shaking the coefficients technique. We apply our methodology\nto study the counterparty risk of derivatives in incomplete markets.\n"
    },
    {
        "paper_id": 1111.3885,
        "authors": "Peter Imkeller and Nicolas Perkowski",
        "title": "The Existence of Dominating Local Martingale Measures",
        "comments": "32 pages; revised version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove that, for locally bounded processes, absence of arbitrage\nopportunities of the first kind is equivalent to the existence of a dominating\nlocal martingale measure. This is related to and motivated by results from the\ntheory of filtration enlargements.\n"
    },
    {
        "paper_id": 1111.4087,
        "authors": "Tinne Haentjens and Karel J. in 't Hout",
        "title": "ADI finite difference schemes for the Heston-Hull-White PDE",
        "comments": null,
        "journal-ref": "The Journal of Computational Finance 16, 83-110 (2012)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we investigate the effectiveness of Alternating Direction\nImplicit (ADI) time discretization schemes in the numerical solution of the\nthree-dimensional Heston-Hull-White partial differential equation, which is\nsemidiscretized by applying finite difference schemes on nonuniform spatial\ngrids. We consider the Heston-Hull-White model with arbitrary correlation\nfactors, with time-dependent mean-reversion levels, with short and long\nmaturities, for cases where the Feller condition is satisfied and for cases\nwhere it is not. In addition, both European-style call options and up-and-out\ncall options are considered. It is shown through extensive tests that ADI\nschemes, with a proper choice of their parameters, perform very well in all\nsituations - in terms of stability, accuracy and efficiency.\n"
    },
    {
        "paper_id": 1111.4298,
        "authors": "Wei Chen",
        "title": "Time Consistent Bid-Ask Dynamic Pricing Mechanisms for Contingent Claims\n  and Its Numerical Simulations Under Uncertainty",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study time consistent dynamic pricing mechanisms of European contingent\nclaims under uncertainty by using G framework introduced by Peng ([24]). We\nconsider a financial market consisting of a riskless asset and a risky stock\nwith price process modelled by a geometric generalized G-Brownian motion, which\nfeatures the drift uncertainty and volatility uncertainty of the stock price\nprocess. Using the techniques on G-framework we show that the risk premium of\nthe asset is uncertain and distributed with maximum distribution. A time\nconsistent G-expectation is defined by the viscosity solution of the G-heat\nequation. Using the time consistent G-expectation we define the G dynamic\npricing mechanism for the claim. We prove that G dynamic pricing mechanism is\nthe bid-ask Markovian dynamic pricing mechanism. The full nonlinear PDE is\nderived to describe the bid (resp. ask) price process of the claim. Monotone\nimplicit characteristic finite difference schemes for the nonlinear PDE are\ngiven, nonlinear iterative schemes are constructed, and the simulations of the\nbid (resp. ask) prices of contingent claims under uncertainty are implemented.\n"
    },
    {
        "paper_id": 1111.4414,
        "authors": "Dominique Gu\\'egan, Wayne Tarrant",
        "title": "On the Necessity of Five Risk Measures",
        "comments": "23 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The banking systems that deal with risk management depend on underlying risk\nmeasures. Following the Basel II accord, there are two separate methods by\nwhich banks may determine their capital requirement. The Value at Risk measure\nplays an important role in computing the capital for both approaches. In this\npaper we analyze the errors produced by using this measure. We discuss other\nmeasures, demonstrating their strengths and shortcomings. We give examples,\nshowing the need for the information from multiple risk measures in order to\ndetermine a bank's loss distribution. We conclude by suggesting a regulatory\nrequirement of multiple risk measures being reported by banks, giving specific\nrecommendations.\n"
    },
    {
        "paper_id": 1111.4417,
        "authors": "Dominique Gu/'egan, Wayne Tarrant",
        "title": "Viewing Risk Measures as Information",
        "comments": "14 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Regulation and risk management in banks depend on underlying risk measures.\nIn general this is the only purpose that is seen for risk measures. In this\npaper we suggest that the reporting of risk measures can be used to determine\nthe loss distribution function for a financial entity. We demonstrate that a\nlack of sufficient information can lead to ambiguous risk situations. We give\nexamples, showing the need for the reporting of multiple risk measures in order\nto determine a bank's loss distribution. We conclude by suggesting a regulatory\nrequirement of multiple risk measures being reported by banks, giving specific\nrecommendations.\n"
    },
    {
        "paper_id": 1111.4421,
        "authors": "Wayne Tarrant",
        "title": "Historical risk measures on stock market indices and energy markets",
        "comments": "11 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we look at the efficacy of different risk measures on energy\nmarkets and across several different stock market indices. We use both the\nValue at Risk and the Tail Conditional Expectation on each of these data sets.\nWe also consider several different durations and levels for historical risk\nmeasures. Through our results we make some recommendations for a robust risk\nmanagement strategy that involves historical risk measures.\n"
    },
    {
        "paper_id": 1111.4637,
        "authors": "Jun-ichi Maskawa",
        "title": "Collective behavior of stock prices as a precursor to market crash",
        "comments": "10 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1143/PTPS.194.1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study precursors to the global market crash that occurred on all main\nstock exchanges throughout the world in October 2008 about three weeks after\nthe bankruptcy of Lehman Brothers Holdings Inc. on 15 September. We examine the\ncollective behavior of stock returns and analyze the market mode, which is a\nmarket-wide collective mode, with constituent issues of the FTSE 100 index\nlisted on the London Stock Exchange. Before the market crash, a sharp rise in a\nmeasure of the collective behavior was observed. It was shown to be associated\nwith news including the words \"financial crisis.\" They did not impact stock\nprices severely alone, but they exacerbated the pessimistic mood that prevailed\namong stock market participants. Such news increased after the Lehman shock\npreceding the market crash. The variance increased along with the cumulative\namount of news according to a power law.\n"
    },
    {
        "paper_id": 1111.4808,
        "authors": "Nico Achtsis, Ronald Cools, Dirk Nuyens",
        "title": "Conditional sampling for barrier option pricing under the LT method",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1137/110855909",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a conditional sampling scheme for pricing knock-out barrier\noptions under the Linear Transformations (LT) algorithm from Imai and Tan\n(2006). We compare our new method to an existing conditional Monte Carlo scheme\nfrom Glasserman and Staum (2001), and show that a substantial variance\nreduction is achieved. We extend the method to allow pricing knock-in barrier\noptions and introduce a root-finding method to obtain a further variance\nreduction. The effectiveness of the new method is supported by numerical\nresults.\n"
    },
    {
        "paper_id": 1111.4852,
        "authors": "Hayafumi Watanabe, Hideki Takayasu, Misako Takayasu",
        "title": "Biased diffusion on Japanese inter-firm trading network: Estimation of\n  sales from network structure",
        "comments": null,
        "journal-ref": "New J. Phys. 14 (2012) 043034",
        "doi": "10.1088/1367-2630/14/4/043034",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To investigate the actual phenomena of transport on a complex network, we\nanalysed empirical data for an inter-firm trading network, which consists of\nabout one million Japanese firms and the sales of these firms (a sale\ncorresponds to the total in-flow into a node). First, we analysed the\nrelationships between sales and sales of nearest neighbourhoods from which we\nobtain a simple linear relationship between sales and the weighted sum of sales\nof nearest neighbourhoods (i.e., customers). In addition, we introduce a simple\nmoney transport model that is coherent with this empirical observation. In this\nmodel, a firm (i.e., customer) distributes money to its out-edges (suppliers)\nproportionally to the in-degree of destinations. From intensive numerical\nsimulations, we find that the steady flows derived from these models can\napproximately reproduce the distribution of sales of actual firms. The sales of\nindividual firms deduced from the money-transport model are shown to be\nproportional, on an average, to the real sales.\n"
    },
    {
        "paper_id": 1111.5069,
        "authors": "Leonidas Sandoval Junior",
        "title": "Cluster formation and evolution in networks of financial market indices",
        "comments": null,
        "journal-ref": null,
        "doi": "10.3233/AF-13015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using data from world stock exchange indices prior to and during periods of\nglobal financial crises, clusters and networks of indices are built for\ndifferent thresholds and diverse periods of time, so that it is then possible\nto analyze how clusters are formed according to correlations among indices and\nhow they evolve in time, particularly during times of financial crises. Further\nanalysis is made on the eigenvectors corresponding to the second highest\neigenvalues of the correlation matrices, revealing a structure peculiar to\nmarkets that operate in different time zones.\n"
    },
    {
        "paper_id": 1111.5228,
        "authors": "Emmanuel A. Abbe, Amir E. Khandani, Andrew W. Lo",
        "title": "Privacy-Preserving Methods for Sharing Financial Risk Exposures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Unlike other industries in which intellectual property is patentable, the\nfinancial industry relies on trade secrecy to protect its business processes\nand methods, which can obscure critical financial risk exposures from\nregulators and the public. We develop methods for sharing and aggregating such\nrisk exposures that protect the privacy of all parties involved and without the\nneed for a trusted third party. Our approach employs secure multi-party\ncomputation techniques from cryptography in which multiple parties are able to\ncompute joint functions without revealing their individual inputs. In our\nframework, individual financial institutions evaluate a protocol on their\nproprietary data which cannot be inverted, leading to secure computations of\nreal-valued statistics such a concentration indexes, pairwise correlations, and\nother single- and multi-point statistics. The proposed protocols are\ncomputationally tractable on realistic sample sizes. Potential financial\napplications include: the construction of privacy-preserving real-time indexes\nof bank capital and leverage ratios; the monitoring of delegated portfolio\ninvestments; financial audits; and the publication of new indexes of\nproprietary trading strategies.\n"
    },
    {
        "paper_id": 1111.5254,
        "authors": "Vladimir Soloviev and Vladimir Saptsin and Dmitry Chabanenko",
        "title": "Markov Chains application to the financial-economic time series\n  prediction",
        "comments": "24 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  In this research the technology of complex Markov chains is applied to\npredict financial time series. The main distinction of complex or high-order\nMarkov Chains and simple first-order ones is the existing of aftereffect or\nmemory. The technology proposes prediction with the hierarchy of time\ndiscretization intervals and splicing procedure for the prediction results at\nthe different frequency levels to the single prediction output time series. The\nhierarchy of time discretizations gives a possibility to use fractal properties\nof the given time series to make prediction on the different frequencies of the\nseries. The prediction results for world's stock market indices is presented.\n"
    },
    {
        "paper_id": 1111.5265,
        "authors": "M. Rypdal and O. L{\\o}vsletten",
        "title": "Multifractal modeling of short-term interest rates",
        "comments": "16 pages, 3 figures, 7 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a multifractal model for short-term interest rates. The model is a\nversion of the Markov-Switching Multifractal (MSM), which incorporates the\nwell-known level effect observed in interest rates. Unlike previously suggested\nmodels, the level-MSM model captures the power-law scaling of the structure\nfunctions and the slowly decaying dependency in the absolute value of returns.\nWe apply the model to the Norwegian Interbank Offered Rate with three months\nmaturity (NIBORM3) and the U.S. Treasury Bill with three months maturity\n(TBM3). The performance of the model is compared to level-GARCH models,\nlevel-EGARCH models and jump-diffusions. For the TBM3 data the multifractal\nout-performs all the alternatives considered.\n"
    },
    {
        "paper_id": 1111.5289,
        "authors": "Vladimir Soloviev and Vladimir Saptsin",
        "title": "Heisenberg uncertainty principle and economic analogues of basic\n  physical quantities",
        "comments": "21 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  From positions, attained by modern theoretical physics in understanding of\nthe universe bases, the methodological and philosophical analysis of\nfundamental physical concepts and their formal and informal connections with\nthe real economic measurings is carried out. Procedures for heterogeneous\neconomic time determination, normalized economic coordinates and economic mass\nare offered, based on the analysis of time series, the concept of economic\nPlank's constant has been proposed. The theory has been approved on the real\neconomic dynamic's time series, including stock indices, Forex and spot prices,\nthe achieved results are open for discussion.\n"
    },
    {
        "paper_id": 1111.5397,
        "authors": "Graham Andersen and David Chisholm",
        "title": "A Mathematical Method for Deriving the Relative Effect of Serviceability\n  on Default Risk",
        "comments": "16 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The writers propose a mathematical Method for deriving risk weights which\ndescribe how a borrower's income, relative to their debt service obligations\n(serviceability) affects the probability of default of the loan.\n  The Method considers the borrower's income not simply as a known quantity at\nthe time the loan is made, but as an uncertain quantity following a statistical\ndistribution at some later point in the life of the loan. This allows a\nprobability to be associated with an income level leading to default, so that\nthe relative risk associated with different serviceability levels can be\nquantified. In a sense, the Method can be thought of as an extension of the\nMerton Model to quantities that fail to satisfy Merton's 'critical' assumptions\nrelating to the efficient markets hypothesis.\n  A set of numerical examples of risk weights derived using the Method suggest\nthat serviceability may be under-represented as a risk factor in many mortgage\ncredit risk models.\n"
    },
    {
        "paper_id": 1111.5726,
        "authors": "A.M. Avdeenko",
        "title": "Multicurrency advisor based on the NSW model. Detailed description and\n  perspectives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Flexible algorithm of multicurrency trade on Forex market has been built on\nthe grounds of non-linear stochastic wavelets (NSW) model. Probability of the\nloss-free trade has been evaluated. Results of the algorithm's real-time\ntesting and issues of the algorithm's development are discussed.\n"
    },
    {
        "paper_id": 1111.5739,
        "authors": "Samuel N. Cohen and Lukasz Szpruch",
        "title": "On Markovian solutions to Markov Chain BSDEs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study (backward) stochastic differential equations with noise coming from\na finite state Markov chain. We show that, for the solutions of these equations\nto be `Markovian', in the sense that they are deterministic functions of the\nstate of the underlying chain, the integrand must be of a specific form. This\nallows us to connect these equations to coupled systems of ODEs, and hence to\ngive fast numerical methods for the evaluation of Markov-Chain BSDEs.\n"
    },
    {
        "paper_id": 1111.6038,
        "authors": "John Schoenmakers, Junbo Huang, Jianing Zhang",
        "title": "Optimal dual martingales, their analysis and application to new\n  algorithms for Bermudan products",
        "comments": "This paper is an extended version of Schoenmakers and Huang, \"Optimal\n  dual martingales and their stability; fast evaluation of Bermudan products\n  via dual backward regression\", WIAS Preprint 1574",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce and study the concept of optimal and surely\noptimal dual martingales in the context of dual valuation of Bermudan options,\nand outline the development of new algorithms in this context. We provide a\ncharacterization theorem, a theorem which gives conditions for a martingale to\nbe surely optimal, and a stability theorem concerning martingales which are\nnear to be surely optimal in a sense. Guided by these results we develop a\nframework of backward algorithms for constructing such a martingale. In turn\nthis martingale may then be utilized for computing an upper bound of the\nBermudan product. The methodology is pure dual in the sense that it doesn't\nrequire certain input approximations to the Snell envelope. In an It\\^o-L\\'evy\nenvironment we outline a particular regression based backward algorithm which\nallows for computing dual upper bounds without nested Monte Carlo simulation.\nMoreover, as a by-product this algorithm also provides approximations to the\ncontinuation values of the product, which in turn determine a stopping policy.\nHence, we may obtain lower bounds at the same time. In a first numerical study\nwe demonstrate the backward dual regression algorithm in a Wiener environment\nat well known benchmark examples. It turns out that the method is at least\ncomparable to the one in Belomestny et. al. (2009) regarding accuracy, but\nregarding computational robustness there are even several advantages.\n"
    },
    {
        "paper_id": 1111.6067,
        "authors": "Ian Iscoe and Asif Lakhany",
        "title": "Adaptive Simulation of the Heston Model",
        "comments": "23 pages, 4 Postscript figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent years have seen an increased level of interest in pricing equity\noptions under a stochastic volatility model such as the Heston model. Often,\nsimulating a Heston model is difficult, as a standard finite difference scheme\nmay lead to significant bias in the simulation result. Reducing the bias to an\nacceptable level is not only challenging but computationally demanding. In this\npaper we address this issue by providing an alternative simulation strategy --\none that systematically decreases the bias in the simulation. Additionally, our\nmethodology is adaptive and achieves the reduction in bias with \"near\" minimum\ncomputational effort. We illustrate this feature with a numerical example.\n"
    },
    {
        "paper_id": 1111.6633,
        "authors": "Giuseppe Benedetti, Luciano Campi, Jan Kallsen, Johannes Muhle-Karbe",
        "title": "On the Existence of Shadow Prices",
        "comments": "14 pages, 1 figure, to appear in \"Finance and Stochastics\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For utility maximization problems under proportional transaction costs, it\nhas been observed that the original market with transaction costs can sometimes\nbe replaced by a frictionless \"shadow market\" that yields the same optimal\nstrategy and utility. However, the question of whether or not this indeed holds\nin generality has remained elusive so far. In this paper we present a\ncounterexample which shows that shadow prices may fail to exist. On the other\nhand, we prove that short selling constraints are a sufficient condition to\nwarrant their existence, even in very general multi-currency market models with\npossibly discontinuous bid-ask-spreads.\n"
    },
    {
        "paper_id": 1111.6826,
        "authors": "Massimiliano Marzo, Daniele Ritelli, Paolo Zagaglia",
        "title": "Optimal Trading Execution with Nonlinear Market Impact: An Alternative\n  Solution Method",
        "comments": "14 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the optimal trade execution strategies for a large portfolio of\nsingle stocks proposed by Almgren (2003). This framework accounts for a\nnonlinear impact of trades on average market prices. The results of Almgren\n(2003) are based on the assumption that no shares of assets per unit of time\nare trade at the beginning of the period. We propose a general solution method\nthat accomodates the case of a positive stock of assets in the initial period.\nOur findings are twofold. First of all, we show that the problem admits a\nsolution with no trading in the opening period only if additional parametric\nrestrictions are imposed. Second, with positive asset holdings in the initial\nperiod, the optimal execution time depends on trading activity at the beginning\nof the planning period.\n"
    },
    {
        "paper_id": 1111.6859,
        "authors": "Pouria Pedram",
        "title": "The minimal length uncertainty and the quantum model for the stock\n  market",
        "comments": "13 pages, no figure",
        "journal-ref": "Physica A 391, 2100 (2012)",
        "doi": "10.1016/j.physa.2011.11.043",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We generalize the recently proposed quantum model for the stock market by\nZhang and Huang to make it consistent with the discrete nature of the stock\nprice. In this formalism, the price of the stock and its trend satisfy the\ngeneralized uncertainty relation and the corresponding generalized Hamiltonian\ncontains an additional term proportional to the fourth power of the trend. We\nstudy a driven infinite quantum well where information as the external field\nperiodically fluctuates and show that the presence of the minimal trading value\nof stocks results in a positive shift in the characteristic frequencies of the\nquantum system. The connection between the information frequency and the\ntransition probabilities is discussed finally.\n"
    },
    {
        "paper_id": 1111.7103,
        "authors": "Nicolas Huth, Fr\\'ed\\'eric Abergel",
        "title": "High Frequency Lead/lag Relationships - Empirical facts",
        "comments": "40 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Lead/lag relationships are an important stylized fact at high frequency. Some\nassets follow the path of others with a small time lag. We provide indicators\nto measure this phenomenon using tick-by-tick data. Strongly asymmetric\ncross-correlation functions are empirically observed, especially in the\nfuture/stock case. We confirm the intuition that the most liquid assets (short\nintertrade duration, narrow bid/ask spread, small volatility, high turnover)\ntend to lead smaller stocks. However, the most correlated stocks are those with\nsimilar levels of liquidity. This lead/lag phenomenon is not constant\nthroughout the day, it shows an intraday seasonality with changes of behaviour\nat very specific times such as the announcement of macroeconomic figures and\nthe US market opening. These lead/lag relationships become more and more\npronounced as we zoom on significant events. We reach 60% of accuracy when\nforecasting the next midquote variation of the lagger using only the past\ninformation of the leader, which is significantly better than using the\ninformation of the lagger only. However, a naive strategy based on market\norders cannot make any profit of this effect because of the bid/ask spread.\n"
    },
    {
        "paper_id": 1112.0076,
        "authors": "Nicolas Della Penna, Mark D. Reid",
        "title": "Bandit Market Makers",
        "comments": "A previous version of this work appeared in the NIPS 2011 Workshop on\n  Computational Social Science and the Wisdom of the Crowds",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  We introduce a modular framework for market making. It combines cost-function\nbased automated market makers with bandit algorithms. We obtain worst-case\nprofits guarantee's relative to the best in hindsight within a class of natural\n\"overround\" cost functions . This combination allow us to have\ndistribution-free guarantees on the regret of profits while preserving the\nbounded worst-case losses and computational tractability over combinatorial\nspaces of the cost function based approach. We present simulation results to\nbetter understand the practical behaviour of market makers from the framework.\n"
    },
    {
        "paper_id": 1112.0105,
        "authors": "Ola L{\\o}vsletten and Martin Rypdal",
        "title": "Approximated maximum likelihood estimation in multifractal random walks",
        "comments": "8 pages, 3 figures, 2 tables",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.85.046705",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an approximated maximum likelihood method for the multifractal\nrandom walk processes of [E. Bacry et al., Phys. Rev. E 64, 026103 (2001)]. The\nlikelihood is computed using a Laplace approximation and a truncation in the\ndependency structure for the latent volatility. The procedure is implemented as\na package in the R computer language. Its performance is tested on synthetic\ndata and compared to an inference approach based on the generalized method of\nmoments. The method is applied to estimate parameters for various financial\nstock indices.\n"
    },
    {
        "paper_id": 1112.021,
        "authors": "Karol Wawrzyniak, Wojciech Wislicki",
        "title": "Mesoscopic approach to minority games in herd regime",
        "comments": "arXiv admin note: substantial text overlap with arXiv:0907.3231",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.11.041",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study minority games in efficient regime. By incorporating the utility\nfunction and aggregating agents with similar strategies we develop an effective\nmesoscale notion of state of the game. Using this approach, the game can be\nrepresented as a Markov process with substantially reduced number of states\nwith explicitly computable probabilities. For any payoff, the finiteness of the\nnumber of states is proved. Interesting features of an extensive random\nvariable, called aggregated demand, viz. its strong inhomogeneity and presence\nof patterns in time, can be easily interpreted. Using Markov theory and\nquenched disorder approach, we can explain important macroscopic\ncharacteristics of the game: behavior of variance per capita and predictability\nof the aggregated demand. We prove that in case of linear payoff many\nattractors in the state space are possible.\n"
    },
    {
        "paper_id": 1112.0226,
        "authors": "Guglielmo D'Amico, Raimondo Manca and Giovanni Salvi",
        "title": "Bivariate Semi-Markov Process for Counterparty Credit Risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of constructing an appropriate multivariate model for\nthe study of the counterparty credit risk in credit rating migration problem.\nFor this financial problem different multivariate Markov chain models were\nproposed. However the markovian assumption may be inappropriate for the study\nof the dynamic of credit ratings which typically show non markovian like\nbehaviour. In this paper we develop a semi-Markov approach to the study of the\ncounterparty credit risk by defining a new multivariate semi-Markov chain\nmodel. Methods are given for computing the transition probabilities,\nreliability functions and the price of a risky Credit Default Swap.\n"
    },
    {
        "paper_id": 1112.0233,
        "authors": "Michael Pickhardt and Goetz Seibold",
        "title": "Income Tax Evasion Dynamics: Evidence from an Agent-based Econophysics\n  Model",
        "comments": "24 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze income tax evasion dynamics in a standard model of statistical\nmechanics, the Ising model of ferromagnetism. However, in contrast to previous\nresearch, we use an inhomogeneous multi-dimensional Ising model where the local\ndegrees of freedom (agents) are subject to a specific social temperature and\ncoupled to external fields which govern their social behavior. This new\nmodeling frame allows for analyzing large societies of four different and\ninteracting agent types. As a second novelty, our model may reproduce results\nfrom agent-based models that incorporate standard Allingham and Sandmo tax\nevasion features as well as results from existing two-dimensional Ising based\ntax evasion models. We then use our model for analyzing income tax evasion\ndynamics under different enforcement scenarios and point to some policy\nimplications.\n"
    },
    {
        "paper_id": 1112.0297,
        "authors": "Sergii Piskun, Oleksandr Piskun, Dmitry Chabanenko",
        "title": "RQA Application for the Monitoring of Financial and Commodity markets\n  state",
        "comments": "22 pages, 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Nowadays, when crashes and crises are rather frequent events, an effective\nmonitoring system for the international financial market is needed. Modern\nnonlinear methods, such as Recurrence Quantification Analysis (RQA),\ndemonstrate the ability to reveal the regularities of the system behavior.\nThus, they can be useful for the analysis of the market state in real time. In\npresent paper we did an effort to apply the RQA for the purpose of economic\ntime series monitoring. 12 stock indexes, 6 currency pairs and 4 commodities\nwere taken for the study.\n"
    },
    {
        "paper_id": 1112.0342,
        "authors": "Dr.Gurjeet Dhesi, Mohammad Abdul Washad Emambocus, Muhammad Bilal\n  Shakeel",
        "title": "Semiclosed Pricing Mechanism",
        "comments": "for improvement",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper aims at designing the different important components of a\nsemi-closed simulated stock market (pricing mechanism, stock allocation and\nnews generation). The purpose is to understand the interactions of the\ndifferent aspects within a 'semi-closed' system. The complexity and nature of\nthe system led to the process of modifying the pricing mechanism which is\nviewed from a different angle to the classical Brownian Motion and the Random\nWalk model. However, it incorporates the essence of these two fundamental\ntheories and then investigates the matrix of investors' behaviours in relation\nto news feedbacks. This paper also explores the realm of randomly generated\nnews to the responses of participants to determine rational and irrational\nbehaviours. This is carried out through uncompressing the time within the\nexperiment and looking at concordant and disconcordant behaviour. The focus is\non how the modified pricing equation adapts to the conditions and uniqueness\nsurrounding a semi-closed stock market. Thus, this paper looks at how a simple\nmarket system where the main determinants of share prices are news, demand and\nsupply along with some filtering of the external forces can affect the\nbehaviours of investors in terms of their portfolio composition. The return\ndistributions can then be stipulated as arising from rational or irrational\ntrajectories and subsequently be simulated and matched via the proposed\nmodified Brownian Motion model to empirical return distributions in specific\ntime periods and markets.\n"
    },
    {
        "paper_id": 1112.0758,
        "authors": "Eric Kemp-Benedict",
        "title": "Confronting the Kaya Identity with Investment and Capital Stocks",
        "comments": "7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Scaling relations, such as the IPAT equation and the Kaya identity, are\nuseful for quickly gauging the scale of economic, technological, and\ndemographic changes required to reduce environmental impacts and pressures; in\nthe case of the Kaya identity, the environmental pressure is greenhouse gas\nemissions. However, when considering large-scale economic transformation, as\nwith a shift to a low-carbon economy, the IPAT and Kaya identities and their\ncousins fail to capture the legacy of existing capital, on the one hand, and\nthe need for new investment, on the other. While detailed models can capture\nthese factors, they do not allow for rapid exploration of widely different\nalternatives, which is the appeal of the IPAT and Kaya identities. In this\npaper we present an extended Kaya identity that includes investment and capital\nstocks. The identity we propose is a sum of terms, rather than a simple scaling\nrelation. Nevertheless, it allows for quick analysis and rapid exploration of a\nvariety of different possible paths toward a low-carbon economy.\n"
    },
    {
        "paper_id": 1112.077,
        "authors": "M. A. Virasoro",
        "title": "Non-Gaussianity of the Intraday Returns Distribution: its evolution in\n  time",
        "comments": "19 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We find a remarkable time persistence of various proxies for the kurtosis\n(p-kurtosis) of the intraday returns distribution for the S&P500 index and this\npermits a significant measure of their evolution from 1983 to 2004. There\nappears a long time scale dramatic variation of the p-kurtosis uncorrelated\nwith the variation of the volatility thus falsifying any hypothesis of a\nuniversal shape for the probability distribution of the returns. A large\nincrease in the kurtosis anticipates the October 87 crash. During the years\n1991-2003 it continuously decreases even when the volatility grows during the\ndot-com bubble. We propose some speculative interpretations of these results.\n"
    },
    {
        "paper_id": 1112.1051,
        "authors": "Huina Mao, Scott Counts and Johan Bollen",
        "title": "Predicting Financial Markets: Comparing Survey, News, Twitter and Search\n  Engine Data",
        "comments": "This paper includes 10 pages, 6 figures and 10 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial market prediction on the basis of online sentiment tracking has\ndrawn a lot of attention recently. However, most results in this emerging\ndomain rely on a unique, particular combination of data sets and sentiment\ntracking tools. This makes it difficult to disambiguate measurement and\ninstrument effects from factors that are actually involved in the apparent\nrelation between online sentiment and market values. In this paper, we survey a\nrange of online data sets (Twitter feeds, news headlines, and volumes of Google\nsearch queries) and sentiment tracking methods (Twitter Investor Sentiment,\nNegative News Sentiment and Tweet & Google Search volumes of financial terms),\nand compare their value for financial prediction of market indices such as the\nDow Jones Industrial Average, trading volumes, and market volatility (VIX), as\nwell as gold prices. We also compare the predictive power of traditional\ninvestor sentiment survey data, i.e. Investor Intelligence and Daily Sentiment\nIndex, against those of the mentioned set of online sentiment indicators. Our\nresults show that traditional surveys of Investor Intelligence are lagging\nindicators of the financial markets. However, weekly Google Insight Search\nvolumes on financial search queries do have predictive value. An indicator of\nTwitter Investor Sentiment and the frequency of occurrence of financial terms\non Twitter in the previous 1-2 days are also found to be very statistically\nsignificant predictors of daily market log return. Survey sentiment indicators\nare however found not to be statistically significant predictors of financial\nmarket values, once we control for all other mood indicators as well as the\nVIX.\n"
    },
    {
        "paper_id": 1112.1114,
        "authors": "Arthur M. Berd",
        "title": "The Nature of Alpha",
        "comments": "22 pages, 5 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We suggest an empirical model of investment strategy returns which elucidates\nthe importance of non-Gaussian features, such as time-varying volatility,\nasymmetry and fat tails, in explaining the level of expected returns.\nEstimating the model on the (former) Lehman Brothers Hedge Fund Index data, we\ndemonstrate that the volatility compensation is a significant component of the\nexpected returns for most strategy styles, suggesting that many of these\nstrategies should be thought of as being `short vol'. We present some\nfundamental and technical reasons why this should indeed be the case, and\nsuggest explanation for exception cases exhibiting `long vol' characteristics.\nWe conclude by drawing some lessons for hedge fund portfolio construction.\n"
    },
    {
        "paper_id": 1112.1156,
        "authors": "Michalis Vafopoulos",
        "title": "Looking for grass-root sources of systemic risk: the case of\n  \"cheques-as-collateral\" network",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The global financial system has become highly connected and complex. Has been\nproven in practice that existing models, measures and reports of financial risk\nfail to capture some important systemic dimensions. Only lately, advisory\nboards have been established in high level and regulations are directly\ntargeted to systemic risk. In the same direction, a growing number of\nresearchers employ network analysis to model systemic risk in financial\nnetworks. Current approaches are concentrated on interbank payment network\nflows in national and international level. This work builds on existing\napproaches to account for systemic risk assessment in micro level.\nParticularly, we introduce the analysis of intra-bank financial risk\ninterconnections, by examining the real case of \"cheques-as-collateral\" network\nfor a major Greek bank. Our model offers useful information about the negative\nspillovers of disruption to a financial entity in a bank's lending network and\ncould complement existing credit scoring models that account only for\nidiosyncratic customer's financial profile. Most importantly, the proposed\nmethodology can be employed in many segments of the entire financial system,\nproviding a useful tool in the hands of regulatory authorities in assessing\nmore accurate estimates of systemic risk.\n"
    },
    {
        "paper_id": 1112.1363,
        "authors": "Chang-Shuai Li",
        "title": "Common persistence in conditional variance: A reconsideration",
        "comments": "23 pages,4 tables, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper demonstrates the flaws of co-persistence theory proposed by\nBollerslev and Engle (1993) which cause the theory can hardly be applied. With\nthe introduction of the half-life of decay coefficient as the measure of the\npersistence, and both the weak definition of persistence and co-persistence in\nvariance, this study attempts to solve the problems by using exhaustive search\nalgorithm for obtaining co-persistent vector. In addition, this method is\nillustrated to research the co-persistence of stock return volatility in 10\nEuropean countries.\n"
    },
    {
        "paper_id": 1112.1502,
        "authors": "M. Vahabi, G. R. Jafari, M. Sadegh Movahed",
        "title": "Analysis of fractional Gaussian noises using level crossing method",
        "comments": "12 pages, 6 figures and 1 table",
        "journal-ref": "J. Stat. Mech. (2011) P11021",
        "doi": "10.1088/1742-5468/2011/11/P11021",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The so-called level crossing analysis has been used to investigate the\nempirical data set. But there is a lack of interpretation for what is reflected\nby the level crossing results. The fractional Gaussian noise as a well-defined\nstochastic series could be a suitable benchmark to make the level crossing\nfindings more sense. In this article, we calculated the average frequency of\nupcrossing for a wide range of fractional Gaussian noises from logarithmic\n(zero Hurst exponent, H=0), to Gaussian, H=1, ($0<H<1$). By introducing the\nrelative change of the total numbers of upcrossings for original data with\nrespect to so-called shuffled one, $\\mathcal{R}$, an empirical function for the\nHurst exponent versus $\\mathcal{R}$ has been established. Finally to make the\nconcept more obvious, we applied this approach to some financial series.\n"
    },
    {
        "paper_id": 1112.1521,
        "authors": "Andrea Pallavicini, Daniele Perini and Damiano Brigo",
        "title": "Funding Valuation Adjustment: a consistent framework including CVA, DVA,\n  collateral,netting rules and re-hypothecation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we describe how to include funding and margining costs into a\nrisk-neutral pricing framework for counterparty credit risk. We consider\nrealistic settings and we include in our models the common market practices\nsuggested by the ISDA documentation without assuming restrictive constraints on\nmargining procedures and close-out netting rules. In particular, we allow for\nasymmetric collateral and funding rates, and exogenous liquidity policies and\nhedging strategies. Re-hypothecation liquidity risk and close-out amount\nevaluation issues are also covered. We define a comprehensive pricing framework\nwhich allows us to derive earlier results on funding or counterparty risk. Some\nrelevant examples illustrate the non trivial settings needed to derive known\nfacts about discounting curves by starting from a general framework and without\nresorting to ad hoc hypotheses. Our main result is a bilateral collateralized\ncounterparty valuation adjusted pricing equation, which allows to price a deal\nwhile taking into account credit and debt valuation adjustments along with\nmargining and funding costs in a coherent way. We find that the equation has a\nrecursive form, making the introduction of an additive funding valuation\nadjustment difficult. Yet, we can cast the pricing equation into a set of\niterative relationships which can be solved by means of standard least-square\nMonte Carlo techniques.\n"
    }
]