[
    {
        "paper_id": 704.0335,
        "authors": "Gilles Pag\\`es (PMA, LSProba), Fabien Panloup (PMA)",
        "title": "Approximation of the distribution of a stationary Markov process with\n  application to option pricing",
        "comments": null,
        "journal-ref": "Bernoulli 15, 1 (2009) 146-177",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We build a sequence of empirical measures on the space D(R_+,R^d) of\nR^d-valued c\\`adl\\`ag functions on R_+ in order to approximate the law of a\nstationary R^d-valued Markov and Feller process (X_t). We obtain some general\nresults of convergence of this sequence. Then, we apply them to Brownian\ndiffusions and solutions to L\\'evy driven SDE's under some Lyapunov-type\nstability assumptions. As a numerical application of this work, we show that\nthis procedure gives an efficient way of option pricing in stochastic\nvolatility models.\n"
    },
    {
        "paper_id": 704.0394,
        "authors": "Anna Ja\\'skiewicz",
        "title": "Average optimality for risk-sensitive control with general state space",
        "comments": "Published at http://dx.doi.org/10.1214/105051606000000790 in the\n  Annals of Applied Probability (http://www.imstat.org/aap/) by the Institute\n  of Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2007, Vol. 17, No. 2, 654-675",
        "doi": "10.1214/105051606000000790",
        "license": null,
        "abstract": "  This paper deals with discrete-time Markov control processes on a general\nstate space. A long-run risk-sensitive average cost criterion is used as a\nperformance measure. The one-step cost function is nonnegative and possibly\nunbounded. Using the vanishing discount factor approach, the optimality\ninequality and an optimal stationary strategy for the decision maker are\nestablished.\n"
    },
    {
        "paper_id": 704.0567,
        "authors": "Martin Keller-Ressel, Thomas Steiner",
        "title": "Yield Curve Shapes and the Asymptotic Short Rate Distribution in Affine\n  One-Factor Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider a model for interest rates, where the short rate is given by a\ntime-homogenous, one-dimensional affine process in the sense of Duffie,\nFilipovic and Schachermayer. We show that in such a model yield curves can only\nbe normal, inverse or humped (i.e. endowed with a single local maximum). Each\ncase can be characterized by simple conditions on the present short rate. We\ngive conditions under which the short rate process will converge to a limit\ndistribution and describe the limit distribution in terms of its cumulant\ngenerating function. We apply our results to the Vasicek model, the CIR model,\na CIR model with added jumps and a model of Ornstein-Uhlenbeck type.\n"
    },
    {
        "paper_id": 704.0589,
        "authors": "Wei-Xing Zhou (ECUST), Didier Sornette (ETH Zurich)",
        "title": "Analysis of the real estate market in Las Vegas: Bubble, seasonal\n  patterns, and prediction of the CSW indexes",
        "comments": "24 Elsart pages including 13 pages and 1 table",
        "journal-ref": "Physica A 387 (1), 243-260 (2008)",
        "doi": "10.1016/j.physa.2007.08.059",
        "license": null,
        "abstract": "  We analyze 27 house price indexes of Las Vegas from Jun. 1983 to Mar. 2005,\ncorresponding to 27 different zip codes. These analyses confirm the existence\nof a real-estate bubble, defined as a price acceleration faster than\nexponential, which is found however to be confined to a rather limited time\ninterval in the recent past from approximately 2003 to mid-2004 and has\nprogressively transformed into a more normal growth rate comparable to\npre-bubble levels in 2005. There has been no bubble till 2002 except for a\nmedium-sized surge in 1990. In addition, we have identified a strong yearly\nperiodicity which provides a good potential for fine-tuned prediction from\nmonth to month. A monthly monitoring using a model that we have developed could\nconfirm, by testing the intra-year structure, if indeed the market has returned\nto ``normal'' or if more turbulence is expected ahead. We predict the evolution\nof the indexes one year ahead, which is validated with new data up to Sep.\n2006. The present analysis demonstrates the existence of very significant\nvariations at the local scale, in the sense that the bubble in Las Vegas seems\nto have preceded the more global USA bubble and has ended approximately two\nyears earlier (mid 2004 for Las Vegas compared with mid-2006 for the whole of\nthe USA).\n"
    },
    {
        "paper_id": 704.0664,
        "authors": "S. Drozdz, M. Forczek, J. Kwapien, P. Oswiecimka, R. Rak",
        "title": "Stock market return distributions: from past to present",
        "comments": "to appear in Physica A",
        "journal-ref": "Physica A 383, 59-64 (2007)",
        "doi": "10.1016/j.physa.2007.04.130",
        "license": null,
        "abstract": "  We show that recent stock market fluctuations are characterized by the\ncumulative distributions whose tails on short, minute time scales exhibit power\nscaling with the scaling index alpha > 3 and this index tends to increase\nquickly with decreasing sampling frequency. Our study is based on\nhigh-frequency recordings of the S&P500, DAX and WIG20 indices over the\ninterval May 2004 - May 2006. Our findings suggest that dynamics of the\ncontemporary market may differ from the one observed in the past. This effect\nindicates a constantly increasing efficiency of world markets.\n"
    },
    {
        "paper_id": 704.0745,
        "authors": "Maria Siopacha and Josef Teichmann",
        "title": "Weak and Strong Taylor methods for numerical solutions of stochastic\n  differential equations",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We apply results of Malliavin-Thalmaier-Watanabe for strong and weak Taylor\nexpansions of solutions of perturbed stochastic differential equations (SDEs).\nIn particular, we work out weight expressions for the Taylor coefficients of\nthe expansion. The results are applied to LIBOR market models in order to deal\nwith the typical stochastic drift and with stochastic volatility. In contrast\nto other accurate methods like numerical schemes for the full SDE, we obtain\neasily tractable expressions for accurate pricing. In particular, we present an\neasily tractable alternative to ``freezing the drift'' in LIBOR market models,\nwhich has an accuracy similar to the full numerical scheme. Numerical examples\nunderline the results.\n"
    },
    {
        "paper_id": 704.0773,
        "authors": "Raj Kumar Pan and Sitabhra Sinha",
        "title": "Collective behavior of stock price movements in an emerging market",
        "comments": "10 pages, 10 figures",
        "journal-ref": "Phys. Rev. E 76, 046116 (2007) (9 pages)",
        "doi": "10.1103/PhysRevE.76.046116",
        "license": null,
        "abstract": "  To investigate the universality of the structure of interactions in different\nmarkets, we analyze the cross-correlation matrix C of stock price fluctuations\nin the National Stock Exchange (NSE) of India. We find that this emerging\nmarket exhibits strong correlations in the movement of stock prices compared to\ndeveloped markets, such as the New York Stock Exchange (NYSE). This is shown to\nbe due to the dominant influence of a common market mode on the stock prices.\nBy comparison, interactions between related stocks, e.g., those belonging to\nthe same business sector, are much weaker. This lack of distinct sector\nidentity in emerging markets is explicitly shown by reconstructing the network\nof mutually interacting stocks. Spectral analysis of C for NSE reveals that,\nthe few largest eigenvalues deviate from the bulk of the spectrum predicted by\nrandom matrix theory, but they are far fewer in number compared to, e.g., NYSE.\nWe show this to be due to the relative weakness of intra-sector interactions\nbetween stocks, compared to the market mode, by modeling stock price dynamics\nwith a two-factor model. Our results suggest that the emergence of an internal\nstructure comprising multiple groups of strongly coupled components is a\nsignature of market development.\n"
    },
    {
        "paper_id": 704.1099,
        "authors": "Bence Toth, Janos Kertesz",
        "title": "The Epps effect revisited",
        "comments": "23 pages, 10 figures, 2 tables; added references, added figures and\n  statistical details, extended overview on literature",
        "journal-ref": "Quantitative Finance, 9(7), 793 (2009)",
        "doi": "10.1080/14697680802595668",
        "license": null,
        "abstract": "  We analyse the dependence of stock return cross-correlations on the sampling\nfrequency of the data known as the Epps effect: For high resolution data the\ncross-correlations are significantly smaller than their asymptotic value as\nobserved on daily data. The former description implies that changing trading\nfrequency should alter the characteristic time of the phenomenon. This is not\ntrue for the empirical data: The Epps curves do not scale with market activity.\nThe latter result indicates that the time scale of the phenomenon is connected\nto the reaction time of market participants (this we denote as human time\nscale), independent of market activity. In this paper we give a new description\nof the Epps effect through the decomposition of cross-correlations. After\ntesting our method on a model of generated random walk price changes we justify\nour analytical results by fitting the Epps curves of real world data.\n"
    },
    {
        "paper_id": 704.1225,
        "authors": "M. Angeles Serrano, Marian Boguna, and Alessandro Vespignani",
        "title": "Patterns of dominant flows in the world trade web",
        "comments": null,
        "journal-ref": "J. Econ. Interac. Coor. 2, 111 (2007)",
        "doi": "10.1007/s11403-007-0026-y",
        "license": null,
        "abstract": "  The large-scale organization of the world economies is exhibiting\nincreasingly levels of local heterogeneity and global interdependency.\nUnderstanding the relation between local and global features calls for\nanalytical tools able to uncover the global emerging organization of the\ninternational trade network. Here we analyze the world network of bilateral\ntrade imbalances and characterize its overall flux organization, unraveling\nlocal and global high-flux pathways that define the backbone of the trade\nsystem. We develop a general procedure capable to progressively filter out in a\nconsistent and quantitative way the dominant trade channels. This procedure is\ncompletely general and can be applied to any weighted network to detect the\nunderlying structure of transport flows. The trade fluxes properties of the\nworld trade web determines a ranking of trade partnerships that highlights\nglobal interdependencies, providing information not accessible by simple local\nanalysis. The present work provides new quantitative tools for a dynamical\napproach to the propagation of economic crises.\n"
    },
    {
        "paper_id": 704.1338,
        "authors": "Ruipeng Liu, T. Di Matteo, Thomas Lux",
        "title": "True and Apparent Scaling: The Proximity of the Markov-Switching\n  Multifractal Model to Long-Range Dependence",
        "comments": "13 pages, accepted for publication in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2007.04.085",
        "license": null,
        "abstract": "  In this paper, we consider daily financial data of a collection of different\nstock market indices, exchange rates, and interest rates, and we analyze their\nmulti-scaling properties by estimating a simple specification of the\nMarkov-switching multifractal model (MSM). In order to see how well the\nestimated models capture the temporal dependence of the data, we estimate and\ncompare the scaling exponents $H(q)$ (for $q = 1, 2$) for both empirical data\nand simulated data of the estimated MSM models. In most cases the multifractal\nmodel appears to generate `apparent' long memory in agreement with the\nempirical scaling laws.\n"
    },
    {
        "paper_id": 704.1348,
        "authors": "Paolo Dai Pra, Wolfgang J. Runggaldier, Elena Sartori, Marco Tolotti",
        "title": "Large portfolio losses: A dynamic contagion model",
        "comments": "Published in at http://dx.doi.org/10.1214/08-AAP544 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 1, 347-394",
        "doi": "10.1214/08-AAP544",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using particle system methodologies we study the propagation of financial\ndistress in a network of firms facing credit risk. We investigate the\nphenomenon of a credit crisis and quantify the losses that a bank may suffer in\na large credit portfolio. Applying a large deviation principle we compute the\nlimiting distributions of the system and determine the time evolution of the\ncredit quality indicators of the firms, deriving moreover the dynamics of a\nglobal financial health indicator. We finally describe a suitable version of\nthe \"Central Limit Theorem\" useful to study large portfolio losses. Simulation\nresults are provided as well as applications to portfolio loss distribution\nanalysis.\n"
    },
    {
        "paper_id": 704.1433,
        "authors": "Benjamin Jourdain (CERMICS), Mohamed Sbai (CERMICS)",
        "title": "Exact retrospective Monte Carlo computation of arithmetic average Asian\n  options",
        "comments": null,
        "journal-ref": "Monte Carlo Methods and Applications 13, 2 (2007) pp 135-171",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Taking advantage of the recent litterature on exact simulation algorithms\n(Beskos, Papaspiliopoulos and Roberts) and unbiased estimation of the\nexpectation of certain fonctional integrals (Wagner, Beskos et al. and\nFearnhead et al.), we apply an exact simulation based technique for pricing\ncontinuous arithmetic average Asian options in the Black and Scholes framework.\nUnlike existing Monte Carlo methods, we are no longer prone to the\ndiscretization bias resulting from the approximation of continuous time\nprocesses through discrete sampling. Numerical results of simulation studies\nare presented and variance reduction problems are considered.\n"
    },
    {
        "paper_id": 704.1738,
        "authors": "A. Chakraborti, M. Patriarca, and M.S. Santhanam",
        "title": "Financial time-series analysis: A brief overview",
        "comments": "16 pages, 7 figures, submitted for publication in the Proceedings\n  Volume of the International Workshop \"Econophys-Kolkata III\", Saha Institute\n  of Nuclear Physics, March 12-15, 2007",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-0665-2_4",
        "license": null,
        "abstract": "  Prices of commodities or assets produce what is called time-series. Different\nkinds of financial time-series have been recorded and studied for decades.\nNowadays, all transactions on a financial market are recorded, leading to a\nhuge amount of data available, either for free in the Internet or commercially.\nFinancial time-series analysis is of great interest to practitioners as well as\nto theoreticians, for making inferences and predictions. Furthermore, the\nstochastic uncertainties inherent in financial time-series and the theory\nneeded to deal with them make the subject especially interesting not only to\neconomists, but also to statisticians and physicists. While it would be a\nformidable task to make an exhaustive review on the topic, with this review we\ntry to give a flavor of some of its aspects.\n"
    },
    {
        "paper_id": 704.1976,
        "authors": "Dorje C. Brody, Lane P. Hughston, Andrea Macrina",
        "title": "Information-Based Asset Pricing",
        "comments": "32 pages. No figure",
        "journal-ref": "International Journal of Theoretical and Applied Finance 11,\n  107-142 (2008)",
        "doi": null,
        "license": null,
        "abstract": "  A new framework for asset price dynamics is introduced in which the concept\nof noisy information about future cash flows is used to derive the price\nprocesses. In this framework an asset is defined by its cash-flow structure.\nEach cash flow is modelled by a random variable that can be expressed as a\nfunction of a collection of independent random variables called market factors.\nWith each such \"X-factor\" we associate a market information process, the values\nof which are accessible to market agents. Each information process is a sum of\ntwo terms; one contains true information about the value of the market factor;\nthe other represents \"noise\". The noise term is modelled by an independent\nBrownian bridge. The market filtration is assumed to be that generated by the\naggregate of the independent information processes. The price of an asset is\ngiven by the expectation of the discounted cash flows in the risk-neutral\nmeasure, conditional on the information provided by the market filtration. When\nthe cash flows are the dividend payments associated with equities, an explicit\nmodel is obtained for the share-price, and the prices of options on\ndividend-paying assets are derived. Remarkably, the resulting formula for the\nprice of a European call option is of the Black-Scholes-Merton type. The\ninformation-based framework also generates a natural explanation for the origin\nof stochastic volatility.\n"
    },
    {
        "paper_id": 704.2003,
        "authors": "Gabriella Vaglica, Fabrizio Lillo, Esteban Moro, Rosario N. Mantegna",
        "title": "Scaling laws of strategic behaviour and size heterogeneity in agent\n  dynamics",
        "comments": "6 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.77.036110",
        "license": null,
        "abstract": "  The dynamics of many socioeconomic systems is determined by the decision\nmaking process of agents. The decision process depends on agent's\ncharacteristics, such as preferences, risk aversion, behavioral biases, etc..\nIn addition, in some systems the size of agents can be highly heterogeneous\nleading to very different impacts of agents on the system dynamics. The large\nsize of some agents poses challenging problems to agents who want to control\ntheir impact, either by forcing the system in a given direction or by hiding\ntheir intentionality. Here we consider the financial market as a model system,\nand we study empirically how agents strategically adjust the properties of\nlarge orders in order to meet their preference and minimize their impact. We\nquantify this strategic behavior by detecting scaling relations of allometric\nnature between the variables characterizing the trading activity of different\ninstitutions. We observe power law distributions in the investment time\nhorizon, in the number of transactions needed to execute a large order and in\nthe traded value exchanged by large institutions and we show that heterogeneity\nof agents is a key ingredient for the emergence of some aggregate properties\ncharacterizing this complex system.\n"
    },
    {
        "paper_id": 704.2115,
        "authors": "Sitabhra Sinha and Raj Kumar Pan",
        "title": "Uncovering the Internal Structure of the Indian Financial Market:\n  Cross-correlation behavior in the NSE",
        "comments": "15 pages, 8 figures, to appear in Proceedings of International\n  Workshop on \"Econophysics & Sociophysics of Markets & Networks\"\n  (Econophys-Kolkata III), Mar 12-15, 2007",
        "journal-ref": "Econophysics of Markets and Business Networks, (Springer, Milan,\n  2007) p. 3-19",
        "doi": "10.1007/978-88-470-0665-2_1",
        "license": null,
        "abstract": "  The cross-correlations between price fluctuations of 201 frequently traded\nstocks in the National Stock Exchange (NSE) of India are analyzed in this\npaper. We use daily closing prices for the period 1996-2006, which coincides\nwith the period of rapid transformation of the market following liberalization.\nThe eigenvalue distribution of the cross-correlation matrix, $\\mathbf{C}$, of\nNSE is found to be similar to that of developed markets, such as the New York\nStock Exchange (NYSE): the majority of eigenvalues fall within the bounds\nexpected for a random matrix constructed from mutually uncorrelated time\nseries. Of the few largest eigenvalues that deviate from the bulk, the largest\nis identified with market-wide movements. The intermediate eigenvalues that\noccur between the largest and the bulk have been associated in NYSE with\nspecific business sectors with strong intra-group interactions. However, in the\nIndian market, these deviating eigenvalues are comparatively very few and lie\nmuch closer to the bulk. We propose that this is because of the relative lack\nof distinct sector identity in the market, with the movement of stocks\ndominantly influenced by the overall market trend. This is shown by explicit\nconstruction of the interaction network in the market, first by generating the\nminimum spanning tree from the unfiltered correlation matrix, and later, using\nan improved method of generating the graph after filtering out the market mode\nand random effects from the data. Both methods show, compared to developed\nmarkets, the relative absence of clusters of co-moving stocks that belong to\nthe same business sector. This is consistent with the general belief that\nemerging markets tend to be more correlated than developed markets.\n"
    },
    {
        "paper_id": 704.2139,
        "authors": "P. K. Mohanty",
        "title": "Why only few are so successful ?",
        "comments": "8 pages, 3 eps figures, elsart.cls (included), accepted in Physica A",
        "journal-ref": "Physica A 384, 75 (2007)",
        "doi": "10.1016/j.physa.2007.04.118",
        "license": null,
        "abstract": "  In many professons employees are rewarded according to their relative\nperformance. Corresponding economy can be modeled by taking $N$ independent\nagents who gain from the market with a rate which depends on their current\ngain. We argue that this simple realistic rate generates a scale free\ndistribution even though intrinsic ability of agents are marginally different\nfrom each other. As an evidence we provide distribution of scores for two\ndifferent systems (a) the global stock game where players invest in real stock\nmarket and (b) the international cricket.\n"
    },
    {
        "paper_id": 704.2244,
        "authors": "Erhan Bayraktar, Virginia R. Young",
        "title": "Proving Regularity of the Minimal Probability of Ruin via a Game of\n  Stopping and Control",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We reveal an interesting convex duality relationship between two problems:\n(a) minimizing the probability of lifetime ruin when the rate of consumption is\nstochastic and when the individual can invest in a Black-Scholes financial\nmarket; (b) a controller-and-stopper problem, in which the controller controls\nthe drift and volatility of a process in order to maximize a running reward\nbased on that process, and the stopper chooses the time to stop the running\nreward and rewards the controller a final amount at that time. Our primary goal\nis to show that the minimal probability of ruin, whose stochastic\nrepresentation does not have a classical form as does the utility maximization\nproblem (i.e., the objective's dependence on the initial values of the state\nvariables is implicit), is the unique classical solution of its\nHamilton-Jacobi-Bellman (HJB) equation, which is a non-linear boundary-value\nproblem. We establish our goal by exploiting the convex duality relationship\nbetween (a) and (b).\n"
    },
    {
        "paper_id": 704.2865,
        "authors": "Andrei Khrennikov",
        "title": "Classical and quantum randomness and the financial market",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We analyze complexity of financial (and general economic) processes by\ncomparing classical and quantum-like models for randomness. Our analysis\nimplies that it might be that a quantum-like probabilistic description is more\nnatural for financial market than the classical one. A part of our analysis is\ndevoted to study the possibility of application of the quantum probabilistic\nmodel to agents of financial market. We show that, although the direct quantum\n(physical) reduction (based on using the scales of quantum mechanics) is\nmeaningless, one may apply so called quantum-like models. In our approach\nquantum-like probabilistic behaviour is a consequence of contextualy of\nstatistical data in finances (and economics in general). However, our\nhypothesis on \"quantumness\" of financial data should be tested experimentally\n(as opposed to the conventional description based on the noncontextual\nclassical probabilistic approach). We present a new statistical test based on a\ngeneralization of the well known in quantum physics Bell's inequality.\n"
    },
    {
        "paper_id": 704.3798,
        "authors": "Bence Toth, Balint Toth, Janos Kertesz",
        "title": "Modeling the Epps effect of cross correlations in asset prices",
        "comments": "to appear in the Proceedings of SPIE Fluctuations and Noise 2007",
        "journal-ref": "Proc. SPIE, Vol. 6601, 66010J (2007)",
        "doi": "10.1117/12.727127",
        "license": null,
        "abstract": "  We review the decomposition method of stock return cross-correlations,\npresented previously for studying the dependence of the correlation coefficient\non the resolution of data (Epps effect). Through a toy model of random\nwalk/Brownian motion and memoryless renewal process (i.e. Poisson point\nprocess) of observation times we show that in case of analytical treatability,\nby decomposing the correlations we get the exact result for the frequency\ndependence. We also demonstrate that our approach produces reasonable fitting\nof the dependence of correlations on the data resolution in case of empirical\ndata. Our results indicate that the Epps phenomenon is a product of the finite\ntime decay of lagged correlations of high resolution data, which does not scale\nwith activity. The characteristic time is due to a human time scale, the time\nneeded to react to news.\n"
    },
    {
        "paper_id": 705.0029,
        "authors": "Esteban Guevara",
        "title": "EGT through Quantum Mechanics & from Statistical Physics to Economics",
        "comments": "9 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  By analyzing the relationships between a socioeconomical system modeled\nthrough evolutionary game theory and a physical system modeled through quantum\nmechanics we show how although both systems are described through two theories\napparently different both are analogous and thus exactly equivalents. The\nextensions of quantum mechanics to statistical physics and information theory\nlet us use some of their definitions for the best understanding of the behavior\nof economics and biology. The quantum analogue of the replicator dynamics is\nthe von Neumann equation. A system in where all its members are in Nash\nequilibrium is equivalent to a system in a maximum entropy state. Nature is a\ngame in where its players compete for a common welfare and the equilibrium of\nthe system that they are members. They act as a whole besides individuals like\nthey obey a rule in where they prefer to work for the welfare of the collective\nbesides the individual welfare.\n"
    },
    {
        "paper_id": 705.0053,
        "authors": "Erhan Bayraktar, Virginia R. Young",
        "title": "Mutual Fund Theorems when Minimizing the Probability of Lifetime Ruin",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We show that the mutual fund theorems of Merton (1971) extend to the problem\nof optimal investment to minimize the probability of lifetime ruin. We obtain\ntwo such theorems by considering a financial market both with and without a\nriskless asset for random consumption. The striking result is that we obtain\ntwo-fund theorems despite the additional source of randomness from consumption.\n"
    },
    {
        "paper_id": 705.0076,
        "authors": "Cheoljun Eom, Gabjin Oh, Seunghwan Kim",
        "title": "Deterministic Factors of Stock Networks based on Cross-correlation in\n  Financial Market",
        "comments": "4 pages, 1 figure",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2007.04.102",
        "license": null,
        "abstract": "  The stock market has been known to form homogeneous stock groups with a\nhigher correlation among different stocks according to common economic factors\nthat influence individual stocks. We investigate the role of common economic\nfactors in the market in the formation of stock networks, using the arbitrage\npricing model reflecting essential properties of common economic factors. We\nfind that the degree of consistency between real and model stock networks\nincreases as additional common economic factors are incorporated into our\nmodel. Furthermore, we find that individual stocks with a large number of links\nto other stocks in a network are more highly correlated with common economic\nfactors than those with a small number of links. This suggests that common\neconomic factors in the stock market can be understood in terms of\ndeterministic factors.\n"
    },
    {
        "paper_id": 705.0161,
        "authors": "Jia Shao, Plamen Ch. Ivanov, Boris Podobnik, H. Eugene Stanley",
        "title": "Quantitative relations between corruption and economic factors",
        "comments": "10 pages, 9 figures",
        "journal-ref": "Eur. Phys. J. B. 56 157-166(2007)",
        "doi": "10.1140/epjb/e2007-00098-2",
        "license": null,
        "abstract": "  We report quantitative relations between corruption level and economic\nfactors, such as country wealth and foreign investment per capita, which are\ncharacterized by a power law spanning multiple scales of wealth and investments\nper capita. These relations hold for diverse countries, and also remain stable\nover different time periods. We also observe a negative correlation between\nlevel of corruption and long-term economic growth. We find similar results for\ntwo independent indices of corruption, suggesting that the relation between\ncorruption and wealth does not depend on the specific measure of corruption.\nThe functional relations we report have implications when assessing the\nrelative level of corruption for two countries with comparable wealth, and for\nquantifying the impact of corruption on economic growth and foreign\ninvestments.\n"
    },
    {
        "paper_id": 705.0503,
        "authors": "Alessandro De Gregorio, Stefano M. Iacus",
        "title": "Change point estimation for the telegraph process observed at discrete\n  times",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The telegraph process models a random motion with finite velocity and it is\nusually proposed as an alternative to diffusion models. The process describes\nthe position of a particle moving on the real line, alternatively with constant\nvelocity $+ v$ or $-v$. The changes of direction are governed by an homogeneous\nPoisson process with rate $\\lambda >0.$ In this paper, we consider a change\npoint estimation problem for the rate of the underlying Poisson process by\nmeans of least squares method. The consistency and the rate of convergence for\nthe change point estimator are obtained and its asymptotic distribution is\nderived. Applications to real data are also presented.\n"
    },
    {
        "paper_id": 705.1056,
        "authors": "Atushi Ishikawa",
        "title": "The log-normal distribution from Non-Gibrat's law in the middle scale\n  region of profits",
        "comments": "13 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Employing profits data of Japanese firms in 2003--2005, we kinematically\nexhibit the static log-normal distribution in the middle scale region. In the\nderivation, a Non-Gibrat's law under the detailed balance is adopted together\nwith following two approximations. Firstly, the probability density function of\nprofits growth rate is described as a tent-shaped exponential function.\nSecondly, the value of the origin of the growth rate distribution divided into\nbins is constant. The derivation is confirmed in the database consistently.\n  This static procedure is applied to a quasi-static system. We dynamically\ndescribe a quasi-static log-normal distribution in the middle scale region. In\nthe derivation, a Non-Gibrat's law under the detailed quasi-balance is adopted\ntogether with two approximations confirmed in the static system. The resultant\ndistribution is power-law with varying Pareto index in the large scale region\nand the quasi-static log-normal distribution in the middle scale region. In the\ndistribution, not only the change of Pareto index but also the change of the\nvariance of the log-normal distribution depends on the parameter of the\ndetailed quasi-balance. As a result, Pareto index and the variance of the\nlog-normal distribution are related to each other.\n"
    },
    {
        "paper_id": 705.1297,
        "authors": "Virginia R. Young",
        "title": "Pricing Life Insurance under Stochastic Mortality via the Instantaneous\n  Sharpe Ratio: Theorems and Proofs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We develop a pricing rule for life insurance under stochastic mortality in an\nincomplete market by assuming that the insurance company requires compensation\nfor its risk in the form of a pre-specified instantaneous Sharpe ratio. Our\nvaluation formula satisfies a number of desirable properties, many of which it\nshares with the standard deviation premium principle. The major result of the\npaper is that the price per contract solves a linear partial differential\nequation as the number of contracts approaches infinity. One can interpret the\nlimiting price as an expectation with respect to an equivalent martingale\nmeasure. Another important result is that if the hazard rate is stochastic,\nthen the risk-adjusted premium is greater than the net premium, even as the\nnumber of contracts approaches infinity. We present a numerical example to\nillustrate our results, along with the corresponding algorithms.\n"
    },
    {
        "paper_id": 705.1302,
        "authors": "Moshe A. Milevsky, S. David Promislow, Virginia R. Young",
        "title": "Financial Valuation of Mortality Risk via the Instantaneous Sharpe\n  Ratio: Applications to Pricing Pure Endowments",
        "comments": "JEL Classification: G13; G22; C60",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We develop a theory for pricing non-diversifiable mortality risk in an\nincomplete market. We do this by assuming that the company issuing a\nmortality-contingent claim requires compensation for this risk in the form of a\npre-specified instantaneous Sharpe ratio. We prove that our ensuing valuation\nformula satisfies a number of desirable properties. For example, we show that\nit is subadditive in the number of contracts sold. A key result is that if the\nhazard rate is stochastic, then the risk-adjusted survival probability is\ngreater than the physical survival probability, even as the number of contracts\napproaches infinity.\n"
    },
    {
        "paper_id": 705.1949,
        "authors": "Siu Lung Law, Chiu Fan Lee, Sam Howison and Jeff N. Dewynne",
        "title": "Correlated multi-asset portfolio optimisation with transaction cost",
        "comments": "Manuscript completely rewritten",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We employ perturbation analysis technique to study multi-asset portfolio\noptimisation with transaction cost. We allow for correlations in risky assets\nand obtain optimal trading methods for general utility functions. Our\nanalytical results are supported by numerical simulations in the context of the\nLong Term Growth Model.\n"
    },
    {
        "paper_id": 705.2097,
        "authors": "L. Gil",
        "title": "A simple algorithm based on fluctuations to play the market",
        "comments": "8 pages 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In Biology, all motor enzymes operate on the same principle: they trap\nfavourable brownian fluctuations in order to generate directed forces and to\nmove. Whether it is possible or not to copy one such strategy to play the\nmarket was the starting point of our investigations. We found the answer is\nyes. In this paper we describe one such strategy and appraise its performance\nwith historical data from the European Monetary System (EMS), the US Dow Jones,\nthe german Dax and the french Cac40.\n"
    },
    {
        "paper_id": 705.2098,
        "authors": "Bikas K. Chakrabarti",
        "title": "Kolkata Restaurant Problem as a generalised El Farol Bar Problem",
        "comments": "2 column RevTeX4, 4 pages, 3 eps figs; to be published in\n  'Econophysics of Markets and Business Networks', [Proc. Econophys-Kolkata\n  III], Eds. A. Chatterjee, B. K. Chakrabarti, New Economic Windows Series,\n  Springer, Milan, 2007, pp. 220-227",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-0665-2_18",
        "license": null,
        "abstract": "  Generalisation of the El Farol bar problem to that of many bars here leads to\nthe Kolkata restaurant problem, where the decision to go to any restaurant or\nnot is much simpler (depending on the previous experience of course, as in the\nEl Farol bar problem). This generalised problem can be exactly analysed in some\nlimiting cases discussed here. The fluctuation in the restaurant service can be\nshown to have precisely an inverse cubic behavior, as widely seen in the stock\nmarket fluctuations.\n"
    },
    {
        "paper_id": 705.211,
        "authors": "Olivier Aj Bardou (GDF-RDD), Sandrine Bouthemy (GDF-RDD), Gilles\n  Pag\\`es (PMA)",
        "title": "Optimal quantization for the pricing of swing options",
        "comments": "27p",
        "journal-ref": "Applied Mathematical Finance 16, 1-2 (2009) 183-217",
        "doi": "10.1080/13504860802453218",
        "license": null,
        "abstract": "  In this paper, we investigate a numerical algorithm for the pricing of swing\noptions, relying on the so-called optimal quantization method. The numerical\nprocedure is described in details and numerous simulations are provided to\nassert its efficiency. In particular, we carry out a comparison with the\nLongstaff-Schwartz algorithm.\n"
    },
    {
        "paper_id": 705.2551,
        "authors": "S.C. Wang, J.J. Tseng, C.C. Tai, K.H. Lai, W.S. Wu, S.H. Chen, S.P. Li",
        "title": "Network Topology of an Experimental Futures Exchange",
        "comments": "6 pages, 12 figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00119-8",
        "license": null,
        "abstract": "  Many systems of different nature exhibit scale free behaviors. Economic\nsystems with power law distribution in the wealth is one of the examples. To\nbetter understand the working behind the complexity, we undertook an empirical\nstudy measuring the interactions between market participants. A Web server was\nsetup to administer the exchange of futures contracts whose liquidation prices\nwere coupled to event outcomes. After free registration, participants started\ntrading to compete for the money prizes upon maturity of the futures contracts\nat the end of the experiment. The evolving `cash' flow network was\nreconstructed from the transactions between players. We show that the network\ntopology is hierarchical, disassortative and scale-free with a power law\nexponent of 1.02+-0.09 in the degree distribution. The small-world property\nemerged early in the experiment while the number of participants was still\nsmall. We also show power law distributions of the net incomes and\ninter-transaction time intervals. Big winners and losers are associated with\nhigh degree, high betweenness centrality, low clustering coefficient and low\ndegree-correlation. We identify communities in the network as groups of the\nlike-minded. The distribution of the community sizes is shown to be power-law\ndistributed with an exponent of 1.19+-0.16.\n"
    },
    {
        "paper_id": 705.282,
        "authors": "Yoichi Hirai (The University of Tokyo, undergraduate)",
        "title": "Entropy Oriented Trading: A Trading Strategy Based on the Second Law of\n  Thermodynamics",
        "comments": "3 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The author proposes a finance trading strategy named Entropy Oriented Trading\nand apply thermodynamics on the strategy. The state variables are chosen so\nthat the strategy satisfies the second law of thermodynamics. Using the law,\nthe author proves that the rate of investment (ROI) of the strategy is equal to\nor more than the rate of price change.\n"
    },
    {
        "paper_id": 705.3248,
        "authors": "Silvio M. Duarte Queiros",
        "title": "On a generalised model for time-dependent variance with long-term memory",
        "comments": "6 pages, 4 figures",
        "journal-ref": "EPL, 80 (2007) 30005",
        "doi": "10.1209/0295-5075/80/30005",
        "license": null,
        "abstract": "  The ARCH process (R. F. Engle, 1982) constitutes a paradigmatic generator of\nstochastic time series with time-dependent variance like it appears on a wide\nbroad of systems besides economics in which ARCH was born. Although the ARCH\nprocess captures the so-called \"volatility clustering\" and the asymptotic\npower-law probability density distribution of the random variable, it is not\ncapable to reproduce further statistical properties of many of these time\nseries such as: the strong persistence of the instantaneous variance\ncharacterised by large values of the Hurst exponent (H > 0.8), and asymptotic\npower-law decay of the absolute values self-correlation function. By means of\nconsidering an effective return obtained from a correlation of past returns\nthat has a q-exponential form we are able to fix the limitations of the\noriginal model. Moreover, this improvement can be obtained through the correct\nchoice of a sole additional parameter, $q_{m}$. The assessment of its validity\nand usefulness is made by mimicking daily fluctuations of SP500 financial\nindex.\n"
    },
    {
        "paper_id": 705.3319,
        "authors": "Jorgen Vitting Andersen",
        "title": "Detecting anchoring in financial markets",
        "comments": "5 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Anchoring is a term used in psychology to describe the common human tendency\nto rely too heavily (anchor) on one piece of information when making decisions.\nA trading algorithm inspired by biological motors, introduced by L.\nGil\\cite{Gil}, is suggested as a testing ground for anchoring in financial\nmarkets. An exact solution of the algorithm is presented for arbitrary price\ndistributions. Furthermore the algorithm is extended to cover the case of a\nmarket neutral portfolio, revealing additional evidence that anchoring is\ninvolved in the decision making of market participants. The exposure of\narbitrage possibilities created by anchoring gives yet another illustration on\nthe difficulty proving market efficiency by only considering lower order\ncorrelations in past price time series\n"
    },
    {
        "paper_id": 705.343,
        "authors": "John Angle",
        "title": "The Macro Model of the Inequality Process and The Surging Relative\n  Frequency of Large Wage Incomes",
        "comments": "26 pages, 21 eps figures, Springer style; to be published in\n  Econophysics of Markets and Business Networks, [Proc. Econophys-Kolkata III],\n  Eds. A. Chatterjee, B.K. Chakrabarti, New Economic Windows Series, Springer,\n  Milan, 2007, pp. 171-196",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-0665-2_14",
        "license": null,
        "abstract": "  This paper presents a model of the dynamics of the wage income distribution.\n"
    },
    {
        "paper_id": 705.376,
        "authors": "Stefan Ankirchner, Peter Imkeller, Alexandre Popier",
        "title": "Optimal cross hedging for insurance derivatives",
        "comments": "27 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider insurance derivatives depending on an external physical risk\nprocess, for example a temperature in a low dimensional climate model. We\nassume that this process is correlated with a tradable financial asset. We\nderive optimal strategies for exponential utility from terminal wealth,\ndetermine the indifference prices of the derivatives, and interpret them in\nterms of diversification pressure. Moreover we check the optimal investment\nstrategies for standard admissibility criteria. Finally we compare the static\nrisk connected with an insurance derivative to the reduced risk due to a\ndynamic investment into the correlated asset. We show that dynamic hedging\nreduces the risk aversion in terms of entropic risk measures by a factor\nrelated to the correlation.\n"
    },
    {
        "paper_id": 705.4023,
        "authors": "Zoltan Eisler, Janos Kertesz, Fabrizio Lillo",
        "title": "The limit order book on different time scales",
        "comments": "11 pages, 7 figures, 2 tables, to appear in Proc. SPIE, Fluctuations\n  and Noise 2007, Florence",
        "journal-ref": "Proc. SPIE 6601, 66010G (2007)",
        "doi": "10.1117/12.724817",
        "license": null,
        "abstract": "  Financial markets can be described on several time scales. We use data from\nthe limit order book of the London Stock Exchange (LSE) to compare how the\nfluctuation dominated microstructure crosses over to a more systematic global\nbehavior.\n"
    },
    {
        "paper_id": 705.4025,
        "authors": "A. Veglio and M. Marsili",
        "title": "Stochastic analysis of an agent-based model",
        "comments": "6 pages, 2 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2007.07.027",
        "license": null,
        "abstract": "  We analyze the dynamics of a forecasting game which exhibits the phenomenon\nof information cascades. Each agent aims at correctly predicting a binary\nvariable and he/she can either look for independent information or herd on the\nchoice of others. We show that dynamics can be analitically described in terms\nof a Langevin equation and its collective behavior is described by the solution\nof a Kramers' problem. This provides very accurate results in the region where\nthe vast majority of agents herd, which corresponds to the most interesting one\nfrom a game theoretic point of view.\n"
    },
    {
        "paper_id": 705.4112,
        "authors": "T. S. Biro and R. Rosenfeld",
        "title": "Microscopic Origin of Non-Gaussian Distributions of Financial Returns",
        "comments": "13 pages, 4 figures. Several clarifying comments, new references and\n  acknowledgments added",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2007.10.067",
        "license": null,
        "abstract": "  In this paper we study the possible microscopic origin of heavy-tailed\nprobability density distributions for the price variation of financial\ninstruments. We extend the standard log-normal process to include another\nrandom component in the so-called stochastic volatility models. We study these\nmodels under an assumption, akin to the Born-Oppenheimer approximation, in\nwhich the volatility has already relaxed to its equilibrium distribution and\nacts as a background to the evolution of the price process. In this\napproximation, we show that all models of stochastic volatility should exhibit\na scaling relation in the time lag of zero-drift modified log-returns. We\nverify that the Dow-Jones Industrial Average index indeed follows this scaling.\nWe then focus on two popular stochastic volatility models, the Heston and\nHull-White models. In particular, we show that in the Hull-White model the\nresulting probability distribution of log-returns in this approximation\ncorresponds to the Tsallis (t-Student) distribution. The Tsallis parameters are\ngiven in terms of the microscopic stochastic volatility model. Finally, we show\nthat the log-returns for 30 years Dow Jones index data is well fitted by a\nTsallis distribution, obtaining the relevant parameters.\n"
    },
    {
        "paper_id": 705.4329,
        "authors": "M. Bartolozzi",
        "title": "Scale-free avalanches in the multifractal random walk",
        "comments": "9 pages, 13 figures. In press: European Physical Journal B",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2007-00178-3",
        "license": null,
        "abstract": "  Avalanches, or Avalanche-like, events are often observed in the dynamical\nbehaviour of many complex systems which span from solar flaring to the Earth's\ncrust dynamics and from traffic flows to financial markets. Self-organized\ncriticality (SOC) is one of the most popular theories able to explain this\nintermittent charge/discharge behaviour. Despite a large amount of theoretical\nwork, empirical tests for SOC are still in their infancy. In the present paper\nwe address the common problem of revealing SOC from a simple time series\nwithout having much information about the underlying system. As a working\nexample we use a modified version of the multifractal random walk originally\nproposed as a model for the stock market dynamics. The study reveals, despite\nthe lack of the typical ingredients of SOC, an avalanche-like dynamics similar\nto that of many physical systems. While, on one hand, the results confirm the\nrelevance of cascade models in representing turbulent-like phenomena, on the\nother, they also raise the question about the current state of reliability of\nSOC inference from time series analysis.\n"
    },
    {
        "paper_id": 705.4487,
        "authors": "Gordan Zitkovic",
        "title": "Utility Maximization with a Stochastic Clock and an Unbounded Random\n  Endowment",
        "comments": null,
        "journal-ref": "Ann. Appl. Prob (2005), vol. 15, no. 1B, pp. 748-777",
        "doi": null,
        "license": null,
        "abstract": "  We introduce a linear space of finitely additive measures to treat the\nproblem of optimal expected utility from consumption under a stochastic clock\nand an unbounded random endowment process. In this way we establish existence\nand uniqueness for a large class of utility maximization problems including the\nclassical ones of terminal wealth or consumption, as well as the problems\ndepending on a random time-horizon or multiple consumption instances. As an\nexample we treat explicitly the problem of maximizing the logarithmic utility\nof a consumption stream, where the local time of an Ornstein-Uhlenbeck process\nacts as a stochastic clock.\n"
    },
    {
        "paper_id": 706.0051,
        "authors": "Ioannis Karatzas, Gordan Zitkovic",
        "title": "Optimal consumption from investment and random endowment in incomplete\n  semimartingale markets",
        "comments": null,
        "journal-ref": "Annals of Probability (2003) vol. 31 no. 4 pp. 1821-1858",
        "doi": null,
        "license": null,
        "abstract": "  We consider the problem of maximizing expected utility from consumption in a\nconstrained incomplete semimartingale market with a random endowment process,\nand establish a general existence and uniqueness result using techniques from\nconvex duality. The notion of asymptotic elasticity of Kramkov and\nSchachermayer is extended to the time-dependent case. By imposing no smoothness\nrequirements on the utility function in the temporal argument, we can treat\nboth pure consumption and combined consumption/terminal wealth problems, in a\ncommon framework. To make the duality approach possible, we provide a detailed\ncharacterization of the enlarged dual domain which is reminiscent of the\nenlargement of $L^1$ to its topological bidual $(L^{\\infty})^*$, a space of\nfinitely-additive measures. As an application, we treat the case of a\nconstrained It\\^ o-process market-model.\n"
    },
    {
        "paper_id": 706.0168,
        "authors": "Michele Tumminello, Fabrizio Lillo, Rosario Nunzio Mantegna",
        "title": "Kullback-Leibler distance as a measure of the information filtered from\n  multivariate data",
        "comments": "13 pages, 6 figures",
        "journal-ref": "Phys. Rev. E 76, 031123 (2007)",
        "doi": "10.1103/PhysRevE.76.031123",
        "license": null,
        "abstract": "  We show that the Kullback-Leibler distance is a good measure of the\nstatistical uncertainty of correlation matrices estimated by using a finite set\nof data. For correlation matrices of multivariate Gaussian variables we\nanalytically determine the expected values of the Kullback-Leibler distance of\na sample correlation matrix from a reference model and we show that the\nexpected values are known also when the specific model is unknown. We propose\nto make use of the Kullback-Leibler distance to estimate the information\nextracted from a correlation matrix by correlation filtering procedures. We\nalso show how to use this distance to measure the stability of filtering\nprocedures with respect to statistical uncertainty. We explain the\neffectiveness of our method by comparing four filtering procedures, two of them\nbeing based on spectral analysis and the other two on hierarchical clustering.\nWe compare these techniques as applied both to simulations of factor models and\nempirical data. We investigate the ability of these filtering procedures in\nrecovering the correlation matrix of models from simulations. We discuss such\nan ability in terms of both the heterogeneity of model parameters and the\nlength of data series. We also show that the two spectral techniques are\ntypically more informative about the sample correlation matrix than techniques\nbased on hierarchical clustering, whereas the latter are more stable with\nrespect to statistical uncertainty.\n"
    },
    {
        "paper_id": 706.0462,
        "authors": "Gordan Zitkovic",
        "title": "Financial equilibria in the semimartingale setting: complete markets and\n  markets with withdrawal constraints",
        "comments": null,
        "journal-ref": "Gordan Zitkovic, \"Financial equilibria in the semimartingale\n  setting: complete markets and markets with withdrawal constraints\" (2006)\n  Finance and Stochastics vol.10 pp. 99-119",
        "doi": null,
        "license": null,
        "abstract": "  Existence of stochastic financial equilibria giving rise to semimartingale\nasset prices is established under a general class of assumptions. These\nequilibria are expressed in real terms and span complete markets or markets\nwith withdrawal constraints.We deal with random endowment density streams which\nadmit jumps and general time-dependent utility functions on which only\nregularity conditions are imposed. As an integral part of the proof of the main\nresult, we establish a novel characterization of semimartingale functions.\n"
    },
    {
        "paper_id": 706.0468,
        "authors": "Kasper Larsen, Gordan Zitkovic",
        "title": "On the semimartingale property via bounded logarithmic utility",
        "comments": "K. Larsen, G. Zitkovic, \"On the semimartingale property via bounded\n  logarithmic utility\" (2006) to appear in Annals of Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper provides a new version of the condition of Di Nunno et al. (2003),\nAnkirchner and Imkeller (2005) and Biagini and \\{O}ksendal (2005) ensuring the\nsemimartingale property for a large class of continuous stochastic processes.\nUnlike our predecessors, we base our modeling framework on the concept of\nportfolio proportions which yields a short self-contained proof of the main\ntheorem, as well as a counterexample, showing that analogues of our results do\nnot hold in the discontinuous setting.\n"
    },
    {
        "paper_id": 706.0474,
        "authors": "Kasper Larsen, Gordan Zitkovic",
        "title": "Stability of utility-maximization in incomplete markets",
        "comments": "to appear in Stochastic Processes and Applications",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The effectiveness of utility-maximization techniques for portfolio management\nrelies on our ability to estimate correctly the parameters of the dynamics of\nthe underlying financial assets. In the setting of complete or incomplete\nfinancial markets, we investigate whether small perturbations of the market\ncoefficient processes lead to small changes in the agent's optimal behavior\nderived from the solution of the related utility-maximization problems.\nSpecifically, we identify the topologies on the parameter process space and the\nsolution space under which utility-maximization is a continuous operation, and\nwe provide a counterexample showing that our results are best possible, in a\ncertain sense. A novel result about the structure of the solution of the\nutility-maximization problem where prices are modeled by continuous\nsemimartingales is established as an offshoot of the proof of our central\ntheorem.\n"
    },
    {
        "paper_id": 706.0478,
        "authors": "Mark Owen, Gordan Zitkovic",
        "title": "Optimal Investment with an Unbounded Random Endowment and Utility-Based\n  Pricing",
        "comments": "major revision (mostly, but not entirely, cosmetic)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper studies the problem of maximizing the expected utility of terminal\nwealth for a financial agent with an unbounded random endowment, and with a\nutility function which supports both positive and negative wealth. We prove the\nexistence of an optimal trading strategy within a class of permissible\nstrategies -- those strategies whose wealth process is a supermartingale under\nall pricing measures with finite relative entropy. We give necessary and\nsufficient conditions for the absence of utility-based arbitrage, and for the\nexistence of a solution to the primal problem.\n  We consider two utility-based methods which can be used to price contingent\nclaims. Firstly we investigate marginal utility-based price processes\n(MUBPP's). We show that such processes can be characterized as local\nmartingales under the normalized optimal dual measure for the utility\nmaximizing investor. Finally, we present some new results on utility\nindifference prices, including continuity properties and volume asymptotics for\nthe case of a general utility function, unbounded endowment and unbounded\ncontingent claims.\n"
    },
    {
        "paper_id": 706.048,
        "authors": "Traian A. Pirvu, Gordan Zitkovic",
        "title": "Maximizing the Growth Rate under Risk Constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate the ergodic problem of growth-rate maximization under a class\nof risk constraints in the context of incomplete, It\\^{o}-process models of\nfinancial markets with random ergodic coefficients. Including {\\em\nvalue-at-risk} (VaR), {\\em tail-value-at-risk} (TVaR), and {\\em limited\nexpected loss} (LEL), these constraints can be both wealth-dependent(relative)\nand wealth-independent (absolute). The optimal policy is shown to exist in an\nappropriate admissibility class, and can be obtained explicitly by uniform,\nstate-dependent scaling down of the unconstrained (Merton) optimal portfolio.\nThis implies that the risk-constrained wealth-growth optimizer locally behaves\nlike a CRRA-investor, with the relative risk-aversion coefficient depending on\nthe current values of the market coefficients.\n"
    },
    {
        "paper_id": 706.0482,
        "authors": "Constantinos Kardaras and Gordan Zitkovic",
        "title": "Stability of the utility maximization problem with random endowment in\n  incomplete markets",
        "comments": "21 pages, revised version. To appear in \"Mathematical Finance\".",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform a stability analysis for the utility maximization problem in a\ngeneral semimartingale model where both liquid and illiquid assets (random\nendowments) are present. Small misspecifications of preferences (as modeled via\nexpected utility), as well as views of the world or the market model (as\nmodeled via subjective probabilities) are considered. Simple sufficient\nconditions are given for the problem to be well-posed, in the sense the optimal\nwealth and the marginal utility-based prices are continuous functionals of\npreferences and probabilistic views.\n"
    },
    {
        "paper_id": 706.0664,
        "authors": "O.Bundau, M.Neamtu, D.Opris",
        "title": "Rent seeking games with tax evasion",
        "comments": "8 pages, 4 figures, the paper was presented at Pannonian Applied\n  Mathematical Meetings, 31 may-3june, 2007",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider the static and dynamic models of Cournot duopoly with tax\nevasion. In the dynamic model we introduce the time delay and we analyze the\nlocal stability of the stationary state. There is a critical value of the delay\nwhen the Hopf bifurcation occurs.\n"
    },
    {
        "paper_id": 706.1028,
        "authors": "Tanya Ara\\'ujo, G\\'erard Weisbuch",
        "title": "Hiking the hypercube: producers and consumers",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the dynamics of co-evolution of producers and customers described by\nbit-strings representing individual traits. Individual ''size-like'' properties\nare controlled by binary encounters which outcome depends upon a recognition\nprocess. Depending upon the parameter set-up, mutual selection of producers and\ncustomers results in different types of attractors, either an exclusive niches\nregime or a competition regime.\n"
    },
    {
        "paper_id": 706.1247,
        "authors": "Silvio M. Duarte Queiros",
        "title": "Are all highly liquid securities within the same class?",
        "comments": "To be published in EPJB",
        "journal-ref": "Eur. Phys. J. B 60, 265-269 (2007)",
        "doi": "10.1140/epjb/e2007-00336-7",
        "license": null,
        "abstract": "  In this manuscript we analyse the leading statistical properties of\nfluctuations of (log) 3-month US Treasury bill quotation in the secondary\nmarket, namely: probability density function, autocorrelation, absolute values\nautocorrelation, and absolute values persistency. We verify that this financial\ninstrument, in spite of its high liquidity, shows very peculiar properties.\nParticularly, we verify that log-fluctuations belong to the Levy class of\nstochastic variables.\n"
    },
    {
        "paper_id": 706.13,
        "authors": "Luigi Accardi and Andreas Boukas",
        "title": "The Quantum Black-Scholes Equation",
        "comments": "Has appeared in GJPAM, vol. 2, no. 2, pp. 155-170 (2006)",
        "journal-ref": "GJPAM, vol. 2, no. 2, pp. 155-170 (2006)",
        "doi": null,
        "license": null,
        "abstract": "  Motivated by the work of Segal and Segal on the Black-Scholes pricing formula\nin the quantum context, we study a quantum extension of the Black-Scholes\nequation within the context of Hudson-Parthasarathy quantum stochastic\ncalculus. Our model includes stock markets described by quantum Brownian motion\nand Poisson process.\n"
    },
    {
        "paper_id": 706.1454,
        "authors": "G\\'erard Weisbuch, Vincent Buskens, Luat Vuong",
        "title": "Heterogeneity and Increasing Returns May Drive Socio-Economic\n  Transitions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  There are clear benefits associated with a particular consumer choice for\nmany current markets. For example, as we consider here, some products might\ncarry environmental or `green' benefits. Some consumers might value these\nbenefits while others do not. However, as evidenced by myriad failed attempts\nof environmental products to maintain even a niche market, such benefits do not\nnecessarily outweigh the extra purchasing cost. The question we pose is, how\ncan such an initially economically-disadvantaged green product evolve to hold\nthe greater share of the market? We present a simple mathematical model for the\ndynamics of product competition in a heterogeneous consumer population. Our\nmodel preassigns a hierarchy to the products, which designates the consumer\nchoice when prices are comparable, while prices are dynamically rescaled to\nreflect increasing returns to scale. Our approach allows us to model many\nscenarios of technology substitution and provides a method for generalizing\nmarket forces. With this model, we begin to forecast irreversible trends\nassociated with consumer dynamics as well as policies that could be made to\ninfluence transitions\n"
    },
    {
        "paper_id": 706.146,
        "authors": "G. R. Jafari, M. Sadegh Movahed, P. Noroozzadeh, A. Bahraminasab,\n  Muhammad Sahimi, F. Ghasemi, and M. Reza Rahimi Tabar",
        "title": "Uncertainty in the Fluctuations of the Price of Stocks",
        "comments": "5 pages, 5 figures. Accepted to appear in IJMPC",
        "journal-ref": null,
        "doi": "10.1142/S0129183107011662",
        "license": null,
        "abstract": "  We report on a study of the Tehran Price Index (TEPIX) from 2001 to 2006 as\nan emerging market that has been affected by several political crises during\nthe recent years, and analyze the non-Gaussian probability density function\n(PDF) of the log returns of the stocks' prices. We show that while the average\nof the index did not fall very much over the time period of the study, its\nday-to-day fluctuations strongly increased due to the crises. Using an approach\nbased on multiplicative processes with a detrending procedure, we study the\nscale-dependence of the non-Gaussian PDFs, and show that the temporal\ndependence of their tails indicates a gradual and systematic increase in the\nprobability of the appearance of large increments in the returns on approaching\ndistinct critical time scales over which the TEPIX has exhibited maximum\nuncertainty.\n"
    },
    {
        "paper_id": 706.1836,
        "authors": "Rohit Deo (IOMS), Meng-Chen Hsieh, Clifford M. Hurvich (IOMS),\n  Philippe Soulier (MODAL'X)",
        "title": "Long Memory in Nonlinear Processes",
        "comments": null,
        "journal-ref": "D\\'ependence in probability and statistics, Springer (Ed.) (2006)\n  221--244",
        "doi": null,
        "license": null,
        "abstract": "  It is generally accepted that many time series of practical interest exhibit\nstrong dependence, i.e., long memory. For such series, the sample\nautocorrelations decay slowly and log-log periodogram plots indicate a\nstraight-line relationship. This necessitates a class of models for describing\nsuch behavior. A popular class of such models is the autoregressive\nfractionally integrated moving average (ARFIMA) which is a linear process.\nHowever, there is also a need for nonlinear long memory models. For example,\nseries of returns on financial assets typically tend to show zero correlation,\nwhereas their squares or absolute values exhibit long memory. Furthermore, the\nsearch for a realistic mechanism for generating long memory has led to the\ndevelopment of other nonlinear long memory models. In this chapter, we will\npresent several nonlinear long memory models, and discuss the properties of the\nmodels, as well as associated parametric andsemiparametric estimators.\n"
    },
    {
        "paper_id": 706.1839,
        "authors": "Didier Sornette (ETH Zurich)",
        "title": "Nurturing Breakthroughs: Lessons from Complexity Theory",
        "comments": "14 pages, Invited talk at the workshop Trans-disciplinary Research\n  Agenda for Societal Dynamics (http://www.uni-lj.si/trasd in Ljubljana),\n  organized by J. Rogers Hollingsworth, Karl H. Mueller, Ivan Svetlik, 24 - 25\n  May 2007, Ljubljana, Slovenia",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A general theory of innovation and progress in human society is outlined,\nbased on the combat between two opposite forces (conservatism/inertia and\nspeculative herding \"bubble\" behavior). We contend that human affairs are\ncharacterized by ubiquitous ``bubbles'', which involve huge risks which would\nnot otherwise be taken using standard cost/benefit analysis. Bubbles result\nfrom self-reinforcing positive feedbacks. This leads to explore uncharted\nterritories and niches whose rare successes lead to extraordinary discoveries\nand provide the base for the observed accelerating development of technology\nand of the economy. But the returns are very heterogeneous, very risky and may\nnot occur. In other words, bubbles, which are characteristic definitions of\nhuman activity, allow huge risks to get huge returns over large scales. We\noutline some underlying mathematical structure and a few results involving\npositive feedbacks, emergence, heavy-tailed power laws, outliers/kings/black\nswans, the problem of predictability and the illusion of control, as well as\nsome policy implications.\n"
    },
    {
        "paper_id": 706.214,
        "authors": "Zhi-Qiang Jiang, Wei-Xing Zhou (ECUST)",
        "title": "Multifractality in stock indexes: Fact or fiction?",
        "comments": "14 elsart pages including 6 eps figures",
        "journal-ref": "Physica A 387 (14), 3605-3614 (2008).",
        "doi": "10.1016/j.physa.2008.02.015",
        "license": null,
        "abstract": "  Multifractal analysis and extensive statistical tests are performed upon\nintraday minutely data within individual trading days for four stock market\nindexes (including HSI, SZSC, S&P500, and NASDAQ) to check whether the indexes\n(instead of the returns) possess multifractality. We find that the mass\nexponent $\\tau(q)$ is linear and the singularity $\\alpha(q)$ is close to 1 for\nall trading days and all indexes. Furthermore, we find strong evidence showing\nthat the scaling behaviors of the original data sets cannot be distinguished\nfrom those of the shuffled time series. Hence, the so-called multifractality in\nthe intraday stock market indexes is merely an illusion.\n"
    },
    {
        "paper_id": 706.3122,
        "authors": "H. M. Yang, Y. S. Ting, and K. Y. Michael Wong",
        "title": "Effects of payoff functions and preference distributions in an adaptive\n  population",
        "comments": null,
        "journal-ref": "Phys. Rev. E 77, 031116 (2008)",
        "doi": "10.1103/PhysRevE.77.031116",
        "license": null,
        "abstract": "  Adaptive populations such as those in financial markets and distributed\ncontrol can be modeled by the Minority Game. We consider how their dynamics\ndepends on the agents' initial preferences of strategies, when the agents use\nlinear or quadratic payoff functions to evaluate their strategies. We find that\nthe fluctuations of the population making certain decisions (the volatility)\ndepends on the diversity of the distribution of the initial preferences of\nstrategies. When the diversity decreases, more agents tend to adapt their\nstrategies together. In systems with linear payoffs, this results in dynamical\ntransitions from vanishing volatility to a non-vanishing one. For low signal\ndimensions, the dynamical transitions for the different signals do not take\nplace at the same critical diversity. Rather, a cascade of dynamical\ntransitions takes place when the diversity is reduced. In contrast, no phase\ntransitions are found in systems with the quadratic payoffs. Instead, a basin\nboundary of attraction separates two groups of samples in the space of the\nagents' decisions. Initial states inside this boundary converge to small\nvolatility, while those outside diverge to a large one. Furthermore, when the\npreference distribution becomes more polarized, the dynamics becomes more\nerratic. All the above results are supported by good agreement between\nsimulations and theory.\n"
    },
    {
        "paper_id": 706.3331,
        "authors": "Yunfen Bai (1 and 2), Xinhua Hu (1), Zhongxing Ye (1) ((1)Department\n  of Mathematics, Shanghai Jiaotong University; (2)Department of Mathematics,\n  Shijiazhuang College)",
        "title": "A Model for Counterparty Risk with Geometric Attenuation Effect and the\n  Valuation of CDS",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper, a geometric function is introduced to reflect the attenuation\nspeed of impact of one firm's default to its partner. If two firms are\ncompetitions (copartners), the default intensity of one firm will decrease\n(increase) abruptly when the other firm defaults. As time goes on, the impact\nwill decrease gradually until extinct. In this model, the joint distribution\nand marginal distributions of default times are derived by employing the change\nof measure, so can we value the fair swap premium of a CDS.\n"
    },
    {
        "paper_id": 706.3827,
        "authors": "R. Vilela Mendes",
        "title": "The fractional volatility model: An agent-based interpretation",
        "comments": "23 pages, 11 figures",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, 387 (2008)\n  3987-3994",
        "doi": "10.1016/j.physa.2008.01.052",
        "license": null,
        "abstract": "  Based on criteria of mathematical simplicity and consistency with empirical\nmarket data, a model with volatility driven by fractional noise has been\nconstructed which provides a fairly accurate mathematical parametrization of\nthe data. Here, some features of the model are discussed and, using agent-based\nmodels, one tries to find which agent strategies and (or) properties of the\nfinancial institutions might be responsible for the features of the fractional\nvolatility model.\n"
    },
    {
        "paper_id": 706.4432,
        "authors": "Willemien Kets",
        "title": "The minority game: An economics perspective",
        "comments": "30 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper gives a critical account of the minority game literature. The\nminority game is a simple congestion game: players need to choose between two\noptions, and those who have selected the option chosen by the minority win. The\nlearning model proposed in this literature seems to differ markedly from the\nlearning models commonly used in economics. We relate the learning model from\nthe minority game literature to standard game-theoretic learning models, and\nshow that in fact it shares many features with these models. However, the\npredictions of the learning model differ considerably from the predictions of\nmost other learning models. We discuss the main predictions of the learning\nmodel proposed in the minority game literature, and compare these to\nexperimental findings on congestion games.\n"
    },
    {
        "paper_id": 707.0324,
        "authors": "Philip V. Fellman and Jonathan Vos Post",
        "title": "Quantum Nash Equilibria and Quantum Computing",
        "comments": "18 Pages, 6th International Conference on Complex Systems. Available\n  from http://necsi.org/events/iccs6/papers/12dc335ba096f7ee3cf094c55489.pdf",
        "journal-ref": "InterJournal Complex Systems, 1846, 2006",
        "doi": "10.1007/978-3-540-85081-6_56",
        "license": null,
        "abstract": "  In this paper we review our earlier work on quantum computing and the Nash\nEquilibrium, in particular, tracing the history of the discovery of new Nash\nEquilibria and then reviewing the ways in which quantum computing may be\nexpected to generate new classes of Nash equilibria. We then extend this work\nthrough a substantive analysis of examples provided by Meyer, Flitney, Iqbal\nand Weigert and Cheon and Tsutsui with respect to quantized games, quantum game\nstrategies and the extension of Nash Equilibrium to solvable games in Hilbert\nspace. Finally, we review earlier work by Sato, Taiji and Ikegami on non-linear\ncomputation and computational classes by way of reference to coherence,\ndecoherence and quantum computating systems.\n"
    },
    {
        "paper_id": 707.0385,
        "authors": "Fabrizio Lillo, Esteban Moro, Gabriella Vaglica, Rosario N. Mantegna",
        "title": "Specialization of strategies and herding behavior of trading firms in a\n  financial market",
        "comments": "8 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/10/4/043019",
        "license": null,
        "abstract": "  The understanding of complex social or economic systems is an important\nscientific challenge. Here we present a comprehensive study of the Spanish\nStock Exchange showing that most financial firms trading in that market are\ncharacterized by a resulting strategy and can be classified in groups of firms\nwith different specialization. Few large firms overally act as trending firms\nwhereas many heterogeneous firm act as reversing firms. The herding properties\nof these two groups are markedly different and consistently observed over a\nfour-year period of trading.\n"
    },
    {
        "paper_id": 707.0854,
        "authors": "Philip V. Fellman, Jonathan Vos Post, Roxana Wright and Usha Dasari",
        "title": "Adaptation and Coevolution on an Emergent Global Competitive Landscape",
        "comments": "16 pages, 5th International Conference on Complex Systems",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Notions of Darwinian selection have been implicit in economic theory for at\nleast sixty years. Richard Nelson and Sidney Winter have argued that while\nevolutionary thinking was prevalent in prewar economics, the postwar\nNeoclassical school became almost entirely preoccupied with equilibrium\nconditions and their mathematical conditions. One of the problems with the\neconomic interpretation of firm selection through competition has been a weak\ngrasp on an incomplete scientific paradigm. As I.F. Price notes, \"The\nbiological metaphor has long lurked in the background of management theory\nlargely because the message of 'survival of the fittest' (usually wrongly\nattributed to Charles Darwin rather than Herbert Spencer) provides a seemingly\nnatural model for market competition (e.g. Alchian 1950, Merrell 1984,\nHenderson 1989, Moore 1993), without seriously challenging the underlying\nparadigms of what an organisation is.\" In this paper we examine the application\nof dynamic fitness landscape models to economic theory, particularly the theory\nof technology substitution, drawing on recent work by Kauffman, Arthur,\nMcKelvey, Nelson and Winter, and Windrum and Birchenhall. In particular we use\nProfessor Post's early work with John Holland on the genetic algorithm to\nexplain some of the key differences between static and dynamic approaches to\neconomic modeling.\n"
    },
    {
        "paper_id": 707.1897,
        "authors": "Esteban Guevara Hidalgo",
        "title": "Maximum Entropy, the Collective Welfare Principle and the Globalization\n  Process",
        "comments": "Econophysics Colloquium & Beyond (Ancona, Italy, 2007), 7 pages.\n  arXiv admin note: substantial text overlap with arXiv:0705.0029,\n  arXiv:physics/0609088, arXiv:physics/0609245; text overlap with\n  arXiv:quant-ph/0510238",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Although both systems analyzed are described through two theories apparently\ndifferent (quantum mechanics and game theory) it is shown that both are\nanalogous and thus exactly equivalents. The quantum analogue of the replicator\ndynamics is the von Neumann equation. Quantum mechanics could be used to\nexplain more correctly biological and economical processes. It could even\nencloses theories like games and evolutionary dynamics. We can take some\nconcepts and definitions from quantum mechanics and physics for the best\nunderstanding of the behavior of economics and biology. Also, we could maybe\nunderstand nature like a game in where its players compete for a common welfare\nand the equilibrium of the system that they are members. All the members of our\nsystem will play a game in which its maximum payoff is the equilibrium of the\nsystem. They act as a whole besides individuals like they obey a rule in where\nthey prefer to work for the welfare of the collective besides the individual\nwelfare. A system where its members are in Nash Equilibrium (or ESS) is exactly\nequivalent to a system in a maximum entropy state. A system is stable only if\nit maximizes the welfare of the collective above the welfare of the individual.\nIf it is maximized the welfare of the individual above the welfare of the\ncollective the system gets unstable an eventually collapses. The results of\nthis work shows that the \"globalization\" process has a behavior exactly\nequivalent to a system that is tending to a maximum entropy state and predicts\nthe apparition of big common markets and strong common currencies that will\nfind its \"equilibrium\" by decreasing its number until they get a state\ncharacterized by only one common currency and only one common market around the\nworld.\n"
    },
    {
        "paper_id": 707.2284,
        "authors": "Xi-Yuan Qian, Fu-Tie Song, Wei-Xing Zhou (ECUST)",
        "title": "Nonlinear behavior of the Chinese SSEC index with a unit root: Evidence\n  from threshold unit root tests",
        "comments": "10 Elsart pages + 5 tables + 1 eps figure",
        "journal-ref": "Physica A 387 (2-3), 503-510 (2008)",
        "doi": "10.1016/j.physa.2007.09.029",
        "license": null,
        "abstract": "  We investigate the behavior of the Shanghai Stock Exchange Composite (SSEC)\nindex for the period from 1990:12 to 2007:06 using an unconstrained two-regime\nthreshold autoregressive (TAR) model with an unit root developed by Caner and\nHansen. The method allows us to simultaneously consider non-stationarity and\nnonlinearity in financial time series. Our finding indicates that the Shanghai\nstock market exhibits nonlinear behavior with two regimes and has unit roots in\nboth regimes. The important implications of the threshold effect in stock\nmarkets are also discussed.\n"
    },
    {
        "paper_id": 707.2341,
        "authors": "Amac Herdagdelen, Haluk Bingol",
        "title": "A Cultural Market Model",
        "comments": null,
        "journal-ref": "International Journal of Modern Physics C Vol. 19, No. 2, 271-282\n  (2008)",
        "doi": "10.1142/S012918310801208X",
        "license": null,
        "abstract": "  Social interactions and personal tastes shape our consumption behavior of\ncultural products. In this study, we present a computational model of a\ncultural market and we aim to analyze the behavior of the consumer population\nas an emergent phenomena. Our results suggest that the final market shares of\ncultural products dramatically depend on consumer heterogeneity and social\ninteraction pressure. Furthermore, the relation between the resulting market\nshares and social interaction is robust with respect to a wide range of\nvariation in the parameter values and the type of topology.\n"
    },
    {
        "paper_id": 707.3198,
        "authors": "Jan Palczewski and Lukasz Stettner",
        "title": "Growth-optimal portfolios under transaction costs",
        "comments": "32 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper studies a portfolio optimization problem in a discrete-time\nMarkovian model of a financial market, in which asset price dynamics depend on\nan external process of economic factors. There are transaction costs with a\nstructure that covers, in particular, the case of fixed plus proportional\ncosts. We prove that there exists a self-financing trading strategy maximizing\nthe average growth rate of the portfolio wealth. We show that this strategy has\na Markovian form. Our result is obtained by large deviations estimates on\nempirical measures of the price process and by a generalization of the\nvanishing discount method to discontinuous transition operators.\n"
    },
    {
        "paper_id": 707.3321,
        "authors": "M. Bartolozzi, C. Mellen, T. Di Matteo and T. Aste",
        "title": "Multi-scale correlations in different futures markets",
        "comments": "14 pages and 25 figures",
        "journal-ref": "Eur. Phys. J. B vol. 58 (2007) p.207-220",
        "doi": "10.1140/epjb/e2007-00216-2",
        "license": null,
        "abstract": "  In the present work we investigate the multiscale nature of the correlations\nfor high frequency data (1 minute) in different futures markets over a period\nof two years, starting on the 1st of January 2003 and ending on the 31st of\nDecember 2004. In particular, by using the concept of \"local\" Hurst exponent,\nwe point out how the behaviour of this parameter, usually considered as a\nbenchmark for persistency/antipersistency recognition in time series, is\nlargely time-scale dependent in the market context. These findings are a direct\nconsequence of the intrinsic complexity of a system where trading strategies\nare scale-adaptive. Moreover, our analysis points out different regimes in the\ndynamical behaviour of the market indices under consideration.\n"
    },
    {
        "paper_id": 707.3478,
        "authors": "Rudi Sch\\\"afer, Markus Sj\\\"olin, Andreas Sundin, Michal Wolanski and\n  Thomas Guhr",
        "title": "Credit risk - A structural model with jumps and correlations",
        "comments": "24 pages",
        "journal-ref": "Physica A 383, 533 (2007)",
        "doi": "10.1016/j.physa.2007.04.053",
        "license": null,
        "abstract": "  We set up a structural model to study credit risk for a portfolio containing\nseveral or many credit contracts. The model is based on a jump--diffusion\nprocess for the risk factors, i.e. for the company assets. We also include\ncorrelations between the companies. We discuss that models of this type have\nmuch in common with other problems in statistical physics and in the theory of\ncomplex systems. We study a simplified version of our model analytically.\nFurthermore, we perform extensive numerical simulations for the full model. The\nobservables are the loss distribution of the credit portfolio, its moments and\nother quantities derived thereof. We compile detailed information about the\nparameter dependence of these observables. In the course of setting up and\nanalyzing our model, we also give a review of credit risk modeling for a\nphysics audience.\n"
    },
    {
        "paper_id": 707.3482,
        "authors": "Kenton K. Yee",
        "title": "A Bayesian Framework for Combining Valuation Estimates",
        "comments": "Citations at\n  http://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=240309 Review of\n  Quantitative Finance and Accounting, 30.3 (2008) forthcoming",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Obtaining more accurate equity value estimates is the starting point for\nstock selection, value-based indexing in a noisy market, and beating benchmark\nindices through tactical style rotation. Unfortunately, discounted cash flow,\nmethod of comparables, and fundamental analysis typically yield discrepant\nvaluation estimates. Moreover, the valuation estimates typically disagree with\nmarket price. Can one form a superior valuation estimate by averaging over the\nindividual estimates, including market price? This article suggests a Bayesian\nframework for combining two or more estimates into a superior valuation\nestimate. The framework justifies the common practice of averaging over several\nestimates to arrive at a final point estimate.\n"
    },
    {
        "paper_id": 707.3703,
        "authors": "Ion Spanulescu, Anca Gheorghiu",
        "title": "Economic Amplifier - A New Econophysics Model",
        "comments": "13 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Most of the econometric and econophysics models have been borrowed from the\nstatistical physics, and as a cosequence, a new interdisciplinary science\ncalled econophysics has emerged. In this paper we planned to extend the analogy\nbetween different economic processes or phenomena and processes and phenomena\nfrom different fields of physics, other than statistical physics. On the basis\nof the economic development process and amplification phenomenon analogy, a new\neconophysics model, named economic amplifier, on the electronic amplification\nprinciple from applied physics was proposed und largely analyzed.\n"
    },
    {
        "paper_id": 707.4343,
        "authors": "K. Bhattacharya, G. Mukherjee, J. Saramaki, K. Kaski, and S. S. Manna",
        "title": "The International Trade Network: weighted network analysis and modelling",
        "comments": "5 pages, 5 figures",
        "journal-ref": "J. Stat. Mech. (2008) P02002",
        "doi": "10.1088/1742-5468/2008/02/P02002",
        "license": null,
        "abstract": "  Tools of the theory of critical phenomena, namely the scaling analysis and\nuniversality, are argued to be applicable to large complex web-like network\nstructures. Using a detailed analysis of the real data of the International\nTrade Network we argue that the scaled link weight distribution has an\napproximate log-normal distribution which remains robust over a period of 53\nyears. Another universal feature is observed in the power-law growth of the\ntrade strength with gross domestic product, the exponent being similar for all\ncountries. Using the 'rich-club' coefficient measure of the weighted networks\nit has been shown that the size of the rich-club controlling half of the\nworld's trade is actually shrinking. While the gravity law is known to describe\nwell the social interactions in the static networks of population migration,\ninternational trade, etc, here for the first time we studied a non-conservative\ndynamical model based on the gravity law which excellently reproduced many\nempirical features of the ITN.\n"
    },
    {
        "paper_id": 707.4347,
        "authors": "K. Bhattacharya, G. Mukherjee and S. S. Manna",
        "title": "The International Trade Network",
        "comments": "9 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-0665-2_10",
        "license": null,
        "abstract": "  Bilateral trade relationships in the international level between pairs of\ncountries in the world give rise to the notion of the International Trade\nNetwork (ITN). This network has attracted the attention of network researchers\nas it serves as an excellent example of the weighted networks, the link weight\nbeing defined as a measure of the volume of trade between two countries. In\nthis paper we analyzed the international trade data for 53 years and studied in\ndetail the variations of different network related quantities associated with\nthe ITN. Our observation is that the ITN has also a scale invariant structure\nlike many other real-world networks.\n"
    },
    {
        "paper_id": 707.4638,
        "authors": "Fengzhong Wang, Kazuko Yamasaki, Shlomo Havlin and H. Eugene Stanley",
        "title": "Indication of multiscaling in the volatility return intervals of stock\n  markets",
        "comments": "19 pages, 6 figures",
        "journal-ref": "Phys. Rev. E 77, 016109 (2008)",
        "doi": "10.1103/PhysRevE.77.016109",
        "license": null,
        "abstract": "  The distribution of the return intervals $\\tau$ between volatilities above a\nthreshold $q$ for financial records has been approximated by a scaling\nbehavior. To explore how accurate is the scaling and therefore understand the\nunderlined non-linear mechanism, we investigate intraday datasets of 500 stocks\nwhich consist of the Standard & Poor's 500 index. We show that the cumulative\ndistribution of return intervals has systematic deviations from scaling. We\nsupport this finding by studying the m-th moment $\\mu_m \\equiv\n<(\\tau/<\\tau>)^m>^{1/m}$, which show a certain trend with the mean interval\n$<\\tau>$. We generate surrogate records using the Schreiber method, and find\nthat their cumulative distributions almost collapse to a single curve and\nmoments are almost constant for most range of $<\\tau>$. Those substantial\ndifferences suggest that non-linear correlations in the original volatility\nsequence account for the deviations from a single scaling law. We also find\nthat the original and surrogate records exhibit slight tendencies for short and\nlong $<\\tau>$, due to the discreteness and finite size effects of the records\nrespectively. To avoid as possible those effects for testing the multiscaling\nbehavior, we investigate the moments in the range $10<<\\tau>\\leq100$, and find\nthe exponent $\\alpha$ from the power law fitting $\\mu_m\\sim<\\tau>^\\alpha$ has a\nnarrow distribution around $\\alpha\\neq0$ which depend on m for the 500 stocks.\nThe distribution of $\\alpha$ for the surrogate records are very narrow and\ncentered around $\\alpha=0$. This suggests that the return interval distribution\nexhibit multiscaling behavior due to the non-linear correlations in the\noriginal volatility.\n"
    },
    {
        "paper_id": 708.0046,
        "authors": "Joshua Brodie, Ingrid Daubechies, Christine De Mol, Domenico Giannone,\n  Ignace Loris",
        "title": "Sparse and stable Markowitz portfolios",
        "comments": "Better emphasis of main result, new abstract, new examples and\n  figures. New appendix with full details of algorithm. 17 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1073/pnas.0904287106",
        "license": null,
        "abstract": "  We consider the problem of portfolio selection within the classical Markowitz\nmean-variance framework, reformulated as a constrained least-squares regression\nproblem. We propose to add to the objective function a penalty proportional to\nthe sum of the absolute values of the portfolio weights. This penalty\nregularizes (stabilizes) the optimization problem, encourages sparse portfolios\n(i.e. portfolios with only few active positions), and allows to account for\ntransaction costs. Our approach recovers as special cases the\nno-short-positions portfolios, but does allow for short positions in limited\nnumber. We implement this methodology on two benchmark data sets constructed by\nFama and French. Using only a modest amount of training data, we construct\nportfolios whose out-of-sample performance, as measured by Sharpe ratio, is\nconsistently and significantly better than that of the naive evenly-weighted\nportfolio which constitutes, as shown in recent literature, a very tough\nbenchmark.\n"
    },
    {
        "paper_id": 708.0063,
        "authors": "Okyu Kwon, Jae-Suk Yang",
        "title": "Information flow between composite stock index and individual stocks",
        "comments": "8 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.007",
        "license": null,
        "abstract": "  We investigate the strength and the direction of information transfer in the\nU.S. stock market between the composite stock price index of stock market and\nprices of individual stocks using the transfer entropy. Through the\ndirectionality of the information transfer, we find that individual stocks are\ninfluenced by the index of the market.\n"
    },
    {
        "paper_id": 708.0089,
        "authors": "Peter L. Bartlett, Shahar Mendelson",
        "title": "Discussion of \"2004 IMS Medallion Lecture: Local Rademacher complexities\n  and oracle inequalities in risk minimization\" by V. Koltchinskii",
        "comments": "Published at http://dx.doi.org/10.1214/009053606000001028 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2657-2663",
        "doi": "10.1214/009053606000001028",
        "license": null,
        "abstract": "  Discussion of \"2004 IMS Medallion Lecture: Local Rademacher complexities and\noracle inequalities in risk minimization\" by V. Koltchinskii [arXiv:0708.0083]\n"
    },
    {
        "paper_id": 708.0098,
        "authors": "St\\'ephan Cl\\'emen\\c{c}on, G\\'abor Lugosi, Nicolas Vayatis",
        "title": "Discussion of ``2004 IMS Medallion Lecture: Local Rademacher\n  complexities and oracle inequalities in risk minimization'' by V.\n  Koltchinskii",
        "comments": "Published at http://dx.doi.org/10.1214/009053606000001046 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2672-2676",
        "doi": "10.1214/009053606000001046",
        "license": null,
        "abstract": "  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and\noracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]\n"
    },
    {
        "paper_id": 708.0121,
        "authors": "Xiaotong Shen, Lifeng Wang",
        "title": "Discussion of ``2004 IMS Medallion Lecture: Local Rademacher\n  complexities and oracle inequalities in risk minimization'' by V.\n  Koltchinskii",
        "comments": "Published at http://dx.doi.org/10.1214/009053606000001055 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2677-2680",
        "doi": "10.1214/009053606000001055",
        "license": null,
        "abstract": "  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and\noracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]\n"
    },
    {
        "paper_id": 708.0124,
        "authors": "A. B. Tsybakov",
        "title": "Discussion of ``2004 IMS Medallion Lecture: Local Rademacher\n  complexities and oracle inequalities in risk minimization'' by V.\n  Koltchinskii",
        "comments": "Published at http://dx.doi.org/10.1214/009053606000001064 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2681-2687",
        "doi": "10.1214/009053606000001064",
        "license": null,
        "abstract": "  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and\noracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]\n"
    },
    {
        "paper_id": 708.0132,
        "authors": "Sara van de Geer",
        "title": "Discussion of ``2004 IMS Medallion Lecture: Local Rademacher\n  complexities and oracle inequalities in risk minimization'' by V.\n  Koltchinskii",
        "comments": "Published at http://dx.doi.org/10.1214/009053606000001073 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2688-2696",
        "doi": "10.1214/009053606000001073",
        "license": null,
        "abstract": "  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and\noracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]\n"
    },
    {
        "paper_id": 708.0209,
        "authors": "C. H. Yeung, K. Y. Michael Wong, Y.-C. Zhang",
        "title": "Models of Financial Markets with Extensive Participation Incentives",
        "comments": "17 pages, 16 figures",
        "journal-ref": "Phys. Rev. E Vol. 77 026107 (2008)",
        "doi": "10.1103/PhysRevE.77.026107",
        "license": null,
        "abstract": "  We consider models of financial markets in which all parties involved find\nincentives to participate. Strategies are evaluated directly by their virtual\nwealths. By tuning the price sensitivity and market impact, a phase diagram\nwith several attractor behaviors resembling those of real markets emerge,\nreflecting the roles played by the arbitrageurs and trendsetters, and including\na phase with irregular price trends and positive sums. The positive-sumness of\nthe players' wealths provides participation incentives for them. Evolution and\nthe bid-ask spread provide mechanisms for the gain in wealth of both the\nplayers and market-makers. New players survive in the market if the\nevolutionary rate is sufficiently slow. We test the applicability of the model\non real Hang Seng Index data over 20 years. Comparisons with other models show\nthat our model has a superior average performance when applied to real\nfinancial data.\n"
    },
    {
        "paper_id": 708.0275,
        "authors": "Kei Takeuchi, Masayuki Kumon, Akimichi Takemura",
        "title": "A new formulation of asset trading games in continuous time with\n  essential forcing of variation exponent",
        "comments": "Published in at http://dx.doi.org/10.3150/08-BEJ188 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2009, Vol. 15, No. 4, 1243-1258",
        "doi": "10.3150/08-BEJ188",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new formulation of asset trading games in continuous time in\nthe framework of the game-theoretic probability established by Shafer and Vovk\n(Probability and Finance: It's Only a Game! (2001) Wiley). In our formulation,\nthe market moves continuously, but an investor trades in discrete times, which\ncan depend on the past path of the market. We prove that an investor can\nessentially force that the asset price path behaves with the variation exponent\nexactly equal to two. Our proof is based on embedding high-frequency\ndiscrete-time games into the continuous-time game and the use of the Bayesian\nstrategy of Kumon, Takemura and Takeuchi (Stoch. Anal. Appl. 26 (2008)\n1161--1180) for discrete-time coin-tossing games. We also show that the main\ngrowth part of the investor's capital processes is clearly described by the\ninformation quantities, which are derived from the Kullback--Leibler\ninformation with respect to the empirical fluctuation of the asset price.\n"
    },
    {
        "paper_id": 708.0353,
        "authors": "D. Grech, G. Pamu{\\l}a (University of Wroclaw, ITP)",
        "title": "The Local Fractal Properties of the Financial Time Series on the Polish\n  Stock Exchange Market",
        "comments": "LaTeX, 14 pages, 12 figures included",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate the local fractal properties of the financial time series\nbased on the evolution of the Warsaw Stock Exchange Index (WIG) connected with\nthe largest developing financial market in Europe. Calculating the local Hurst\nexponent for the WIG time series we find an interesting dependence between the\nbehavior of the local fractal properties of the WIG time series and the crashes\nappearance on the financial market.\n"
    },
    {
        "paper_id": 708.0544,
        "authors": "Miquel Montero",
        "title": "Perpetual American options within CTRW's",
        "comments": "elsart, 12 pages, 2 figures, presented at APFA 6 conference; Revised\n  and condensed version: 8 pages",
        "journal-ref": "Physica A 387 (2008) 3936-3941",
        "doi": "10.1016/j.physa.2008.01.054",
        "license": null,
        "abstract": "  Continuous-time random walks are a well suited tool for the description of\nmarket behaviour at the smallest scale: the tick-to-tick evolution. We will\napply this kind of market model to the valuation of perpetual American options:\nderivatives with no maturity that can be exercised at any time. Our approach\nleads to option prices that fulfil financial formulas when canonical\nassumptions on the dynamics governing the process are made, but it is still\nsuitable for more exotic market conditions.\n"
    },
    {
        "paper_id": 708.0562,
        "authors": "Woo-Sung Jung, Okyu Kwon, Fengzhong Wang, Taisei Kaizoji, Hie-Tae\n  Moon, H. Eugene Stanley",
        "title": "Group dynamics of the Japanese market",
        "comments": "9 pages",
        "journal-ref": "Physica A 387(2-3), 537-542 (2008)",
        "doi": "10.1016/j.physa.2007.09.022",
        "license": null,
        "abstract": "  We investigated the network structures of the Japanese stock market through\nthe minimum spanning tree. We defined grouping coefficient to test the validity\nof conventional grouping by industrial categories, and found a decreasing in\ntrend for the coefficient. This phenomenon supports the increasing external\ninfluences on the market due to the globalization. To reduce this influence, we\nused S&P500 index as the international market and removed its correlation with\nevery stock. We found stronger grouping in this measurement, compared to the\noriginal analysis, which agrees with our assumption that the international\nmarket influences to the Japanese market.\n"
    },
    {
        "paper_id": 708.0588,
        "authors": "Ivar Ekeland and Traian A. Pirvu",
        "title": "Investment and Consumption without Commitment",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper, we investigate the Merton portfolio management problem in the\ncontext of non-exponential discounting. This gives rise to time-inconsistency\nof the decision-maker. If the decision-maker at time t=0 can commit his/her\nsuccessors, he/she can choose the policy that is optimal from his/her point of\nview, and constrain the others to abide by it, although they do not see it as\noptimal for them. If there is no commitment mechanism, one must seek a\nsubgame-perfect equilibrium strategy between the successive decision-makers. In\nthe line of the earlier work by Ekeland and Lazrak we give a precise definition\nof equilibrium strategies in the context of the portfolio management problem,\nwith finite horizon, we characterize it by a system of partial differential\nequations, and we show existence in the case when the utility is CRRA and the\nterminal time T is small. We also investigate the infinite-horizon case and we\ngive two different explicit solutions in the case when the utility is CRRA (in\ncontrast with the case of exponential discount, where there is only one). Some\nof our results are proved under the assumption that the discount function h(t)\nis a linear combination of two exponentials, or is the product of an\nexponential by a linear function.\n"
    },
    {
        "paper_id": 708.0998,
        "authors": "Jan Obloj",
        "title": "Fine-tune your smile: Correction to Hagan et al",
        "comments": "Typos and reference corrected. Eq (3) valid for all x now",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this small note we use results derived in Berestycki et al. to correct the\ncelebrated formulae of Hagan et al. We derive explicitly the correct zero order\nterm in the expansion of the implied volatility in time to maturity. The new\nterm is consistent as $\\beta\\to 1$. Furthermore, numerical simulations show\nthat it reduces or eliminates known pathologies of the earlier formula.\n"
    },
    {
        "paper_id": 708.1146,
        "authors": "Grace Lin, Yingdong Lu, David Yao",
        "title": "Stochastic Knapsack Problem Revisited: Switch-Over Policies and Dynamic\n  Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The stochastic knapsack has been used as a model in wide ranging applications\nfrom dynamic resource allocation to admission control in telecommunication. In\nrecent years, a variation of the model has become a basic tool in studying\nproblems that arise in revenue management and dynamic/flexible pricing; and it\nis in this context that our study is undertaken. Based on a dynamic programming\nformulation and associated properties of the value function, we study in this\npaper a class of control that we call switch-over policies -- start from\naccepting only orders of the highest price, and switch to including lower\nprices as time goes by, with the switch-over times optimally decided via convex\nprogramming. We establish the asymptotic optimality of the switch-over policy,\nand develop pricing models based on this policy to optimize the price\nreductions over the decision horizon.\n"
    },
    {
        "paper_id": 708.1568,
        "authors": "Ljudmila A. Bordag, Ruediger Frey",
        "title": "Nonlinear option pricing models for illiquid markets: scaling properties\n  and explicit solutions",
        "comments": "26 pages, 7 figures, 25 references",
        "journal-ref": "book: \"Nonlinear Models in Mathematical Finance. New Research\n  Trends in Option Pricing.\", 2009, pp103-130; ISBN 978-1-60456-931-5, Nova\n  Science Publicher, Inc.",
        "doi": null,
        "license": null,
        "abstract": "  Several models for the pricing of derivative securities in illiquid markets\nare discussed. A typical type of nonlinear partial differential equations\narising from these investigation is studied. The scaling properties of these\nequations are discussed. Explicit solutions for one of the models are obtained\nand studied.\n"
    },
    {
        "paper_id": 708.1715,
        "authors": "Ale\\v{s} \\v{C}ern\\'y, Jan Kallsen",
        "title": "On the Structure of General Mean-Variance Hedging Strategies",
        "comments": "Published at http://dx.doi.org/10.1214/009117906000000872 in the\n  Annals of Probability (http://www.imstat.org/aop/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Probability 2007, Vol. 35, No. 4, 1479-1531",
        "doi": "10.1214/009117906000000872",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a new characterization of mean-variance hedging strategies in a\ngeneral semimartingale market. The key point is the introduction of a new\nprobability measure $P^{\\star}$ which turns the dynamic asset allocation\nproblem into a myopic one. The minimal martingale measure relative to\n$P^{\\star}$ coincides with the variance-optimal martingale measure relative to\nthe original probability measure $P$.\n"
    },
    {
        "paper_id": 708.1756,
        "authors": "Aur\\'elien Alfonsi (CERMICS), Antje Fruth, Alexander Schied",
        "title": "Optimal execution strategies in limit order books with general shape\n  functions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider optimal execution strategies for block market orders placed in a\nlimit order book (LOB). We build on the resilience model proposed by Obizhaeva\nand Wang (2005) but allow for a general shape of the LOB defined via a given\ndensity function. Thus, we can allow for empirically observed LOB shapes and\nobtain a nonlinear price impact of market orders. We distinguish two\npossibilities for modeling the resilience of the LOB after a large market\norder: the exponential recovery of the number of limit orders, i.e., of the\nvolume of the LOB, or the exponential recovery of the bid-ask spread. We\nconsider both of these resilience modes and, in each case, derive explicit\noptimal execution strategies in discrete time. Applying our results to a\nblock-shaped LOB, we obtain a new closed-form representation for the optimal\nstrategy, which explicitly solves the recursive scheme given in Obizhaeva and\nWang (2005). We also provide some evidence for the robustness of optimal\nstrategies with respect to the choice of the shape function and the\nresilience-type.\n"
    },
    {
        "paper_id": 708.1874,
        "authors": "Susanne M. Schennach",
        "title": "Point estimation with exponentially tilted empirical likelihood",
        "comments": "Published at http://dx.doi.org/10.1214/009053606000001208 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Statistics 2007, Vol. 35, No. 2, 634-672",
        "doi": "10.1214/009053606000001208",
        "license": null,
        "abstract": "  Parameters defined via general estimating equations (GEE) can be estimated by\nmaximizing the empirical likelihood (EL). Newey and Smith [Econometrica 72\n(2004) 219--255] have recently shown that this EL estimator exhibits desirable\nhigher-order asymptotic properties, namely, that its $O(n^{-1})$ bias is small\nand that bias-corrected EL is higher-order efficient. Although EL possesses\nthese properties when the model is correctly specified, this paper shows that,\nin the presence of model misspecification, EL may cease to be root n convergent\nwhen the functions defining the moment conditions are unbounded (even when\ntheir expectations are bounded). In contrast, the related exponential tilting\n(ET) estimator avoids this problem. This paper shows that the ET and EL\nestimators can be naturally combined to yield an estimator called exponentially\ntilted empirical likelihood (ETEL) exhibiting the same $O(n^{-1})$ bias and the\nsame $O(n^{-2})$ variance as EL, while maintaining root n convergence under\nmodel misspecification.\n"
    },
    {
        "paper_id": 708.202,
        "authors": "A. Elices",
        "title": "Models with time-dependent parameters using transform methods:\n  application to Heston's model",
        "comments": "10 pages, 10 figures, 6 tables, error corrected in sections VI and\n  VII, references added in sections I and VI, Submitted to the Journal of\n  Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a methodology to introduce time-dependent parameters for\na wide family of models preserving their analytic tractability. This family\nincludes hybrid models with stochastic volatility, stochastic interest-rates,\njumps and their non-hybrid counterparts. The methodology is applied to Heston's\nmodel. A bootstrapping algorithm is presented for calibration. A case study\nworks out the calibration of the time-dependent parameters to the volatility\nsurface of the Eurostoxx 50 index. The methodology is also applied to the\nanalytic valuation of forward start vanilla options driven by Heston's model.\nThis result is used to explore the forward skew of the case study.\n"
    },
    {
        "paper_id": 708.2071,
        "authors": "H.-U. Habermeier",
        "title": "Eduction and Economy -- An Analysis of Statistical Data",
        "comments": "15 pages",
        "journal-ref": "Journal of Materials Education Vol. 29 (1-2): 55-70 (2007)",
        "doi": null,
        "license": null,
        "abstract": "  In this paper the correlation between education, research and macroeconomic\nstrength of countries at a global scale is analyzed on the basis of statistical\ndata published by the UNIDO and OECD. It uses sets of composite indicators\ndescribing the economical performance and competitiveness as well as those\nrelevant for human development, education, knowledge and technology achievement\nand correlates them. It turns out that for countries with a human development\nindex (HDI) below 0.7 the basic education and technology achievement indices\nare the driving force for further development, whereas for the industrialized\ncountries the knowledge index as a composite education and communication index\nhas the strongest effect on the economic strength of a country as measured by\nthe gross domestic product.\n"
    },
    {
        "paper_id": 708.209,
        "authors": "C. A. Hidalgo, B. Klinger, A.-L. Barabasi, R. Hausmann",
        "title": "The Product Space Conditions the Development of Nations",
        "comments": "This version is slightly different from the one published in Science",
        "journal-ref": "Science 317, 482 (2007)",
        "doi": "10.1126/science.1144581",
        "license": null,
        "abstract": "  Economies grow by upgrading the type of products they produce and export. The\ntechnology, capital, institutions and skills needed to make such new products\nare more easily adapted from some products than others. We study the network of\nrelatedness between products, or product space, finding that most upscale\nproducts are located in a densely connected core while lower income products\noccupy a less connected periphery. We show that countries tend to move to goods\nclose to those they are currently specialized in, allowing nations located in\nmore connected parts of the product space to upgrade their exports basket more\nquickly. Most countries can reach the core only if they jump over empirically\ninfrequent distances in the product space. This may help explain why poor\ncountries have trouble developing more competitive exports, failing to converge\nto the income levels of rich countries.\n"
    },
    {
        "paper_id": 708.2542,
        "authors": "Dirk Tasche",
        "title": "Capital Allocation to Business Units and Sub-Portfolios: the Euler\n  Principle",
        "comments": "21 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Despite the fact that the Euler allocation principle has been adopted by many\nfinancial institutions for their internal capital allocation process, a\ncomprehensive description of Euler allocation seems still to be missing. We try\nto fill this gap by presenting the theoretical background as well as practical\naspects. In particular, we discuss how Euler risk contributions can be\nestimated for some important risk measures. We furthermore investigate the\nanalysis of CDO tranche expected losses by means of Euler's theorem and suggest\nan approach to measure the impact of risk factors on non-linear portfolios.\n"
    },
    {
        "paper_id": 708.2805,
        "authors": "Zi-Gang Huang, Zhi-Xi Wu, Jian-Yue Guan, An-Cai Wu, and Ying-Hai Wang",
        "title": "The public goods game on homogeneous and heterogeneous networks:\n  investment strategy according to the pool size",
        "comments": "6 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose an extended public goods interaction model to study the evolution\nof cooperation in heterogeneous population. The investors are arranged on the\nwell known scale-free type network, the Barab\\'{a}si-Albert model. Each\ninvestor is supposed to preferentially distribute capital to pools in its\nportfolio based on the knowledge of pool sizes. The extent that investors\nprefer larger pools is determined by investment strategy denoted by a tunable\nparameter $\\alpha$, with larger $\\alpha$ corresponding to more preference to\nlarger pools. As comparison, we also study this interaction model on square\nlattice, and find that the heterogeneity contacts favors cooperation.\nAdditionally, the influence of local topology to the game dynamics under\ndifferent $\\alpha$ strategies are discussed. It is found that the system with\nsmaller $\\alpha$ strategy can perform comparatively better than the larger\n$\\alpha$ ones.\n"
    },
    {
        "paper_id": 708.3012,
        "authors": "Petr Jizba, Hagen Kleinert and Patrick Haener",
        "title": "Perturbation Expansion for Option Pricing with Stochastic Volatility",
        "comments": "33 pages, 13 figures, LaTeX4",
        "journal-ref": "Physica A 388 (2009) 3503-3520",
        "doi": "10.1016/j.physa.2009.04.027",
        "license": null,
        "abstract": "  We fit the volatility fluctuations of the S&P 500 index well by a Chi\ndistribution, and the distribution of log-returns by a corresponding\nsuperposition of Gaussian distributions. The Fourier transform of this is,\nremarkably, of the Tsallis type. An option pricing formula is derived from the\nsame superposition of Black-Scholes expressions. An explicit analytic formula\nis deduced from a perturbation expansion around a Black-Scholes formula with\nthe mean volatility. The expansion has two parts. The first takes into account\nthe non-Gaussian character of the stock-fluctuations and is organized by powers\nof the excess kurtosis, the second is contract based, and is organized by the\nmoments of moneyness of the option. With this expansion we show that for the\nDow Jones Euro Stoxx 50 option data, a Delta-hedging strategy is close to being\noptimal.\n"
    },
    {
        "paper_id": 708.3198,
        "authors": "Wei-Xing Zhou (ECUST)",
        "title": "Universal price impact functions of individual trades in an order-driven\n  market",
        "comments": "17 pages + supplementary figures. The paper has been significantly\n  expanded and more Supplementary Information is added",
        "journal-ref": "Quantitative Finance 12 (8), 1253-1263 (2012)",
        "doi": "10.1080/14697688.2010.504733",
        "license": null,
        "abstract": "  The trade size $\\omega$ has direct impact on the price formation of the stock\ntraded. Econophysical analyses of transaction data for the US and Australian\nstock markets have uncovered market-specific scaling laws, where a master curve\nof price impact can be obtained in each market when stock capitalization $C$ is\nincluded as an argument in the scaling relation. However, the rationale of\nintroducing stock capitalization in the scaling is unclear and the anomalous\nnegative correlation between price change $r$ and trade size $\\omega$ for small\ntrades is unexplained. Here we show that these issues can be addressed by\ntaking into account the aggressiveness of orders that result in trades together\nwith a proper normalization technique. Using order book data from the Chinese\nmarket, we show that trades from filled and partially filled limit orders have\nvery different price impact. The price impact of trades from partially filled\norders is constant when the volume is not too large, while that of filled\norders shows power-law behavior $r\\sim \\omega^\\alpha$ with $\\alpha\\approx2/3$.\nWhen returns and volumes are normalized by stock-dependent averages,\ncapitalization-independent scaling laws emerge for both types of trades.\nHowever, no scaling relation in terms of stock capitalization can be\nconstructed. In addition, the relation $\\alpha=\\alpha_\\omega/\\alpha_r$ is\nverified, where $\\alpha_\\omega$ and $\\alpha_r$ are the tail exponents of trade\nsizes and returns. These observations also enable us to explain the anomalous\nnegative correlation between $r$ and $\\omega$ for small-size trades. We\nanticipate that these regularities may hold in other order-driven markets.\n"
    },
    {
        "paper_id": 708.3467,
        "authors": "Arnabi Marjit, Sudipto Marjit, Arnab K. Ray",
        "title": "Analytical modelling of terminal properties in industrial growth",
        "comments": "ReVTeX, 11 pages, 8 figures. Revisions have been made in the draft",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this pedagogical study, carried out by adopting standard mathematical\nmethods of nonlinear dynamics, we have presented some simple analytical models\nto understand terminal behaviour in industrial growth. This issue has also been\naddressed from a dynamical systems perspective, with especial emphasis on the\nconcept of the Balanced Scorecard. Our study enables us to make the general\nclaim that although the fortunes of an industrial organization can rise with\nexponential rapidity on relatively short time scales, its growth will\nultimately and inevitably be saturated on long time scales by various factors\nwhich are nonlinear in character. We have mathematically demonstrated the\nlikely occurrence of this feature under various possible circumstances,\nincluding the Red Ocean and the Blue Ocean. Finally and most importantly, our\narguments and their associated mathematical modelling have received remarkable\nsupport from the growth pattern indicated by empirical data gathered from a\nwell-recognized global company like IBM.\n"
    },
    {
        "paper_id": 708.3472,
        "authors": "Gao-Feng Gu (ECUST), Wei Chen (SZSE), Wei-Xing Zhou (ECUST)",
        "title": "Empirical distributions of Chinese stock returns at different\n  microscopic timescales",
        "comments": "14 Elsart page including 2 tables and 3 figures",
        "journal-ref": "Physica A 387 (2-3), 495-502 (2008)",
        "doi": "10.1016/j.physa.2007.10.012",
        "license": null,
        "abstract": "  We study the distributions of event-time returns and clock-time returns at\ndifferent microscopic timescales using ultra-high-frequency data extracted from\nthe limit-order books of 23 stocks traded in the Chinese stock market in 2003.\nWe find that the returns at the one-trade timescale obey the inverse cubic law.\nFor larger timescales (2-32 trades and 1-5 minutes), the returns follow the\nStudent distribution with power-law tails. With the decrease of timescale, the\ntail becomes fatter, which is consistent with the vibrational theory.\n"
    },
    {
        "paper_id": 708.4022,
        "authors": "Gilles Zumbach",
        "title": "Time reversal invariance in finance",
        "comments": "23 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Time reversal invariance can be summarized as follows: no difference can be\nmeasured if a sequence of events is run forward or backward in time. Because\nprice time series are dominated by a randomness that hides possible structures\nand orders, the existence of time reversal invariance requires care to be\ninvestigated. Different statistics are constructed with the property to be zero\nfor time series which are time reversal invariant; they all show that\nhigh-frequency empirical foreign exchange prices are not invariant. The same\nstatistics are applied to mathematical processes that should mimic empirical\nprices. Monte Carlo simulations show that only some ARCH processes with a\nmulti-timescales structure can reproduce the empirical findings. A GARCH(1,1)\nprocess can only reproduce some asymmetry. On the other hand, all the\nstochastic volatility type processes are time reversal invariant. This clear\ndifference related to the process structures gives some strong selection\ncriterion for processes.\n"
    },
    {
        "paper_id": 708.4095,
        "authors": "M. Mania, R. Tevzadze and T. Toronjadze",
        "title": "$L^2$-approximating pricing under restricted information",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider the mean-variance hedging problem under partial information in\nthe case where the flow of observable events does not contain the full\ninformation on the underlying asset price process. We introduce a martingale\nequation of a new type and characterize the optimal strategy in terms of the\nsolution of this equation. We give relations between this equation and backward\nstochastic differential equations for the value process of the problem.\n"
    },
    {
        "paper_id": 708.4178,
        "authors": "Cheoljun Eom, Gabjin Oh, Woo-Sung Jung",
        "title": "Relationship between degree of efficiency and prediction in stock price\n  changes",
        "comments": "10 pages",
        "journal-ref": "Physica A 387(22), 5511-5517 (2008)",
        "doi": "10.1016/j.physa.2008.05.059",
        "license": null,
        "abstract": "  This study investigates empirically whether the degree of stock market\nefficiency is related to the prediction power of future price change using the\nindices of twenty seven stock markets. Efficiency refers to weak-form efficient\nmarket hypothesis (EMH) in terms of the information of past price changes. The\nprediction power corresponds to the hit-rate, which is the rate of the\nconsistency between the direction of actual price change and that of predicted\none, calculated by the nearest neighbor prediction method (NN method) using the\nout-of-sample. In this manuscript, the Hurst exponent and the approximate\nentropy (ApEn) are used as the quantitative measurements of the degree of\nefficiency. The relationship between the Hurst exponent, reflecting the various\ntime correlation property, and the ApEn value, reflecting the randomness in the\ntime series, shows negative correlation. However, the average prediction power\non the direction of future price change has the strongly positive correlation\nwith the Hurst exponent, and the negative correlation with the ApEn. Therefore,\nthe market index with less market efficiency has higher prediction power for\nfuture price change than one with higher market efficiency when we analyze the\nmarket using the past price change pattern. Furthermore, we show that the Hurst\nexponent, a measurement of the long-term memory property, provides more\nsignificant information in terms of prediction of future price changes than the\nApEn and the NN method.\n"
    },
    {
        "paper_id": 708.4347,
        "authors": "S. Drozdz, A.Z. Gorski, J. Kwapien",
        "title": "World currency exchange rate cross-correlations",
        "comments": "4 pages, 3 figures, LaTeX",
        "journal-ref": "Eur. Phys. J. B58 (2007) 499",
        "doi": "10.1140/epjb/e2007-00246-8",
        "license": null,
        "abstract": "  World currency network constitutes one of the most complex structures that is\nassociated with the contemporary civilization. On a way towards quantifying its\ncharacteristics we study the cross correlations in changes of the daily foreign\nexchange rates within the basket of 60 currencies in the period December 1998\n-- May 2005. Such a dynamics turns out to predominantly involve one outstanding\neigenvalue of the correlation matrix. The magnitude of this eigenvalue depends\nhowever crucially on which currency is used as a base currency for the\nremaining ones. Most prominent it looks from the perspective of a peripheral\ncurrency. This largest eigenvalue is seen to systematically decrease and thus\nthe structure of correlations becomes more heterogeneous, when more significant\ncurrencies are used as reference. An extreme case in this later respect is the\nUSD in the period considered. Besides providing further insight into subtle\nnature of complexity, these observations point to a formal procedure that in\ngeneral can be used for practical purposes of measuring the relative currencies\nsignificance on various time horizons.\n"
    },
    {
        "paper_id": 708.4359,
        "authors": "Giorgio Fagiolo, Javier Reyes, Stefano Schiavo",
        "title": "On the Topological Properties of the World Trade Web: A Weighted Network\n  Analysis",
        "comments": "To be submitted to APFA 6 Proceedings. 8 pages, 10 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.050",
        "license": null,
        "abstract": "  This paper studies the topological properties of the World Trade Web (WTW)\nand its evolution over time by employing a weighted network analysis. We show\nthat the WTW, viewed as a weighted network, displays statistical features that\nare very different from those obtained by using a traditional binary-network\napproach. In particular, we find that: (i) the majority of existing links are\nassociated to weak trade relationships; (ii) the weighted WTW is only weakly\ndisassortative; (iii) countries holding more intense trade relationships are\nmore clustered.\n"
    },
    {
        "paper_id": 708.4376,
        "authors": "Kostas Triantafyllopoulos and Giovanni Montana",
        "title": "Fast estimation of multivariate stochastic volatility",
        "comments": "15 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper we develop a Bayesian procedure for estimating multivariate\nstochastic volatility (MSV) using state space models. A multiplicative model\nbased on inverted Wishart and multivariate singular beta distributions is\nproposed for the evolution of the volatility, and a flexible sequential\nvolatility updating is employed. Being computationally fast, the resulting\nestimation procedure is particularly suitable for on-line forecasting. Three\nperformance measures are discussed in the context of model selection: the\nlog-likelihood criterion, the mean of standardized one-step forecast errors,\nand sequential Bayes factors. Finally, the proposed methods are applied to a\ndata set comprising eight exchange rates vis-a-vis the US dollar.\n"
    },
    {
        "paper_id": 709.0159,
        "authors": "Szabolcs Mike, J. Doyne Farmer",
        "title": "An empirical behavioral model of liquidity and volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We develop a behavioral model for liquidity and volatility based on empirical\nregularities in trading order flow in the London Stock Exchange. This can be\nviewed as a very simple agent based model in which all components of the model\nare validated against real data. Our empirical studies of order flow uncover\nseveral interesting regularities in the way trading orders are placed and\ncancelled. The resulting simple model of order flow is used to simulate price\nformation under a continuous double auction, and the statistical properties of\nthe resulting simulated sequence of prices are compared to those of real data.\nThe model is constructed using one stock (AZN) and tested on 24 other stocks.\nFor low volatility, small tick size stocks (called Group I) the predictions are\nvery good, but for stocks outside Group I they are not good. For Group I, the\nmodel predicts the correct magnitude and functional form of the distribution of\nthe volatility and the bid-ask spread, without adjusting any parameters based\non prices. This suggests that at least for Group I stocks, the volatility and\nheavy tails of prices are related to market microstructure effects, and\nsupports the hypothesis that, at least on short time scales, the large\nfluctuations of absolute returns are well described by a power law with an\nexponent that varies from stock to stock.\n"
    },
    {
        "paper_id": 709.0232,
        "authors": "A. Jobert and L. C. G. Rogers",
        "title": "Valuations and dynamic convex risk measures",
        "comments": "26 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper approaches the definition and properties of dynamic convex risk\nmeasures through the notion of a family of concave valuation operators\nsatisfying certain simple and credible axioms. Exploring these in the simplest\ncontext of a finite time set and finite sample space, we find natural\nrisk-transfer and time-consistency properties for a firm seeking to spread its\nrisk across a group of subsidiaries.\n"
    },
    {
        "paper_id": 709.0281,
        "authors": "Boris Podobnik, H. Eugene Stanley",
        "title": "Detrended Cross-Correlation Analysis: A New Method for Analyzing Two\n  Non-stationary Time Series",
        "comments": "11 pages, 7 pictures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevLett.100.084102",
        "license": null,
        "abstract": "  Here we propose a method, based on detrended covariance which we call\ndetrended cross-correlation analysis (DXA), to investigate power-law\ncross-correlations between different simultaneously-recorded time series in the\npresence of non-stationarity. We illustrate the method by selected examples\nfrom physics, physiology, and finance.\n"
    },
    {
        "paper_id": 709.044,
        "authors": "Yingying Li, Per A. Mykland",
        "title": "Are volatility estimators robust with respect to modeling assumptions?",
        "comments": "Published at http://dx.doi.org/10.3150/07-BEJ6067 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2007, Vol. 13, No. 3, 601-622",
        "doi": "10.3150/07-BEJ6067",
        "license": null,
        "abstract": "  We consider microstructure as an arbitrary contamination of the underlying\nlatent securities price, through a Markov kernel $Q$. Special cases include\nadditive error, rounding and combinations thereof. Our main result is that,\nsubject to smoothness conditions, the two scales realized volatility is robust\nto the form of contamination $Q$. To push the limits of our result, we show\nwhat happens for some models that involve rounding (which is not, of course,\nsmooth) and see in this situation how the robustness deteriorates with\ndecreasing smoothness. Our conclusion is that under reasonable smoothness, one\ndoes not need to consider too closely how the microstructure is formed, while\nif severe non-smoothness is suspected, one needs to pay attention to the\nprecise structure and also the use to which the estimator of volatility will be\nput.\n"
    },
    {
        "paper_id": 709.0591,
        "authors": "Andreia Dionisio and A. Heitor Reis",
        "title": "Utility function estimation: the entropy approach",
        "comments": "9 pages, paper presented at APFA 6 conference",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.02.072",
        "license": null,
        "abstract": "  The maximum entropy principle can be used to assign utility values when only\npartial information is available about the decision maker's preferences. In\norder to obtain such utility values it is necessary to establish an analogy\nbetween probability and utility through the notion of a utility density\nfunction. According to some authors [Soofi (1990), Abbas (2006a) (2006b),\nSandow et al. (2006), Friedman and Sandow (2006), Darooneh (2006)] the maximum\nentropy utility solution embeds a large family of utility functions. In this\npaper we explore the maximum entropy principle to estimate the utility function\nof a risk averse decision maker.\n"
    },
    {
        "paper_id": 709.0668,
        "authors": "Andreia Dionisio, Rui Menezes and Diana A. Mendes",
        "title": "Entropy and Uncertainty Analysis in Financial Markets",
        "comments": "9 pages, 2 figures, paper presented in APFA 6 conference",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The investor is interested in the expected return and he is also concerned\nabout the risk and the uncertainty assumed by the investment. One of the most\npopular concepts used to measure the risk and the uncertainty is the variance\nand/or the standard-deviation. In this paper we explore the following issues:\nIs the standard-deviation a good measure of risk and uncertainty? What are the\npotentialities of the entropy in this context? Can entropy present some\nadvantages as a measure of uncertainty and simultaneously verify some basic\nassumptions of the portfolio management theory, namely the effect of\ndiversification?\n"
    },
    {
        "paper_id": 709.081,
        "authors": "E. Cisana, L. Fermi, G. Montagna, O. Nicrosini",
        "title": "A Comparative Study of Stochastic Volatility Models",
        "comments": "8 pages, 7 .eps figures, APFA6 conference contribution (4-7 July\n  2007, Lisbon)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The correlated stochastic volatility models constitute a natural extension of\nthe Black and Scholes-Merton framework: here the volatility is not a constant,\nbut a stochastic process correlated with the price log-return one. At present,\nseveral stochastic volatility models are discussed in the literature, differing\nin the dynamics attached to the volatility. The aim of the present work is to\ncompare the most recent results about three popular models: the Vasicek, Heston\nand exponential Ornstein-Uhlenbeck models. We analyzed for each of them the\ntheoretical results known in the literature (volatility and return\ndistribution, higher-order moments and different-time correlations) in order to\ntest their predictive effectiveness on the outcomes of original numerical\nsimulations, paying particular attention to their ability to reproduce\nempirical statistical properties of prices. The numerical results demonstrate\nthat these models can be implemented maintaining all their features, especially\nin view of financial applications like market risk management or option\npricing. In order to critically compare the models, we also perform an\nempirical analysis of financial time series from the Italian stock market,\nshowing the exponential Ornstein-Uhlenbeck model's ability to capture the\nstylized facts of volatility and log-return probability distributions.\n"
    },
    {
        "paper_id": 709.0838,
        "authors": "Boris Podobnik, Davor Horvatic, Alfonso Lam Ng, H. Eugene Stanley,\n  Plamen Ch. Ivanov",
        "title": "Modeling long-range cross-correlations in two-component ARFIMA and\n  FIARCH processes",
        "comments": "8 pages, 5 figures, elsart.cls",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.062",
        "license": null,
        "abstract": "  We investigate how simultaneously recorded long-range power-law correlated\nmulti-variate signals cross-correlate. To this end we introduce a two-component\nARFIMA stochastic process and a two-component FIARCH process to generate\ncoupled fractal signals with long-range power-law correlations which are at the\nsame time long-range cross-correlated. We study how the degree of\ncross-correlations between these signals depends on the scaling exponents\ncharacterizing the fractal correlations in each signal and on the coupling\nbetween the signals. Our findings have relevance when studying parallel outputs\nof multiple-component of physical, physiological and social systems.\n"
    },
    {
        "paper_id": 709.0976,
        "authors": "Antonio F. Crepaldi, Camilo Rodrigues Neto, Fernando F. Ferreira and\n  Gerson Francisco",
        "title": "Multifractal regime transition in a modified minority game model",
        "comments": "14 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The search for more realistic modeling of financial time series reveals\nseveral stylized facts of real markets. In this work we focus on the\nmultifractal properties found in price and index signals. Although the usual\nMinority Game (MG) models do not exhibit multifractality, we study here one of\nits variants that does. We show that the nonsynchronous MG models in the\nnonergodic phase is multifractal and in this sense, together with other\nstylized facts, constitute a better modeling tool. Using the Structure Function\n(SF) approach we detected the stationary and the scaling range of the time\nseries generated by the MG model and, from the linear (nonlinear) behavior of\nthe SF we identified the fractal (multifractal) regimes. Finally, using the\nWavelet Transform Modulus Maxima (WTMM) technique we obtained its multifractal\nspectrum width for different dynamical regimes.\n"
    },
    {
        "paper_id": 709.1092,
        "authors": "S. Jain, T. Yamano",
        "title": "Persistence in a Random Bond Ising Model of Socio-Econo Dynamics",
        "comments": "11 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1142/S012918310801198X",
        "license": null,
        "abstract": "  We study the persistence phenomenon in a socio-econo dynamics model using\ncomputer simulations at a finite temperature on hypercubic lattices in\ndimensions up to 5. The model includes a ` social\\rq local field which contains\nthe magnetization at time $t$. The nearest neighbour quenched interactions are\ndrawn from a binary distribution which is a function of the bond concentration,\n$p$. The decay of the persistence probability in the model depends on both the\nspatial dimension and $p$. We find no evidence of ` blocking\\rq in this model.\nWe also discuss the implications of our results for possible applications in\nthe social and economic fields. It is suggested that the absence, or otherwise,\nof blocking could be used as a criterion to decide on the validity of a given\nmodel in different scenarios.\n"
    },
    {
        "paper_id": 709.1219,
        "authors": "Guo-Hua Mu, Wei-Xing Zhou (ECUST)",
        "title": "Relaxation dynamics of aftershocks after large volatility shocks in the\n  SSEC index",
        "comments": "8 EPL pages including 3 figures and 3 tables",
        "journal-ref": "Physica A 387 (21), 5211-5218 (2008)",
        "doi": "10.1016/j.physa.2008.05.019",
        "license": null,
        "abstract": "  The relaxation dynamics of aftershocks after large volatility shocks are\ninvestigated based on two high-frequency data sets of the Shanghai Stock\nExchange Composite (SSEC) index. Compared with previous relevant work, we have\ndefined main financial shocks based on large volatilities rather than large\ncrashes. We find that the occurrence rate of aftershocks with the magnitude\nexceeding a given threshold for both daily volatility (constructed using\n1-minute data) and minutely volatility (using intra-minute data) decays as a\npower law. The power-law relaxation exponent increases with the volatility\nthreshold and is significantly greater than 1. Taking financial volatility as\nthe counterpart of seismic activity, the power-law relaxation in financial\nvolatility deviates remarkably from the Omori law in Geophysics.\n"
    },
    {
        "paper_id": 709.1281,
        "authors": "Grzegorz Hara\\'nczyk, Wojciech S{\\l}omczy\\'nski, Tomasz Zastawniak",
        "title": "Relative and Discrete Utility Maximising Entropy",
        "comments": "19 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The notion of utility maximising entropy (u-entropy) of a probability\ndensity, which was introduced and studied by Slomczynski and Zastawniak (Ann.\nProb 32 (2004) 2261-2285, arXiv:math.PR/0410115 v1), is extended in two\ndirections. First, the relative u-entropy of two probability measures in\narbitrary probability spaces is defined. Then, specialising to discrete\nprobability spaces, we also introduce the absolute u-entropy of a probability\nmeasure. Both notions are based on the idea, borrowed from mathematical\nfinance, of maximising the expected utility of the terminal wealth of an\ninvestor. Moreover, u-entropy is also relevant in thermodynamics, as it can\nreplace the standard Boltzmann-Shannon entropy in the Second Law. If the\nutility function is logarithmic or isoelastic (a power function), then the\nwell-known notions of the Boltzmann-Shannon and Renyi relative entropy are\nrecovered. We establish the principal properties of relative and discrete\nu-entropy and discuss the links with several related approaches in the\nliterature.\n"
    },
    {
        "paper_id": 709.153,
        "authors": "Aki-Hiro Sato",
        "title": "Application of spectral methods for high-frequency financial data to\n  quantifying states of market participants",
        "comments": "8 pages, 6 figures, APFA6",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.044",
        "license": null,
        "abstract": "  Empirical analysis of the foreign exchange market is conducted based on\nmethods to quantify similarities among multi-dimensional time series with\nspectral distances introduced in [A.-H. Sato, Physica A, 382 (2007) 258--270].\nAs a result it is found that the similarities among currency pairs fluctuate\nwith the rotation of the earth, and that the similarities among best quotation\nrates are associated with those among quotation frequencies. Furthermore it is\nshown that the Jensen-Shannon spectral divergence is proportional to a mean of\nthe Kullback-Leibler spectral distance both empirically and numerically. It is\nconfirmed that these spectral distances are connected with distributions for\nbehavioral parameters of the market participants from numerical simulation.\nThis concludes that spectral distances of representative quantities of\nfinancial markets are related into diversification of behavioral parameters of\nthe market participants.\n"
    },
    {
        "paper_id": 709.1536,
        "authors": "Calin Vamos, Maria Craciun (\"T. Popoviciu\" Institute of Numerical\n  Analysis, Romanian Academy, Romania)",
        "title": "Influence of deterministic trend on the estimated parameters of\n  GARCH(1,1) model",
        "comments": "8 pages, 6 figures, corrected typos for authors' names",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The log returns of financial time series are usually modeled by means of the\nstationary GARCH(1,1) stochastic process or its generalizations which can not\nproperly describe the nonstationary deterministic components of the original\nseries. We analyze the influence of deterministic trends on the GARCH(1,1)\nparameters using Monte Carlo simulations. The statistical ensembles contain\nnumerically generated time series composed by GARCH(1,1) noise superposed on\ndeterministic trends. The GARCH(1,1) parameters characteristic for financial\ntime series longer than one year are not affected by the detrending errors. We\nalso show that if the ARCH coefficient is greater than the GARCH coefficient,\nthen the estimated GARCH(1,1) parameters depend on the number of monotonic\nparts of the trend and on the ratio between the trend and the noise amplitudes.\n"
    },
    {
        "paper_id": 709.1543,
        "authors": "Arnab Chatterjee, Bikas K. Chakrabarti",
        "title": "Kinetic Exchange Models for Income and Wealth Distributions",
        "comments": "15 pages, 20 eps figures, EPJ class; To be published as \"Colloquium\"\n  in Eur Phys J B",
        "journal-ref": "The European Physical Journal B 60 (2007) 135-149",
        "doi": "10.1140/epjb/e2007-00343-8",
        "license": null,
        "abstract": "  Increasingly, a huge amount of statistics have been gathered which clearly\nindicates that income and wealth distributions in various countries or\nsocieties follow a robust pattern, close to the Gibbs distribution of energy in\nan ideal gas in equilibrium. However, it also deviates in the low income and\nmore significantly for the high income ranges. Application of physics models\nprovides illuminating ideas and understanding, complementing the observations.\n"
    },
    {
        "paper_id": 709.1589,
        "authors": "Alet Roux, Tomasz Zastawniak",
        "title": "American Options under Proportional Transaction Costs: Pricing, Hedging\n  and Stopping Algorithms for Long and Short Positions",
        "comments": "34 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  American options are studied in a general discrete market in the presence of\nproportional transaction costs, modelled as bid-ask spreads. Pricing algorithms\nand constructions of hedging strategies, stopping times and martingale\nrepresentations are presented for short (seller's) and long (buyer's) positions\nin an American option with an arbitrary payoff. This general approach extends\nthe special cases considered in the literature concerned primarily with\ncomputing the prices of American puts under transaction costs by relaxing any\nrestrictions on the form of the payoff, the magnitude of the transaction costs\nor the discrete market model itself. The largely unexplored case of pricing,\nhedging and stopping for the American option buyer under transaction costs is\nalso covered. The pricing algorithms are computationally efficient, growing\nonly polynomially with the number of time steps in a recombinant tree model.\nThe stopping times realising the ask (seller's) and bid (buyer's) option prices\ncan differ from one another. The former is generally a so-called mixed\n(randomised) stopping time, whereas the latter is always a pure (ordinary)\nstopping time.\n"
    },
    {
        "paper_id": 709.1725,
        "authors": "Woo-Sung Jung, Fengzhong Wang, Shlomo Havlin, Taisei Kaizoji, Hie-Tae\n  Moon, H. Eugene Stanley",
        "title": "Volatility return intervals analysis of the Japanese market",
        "comments": "11 pages",
        "journal-ref": "The European Physical Journal B 62(1), 113-119 (2008)",
        "doi": "10.1140/epjb/e2008-00123-0",
        "license": null,
        "abstract": "  We investigate scaling and memory effects in return intervals between price\nvolatilities above a certain threshold $q$ for the Japanese stock market using\ndaily and intraday data sets. We find that the distribution of return intervals\ncan be approximated by a scaling function that depends only on the ratio\nbetween the return interval $\\tau$ and its mean $<\\tau>$. We also find memory\neffects such that a large (or small) return interval follows a large (or small)\ninterval by investigating the conditional distribution and mean return\ninterval. The results are similar to previous studies of other markets and\nindicate that similar statistical features appear in different financial\nmarkets. We also compare our results between the period before and after the\nbig crash at the end of 1989. We find that scaling and memory effects of the\nreturn intervals show similar features although the statistical properties of\nthe returns are different.\n"
    },
    {
        "paper_id": 709.207,
        "authors": "G. Qiu, D. Kandhai, P. M. A. Sloot",
        "title": "Understanding the volatility smile of options markets through\n  microsimulation",
        "comments": "This paper has been withdrawn by the author(s)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we aim to gain a better understanding of the volatility smile\nobserved in options markets through microsimulation (MS). We adopt two types of\nactive traders in our MS model: speculators and arbitrageurs, and call and put\noptions on one underlying asset. Speculators make decisions based on their\nexpectations of the asset price at the option expiration time. Arbitrageurs\ntrade at different arbitrage opportunities such as violation of put-call\nparity. Difference in liquidity among options is also included. Notwithstanding\nits simplicity, our model can generate implied volatility (IV) curves similar\nto empirical observations. Our results suggest that the volatility smile is\nrelated to the competing effect of heterogeneous trading behavior and the\nimpact of differential liquidity.\n"
    },
    {
        "paper_id": 709.2083,
        "authors": "Corrado Di Guilmi, Mauro Gallegati, Simone Landini",
        "title": "Economic dynamics with financial fragility and mean-field interaction: a\n  model",
        "comments": "APFA6 proceedings",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.048",
        "license": null,
        "abstract": "  Following the statistical mechanics methodology, firstly introduced in\nmacroeconomics by Aoki [1996,2002], we provide some insights to the well known\nworks of Greenwald and Stiglitz [1990, 1993]. Specifically, we reach\nanalytically a closed form solution of their models overcoming the aggregation\nproblem. The key idea is to represent the economy as an evolving complex\nsystem, composed by heterogeneous interacting agents, that can partitioned into\na space of macroscopic states. This meso level of aggregation permits to adopt\nmean field interaction modeling and master equation techniques.\n"
    },
    {
        "paper_id": 709.2178,
        "authors": "Sonia R. Bentes, Rui Menezes, Diana A. Mendes",
        "title": "Long Memory and Volatility Clustering: is the empirical evidence\n  consistent across stock markets?",
        "comments": "8 pages; 2 figures; paper presented in APFA 6 conference",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.046",
        "license": null,
        "abstract": "  Long memory and volatility clustering are two stylized facts frequently\nrelated to financial markets. Traditionally, these phenomena have been studied\nbased on conditionally heteroscedastic models like ARCH, GARCH, IGARCH and\nFIGARCH, inter alia. One advantage of these models is their ability to capture\nnonlinear dynamics. Another interesting manner to study the volatility\nphenomena is by using measures based on the concept of entropy. In this paper\nwe investigate the long memory and volatility clustering for the SP 500, NASDAQ\n100 and Stoxx 50 indexes in order to compare the US and European Markets.\nAdditionally, we compare the results from conditionally heteroscedastic models\nwith those from the entropy measures. In the latter, we examine Shannon\nentropy, Renyi entropy and Tsallis entropy. The results corroborate the\nprevious evidence of nonlinear dynamics in the time series considered.\n"
    },
    {
        "paper_id": 709.22,
        "authors": "Cheoljun Eom, Gabjin Oh, Seunghwan Kim",
        "title": "Statistical Investigation of Connected Structures of Stock Networks in\n  Financial Time Series",
        "comments": "11 pages, 2 figures",
        "journal-ref": null,
        "doi": "10.3938/jkps.53.3837",
        "license": null,
        "abstract": "  In this study, we have investigated factors of determination which can affect\nthe connected structure of a stock network. The representative index for\ntopological properties of a stock network is the number of links with other\nstocks. We used the multi-factor model, extensively acknowledged in financial\nliterature. In the multi-factor model, common factors act as independent\nvariables while returns of individual stocks act as dependent variables. We\ncalculated the coefficient of determination, which represents the measurement\nvalue of the degree in which dependent variables are explained by independent\nvariables. Therefore, we investigated the relationship between the number of\nlinks in the stock network and the coefficient of determination in the\nmulti-factor model. We used individual stocks traded on the market indices of\nKorea, Japan, Canada, Italy and the UK. The results are as follows. We found\nthat the mean coefficient of determination of stocks with a large number of\nlinks have higher values than those with a small number of links with other\nstocks. These results suggest that common factors are significantly\ndeterministic factors to be taken into account when making a stock network.\nFurthermore, stocks with a large number of links to other stocks can be more\naffected by common factors.\n"
    },
    {
        "paper_id": 709.2209,
        "authors": "Cheoljun Eom, Gapjin Oh, Hawoong Jeong, Seunghwan Kim",
        "title": "Topological Properties of Stock Networks Based on Random Matrix Theory\n  in Financial Time Series",
        "comments": "8 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigated the topological properties of stock networks through a\ncomparison of the original stock network with the estimated stock network from\nthe correlation matrix created by the random matrix theory (RMT). We used\nindividual stocks traded on the market indices of Korea, Japan, Canada, the\nUSA, Italy, and the UK. The results are as follows. As the correlation matrix\nreflects the more eigenvalue property, the estimated stock network from the\ncorrelation matrix gradually increases the degree of consistency with the\noriginal stock network. Each stock with a different number of links to other\nstocks in the original stock network shows a different response. In particular,\nthe largest eigenvalue is a significant deterministic factor in terms of the\nformation of a stock network.\n"
    },
    {
        "paper_id": 709.2416,
        "authors": "Gabjin Oh, Seunghwan Kim, Cheoljun Eom, Taehyuk Kim",
        "title": "Measuring Volatility Clustering in Stock Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a novel method to quantify the clustering behavior in a complex\ntime series and apply it to a high-frequency data of the financial markets. We\nfind that regardless of used data sets, all data exhibits the volatility\nclustering properties, whereas those which filtered the volatility clustering\neffect by using the GARCH model reduce volatility clustering significantly. The\nresult confirms that our method can measure the volatility clustering effect in\nfinancial market.\n"
    },
    {
        "paper_id": 709.2423,
        "authors": "Filippo Petroni and Giulia Rotundo",
        "title": "Effectiveness of Measures of Performance During Speculative Bubbles",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.02.070",
        "license": null,
        "abstract": "  Statistical analysis of financial data most focused on testing the validity\nof Brownian motion (Bm). Analysis performed on several time series have shown\ndeviation from the Bm hypothesis, that is at the base of the evaluation of many\nfinancial derivatives. We inquiry in the behavior of measures of performance\nbased on maximum drawdown movements (MDD), testing their stability when the\nunderlying process deviates from the Bm hypothesis. In particular we consider\nthe fractional Brownian motion (fBm), and fluctuations estimated empirically on\nraw market data. The case study of the rising part of speculative bubbles is\nreported.\n"
    },
    {
        "paper_id": 709.263,
        "authors": "Irena Tzekina, Karan Danthi, Daniel N. Rockmore",
        "title": "Evolution of community structure in the world trade web",
        "comments": "To be submitted to APFA 6 Proceedings, 8 pages, 3 Figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00181-2",
        "license": null,
        "abstract": "  In this note we study the bilateral merchandise trade flows between 186\ncountries over the 1948-2005 period using data from the International Monetary\nFund. We use Pajek to identify network structure and behavior across thresholds\nand over time. In particular, we focus on the evolution of trade \"islands\" in\nthe a world trade network in which countries are linked with directed edges\nweighted according to fraction of total dollars sent from one country to\nanother. We find mixed evidence for globalization.\n"
    },
    {
        "paper_id": 709.2694,
        "authors": "Tanya Araujo, R. Vilela Mendes",
        "title": "Innovation Success and Structural Change: An Abstract Agent Based Study",
        "comments": "20 pages, 12 figures",
        "journal-ref": "Advances in Complex Systems 12 (2009) 233-253",
        "doi": null,
        "license": null,
        "abstract": "  A model is developed to study the effectiveness of innovation and its impact\non structure creation and structure change on agent-based societies. The\nabstract model that is developed is easily adapted to any particular field. In\nany interacting environment, the agents receive something from the environment\n(the other agents) in exchange for their effort and pay the environment a\ncertain amount of value for the fulfilling of their needs or for the very price\nof existence in that environment. This is coded by two bit strings and the\ndynamics of the exchange is based on the matching of these strings to those of\nthe other agents. Innovation is related to the adaptation by the agents of\ntheir bit strings to improve some utility function.\n"
    },
    {
        "paper_id": 709.283,
        "authors": "Hanqing Jin, Xunyu Zhou",
        "title": "Behavioral Portfolio Selection in Continuous Time",
        "comments": "43 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper formulates and studies a general continuous-time behavioral\nportfolio selection model under Kahneman and Tversky's (cumulative) prospect\ntheory, featuring S-shaped utility (value) functions and probability\ndistortions. Unlike the conventional expected utility maximization model, such\na behavioral model could be easily mis-formulated (a.k.a. ill-posed) if its\ndifferent components do not coordinate well with each other. Certain classes of\nan ill-posed model are identified. A systematic approach, which is\nfundamentally different from the ones employed for the utility model, is\ndeveloped to solve a well-posed model, assuming a complete market and general\nIt\\^o processes for asset prices. The optimal terminal wealth positions,\nderived in fairly explicit forms, possess surprisingly simple structure\nreminiscent of a gambling policy betting on a good state of the world while\naccepting a fixed, known loss in case of a bad one. An example with a two-piece\nCRRA utility is presented to illustrate the general results obtained, and is\nsolved completely for all admissible parameters. The effect of the behavioral\ncriterion on the risky allocations is finally discussed.\n"
    },
    {
        "paper_id": 709.3005,
        "authors": "Damien Challet",
        "title": "Feedback and efficiency in limit order markets",
        "comments": "8 pages, 2 figures. Proceedings of APFA6",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.086",
        "license": null,
        "abstract": "  A consistency criterion for price impact functions in limit order markets is\nproposed that prohibits chain arbitrage exploitation. Both the bid-ask spread\nand the feedback of sequential market orders of the same kind onto both sides\nof the order book are essential to ensure consistency at the smallest time\nscale. All the stocks investigated in Paris Stock Exchange have consistent\nprice impact functions.\n"
    },
    {
        "paper_id": 709.3261,
        "authors": "Ilija I. Zovko, J. Doyne Farmer",
        "title": "Correlations and clustering in the trading of members of the London\n  Stock Exchange",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1063/1.2828747",
        "license": null,
        "abstract": "  This paper analyzes correlations in patterns of trading of different members\nof the London Stock Exchange. The collection of strategies associated with a\nmember institution is defined by the sequence of signs of net volume traded by\nthat institution in hour intervals. Using several methods we show that there\nare significant and persistent correlations between institutions. In addition,\nthe correlations are structured into correlated and anti-correlated groups.\nClustering techniques using the correlations as a distance metric reveal a\nmeaningful clustering structure with two groups of institutions trading in\nopposite directions.\n"
    },
    {
        "paper_id": 709.363,
        "authors": "Emeterio Navarro, Ruben Cantero, Joao Rodrigues, Frank Schweitzer",
        "title": "Investments in Random Environments",
        "comments": "19 pp., corrections and extensions to compare with other approaches",
        "journal-ref": "Physica A, vol. 387, no. 8-9 (2008), pp. 2035-2046",
        "doi": "10.1016/j.physa.2007.11.029",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present analytical investigations of a multiplicative stochastic process\nthat models a simple investor dynamics in a random environment. The dynamics of\nthe investor's budget, $x(t)$, depends on the stochasticity of the return on\ninvestment, $r(t)$, for which different model assumptions are discussed. The\nfat-tail distribution of the budget is investigated and compared with\ntheoretical predictions. Weare mainly interested in the most probable value\n$x_mp$ of the budget that reaches a constant value over time. Based on an\nanalytical investigation of the dynamics, we are able to predict $x_mp^stat$.\nWe find a scaling law that relates the most probable value to the\ncharacteristic parameters describing the stochastic process. Our analytical\nresults are confirmed by stochastic computer simulations that show a very good\nagreement with the predictions.\n"
    },
    {
        "paper_id": 709.3662,
        "authors": "Victor M. Yakovenko",
        "title": "Econophysics, Statistical Mechanics Approach to",
        "comments": "24 pages, 11 figures, 151 citations. V.2: one reference added. V.3:\n  many minor corrections, some references added. V.4: many minor stylistic\n  corrections incorporated after receiving the proofs",
        "journal-ref": "Encyclopedia of Complexity and System Science, edited by R. A.\n  Meyers, Springer, 1st edition 2009 ISBN 978-0-387-75888-6 (DOI\n  10.1007/978-0-387-30440-3_169), 2nd edition 2022 ISBN 978-3-642-27737-5",
        "doi": "10.1007/978-3-642-27737-5_169-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This is a review article for Encyclopedia of Complexity and System Science,\nto be published by Springer http://refworks.springer.com/complexity/. The paper\nreviews statistical models for money, wealth, and income distributions\ndeveloped in the econophysics literature since late 1990s.\n"
    },
    {
        "paper_id": 709.371,
        "authors": "C. Gao, E. Bompard, R. Napoli, Q. Wan",
        "title": "Bidding Strategy with Forecast Technology Based on Support Vector\n  Machine in Electrcity Market",
        "comments": "8pages, 13figures, paper for the conference \"Applications of Physics\n  in Financial Analysis 6th International Conference\"",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.02.080",
        "license": null,
        "abstract": "  The participants of the electricity market concern very much the market price\nevolution. Various technologies have been developed for price forecast. SVM\n(Support Vector Machine) has shown its good performance in market price\nforecast. Two approaches for forming the market bidding strategies based on SVM\nare proposed. One is based on the price forecast accuracy, with which the being\nrejected risk is defined. The other takes into account the impact of the\nproducer's own bid. The risks associated with the bidding are controlled by the\nparameters setting. The proposed approaches have been tested on a numerical\nexample.\n"
    },
    {
        "paper_id": 709.3884,
        "authors": "Giovanni Montana, Kostas Triantafyllopoulos, and Theodoros Tsagaris",
        "title": "Flexible least squares for temporal data mining and statistical\n  arbitrage",
        "comments": "28 pages, 6 figures, submitted to journal",
        "journal-ref": "Expert Systems with Applications (2009), 36, 2819-2830.",
        "doi": "10.1016/j.eswa.2008.01.062",
        "license": null,
        "abstract": "  A number of recent emerging applications call for studying data streams,\npotentially infinite flows of information updated in real-time. When multiple\nco-evolving data streams are observed, an important task is to determine how\nthese streams depend on each other, accounting for dynamic dependence patterns\nwithout imposing any restrictive probabilistic law governing this dependence.\nIn this paper we argue that flexible least squares (FLS), a penalized version\nof ordinary least squares that accommodates for time-varying regression\ncoefficients, can be deployed successfully in this context. Our motivating\napplication is statistical arbitrage, an investment strategy that exploits\npatterns detected in financial data streams. We demonstrate that FLS is\nalgebraically equivalent to the well-known Kalman filter equations, and take\nadvantage of this equivalence to gain a better understanding of FLS and suggest\na more efficient algorithm. Promising experimental results obtained from a\nFLS-based algorithmic trading system for the S&P 500 Futures Index are\nreported.\n"
    },
    {
        "paper_id": 709.3955,
        "authors": "Cecilia Pennetta",
        "title": "Statistics of Extreme Values in Time Series with Intermediate-Term\n  Correlations",
        "comments": "6 pages, 7 figures, conference paper, in Noise and Stochastics in\n  Complex Systems and Finance, ed. by J. Kertez, S. Bornhold, R. N. Mantegna,\n  Procs. of SPIE, vol. 6601, 19, 2007",
        "journal-ref": null,
        "doi": "10.1117/12.724654",
        "license": null,
        "abstract": "  It will be discussed the statistics of the extreme values in time series\ncharacterized by finite-term correlations with non-exponential decay.\nPrecisely, it will be considered the results of numerical analyses concerning\nthe return intervals of extreme values of the fluctuations of resistance and\ndefect-fraction displayed by a resistor with granular structure in a\nnonequilibrium stationary state. The resistance and defect-fraction are\ncalculated as a function of time by Monte Carlo simulations using a resistor\nnetwork approach. It will be shown that when the auto-correlation function of\nthe fluctuations displays a non-exponential and non-power-law decay, the\ndistribution of the return intervals of extreme values is a stretched\nexponential, with exponent largely independent of the threshold. Recently, a\nstretched exponential distribution of the return intervals of extreme values\nhas been identified in long-term correlated time series by Bunde et al. (2003)\nand Altmann and Kantz (2005). Thus, the present results show that the stretched\nexponential distribution of the return intervals is not an exclusive feature of\nlong-term correlated time series.\n"
    },
    {
        "paper_id": 709.4093,
        "authors": "Bikas K Chakrabarti",
        "title": "A Brief History of Economics: An Outsider's Account",
        "comments": "6 pages, Springer style, from 'Econophysics of Stock and Other\n  Markets', Eds. A. Chatterjee, B. K. Chakrabarti, New Economic Windows Series,\n  Springer, Milan, 2006, pp~219-224",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A dangerously brief history of the developments of the main ideas in\neconomics, as observed by a physicist, is given. This was published in\n'Econophysics of Stock and Other Markets', Eds. A. Chatterjee, B. K.\nChakrabarti, New Economic Windows Series, Springer, Milan, 2006, pp~219-224.\n"
    },
    {
        "paper_id": 709.4096,
        "authors": "E.W. Piotrowski, J. Sladkowski",
        "title": "Quantum Auctions: Facts and Myths",
        "comments": "Talk given at the conference APFA6 (July 2007, Lisbone); 9 pages",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.02.071",
        "license": null,
        "abstract": "  Quantum game theory, whatever opinions may be held due to its abstract\nphysical formalism, have already found various applications even outside the\northodox physics domain. In this paper we introduce the concept of a quantum\nauction, its advantages and drawbacks. Then we describe the models that have\nalready been put forward. A general model involves Wigner formalism and\ninfinite dimensional Hilbert spaces - we envisage that the implementation might\nnot be an easy task. But a restricted model advocated by the Hewlett-Packard\ngroup seems to be much easier to implement. Simulations involving humans have\nalready been performed. We will focus on problems related to combinatorial\nauctions and technical assumptions that are made. Quantum approach offers at\nleast two important developments. Powerful quantum algorithms for finding\nsolutions would extend the range of possible applications. Quantum strategies,\nbeing qubits, can be teleported but are immune from cloning - therefore extreme\nprivacy of agent's activity could in principle be guaranteed. Then we point out\nsome key problem that have to be solved before commercial use would be\npossible. With present technology, optical networks, single photon sources and\ndetectors seems to be sufficient for experimental realization in the near\nfuture. We conclude by describing potential customers, estimating the potential\nmarket size and possible timing.\n"
    },
    {
        "paper_id": 709.4242,
        "authors": "H. Lamba and T. Seaman",
        "title": "Rational Expectations, psychology and inductive learning via moving\n  thresholds",
        "comments": "APFA6 Conference",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.061",
        "license": null,
        "abstract": "  This work suggests modifications to a previously introduced class of\nheterogeneous agent models that allow for the inclusion of different types of\nagent motivations and behaviours in a unified way. The agents operate within a\nhighly simplified environment where they are only able to be long or short one\nunit of the asset. The price of the asset is influenced by both an external\ninformation stream and the demand of the agents. The current strategy of each\nagent is defined by a pair of moving thresholds straddling the current price.\nWhen the price crosses either of the thresholds for a particular agent, that\nagent switches position and a new pair of thresholds is generated.\n  Different kinds of threshold motion correspond to different sources of\nmotivation, running the gamut from purely rational information-processing,\nthrough rational (but often undesirable) behaviour induced by perverse\nincentives and moral hazards, to purely psychological effects. As with the\nprevious class of models, the fact that the simplest model of this kind\nprecisely conforms to the Efficient Market Hypothesis allows causal\nrelationships to be established between properties at the agent level and\nviolations of EMH price statistics at the global level.\n"
    },
    {
        "paper_id": 709.4355,
        "authors": "Yuichi Ikeda, Yoshi Fujiwara, Wataru Souma, Hideaki Aoyama and Hiroshi\n  Iyetomi",
        "title": "Agent Simulation of Chain Bankruptcy",
        "comments": "Proceeding of APFA6",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We have conducted an agent-based simulation of chain bankruptcy. The\npropagation of credit risk on a network, i.e., chain bankruptcy, is the key to\nnderstanding largesized bankruptcies. In our model, decrease of revenue by the\nloss of accounts payable is modeled by an interaction term, and bankruptcy is\ndefined as a capital deficit. Model parameters were estimated using financial\ndata for 1,077 listed Japanese firms. Simulations of chain bankruptcy on the\nreal transaction network consisting of those 1,077 firms were made with the\nestimated model parameters. Given an initial bankrupt firm, a list of chain\nbankrupt firms was obtained. This model can be used to detect high-risk links\nin a transaction network, for the management of chain bankruptcy.\n"
    },
    {
        "paper_id": 709.4358,
        "authors": "Anna Szczypinska, Edward W. Piotrowski",
        "title": "Projective Market Model Approach to AHP Decision-Making",
        "comments": "APFA 6 - Applications of Physics in Financial Analysis 6th\n  International Conference, 4-7 July 2007, Lisbon, Portugal",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.01.053",
        "license": null,
        "abstract": "  In this paper we describe market in projective geometry language and give\ndefinition of a matrix of market rate, which is related to the matrix rate of\nreturn and the matrix of judgements in the Analytic Hierarchy Process (AHP). We\nuse these observations to extend the AHP model to projective geometry formalism\nand generalise it to intransitive case. We give financial interpretations of\nsuch generalised model and propose its simplification. The unification of the\nAHP model and projective aspect of portfolio theory suggests a wide spectrum of\nnew applications such extended model.\n"
    },
    {
        "paper_id": 709.4361,
        "authors": "M. Kanevski, M. Maignan, A. Pozdnoukhov, V. Timonin",
        "title": "Interest rates mapping",
        "comments": "8 pages, 8 figures. Presented at Applications of Physics in Financial\n  Analysis conference (APFA6), Lisbon, Portugal, 2006",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.02.069",
        "license": null,
        "abstract": "  The present study deals with the analysis and mapping of Swiss franc interest\nrates. Interest rates depend on time and maturity, defining term structure of\nthe interest rate curves (IRC). In the present study IRC are considered in a\ntwo-dimensional feature space - time and maturity. Geostatistical models and\nmachine learning algorithms (multilayer perceptron and Support Vector Machines)\nwere applied to produce interest rate maps. IR maps can be used for the\nvisualisation and patterns perception purposes, to develop and to explore\neconomical hypotheses, to produce dynamic asses-liability simulations and for\nthe financial risk assessments. The feasibility of an application of interest\nrates mapping approach for the IRC forecasting is considered as well.\n"
    },
    {
        "paper_id": 709.4467,
        "authors": "Hanqing Jin, Zuo Quan Xu and Xun Yu Zhou",
        "title": "A Convex Stochastic Optimization Problem Arising from Portfolio\n  Selection",
        "comments": "15 pages",
        "journal-ref": "Mathematical Finance, Vol. 18, No. 1 (January 2008), 171-183",
        "doi": "10.1111/j.1467-9965.2007.00327.x",
        "license": null,
        "abstract": "  A continuous-time financial portfolio selection model with expected utility\nmaximization typically boils down to solving a (static) convex stochastic\noptimization problem in terms of the terminal wealth, with a budget constraint.\nIn literature the latter is solved by assuming {\\it a priori} that the problem\nis well-posed (i.e., the supremum value is finite) and a Lagrange multiplier\nexists (and as a consequence the optimal solution is attainable). In this paper\nit is first shown, via various counter-examples, neither of these two\nassumptions needs to hold, and an optimal solution does not necessarily exist.\nThese anomalies in turn have important interpretations in and impacts on the\nportfolio selection modeling and solutions. Relations among the non-existence\nof the Lagrange multiplier, the ill-posedness of the problem, and the\nnon-attainability of an optimal solution are then investigated. Finally,\nexplicit and easily verifiable conditions are derived which lead to finding the\nunique optimal solution.\n"
    },
    {
        "paper_id": 710.0069,
        "authors": "J.C. Ndogmo and D. B. Ntwiga",
        "title": "High-order accurate implicit methods for the pricing of barrier options",
        "comments": "20 pages, 3 poscript figures, 6 tables",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper deals with a high-order accurate implicit finite-difference\napproach to the pricing of barrier options. In this way various types of\nbarrier options are priced, including barrier options paying rebates, and\noptions on dividend-paying-stocks. Moreover, the barriers may be monitored\neither continuously or discretely. In addition to the high-order accuracy of\nthe scheme, and the stretching effect of the coordinate transformation, the\nmain feature of this approach lies on a probability-based optimal determination\nof boundary conditions. This leads to much faster and accurate results when\ncompared with similar pricing approaches. The strength of the present scheme is\nparticularly demonstrated in the valuation of discretely monitored barrier\noptions where it yields values closest to those obtained from the only\nsemi-analytical valuation method available.\n"
    },
    {
        "paper_id": 710.0114,
        "authors": "Edward W. Piotrowski, Jan Sladkowski, Anna Szczypinska",
        "title": "Reinforcement learning in market games",
        "comments": "Talk given at the conference APFA6 (July 2007, Lisbone); 7 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Financial markets investors are involved in many games -- they must interact\nwith other agents to achieve their goals. Among them are those directly\nconnected with their activity on markets but one cannot neglect other aspects\nthat influence human decisions and their performance as investors.\nDistinguishing all subgames is usually beyond hope and resource consuming. In\nthis paper we study how investors facing many different games, gather\ninformation and form their decision despite being unaware of the complete\nstructure of the game. To this end we apply reinforcement learning methods to\nthe Information Theory Model of Markets (ITMM). Following Mengel, we can try to\ndistinguish a class $\\Gamma$ of games and possible actions (strategies)\n$a^{i}_{m_{i}}$ for $i-$th agent. Any agent divides the whole class of games\ninto analogy subclasses she/he thinks are analogous and therefore adopts the\nsame strategy for a given subclass. The criteria for partitioning are based on\nprofit and costs analysis. The analogy classes and strategies are updated at\nvarious stages through the process of learning. This line of research can be\ncontinued in various directions.\n"
    },
    {
        "paper_id": 710.0241,
        "authors": "Kateryna Mishchenko, Volodymyr Mishchenko and Anatoliy Malyarenko",
        "title": "Adapted Downhill Simplex Method for Pricing Convertible Bonds",
        "comments": "18 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The paper is devoted to modeling optimal exercise strategies of the behavior\nof investors and issuers working with convertible bonds. This implies solution\nof the problems of stock price modeling, payoff computation and min-max\noptimization.\n  Stock prices (underlying asset) were modeled under the assumption of the\ngeometric Brownian motion of their values. The Monte Carlo method was used for\ncalculating the real payoff which is the objective function. The min-max\noptimization problem was solved using the derivative-free Downhill Simplex\nmethod.\n  The performed numerical experiments allowed to formulate recommendations for\nthe choice of appropriate size of the initial simplex in the Downhill Simplex\nMethod, the number of generated trajectories of underlying asset, the size of\nthe problem and initial trajectories of the behavior of investors and issuers.\n"
    },
    {
        "paper_id": 710.0459,
        "authors": "Zoltan Kuscsik and Denis Horvath",
        "title": "Statistical properties of agent-based market area model",
        "comments": "5 figures, 7 pages. submited to ICCS 2007, Boston",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  One dimensional stylized model taking into account spatial activity of firms\nwith uniformly distributed customers is proposed. The spatial selling area of\neach firm is defined by a short interval cut out from selling space (large\ninterval). In this representation, the firm size is directly associated with\nthe size of its selling interval.\n  The recursive synchronous dynamics of economic evolution is discussed where\nthe growth rate is proportional to the firm size incremented by the term\nincluding the overlap of the selling area with areas of competing firms. Other\nwords, the overlap of selling areas inherently generate a negative feedback\noriginated from the pattern of demand. Numerical simulations focused on the\nobtaining of the firm size distributions uncovered that the range of free\nparameters where the Pareto's law holds corresponds to the range for which the\npair correlation between the nearest neighbor firms attains its minimum.\n"
    },
    {
        "paper_id": 710.0576,
        "authors": "M. Tumminello, F. Lillo, R. N. Mantegna",
        "title": "Shrinkage and spectral filtering of correlation matrices: a comparison\n  via the Kullback-Leibler distance",
        "comments": "11 pages, 4 figures, Presented at the Workshop \"Random Matrix Theory:\n  From Fundamental Physics To Application\", Krakow, Poland, May 3-5, 2007",
        "journal-ref": "Acta Phys. Pol. B 38 (13), 4079-4088 (2007)",
        "doi": null,
        "license": null,
        "abstract": "  The problem of filtering information from large correlation matrices is of\ngreat importance in many applications. We have recently proposed the use of the\nKullback-Leibler distance to measure the performance of filtering algorithms in\nrecovering the underlying correlation matrix when the variables are described\nby a multivariate Gaussian distribution. Here we use the Kullback-Leibler\ndistance to investigate the performance of filtering methods based on Random\nMatrix Theory and on the shrinkage technique. We also present some results on\nthe application of the Kullback-Leibler distance to multivariate data which are\nnon Gaussian distributed.\n"
    },
    {
        "paper_id": 710.0745,
        "authors": "Marie-Th\\'er\\`ese Boyer-Xambeu (LED - EA3391), Ghislain Deleplace (LED\n  - EA3391), Patrice Gaubert (SAMOS), Lucien Gillard (LED - EA3391), Madalina\n  Olteanu (SAMOS)",
        "title": "Mixing Kohonen Algorithm, Markov Switching Model and Detection of\n  Multiple Change-Points: An Application to Monetary History",
        "comments": null,
        "journal-ref": "Computational and Ambient Intelligence, Springer (Ed.) (2007)\n  547-555",
        "doi": null,
        "license": null,
        "abstract": "  The present paper aims at locating the breakings of the integration process\nof an international system observed during about 50 years in the 19th century.\nA historical study could link them to special events, which operated as\nexogenous shocks on this process. The indicator of integration used is the\nspread between the highest and the lowest among the London, Hamburg and Paris\ngold-silver prices. Three algorithms are combined to study this integration: a\nperiodization obtained with the SOM algorithm is confronted to the estimation\nof a two-regime Markov switching model, in order to give an interpretation of\nthe changes of regime; in the same time change-points are identified over the\nwhole period providing a more precise interpretation of the various types of\nregulation.\n"
    },
    {
        "paper_id": 710.0753,
        "authors": "Helen Haworth, Christoph Reisinger and William Shaw",
        "title": "Modelling Bonds & Credit Default Swaps using a Structural Model with\n  Contagion",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper develops a two-dimensional structural framework for valuing credit\ndefault swaps and corporate bonds in the presence of default contagion.\nModelling the values of related firms as correlated geometric Brownian motions\nwith exponential default barriers, analytical formulae are obtained for both\ncredit default swap spreads and corporate bond yields. The credit dependence\nstructure is influenced by both a longer-term correlation structure as well as\nby the possibility of default contagion. In this way, the model is able to\ngenerate a diverse range of shapes for the term structure of credit spreads\nusing realistic values for input parameters.\n"
    },
    {
        "paper_id": 710.0802,
        "authors": "Giulio Biroli, Jean-Philippe Bouchaud and Marc Potters",
        "title": "The Student ensemble of correlation matrices: eigenvalue spectrum and\n  Kullback-Leibler entropy",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study a new ensemble of random correlation matrices related to\nmultivariate Student (or more generally elliptic) random variables. We\nestablish the exact density of states of empirical correlation matrices that\ngeneralizes the Marcenko-Pastur result. The comparison between the theoretical\ndensity of states in the Student case and empirical financial data is\nsurprisingly good, even if we are still able to detect systematic deviations.\nFinally, we compute explicitely the Kullback-Leibler entropies of empirical\nStudent matrices, which are found to be independent of the true correlation\nmatrix, as in the Gaussian case. We provide numerically exact values for these\nKullback-Leibler entropies.\n"
    },
    {
        "paper_id": 710.1014,
        "authors": "Marisciel L. Palima and Eduardo J. David",
        "title": "Wealth distribution in a System with Wealth-limited Interactions",
        "comments": "10 pages, 4 figures, Presented at the Econophysics Colloquium at the\n  Polytechnic University of Marche, Anchoa, Italy last Sept. 27, 2007",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We model a closed economic system with interactions that generates the\nfeatures of empirical wealth distribution across all wealth brackets, namely a\nGibbsian trend in the lower and middle wealth range and a Pareto trend in the\nhigher range, by simply limiting the an agents' interaction to only agents with\nnearly the same wealth. To do this, we introduce a parameter BETA that limits\nthe range on the wealth of a partner with which an agent is allowed to\ninteract. We show that this wealth-limited interaction is enough to distribute\nwealth in a purely power law trend. If the interaction is not wealth limited,\nthe wealth distribution is expectedly Gibbsian. The value of BETA where the\ntransition from a purely Gibbsian law to a purely power law distribution\nhappens depends on whether the choice of interaction partner is mutual nor not.\nFor a non-mutual choice, where the richer agent gets to decide, the transition\nhappens at BETA=1.0. For a mutual choice, the transition is at BETA= 0.60. In\norder to generate a mixed Gibbs-Pareto distribution, we apply another\nwealth-based rule that depends on the parameter w_limit. An agent whose wealth\nis below w_limit can choose any partner to interact with, while an agent whose\nwealth is above w_limit is subject to the wealth-limited range in his choice of\npartner. A Gibbs-Pareto distribution appears if both these wealth-based rules\nare applied.\n"
    },
    {
        "paper_id": 710.1139,
        "authors": "Wan Ahmad Tajuddin Wan Abdullah and Sidiq Mohamad Khidzir (Universiti\n  Malaya)",
        "title": "Kinetic Economies",
        "comments": "Presented at the 10th Asia-Pacific Physics Conference, Pohang, South\n  Korea, August 2007",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study a minimalist kinetic model for economies. A system of agents with\nlocal trading rules display emergent demand behaviour. We examine the resulting\nwealth distribution to look for non-thermal behaviour. We compare and contrast\nthis model with other similar models.\n"
    },
    {
        "paper_id": 710.1307,
        "authors": "Esteban Guevara Hidalgo",
        "title": "Common Markets, Strong Currencies & the Collective Welfare",
        "comments": "9 pages. arXiv admin note: substantial text overlap with\n  arXiv:0705.0029, arXiv:physics/0609088, arXiv:quant-ph/0606045,\n  arXiv:physics/0609245; text overlap with arXiv:quant-ph/0510238",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The so called \"globalization\" process (i.e. the inexorable integration of\nmarkets, currencies, nation-states, technologies and the intensification of\nconsciousness of the world as a whole) has a behavior exactly equivalent to a\nsystem that is tending to a maximum entropy state. This globalization process\nobeys a collective welfare principle in where the maximum payoff is given by\nthe equilibrium of the system and its stability by the maximization of the\nwelfare of the collective besides the individual welfare. This let us predict\nthe apparition of big common markets and strong common currencies. They will\nreach the \"equilibrium\" by decreasing its number until they reach a state\ncharacterized by only one common currency and only one big common community\naround the world.\n"
    },
    {
        "paper_id": 710.1439,
        "authors": "V. Gontis, B. Kaulakys, J. Ruseckas",
        "title": "Trading activity as driven Poisson process: comparison with empirical\n  data",
        "comments": "9 pages, 5 figures, proceedings of APFA6",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.02.078",
        "license": null,
        "abstract": "  We propose the point process model as the Poissonian-like stochastic sequence\nwith slowly diffusing mean rate and adjust the parameters of the model to the\nempirical data of trading activity for 26 stocks traded on NYSE. The proposed\nscaled stochastic differential equation provides the universal description of\nthe trading activities with the same parameters applicable for all stocks.\n"
    },
    {
        "paper_id": 710.1729,
        "authors": "Kenta Yamada, Hideki Takayasu, Misako Takayasu",
        "title": "The Grounds For Time Dependent Market Potentials From Dealers' Dynamics",
        "comments": "9 pages, 3 figures, proceedings of APFA6",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00155-4",
        "license": null,
        "abstract": "  We apply the potential force estimation method to artificial time series of\nmarket price produced by a deterministic dealer model. We find that dealers'\nfeedback of linear prediction of market price based on the latest mean price\nchanges plays the central role in the market's potential force. When markets\nare dominated by dealers with positive feedback the resulting potential force\nis repulsive, while the effect of negative feedback enhances the attractive\npotential force.\n"
    },
    {
        "paper_id": 710.1855,
        "authors": "Imre Kondor, Istvan Varga-Haszonits",
        "title": "Divergent estimation error in portfolio optimization and in linear\n  regression",
        "comments": "5 pages, 2 figures, Statphys 23 Conference Proceeding",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00060-x",
        "license": null,
        "abstract": "  The problem of estimation error in portfolio optimization is discussed, in\nthe limit where the portfolio size N and the sample size T go to infinity such\nthat their ratio is fixed. The estimation error strongly depends on the ratio\nN/T and diverges for a critical value of this parameter. This divergence is the\nmanifestation of an algorithmic phase transition, it is accompanied by a number\nof critical phenomena, and displays universality. As the structure of a large\nnumber of multidimensional regression and modelling problems is very similar to\nportfolio optimization, the scope of the above observations extends far beyond\nfinance, and covers a large number of problems in operations research, machine\nlearning, bioinformatics, medical science, economics, and technology.\n"
    },
    {
        "paper_id": 710.1893,
        "authors": "Atushi Ishikawa",
        "title": "Quasistatically varying log-normal distribution in the middle scale\n  region of Japanese land prices",
        "comments": "16 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Employing data on the assessed value of land in 1974--2007 Japan, we exhibit\na quasistatically varying log-normal distribution in the middle scale region.\nIn the derivation, a Non-Gibrat's law under the detailed quasi-balance is\nadopted together with two approximations. The resultant distribution is\npower-law with the varying exponent in the large scale region and the\nquasistatic log-normal distribution with the varying standard deviation in the\nmiddle scale region. In the distribution, not only the change of the exponent\nbut also the change of the standard deviation depends on the parameter of the\ndetailed quasi-balance. These results are consistently confirmed by the\nempirical data.\n"
    },
    {
        "paper_id": 710.1909,
        "authors": "Walter Schachermayer, Mihai Sirbu and Erik Taflin",
        "title": "In which Financial Markets do Mutual Fund Theorems hold true?",
        "comments": "21 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Mutual Fund Theorem (MFT) is considered in a general semimartingale\nfinancial market S with a finite time horizon T, where agents maximize expected\nutility of terminal wealth. It is established that:\n  1) Let N be the wealth process of the num\\'eraire portfolio (i.e. the optimal\nportfolio for the log utility). If any path-independent option with maturity T\nwritten on the num\\'eraire portfolio can be replicated by trading \\emph{only}\nin N, then the (MFT) holds true for general utility functions, and the\nnum\\'eraire portfolio may serve as mutual fund. This generalizes Merton's\nclassical result on Black-Scholes markets.\n  Conversely, under a supplementary weak completeness assumption, we show that\nthe validity of the (MFT) for general utility functions implies the same\nreplicability property for options on the num\\'eraire portfolio described\nabove.\n  2) If for a given class of utility functions (i.e. investors) the (MFT) holds\ntrue in all complete Brownian financial markets S, then all investors use the\nsame utility function U, which must be of HARA type. This is a result in the\nspirit of the classical work by Cass and Stiglitz.\n"
    },
    {
        "paper_id": 710.1995,
        "authors": "Boris Podobnik, Jia Shao, Djuro Njavro, Plamen Ch. Ivanov, H. Eugene\n  Stanley",
        "title": "Influence of corruption on economic growth rate and foreign investments",
        "comments": "8 pages, 3 figures, elsart style",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00210-2",
        "license": null,
        "abstract": "  In order to investigate whether government regulations against corruption can\naffect the economic growth of a country, we analyze the dependence between\nGross Domestic Product (GDP) per capita growth rates and changes in the\nCorruption Perceptions Index (CPI). For the period 1999-2004 on average for all\ncountries in the world, we find that an increase of CPI by one unit leads to an\nincrease of the annual GDP per capita by 1.7 %. By regressing only European\ntransition countries, we find that $\\Delta$CPI = 1 generates increase of the\nannual GDP per capita by 2.4 %. We also analyze the relation between foreign\ndirect investments received by different countries and CPI, and we find a\nstatistically significant power-law functional dependence between foreign\ndirect investment per capita and the country corruption level measured by the\nCPI. We introduce a new measure to quantify the relative corruption between\ncountries based on their respective wealth as measured by GDP per capita.\n"
    },
    {
        "paper_id": 710.2402,
        "authors": "Xiao-Hui Ni, Wei-Xing Zhou (ECUST)",
        "title": "Intraday pattern in bid-ask spreads and its power-law relaxation for\n  Chinese A-share stocks",
        "comments": "12 Elsart pages including 7 eps figures",
        "journal-ref": "Journal of the Korean Physics Society 54 (2), 786-791 (2009)",
        "doi": "10.3938/jkps.54.786",
        "license": null,
        "abstract": "  We use high-frequency data of 1364 Chinese A-share stocks traded on the\nShanghai Stock Exchange and Shenzhen Stock Exchange to investigate the intraday\npatterns in the bid-ask spreads. The daily periodicity in the spread time\nseries is confirmed by Lomb analysis and the intraday bid-ask spreads are found\nto exhibit $L$-shaped pattern with idiosyncratic fine structure. The intraday\nspread of individual stocks relaxes as a power law within the first hour of the\ncontinuous double auction from 9:30AM to 10:30AM with exponents\n$\\beta_{\\rm{SHSE}}=0.19\\pm0.069$ for the Shanghai market and\n$\\beta_{\\rm{SZSE}}=0.18\\pm0.067$ for the Shenzhen market. The power-law\nrelaxation exponent $\\beta$ of individual stocks is roughly normally\ndistributed. There is evidence showing that the accumulation of information\nwidening the spread is an endogenous process.\n"
    },
    {
        "paper_id": 710.2583,
        "authors": "Joseph L. McCauley, Kevin E. Bassler, and Gemunu H. Gunaratne",
        "title": "Martingales, the Efficient Market Hypothesis, and Spurious Stylized\n  Facts",
        "comments": "5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The condition for stationary increments, not scaling, detemines long time\npair autocorrelations. An incorrect assumption of stationary increments\ngenerates spurious stylized facts, fat tails and a Hurst exponent H_s=1/2, when\nthe increments are nonstationary, as they are in FX markets. The\nnonstationarity arises from systematic uneveness in noise traders' behavior.\nSpurious results arise mathematically from using a log increment with a\n'sliding window'. We explain why a hard to beat market demands martingale\ndynamics , and martingales with nonlinear variance generate nonstationary\nincrements. The nonstationarity is exhibited directly for Euro/Dollar FX data.\nWe observe that the Hurst exponent H_s generated by the using the sliding\nwindow technique on a time series plays the same role as does Mandelbrot's\nJoseph exponent. Finally, Mandelbrot originally assumed that the 'badly\nbehaved' second moment of cotton returns is due to fat tails, but that\nnonconvergent behavior is instead direct evidence for nonstationary increments.\nSummarizing, the evidence for scaling and fat tails as the basis for\neconophysics and financial economics is provided neither by FX markets nor by\ncotton price data.\n"
    },
    {
        "paper_id": 710.2758,
        "authors": "Alet Roux",
        "title": "The fundamental theorem of asset pricing under proportional transaction\n  costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We extend the fundamental theorem of asset pricing to a model where the risky\nstock is subject to proportional transaction costs in the form of bid-ask\nspreads and the bank account has different interest rates for borrowing and\nlending. We show that such a model is free of arbitrage if and only if one can\nembed in it a friction-free model that is itself free of arbitrage, in the\nsense that there exists an artificial friction-free price for the stock between\nits bid and ask prices and an artificial interest rate between the borrowing\nand lending interest rates such that, if one discounts this stock price by this\ninterest rate, then the resulting process is a martingale under some\nnon-degenerate probability measure. Restricting ourselves to the simple case of\na finite number of time steps and a finite number of possible outcomes for the\nstock price, the proof follows by combining classical arguments based on\nfinite-dimensional separation theorems with duality results from linear\noptimisation.\n"
    },
    {
        "paper_id": 710.2775,
        "authors": "Dorje C. Brody, Lane P. Hughston, Andrea Macrina",
        "title": "Dam Rain and Cumulative Gain",
        "comments": "25 Pages, 1 Figure",
        "journal-ref": "Proceedings of the Royal Society London A464, 1801-1822 (2008)",
        "doi": "10.1098/rspa.2007.0273",
        "license": null,
        "abstract": "  We consider a financial contract that delivers a single cash flow given by\nthe terminal value of a cumulative gains process. The problem of modelling and\npricing such an asset and associated derivatives is important, for example, in\nthe determination of optimal insurance claims reserve policies, and in the\npricing of reinsurance contracts. In the insurance setting, the aggregate\nclaims play the role of the cumulative gains, and the terminal cash flow\nrepresents the totality of the claims payable for the given accounting period.\nA similar example arises when we consider the accumulation of losses in a\ncredit portfolio, and value a contract that pays an amount equal to the\ntotality of the losses over a given time interval. An explicit expression for\nthe value process is obtained. The price of an Arrow-Debreu security on the\ncumulative gains process is determined, and is used to obtain a closed-form\nexpression for the price of a European-style option on the value of the asset.\nThe results obtained make use of various remarkable properties of the gamma\nbridge process, and are applicable to a wide variety of financial products\nbased on cumulative gains processes such as aggregate claims, credit portfolio\nlosses, defined-benefit pension schemes, emissions, and rainfall.\n"
    },
    {
        "paper_id": 710.2792,
        "authors": "Mark Davis and Jan Obloj",
        "title": "Market completion using options",
        "comments": "Keywords, AMS Classification and some further specific comments about\n  results from PDEs added. The final version to appear in volume 83 of Banach\n  Center Publications (ed. L. Stettner)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Mathematical models for financial asset prices which include, for example,\nstochastic volatility or jumps are incomplete in that derivative securities are\ngenerally not replicable by trading in the underlying. In earlier work (2004)\nthe first author provided a geometric condition under which trading in the\nunderlying and a finite number of vanilla options completes the market. We\ncomplement this result in several ways. First, we show that the geometric\ncondition is not necessary and a weaker, necessary and sufficient, condition is\npresented. While this condition is generally not directly verifiable, we show\nthat it simplifies to matrix non-degeneracy in a single point when the pricing\nfunctions are real analytic functions. In particular, any stochastic volatility\nmodel is then completed with an arbitrary European type option. Further, we\nshow that adding path-dependent options such as a variance swap to the set of\nprimary assets, instead of plain vanilla options, also completes the market.\n"
    },
    {
        "paper_id": 710.2876,
        "authors": "Lane P. Hughston and Andrea Macrina",
        "title": "Information, Inflation, and Interest",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a class of discrete-time stochastic models for the pricing of\ninflation-linked assets. The paper begins with an axiomatic scheme for asset\npricing and interest rate theory in a discrete-time setting. The first axiom\nintroduces a \"risk-free\" asset, and the second axiom determines the\nintertemporal pricing relations that hold for dividend-paying assets. The\nnominal and real pricing kernels, in terms of which the price index can be\nexpressed, are then modelled by introducing a Sidrauski-type utility function\ndepending on (a) the aggregate rate of consumption, and (b) the aggregate rate\nof real liquidity benefit conferred by the money supply. Consumption and money\nsupply policies are chosen such that the expected joint utility obtained over a\nspecified time horizon is maximised subject to a budget constraint that takes\ninto account the \"value\" of the liquidity benefit associated with the money\nsupply. For any choice of the bivariate utility function, the resulting model\ndetermines a relation between the rate of consumption, the price level, and the\nmoney supply. The model also produces explicit expressions for the real and\nnominal pricing kernels, and hence establishes a basis for the valuation of\ninflation-linked securities.\n"
    },
    {
        "paper_id": 710.2991,
        "authors": "Claudio Albanese and Adel Osseiran",
        "title": "Moment Methods for Exotic Volatility Derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The latest generation of volatility derivatives goes beyond variance and\nvolatility swaps and probes our ability to price realized variance and sojourn\ntimes along bridges for the underlying stock price process. In this paper, we\ngive an operator algebraic treatment of this problem based on Dyson expansions\nand moment methods and discuss applications to exotic volatility derivatives.\nThe methods are quite flexible and allow for a specification of the underlying\nprocess which is semi-parametric or even non-parametric, including\nstate-dependent local volatility, jumps, stochastic volatility and regime\nswitching. We find that volatility derivatives are particularly well suited to\nbe treated with moment methods, whereby one extrapolates the distribution of\nthe relevant path functionals on the basis of a few moments. We consider a\nnumber of exotics such as variance knockouts, conditional corridor variance\nswaps, gamma swaps and variance swaptions and give valuation formulas in\ndetail.\n"
    },
    {
        "paper_id": 710.3645,
        "authors": "F. Clementi, T. Di Matteo, M. Gallegati, G. Kaniadakis",
        "title": "The k-generalized distribution: A new descriptive model for the size\n  distribution of incomes",
        "comments": "12 pages with 8 figures; LaTeX; introduction revised, added reference\n  for section 1; accepted for publication in Physica A: Statistical Mechanics\n  and its Applications",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, Vol: 387,\n  Issue: 13, 15 May 2008, pp: 3201-3208",
        "doi": "10.1016/j.physa.2008.01.109",
        "license": null,
        "abstract": "  This paper proposes the k-generalized distribution as a model for describing\nthe distribution and dispersion of income within a population. Formulas for the\nshape, moments and standard tools for inequality measurement - such as the\nLorenz curve and the Gini coefficient - are given. A method for parameter\nestimation is also discussed. The model is shown to fit extremely well the data\non personal income distribution in Australia and the United States.\n"
    },
    {
        "paper_id": 710.3892,
        "authors": "Thaleia Zariphopoulou and Gordan Zitkovic",
        "title": "Maturity-independent risk measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The new notion of maturity-independent risk measures is introduced and\ncontrasted with the existing risk measurement concepts. It is shown, by means\nof two examples, one set on a finite probability space and the other in a\ndiffusion framework, that, surprisingly, some of the widely utilized risk\nmeasures cannot be used to build maturity-independent counterparts. We\nconstruct a large class of maturity-independent risk measures and give\nrepresentative examples in both continuous- and discrete-time financial models.\n"
    },
    {
        "paper_id": 710.3959,
        "authors": "Xiaolin Luo and Pavel V. Shevchenko",
        "title": "The t copula with Multiple Parameters of Degrees of Freedom: Bivariate\n  Characteristics and Application to Risk Management",
        "comments": null,
        "journal-ref": "Quantitative Finance. Volume 10, Issue 9. November 2010. 1039-1054",
        "doi": "10.1080/14697680903085544",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The t copula is often used in risk management as it allows for modelling tail\ndependence between risks and it is simple to simulate and calibrate. However,\nthe use of a standard t copula is often criticized due to its restriction of\nhaving a single parameter for the degrees of freedom (dof) that may limit its\ncapability to model the tail dependence structure in a multivariate case. To\novercome this problem, grouped t copula was proposed recently, where risks are\ngrouped a priori in such a way that each group has a standard t copula with its\nspecific dof parameter. In this paper we propose the use of a grouped t copula,\nwhere each group consists of one risk factor only, so that a priori grouping is\nnot required. The copula characteristics in the bivariate case are studied. We\nexplain simulation and calibration procedures, including a simulation study on\nfinite sample properties of the maximum likelihood estimators and Kendall's tau\napproximation. This new copula can be significantly different from the standard\nt copula in terms of risk measures such as tail dependence, value at risk and\nexpected shortfall.\n  Keywords: grouped t copula, tail dependence, risk management.\n"
    },
    {
        "paper_id": 710.401,
        "authors": "Martin Rypdal, Kristoffer Rypdal",
        "title": "A stochastic theory for temporal fluctuations in self-organized critical\n  systems",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/10/12/123010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A stochastic theory for the toppling activity in sandpile models is\ndeveloped, based on a simple mean-field assumption about the toppling process.\nThe theory describes the process as an anti-persistent Gaussian walk, where the\ndiffusion coefficient is proportional to the activity. It is formulated as a\ngeneralization of the It\\^{o} stochastic differential equation with an\nanti-persistent fractional Gaussian noise source. An essential element of the\ntheory is re-scaling to obtain a proper thermodynamic limit, and it captures\nall temporal features of the toppling process obtained by numerical simulation\nof the Bak-Tang-Wiesenfeld sandpile in this limit.\n"
    },
    {
        "paper_id": 710.4106,
        "authors": "Nicole El Karoui and Claudia Ravanelli",
        "title": "Cash Sub-additive Risk Measures and Interest Rate Ambiguity",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A new class of risk measures called cash sub-additive risk measures is\nintroduced to assess the risk of future financial, nonfinancial and insurance\npositions. The debated cash additive axiom is relaxed into the cash sub\nadditive axiom to preserve the original difference between the numeraire of the\ncurrent reserve amounts and future positions. Consequently, cash sub-additive\nrisk measures can model stochastic and/or ambiguous interest rates or\ndefaultable contingent claims. Practical examples are presented and in such\ncontexts cash additive risk measures cannot be used. Several representations of\nthe cash sub-additive risk measures are provided. The new risk measures are\ncharacterized by penalty functions defined on a set of sub-linear probability\nmeasures and can be represented using penalty functions associated with cash\nadditive risk measures defined on some extended spaces. The issue of the\noptimal risk transfer is studied in the new framework using inf-convolution\ntechniques. Examples of dynamic cash sub-additive risk measures are provided\nvia BSDEs where the generator can locally depend on the level of the cash\nsub-additive risk measure.\n"
    },
    {
        "paper_id": 710.5301,
        "authors": "Daniel Sevcovic",
        "title": "An iterative algorithm for evaluating approximations to the optimal\n  exercise boundary for a nonlinear Black-Scholes equation",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The purpose of this paper is to analyze and compute the early exercise\nboundary for a class of nonlinear Black--Scholes equations with a nonlinear\nvolatility which can be a function of the second derivative of the option price\nitself. A motivation for studying the nonlinear Black--Scholes equation with a\nnonlinear volatility arises from option pricing models taking into account e.g.\nnontrivial transaction costs, investor's preferences, feedback and illiquid\nmarkets effects and risk from a volatile (unprotected) portfolio. We present a\nnew method how to transform the free boundary problem for the early exercise\nboundary position into a solution of a time depending nonlinear parabolic\nequation defined on a fixed domain. We furthermore propose an iterative\nnumerical scheme that can be used to find an approximation of the free\nboundary. We present results of numerical approximation of the early exercise\nboundary for various types of nonlinear Black--Scholes equations and we discuss\ndependence of the free boundary on various model parameters.\n"
    },
    {
        "paper_id": 710.5497,
        "authors": "Camilo Rodrigues Neto, Andr\\' e C.R. Martins",
        "title": "Multifractality in the Random Parameters Model",
        "comments": "9 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Random Parameters model was proposed to explain the structure of the\ncovariance matrix in problems where most, but not all, of the eigenvalues of\nthe covariance matrix can be explained by Random Matrix Theory. In this\narticle, we explore other properties of the model, like the scaling of its PDF\nas one take larger scales. Special attention is given to the multifractal\nstructure of the model time series, which revealed a scaling structure\ncompatible with the known stylized facts for a reasonable choice of the\nparameter values.\n"
    },
    {
        "paper_id": 711.0223,
        "authors": "Luca Capriotti",
        "title": "Least Squares Importance Sampling for Libor Market Models",
        "comments": "14 pages, 1 figure",
        "journal-ref": "Wilmott Magazine, September 2007",
        "doi": null,
        "license": null,
        "abstract": "  A recently introduced Importance Sampling strategy based on a least squares\noptimization is applied to the Monte Carlo simulation of Libor Market Models.\nSuch Least Squares Importance Sampling (LSIS) allows the automatic optimization\nof the sampling distribution within a trial class by means of a quick\npresimulation algorithm of straightforward implementation. With several\nnumerical examples we show that LSIS can be extremely effective in reducing the\nvariance of Monte Carlo estimators often resulting, especially when combined\nwith stratified sampling, in computational speed-ups of orders of magnitude.\n"
    },
    {
        "paper_id": 711.0644,
        "authors": "S. Drozdz, J. Kwapien, P. Oswiecimka",
        "title": "Empirics versus RMT in financial cross-correlations",
        "comments": "Presented at the conference \"Random Matrix Theory: From Fundamental\n  Physics To Applications\", May 2-6, 2007, Krakow, Poland",
        "journal-ref": "Acta Physica Polonica B 58, 4027-4039 (2007)",
        "doi": null,
        "license": null,
        "abstract": "  In order to pursue the issue of the relation between the financial\ncross-correlations and the conventional Random Matrix Theory we analyse several\ncharacteristics of the stock market correlation matrices like the distribution\nof eigenvalues, the cross-correlations among signs of the returns, the\nvolatility cross-correlations, and the multifractal characteristics of the\nprincipal values. The results indicate that the stock market dynamics is not\nsimply decomposable into 'market', 'sectors', and the Wishart random bulk. This\nclearly is seen when the time series used to construct the correlation matrices\nare sufficiently long and thus the measurement noise suppressed. Instead, a\nhierarchically convoluted and highly nonlinear organization of the market\nemerges and indicates that the relevant information about the whole market is\nencoded already in its constituents.\n"
    },
    {
        "paper_id": 711.0729,
        "authors": "Massimiliano Zanin",
        "title": "Forbidden patterns in financial time series",
        "comments": "4 pages, 4 figures; affiliation updated",
        "journal-ref": null,
        "doi": "10.1063/1.2841197",
        "license": null,
        "abstract": "  The existence of forbidden patterns, i.e., certain missing sequences in a\ngiven time series, is a recently proposed instrument of potential application\nin the study of time series. Forbidden patterns are related to the permutation\nentropy, which has the basic properties of classic chaos indicators, thus\nallowing to separate deterministic (usually chaotic) from random series;\nhowever, it requires less values of the series to be calculated, and it is\nsuitable for using with small datasets. In this Letter, the appearance of\nforbidden patterns is studied in different economical indicators like stock\nindices (Dow Jones Industrial Average and Nasdaq Composite), NYSE stocks (IBM\nand Boeing) and others (10-year Bond interest rate), to find evidences of\ndeterministic behavior in their evolutions.\n"
    },
    {
        "paper_id": 711.1136,
        "authors": "Soumik Pal, Philip Protter",
        "title": "Analysis of continuous strict local martingales via h-transforms",
        "comments": "Significantly revised version. 28 pages",
        "journal-ref": null,
        "doi": "10.1016/j.spa.2010.04.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study strict local martingales via h-transforms, a method which first\nappeared in Delbaen-Schachermayer. We show that strict local martingales arise\nwhenever there is a consistent family of change of measures where the two\nmeasures are not equivalent to one another. Several old and new strict local\nmartingales are identified. We treat examples of diffusions with various\nboundary behavior, size-bias sampling of diffusion paths, and non-colliding\ndiffusions. A multidimensional generalization to conformal strict local\nmartingales is achieved through Kelvin transform. As curious examples of\nnon-standard behavior, we show by various examples that strict local\nmartingales do not behave uniformly when the function (x-K)^+ is applied to\nthem. Implications to the recent literature on financial bubbles are discussed.\n"
    },
    {
        "paper_id": 711.1143,
        "authors": "Kei Fukuda, Akihiko Inoue and Yumiharu Nakano",
        "title": "Optimal intertemporal risk allocation applied to insurance pricing",
        "comments": "20 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present a general approach to the pricing of products in finance and\ninsurance in the multi-period setting. It is a combination of the utility\nindifference pricing and optimal intertemporal risk allocation. We give a\ncharacterization of the optimal intertemporal risk allocation by a first order\ncondition. Applying this result to the exponential utility function, we obtain\nan essentially new type of premium calculation method for a popular type of\nmulti-period insurance contract. This method is simple and can be easily\nimplemented numerically. We see that the results of numerical calculations are\nwell coincident with the risk loading level determined by traditional\npractices. The results also suggest a possible implied utility approach to\ninsurance pricing.\n"
    },
    {
        "paper_id": 711.1272,
        "authors": "Walter Schachermayer, Josef Teichmann",
        "title": "How close are the option pricing formulas of Bachelier and\n  Black-Merton-Scholes?",
        "comments": "to appear in Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We compare the option pricing formulas of Louis Bachelier and\nBlack-Merton-Scholes and observe -- theoretically as well as for Bachelier's\noriginal data -- that the prices coincide very well. We illustrate Louis\nBachelier's efforts to obtain applicable formulas for option pricing in\npre-computer time. Furthermore we explain -- by simple methods from chaos\nexpansion -- why Bachelier's model yields good short-time approximations of\nprices and volatilities.\n"
    },
    {
        "paper_id": 711.1594,
        "authors": "Konstantinos Kalogeropoulos, Gareth O. Roberts, Petros Dellaportas",
        "title": "Inference for stochastic volatility models using time change\n  transformations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We address the problem of parameter estimation for diffusion driven\nstochastic volatility models through Markov chain Monte Carlo (MCMC). To avoid\ndegeneracy issues we introduce an innovative reparametrisation defined through\ntransformations that operate on the time scale of the diffusion. A novel MCMC\nscheme which overcomes the inherent difficulties of time change transformations\nis also presented. The algorithm is fast to implement and applies to models\nwith stochastic volatility. The methodology is tested through simulation based\nexperiments and illustrated on data consisting of US treasury bill rates.\n"
    },
    {
        "paper_id": 711.1595,
        "authors": "Konstantinos Kalogeropoulos, Petros Dellaportas, Gareth O. Roberts",
        "title": "Likelihood-based inference for correlated diffusions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We address the problem of likelihood based inference for correlated diffusion\nprocesses using Markov chain Monte Carlo (MCMC) techniques. Such a task\npresents two interesting problems. First, the construction of the MCMC scheme\nshould ensure that the correlation coefficients are updated subject to the\npositive definite constraints of the diffusion matrix. Second, a diffusion may\nonly be observed at a finite set of points and the marginal likelihood for the\nparameters based on these observations is generally not available. We overcome\nthe first issue by using the Cholesky factorisation on the diffusion matrix. To\ndeal with the likelihood unavailability, we generalise the data augmentation\nframework of Roberts and Stramer (2001 Biometrika 88(3):603-621) to\nd-dimensional correlated diffusions including multivariate stochastic\nvolatility models. Our methodology is illustrated through simulation based\nexperiments and with daily EUR /USD, GBP/USD rates together with their implied\nvolatilities.\n"
    },
    {
        "paper_id": 711.1836,
        "authors": "Pavel Exner and Petr \\v{S}eba",
        "title": "A Markov process associated with plot-size distribution in Czech Land\n  Registry and its number-theoretic properties",
        "comments": "LaTeX, 7 pages with two ps figure. A discussion of convergence added;\n  the final version to appear in J. Phys. A: Math. Theor",
        "journal-ref": "J. Phys. A: Math. Theor. 41 (2008), 045004 (7pp)",
        "doi": "10.1088/1751-8113/41/4/045004",
        "license": null,
        "abstract": "  The size distribution of land plots is a result of land allocation processes\nin the past. In the absence of regulation this is a Markov process leading an\nequilibrium described by a probabilistic equation used commonly in the\ninsurance and financial mathematics. We support this claim by analyzing the\ndistribution of two plot types, garden and build-up areas, in the Czech Land\nRegistry pointing out the coincidence with the distribution of prime number\nfactors described by Dickman function in the first case.\n"
    },
    {
        "paper_id": 711.255,
        "authors": "Jeferson de Souza, Silvio M. Duarte Queiros",
        "title": "Effective multifractal features and l-variability diagrams of\n  high-frequency price fluctuations time series",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this manuscript we present a comprehensive study on the multifractal\nproperties of high-frequency price fluctuations and instantaneous volatility of\nthe equities that compose Dow Jones Industrial Average. The analysis consists\nabout quantification of dependence and non-Gaussianity on the multifractal\ncharacter of financial quantities. Our results point out an equivalent\ninfluence of dependence and non-Gaussianity on the multifractality of time\nseries. Moreover, we analyse l-diagrams of price fluctuations. In the latter\ncase, we show that the fractal dimension of these maps is basically independent\nof the lag between price fluctuations that we assume.\n"
    },
    {
        "paper_id": 711.2624,
        "authors": "Miquel Montero",
        "title": "Renewal equations for option pricing",
        "comments": "19 pages, 5 figures, svjour (epj); Enlarged and revised version, two\n  new figures in a new subsection, and a new appendix added",
        "journal-ref": "Eur. Phys. J. B 65, 295-306 (2008)",
        "doi": "10.1140/epjb/e2008-00349-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we will develop a methodology for obtaining pricing expressions\nfor financial instruments whose underlying asset can be described through a\nsimple continuous-time random walk (CTRW) market model. Our approach is very\nnatural to the issue because it is based in the use of renewal equations, and\ntherefore it enhances the potential use of CTRW techniques in finance. We solve\nthese equations for typical contract specifications, in a particular but\nexemplifying case. We also show how a formal general solution can be found for\nmore exotic derivatives, and we compare prices for alternative models of the\nunderlying. Finally, we recover the celebrated results for the Wiener process\nunder certain limits.\n"
    },
    {
        "paper_id": 711.2718,
        "authors": "Mayank Goel, K. Suresh Kumar",
        "title": "A Risk-Sensitive Portfolio Optimization Problem with Fixed Incomes\n  Securities",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We discuss a class of risk-sensitive portfolio optimization problems. We\nconsider the portfolio optimization model investigated by Nagai in 2003. The\nmodel by its nature can include fixed income securities as well in the\nportfolio. Under fairly general conditions, we prove the existence of optimal\nportfolio in both finite and infinite horizon problems.\n"
    },
    {
        "paper_id": 711.2807,
        "authors": "Soeren Asmussen, Dilip Madan, Martijn Pistorius",
        "title": "Pricing Equity Default Swaps under an approximation to the CGMY L\\'{e}%\n  vy Model",
        "comments": "Accepted for publication in J. Comp. Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Wiener-Hopf factorization is obtained in closed form for a phase type\napproximation to the CGMY L\\'{e}vy process. This allows, for the approximation,\nexact computation of first passage times to barrier levels via Laplace\ntransform inversion. Calibration of the CGMY model to market option prices\ndefines the risk neutral process for which we infer the first passage times of\nstock prices to 30% of the price level at contract initiation. These\ndistributions are then used in pricing 50% recovery rate equity default swap\n(EDS) contracts and the resulting prices are compared with the prices of credit\ndefault swaps (CDS). An illustrative analysis is presented for these contracts\non Ford and GM.\n"
    },
    {
        "paper_id": 711.3106,
        "authors": "Pawe{\\l} Sieczka and Janusz A. Ho{\\l}yst",
        "title": "A threshold model of financial markets",
        "comments": null,
        "journal-ref": "Acta Physica Polonica A 114 (3): 458-648 (2008)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We proposed a model of interacting market agents based on the Ising spin\nmodel. The agents can take three actions: \"buy,\" \"sell,\" or \"stay inactive.\" We\ndefined a price evolution in terms of the system magnetization. The model\nreproduces main stylized facts of real markets such as: fat-tailed distribution\nof returns and volatility clustering.\n"
    },
    {
        "paper_id": 711.3581,
        "authors": "Carl Chiarella, Giulia Iori, Josep Perello",
        "title": "The Impact of Heterogeneous Trading Rules on the Limit Order Book and\n  Order Flows",
        "comments": "15 pages, 11 figures",
        "journal-ref": "Journal of Economic Dynamics and Control 33, 525 (2009)",
        "doi": "10.1016/j.jedc.2008.08.001",
        "license": null,
        "abstract": "  In this paper we develop a model of an order-driven market where traders set\nbids and asks and post market or limit orders according to exogenously fixed\nrules. Agents are assumed to have three components to the expectation of future\nasset returns, namely-fundamentalist, chartist and noise trader. Furthermore\nagents differ in the characteristics describing these components, such as time\nhorizon, risk aversion and the weights given to the various components. The\nmodel developed here extends a great deal of earlier literature in that the\norder submissions of agents are determined by utility maximisation, rather than\nthe mechanical unit order size that is commonly assumed. In this way the order\nflow is better related to the ongoing evolution of the market. For the given\nmarket structure we analyze the impact of the three components of the trading\nstrategies on the statistical properties of prices and order flows and observe\nthat it is the chartist strategy that is mainly responsible of the fat tails\nand clustering in the artificial price data generated by the model. The paper\nprovides further evidence that large price changes are likely to be generated\nby the presence of large gaps in the book.\n"
    },
    {
        "paper_id": 711.3909,
        "authors": "Carmen Costea",
        "title": "Application of Tuncay's language teacher model to business-customer\n  relations",
        "comments": "5 pages, no figures, to be published in Int. J. Mod. Phys. C",
        "journal-ref": null,
        "doi": "10.1142/S0129183108012054",
        "license": null,
        "abstract": "  It seems that what has been said by now about market and competitiveness do\nnot fit perfectly with competences of getting the best of profit. Sometimes,\nthe classical methods of fundamentals of management do not apply to individual\ncompanies that face irregular accommodation on the market. It is high time to\nreplace the perfect business with the right one. New approaches and models may\nhelp in identifying new competition trends, changes for better application of\npurposes and proposals.\n"
    },
    {
        "paper_id": 711.4225,
        "authors": "Tom Fischer",
        "title": "Consumption processes and positively homogeneous projection properties",
        "comments": "24 pages, 2 figures",
        "journal-ref": "Fischer, T., 2008. Consumption processes and positively\n  homogeneous projection properties. Finance & Stochastics 12 (3), 357-380",
        "doi": "10.1007/s00780-008-0064-x",
        "license": null,
        "abstract": "  We constructively prove the existence of time-discrete consumption processes\nfor stochastic money accounts that fulfill a pre-specified positively\nhomogeneous projection property (PHPP) and let the account always be positive\nand exactly zero at the end. One possible example is consumption rates forming\na martingale under the above restrictions. For finite spaces, it is shown that\nany strictly positive consumption strategy with restrictions as above possesses\nat least one corresponding PHPP and could be constructed from it. We also\nconsider numeric examples under time-discrete and -continuous account\nprocesses, cases with infinite time horizons and applications to income\ndrawdown and bonus theory.\n"
    },
    {
        "paper_id": 711.4596,
        "authors": "Gabriele La Spada, J. Doyne Farmer and Fabrizio Lillo",
        "title": "The non-random walk of stock prices: The long-term correlation between\n  signs and sizes",
        "comments": "9 pages, 5 figures, StatPhys23",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00244-4",
        "license": null,
        "abstract": "  We investigate the random walk of prices by developing a simple model\nrelating the properties of the signs and absolute values of individual price\nchanges to the diffusion rate (volatility) of prices at longer time scales. We\nshow that this benchmark model is unable to reproduce the diffusion properties\nof real prices. Specifically, we find that for one hour intervals this model\nconsistently over-predicts the volatility of real price series by about 70%,\nand that this effect becomes stronger as the length of the intervals increases.\nBy selectively shuffling some components of the data while preserving others we\nare able to show that this discrepancy is caused by a subtle but long-range\nnon-contemporaneous correlation between the signs and sizes of individual\nreturns. We conjecture that this is related to the long-memory of transaction\nsigns and the need to enforce market efficiency.\n"
    },
    {
        "paper_id": 711.471,
        "authors": "Diego Garlaschelli, Maria I. Loffredo",
        "title": "Effects of network topology on wealth distributions",
        "comments": "References added",
        "journal-ref": "J. Phys. A: Math. Theor. 41, 224018 (2008)",
        "doi": "10.1088/1751-8113/41/22/224018",
        "license": null,
        "abstract": "  We focus on the problem of how wealth is distributed among the units of a\nnetworked economic system. We first review the empirical results documenting\nthat in many economies the wealth distribution is described by a combination of\nlog--normal and power--law behaviours. We then focus on the Bouchaud--M\\'ezard\nmodel of wealth exchange, describing an economy of interacting agents connected\nthrough an exchange network. We report analytical and numerical results showing\nthat the system self--organises towards a stationary state whose associated\nwealth distribution depends crucially on the underlying interaction network. In\nparticular we show that if the network displays a homogeneous density of links,\nthe wealth distribution displays either the log--normal or the power--law form.\nThis means that the first--order topological properties alone (such as the\nscale--free property) are not enough to explain the emergence of the\nempirically observed \\emph{mixed} form of the wealth distribution. In order to\nreproduce this nontrivial pattern, the network has to be heterogeneously\ndivided into regions with variable density of links. We show new results\ndetailing how this effect is related to the higher--order correlation\nproperties of the underlying network. In particular, we analyse assortativity\nby degree and the pairwise wealth correlations, and discuss the effects that\nthese properties have on each other.\n"
    },
    {
        "paper_id": 712.0083,
        "authors": "Petr Jizba and Hagen Kleinert",
        "title": "Smearing Distributions and their use in Financial Markets",
        "comments": "6 pages. Presented at the International Conference: Path Integrals -\n  New Trends and Perspectives, Dresden, Germany, September 23 - 28, 2007",
        "journal-ref": null,
        "doi": "10.1142/9789812837271_0089",
        "license": null,
        "abstract": "  It is shown that superpositions of path integrals with arbitrary Hamiltonians\nand different scaling parameters v (\"variances\") obey the Chapman-Kolmogorov\nrelation for Markovian processes if and only if the corresponding smearing\ndistributions for v have a specific functional form. Ensuing \"smearing\"\ndistributions substantially simplify the coupled system of Fokker-Planck\nequations for smeared and un-smeared conditional probabilities. Simple\napplication in financial models with stochastic volatility is presented.\n"
    },
    {
        "paper_id": 712.0337,
        "authors": "Tobias Galla, Andrea De Martino",
        "title": "On the transition to efficiency in Minority Games",
        "comments": "12 pages, 3 figures; contribution to the special issue \"Viewing the\n  World through Spin Glasses\" in honour of David Sherrington on the occasion of\n  his 65th birthday",
        "journal-ref": null,
        "doi": "10.1088/1751-8113/41/32/324003",
        "license": null,
        "abstract": "  The existence of a phase transition with diverging susceptibility in batch\nMinority Games (MGs) is the mark of informationally efficient regimes and is\nlinked to the specifics of the agents' learning rules. Here we study how the\nstandard scenario is affected in a mixed population game in which agents with\nthe `optimal' learning rule (i.e. the one leading to efficiency) coexist with\nones whose adaptive dynamics is sub-optimal. Our generic finding is that any\nnon-vanishing intensive fraction of optimal agents guarantees the existence of\nan efficient phase. Specifically, we calculate the dependence of the critical\npoint on the fraction $q$ of `optimal' agents focusing our analysis on three\ncases: MGs with market impact correction, grand-canonical MGs and MGs with\nheterogeneous comfort levels.\n"
    },
    {
        "paper_id": 712.0912,
        "authors": "Gao-Feng Gu (ECUST), Wei Chen (SZSE), Wei-Xing Zhou (ECUST)",
        "title": "Empirical regularities of order placement in the Chinese stock market",
        "comments": "15 Elsart page including 1 table and 5 figures",
        "journal-ref": "Physica A 387 (13), 3173-3182 (2008)",
        "doi": "10.1016/j.physa.2008.01.114",
        "license": null,
        "abstract": "  Using ultra-high-frequency data extracted from the order flows of 23 stocks\ntraded on the Shenzhen Stock Exchange, we study the empirical regularities of\norder placement in the opening call auction, cool period and continuous\nauction. The distributions of relative logarithmic prices against reference\nprices in the three time periods are qualitatively the same with quantitative\ndiscrepancies. The order placement behavior is asymmetric between buyers and\nsellers and between the inside-the-book orders and outside-the-book orders. In\naddition, the conditional distributions of relative prices in the continuous\nauction are independent of the bid-ask spread and volatility. These findings\nare crucial to build an empirical behavioral microscopic model based on order\nflows for Chinese stocks.\n"
    },
    {
        "paper_id": 712.1093,
        "authors": "Jungmin Choi and Kyounghee Kim",
        "title": "The derivatives of Asian call option prices",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The distribution of a time integral of geometric Brownian motion is not well\nunderstood. To price an Asian option and to obtain measures of its dependence\non the parameters of time, strike price, and underlying market price, it is\nessential to have the distribution of time integral of geometric Brownian\nmotion and it is also required to have a way to manipulate its distribution. We\npresent integral forms for key quantities in the price of Asian option and its\nderivatives ({\\it{delta, gamma,theta, and vega}}). For example for any $a>0$\n$\\mathbb{E} [ (A_t -a)^+] = t -a + a^{2} \\mathbb{E} [ (a+A_t)^{-1} \\exp\n(\\frac{2M_t}{a+ A_t} - \\frac{2}{a}) ]$, where $A_t = \\int^t_0 \\exp (B_s -s/2)\nds$ and $M_t =\\exp (B_t -t/2).$\n"
    },
    {
        "paper_id": 712.1275,
        "authors": "Vladimir Vovk",
        "title": "Continuous-time trading and emergence of randomness",
        "comments": "14 pages; this version: new references and minor corrections",
        "journal-ref": "Stochastics 81, 455 - 466 (2009)",
        "doi": "10.1080/17442500802221712",
        "license": null,
        "abstract": "  A new definition of events of game-theoretic probability zero in continuous\ntime is proposed and used to prove results suggesting that trading in financial\nmarkets results in the emergence of properties usually associated with\nrandomness. This paper concentrates on \"qualitative\" results, stated in terms\nof order (or order topology) rather than in terms of the precise values taken\nby the price processes (assumed continuous).\n"
    },
    {
        "paper_id": 712.1343,
        "authors": "A. Brace, G. Fabbri, B. Goldys",
        "title": "An Hilbert space approach for a class of arbitrage free implied\n  volatilities models",
        "comments": "21 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present an Hilbert space formulation for a set of implied volatility\nmodels introduced in \\cite{BraceGoldys01} in which the authors studied\nconditions for a family of European call options, varying the maturing time and\nthe strike price $T$ an $K$, to be arbitrage free. The arbitrage free\nconditions give a system of stochastic PDEs for the evolution of the implied\nvolatility surface ${\\hat\\sigma}_t(T,K)$. We will focus on the family obtained\nfixing a strike $K$ and varying $T$. In order to give conditions to prove an\nexistence-and-uniqueness result for the solution of the system it is here\nexpressed in terms of the square root of the forward implied volatility and\nrewritten in an Hilbert space setting. The existence and the uniqueness for the\n(arbitrage free) evolution of the forward implied volatility, and then of the\nthe implied volatility, among a class of models, are proved. Specific examples\nare also given.\n"
    },
    {
        "paper_id": 712.1483,
        "authors": "Vladimir Vovk",
        "title": "Continuous-time trading and emergence of volatility",
        "comments": "7 pages; v2: new title and minor corrections",
        "journal-ref": "Electronic Communications in Probability 13, 319 - 324 (2008)",
        "doi": null,
        "license": null,
        "abstract": "  This note continues investigation of randomness-type properties emerging in\nidealized financial markets with continuous price processes. It is shown,\nwithout making any probabilistic assumptions, that the strong variation\nexponent of non-constant price processes has to be 2, as in the case of\ncontinuous martingales.\n"
    },
    {
        "paper_id": 712.1624,
        "authors": "Cheoljun Eom, Sunghoon Choi, Gabjin Oh, Woo-Sung Jung",
        "title": "Hurst exponent and prediction based on weak-form efficient market\n  hypothesis of stock markets",
        "comments": "11 pages",
        "journal-ref": "Physica A 387(18), 4630-4636 (2008)",
        "doi": "10.1016/j.physa.2008.03.035",
        "license": null,
        "abstract": "  We empirically investigated the relationships between the degree of\nefficiency and the predictability in financial time-series data. The Hurst\nexponent was used as the measurement of the degree of efficiency, and the hit\nrate calculated from the nearest-neighbor prediction method was used for the\nprediction of the directions of future price changes. We used 60 market indexes\nof various countries. We empirically discovered that the relationship between\nthe degree of efficiency (the Hurst exponent) and the predictability (the hit\nrate) is strongly positive. That is, a market index with a higher Hurst\nexponent tends to have a higher hit rate. These results suggested that the\nHurst exponent is useful for predicting future price changes. Furthermore, we\nalso discovered that the Hurst exponent and the hit rate are useful as\nstandards that can distinguish emerging capital markets from mature capital\nmarkets.\n"
    },
    {
        "paper_id": 712.2088,
        "authors": "Byron E. Bell",
        "title": "Financial Variables Effect on the U.S. Gross Private Domestic Investment\n  (GPDI) 1959-2001",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  I studied what role the US stock markets and money markets have possibly\nplayed in the Gross Private Domestic Investment (GPDI) of the United States\nfrom the year 1959 to the year 2001, Gross Private Domestic Investment refers\nto the total amount of investment spending by businesses and firms located\nwithin the borders of a nation. It includes both the values of the purchases of\nnon-residential fixed investment, which include capital goods used for\nproduction, and the values of the purchases of residential fixed investment,\nwhich include construction spending for factories or offices. And I created a\nMultiple Linear Regression Model of the GDPI. To see if companies and private\ncitizens use the stock market and money markets as a way of financing capital\nprojects (business ventures, buying commercial and noncommercial property,\netc).\n  Keywords: Gross Private Domestic Investment, Pearson Correlation, SP 500, TB3\n"
    },
    {
        "paper_id": 712.222,
        "authors": "James P. Bagrow, Jie Sun, Daniel ben-Avraham",
        "title": "Phase transition in the rich-get-richer mechanism due to finite-size\n  effects",
        "comments": "9 pages, 1 figure, code and data included with source. Update\n  corrects typos, adds journal-ref",
        "journal-ref": "J. Phys. A: Math. Theor. 41 (2008) 185001",
        "doi": "10.1088/1751-8113/41/18/185001",
        "license": null,
        "abstract": "  The rich-get-richer mechanism (agents increase their ``wealth'' randomly at a\nrate proportional to their holdings) is often invoked to explain the Pareto\npower-law distribution observed in many physical situations, such as the degree\ndistribution of growing scale free nets. We use two different analytical\napproaches, as well as numerical simulations, to study the case where the\nnumber of agents is fixed and finite (but large), and the rich-get-richer\nmechanism is invoked a fraction r of the time (the remainder of the time wealth\nis disbursed by a homogeneous process). At short times, we recover the Pareto\nlaw observed for an unbounded number of agents. In later times, the (moving)\ndistribution can be scaled to reveal a phase transition with a Gaussian\nasymptotic form for r < 1/2 and a Pareto-like tail (on the positive side) and a\nnovel stretched exponential decay (on the negative side) for r > 1/2.\n"
    },
    {
        "paper_id": 712.2684,
        "authors": "R. Lopez-Ruiz, J. Gonzalez-Estevez, M.G. Cosenza, and J.R. Sanchez",
        "title": "An Economic Model of Coupled Exponential Maps",
        "comments": "3 pages, 1 figure ; Presented at NOMA'07 Conference, December 2007,\n  Toulouse (France)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this work, an ensemble of economic interacting agents is considered. The\nagents are arranged in a linear array where only local couplings are allowed.\nThe deterministic dynamics of each agent is given by a map. This map is\nexpressed by two factors. The first one is a linear term that models the\nexpansion of the agent's economy and that is controlled by the {\\it growth\ncapacity parameter}. The second one is an inhibition exponential term that is\nregulated by the {\\it local environmental pressure}. Depending on the parameter\nsetting, the system can display Pareto or Boltzmann-Gibbs behavior in the\nasymptotic dynamical regime. The regions of parameter space where the system\nexhibits one of these two statistical behaviors are delimited. Other properties\nof the system, such as the mean wealth, the standard deviation and the Gini\ncoefficient, are also calculated.\n"
    },
    {
        "paper_id": 712.2687,
        "authors": "Bence Toth, Enrico Scalas",
        "title": "The value of information in financial markets: An agent-based simulation",
        "comments": "25 pages, 7 figures invited paper to \"Information, Interaction, and\n  (In)Efficiency in Financial Markets\" edited by Juergen Huber and Michael\n  Hanke",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present results on simulations of a stock market with heterogeneous,\ncumulative information setup. We find a non-monotonic behaviour of traders'\nreturns as a function of their information level. Particularly, the average\ninformed agents underperform random traders; only the most informed agents are\nable to beat the market. We also study the effect of a strategy updating\nmechanism, when traders have the possibility of using other pieces of\ninformation than the fundamental value. These results corroborate the latter\nones: it is only for the most informed player that it is rewarding to stay\nfundamentalist. The simulations reproduce some stylized facts of tick-by-tick\nstock-exchange data and globally show informational efficiency.\n"
    },
    {
        "paper_id": 712.2771,
        "authors": "Paolo Laureti, Matus Medo, Yi-Cheng Zhang",
        "title": "Analysis of Kelly-optimal portfolios",
        "comments": "15 pages, 7 figures; extended list of references and some minor\n  modifications",
        "journal-ref": "Quantitative Finance 10, 689-697 (2010)",
        "doi": "10.1080/14697680902991619",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the use of Kelly's strategy in the construction of an optimal\nportfolio of assets. For lognormally distributed asset returns, we derive\napproximate analytical results for the optimal investment fractions in various\nsettings. We show that when mean returns and volatilities of the assets are\nsmall and there is no risk-free asset, the Kelly-optimal portfolio lies on\nMarkowitz Efficient Frontier. Since in the investigated case the Kelly approach\nforbids short positions and borrowing, often only a small fraction of the\navailable assets is included in the Kelly-optimal portfolio. This phenomenon,\nthat we call condensation, is studied analytically in various model scenarios.\n"
    },
    {
        "paper_id": 712.291,
        "authors": "M. Bartolozzi, C. Mellen, F. Chan, D. Oliver, T. Di Matteo, T. Aste",
        "title": "Applications of physical methods in high-frequency futures markets",
        "comments": "14 Pages and 10 figures. Proceeding to the SPIE conference, 4 - 7\n  December 2007 Australian National Univ. Canberra, ACT, Australia",
        "journal-ref": null,
        "doi": "10.1117/12.758431",
        "license": null,
        "abstract": "  In the present work we demonstrate the application of different physical\nmethods to high-frequency or tick-by-tick financial time series data. In\nparticular, we calculate the Hurst exponent and inverse statistics for the\nprice time series taken from a range of futures indices. Additionally, we show\nthat in a limit order book the relaxation times of an imbalanced book state\nwith more demand or supply can be described by stretched exponential laws\nanalogous to those seen in many physical systems.\n"
    },
    {
        "paper_id": 712.335,
        "authors": "Matus Medo, Yi-Cheng Zhang",
        "title": "Market Model with Heterogeneous Buyers",
        "comments": "26 pages, 15 figures, accepted to Physica A",
        "journal-ref": "Physica A 387, 2889-2908 (2008)",
        "doi": "10.1016/j.physa.2008.01.008",
        "license": null,
        "abstract": "  In market modeling, one often treats buyers as a homogeneous group. In this\npaper we consider buyers with heterogeneous preferences and products available\nin many variants. Such a framework allows us to successfully model various\nmarket phenomena. In particular, we investigate how is the vendor's behavior\ninfluenced by the amount of available information and by the presence of\ncorrelations in the system.\n"
    },
    {
        "paper_id": 712.3363,
        "authors": "Dirk Tasche",
        "title": "Incorporating exchange rate risk into PDs and asset correlations",
        "comments": "7 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Intuitively, the default risk of a single borrower is higher when her or his\nassets and debt are denominated in different currencies. Additionally, the\ndefault dependence of borrowers with assets and debt in different currencies\nshould be stronger than in the one-currency case. By combining well-known\nmodels by Merton (1974), Garman and Kohlhagen (1983), and Vasicek (2002) we\ndevelop simple representations of PDs and asset correlations that take into\naccount exchange rate risk. From these results, consistency conditions can be\nderived that link the changes in PD and asset correlation and do not require\nknowledge of hard-to-estimate parameters like asset value volatility.\n"
    },
    {
        "paper_id": 712.3428,
        "authors": "Nikita Ratanov, Alexander Melnikov",
        "title": "On Financial Markets Based on Telegraph Processes",
        "comments": "To appear in a Special Volume of Stochastics: An International\n  Journal of Probability and Stochastic Processes\n  (http://www.informaworld.com/openurl?genre=journal%26issn=1744-2508) edited\n  by N.H. Bingham and I.V. Evstigneev which will be reprinted as Volume 57 of\n  the IMS Lecture Notes Monograph Series\n  (http://imstat.org/publications/lecnotes.htm)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The paper develops a new class of financial market models. These models are\nbased on generalized telegraph processes: Markov random flows with alternating\nvelocities and jumps occurring when the velocities are switching. While such\nmarkets may admit an arbitrage opportunity, the model under consideration is\narbitrage-free and complete if directions of jumps in stock prices are in a\ncertain correspondence with their velocity and interest rate behaviour. An\nanalog of the Black-Scholes fundamental differential equation is derived, but,\nin contrast with the Black-Scholes model, this equation is hyperbolic. Explicit\nformulas for prices of European options are obtained using perfect and quantile\nhedging.\n"
    },
    {
        "paper_id": 712.3485,
        "authors": "Eric Benhamou (LJK), Emmanuel Gobet (LJK), Mohammed Miri (LJK)",
        "title": "Smart expansion and fast calibration for jump diffusion",
        "comments": "in Finance and Stochastics (2009) a paraitre",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using Malliavin calculus techniques, we derive an analytical formula for the\nprice of European options, for any model including local volatility and Poisson\njump process. We show that the accuracy of the formula depends on the\nsmoothness of the payoff function. Our approach relies on an asymptotic\nexpansion related to small diffusion and small jump frequency/size. Our formula\nhas excellent accuracy (the error on implied Black-Scholes volatilities for\ncall option is smaller than 2 bp for various strikes and maturities).\nAdditionally, model calibration becomes very rapid.\n"
    },
    {
        "paper_id": 712.3537,
        "authors": "Gr\\'egory Benmenzer (LJK), Emmanuel Gobet (LJK), C\\'eline J\\'erusalem\n  (LJK)",
        "title": "Arbitrage free cointegrated models in gas and oil future markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this article we present a continuous time model for natural gas and crude\noil future prices. Its main feature is the possibility to link both energies in\nthe long term and in the short term. For each energy, the future returns are\nrepresented as the sum of volatility functions driven by motions. Under the\nrisk neutral probability, the motions of both energies are correlated Brownian\nmotions while under the historical probability, they are cointegrated by a\nVectorial Error Correction Model. Our approach is equivalent to defining the\nmarket price of risk. This model is free of arbitrage: thus, it can be used for\nrisk management as well for option pricing issues. Calibration on European\nmarket data and numerical simulations illustrate well its behavior.\n"
    },
    {
        "paper_id": 712.3611,
        "authors": "F. Ghoulmi\\'e, M. Bartolozzi, C.P. Mellen, T. Di Matteo",
        "title": "Effects of diversification among assets in an agent-based market model",
        "comments": "12 pages, 5 figures, accepted for publication in the Proceedings of\n  the Complex Systems II Conference at the Australian National University, 4-7\n  December 2007, Canberra, ACT Australia",
        "journal-ref": null,
        "doi": "10.1117/12.758912",
        "license": null,
        "abstract": "  We extend to the multi-asset case the framework of a discrete time model of a\nsingle asset financial market developed in Ghoulmie et al (2005). In\nparticular, we focus on adaptive agents with threshold behavior allocating\ntheir resources among two assets. We explore numerically the effect of this\ndiversification as an additional source of complexity in the financial market\nand we discuss its destabilizing role. We also point out the relevance of these\nstudies for financial decision making.\n"
    },
    {
        "paper_id": 712.3746,
        "authors": "Stefan Ankirchner, Peter Imkeller, Goncalo dos Reis",
        "title": "Pricing and hedging of derivatives based on non-tradable underlyings",
        "comments": null,
        "journal-ref": "Mathematical Finance, 2010, 20, 289 - 312",
        "doi": "10.1111/j.1467-9965.2010.00398.x",
        "license": null,
        "abstract": "  This paper is concerned with the study of insurance related derivatives on\nfinancial markets that are based on non-tradable underlyings, but are\ncorrelated with tradable assets. We calculate exponential utility-based\nindifference prices, and corresponding derivative hedges. We use the fact that\nthey can be represented in terms of solutions of forward-backward stochastic\ndifferential equations (FBSDE) with quadratic growth generators. We derive the\nMarkov property of such FBSDE and generalize results on the differentiability\nrelative to the initial value of their forward components. In this case the\noptimal hedge can be represented by the price gradient multiplied with the\ncorrelation coefficient. This way we obtain a generalization of the classical\n'delta hedge' in complete markets.\n"
    },
    {
        "paper_id": 712.3992,
        "authors": "Bikas K. Chakrabarti, Arnab Chatterjee, Pratip Bhattacharyya",
        "title": "Two Fractal Overlap Time Series: Earthquakes and Market Crashes",
        "comments": "2 column RevTeX4, 4 pages, 5 eps figures; Published in \"Econophysics\n  of Stock and Other Markets\", Eds. A. Chatterjee, B. K. Chakrabarti, New\n  Economic Windows Series, Springer, Milan (2006); Sec V and 2 refs added new\n  in this arXiv version",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We find prominent similarities in the features of the time series for the\n(model earthquakes or) overlap of two Cantor sets when one set moves with\nuniform relative velocity over the other and time series of stock prices. An\nanticipation method for some of the crashes have been proposed here, based on\nthese observations.\n"
    },
    {
        "paper_id": 801.0003,
        "authors": "Gunter M. Sch\\\"utz, Fernando Pigeard de Almeida Prado, Rosemary J.\n  Harris, Vladimir Belitsky",
        "title": "Short-time behaviour of demand and price viewed through an exactly\n  solvable model for heterogeneous interacting market agents",
        "comments": "26 pages, 3 figures. v2: minor alterations, to appear in Physica A\n  (http://www.elsevier.com/wps/find/journaldescription.cws_home/505702/description#description)",
        "journal-ref": "Physica A 388 (2009) 4126-4144",
        "doi": "10.1016/j.physa.2009.06.025",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a stochastic heterogeneous interacting-agent model for the\nshort-time non-equilibrium evolution of excess demand and price in a stylized\nasset market. We consider a combination of social interaction within peer\ngroups and individually heterogeneous fundamentalist trading decisions which\ntake into account the market price and the perceived fundamental value of the\nasset. The resulting excess demand is coupled to the market price. Rigorous\nanalysis reveals that this feedback may lead to price oscillations, a single\nbounce, or monotonic price behaviour. The model is a rare example of an\nanalytically tractable interacting-agent model which allows us to deduce in\ndetail the origin of these different collective patterns. For a natural choice\nof initial distribution the results are independent of the graph structure that\nmodels the peer network of agents whose decisions influence each other.\n"
    },
    {
        "paper_id": 801.0108,
        "authors": "Shi-Mei Jiang, Shi-Min Cai, Tao Zhou, and Pei-Ling Zhou",
        "title": "Note on two phase phenomena in financial markets",
        "comments": "8 pages and 5 figures",
        "journal-ref": "Chin. Phys. Lett. 25 (2008) 2319",
        "doi": "10.1088/0256-307X/25/6/108",
        "license": null,
        "abstract": "  The two phase behavior in financial markets actually means the bifurcation\nphenomenon, which represents the change of the conditional probability from an\nunimodal to a bimodal distribution. In this paper, the bifurcation phenomenon\nin Hang-Seng index is carefully investigated. It is observed that the\nbifurcation phenomenon in financial index is not universal, but specific under\ncertain conditions. The phenomenon just emerges when the power-law exponent of\nabsolute increment distribution is between 1 and 2 with appropriate period.\nSimulations on a randomly generated time series suggest the bifurcation\nphenomenon itself is subject to the statistics of absolute increment, thus it\nmay not be able to reflect the essential financial behaviors. However, even\nunder the same distribution of absolute increment, the range where bifurcation\nphenomenon occurs is far different from real market to artificial data, which\nmay reflect certain market information.\n"
    },
    {
        "paper_id": 801.0195,
        "authors": "Masahiko Egami, Hideki Iwaki",
        "title": "An optimal life insurance policy in the investment-consumption problem\n  in an incomplete market",
        "comments": "This paper has been withdrawn by the authors",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper considers an optimal life insurance for a householder subject to\nmortality risk. The household receives a wage income continuously, which is\nterminated by unexpected (premature) loss of earning power or (planned and\nintended) retirement, whichever happens first. In order to hedge the risk of\nlosing income stream by householder's unpredictable event, the household enters\na life insurance contract by paying a premium to an insurance company. The\nhousehold may also invest their wealth into a financial market. The problem is\nto determine an optimal insurance/investment/consumption strategy in order to\nmaximize the expected total, discounted utility from consumption and terminal\nwealth. To reflect a real-life situation better, we consider an incomplete\nmarket where the householder cannot trade insurance contracts continuously. To\nour best knowledge, such a model is new in the insurance and finance\nliterature. The case of exponential utilities is considered in detail to derive\nan explicit solution. We also provide numerical experiments for that particular\ncase to illustrate our results.\n"
    },
    {
        "paper_id": 801.0631,
        "authors": "Frantisek Slanina",
        "title": "Critical comparison of several order-book models for stock-market\n  fluctuations",
        "comments": "17 pages, 26 figures, accepted in Eur. Phys. J. B",
        "journal-ref": "Eur. Phys. J. B 61, 225-240 (2008)",
        "doi": "10.1140/epjb/e2008-00059-3",
        "license": null,
        "abstract": "  Far-from-equilibrium models of interacting particles in one dimension are\nused as a basis for modelling the stock-market fluctuations. Particle types and\ntheir positions are interpreted as buy and sell orders placed on a price axis\nin the order book. We revisit some modifications of well-known models, starting\nwith the Bak-Paczuski-Shubik model. We look at the four decades old Stigler\nmodel and investigate its variants. One of them is the simplified version of\nthe Genoa artificial market. The list of studied models is completed by the\nmodels of Maslov and Daniels et al. Generically, in all cases we compare the\nreturn distribution, absolute return autocorrelation and the value of the Hurst\nexponent. It turns out that none of the models reproduces satisfactorily all\nthe empirical data, but the most promising candidates for further development\nare the Genoa artificial market and the Maslov model with moderate order\nevaporation.\n"
    },
    {
        "paper_id": 801.0718,
        "authors": "Erhan Bayraktar, Hasanjan Sayit",
        "title": "On the Stickiness Property",
        "comments": "Key words: Transaction costs. No Arbitrage. Sticky processes. Time\n  change",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In [2] the notion of stickiness for stochastic processes was introduced. It\nwas also shown that stickiness implies absense of arbitrage in a market with\nproportional transaction costs. In this paper, we investigate the notion of\nstickiness further. In particular, we give examples of processes that are not\nsemimartingales but are sticky.\n"
    },
    {
        "paper_id": 801.0748,
        "authors": "N. Basalto, R. Bellotti, F. De Carlo, P. Facchi, E. Pantaleo, S.\n  Pascazio",
        "title": "Hausdorff clustering",
        "comments": "12 pages, 13 figures",
        "journal-ref": "Phys. Rev. E 78, 046112 (2008)",
        "doi": "10.1103/PhysRevE.78.046112",
        "license": null,
        "abstract": "  A clustering algorithm based on the Hausdorff distance is introduced and\ncompared to the single and complete linkage. The three clustering procedures\nare applied to a toy example and to the time series of financial data. The\ndendrograms are scrutinized and their features confronted. The Hausdorff\nlinkage relies of firm mathematical grounds and turns out to be very effective\nwhen one has to discriminate among complex structures.\n"
    },
    {
        "paper_id": 801.0969,
        "authors": "J. Gonzalez-Estevez, M. G. Cosenza, R. Lopez-Ruiz, and J. R. Sanchez",
        "title": "Pareto and Boltzmann-Gibbs behaviors in a deterministic multi-agent\n  system",
        "comments": "9 pages, 9 color .eps figures, submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.03.013",
        "license": null,
        "abstract": "  A deterministic system of interacting agents is considered as a model for\neconomic dynamics. The dynamics of the system is described by a coupled map\nlattice with near neighbor interactions. The evolution of each agent results\nfrom the competition between two factors: the agent's own tendency to grow and\nthe environmental influence that moderates this growth. Depending on the values\nof the parameters that control these factors, the system can display Pareto or\nBoltzmann-Gibbs statistical behaviors in its asymptotic dynamical regime. The\nregions where these behaviors appear are calculated on the space of parameters\nof the system. Other statistical properties, such as the mean wealth, the\nstandard deviation, and the Gini coefficient characterizing the degree of\nequity in the wealth distribution are also calculated on the space of\nparameters of the system.\n"
    },
    {
        "paper_id": 801.1475,
        "authors": "Gabjin Oh, Cheoljun Eom, Shlomo Havlin, Woo-Sung Jung, Fengzhong Wang,\n  H. Eugene Stanley, Seunghwan Kim",
        "title": "A Multifractal Analysis of Asian Foreign Exchange Markets",
        "comments": null,
        "journal-ref": "Eur. Phys. J. B (2012) 85: 214",
        "doi": "10.1140/epjb/e2012-20570-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the multifractal spectra of daily foreign exchange rates for\nJapan, Hong-Kong, Korea, and Thailand with respect to the United States Dollar\nfrom 1991 to 2005. We find that the return time series show multifractal\nspectrum features for all four cases. To observe the effect of the Asian\ncurrency crisis, we also estimate the multifractal spectra of limited series\nbefore and after the crisis. We find that the Korean and Thai foreign exchange\nmarkets experienced a significant increase in multifractality compared to\nHong-Kong and Japan. We also show that the multifractality is stronge related\nto the presence of high values of returns in the series.\n"
    },
    {
        "paper_id": 801.1599,
        "authors": "Zhibiao Zhao",
        "title": "Parametric and nonparametric models and methods in financial\n  econometrics",
        "comments": "Published in at http://dx.doi.org/10.1214/08-SS034 the Statistics\n  Surveys (http://www.i-journals.org/ss/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)",
        "journal-ref": "Statistics Surveys 2008, Vol. 2, 1-42",
        "doi": "10.1214/08-SS034",
        "license": null,
        "abstract": "  Financial econometrics has become an increasingly popular research field. In\nthis paper we review a few parametric and nonparametric models and methods used\nin this area. After introducing several widely used continuous-time and\ndiscrete-time models, we study in detail dependence structures of discrete\nsamples, including Markovian property, hidden Markovian structure, contaminated\nobservations, and random samples. We then discuss several popular parametric\nand nonparametric estimation methods. To avoid model mis-specification, model\nvalidation plays a key role in financial modeling. We discuss several model\nvalidation techniques, including pseudo-likelihood ratio test, nonparametric\ncurve regression based test, residuals based test, generalized likelihood ratio\ntest, simultaneous confidence band construction, and density based test.\nFinally, we briefly touch on tools for studying large sample properties.\n"
    },
    {
        "paper_id": 801.171,
        "authors": "Zhi-Qiang Jiang, Wei-Xing Zhou (ECUST)",
        "title": "Multifractal analysis of Chinese stock volatilities based on partition\n  function approach",
        "comments": "14 elsart pages including 4 eps figures",
        "journal-ref": "Physica A 387 (19), 4881-4888 (2008)",
        "doi": "10.1016/j.physa.2008.04.028",
        "license": null,
        "abstract": "  We have performed detailed multifractal analysis on the minutely volatility\nof two indexes and 1139 stocks in the Chinese stock markets based on the\npartition function approach. The partition function $\\chi_q(s)$ scales as a\npower law with respect to box size $s$. The scaling exponents $\\tau(q)$ form a\nnonlinear function of $q$. Statistical tests based on bootstrapping show that\nthe extracted multifractal nature is significant at the 1% significance level.\nThe individual securities can be well modeled by the $p$-model in turbulence\nwith $p = 0.40 \\pm 0.02$. Based on the idea of ensemble averaging (including\nquenched and annealed average), we treat each stock exchange as a whole and\nconfirm the existence of multifractal nature in the Chinese stock markets.\n"
    },
    {
        "paper_id": 801.298,
        "authors": "Georg Zaklan, Frank Westerhoff, Dietrich Stauffer",
        "title": "Analysing tax evasion dynamics via the Ising model",
        "comments": "15 pages including figures and the Fortran program",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We develop a model of tax evasion based on the Ising model. We augment the\nmodel using an appropriate enforcement mechanism that may allow policy makers\nto curb tax evasion. With a certain probability tax evaders are subject to an\naudit. If they get caught they behave honestly for a certain number of periods.\nSimulating the model for a range of parameter combinations, we show that tax\nevasion may be controlled effectively by using punishment as an enforcement\nmechanism.\n"
    },
    {
        "paper_id": 801.3043,
        "authors": "Mauro Politi and Enrico Scalas",
        "title": "Activity spectrum from waiting-time distribution",
        "comments": "8 pages, 5 figures",
        "journal-ref": "Physica A 383 (2007) 43-48",
        "doi": "10.1016/j.physa.2007.04.086",
        "license": null,
        "abstract": "  In high frequency financial data not only returns but also waiting times\nbetween trades are random variables. In this work, we analyze the spectra of\nthe waiting-time processes for tick-by-tick trades. The numerical problem,\nstrictly related with the real inversion of Laplace transforms, is analyzed by\nusing Tikhonov's regularization method. We also analyze these spectra by a\nrough method using a comb of Dirac's delta functions.\n"
    },
    {
        "paper_id": 801.3047,
        "authors": "G. Innocenti and D. Materassi",
        "title": "Econometrics as Sorcery",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The paper deals with the problem of identifying the internal dependencies and\nsimilarities among a large number of random processes. Linear models are\nconsidered to describe the relations among the time series and the energy\nassociated to the corresponding modeling error is the criterion adopted to\nquantify their similarities. Such an approach is interpreted in terms of graph\ntheory suggesting a natural way to group processes together when one provides\nthe best model to explain the other. Moreover, the clustering technique\nintroduced in this paper will turn out to be the dynamical generalization of\nother multivariate procedures described in literature.\n"
    },
    {
        "paper_id": 801.3191,
        "authors": "Xin Guo, Yan Zeng",
        "title": "Intensity process and compensator: A new filtration expansion approach\n  and the Jeulin--Yor theorem",
        "comments": "Published in at http://dx.doi.org/10.1214/07-AAP447 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2008, Vol. 18, No. 1, 120-142",
        "doi": "10.1214/07-AAP447",
        "license": null,
        "abstract": "  Let $(X_t)_{t\\ge0}$ be a continuous-time, time-homogeneous strong Markov\nprocess with possible jumps and let $\\tau$ be its first hitting time of a Borel\nsubset of the state space. Suppose $X$ is sampled at random times and suppose\nalso that $X$ has not hit the Borel set by time $t$. What is the intensity\nprocess of $\\tau$ based on this information? This question from credit risk\nencompasses basic mathematical problems concerning the existence of an\nintensity process and filtration expansions, as well as some conceptual issues\nfor credit risk. By revisiting and extending the famous Jeulin--Yor [Lecture\nNotes in Math. 649 (1978) 78--97] result regarding compensators under a general\nfiltration expansion framework, a novel computation methodology for the\nintensity process of a stopping time is proposed. En route, an analogous\ncharacterization result for martingales of Jacod and Skorohod [Lecture Notes in\nMath. 1583 (1994) 21--35] under local jumping filtration is derived.\n"
    },
    {
        "paper_id": 801.3263,
        "authors": "A.A.G. Cortines, R. Riera, C. Anteneodo",
        "title": "From short to fat tails in financial markets: A unified description",
        "comments": "11 pages, 5 figures",
        "journal-ref": "European Journal of Physics B, volume 60, p. 385, 2007",
        "doi": null,
        "license": null,
        "abstract": "  In complex systems such as turbulent flows and financial markets, the\ndynamics in long and short time-lags, signaled by Gaussian and fat-tailed\nstatistics, respectively, calls for a unified description. To address this\nissue we analyze a real dataset, namely, price fluctuations, in a wide range of\ntemporal scales to embrace both regimes. By means of Kramers-Moyal (KM)\ncoefficients evaluated from empirical time series, we obtain the evolution\nequation for the probability density function (PDF) of price returns. We also\npresent consistent asymptotic solutions for the timescale dependent equation\nthat emerges from the empirical analysis. From these solutions, new\nrelationships connecting PDF characteristics, such as tail exponents, to\nparameters of KM coefficients arise. The results reveal a dynamical path that\nleads from Gaussian to fat-tailed statistics, furnishing insights on other\ncomplex systems where akin crossover is observed.\n"
    },
    {
        "paper_id": 801.3348,
        "authors": "Theodoros Tsagaris",
        "title": "Statistical Arbitrage and Optimal Trading with Transaction Costs in\n  Futures Markets",
        "comments": "28 pages, submitted to journal",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider the Brownian market model and the problem of expected utility\nmaximization of terminal wealth. We, specifically, examine the problem of\nmaximizing the utility of terminal wealth under the presence of transaction\ncosts of a fund/agent investing in futures markets. We offer some preliminary\nremarks about statistical arbitrage strategies and we set the framework for\nfutures markets, and introduce concepts such as margin, gearing and slippage.\nThe setting is of discrete time, and the price evolution of the futures prices\nis modelled as discrete random sequence involving Ito's sums. We assume the\ndrift and the Brownian motion driving the return process are non-observable and\nthe transaction costs are represented by the bid-ask spread. We provide\nexplicit solution to the optimal portfolio process, and we offer an example\nusing logarithmic utility.\n"
    },
    {
        "paper_id": 801.3494,
        "authors": "Zhi-Qiang Jiang, Wei-Xing Zhou (ECUST)",
        "title": "Direct evidence for inversion formula in multifractal financial\n  volatility measure",
        "comments": "4 Revtex pages + 4 figures",
        "journal-ref": "Chinese Phys. Lett. 26, 028901, (2009)",
        "doi": "10.1088/0256-307X/26/2/028901",
        "license": null,
        "abstract": "  The inversion formula for conservative multifractal measures was unveiled\nmathematically a decade ago, which is however not well tested in real complex\nsystems. In this Letter, we propose to verify the inversion formula using\nhigh-frequency turbulent financial data. We construct conservative volatility\nmeasure based on minutely S&P 500 index from 1982 to 1999 and its inverse\nmeasure of exit time. Both the direct and inverse measures exhibit nice\nmultifractal nature, whose scaling ranges are not irrelevant. Empirical\ninvestigation shows that the inversion formula holds in financial markets.\n"
    },
    {
        "paper_id": 801.356,
        "authors": "F. Ren and Y.-C. Zhang",
        "title": "Trading Model with Pair Pattern Strategies",
        "comments": "22 pages, 16 figures",
        "journal-ref": "Physica A 387 (2008), 5523-5534",
        "doi": "10.1016/j.physa.2008.06.027",
        "license": null,
        "abstract": "  A simple trading model based on pair pattern strategy space with holding\nperiods is proposed. Power-law behaviors are observed for the return variance\n$\\sigma^2$, the price impact $H$ and the predictability $K$ for both models\nwith linear and square root impact functions. The sum of the traders' wealth\ndisplays a positive value for the model with square root price impact function,\nand a qualitative explanation is given based on the observation of the\nconditional excess demand $<A|u>$. An evolutionary trading model is further\nproposed, and the elimination mechanism effectively changes the behavior of the\ntraders highly performed in the model without evolution. The trading model with\nother types of traders, e.g., traders with the MG's strategies and producers,\nare also carefully studied.\n"
    },
    {
        "paper_id": 801.3712,
        "authors": "Gao-Feng Gu (ECUST), Wei Chen (SZSE), Wei-Xing Zhou (ECUST)",
        "title": "Empirical shape function of limit-order books in the Chinese stock\n  market",
        "comments": "10 Elsart page including 4 figures",
        "journal-ref": "Physica A 387 (21), 5182-5188 (2008)",
        "doi": "10.1016/j.physa.2008.05.008",
        "license": null,
        "abstract": "  We have analyzed the statistical probabilities of limit-order book (LOB)\nshape through building the book using the ultra-high-frequency data from 23\nliquid stocks traded on the Shenzhen Stock Exchange in 2003. We find that the\naveraged LOB shape has a maximum away from the same best price for both buy and\nsell LOBs. The LOB shape function has nice exponential form in the right tail.\nThe buy LOB is found to be abnormally thicker for the price levels close to the\nsame best although there are much more sell orders on the book. We also find\nthat the LOB shape functions for both buy and sell sides have periodic peaks\nwith a period of five. The 1-min averaged volumes at fixed tick level follow\nlognormal distributions, except for the left tails which display power-law\nbehaviors, and exhibit long memory. Academic implications of our empirical\nresults are also discussed briefly.\n"
    },
    {
        "paper_id": 801.3973,
        "authors": "Lawrence Mitchell and G. J. Ackland",
        "title": "Boom and bust in continuous time evolving economic model",
        "comments": "7 pages, 9 figures, epjb style. New references. Section on avoiding\n  boom and bust. Fix bibliography",
        "journal-ref": "EPJB 70:567-573 (2009)",
        "doi": "10.1140/epjb/e2009-00243-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that a simple model of a spatially resolved evolving economic system,\nwhich has a steady state under simultaneous updating, shows stable oscillations\nin price when updated asynchronously. The oscillations arise from a gradual\ndecline of the mean price due to competition among sellers competing for the\nsame resource. This lowers profitability and hence population but is followed\nby a sharp rise as speculative sellers invade the large un-inhabited areas.\nThis cycle then begins again.\n"
    },
    {
        "paper_id": 801.4047,
        "authors": "Erhan Bayraktar, Hasanjan Sayit",
        "title": "No Arbitrage Conditions For Simple Trading Strategies",
        "comments": "Keywords: Simple trading strategies. Arbitrage. Sticky processes.\n  Short-Sales Restrictions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Strict local martingales may admit arbitrage opportunities with respect to\nthe class of simple trading strategies. (Since there is no possibility of using\ndoubling strategies in this framework, the losses are not assumed to be bounded\nfrom below.) We show that for a class of non-negative strict local martingales,\nthe strong Markov property implies the no arbitrage property with respect to\nthe class of simple trading strategies. This result can be seen as a\ngeneralization of a similar result on three dimensional Bessel process in [3].\nWe also pro- vide no arbitrage conditions for stochastic processes within the\nclass of simple trading strategies with shortsale restriction.\n"
    },
    {
        "paper_id": 801.422,
        "authors": "Jean Duchon (IF), Raoul Robert (IF), Vincent Vargas (CEREMADE)",
        "title": "Forecasting volatility with the multifractal random walk model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the problem of forecasting volatility for the multifractal random\nwalk model. In order to avoid the ill posed problem of estimating the\ncorrelation length T of the model, we introduce a limiting object defined in a\nquotient space; formally, this object is an infinite range logvolatility. For\nthis object and the non limiting object, we obtain precise prediction formulas\nand we apply them to the problem of forecasting volatility and pricing options\nwith the MRW model in the absence of a reliable estimate of the average\nvolatility and T.\n"
    },
    {
        "paper_id": 801.4305,
        "authors": "J. Emeterio Navarro Barrientos, Frank E. Walter, Frank Schweitzer",
        "title": "Risk-Seeking versus Risk-Avoiding Investments in Noisy Periodic\n  Environments",
        "comments": "27 pp. v2 with minor corrections. See http://www.sg.ethz.ch for more\n  info",
        "journal-ref": "International Journal of Modern Physics C vol. 19, no. 6 (2008)\n  971-994",
        "doi": "10.1142/S0129183108012662",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the performance of various agent strategies in an artificial\ninvestment scenario. Agents are equipped with a budget, $x(t)$, and at each\ntime step invest a particular fraction, $q(t)$, of their budget. The return on\ninvestment (RoI), $r(t)$, is characterized by a periodic function with\ndifferent types and levels of noise. Risk-avoiding agents choose their fraction\n$q(t)$ proportional to the expected positive RoI, while risk-seeking agents\nalways choose a maximum value $q_{max}$ if they predict the RoI to be positive\n(\"everything on red\"). In addition to these different strategies, agents have\ndifferent capabilities to predict the future $r(t)$, dependent on their\ninternal complexity. Here, we compare 'zero-intelligent' agents using technical\nanalysis (such as moving least squares) with agents using reinforcement\nlearning or genetic algorithms to predict $r(t)$. The performance of agents is\nmeasured by their average budget growth after a certain number of time steps.\nWe present results of extensive computer simulations, which show that, for our\ngiven artificial environment, (i) the risk-seeking strategy outperforms the\nrisk-avoiding one, and (ii) the genetic algorithm was able to find this optimal\nstrategy itself, and thus outperforms other prediction approaches considered.\n"
    },
    {
        "paper_id": 801.4337,
        "authors": "G. Weisbuch, D. Stauffer, D. Mangalagiu, R. Ben-Av, S. Solomon",
        "title": "Emergence of firms in $(d+1)$-dimensional work space",
        "comments": "13 pages including all figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Standard micro-economics concentrate on the description of markets but is\nseldom interested in production. Several economists discussed the concept of a\nfirm, as opposed to an open labour market where entrepreneurs would recrute\nworkers on the occasion of each business opportunity. Coase \\cite{Coase} is one\nof them, who explains the existence of firms as institution because they reduce\nthe transaction costs with respect to an open labour market. Whatever the\nrationale proposed by economists to account for the existence of firms, their\nperspective is based on efficiency and cost analysis. Little attention is paid\nto the dynamics of emergence and evolution of firms. The aim of the present\nmanuscript is to check the global dynamical properties of a very simple model\nbased on bounded rationality and reinforcement learning.\n  Workers and managers are localised on a lattice and they choose collaborators\non the basis of the success of previous work relations. The choice algorithm is\nlargely inspired rom the observation and modeling of long term customer/sellers\nrelationships observed on perishable goods markets discussed in Weisbuch\netal\\cite{Weisbuch} and Nadal etal\\cite{Nadal}. The model presented here is in\nno way an alternative to Coase. We describe the build-up of long term\nrelationships which do reduce transaction costs, and we deduce the dynamical\nproperties of networks built from our simple assumptions.\n  In conclusion, the present model explains the metastability of employment\nrelations in the firm, but something has to be added to it to explain the more\nefficient workload repartition observed in real firms.\n"
    },
    {
        "paper_id": 801.4341,
        "authors": "L. Gazola, C. Fernandes, A. Pizzinga and R. Riera",
        "title": "The log-periodic-AR(1)-GARCH(1,1) model for financial crashes",
        "comments": "17 pages, 4 figures, 12 tables, to appear in Europen Physical Journal\n  B",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00085-1",
        "license": null,
        "abstract": "  This paper intends to meet recent claims for the attainment of more rigorous\nstatistical methodology within the econophysics literature. To this end, we\nconsider an econometric approach to investigate the outcomes of the\nlog-periodic model of price movements, which has been largely used to forecast\nfinancial crashes. In order to accomplish reliable statistical inference for\nunknown parameters, we incorporate an autoregressive dynamic and a conditional\nheteroskedasticity structure in the error term of the original model, yielding\nthe log-periodic-AR(1)-GARCH(1,1) model. Both the original and the extended\nmodels are fitted to financial indices of U. S. market, namely S&P500 and\nNASDAQ. Our analysis reveal two main points: (i) the\nlog-periodic-AR(1)-GARCH(1,1) model has residuals with better statistical\nproperties and (ii) the estimation of the parameter concerning the time of the\nfinancial crash has been improved.\n"
    },
    {
        "paper_id": 801.4941,
        "authors": "Wing Yan Yip, Sofia Olhede, David Stephens",
        "title": "Hedging strategies and minimal variance portfolios for European and\n  exotic options in a Levy market",
        "comments": "32 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents hedging strategies for European and exotic options in a\nLevy market. By applying Taylor's Theorem, dynamic hedging portfolios are con-\nstructed under different market assumptions, such as the existence of power\njump assets or moment swaps. In the case of European options or baskets of\nEuropean options, static hedging is implemented. It is shown that perfect\nhedging can be achieved. Delta and gamma hedging strategies are extended to\nhigher moment hedging by investing in other traded derivatives depending on the\nsame underlying asset. This development is of practical importance as such\nother derivatives might be readily available. Moment swaps or power jump assets\nare not typically liquidly traded. It is shown how minimal variance portfolios\ncan be used to hedge the higher order terms in a Taylor expansion of the\npricing function, investing only in a risk-free bank account, the underlying\nasset and potentially variance swaps. The numerical algorithms and performance\nof the hedging strategies are presented, showing the practical utility of the\nderived results.\n"
    },
    {
        "paper_id": 802.0214,
        "authors": "K. Triantafyllopoulos",
        "title": "Multivariate stochastic volatility with Bayesian dynamic linear models",
        "comments": "24 pages, 3 figures, 2 tables",
        "journal-ref": "Journal of Statistical Planning and Inference (2008), 138(4), pp.\n  1021-1037",
        "doi": "10.1016/j.jspi.2007.03.057",
        "license": null,
        "abstract": "  This paper develops a Bayesian procedure for estimation and forecasting of\nthe volatility of multivariate time series. The foundation of this work is the\nmatrix-variate dynamic linear model, for the volatility of which we adopt a\nmultiplicative stochastic evolution, using Wishart and singular multivariate\nbeta distributions. A diagonal matrix of discount factors is employed in order\nto discount the variances element by element and therefore allowing a flexible\nand pragmatic variance modelling approach. Diagnostic tests and sequential\nmodel monitoring are discussed in some detail. The proposed estimation theory\nis applied to a four-dimensional time series, comprising spot prices of\naluminium, copper, lead and zinc of the London metal exchange. The empirical\nfindings suggest that the proposed Bayesian procedure can be effectively\napplied to financial data, overcoming many of the disadvantages of existing\nvolatility models.\n"
    },
    {
        "paper_id": 802.022,
        "authors": "K. Triantafyllopoulos",
        "title": "Forecasting with time-varying vector autoregressive models",
        "comments": "17 pages, 7 figures, tables 3",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The purpose of this paper is to propose a time-varying vector autoregressive\nmodel (TV-VAR) for forecasting multivariate time series. The model is casted\ninto a state-space form that allows flexible description and analysis. The\nvolatility covariance matrix of the time series is modelled via inverted\nWishart and singular multivariate beta distributions allowing a fully conjugate\nBayesian inference. Model performance and model comparison is done via the\nlikelihood function, sequential Bayes factors, the mean of squared standardized\nforecast errors, the mean of absolute forecast errors (known also as mean\nabsolute deviation), and the mean forecast error. Bayes factors are also used\nin order to choose the autoregressive order of the model. Multi-step\nforecasting is discussed in detail and a flexible formula is proposed to\napproximate the forecast function. Two examples, consisting of bivariate data\nof IBM shares and of foreign exchange (FX) rates for 8 currencies, illustrate\nthe methods. For the IBM data we discuss model performance and multi-step\nforecasting in some detail. For the FX data we discuss sequential portfolio\nallocation; for both data sets our empirical findings suggest that the TV-VAR\nmodels outperform the widely used VAR models.\n"
    },
    {
        "paper_id": 802.0223,
        "authors": "K. Triantafyllopoulos",
        "title": "Multivariate stochastic volatility using state space models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A Bayesian procedure is developed for multivariate stochastic volatility,\nusing state space models. An autoregressive model for the log-returns is\nemployed. We generalize the inverted Wishart distribution to allow for\ndifferent correlation structure between the observation and state innovation\nvectors and we extend the convolution between the Wishart and the multivariate\nsingular beta distribution. A multiplicative model based on the generalized\ninverted Wishart and multivariate singular beta distributions is proposed for\nthe evolution of the volatility and a flexible sequential volatility updating\nis employed. The proposed algorithm for the volatility is fast and\ncomputationally cheap and it can be used for on-line forecasting. The methods\nare illustrated with an example consisting of foreign exchange rates data of 8\ncurrencies. The empirical results suggest that time-varying correlations can be\nestimated efficiently, even in situations of high dimensional data.\n"
    },
    {
        "paper_id": 802.0984,
        "authors": "Z.K. Silagadze",
        "title": "Moving Mini-Max - a new indicator for technical analysis",
        "comments": "10 pages, 3 figures. Published version",
        "journal-ref": "IFTA Journal 11 (2011), 46-49",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new indicator for technical analysis. The indicator emphasizes\nmaximums and minimums in price series with inherent smoothing and has a\npotential to be useful in both mechanical trading rules and chart pattern\nanalysis.\n"
    },
    {
        "paper_id": 802.1121,
        "authors": "Freddy Delbaen, Shige Peng, Emanuela Rosazza Gianin",
        "title": "Representation of the penalty term of dynamic concave utilities",
        "comments": "An updated version is published in Finance & Stochastics. The final\n  publication is available at http://www.springerlink.com",
        "journal-ref": null,
        "doi": "10.1007/s00780-009-0119-7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we will provide a representation of the penalty term of general\ndynamic concave utilities (hence of dynamic convex risk measures) by applying\nthe theory of g-expectations.\n"
    },
    {
        "paper_id": 802.1288,
        "authors": "Alberto Ohashi",
        "title": "Fractional term structure models: No-arbitrage and consistency",
        "comments": "Published in at http://dx.doi.org/10.1214/08-AAP586 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 4, 1553-1580",
        "doi": "10.1214/08-AAP586",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we introduce Heath-Jarrow-Morton (HJM) interest rate models\ndriven by fractional Brownian motions. By using support arguments we prove that\nthe resulting model is arbitrage free under proportional transaction costs in\nthe same spirit of Guasoni [Math. Finance 16 (2006) 569-582]. In particular, we\nobtain a drift condition which is similar in nature to the classical HJM\nno-arbitrage drift restriction. The second part of this paper deals with\nconsistency problems related to the fractional HJM dynamics. We give a fairly\ncomplete characterization of finite-dimensional invariant manifolds for HJM\nmodels with fractional Brownian motion by means of Nagumo-type conditions. As\nan application, we investigate consistency of Nelson-Siegel family with respect\nto Ho-Lee and Hull-White models. It turns out that similar to the Brownian case\nsuch a family does not go well with the fractional HJM dynamics with\ndeterministic volatility. In fact, there is no nontrivial fractional interest\nrate model consistent with the Nelson-Siegel family.\n"
    },
    {
        "paper_id": 802.1407,
        "authors": "Vincent Leijdekker and Peter Spreij",
        "title": "Explicit Computations for a Filtering Problem with Point Process\n  Observations with Applications to Credit Risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the intensity-based approach for the modeling of default times of\none or more companies. In this approach the default times are defined as the\njump times of a Cox process, which is a Poisson process conditional on the\nrealization of its intensity. We assume that the intensity follows the\nCox-Ingersoll-Ross model. This model allows one to calculate survival\nprobabilities and prices of defaultable bonds explicitly. In this paper we\nassume that the Brownian motion, that drives the intensity, is not observed.\nUsing filtering theory for point process observations, we are able to derive\ndynamics for the intensity and its moment generating function, given the\nobservations of the Cox process. A transformation of the dynamics of the\nconditional moment generating function allows us to solve the filtering\nproblem, between the jumps of the Cox process, as well as at the jumps.\nAssuming that the initial distribution of the intensity is of the Gamma type,\nwe obtain an explicit solution to the filtering problem for all t>0. We\nconclude the paper with the observation that the resulting conditional moment\ngenerating function at time t corresponds to a mixture of Gamma distributions.\n"
    },
    {
        "paper_id": 802.1416,
        "authors": "G. Daniel and D. Sornette",
        "title": "Econophysics: historical perspectives",
        "comments": "7 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Econophysics embodies the recent upsurge of interest by physicists into\nfinancial economics, driven by the availability of large amount of data, job\nshortage in physics and the possibility of applying many-body techniques\ndeveloped in statistical and theoretical physics to the understanding of the\nself-organizing economy. This brief historical survey emphasizes that\nEconophysics has many historical precursors, and is in fact rooted in a\ncontinuous cross-fertilization between economics and physics that has been\nactive in the last centuries.\n"
    },
    {
        "paper_id": 802.15,
        "authors": "Cheoljun Eom, Woo-Sung Jung, Sunghoon Choi, Gabjin Oh, Seunghwan Kim",
        "title": "Effects of time dependency and efficiency on information flow in\n  financial markets",
        "comments": null,
        "journal-ref": "Physica A 387(21), 5219-5224 (2008)",
        "doi": "10.1016/j.physa.2008.05.054",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigated financial market data to determine which factors affect\ninformation flow between stocks. Two factors, the time dependency and the\ndegree of efficiency, were considered in the analysis of Korean, the Japanese,\nthe Taiwanese, the Canadian, and US market data. We found that the frequency of\nthe significant information decreases as the time interval increases. However,\nno significant information flow was observed in the time series from which the\ntemporal time correlation was removed. These results indicated that the\ninformation flow between stocks evidences time-dependency properties.\nFurthermore, we discovered that the difference in the degree of efficiency\nperforms a crucial function in determining the direction of the significant\ninformation flow.\n"
    },
    {
        "paper_id": 802.1747,
        "authors": "Okyu Kwon, Jae-Suk Yang",
        "title": "Information flow between stock indices",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1209/0295-5075/82/68003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using transfer entropy, we observed the strength and direction of information\nflow between stock indices. We uncovered that the biggest source of information\nflow is America. In contrast, the Asia/Pacific region the biggest is receives\nthe most information. According to the minimum spanning tree, the GSPC is\nlocated at the focal point of the information source for world stock markets.\n"
    },
    {
        "paper_id": 802.1823,
        "authors": "Martin Keller-Ressel",
        "title": "Moment Explosions and Long-Term Behavior of Affine Stochastic Volatility\n  Models",
        "comments": "minor revision",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a class of asset pricing models, where the risk-neutral joint\nprocess of log-price and its stochastic variance is an affine process in the\nsense of Duffie, Filipovic and Schachermayer [2003]. First we obtain conditions\nfor the price process to be conservative and a martingale. Then we present some\nresults on the long-term behavior of the model, including an expression for the\ninvariant distribution of the stochastic variance process. We study moment\nexplosions of the price process, and provide explicit expressions for the time\nat which a moment of given order becomes infinite. We discuss applications of\nthese results, in particular to the asymptotics of the implied volatility\nsmile, and conclude with some calculations for the Heston model, a model of\nBates and the Barndorff-Nielsen-Shephard model.\n"
    },
    {
        "paper_id": 802.2004,
        "authors": "Damien Challet, Sorin Solomon, Gur Yaari",
        "title": "The universal shape of economic recession and recovery after a shock",
        "comments": "21 pages, 11 figures. The new version expands the discussion on\n  shocks with quarterly data analysis",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that a simple and intuitive three-parameter equation fits remarkably\nwell the evolution of the gross domestic product (GDP) in current and constant\ndollars of many countries during times of recession and recovery. We then argue\nthat this equation is the response function of the economy to isolated shocks,\nhence that it can be used to detect large and small shocks, including those\nwhich do not lead to a recession; we also discuss its predictive power.\nFinally, a two-sector toy model of recession and recovery illustrates how the\nseverity and length of recession depends on the dynamics of transfer rate\nbetween the growing and failing parts of the economy.\n"
    },
    {
        "paper_id": 802.2172,
        "authors": "Marie-Amelie Morlais",
        "title": "Reflected backward stochastic differential equations and a class of non\n  linear dynamic pricing rule",
        "comments": "20 pages, partial modification of the content",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In that paper, we provide a new characterization of the solutions of specific\nreflected backward stochastic differential equations (or RBSDEs) whose driver\n$g$ is convex and has quadratic growth in its second variable: this is done by\nintroducing the extended notion of $g$-Snell enveloppe. Then, in a second step,\nwe relate this representation to a specific class of dynamic monetary concave\nfunctionals already introduced in a discrete time setting. This connection\nimplies that the solution, characterized by means of non linear expectations,\nhas again the time consistency property.\n"
    },
    {
        "paper_id": 802.3039,
        "authors": "Beata Stehlikova and Daniel Sevcovic",
        "title": "Approximate formulae for pricing zero-coupon bonds and their asymptotic\n  analysis",
        "comments": "to appear in: International Journal of Numerical Analysis and\n  Modeling",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze analytic approximation formulae for pricing zero-coupon bonds in\nthe case when the short-term interest rate is driven by a one-factor\nmean-reverting process with a volatility nonlinearly depending on the interest\nrate itself. We derive the order of accuracy of the analytical approximation\ndue to Choi and Wirjanto. We furthermore give an explicit formula for a higher\norder approximation and we test both approximations numerically for a class of\none-factor interest rate models.\n"
    },
    {
        "paper_id": 802.325,
        "authors": "Erhan Bayraktar, Moshe Milevsky, David Promislow, Virginia Young",
        "title": "Valuation of Mortality Risk via the Instantaneous Sharpe Ratio:\n  Applications to Life Annuities",
        "comments": "Keywords: Stochastic mortality; pricing; annuities; Sharpe ratio;\n  non-linear partial differential equations; market price of risk; equivalent\n  martingale measures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a theory for valuing non-diversifiable mortality risk in an\nincomplete market. We do this by assuming that the company issuing a\nmortality-contingent claim requires compensation for this risk in the form of a\npre-specified instantaneous Sharpe ratio. We apply our method to value life\nannuities. One result of our paper is that the value of the life annuity is\n{\\it identical} to the upper good deal bound of Cochrane and Sa\\'{a}-Requejo\n(2000) and of Bj\\\"{o}rk and Slinko (2006) applied to our setting. A second\nresult of our paper is that the value per contract solves a {\\it linear}\npartial differential equation as the number of contracts approaches infinity.\nOne can represent the limiting value as an expectation with respect to an\nequivalent martingale measure (as in Blanchet-Scalliet, El Karoui, and\nMartellini (2005)), and from this representation, one can interpret the\ninstantaneous Sharpe ratio as an annuity market's price of mortality risk.\n"
    },
    {
        "paper_id": 802.3291,
        "authors": "Alessandro Cappellini, Gianluigi Ferraris",
        "title": "Waiting Times in Simulated Stock Markets",
        "comments": "11 pages, 4 figures. Presented at ECCS'07. Submitted at ACS",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Exploiting a precise reproduction of a stock exchange, the robustness of the\nContinuous Double Auction (CDA) mechanism, evaluated by means of the waiting\ntime distributions, has been proved versus 36 different set ups made by varying\nboth the operators' behaviour and the market micro structure. The obtained\nresults demonstrate that the CDA remains able to clear strongly different order\nflows, though the Milan stock exchange seemed to be a little more efficient\nthan the NYSE under the allocative point of view, witnessing the intrinsic\ncomplexity of the stock market. The simulation has been built as an Agent Based\nModel in order to obtain a plausible order flow. The decisions of single agents\nand their interaction through the market book are realistic and reproduce some\nempirical analysis results. The mentioned results have been obtained either by\nthe analysis of the complete pending time series and the same computation of\nthe asks and bids series alone.\n"
    },
    {
        "paper_id": 802.3541,
        "authors": "G. Yaari and D. Stauffer and S. Solomon",
        "title": "Intermittency and Localization",
        "comments": "23 pages, 4 figures. For Springers' Encyclopedia of Complexity and\n  System Science",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we show how simple logistic growth that was studied\nintensively during the last 200 years in many domains of science could be\nextended in a rather simple way and with these extensions is capable to produce\na collection of behaviors widely observed in an enormous number of real-life\nsystems in Economics, Sociology, Biology, Ecology and more.\n"
    },
    {
        "paper_id": 802.3553,
        "authors": "Martin A. Szybisz and Leszek Szybisz",
        "title": "Finite-time singularity in the evolution of hyperinflation episodes",
        "comments": "14 pages, including 9 figures and 2 tables.(I am sending a file.tex\n  and 9 figures as *.eps files",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A model proposed by Sornette, Takayasu, and Zhou for describing\nhyperinflation regimes based on adaptive expectations expressed in terms of a\npower law which leads to a finite-time singularity is revisited. It is\nsuggested to express the price index evolution explicitly in terms of the\nparameters introduced along the theoretical formulation avoiding any\ncombination of them used in the original work. This procedure allows to study\nunambiguously the uncertainties of such parameters when an error is assigned to\nthe measurement of the price index. In this way, it is possible to determine an\nuncertainty in the critical time at which the singularity occurs. For this\npurpose, Monte Carlo simulation techniques are applied. The hyperinflation\nepisodes of Peru (1969-90) and Weimar Germany (1920-3) are reexamined. The\nfirst analyses performed within this framework of the very extreme\nhyper-inflations occurred in Greece (1941-4) and Yugoslavia (1991-4) are\nreported. The study of the hyperinflation spiral experienced just nowadays in\nZimbabwe predicts a singularity, i.e., a complete economic crash within two\nyears.\n"
    },
    {
        "paper_id": 802.3585,
        "authors": "V. Filipe Martins-da-Rocha, Frank Riedel",
        "title": "On Equilibrium Prices in Continuous Time",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We combine general equilibrium theory and theorie generale of stochastic\nprocesses to derive structural results about equilibrium state prices.\n"
    },
    {
        "paper_id": 802.3679,
        "authors": "Pavel Levin",
        "title": "Mirror-time diffusion discount model of options pricing",
        "comments": "22 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The proposed model modifies option pricing formulas for the basic case of\nlog-normal probability distribution providing correspondence to formulated\ncriteria of efficiency and completeness. The model is self-calibrating by\nhistoric volatility data; it maintains the constant expected value at maturity\nof the hedged instantaneously self-financing portfolio. The payoff variance\ndependent on random stock price at maturity obtained under an equivalent\nmartingale measure is taken as a condition for introduced \"mirror-time\"\nderivative diffusion discount process. Introduced ksi-return distribution,\ncorrespondent to the found general solution of backward drift-diffusion\nequation and normalized by theoretical diffusion coefficient, does not contain\nso-called \"long tails\" and unbiased for considered 2004-2007 S&P 100 index\ndata. The model theoretically yields skews correspondent to practical term\nstructure for interest rate derivatives. The method allows increasing the\nnumber of asset price probability distribution parameters.\n"
    },
    {
        "paper_id": 802.3769,
        "authors": "Guido Germano, Mauro Politi, Enrico Scalas, Ren\\'e L. Schilling",
        "title": "Stochastic calculus for uncoupled continuous-time random walks",
        "comments": "12 pages, 3 figures, submitted to Phys. Rev. E",
        "journal-ref": "Physical Review E 79 (6), 066102:1-12, 2009",
        "doi": "10.1103/PhysRevE.79.066102",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The continuous-time random walk (CTRW) is a pure-jump stochastic process with\nseveral applications in physics, but also in insurance, finance and economics.\nA definition is given for a class of stochastic integrals driven by a CTRW,\nthat includes the Ito and Stratonovich cases. An uncoupled CTRW with zero-mean\njumps is a martingale. It is proved that, as a consequence of the martingale\ntransform theorem, if the CTRW is a martingale, the Ito integral is a\nmartingale too. It is shown how the definition of the stochastic integrals can\nbe used to easily compute them by Monte Carlo simulation. The relations between\na CTRW, its quadratic variation, its Stratonovich integral and its Ito integral\nare highlighted by numerical calculations when the jumps in space of the CTRW\nhave a symmetric Levy alpha-stable distribution and its waiting times have a\none-parameter Mittag-Leffler distribution. Remarkably these distributions have\nfat tails and an unbounded quadratic variation. In the diffusive limit of\nvanishing scale parameters, the probability density of this kind of CTRW\nsatisfies the space-time fractional diffusion equation (FDE) or more in general\nthe fractional Fokker-Planck equation, that generalize the standard diffusion\nequation solved by the probability density of the Wiener process, and thus\nprovides a phenomenologic model of anomalous diffusion. We also provide an\nanalytic expression for the quadratic variation of the stochastic process\ndescribed by the FDE, and check it by Monte Carlo.\n"
    },
    {
        "paper_id": 802.4043,
        "authors": "Stanislaw Drozdz, Jaroslaw Kwapien, Pawel Oswiecimka, Josef Speth",
        "title": "Current log-periodic view on future world market development",
        "comments": "presented by S. Drozdz at FENS2007 conference, 10 pages, 6 Figs, an\n  extended version with the oil market included (Fig.7)",
        "journal-ref": "Acta Physica Polonica A 114, 539 (2008)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Applicability of the concept of financial log-periodicity is discussed and\nencouragingly verified for various phases of the world stock markets\ndevelopment in the period 2000-2010. In particular, a speculative forecasting\nscenario designed in the end of 2004, that properly predicted the world stock\nmarket increases in 2007, is updated by setting some more precise constraints\non the time of duration of the present long-term equity market bullish phase. A\ntermination of this phase is evaluated to occur in around November 2009. In\nparticular, on the way towards this dead-line, a Spring-Summer 2008 increase is\nexpected. On the precious metals market a forthcoming critical time signal is\ndetected at the turn of March/April 2008 which marks a tendency for at least a\nserious correction to begin.\n  In the present extended version some predictions for the future oil price are\nincorporated. In particular a serious correction on this market is expected to\nstart in the coming days.\n"
    },
    {
        "paper_id": 802.4064,
        "authors": "Caglar Tuncay",
        "title": "A theoretical approach for Pareto-Zipf law",
        "comments": "6 pages 2 figures and dated for IJMPC Volume 19 presumably issue 8",
        "journal-ref": null,
        "doi": "10.1142/S0129183108012790",
        "license": "http://creativecommons.org/licenses/publicdomain/",
        "abstract": "  We suggest an analytical approach for Pareto-Zipf law, where we assume random\nmultiplicative noise and fragmentation processes for the growth of the number\nof citizens of each city and the number of the cities, respectively.\n"
    },
    {
        "paper_id": 802.4141,
        "authors": "Takuji Arai",
        "title": "Good deal bounds induced by shortfall risk",
        "comments": "This paper has been withdrawn by the author.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We shall provide in this paper good deal pricing bounds for contingent claims\ninduced by the shortfall risk with some loss function. Assumptions we impose on\nloss functions and contingent claims are very mild. We prove that the upper and\nlower bounds of good deal pricing bounds are expressed by convex risk measures\non Orlicz hearts. In addition, we obtain its representation with the minimal\npenalty function. Moreover, we give a representation, for two simple cases, of\ngood deal bounds and calculate the optimal strategies when a claim is traded at\nthe upper or lower bounds of its good deal pricing bound.\n"
    },
    {
        "paper_id": 802.4165,
        "authors": "J.B. Satinover and D. Sornette",
        "title": "Illusory versus Genuine Control in Agent-Based Games",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2009-00037-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the Minority, Majority and Dollar Games (MG, MAJG, $G), synthetic agents\ncompete for rewards, at each time-step acting in accord with the previously\nbest-performing of their limited sets of strategies. Different components\nand/or aspects of real-world financial markets are modelled by these games. In\nthe MG, agents compete for scarce resources; in the MAJG gents imitate the\ngroup in the hope of exploiting a trend; in the $G agents attempt to\nsuccessfully predict and benefit from trends as well as changes in the\ndirection of a market. It has been previously shown that in the MG for a\nreasonable number of preliminary time steps preceding equilibrium (Time Horizon\nMG, THMG), agents' attempt to optimize their gains by active strategy selection\nis ``illusory'': The calculated hypothetical gains of their individual\nstrategies is greater on average than agents' actual average gains.\nFurthermore, if a small proportion of agents deliberately choose and act in\naccord with their seemingly worst performing strategy, these outper-form all\nother agents on average, and even attain mean positive gain, otherwise rare for\nagents in the MG. This latter phenomenon raises the question as to how well the\noptimization procedure works in the MAJG and $G. We demonstrate that the\nillusion of control is absent in MAJG and $G. In other words, low-entropy (more\ninformative) strategies under-perform high-entropy (or random) strategies in\nthe MG but outperform them in the MAJG and $G. This provides further\nclarification of the kinds of situations subject to genuine control, and those\nnot, in set-ups a priori defined to emphasize the importance of optimization.\n"
    },
    {
        "paper_id": 802.4311,
        "authors": "Kei Takeuchi, Masayuki Kumon and Akimichi Takemura",
        "title": "Multistep Bayesian strategy in coin-tossing games and its application to\n  asset trading games in continuous time",
        "comments": null,
        "journal-ref": "Stochastic Analysis and Applications, Vol.28 (2010), 842-861",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study multistep Bayesian betting strategies in coin-tossing games in the\nframework of game-theoretic probability of Shafer and Vovk (2001). We show that\nby a countable mixture of these strategies, a gambler or an investor can\nexploit arbitrary patterns of deviations of nature's moves from independent\nBernoulli trials. We then apply our scheme to asset trading games in continuous\ntime and derive the exponential growth rate of the investor's capital when the\nvariation exponent of the asset price path deviates from two.\n"
    },
    {
        "paper_id": 802.441,
        "authors": "Anirban Chakraborti and Marco Patriarca",
        "title": "Gamma-distribution and wealth inequality",
        "comments": "Presented to the International Workshop and Conference on:\n  Statistical Physics Approaches to Multi-disciplinary Problems, January 07-13,\n  2008, IIT Guwahati, India",
        "journal-ref": null,
        "doi": "10.1007/s12043-008-0156-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the equivalence between kinetic wealth-exchange models, in which\nagents exchange wealth during trades, and mechanical models of particles,\nexchanging energy during collisions. The universality of the underlying\ndynamics is shown both through a variational approach based on the minimization\nof the Boltzmann entropy and a complementary microscopic analysis of the\ncollision dynamics of molecules in a gas. In various relevant cases the\nequilibrium distribution is the same for all these models, namely a\ngamma-distribution with suitably defined temperature and number of dimensions.\nThis in turn allows one to quantify the inequalities observed in the wealth\ndistributions and suggests that their origin should be traced back to very\ngeneral underlying mechanisms: for instance, it follows that the smaller the\nfraction of the relevant quantity (e.g. wealth or energy) that agents can\nexchange during an interaction, the closer the corresponding equilibrium\ndistribution is to a fair distribution.\n"
    },
    {
        "paper_id": 802.4411,
        "authors": "Simon J. A. Malham and Anke Wiese",
        "title": "Chi-square simulation of the CIR process and the Heston model",
        "comments": "32 pages, 6 figures, 8 tables, update",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The transition probability of a Cox-Ingersoll-Ross process can be represented\nby a non-central chi-square density. First we prove a new representation for\nthe central chi-square density based on sums of powers of generalized Gaussian\nrandom variables. Second we prove Marsaglia's polar method extends to this\ndistribution, providing a simple, exact, robust and efficient\nacceptance-rejection method for generalized Gaussian sampling and thus central\nchi-square sampling. Third we derive a simple, high-accuracy, robust and\nefficient direct inversion method for generalized Gaussian sampling based on\nthe Beasley-Springer-Moro method. Indeed the accuracy of the approximation to\nthe inverse cumulative distribution function is to the tenth decimal place. We\nthen apply our methods to non-central chi-square variance sampling in the\nHeston model. We focus on the case when the number of degrees of freedom is\nsmall and the zero boundary is attracting and attainable, typical in foreign\nexchange markets. Using the additivity property of the chi-square distribution,\nour methods apply in all parameter regimes.\n"
    },
    {
        "paper_id": 802.446,
        "authors": "Yu.A Kuperin, R.R. Schastlivtsev",
        "title": "Modified Holder Exponents Approach to Prediction of the USA Stock Market\n  Critical Points and Crashes",
        "comments": "15 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper is devoted to elaboration of a novel specific indicator based on\nthe modified Holder exponents. This indicator has been used for forecasting\ncritical points of financial time series and crashes of the USA stock market.\nThe proposed approach is based on the hypothesis, which claims that before\nmarket critical points occur the dynamics of financial time series radically\nchanges, namely time series become smoother. The approach has been tested on\nthe stylized data and real USA stock market data. It has been shown that it is\npossible to forecast such critical points of financial time series as large\nupward and downward movements and trend changes. On this basis a new trading\nstrategy has been elaborated and tested.\n"
    },
    {
        "paper_id": 803.0057,
        "authors": "R.Rak, J.Kwapien, S.Drozdz, P.Oswiecimka",
        "title": "Cross-correlations in Warsaw Stock Exchange",
        "comments": "presented by R.Rak at FENS2007 conference, 9 pages, 4 Figs",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the inter-stock correlations for the largest companies listed on\nWarsaw Stock Exchange and included in the WIG20 index. Our results from the\ncorrelation matrix analysis indicate that the Polish stock market can be well\ndescribed by a one factor model. We also show that the stock-stock correlations\ntend to increase with the time scale of returns and they approach a saturation\nlevel for the time scales of at least 200 min, i.e. an order of magnitude\nlonger than in the case of some developed markets. We also show that the\nstrength of correlations among the stocks crucially depends on their\ncapitalization. These results combined with our earlier findings together\nsuggest that now the Polish stock market situates itself somewhere between an\nemerging market phase and a mature market phase.\n"
    },
    {
        "paper_id": 803.0436,
        "authors": "S. Jain and T. Yamano",
        "title": "Double Power Law Decay of the Persistence in Financial Markets",
        "comments": "9 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The persistence phenomenon is studied in the Japanese financial market by\nusing a novel mapping of the time evolution of the values of shares quoted on\nthe Nikkei Index onto Ising spins. The method is applied to historical end of\nday data from the Japanese stock market during 2002. By studying the time\ndependence of the spins, we find clear evidence for a double-power law decay of\nthe proportion of shares that remain either above or below ` starting\\rq\\\nvalues chosen at random. The results are consistent with a recent analysis of\nthe data from the London FTSE100 market. The slopes of the power-laws are also\nin agreement. We estimate a long time persistence exponent for the underlying\nJapanese financial market to be 0.5.\n"
    },
    {
        "paper_id": 803.0844,
        "authors": "F. Ren, B. Zheng, and P. Chen",
        "title": "Modeling interaction of trading volume in financial dynamics",
        "comments": "7 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A dynamic herding model with interactions of trading volumes is introduced.\nAt time $t$, an agent trades with a probability, which depends on the ratio of\nthe total trading volume at time $t-1$ to its own trading volume at its last\ntrade. The price return is determined by the volume imbalance and number of\ntrades. The model successfully reproduces the power-law distributions of the\ntrading volume, number of trades and price return, and their relations.\nMoreover, the generated time series are long-range correlated. We demonstrate\nthat the results are rather robust, and do not depend on the particular form of\nthe trading probability.\n"
    },
    {
        "paper_id": 803.1364,
        "authors": "Matus Medo, Yury M. Pis'mak, Yi-Cheng Zhang",
        "title": "Diversification and limited information in the Kelly game",
        "comments": "11 pages, 4 figures",
        "journal-ref": "Physica A 387, 6151-6158 (2008)",
        "doi": "10.1016/j.physa.2008.07.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets, with their vast range of different investment\nopportunities, can be seen as a system of many different simultaneous games\nwith diverse and often unknown levels of risk and reward. We introduce\ngeneralizations to the classic Kelly investment game [Kelly (1956)] that\nincorporates these features, and use them to investigate the influence of\ndiversification and limited information on Kelly-optimal portfolios. In\nparticular we present approximate formulas for optimizing diversified\nportfolios and exact results for optimal investment in unknown games where the\nonly available information is past outcomes.\n"
    },
    {
        "paper_id": 803.1374,
        "authors": "P. Oswiecimka, J. Kwapien, S. Drozdz, A. Z. Gorski, R. Rak",
        "title": "Different fractal properties of positive and negative returns",
        "comments": "presented at FENS2007 conference, 8 pages, 4 Figs",
        "journal-ref": "Acta Physica Polonica A Vol. 114 No 3. page 547 (2008)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform an analysis of fractal properties of the positive and the negative\nchanges of the German DAX30 index separately using Multifractal Detrended\nFluctuation Analysis (MFDFA). By calculating the singularity spectra\n$f(\\alpha)$ we show that returns of both signs reveal multiscaling. Curiously,\nthese spectra display a significant difference in the scaling properties of\nreturns with opposite sign. The negative price changes are ruled by stronger\ntemporal correlations than the positive ones, what is manifested by larger\nvalues of the corresponding H\\\"{o}lder exponents. As regards the properties of\ndominant trends, a bear market is more persistent than the bull market\nirrespective of the sign of fluctuations.\n"
    },
    {
        "paper_id": 803.1589,
        "authors": "Yukio Hirashita",
        "title": "A new market model in the large volatility case",
        "comments": "5 pages",
        "journal-ref": "Far East Journal of Applied Mathematics 32 (2008), 13-20.",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We will compare three types of prices, namely, rational (hedging) prices,\ngeometric (growth rate) prices, and martingale (measure) prices. We will show\nthat rational prices in the complete market theory are sometimes contrary to\ncommon sense. In the continuous-time case, we insist that the market model\nshould differ between the small volatility case and the large volatility case.\n"
    },
    {
        "paper_id": 803.1706,
        "authors": "M. S. Santhanam and Holger Kantz",
        "title": "Return interval distribution of extreme events and long term memory",
        "comments": "8 pages, 6 figures",
        "journal-ref": "Phys. Rev. E 78, 051113 (2008)",
        "doi": "10.1103/PhysRevE.78.051113",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The distribution of recurrence times or return intervals between extreme\nevents is important to characterize and understand the behavior of physical\nsystems and phenomena in many disciplines. It is well known that many physical\nprocesses in nature and society display long range correlations. Hence, in the\nlast few years, considerable research effort has been directed towards studying\nthe distribution of return intervals for long range correlated time series.\nBased on numerical simulations, it was shown that the return interval\ndistributions are of stretched exponential type. In this paper, we obtain an\nanalytical expression for the distribution of return intervals in long range\ncorrelated time series which holds good when the average return intervals are\nlarge. We show that the distribution is actually a product of power law and a\nstretched exponential form. We also discuss the regimes of validity and perform\ndetailed studies on how the return interval distribution depends on the\nthreshold used to define extreme events.\n"
    },
    {
        "paper_id": 803.1769,
        "authors": "Armand Joulin, Augustin Lefevre, Daniel Grunberg, Jean-Philippe\n  Bouchaud (CFM)",
        "title": "Stock price jumps: news and volume play a minor role",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In order to understand the origin of stock price jumps, we cross-correlate\nhigh-frequency time series of stock returns with different news feeds. We find\nthat neither idiosyncratic news nor market wide news can explain the frequency\nand amplitude of price jumps. We find that the volatility patterns around jumps\nand around news are quite different: jumps are followed by increased\nvolatility, whereas news tend on average to be followed by lower volatility\nlevels. The shape of the volatility relaxation is also markedly different in\nthe two cases. Finally, we provide direct evidence that large transaction\nvolumes are_not_ responsible for large price jumps. We conjecture that most\nprice jumps are induced by order flow fluctuations close to the point of\nvanishing liquidity.\n"
    },
    {
        "paper_id": 803.1815,
        "authors": "S.Hamad\\'ene and H.Wang",
        "title": "BSDEs with two RCLL Reflecting Obstacles driven by a Brownian Motion and\n  Poisson Measure and related Mixed Zero-Sum Games",
        "comments": "31 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study Backward Stochastic Differential Equations with two\nreflecting right continuous with left limits obstacles (or barriers) when the\nnoise is given by Brownian motion and a Poisson random measure mutually\nindependent. The jumps of the obstacle processes could be either predictable or\ninaccessible. We show existence and uniqueness of the solution when the\nbarriers are completely separated and the generator uniformly Lipschitz. We do\nnot assume the existence of a difference of supermartingales between the\nobstacles. As an application, we show that the related mixed zero-sum\ndifferential-integral game problem has a value.\n"
    },
    {
        "paper_id": 803.1858,
        "authors": "Constantinos Kardaras",
        "title": "Balance, growth and diversity of financial markets",
        "comments": "25 pages",
        "journal-ref": "Annals of Finance, volume 4, number 3 (2008), pages 369-397",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A financial market comprising of a certain number of distinct companies is\nconsidered, and the following statement is proved: either a specific agent will\nsurely beat the whole market unconditionally in the long run, or (and this \"or\"\nis not exclusive) all the capital of the market will accumulate in one company.\nThus, absence of any \"free unbounded lunches relative to the total capital\"\nopportunities lead to the most dramatic failure of diversity in the market: one\ncompany takes over all other until the end of time. In order to prove this, we\nintroduce the notion of perfectly balanced markets, which is an equilibrium\nstate in which the relative capitalization of each company is a martingale\nunder the physical probability. Then, the weaker notion of balanced markets is\ndiscussed where the martingale property of the relative capitalizations holds\nonly approximately, we show how these concepts relate to growth-optimality and\nefficiency of the market, as well as how we can infer a shadow interest rate\nthat is implied in the economy in the absence of a bank.\n"
    },
    {
        "paper_id": 803.1877,
        "authors": "Ioannis Karatzas and Constantinos Kardaras",
        "title": "The numeraire portfolio in semimartingale financial models",
        "comments": "43 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the existence of the numeraire portfolio under predictable convex\nconstraints in a general semimartingale model of a financial market. The\nnumeraire portfolio generates a wealth process, with respect to which the\nrelative wealth processes of all other portfolios are supermartingales.\nNecessary and sufficient conditions for the existence of the numeraire\nportfolio are obtained in terms of the triplet of predictable characteristics\nof the asset price process. This characterization is then used to obtain\nfurther necessary and sufficient conditions, in terms of a no-free-lunch-type\nnotion. In particular, the full strength of the \"No Free Lunch with Vanishing\nRisk\" (NFLVR) is not needed, only the weaker \"No Unbounded Profit with Bounded\nRisk\" (NUPBR) condition that involves the boundedness in probability of the\nterminal values of wealth processes. We show that this notion is the minimal\na-priori assumption required in order to proceed with utility optimization. The\nfact that it is expressed entirely in terms of predictable characteristics\nmakes it easy to check, something that the stronger NFLVR condition lacks.\n"
    },
    {
        "paper_id": 803.189,
        "authors": "Constantinos Kardaras, Eckhard Platen",
        "title": "On the semimartingale property of discounted asset-price processes",
        "comments": "11 pages. The text has been thoroughly revised and there are new\n  results. This is the 1st part of what comprised the older arxiv submission\n  arXiv:0803.1890 \"On financial markets where only buy-and-hold trading is\n  possible\" by the two authors",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A financial market model where agents trade using realistic combinations of\nbuy-and-hold strategies is considered. Minimal assumptions are made on the\ndiscounted asset-price process - in particular, the semimartingale property is\nnot assumed. Via a natural market viability assumption, namely, absence of\narbitrages of the first kind, we establish that discounted asset-prices have to\nbe semimartingales. In a slightly more specialized case, we extend the previous\nresult in a weakened version of the Fundamental Theorem of Asset Pricing that\ninvolves strictly positive supermartingale deflators rather than Equivalent\nMartingale Measures.\n"
    },
    {
        "paper_id": 803.1916,
        "authors": "Masa-aki Taniguchi, Masako Bando, and Akihiro Nakayama",
        "title": "Business Cycle and Conserved Quantity in Economics",
        "comments": "13 pages and 10 figures",
        "journal-ref": null,
        "doi": "10.1143/JPSJ.77.114001",
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  We propose a dynamical model for business cycle based on an optimal DI model.\nIn the model there exists a conserved quantity, which corresponds to the total\nenergy in a dynamical system. We found that the business cycle with the period\n6 or 7 years is nicely reproduced, since the model predicts a periodic motion\nin the conservative system.\n"
    },
    {
        "paper_id": 803.2169,
        "authors": "Constantinos Kardaras",
        "title": "No-Free-Lunch equivalences for exponential Levy models",
        "comments": "29 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide equivalence of numerous no-free-lunch type conditions for\nfinancial markets where the asset prices are modeled as exponential Levy\nprocesses, under possible convex constraints in the use of investment\nstrategies. The general message is the following: if any kind of free lunch\nexists in these models it has to be of the most egregious type, generating an\nincreasing ealth. Furthermore, we connect the previous to the existence of the\nnumeraire portfolio, both for its particular expositional clarity in\nexponential Levy models and as a first step in obtaining analogues of the\nno-free-lunch equivalences in general semimartingale models.\n"
    },
    {
        "paper_id": 803.2198,
        "authors": "Michail Anthropelos and Gordan Zitkovic",
        "title": "On Agents' Agreement and Partial-Equilibrium Pricing in Incomplete\n  Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider two risk-averse financial agents who negotiate the price of an\nilliquid indivisible contingent claim in an incomplete semimartingale market\nenvironment. Under the assumption that the agents are exponential utility\nmaximizers with non-traded random endowments, we provide necessary and\nsufficient conditions for negotiation to be successful, i.e., for the trade to\noccur. We also study the asymptotic case where the size of the claim is small\ncompared to the random endowments and we give a full characterization in this\ncase. Finally, we study a partial-equilibrium problem for a bundle of divisible\nclaims and establish existence and uniqueness. A number of technical results on\nconditional indifference prices are provided.\n"
    },
    {
        "paper_id": 803.2201,
        "authors": "Gur Yaari, Andrzej Nowak, Kamil Rakocy and Sorin Solomon",
        "title": "Microscopic Study Reveals the Singular Origins of Growth",
        "comments": "20 pages, 6 figures",
        "journal-ref": "EPJB 2008",
        "doi": "10.1140/epjb/e2008-00189-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  P.W. Anderson proposed the concept of complexity in order to describe the\nemergence and growth of macroscopic collective patterns out of the simple\ninteractions of many microscopic agents. In the physical sciences this paradigm\nwas implemented systematically and confirmed repeatedly by successful\nconfrontation with reality. In the social sciences however, the possibilities\nto stage experiments to validate it are limited. During the 90's a series of\ndramatic political and economic events have provided the opportunity to do so.\nWe exploit the resulting empirical evidence to validate a simple agent based\nalternative to the classical logistic dynamics. The post-liberalization\nempirical data from Poland confirm the theoretical prediction that the dynamics\nis dominated by singular rare events which insure the resilience and\nadaptability of the system. We have shown that growth is led by few singular\n\"growth centers\" (Figure 1), that initially developed at a tremendous rate\n(Figure3), followed by a diffusion process to the rest of the country and\nleading to a positive growth rate uniform across the counties. In addition to\nthe interdisciplinary unifying potential of our generic formal approach, the\npresent work reveals the strong causal ties between the \"softer\" social\nconditions and their \"hard\" economic consequences.\n"
    },
    {
        "paper_id": 803.2283,
        "authors": "Imre Kondor and Istvan Varga-Haszonits",
        "title": "Feasibility of Portfolio Optimization under Coherent Risk Measures",
        "comments": "13 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is shown that the axioms for coherent risk measures imply that whenever\nthere is an asset in a portfolio that dominates the others in a given sample\n(which happens with finite probability even for large samples), then this\nportfolio cannot be optimized under any coherent measure on that sample, and\nthe risk measure diverges to minus infinity. This instability was first\ndiscovered on the special example of Expected Shortfall which is used here both\nas an illustration and as a prompt for generalization.\n"
    },
    {
        "paper_id": 803.2302,
        "authors": "Z. Jiang and M.R. Pistorius",
        "title": "On perpetual American put valuation and first-passage in a\n  regime-switching model with jumps",
        "comments": "22 pages, 3 figures. Tp appear in Finance and Stochastics,",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider the problem of pricing a perpetual American put\noption in an exponential regime-switching L\\'{e}vy model. For the case of the\n(dense) class of phase-type jumps and finitely many regimes we derive an\nexplicit expression for the value function. The solution of the corresponding\nfirst passage problem under a state-dependent level rests on a path\ntransformation and a new matrix Wiener-Hopf factorization result for this class\nof processes.\n"
    },
    {
        "paper_id": 803.2388,
        "authors": "M. Vahabi, G. R. Jafari",
        "title": "Quantitative analysis of privatization",
        "comments": "25 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In recent years, the economic policy of privatization, which is defined as\nthe transfer of property or responsibility from public sector to private\nsector, is one of the global phenomenon that increases use of markets to\nallocate resources. One important motivation for privatization is to help\ndevelop factor and product markets, as well as security markets. Progress in\nprivatization is correlated with improvements in perceived political and\ninvestment risk. Many emerging countries have gradually reduced their political\nrisks during the course of sustained privatization. In fact, most risk\nresolution seems to take place as privatization proceeds to its later stage.\nAlternative benefits of privatization are improved risk sharing and increased\nliquidity and activity of the market. One of the main methods to develop\nprivatization is entering a new stock to the markets for arising competition.\nHowever, attention to the capability of the markets to accept a new stock is\nsubstantial. Without considering the above statement, it is possible to reduce\nthe market's efficiency. In other words, introduction of a new stock to the\nmarket usually decreases the stage of development and activity and increases\nthe risk. Based on complexity theory, we quantify how the following factors:\nstage of development, activity, risk and investment horizons play roles in the\nprivatization.\n"
    },
    {
        "paper_id": 803.2635,
        "authors": "Alexandre Souto Martinez, Rodrigo Silva Gonzalez and Cesar Augusto\n  Sangaletti Tercariol",
        "title": "Continuous growth models in terms of generalized logarithm and\n  exponential functions",
        "comments": "7 pages, 1 table and 1 figure",
        "journal-ref": "Physica A 387 (2008) 5679--5687",
        "doi": "10.1016/j.physa.2008.06.015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider the one-parameter generalizations of the logarithmic and exponential\nfunctions which are obtained from the integration of non-symmetrical\nhyperboles. These generalizations coincide to the one obtained in the context\nof non-extensive thermostatistics. We show that these functions are suitable to\ndescribe and unify the great majority of continuous growth models, which we\nbriefly review. Physical interpretation to the generalization function\nparameter is given for the Richards' model, which has an underlying microscopic\nmodel to justify it.\n"
    },
    {
        "paper_id": 803.2773,
        "authors": "Wei-Xing Zhou (ECUST)",
        "title": "Multifractal detrended cross-correlation analysis for two nonstationary\n  signals",
        "comments": "4 RevTex pages including 6 eps figures",
        "journal-ref": "Physical Review E 77 (6), 066211 (2008).",
        "doi": "10.1103/PhysRevE.77.066211",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is ubiquitous in natural and social sciences that two variables, recorded\ntemporally or spatially in a complex system, are cross-correlated and possess\nmultifractal features. We propose a new method called multifractal detrended\ncross-correlation analysis (MF-DXA) to investigate the multifractal behaviors\nin the power-law cross-correlations between two records in one or higher\ndimensions. The method is validated with cross-correlated 1D and 2D binomial\nmeasures and multifractal random walks. Application to two financial time\nseries is also illustrated.\n"
    },
    {
        "paper_id": 803.2996,
        "authors": "J. Doyne Farmer and John Geanakoplos",
        "title": "The virtues and vices of equilibrium and the future of financial\n  economics",
        "comments": "68 pages, one figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The use of equilibrium models in economics springs from the desire for\nparsimonious models of economic phenomena that take human reasoning into\naccount. This approach has been the cornerstone of modern economic theory. We\nexplain why this is so, extolling the virtues of equilibrium theory; then we\npresent a critique and describe why this approach is inherently limited, and\nwhy economics needs to move in new directions if it is to continue to make\nprogress. We stress that this shouldn't be a question of dogma, but should be\nresolved empirically. There are situations where equilibrium models provide\nuseful predictions and there are situations where they can never provide useful\npredictions. There are also many situations where the jury is still out, i.e.,\nwhere so far they fail to provide a good description of the world, but where\nproper extensions might change this. Our goal is to convince the skeptics that\nequilibrium models can be useful, but also to make traditional economists more\naware of the limitations of equilibrium models. We sketch some alternative\napproaches and discuss why they should play an important role in future\nresearch in economics.\n"
    },
    {
        "paper_id": 803.3093,
        "authors": "Robert Fernholz, Ioannis Karatzas, Constantinos Kardaras",
        "title": "Diversity and relative arbitrage in equity markets",
        "comments": "28 pages",
        "journal-ref": "Finance & Stochastics. Volume 9, Number 1 / January, 2005",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A financial market is called \"diverse\" if no single stock is ever allowed to\ndominate the entire market in terms of relative capitalization. In the context\nof the standard Ito-process model initiated by Samuelson (1965) we formulate\nthis property (and the allied, successively weaker notions of \"weak diversity\"\nand \"asymptotic weak diversity\") in precise terms. We show that diversity is\npossible to achieve, but delicate. Several illustrative examples are provided,\nwhich demonstrate that weakly-diverse financial markets contain relative\narbitrage opportunities: it is possible to outperform (or underperform) such\nmarkets over sufficiently long time-horizons, and to underperform them\nsignificantly over arbitrary time-horizons. The existence of such relative\narbitrage does not interfere with the development of option pricing, and has\ninteresting consequences for the pricing of long-term warrants and for put-call\nparity. Several open questions are suggested for further study.\n"
    },
    {
        "paper_id": 803.359,
        "authors": "Alexander Weiss",
        "title": "Escaping the Brownian stalkers",
        "comments": "AMS-LaTeX v2.0, 21 pages with 8 eps-figures, uses psfrag.sty",
        "journal-ref": "Electron. J. Probab. 14 (2009) 139-160",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a simple model for the behaviour of longterm investors on a stock\nmarket, consisting of three particles, which represent the current price of the\nstock and the opinion of the buyers, respectively sellers, about the right\ntrading price. As time evolves, both groups of traders update their opinions\nwith respect to the current price. The update speed is controled by a parameter\n$\\gamma$, the price process is described by a geometric Brownian motion. We\nconsider the stability of the market in terms of the distance between the\nbuyers' and sellers' opinion, and prove that the distance process is\nrecurrent/transient in dependence on $\\gamma$.\n"
    },
    {
        "paper_id": 803.3733,
        "authors": "\\'Eva R\\'acz, Zolt\\'an Eisler, J\\'anos Kert\\'esz",
        "title": "Comment on ``Tests of scaling and universality of the distributions of\n  trade size and share volume: Evidence from three distinct markets\" by Plerou\n  and Stanley, Phys. Rev. E 76, 046109 (2007)",
        "comments": "1 page, 1 figure",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.79.068101",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Comment on ``Tests of scaling and universality of the distributions of trade\nsize and share volume: Evidence from three distinct markets\" by Plerou and\nStanley, Phys. Rev. E 76, 046109 (2007)\n"
    },
    {
        "paper_id": 803.3884,
        "authors": "Pawe{\\l} Sieczka, Janusz A. Ho{\\l}yst",
        "title": "Correlations in commodity markets",
        "comments": null,
        "journal-ref": "Physica A 388 (2009) 1621-1630",
        "doi": "10.1016/j.physa.2009.01.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we analyzed dependencies in commodity markets investigating\ncorrelations of future contracts for commodities over the period 1998.09.01 -\n2007.12.14. We constructed a minimal spanning tree based on the correlation\nmatrix. The tree provides evidence for sector clusterization of investigated\ncontracts. We also studied dynamical properties of commodity dependencies. It\nturned out that the market was constantly getting more correlated within the\ninvestigated period, although the increase of correlation was distributed\nnonuniformly among all contracts, and depended on contracts branches.\n"
    },
    {
        "paper_id": 803.3902,
        "authors": "Urna Basu and P. K. Mohanty",
        "title": "Modeling wealth distribution in growing markets",
        "comments": "5 pages, 4 eps figures, revtex4",
        "journal-ref": "Eur. Phys. J. B 65, 585 (2008)",
        "doi": "10.1140/epjb/e2008-00372-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce an auto-regressive model which captures the growing nature of\nrealistic markets. In our model agents do not trade with other agents, they\ninteract indirectly only through a market. Change of their wealth depends,\nlinearly on how much they invest, and stochastically on how much they gain from\nthe noisy market. The average wealth of the market could be fixed or growing.\nWe show that in a market where investment capacity of agents differ, average\nwealth of agents generically follow the Pareto-law. In few cases, the\nindividual distribution of wealth of every agent could also be obtained\nexactly. We also show that the underlying dynamics of other well studied\nkinetic models of markets can be mapped to the dynamics of our auto-regressive\nmodel.\n"
    },
    {
        "paper_id": 803.3959,
        "authors": "Joseph L. McCauley, Kevin E. Bassler, and Gemunu H. Gunaratne",
        "title": "Integration I(d) of Nonstationary Time Series: Stationary and\n  nonstationary increments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The method of cointegration in regression analysis is based on an assumption\nof stationary increments. Stationary increments with fixed time lag are called\nintegration I(d). A class of regression models where cointegration works was\nidentified by Granger and yields the ergodic behavior required for equilibrium\nexpectations in standard economics. Detrended finance market returns are\nmartingales, and martingales do not satisfy regression equations. We extend the\nstandard discussion to discover the class of detrended processes beyond\nstandard regression models that satisfy integration I(d). In the language of\neconometrics, the models of interest are unit root models, meaning martingales.\nTypical martingales do not have stationary increments, and those that do\ngenerally do not admit ergodicity. Our analysis leads us to comment on the lack\nof equilibrium observed earlier between FX rates and relative price levels.\n"
    },
    {
        "paper_id": 803.4046,
        "authors": "Dapeng CAI (1), Takashi Gyoshin NITTA (2) ((1) Institute for Advanced\n  Research, Nagoya University, Nagoya, Japan, (2) Department of Mathematics,\n  Faculty of Education, Mie University, Tsu, Japan)",
        "title": "Constructing the Optimal Solutions to the Undiscounted Continuous-Time\n  Infinite Horizon Optimization Problems",
        "comments": null,
        "journal-ref": "Nonlinear Analysis: Theory, Methods & Applications, Volume 71,\n  Issue 12, 15 December 2009, Pages e2103-e2108",
        "doi": "10.1016/j.na.2009.03.066",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We aim to construct the optimal solutions to the undiscounted continuous-time\ninfinite horizon optimization problems, the objective functionals of which may\nbe unbounded. We identify the condition under which the limit of the solutions\nto the finite horizon problems is optimal for the infinite horizon problems\nunder the overtaking criterion.\n"
    },
    {
        "paper_id": 803.405,
        "authors": "Dapeng CAI (1), Takashi Gyoshin NITTA (2) ((1) Institute for Advanced\n  Research, Nagoya University, Nagoya, Japan, (2) Department of Mathematics,\n  Faculty of Education, Mie University, Tsu, Japan)",
        "title": "Limit of the Solutions for the Finite Horizon Problems as the Optimal\n  Solution to the Infinite Horizon Optimization Problems",
        "comments": null,
        "journal-ref": "Journal of Difference Equations and Applications Volume 17, Issue\n  3, 2011, Pages 359 - 373",
        "doi": "10.1080/10236190902953763",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We aim to generalize the results of Cai and Nitta (2007) by allowing both the\nutility and production function to depend on time. We also consider an\nadditional intertemporal optimality criterion. We clarify the conditions under\nwhich the limit of the solutions for the finite horizon problems is optimal\namong all attainable paths for the infinite horizon problems under the\novertaking criterion, as well as the conditions under which such a limit is the\nunique optimum under the sum-of-utilities criterion. The results are applied to\na parametric example of the one-sector growth model to examine the impacts of\ndiscounting on optimal paths.\n"
    },
    {
        "paper_id": 803.4282,
        "authors": "Edward W. Piotrowski, Malgorzata Schroeder, Anna Szczypinska",
        "title": "The price of bond and European option on bond without credit risk.\n  Classical look and its quantum extension",
        "comments": "17 pages, 2 figures, working paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we compare two classical one-factor diffusion models which are\nused to model the term structure of interest rates. One of them is based on the\nWiener-Bachelier process while the second one is based on the\nOrnstein-Uhlenbeck process. We show essential differences between the prices of\nEuropean call options on a zero-coupon bond in these models.\n"
    },
    {
        "paper_id": 803.4416,
        "authors": "Paolo Guasoni, Mikl\\'os R\\'asonyi, Walter Schachermayer",
        "title": "Consistent price systems and face-lifting pricing under transaction\n  costs",
        "comments": "Published in at http://dx.doi.org/10.1214/07-AAP461 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2008, Vol. 18, No. 2, 491-520",
        "doi": "10.1214/07-AAP461",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In markets with transaction costs, consistent price systems play the same\nrole as martingale measures in frictionless markets. We prove that if a\ncontinuous price process has conditional full support, then it admits\nconsistent price systems for arbitrarily small transaction costs. This result\napplies to a large class of Markovian and non-Markovian models, including\ngeometric fractional Brownian motion. Using the constructed price systems, we\nshow, under very general assumptions, the following ``face-lifting'' result:\nthe asymptotic superreplication price of a European contingent claim $g(S_T)$\nequals $\\hat{g}(S_0)$, where $\\hat{g}$ is the concave envelope of $g$ and $S_t$\nis the price of the asset at time $t$. This theorem generalizes similar results\nobtained for diffusion processes to processes with conditional full support.\n"
    },
    {
        "paper_id": 803.448,
        "authors": "Joseph L. McCauley",
        "title": "ARCH and GARCH Models vs. Martingale Volatility of Finance Market\n  Returns",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  ARCH and GARCH models assume either i.i.d. or (what economists lable as)\nwhite noise as is usual in regression analysis while assuming memory in a\nconditional mean square fluctuation with stationary increments. We will show\nthat ARCH/GARCH is inconsistent with uncorrelated increments, violating the\ni.i.d. and white assumptions and finance data and the efficient market\nhypothesis as well.\n"
    },
    {
        "paper_id": 804.0127,
        "authors": "Johannes Leitner",
        "title": "Convex pricing by a generalized entropy penalty",
        "comments": "Published in at http://dx.doi.org/10.1214/07-AAP466 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2008, Vol. 18, No. 2, 620-631",
        "doi": "10.1214/07-AAP466",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an incomplete Brownian-motion market setting, we propose a convex\nmonotonic pricing functional for nonattainable bounded contingent claims which\nis compatible with prices for attainable claims. The pricing functional is\ndefined as the convex conjugate of a generalized entropy penalty functional and\nan interpretation in terms of tracking with instantaneously vanishing risk can\nbe given.\n"
    },
    {
        "paper_id": 804.0162,
        "authors": "L. C. G. Rogers, Fanyin Zhou",
        "title": "Estimating correlation from high, low, opening and closing prices",
        "comments": "Published in at http://dx.doi.org/10.1214/07-AAP460 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2008, Vol. 18, No. 2, 813-823",
        "doi": "10.1214/07-AAP460",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In earlier studies, the estimation of the volatility of a stock using\ninformation on the daily opening, closing, high and low prices has been\ndeveloped; the additional information in the high and low prices can be\nincorporated to produce unbiased (or near-unbiased) estimators with\nsubstantially lower variance than the simple open--close estimator. This paper\ntackles the more difficult task of estimating the correlation of two stocks\nbased on the daily opening, closing, high and low prices of each. If we had\naccess to the high and low values of some linear combination of the two log\nprices, then we could use the univariate results via polarization, but this is\nnot data that is available. The actual problem is more challenging; we present\nan unbiased estimator which halves the variance.\n"
    },
    {
        "paper_id": 804.0185,
        "authors": "E. Bacry, A. Kozhemyak and J.-F. Muzy",
        "title": "Log-Normal continuous cascades: aggregation properties and estimation.\n  Application to financial time-series",
        "comments": "27 pages, 1 figure and 5 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Log-normal continuous random cascades form a class of multifractal processes\nthat has already been successfully used in various fields. Several statistical\nissues related to this model are studied. We first make a quick but extensive\nreview of their main properties and show that most of these properties can be\nanalytically studied. We then develop an approximation theory of these\nprocesses in the limit of small intermittency $\\lambda^2\\ll 1$, i.e., when the\ndegree of multifractality is small. This allows us to prove that the\nprobability distributions associated with these processes possess some very\nsimple aggregation properties accross time scales. Such a control of the\nprocess properties at different time scales, allows us to address the problem\nof parameter estimation. We show that one has to distinguish two different\nasymptotic regimes: the first one, referred to as the ''low frequency regime'',\ncorresponds to taking a sample whose overall size increases whereas the second\none, referred to as the ''high frequency regime'', corresponds to sampling the\nprocess at an increasing sampling rate. We show that, the first regime leads to\nconvergent estimators whereas, in the high frequency regime, the situation is\nmuch more intricate : only the intermittency coefficient $\\lambda^2$ can be\nestimated using a consistent estimator. However, we show that, in practical\nsituations, one can detect the nature of the asymptotic regime (low frequency\nversus high frequency) and consequently decide whether the estimations of the\nother parameters are reliable or not. We finally illustrate how both our\nresults on parameter estimation and on aggregation properties, allow one to\nsuccessfully use these models for modelization and prediction of financial time\nseries.\n"
    },
    {
        "paper_id": 804.0331,
        "authors": "Attilio L. Stella and Fulvio Baldovin",
        "title": "Role of scaling in the statistical modeling of finance",
        "comments": "Based on the Key Note lecture by A.L. Stella at the Conference on\n  ``Statistical Physics Approaches to Multi-Disciplinary Problems'', IIT\n  Guwahati, India, 7-13 January 2008",
        "journal-ref": "Pramana - Journal of Physics 71, 341 (2008)",
        "doi": "10.1007/s12043-008-0167-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Modeling the evolution of a financial index as a stochastic process is a\nproblem awaiting a full, satisfactory solution since it was first formulated by\nBachelier in 1900. Here it is shown that the scaling with time of the return\nprobability density function sampled from the historical series suggests a\nsuccessful model. The resulting stochastic process is a heteroskedastic,\nnon-Markovian martingale, which can be used to simulate index evolution on the\nbasis of an auto-regressive strategy. Results are fully consistent with\nvolatility clustering and with the multi-scaling properties of the return\ndistribution. The idea of basing the process construction on scaling, and the\nconstruction itself, are closely inspired by the probabilistic renormalization\ngroup approach of statistical mechanics and by a recent formulation of the\ncentral limit theorem for sums of strongly correlated random variables.\n"
    },
    {
        "paper_id": 804.0482,
        "authors": "Antonis Papapantoleon",
        "title": "An introduction to L\\'{e}vy processes with applications in finance",
        "comments": "50 pages, introductory lecture notes; typos corrected, change of\n  format",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  These lectures notes aim at introducing L\\'{e}vy processes in an informal and\nintuitive way, accessible to non-specialists in the field. In the first part,\nwe focus on the theory of L\\'{e}vy processes. We analyze a `toy' example of a\nL\\'{e}vy process, viz. a L\\'{e}vy jump-diffusion, which yet offers significant\ninsight into the distributional and path structure of a L\\'{e}vy process. Then,\nwe present several important results about L\\'{e}vy processes, such as infinite\ndivisibility and the L\\'{e}vy-Khintchine formula, the L\\'{e}vy-It\\^{o}\ndecomposition, the It\\^{o} formula for L\\'{e}vy processes and Girsanov's\ntransformation. Some (sketches of) proofs are presented, still the majority of\nproofs is omitted and the reader is referred to textbooks instead. In the\nsecond part, we turn our attention to the applications of L\\'{e}vy processes in\nfinancial modeling and option pricing. We discuss how the price process of an\nasset can be modeled using L\\'{e}vy processes and give a brief account of\nmarket incompleteness. Popular models in the literature are presented and\nrevisited from the point of view of L\\'{e}vy processes, and we also discuss\nthree methods for pricing financial derivatives. Finally, some indicative\nevidence from applications to market data is presented.\n"
    },
    {
        "paper_id": 804.09,
        "authors": "Alexander Shapovalov, Andrey Trifonov and Elena Masalova",
        "title": "Nonlinear Fokker-Planck Equation in the Model of Asset Returns",
        "comments": "This is a contribution to the Proc. of the Seventh International\n  Conference ''Symmetry in Nonlinear Mathematical Physics'' (June 24-30, 2007,\n  Kyiv, Ukraine), published in SIGMA (Symmetry, Integrability and Geometry:\n  Methods and Applications) at http://www.emis.de/journals/SIGMA/",
        "journal-ref": "SIGMA 4 (2008), 038, 10 pages",
        "doi": "10.3842/SIGMA.2008.038",
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  The Fokker-Planck equation with diffusion coefficient quadratic in space\nvariable, linear drift coefficient, and nonlocal nonlinearity term is\nconsidered in the framework of a model of analysis of asset returns at\nfinancial markets. For special cases of such a Fokker-Planck equation we\ndescribe a construction of exact solution of the Cauchy problem. In the general\ncase, we construct the leading term of the Cauchy problem solution asymptotic\nin a formal small parameter in semiclassical approximation following the\ncomplex WKB-Maslov method in the class of trajectory concentrated functions.\n"
    },
    {
        "paper_id": 804.0902,
        "authors": "Joseph L. McCauley",
        "title": "Time vs. Ensemble Averages for Nonstationary Time Series",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.05.057",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the question whether sliding window time averages applied to\nstationary increment processes converge to a limit in probability. The question\ncenters on averages, correlations, and densities constructed via time averages\nof the increment x(t,T)=x(t+T)-x(t)and the assumption is that the increment is\ndistributed independently of t. We show that the condition for applying\nTchebyshev's Theorem to time averages of functions of stationary increments is\nstrongly violated. We argue that, for both stationary and nonstationary\nincrements, Tchebyshev's Theorem provides the basis for constructing emsemble\naverages and densities from a single, historic time series if, as in FX\nmarkets, the series shows a definite statistical periodicity on the average.\n"
    },
    {
        "paper_id": 804.1039,
        "authors": "Peter Spreij, Enno Veerman, Peter Vlaar",
        "title": "Multivariate Feller conditions in term structure models: Why do(n't) we\n  care?",
        "comments": "19 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, the relevance of the Feller conditions in discrete time\nmacro-finance term structure models is investigated. The Feller conditions are\nusually imposed on a continuous time multivariate square root process to ensure\nthat the roots have nonnegative arguments. For a discrete time approximate\nmodel, the Feller conditions do not give this guarantee. Moreover, in a\nmacro-finance context the restrictions imposed might be economically\nunappealing. At the same time, it has also been observed that even without the\nFeller conditions imposed, for a practically relevant term structure model,\nnegative arguments rarely occur. Using models estimated on German data, we\ncompare the yields implied by (approximate) analytic exponentially affine\nexpressions to those obtained through Monte Carlo simulations of very high\nnumbers of sample paths. It turns out that the differences are rarely\nstatistically significant, whether the Feller conditions are imposed or not.\nMoreover, economically the differences are negligible, as they are always below\none basis point.\n"
    },
    {
        "paper_id": 804.1229,
        "authors": "Linyuan L\\\"u, Matus Medo, Yi-Cheng Zhang, Damien Challet",
        "title": "Emergence of product differentiation from consumer heterogeneity and\n  asymmetric information",
        "comments": "12 pages, 12 figures",
        "journal-ref": "European Physical Journal B 64, 293-300 (2008)",
        "doi": "10.1140/epjb/e2008-00289-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a fully probabilistic framework of consumer product choice based\non quality assessment. It allows us to capture many aspects of marketing such\nas partial information asymmetry, quality differentiation, and product\nplacement in a supermarket.\n"
    },
    {
        "paper_id": 804.1414,
        "authors": "Sascha Kurz and Joerg Rambau",
        "title": "Demand forecasting for companies with many branches, low sales numbers\n  per product, and non-recurring orderings",
        "comments": "6 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose the new Top-Dog-Index to quantify the historic deviation of the\nsupply data of many small branches for a commodity group from sales data. On\nthe one hand, the common parametric assumptions on the customer demand\ndistribution in the literature could not at all be supported in our real-world\ndata set. On the other hand, a reasonably-looking non-parametric approach to\nestimate the demand distribution for the different branches directly from the\nsales distribution could only provide us with statistically weak and unreliable\nestimates for the future demand. Based on real-world sales data from our\nindustry partner we provide evidence that our Top-Dog-Index is statistically\nrobust. Using the Top-Dog-Index, we propose a heuristics to improve the\nbranch-dependent proportion between supply and demand. Our approach cannot\nestimate the branch-dependent demand directly. It can, however, classify the\nbranches into a given number of clusters according to an historic oversupply or\nundersupply. This classification of branches can iteratively be used to adapt\nthe branch distribution of supply and demand in the future.\n"
    },
    {
        "paper_id": 804.1642,
        "authors": "Jir\\^o Akahori, Yuuki Kanishi, Yuichi Morimura",
        "title": "Calibration of transparency risks: a note",
        "comments": "11pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this research is to give a simple framework to evaluate/quantize\nthe \"transparency\" of a firm. We assume that the process of the firm value is\nonly observable once in a while but is strongly correlated with the stock price\nwhich is observable and tradable. This hybrid type structure make the\ntransparency \"observable\". The implication of the present study is that the\ndepth of the shock to the market caused by the precise accounting information\ndoes reflect the degree of transparency. Furthermore, it can be quantized\nresorting to the calibration method.\n"
    },
    {
        "paper_id": 804.1837,
        "authors": "Kumiko Hattori, Tetsuya Hattori",
        "title": "Mathematical analysis of long tail economy using stochastic ranking\n  processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new method of estimating the distribution of sales rates of,\ne.g., book titles at an online bookstore, from the time evolution of ranking\ndata found at websites of the store. The method is based on new mathematical\nresults on an infinite particle limit of the stochastic ranking process, and is\nsuitable for quantitative studies of the long tail structure of online retails.\nWe give an example of a fit to the actual data obtained from Amazon.co.jp,\nwhich gives the Pareto slope parameter of the distribution of sales rates of\nthe book titles in the store.\n"
    },
    {
        "paper_id": 804.2064,
        "authors": "Sergio Arianos and Anna Carbone",
        "title": "Cross-correlation of long-range correlated series",
        "comments": "14 pages, 8 figures",
        "journal-ref": "J. Stat. Mech. (2009) P03037",
        "doi": "10.1088/1742-5468/2009/03/P03037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A method for estimating the cross-correlation $C_{xy}(\\tau)$ of long-range\ncorrelated series $x(t)$ and $y(t)$, at varying lags $\\tau$ and scales $n$, is\nproposed. For fractional Brownian motions with Hurst exponents $H_1$ and $H_2$,\nthe asymptotic expression of $C_{xy}(\\tau)$ depends only on the lag $\\tau$\n(wide-sense stationarity) and scales as a power of $n$ with exponent\n${H_1+H_2}$ for $\\tau\\to 0$. The method is illustrated on (i) financial series,\nto show the leverage effect; (ii) genomic sequences, to estimate the\ncorrelations between structural parameters along the chromosomes.\n"
    },
    {
        "paper_id": 804.2441,
        "authors": "Donatello W. Materassi and Giacomo W. Innocenti",
        "title": "Topological identification in networks of dynamical systems",
        "comments": "9 pages, 3 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper deals with the problem of reconstructing the topological structure\nof a network of dynamical systems. A distance function is defined in order to\nevaluate the \"closeness\" of two processes and a few useful mathematical\nproperties are derived. Theoretical results to guarantee the correctness of the\nidentification procedure for networked linear systems with tree topology are\nprovided as well. Finally, the application of the techniques to the analysis of\nan actual complex network, i.e. to high frequency time series of the stock\nmarket, is illustrated.\n"
    },
    {
        "paper_id": 804.2561,
        "authors": "Nicole El Karoui, Asma Meziou",
        "title": "Max-Plus decomposition of supermartingales and convex order. Application\n  to American options and portfolio insurance",
        "comments": "Published in at http://dx.doi.org/10.1214/009117907000000222 the\n  Annals of Probability (http://www.imstat.org/aop/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Probability 2008, Vol. 36, No. 2, 647-697",
        "doi": "10.1214/009117907000000222",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We are concerned with a new type of supermartingale decomposition in the\nMax-Plus algebra, which essentially consists in expressing any supermartingale\nof class $(\\mathcal{D})$ as a conditional expectation of some running supremum\nprocess. As an application, we show how the Max-Plus supermartingale\ndecomposition allows, in particular, to solve the American optimal stopping\nproblem without having to compute the option price. Some illustrative examples\nbased on one-dimensional diffusion processes are then provided. Another\ninteresting application concerns the portfolio insurance. Hence, based on the\n``Max-Plus martingale,'' we solve in the paper an optimization problem whose\naim is to find the best martingale dominating a given floor process (on every\nintermediate date), w.r.t. the convex order on terminal values.\n"
    },
    {
        "paper_id": 804.2589,
        "authors": "Josep Perello, Ronnie Sircar, Jaume Masoliver",
        "title": "Option pricing under stochastic volatility: the exponential\n  Ornstein-Uhlenbeck model",
        "comments": "26 pages, 6 colored figures",
        "journal-ref": "J. Stat. Mech. (2008) P06010",
        "doi": "10.1088/1742-5468/2008/06/P06010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the pricing problem for a European call option when the volatility\nof the underlying asset is random and follows the exponential\nOrnstein-Uhlenbeck model. The random diffusion model proposed is a\ntwo-dimensional market process that takes a log-Brownian motion to describe\nprice dynamics and an Ornstein-Uhlenbeck subordinated process describing the\nrandomness of the log-volatility. We derive an approximate option price that is\nvalid when (i) the fluctuations of the volatility are larger than its normal\nlevel, (ii) the volatility presents a slow driving force toward its normal\nlevel and, finally, (iii) the market price of risk is a linear function of the\nlog-volatility. We study the resulting European call price and its implied\nvolatility for a range of parameters consistent with daily Dow Jones Index\ndata.\n"
    },
    {
        "paper_id": 804.2772,
        "authors": "M. Marsili",
        "title": "A note on wealth in a volatile economy",
        "comments": "7 pages no figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I show that if the capital accumulation dynamics is stochastic a new term, in\naddition to that given by accounting prices, has to be introduced in order to\nderive a correct estimate of the genuine wealth of an economy. In a simple\nmodel with multiplicative accumulation dynamics I show that: 1) the value\nfunction is always a decreasing function of volatility 2) the accounting prices\nare affected by volatility 3) the new term always gives a negative contribution\nto wealth changes. I discuss results for models with constant elasticity\nutility functions. When the elasticity of marginal utility is larger than one,\naccounting prices increase with volatility whereas when it is less than one\naccounting prices decrease with volatility. These conclusions are not altered\nwhen adopting optimal saving rates.\n"
    },
    {
        "paper_id": 804.2912,
        "authors": "Constantinos Kardaras",
        "title": "The continuous behavior of the numeraire portfolio under small changes\n  in information structure, probabilistic views and investment constraints",
        "comments": "16 pages; revised version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The numeraire portfolio in a financial market is the unique positive wealth\nprocess that makes all other nonnegative wealth processes, when deflated by it,\nsupermartingales. The numeraire portfolio depends on market characteristics,\nwhich include: (a) the information flow available to acting agents, given by a\nfiltration; (b) the statistical evolution of the asset prices and, more\ngenerally, the states of nature, given by a probability measure; and (c)\npossible restrictions that acting agents might be facing on available\ninvestment strategies, modeled by a constraints set. In a financial market with\ncontinuous-path asset prices, we establish the stable behavior of the numeraire\nportfolio when each of the aforementioned market parameters is changed in an\ninfinitesimal way.\n"
    },
    {
        "paper_id": 804.3209,
        "authors": "Hirbod Assa",
        "title": "Convex Risk Measures: Lebesgue Property on one Period and Multi Period\n  Risk Measures and Application in Capital Allocation Problem",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we study the Lebesgue property for convex risk measures on the\nspace of bounded c\\`adl\\`ag random processes ($\\mathcal{R}^\\infty$). Lebesgue\nproperty has been defined for one period convex risk measures in \\cite{Jo} and\nearlier had been studied in \\cite{De} for coherent risk measures. We introduce\nand study the Lebesgue property for convex risk measures in the multi period\nframework. We give presentation of all convex risk measures with Lebesgue\nproperty on bounded c\\`adl\\`ag processes. To do that we need to have a complete\ndescription of compact sets of $\\mathcal{A}^1$. The main mathematical\ncontribution of this paper is the characterization of the compact sets of\n$\\mathcal{A}^p$ (including $\\mathcal{A}^1$). At the final part of this paper,\nwe will solve the Capital Allocation Problem when we work with coherent risk\nmeasures.\n"
    },
    {
        "paper_id": 804.3431,
        "authors": "Zhi-Qiang Jiang (ECUST), Wei Chen (SZSE), Wei-Xing Zhou (ECUST)",
        "title": "Scaling in the distribution of intertrade durations of Chinese stocks",
        "comments": "16 elsart pages including 3 eps figures",
        "journal-ref": "Physica A 387 (23), 5818-5825 (2008)",
        "doi": "10.1016/j.physa.2008.06.039",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The distribution of intertrade durations, defined as the waiting times\nbetween two consecutive transactions, is investigated based upon the limit\norder book data of 23 liquid Chinese stocks listed on the Shenzhen Stock\nExchange in the whole year 2003. A scaling pattern is observed in the\ndistributions of intertrade durations, where the empirical density functions of\nthe normalized intertrade durations of all 23 stocks collapse onto a single\ncurve. The scaling pattern is also observed in the intertrade duration\ndistributions for filled and partially filled trades and in the conditional\ndistributions. The ensemble distributions for all stocks are modeled by the\nWeibull and the Tsallis $q$-exponential distributions. Maximum likelihood\nestimation shows that the Weibull distribution outperforms the $q$-exponential\nfor not-too-large intertrade durations which account for more than 98.5% of the\ndata. Alternatively, nonlinear least-squares estimation selects the\n$q$-exponential as a better model, in which the optimization is conducted on\nthe distance between empirical and theoretical values of the logarithmic\nprobability densities. The distribution of intertrade durations is Weibull\nfollowed by a power-law tail with an asymptotic tail exponent close to 3.\n"
    },
    {
        "paper_id": 804.3658,
        "authors": "S. I. Chernyshov, V. S. Ponomarenko, and A. V. Voronin",
        "title": "The Problem of Modelling of Economic Dynamics in Differential Form",
        "comments": "36 pages; made minor textual corrections",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Traditional models of macroeconomic dynamics are fundamentally incorrect. The\nreason lies in a misunderstanding of peculiarities of the analysis of\ninfinitesimal quantities. However, even those types of solutions that are\nenvisaged by the above-mentioned models are nonrepresentative in the sense of\nthe reflection of realities. It became obvious that the techniques of the\ntheory of linear differential equations were insufficient here. Accordingly,\nthe scientists' attention switched to the theory of nonlinear differential\nequations. At the same time, balance and, accordingly, the model with matrix\nproperties are objectively inherent in the economic system. For the reduction\nof this model to a differential form, there exist rather elementary means that\nproved to be unclaimed. Macroeconomic rhetoric - the power of the accelerator,\na lag on the part of demand, etc. - accompanied by the use of a lot of abstract\ncoefficients prevailed. However, there is no organic interrelation between\nmatrix and nonlinear differential equations. On the contrary, it can be said\nthat linear theory of integral equations originated in matrix analysis. The\nFredholm linear integral equation of the second kind with a parameter-dependent\nkernel proves to be rather representative with regard to the class of possible\nsolutions. It seems that it can be used for the description of any zigzags of\nthe economy. The price one has to pay for this is the nontriviality of existing\ntheory.\n"
    },
    {
        "paper_id": 804.3818,
        "authors": "Austin Gerig",
        "title": "A Theory for Market Impact: How Order Flow Affects Stock Price",
        "comments": "PhD Thesis, University of Illinois at Urbana-Champaign (2007), 124\n  pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is known that the impact of transactions on stock price (market impact) is\na concave function of the size of the order, but there exists little\nquantitative theory that suggests why this is so. I develop a quantitative\ntheory for the market impact of hidden orders (orders that reflect the true\nintention of buying and selling) that matches the empirically measured result\nand that reproduces some of the non-trivial and universal properties of stock\nreturns (returns are percent changes in stock price). The theory is based on a\nsimple premise, that the stock market can be modeled in a mechanical way - as a\ndevice that translates order flow into an uncorrelated price stream. Given that\norder flow is highly autocorrelated, this premise requires that market impact\n(1) depends on past order flow and (2) is asymmetric for buying and selling. I\nderive the specific form for the dependence in (1) by assuming that current\nliquidity responds to information about all currently active hidden orders\n(liquidity is a measure of the price response to a transaction of a given\nsize). This produces an equation that suggests market impact should scale\nlogarithmically with total order size. Using data from the London Stock\nExchange I empirically measure market impact and show that the result matches\nthe theory. Also using empirical data, I qualitatively specify the asymmetry of\n(2). Putting all results together, I form a model for market impact that\nreproduces three universal properties of stock returns - that returns are\nuncorrelated, that returns are distributed with a power law tail, and that the\nmagnitude of returns is highly autocorrelated (also known as clustered\nvolatility).\n"
    },
    {
        "paper_id": 804.39,
        "authors": "D. Goreac",
        "title": "Insurance, Reinsurance and Dividend Payment",
        "comments": "26 pages, submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to introduce an insurance model allowing reinsurance\nand dividend payment. Our model deals with several homogeneous contracts and\ntakes into account the legislation regarding the provisions to be justified by\nthe insurance companies. This translates into some restriction on the (maximal)\nnumber of contracts the company is allowed to cover. We deal with a controlled\njump process in which one has free choice of retention level and dividend\namount. The value function is given as the maximized expected discounted\ndividends. We prove that this value function is a viscosity solution of some\nfirst-order Hamilton-Jacobi-Bellman variational inequality. Moreover, a\nuniqueness result is provided.\n"
    },
    {
        "paper_id": 804.4081,
        "authors": "Amir Bashan, Ronny Bartsch, Jan W. Kantelhardt, and Shlomo Havlin",
        "title": "Comparison of detrending methods for fluctuation analysis",
        "comments": "20 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.04.023",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We examine several recently suggested methods for the detection of long-range\ncorrelations in data series based on similar ideas as the well-established\nDetrended Fluctuation Analysis (DFA). In particular, we present a detailed\ncomparison between the regular DFA and two recently suggested methods: the\nCentered Moving Average (CMA) Method and a Modified Detrended Fluctuation\nAnalysis (MDFA). We find that CMA is performing equivalently as DFA in long\ndata with weak trends and slightly superior to DFA in short data with weak\ntrends. When comparing standard DFA to MDFA we observe that DFA performs\nslightly better in almost all examples we studied. We also discuss how several\ntypes of trends affect the different types of DFA. For weak trends in the data,\nthe new methods are comparable with DFA in these respects. However, if the\nfunctional form of the trend in data is not a-priori known, DFA remains the\nmethod of choice. Only a comparison of DFA results, using different detrending\npolynomials, yields full recognition of the trends. A comparison with\nindependent methods is recommended for proving long-range correlations.\n"
    },
    {
        "paper_id": 804.4152,
        "authors": "Z. Burda, A. Krzywicki, O.C. Martin",
        "title": "Adaptive networks of trading agents",
        "comments": "7 figures",
        "journal-ref": "Phys. Rev. E78, 046106 (2008)",
        "doi": "10.1103/PhysRevE.78.046106",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Multi-agent models have been used in many contexts to study generic\ncollective behavior. Similarly, complex networks have become very popular\nbecause of the diversity of growth rules giving rise to scale-free behavior.\nHere we study adaptive networks where the agents trade ``wealth'' when they are\nlinked together while links can appear and disappear according to the wealth of\nthe corresponding agents; thus the agents influence the network dynamics and\nvice-versa. Our framework generalizes a multi-agent model of Bouchand and\nMezard, and leads to a steady state with fluctuating connectivities. The system\nspontaneously self-organizes into a critical state where the wealth\ndistribution has a fat tail and the network is scale-free; in addition, network\nheterogeneities lead to enhanced wealth condensation.\n"
    },
    {
        "paper_id": 804.4191,
        "authors": "S.V. Panyukov",
        "title": "Theory of market fluctuations",
        "comments": "34 pages, 22 figures; added Langeven equations",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose coalescent mechanism of economic grow because of redistribution of\nexternal resources. It leads to Zipf distribution of firms over their sizes,\nturning to stretched exponent because of size-dependent effects, and predicts\nexponential distribution of income between individuals. We also present new\napproach to describe fluctuations on the market, based on separation of hot\n(short-time) and cold (long-time) degrees of freedoms, which predicts tent-like\ndistribution of fluctuations with stable tail exponent mu=3 (mu=2 for news).\nThe theory predicts observable asymmetry of the distribution, and its size\ndependence. In the case of financial markets the theory explains first time\nmarket mill patterns, conditional distribution, D-smile, z-shaped response,\nconditional double dynamics, the skewness and so on. We derive the set of\nLangeven equations, which predicts logarithmic dependence of price shift on\ntrading volume and volatility patterns after jumps. We calculate parameters of\nprice distributions, correlation functions and Hurst exponents at different\ntime scales. At large times the price experiences fractional Brownian motion\nwith chaotically switching of long-time persistent and anti-persistent\nbehavior, and we calculate corresponding probabilities, response functions, and\nrisks.\n"
    },
    {
        "paper_id": 804.4522,
        "authors": "Nikolai Dokuchaev",
        "title": "Optimal solution of investment problems via linear parabolic equations\n  generated by Kalman filter",
        "comments": "25 pages",
        "journal-ref": "SIAM J. of Control and Optimization} (2005) 44, No. 4, pp.\n  1239-1258",
        "doi": "10.1137/S036301290342557x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider optimal investment problems for a diffusion market model with\nnon-observable random drifts that evolve as an Ito's process. Admissible\nstrategies do not use direct observations of the market parameters, but rather\nuse historical stock prices. For a non-linear problem with a general\nperformance criterion, the optimal portfolio strategy is expressed via the\nsolution of a scalar minimization problem and a linear parabolic equation with\ncoefficients generated by the Kalman filter.\n"
    },
    {
        "paper_id": 805.0122,
        "authors": "N. Lazrieva, T. Toronjadze",
        "title": "Optimal Robust Mean-Variance Hedging in Incomplete Financial Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Optimal B-robust estimate is constructed for multidimensional parameter in\ndrift coefficient of diffusion type process with small noise. Optimal\nmean-variance robust (optimal V -robust) trading strategy is find to hedge in\nmean-variance sense the contingent claim in incomplete financial market with\narbitrary information structure and misspecified volatility of asset price,\nwhich is modelled by multidimensional continuous semimartingale. Obtained\nresults are applied to stochastic volatility model, where the model of latent\nvolatility process contains unknown multidimensional parameter in drift\ncoefficient and small parameter in diffusion term.\n"
    },
    {
        "paper_id": 805.054,
        "authors": "Giacomo Bormetti, Valentina Cazzola, Guido Montagna and Oreste\n  Nicrosini",
        "title": "Probability distribution of returns in the exponential\n  Ornstein-Uhlenbeck model",
        "comments": "26 pages, 9 figures and 3 tables. New section with real data analysis\n  and related references added, some minor typos corrected. Accepted for\n  publication on JSTAT",
        "journal-ref": "J. Stat. Mech. (2008) P11013",
        "doi": "10.1088/1742-5468/2008/11/P11013",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the problem of the analytical characterization of the probability\ndistribution of financial returns in the exponential Ornstein-Uhlenbeck model\nwith stochastic volatility. In this model the prices are driven by a Geometric\nBrownian motion, whose diffusion coefficient is expressed through an\nexponential function of an hidden variable Y governed by a mean-reverting\nprocess. We derive closed-form expressions for the probability distribution and\nits characteristic function in two limit cases. In the first one the\nfluctuations of Y are larger than the volatility normal level, while the second\none corresponds to the assumption of a small stationary value for the variance\nof Y. Theoretical results are tested numerically by intensive use of Monte\nCarlo simulations. The effectiveness of the analytical predictions is checked\nvia a careful analysis of the parameters involved in the numerical\nimplementation of the Euler-Maruyama scheme and is tested on a data set of\nfinancial indexes. In particular, we discuss results for the German DAX30 and\nDow Jones Euro Stoxx 50, finding a good agreement between the empirical data\nand the theoretical description.\n"
    },
    {
        "paper_id": 805.0611,
        "authors": "Daniel Sevcovic",
        "title": "Transformation methods for evaluating approximations to the optimal\n  exercise boundary for linear and nonlinear Black-Scholes equations",
        "comments": "submitted to: Nonlinear Models in Mathematical Finance: New Research\n  Trends in Option Pricing",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this survey chapter is to present a transformation technique\nthat can be used in analysis and numerical computation of the early exercise\nboundary for an American style of vanilla options that can be modelled by class\nof generalized Black-Scholes equations. We analyze qualitatively and\nquantitatively the early exercise boundary for a linear as well as a class of\nnonlinear Black-Scholes equations with a volatility coefficient which can be a\nnonlinear function of the second derivative of the option price itself. A\nmotivation for studying the nonlinear Black-Scholes equation with a nonlinear\nvolatility arises from option pricing models taking into account e.g.\nnontrivial transaction costs, investor's preferences, feedback and illiquid\nmarkets effects and risk from a volatile (unprotected) portfolio. We present a\nmethod how to transform the free boundary problem for the early exercise\nboundary position into a solution of a time depending nonlinear nonlocal\nparabolic equation defined on a fixed domain. We furthermore propose an\niterative numerical scheme that can be used in order to find an approximation\nof the free boundary. In the case of a linear Black-Scholes equation we are\nable to derive a nonlinear integral equation for the position of the free\nboundary. We present results of numerical approximation of the early exercise\nboundary for various types of linear and nonlinear Black-Scholes equations and\nwe discuss dependence of the free boundary on model parameters. Finally, we\ndiscuss an application of the transformation method for the pricing equation\nfor American type of Asian options.\n"
    },
    {
        "paper_id": 805.0618,
        "authors": "Jianming Xia",
        "title": "Risk Aversion and Portfolio Selection in a Continuous-Time Model",
        "comments": "Published in SIAM Journal on Control and Optimization after a major\n  revision",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The comparative statics of the optimal portfolios across individuals is\ncarried out for a continuous-time complete market model, where the risky assets\nprice process follows a joint geometric Brownian motion with time-dependent and\ndeterministic coefficients. It turns out that the indirect utility functions\ninherit the order of risk aversion (in the Arrow-Pratt sense) from the von\nNeumann-Morgenstern utility functions, and therefore, a more risk-averse agent\nwould invest less wealth (in absolute value) in the risky assets.\n"
    },
    {
        "paper_id": 805.0746,
        "authors": "P. Papadopoulos and A. C. C. Coolen",
        "title": "Market response to external events and interventions in spherical\n  minority games",
        "comments": "14 pages LaTeX, 5 (composite) postscript figures, submitted to\n  Journal of Physics A",
        "journal-ref": null,
        "doi": "10.1088/1751-8113/41/36/365002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We solve the dynamics of large spherical Minority Games (MG) in the presence\nof non-negligible time dependent external contributions to the overall market\nbid. The latter represent the actions of market regulators, or other major\nnatural or political events that impact on the market. In contrast to\nnon-spherical MGs, the spherical formulation allows one to derive closed\ndynamical order parameter equations in explicit form and work out the market's\nresponse to such events fully analytically. We focus on a comparison between\nthe response to stationary versus oscillating market interventions, and reveal\nprofound and partially unexpected differences in terms of transition lines and\nthe volatility.\n"
    },
    {
        "paper_id": 805.1353,
        "authors": "J. Perello, J. Masoliver, A. Kasprzak, R. Kutner",
        "title": "A model for interevent times with long tails and multifractality in\n  human communications: An application to financial trading",
        "comments": "25 pages, 10 colored figures",
        "journal-ref": "Phys. Rev. E 78, 036108 (2008)",
        "doi": "10.1103/PhysRevE.78.036108",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Social, technological and economic time series are divided by events which\nare usually assumed to be random albeit with some hierarchical structure. It is\nwell known that the interevent statistics observed in these contexts differs\nfrom the Poissonian profile by being long-tailed distributed with resting and\nactive periods interwoven. Understanding mechanisms generating consistent\nstatistics have therefore become a central issue. The approach we present is\ntaken from the Continuous Time Random Walk formalism and represents an\nanalytical alternative to models of non-trivial priority that have been\nrecently proposed. Our analysis also goes one step further by looking at the\nmultifractal structure of the interevent times of human decisions. We here\nanalyze the inter-transaction time intervals of several financial markets. We\nobserve that empirical data describes a subtle multifractal behavior. Our model\nexplains this structure by taking the pausing-time density in the form of a\nsuperstatistics where the integral kernel quantifies the heterogeneous nature\nof the executed tasks. An stretched exponential kernel provides a multifractal\nprofile valid for a certain limited range. A suggested heuristic analytical\nprofile is capable of covering a broader region.\n"
    },
    {
        "paper_id": 805.2096,
        "authors": "Ross A. Maller, Gernot M\\\"uller, Alex Szimayer",
        "title": "GARCH modelling in continuous time for irregularly spaced time series\n  data",
        "comments": "Published in at http://dx.doi.org/10.3150/07-BEJ6189 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2008, Vol. 14, No. 2, 519-542",
        "doi": "10.3150/07-BEJ6189",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The discrete-time GARCH methodology which has had such a profound influence\non the modelling of heteroscedasticity in time series is intuitively well\nmotivated in capturing many `stylized facts' concerning financial series, and\nis now almost routinely used in a wide range of situations, often including\nsome where the data are not observed at equally spaced intervals of time.\nHowever, such data is more appropriately analyzed with a continuous-time model\nwhich preserves the essential features of the successful GARCH paradigm. One\npossible such extension is the diffusion limit of Nelson, but this is\nproblematic in that the discrete-time GARCH model and its continuous-time\ndiffusion limit are not statistically equivalent. As an alternative,\nKl\\\"{u}ppelberg et al. recently introduced a continuous-time version of the\nGARCH (the `COGARCH' process) which is constructed directly from a background\ndriving L\\'{e}vy process. The present paper shows how to fit this model to\nirregularly spaced time series data using discrete-time GARCH methodology, by\napproximating the COGARCH with an embedded sequence of discrete-time GARCH\nseries which converges to the continuous-time model in a strong sense (in\nprobability, in the Skorokhod metric), as the discrete approximating grid grows\nfiner. This property is also especially useful in certain other applications,\nsuch as options pricing. The way is then open to using, for the COGARCH,\nsimilar statistical techniques to those already worked out for GARCH models and\nto illustrate this, an empirical investigation using stock index data is\ncarried out.\n"
    },
    {
        "paper_id": 805.2194,
        "authors": "Tian Qiu (NHU), Liang Guo (ECUST), Guang Chen (NHU)",
        "title": "Scaling and Memory Effect in Volatility Return Interval of the Chinese\n  Stock Market",
        "comments": "10 elsart pages including 7 eps figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.09.002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the probability distribution of the volatility return\nintervals $\\tau$ for the Chinese stock market. We rescale both the probability\ndistribution $P_{q}(\\tau)$ and the volatility return intervals $\\tau$ as\n$P_{q}(\\tau)=1/\\bar{\\tau} f(\\tau/\\bar{\\tau})$ to obtain a uniform scaling curve\nfor different threshold value $q$. The scaling curve can be well fitted by the\nstretched exponential function $f(x) \\sim e^{-\\alpha x^{\\gamma}}$, which\nsuggests memory exists in $\\tau$. To demonstrate the memory effect, we\ninvestigate the conditional probability distribution $P_{q} (\\tau|\\tau_{0})$,\nthe mean conditional interval $<\\tau|\\tau_{0}>$ and the cumulative probability\ndistribution of the cluster size of $\\tau$. The results show clear clustering\neffect. We further investigate the persistence probability distribution\n$P_{\\pm}(t)$ and find that $P_{-}(t)$ decays by a power law with the exponent\nfar different from the value 0.5 for the random walk, which further confirms\nlong memory exists in $\\tau$. The scaling and long memory effect of $\\tau$ for\nthe Chinese stock market are similar to those obtained from the United States\nand the Japanese financial markets.\n"
    },
    {
        "paper_id": 805.2477,
        "authors": "Antonios Garas, Panos Argyrakis, and Shlomo Havlin",
        "title": "The structural role of weak and strong links in a financial market\n  network",
        "comments": "To appear in EPJ-B",
        "journal-ref": "Eur. Phys. J. B 63, 265--271 (2008)",
        "doi": "10.1140/epjb/e2008-00237-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the properties of correlation based networks originating from\neconomic complex systems, such as the network of stocks traded at the New York\nStock Exchange (NYSE). The weaker links (low correlation) of the system are\nfound to contribute to the overall connectivity of the network significantly\nmore than the strong links (high correlation). We find that nodes connected\nthrough strong links form well defined communities. These communities are\nclustered together in more complex ways compared to the widely used\nclassification according to the economic activity. We find that some companies,\nsuch as General Electric (GE), Coca Cola (KO), and others, can be involved in\ndifferent communities. The communities are found to be quite stable over time.\nSimilar results were obtained by investigating markets completely different in\nsize and properties, such as the Athens Stock Exchange (ASE). The present\nmethod may be also useful for other networks generated through correlations.\n"
    },
    {
        "paper_id": 805.2713,
        "authors": "Donatello Materassi and Giacomo Innocenti",
        "title": "Coherence-based multivariate analysis of high frequency stock market\n  values",
        "comments": "4 pages and 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper tackles the problem of deriving a topological structure among stock\nprices from high frequency historical values. Similar studies using low\nfrequency data have already provided valuable insights. However, in those cases\ndata need to be collected for a longer period and then they have to be\ndetrended. An effective technique based on averaging a metric function on short\nsubperiods of the observation horizon is suggested. Since a standard\ncorrelation-based metric is not capable of catching dependencies at different\ntime instants, it is not expected to perform the best when dealing with high\nfrequency data. Hence, the choice of a more suitable metric is discussed. In\nparticular, a coherence-based metric is proposed, for it is able to detect any\npossible linear relation between two times series, even at different time\ninstants. The averaging technique is employed to analyze a set of 100 high\nvolume stocks of the New York Stock Exchange, observed during March 2008.\n"
    },
    {
        "paper_id": 805.2792,
        "authors": "Hideaki Aoyama, Hiroshi Yoshikawa, Hiroshi Iyetomi and Yoshi Fujiwara",
        "title": "Productivity Dispersion: Facts, Theory, and Implications",
        "comments": "29 pages, 12 eps figures, in AER format",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study productivity dispersions across workers, firms and industrial\nsectors. Empirical study of the Japanese data shows that they all obey the\nPareto law, and also that the Pareto index decreases with the level of\naggregation. In order to explain these two stylized facts, we propose a\ntheoretical framework built upon the basic principle of statistical physics. In\nthis framework, we employ the concept of superstatistics which accommodates\nfluctuations of aggregate demand.\n"
    },
    {
        "paper_id": 805.3071,
        "authors": "Mircea Gligor and Marcel Ausloos",
        "title": "Convergence and cluster structures in EU area according to fluctuations\n  in macroeconomic indices",
        "comments": "31 pages, 57 references,4 Tables, 7 figures; submitted to J. Economic\n  Integration",
        "journal-ref": "Journal of Economic Integration 23 (2008) 297-330",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The cluster analysis methods are used in order to perform a comparative study\nof 15 EU countries in relation with the fluctuations of some basic\nmacroeconomic indicators. The statistical distances between countries are\ncalculated for various moving time windows, and the time variation of the mean\nstatistical distance is investigated. The decreasing of the mean statistical\ndistance between EU countries is reflected in the correlated fluctuations of\nthe basic ME indicators: GDP, GDP/capita, Consumption and Investments. This\nempirical evidence can be seen as an economic aspect of globalization. The\nMoving Average Minimal Length Path (MAMLP) algorithm allows to search for a\ncluster-like structures derived both from the hierarchical organization of\ncountries and from their relative movement inside the hierarchy. It is found\nthat the strongly correlated countries with respect to GDP fluctuations can be\npartitioned into stable clusters. Some of the highly correlated countries, with\nrespect to GDP fluctuations, display strong correlations also in the Final\nConsumption Expenditure, while others are strongly correlated in Gross Capital\nFormation. On the other hand, one notices the similitude of the classifications\nregarding GDP and Net Exports fluctuations as concerns the squared sum of the\ncorrelation coefficients (so called country sensitivity). The final structure\nproves to be robust against the constant size time window moving over the\nscanned time interval. The policy implications of the above empirical results\nconcern the economic clusters arising in the presence of Marshallian\nexternalities and the relationships between trade barriers, R&D incentives and\ngrowth that must be accounted in elaborating a cluster-promotion policy.\n"
    },
    {
        "paper_id": 805.3129,
        "authors": "Anna Szczypinska, Edward W. Piotrowski",
        "title": "Deterministic definition of the capital risk",
        "comments": "9 pages,",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a look at the capital risk problem inspired by\ndeterministic, known from classical mechanics, problem of juggling. We propose\ncapital equivalents to the Newton's laws of motion and on this basis we\ndetermine the most secure form of credit repayment with regard to maximisation\nof profit. Then we extend the Newton's laws to models in linear spaces of\narbitrary dimension with the help of matrix rates of return. The matrix rates\ndescribe the evolution of multidimensional capital and they are sensitive to\nboth quantitative changes of individual elements and flows between them. This\nallows us for simultaneous analysis of evolution of complex capital in both\ncontinuous and discrete time models.\n"
    },
    {
        "paper_id": 805.3213,
        "authors": "Giovanni Arcioni",
        "title": "Using self-similarity and renormalization group to analyze time series",
        "comments": "16 pages, 9 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An algorithm based on Renormalization Group (RG) to analyze time series\nforecasting was proposed in cond-mat/0110285. In this paper we explicitly code\nand test it. We choose in particular some financial time series (stocks,\nindexes and commodities) with daily data and compute one step ahead forecasts.\nWe then construct some indicators to evaluate performances. The algorithm is\nsupposed to prescribe the future development of the time series by using the\nself-similarity property intrinsically present in RG approach. This property\ncould be potentially very attractive for the purpose of building winning\ntrading systems. We discuss some relevant points along this direction. Although\ncurrent performances have to be improved the algorithm seems quite reactive to\nvarious combinations of input parameters and different past values sequences.\nThis makes it a potentially good candidate to detect sharp market movements. We\nfinally mention current drawbacks and sketch how to improve them.\n"
    },
    {
        "paper_id": 805.3397,
        "authors": "Matus Medo, Chi Ho Yeung, Yi-Cheng Zhang",
        "title": "How to quantify the influence of correlations on investment\n  diversification",
        "comments": "14 pages, 4 figures",
        "journal-ref": "International Review of Financial Analysis 18, 34-39 (2009)",
        "doi": "10.1016/j.irfa.2009.01.001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  When assets are correlated, benefits of investment diversification are\nreduced. To measure the influence of correlations on investment performance, a\nnew quantity - the effective portfolio size - is proposed and investigated in\nboth artificial and real situations. We show that in most cases, the effective\nportfolio size is much smaller than the actual number of assets in the\nportfolio and that it lowers even further during financial crises.\n"
    },
    {
        "paper_id": 805.347,
        "authors": "Greg Leibon, Scott D. Pauls, Daniel N. Rockmore, Robert Savell",
        "title": "Topological structures in the equities market network",
        "comments": "17 pages, 4 figures, 3 tables",
        "journal-ref": null,
        "doi": "10.1073/pnas.0802806106",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new method for articulating scale-dependent topological\ndescriptions of the network structure inherent in many complex systems. The\ntechnique is based on \"Partition Decoupled Null Models,'' a new class of null\nmodels that incorporate the interaction of clustered partitions into a random\nmodel and generalize the Gaussian ensemble. As an application we analyze a\ncorrelation matrix derived from four years of close prices of equities in the\nNYSE and NASDAQ. In this example we expose (1) a natural structure composed of\ntwo interacting partitions of the market that both agrees with and generalizes\nstandard notions of scale (eg., sector and industry) and (2) structure in the\nfirst partition that is a topological manifestation of a well-known pattern of\ncapital flow called \"sector rotation.'' Our approach gives rise to a natural\nform of multiresolution analysis of the underlying time series that naturally\ndecomposes the basic data in terms of the effects of the different scales at\nwhich it clusters. The equities market is a prototypical complex system and we\nexpect that our approach will be of use in understanding a broad class of\ncomplex systems in which correlation structures are resident.\n"
    },
    {
        "paper_id": 805.3593,
        "authors": "Gao-Feng Gu (ECUST), Wei-Xing Zhou (ECUST)",
        "title": "On the probability distribution of stock returns in the Mike-Farmer\n  model",
        "comments": "16 Elsart pages including 1 table and 5 figures",
        "journal-ref": "European Physical Journal B 67(4), 585-592 (2009)",
        "doi": "10.1140/epjb/e2009-00052-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recently, Mike and Farmer have constructed a very powerful and realistic\nbehavioral model to mimick the dynamic process of stock price formation based\non the empirical regularities of order placement and cancelation in a purely\norder-driven market, which can successfully reproduce the whole distribution of\nreturns, not only the well-known power-law tails, together with several other\nimportant stylized facts. There are three key ingredients in the Mike-Farmer\n(MF) model: the long memory of order signs characterized by the Hurst index\n$H_s$, the distribution of relative order prices $x$ in reference to the same\nbest price described by a Student distribution (or Tsallis' $q$-Gaussian), and\nthe dynamics of order cancelation. They showed that different values of the\nHurst index $H_s$ and the freedom degree $\\alpha_x$ of the Student distribution\ncan always produce power-law tails in the return distribution $f(r)$ with\ndifferent tail exponent $\\alpha_r$. In this paper, we study the origin of the\npower-law tails of the return distribution $f(r)$ in the MF model, based on\nextensive simulations with different combinations of the left part $f_L(x)$ for\n$x<0$ and the right part $f_R(x)$ for $x>0$ of $f(x)$. We find that power-law\ntails appear only when $f_L(x)$ has a power-law tail, no matter $f_R(x)$ has a\npower-law tail or not. In addition, we find that the distributions of returns\nin the MF model at different timescales can be well modeled by the Student\ndistributions, whose tail exponents are close to the well-known cubic law and\nincrease with the timescale.\n"
    },
    {
        "paper_id": 805.3981,
        "authors": "Erhan Bayraktar, Virginia R. Young",
        "title": "Optimal Investment Strategy to Minimize Occupation Time",
        "comments": "Occupation time, optimal investment, stochastic control,\n  free-boundary problem",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We find the optimal investment strategy to minimize the expected time that an\nindividual's wealth stays below zero, the so-called {\\it occupation time}. The\nindividual consumes at a constant rate and invests in a Black-Scholes financial\nmarket consisting of one riskless and one risky asset, with the risky asset's\nprice process following a geometric Brownian motion. We also consider an\nextension of this problem by penalizing the occupation time for the degree to\nwhich wealth is negative.\n"
    },
    {
        "paper_id": 806.0239,
        "authors": "Amel Bentata (PMA), Marc Yor (PMA, Iuf)",
        "title": "From Black-Scholes and Dupire formulae to last passage times of local\n  martingales. Part A : The infinite time horizon",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  These notes are the first half of the contents of the course given by the\nsecond author at the Bachelier Seminar (February 8-15-22 2008) at IHP. They\nalso correspond to topics studied by the first author for her Ph.D.thesis.\n"
    },
    {
        "paper_id": 806.024,
        "authors": "M. Mania and R. Tevzadze",
        "title": "Backward Stochastic PDEs related to the utility maximization problem",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study utility maximization problem for general utility functions using\ndynamic programming approach. We consider an incomplete financial market model,\nwhere the dynamics of asset prices are described by an $R^d$-valued continuous\nsemimartingale. Under some regularity assumptions we derive backward stochastic\npartial differential equation (BSPDE) related directly to the primal problem\nand show that the strategy is optimal if and only if the corresponding wealth\nprocess satisfies a certain forward-SDE. As examples the cases of power,\nexponential and logarithmic utilities are considered.\n"
    },
    {
        "paper_id": 806.0287,
        "authors": "Simone Scotti",
        "title": "Perturbative Approach on Financial Markets",
        "comments": "23 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the point of transition between complete and incomplete financial\nmodels thanks to Dirichlet Forms methods. We apply recent techniques,\ndevelopped by Bouleau, to hedging procedures in order to perturbate parameters\nand stochastic processes, in the case of a volatility parameter fixed but\nuncertain for traders; we call this model Perturbed Black Scholes (PBS) Model.\nWe show that this model can reproduce at the same time a smile effect and a\nbid-ask spread; we exhibit the volatility function associated to the\nlocal-volatility model equivalent to PBS model when vanilla options are\nconcerned.\n  Lastly, we present a connection between Error Theory using Dirichlet Forms\nand Utility Function Theory.\n"
    },
    {
        "paper_id": 806.0307,
        "authors": "Luca Regis and Simone Scotti",
        "title": "Risk Premium Impact in the Perturbative Black Scholes Model",
        "comments": "20 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the risk premium impact in the Perturbative Black Scholes model. The\nPerturbative Black Scholes model, developed by Scotti, is a subjective\nvolatility model based on the classical Black Scholes one, where the volatility\nused by the trader is an estimation of the market one and contains measurement\nerrors. In this article we analyze the correction to the pricing formulas due\nto the presence of an underlying drift different from the risk free return. We\nprove that, under some hypothesis on the parameters, if the asset price is a\nsub-martingale under historical probability, then the implied volatility\npresents a skewed structure, and the position of the minimum depends on the\nrisk premium $\\lambda$.\n"
    },
    {
        "paper_id": 806.0932,
        "authors": "D. Lemmens, M. Wouters, J. Tempere, S. Foulon",
        "title": "A path integral approach to closed-form option pricing formulas with\n  applications to stochastic volatility and interest rate models",
        "comments": null,
        "journal-ref": "Phys. Rev. E 78, 016101 (2008).",
        "doi": "10.1103/PhysRevE.78.016101",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a path integral method to derive closed-form solutions for option\nprices in a stochastic volatility model. The method is explained in detail for\nthe pricing of a plain vanilla option. The flexibility of our approach is\ndemonstrated by extending the realm of closed-form option price formulas to the\ncase where both the volatility and interest rates are stochastic. This\nflexibility is promising for the treatment of exotic options. Our new\nanalytical formulas are tested with numerical Monte Carlo simulations.\n"
    },
    {
        "paper_id": 806.117,
        "authors": "D. Sornette (ETH Zurich), R. Woodard (ETH Zurich) and W.-X. Zhou\n  (ECUST, China)",
        "title": "The 2006-2008 Oil Bubble and Beyond",
        "comments": "4 pages; 4 figures, discussion of the oil supply-demand view point\n  and uncertainties",
        "journal-ref": "Physica A 388, 1571-1576 (2009)",
        "doi": "10.1016/j.physa.2009.01.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an analysis of oil prices in US$ and in other major currencies\nthat diagnoses unsustainable faster-than-exponential behavior. This supports\nthe hypothesis that the recent oil price run-up has been amplified by\nspeculative behavior of the type found during a bubble-like expansion. We also\nattempt to unravel the information hidden in the oil supply-demand data\nreported by two leading agencies, the US Energy Information Administration\n(EIA) and the International Energy Agency (IEA). We suggest that the found\nincreasing discrepancy between the EIA and IEA figures provides a measure of\nthe estimation errors. Rather than a clear transition to a supply restricted\nregime, we interpret the discrepancy between the IEA and EIA as a signature of\nuncertainty, and there is no better fuel than uncertainty to promote\nspeculation!\n"
    },
    {
        "paper_id": 806.2124,
        "authors": "Magda Roszczynska, Andrzej Nowak, Daniel Kamieniarz, Sorin Solomon and\n  Jorgen Vitting Andersen",
        "title": "Detecting speculative bubbles created in experiments via decoupling in\n  agent based models",
        "comments": "7 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Proving the existence of speculative financial bubbles even a posteriori has\nproven exceedingly difficult so anticipating a speculative bubble ex ante would\nat first seem an impossible task. Still as illustrated by the recent turmoil in\nfinancial markets initiated by the so called subprime crisis there is clearly\nan urgent need for new tools in our understanding and handling of financial\nspeculative bubbles. In contrast to periods of fast growth, the nature of\nmarket dynamics profoundly changes during speculative bubbles where self\ncontained strategies often leads to unconditional buying. A critical question\nis therefore whether such a signature can be quantified, and if so, used in the\nunderstanding of what are the sufficient and necessary conditions in the\ncreation of a speculative bubble. Here we show a new technique, based on agent\nbased simulations, gives a robust measure of detachment of trading choices\ncreated by feedback, and predicts the onset of speculative bubbles in\nexperiments with human subjects. We use trading data obtained from experiments\nwith humans as input to computer simulations of artificial agents that use\nadaptive strategies defined from game theory....\n"
    },
    {
        "paper_id": 806.2358,
        "authors": "Erhan Bayraktar, Virginia R. Young",
        "title": "Minimizing the Probability of Ruin when Consumption is Ratcheted",
        "comments": "Key Words: Self-annuitization, optimal investment, stochastic optimal\n  control, probability of ruin, ratcheting of consumption",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We assume that an agent's rate of consumption is {\\it ratcheted}; that is, it\nforms a non-decreasing process. Given the rate of consumption, we act as\nfinancial advisers and find the optimal investment strategy for the agent who\nwishes to minimize his probability of ruin.\n"
    },
    {
        "paper_id": 806.2397,
        "authors": "Christopher Gardner",
        "title": "Measuring Value in Healthcare",
        "comments": "52 pages, 55 figures, appendix, and endnotes",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A statistical description and model of individual healthcare expenditures in\nthe US has been developed for measuring value in healthcare. We find evidence\nthat healthcare expenditures are quantifiable as an infusion-diffusion process,\nwhich can be thought of intuitively as a steady change in the intensity of\ntreatment superimposed on a random process reflecting variations in the\nefficiency and effectiveness of treatment. The arithmetic mean represents the\nnet average annual cost of healthcare; and when multiplied by the arithmetic\nstandard deviation, which represents the effective risk, the result is a\nmeasure of healthcare cost control. Policymakers, providers, payors, or\npatients that decrease these parameters are generating value in healthcare. The\nmodel has an average absolute prediction error of approximately 10-12% across\nthe range of expenditures which spans 6 orders of magnitude over a nearly\n10-year period. For the top 1% of the population with the largest expenditures,\nrepresenting 20%-30% of total spending on healthcare, a power-law relationship\nemerges. This relationship also applies to the most expensive medical\nconditions in the US. A fundamental connection between healthcare expenditures\nand mathematical finance is found by showing that the process healthcare\nexpenditures follow is similar to a widely used model for managing financial\nassets, leading to the conclusion that a combination of these two fields may\nyield useful results.\n"
    },
    {
        "paper_id": 806.2444,
        "authors": "Zhi-Qiang Jiang (ECUST), Wei Chen (SZSE), Wei-Xing Zhou (ECUST)",
        "title": "Detrended fluctuation analysis of intertrade durations",
        "comments": "15 Elsart pages including 4 figures and 1 table",
        "journal-ref": "Physica A 388 (4), 433-440 (2009)",
        "doi": "10.1016/j.physa.2008.10.028",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The intraday pattern, long memory, and multifractal nature of the intertrade\ndurations, which are defined as the waiting times between two consecutive\ntransactions, are investigated based upon the limit order book data and order\nflows of 23 liquid Chinese stocks listed on the Shenzhen Stock Exchange in\n2003. An inverse $U$-shaped intraday pattern in the intertrade durations with\nan abrupt drop in the first minute of the afternoon trading is observed. Based\non the detrended fluctuation analysis, we find a crossover of power-law scaling\nbehaviors for small box sizes (trade numbers in boxes) and large box sizes and\nstrong evidence in favor of long memory in both regimes. In addition, the\nmultifractal nature of intertrade durations in both regimes is confirmed by a\nmultifractal detrended fluctuation analysis for individual stocks with a few\nexceptions in the small-duration regime. The intraday pattern has little\ninfluence on the long memory and multifractaility.\n"
    },
    {
        "paper_id": 806.257,
        "authors": "{\\L}ukasz Delong, Claudia Kl\\\"uppelberg",
        "title": "Optimal investment and consumption in a Black--Scholes market with\n  L\\'evy-driven stochastic coefficients",
        "comments": "Published in at http://dx.doi.org/10.1214/07-AAP475 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2008, Vol. 18, No. 3, 879-908",
        "doi": "10.1214/07-AAP475",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we investigate an optimal investment and consumption problem\nfor an investor who trades in a Black--Scholes financial market with stochastic\ncoefficients driven by a non-Gaussian Ornstein--Uhlenbeck process. We assume\nthat an agent makes investment and consumption decisions based on a power\nutility function. By applying the usual separation method in the variables, we\nare faced with the problem of solving a nonlinear (semilinear) first-order\npartial integro-differential equation. A candidate solution is derived via the\nFeynman--Kac representation. By using the properties of an operator defined in\na suitable function space, we prove uniqueness and smoothness of the solution.\nOptimality is verified by applying a classical verification theorem.\n"
    },
    {
        "paper_id": 806.2606,
        "authors": "J.B. Satinover (Univ. Nice) and D. Sornette (ETH Zurich)",
        "title": "Anomalous Returns in a Neural Network Equity-Ranking Predictor",
        "comments": "36 pages, 16 figures, 8 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using an artificial neural network (ANN), a fixed universe of approximately\n1500 equities from the Value Line index are rank-ordered by their predicted\nprice changes over the next quarter. Inputs to the network consist only of the\nten prior quarterly percentage changes in price and in earnings for each equity\n(by quarter, not accumulated), converted to a relative rank scaled around zero.\nThirty simulated portfolios are constructed respectively of the 10, 20,..., and\n100 top ranking equities (long portfolios), the 10, 20,..., 100 bottom ranking\nequities (short portfolios) and their hedged sets (long-short portfolios). In a\n29-quarter simulation from the end of the third quarter of 1994 through the\nfourth quarter of 2001 that duplicates real-world trading of the same method\nemployed during 2002, all portfolios are held fixed for one quarter. Results\nare compared to the S&P 500, the Value Line universe itself, trading the\nuniverse of equities using the proprietary ``Value Line Ranking System'' (to\nwhich this method is in some ways similar), and to a Martingale method of\nranking the same equities. The cumulative returns generated by the network\npredictor significantly exceed those generated by the S&P 500, the overall\nuniverse, the Martingale and Value Line prediction methods and are not eroded\nby trading costs. The ANN shows significantly positive Jensen's alpha, i.e.,\nanomalous risk-adjusted expected return. A time series of its global\nperformance shows a clear antipersistence. However, its performance is\nsignificantly better than a simple one-step Martingale predictor, than the\nValue Line system itself and than a simple buy and hold strategy, even when\ntransaction costs are accounted for.\n"
    },
    {
        "paper_id": 806.2617,
        "authors": "Silvio M. Duarte Queiros",
        "title": "On discrete stochastic processes with long-lasting time dependence",
        "comments": "24 pages",
        "journal-ref": "Eur. Phys. J. B 66, 137-148 (2008)",
        "doi": "10.1140/epjb/e2008-00387-2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this manuscript, we analytically and numerically study statistical\nproperties of an heteroskedastic process based on the celebrated ARCH generator\nof random variables whose variance is defined by a memory of\n$q_{m}$-exponencial, form ($e_{q_{m}=1}^{x}=e^{x}$). Specifically, we inspect\nthe self-correlation function of squared random variables as well as the\nkurtosis. In addition, by numerical procedures, we infer the stationary\nprobability density function of both of the heteroskedastic random variables\nand the variance, the multiscaling properties, the first-passage times\ndistribution, and the dependence degree. Finally, we introduce an asymmetric\nvariance version of the model that enables us to reproduce the so-called\nleverage effect in financial markets.\n"
    },
    {
        "paper_id": 806.2964,
        "authors": "Aleksandar Bogojevic, Antun Balaz, Rasa Karapandza",
        "title": "Consequences of increased longevity for wealth, fertility, and\n  population growth",
        "comments": "13 pages, 5 figures, uses elsart.cls",
        "journal-ref": "Physica A 387 (2008) 543",
        "doi": "10.1016/j.physa.2007.09.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present, solve and numerically simulate a simple model that describes the\nconsequences of increased longevity on fertility rates, population growth and\nthe distribution of wealth in developed societies. We look at the consequences\nof the repeated use of life extension techniques and show that they represent a\nnovel commodity whose introduction will profoundly influence key aspects of\neconomy and society in general. In particular, we uncover two phases within our\nsimplified model, labeled as 'mortal' and 'immortal'. Within the life extension\nscenario it is possible to have sustainable economic growth in a population of\nstable size, as a result of dynamical equilibrium between the two phases.\n"
    },
    {
        "paper_id": 806.2989,
        "authors": "Georges Harras, Didier Sornette",
        "title": "How to grow a bubble: A model of myopic adapting agents",
        "comments": "35 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a simple agent-based model to study the development of a bubble\nand the consequential crash and investigate how their proximate triggering\nfactor might relate to their fundamental mechanism, and vice versa. Our agents\ninvest according to their opinion on future price movements, which is based on\nthree sources of information, (i) public information, i.e. news, (ii)\ninformation from their \"friendship\" network and (iii) private information. Our\nbounded rational agents continuously adapt their trading strategy to the\ncurrent market regime by weighting each of these sources of information in\ntheir trading decision according to its recent predicting performance. We find\nthat bubbles originate from a random lucky streak of positive news, which, due\nto a feedback mechanism of these news on the agents' strategies develop into a\ntransient collective herding regime. After this self-amplified exuberance, the\nprice has reached an unsustainable high value, being corrected by a crash,\nwhich brings the price even below its fundamental value. These ingredients\nprovide a simple mechanism for the excess volatility documented in financial\nmarkets. Paradoxically, it is the attempt for investors to adapt to the current\nmarket regime which leads to a dramatic amplification of the price volatility.\nA positive feedback loop is created by the two dominating mechanisms\n(adaptation and imitation) which, by reinforcing each other, result in bubbles\nand crashes. The model offers a simple reconciliation of the two opposite\n(herding versus fundamental) proposals for the origin of crashes within a\nsingle framework and justifies the existence of two populations in the\ndistribution of returns, exemplifying the concept that crashes are\nqualitatively different from the rest of the price moves.\n"
    },
    {
        "paper_id": 806.3171,
        "authors": "H. Eduardo Roman and Markus Porto",
        "title": "Fractional derivatives of random walks: Time series with long-time\n  memory",
        "comments": "10 pages, 14 figures",
        "journal-ref": "Phys. Rev. E. 78, 031127 (2008)",
        "doi": "10.1103/PhysRevE.78.031127",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review statistical properties of models generated by the application of a\n(positive and negative order) fractional derivative operator to a standard\nrandom walk and show that the resulting stochastic walks display\nslowly-decaying autocorrelation functions. The relation between these\ncorrelated walks and the well-known fractionally integrated autoregressive\n(FIGARCH) models, commonly used in econometric studies, is discussed. The\napplication of correlated random walks to simulate empirical financial times\nseries is considered and compared with the predictions from FIGARCH and the\nsimpler FIARCH processes. A comparison with empirical data is performed.\n"
    },
    {
        "paper_id": 806.3399,
        "authors": "Paolo Dai Pra, Marco Tolotti",
        "title": "Heterogeneous credit portfolios and the dynamics of the aggregate losses",
        "comments": "35 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the impact of contagion in a network of firms facing credit risk. We\ndescribe an intensity based model where the homogeneity assumption is broken by\nintroducing a random environment that makes it possible to take into account\nthe idiosyncratic characteristics of the firms. We shall see that our model\ngoes behind the identification of groups of firms that can be considered\nbasically exchangeable. Despite this heterogeneity assumption our model has the\nadvantage of being totally tractable. The aim is to quantify the losses that a\nbank may suffer in a large credit portfolio. Relying on a large deviation\nprinciple on the trajectory space of the process, we state a suitable law of\nlarge number and a central limit theorem useful to study large portfolio\nlosses. Simulation results are provided as well as applications to portfolio\nloss distribution analysis.\n"
    },
    {
        "paper_id": 806.3813,
        "authors": "Abhijit KarGupta",
        "title": "The Question of Relaxation in the Wealth Exchange Models",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We look at the meaning of 'relaxation' in the wealth exchange models that are\nrecently proposed in Econophysics to interpret the wealth distributions. To\nquantify and characterise the process of relaxation, we define an appropriate\nquantity and evaluate that numerically for the systems of many agents. Also,\nthe numerical results have been supported heuristically by constructing a\nsimple differential equation.\n"
    },
    {
        "paper_id": 806.4026,
        "authors": "Ivar Ekeland and Traian A Pirvu",
        "title": "On a Non-Standard Stochastic Control Problem",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the Merton portfolio management problem. We are\nconcerned with non-exponential discounting of time and this leads to time\ninconsistencies of the decision maker. Following Ekeland and Pirvu 2006, we\nintroduce the notion of equilibrium policies and we characterize them by an\nintegral equation. The main idea is to come up with the value function in this\ncontext. If risk preferences are of CRRA type, the integral equation which\ncharacterizes the value function is shown to have a solution which leads to an\nequilibrium policy. This work is an extension of Ekeland and Pirvu 2006.\n"
    },
    {
        "paper_id": 806.4061,
        "authors": "Vicky Henderson, David Hobson",
        "title": "An explicit solution for an optimal stopping/optimal control problem\n  which models an asset sale",
        "comments": "Published in at http://dx.doi.org/10.1214/07-AAP511 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2008, Vol. 18, No. 5, 1681-1705",
        "doi": "10.1214/07-AAP511",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we study an optimal stopping/optimal control problem which\nmodels the decision facing a risk-averse agent over when to sell an asset. The\nmarket is incomplete so that the asset exposure cannot be hedged. In addition\nto the decision over when to sell, the agent has to choose a control strategy\nwhich corresponds to a feasible wealth process. We formulate this problem as\none involving the choice of a stopping time and a martingale. We conjecture the\nform of the solution and verify that the candidate solution is equal to the\nvalue function. The interesting features of the solution are that it is\navailable in a very explicit form, that for some parameter values the optimal\nstrategy is more sophisticated than might originally be expected, and that\nalthough the setup is based on continuous diffusions, the optimal martingale\nmay involve a jump process. One interpretation of the solution is that it is\noptimal for the risk-averse agent to gamble.\n"
    },
    {
        "paper_id": 806.4125,
        "authors": "Jostein Paulsen",
        "title": "Ruin models with investment income",
        "comments": "Published in at http://dx.doi.org/10.1214/08-PS134 the Probability\n  Surveys (http://www.i-journals.org/ps/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)",
        "journal-ref": "Probability Surveys 2008, Vol. 5, No. 0, 416-434",
        "doi": "10.1214/08-PS134",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This survey treats the problem of ruin in a risk model when assets earn\ninvestment income. In addition to a general presentation of the problem, topics\ncovered are a presentation of the relevant integro-differential equations,\nexact and numerical solutions, asymptotic results, bounds on the ruin\nprobability and also the possibility of minimizing the ruin probability by\ninvestment and possibly reinsurance control. The main emphasis is on continuous\ntime models, but discrete time models are also covered. A fairly extensive list\nof references is provided, particularly of papers published after 1998. For\nmore references to papers published before that, the reader can consult [47].\n"
    },
    {
        "paper_id": 806.4506,
        "authors": "Ilya Molchanov and Michael Schmutz",
        "title": "Geometric extension of put-call symmetry in the multiasset setting",
        "comments": "59 pages, minor revision",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we show how to relate European call and put options on multiple\nassets to certain convex bodies called lift zonoids. Based on this, geometric\nproperties can be translated into economic statements and vice versa. For\ninstance, the European call-put parity corresponds to the central symmetry\nproperty, while the concept of dual markets can be explained by reflection with\nrespect to a plane. It is known that the classical univariate log-normal model\nbelongs to a large class of distributions with an extra property, analytically\nknown as put-call symmetry. The geometric interpretation of this symmetry\nproperty motivates a natural multivariate extension. The financial meaning of\nthis extension is explained, the asset price distributions that have this\nproperty are characterised and their further properties explored. It is also\nshown how to relate some multivariate asymmetric distributions to symmetric\nones by a power transformation that is useful to adjust for carrying costs. A\nparticular attention is devoted to the case of asset prices driven by L\\'evy\nprocesses. Based on this, semi-static hedging techniques for multiasset barrier\noptions are suggested.\n"
    },
    {
        "paper_id": 806.4675,
        "authors": "JC Ndogmo",
        "title": "Some Control Variates for exotic options",
        "comments": "The paper is a contribution to Monte Carlo simulation and variance\n  reduction techniques",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There are no known exact formulas for the valuation of a number of exotic\noptions, and this is particularly true for options under discrete monitoring\nand for American style options. Therefore, one usually recourses to a Monte\nCarlo Simulation approach, amongst other numerical methods, to estimate the\nvalue of these options. The problem which then arises with this method is one\nof variance reduction. Control variates are often used, and we present some\nresults concerning these control variables, for the valuation of Asian and\nlookback options. An inequality on functions of correlations useful for\ncomparing estimators in variance reduction procedures is also provided.\n"
    },
    {
        "paper_id": 806.4676,
        "authors": "J. C. Ndogmo",
        "title": "Classification of barrier options",
        "comments": "10 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a given level of accuracy in option prices, the paper considers the\nproblem of deciding when exactly, as one or more of the pricing parameters\nchange, a barrier option degenerates into a simpler type of option. This\nproblem is meaningful in the real world where option prices are always\ndetermined within a certain level of accuracy. The problem is reduced to\nfinding certain critical values of the initial stock price, and this is\nachieved through a probability-based approach.\n"
    },
    {
        "paper_id": 806.4834,
        "authors": "Shaolin Ji",
        "title": "Dual method for continuous-time Markowitz's Problems with nonlinear\n  wealth equations",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Continuous-time mean-variance portfolio selection model with nonlinear wealth\nequations and bankruptcy prohibition is investigated by the dual method. A\nnecessary and sufficient condition which the optimal terminal wealth satisfies\nis obtained through a terminal perturbation technique. It is also shown that\nthe optimal wealth and portfolio is the solution of a forward-backward\nstochastic differential equation with constraints.\n"
    },
    {
        "paper_id": 806.4876,
        "authors": "Anna Szczypinska, Edward W. Piotrowski",
        "title": "Inconsistency of the judgment matrix in the AHP method and the decision\n  maker's knowledge",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2008.11.034",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a method for a quantitative estimation of the\ndecision maker's knowledge in the context of the Analytic Hierarchy Process\n(AHP) in cases, where the judgment matrix is inconsistent. We show that the\nmatrix of deviation from the transitivity condition corresponds to the rate\nmatrix for transaction costs in the financial market. For the quantitative\nestimation of the decision maker's professionalism, we apply the Ising model\nand thermodynamics tools.\n"
    },
    {
        "paper_id": 807.0309,
        "authors": "Christophette Blanchet-Scalliet (ICJ), Fr\\'ed\\'eric Patras (JAD)",
        "title": "Counterparty risk valuation for CDS",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The valuation of counterparty risk for single name credit derivatives\nrequires the computa- tion of joint distributions of default times of two\ndefault-prone entities. For a Merton-type model, we derive some formulas for\nthese joint distribu- tions. As an application, closed formulas for\ncounterparty risk on a CDS or for a first-to-default swap on two underlyings\nare obtained.\n"
    },
    {
        "paper_id": 807.0563,
        "authors": "Hari M. Gupta, Jose R. Campanha",
        "title": "The exponentially truncated q-distribution: A generalized distribution\n  for real complex systems",
        "comments": "20 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To know the statistical distribution of a variable is an important problem in\nmanagement of resources. Distributions of the power law type are observed in\nmany real systems. However power law distributions have an infinite variance\nand thus can not be used as a standard distribution. Normally professionals in\nthe area use normal distribution with variable parameters or some other\napproximate distribution like Gumbel, Wakeby, or Pareto, which has limited\nvalidity.\n  Tsallis presented a microscopic theory of power law in the framework of\nnon-extensive thermodynamics considering long-range interactions or long\nmemory. In the present work, we consider softing of long-range interactions or\nmemory and presented a generalized distribution which have finite variance and\ncan be used as a standard distribution for all real complex systems with power\nlaw behaviour. We applied this distribution for a financial system, rain\nprecipitation and some geophysical and social systems. We found a good\nagreement for entire range in all cases for the probability density function\n(pdf) as well as the accumulated probability. This distribution shows universal\nnature of the size limiting in real systems.\n"
    },
    {
        "paper_id": 807.0925,
        "authors": "A. Christian Silva and Ju-Yi J. Yen",
        "title": "Stochastic resonance and the trade arrival rate of stocks",
        "comments": "4 figures and 8 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We studied non-dynamical stochastic resonance for the number of trades in the\nstock market. The trade arrival rate presents a deterministic pattern that can\nbe modeled by a cosine function perturbed by noise. Due to the nonlinear\nrelationship between the rate and the observed number of trades, the noise can\neither enhance or suppress the detection of the deterministic pattern. By\nfinding the parameters of our model with intra-day data, we describe the\ntrading environment and illustrate the presence of SR in the trade arrival rate\nof stocks in the U.S. market.\n"
    },
    {
        "paper_id": 807.1014,
        "authors": "Jaume Masoliver, Josep Perello",
        "title": "The escape problem under stochastic volatility: the Heston model",
        "comments": "29 pages, 12 figures",
        "journal-ref": "Phys. Rev. E 78, 056104 (2008)",
        "doi": "10.1103/PhysRevE.78.056104",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We solve the escape problem for the Heston random diffusion model. We obtain\nexact expressions for the survival probability (which ammounts to solving the\ncomplete escape problem) as well as for the mean exit time. We also average the\nvolatility in order to work out the problem for the return alone regardless\nvolatility. We look over these results in terms of the dimensionless normal\nlevel of volatility --a ratio of the three parameters that appear in the Heston\nmodel-- and analyze their form in several assymptotic limits. Thus, for\ninstance, we show that the mean exit time grows quadratically with large spans\nwhile for small spans the growth is systematically slower depending on the\nvalue of the normal level. We compare our results with those of the Wiener\nprocess and show that the assumption of stochastic volatility, in an apparent\nparadoxical way, increases survival and prolongs the escape time.\n"
    },
    {
        "paper_id": 807.1201,
        "authors": "Federico Bassetti",
        "title": "Quantitative comparisons between finitary posterior distributions and\n  Bayesian posterior distributions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main object of Bayesian statistical inference is the determination of\nposterior distributions. Sometimes these laws are given for quantities devoid\nof empirical value. This serious drawback vanishes when one confines oneself to\nconsidering a finite horizon framework. However, assuming infinite\nexchangeability gives rise to fairly tractable {\\it a posteriori} quantities,\nwhich is very attractive in applications. Hence, with a view to a\nreconciliation between these two aspects of the Bayesian way of reasoning, in\nthis paper we provide quantitative comparisons between posterior distributions\nof finitary parameters and posterior distributions of allied parameters\nappearing in usual statistical models.\n"
    },
    {
        "paper_id": 807.1213,
        "authors": "Joerg Kampen, Anastasia Kolodko, and John Schoenmakers",
        "title": "Monte Carlo Greeks for financial products via approximative transition\n  densities",
        "comments": "24 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce efficient Monte Carlo estimators for the valuation\nof high-dimensional derivatives and their sensitivities (''Greeks''). These\nestimators are based on an analytical, usually approximative representation of\nthe underlying density. We study approximative densities obtained by the WKB\nmethod. The results are applied in the context of a Libor market model.\n"
    },
    {
        "paper_id": 807.1227,
        "authors": "Friedrich Hubalek (Technical University of Vienna) Carlo Sgarra\n  (Technical University of Milan)",
        "title": "On the Esscher transforms and other equivalent martingale measures for\n  Barndorff-Nielsen and Shephard stochastic volatility models with jumps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We compute and discuss the Esscher martingale transform for exponential\nprocesses, the Esscher martingale transform for linear processes, the minimal\nmartingale measure, the class of structure preserving martingale measures, and\nthe minimum entropy martingale measure for stochastic volatility models of\nOrnstein-Uhlenbeck type as introduced by Barndorff-Nielsen and Shephard. We\nshow, that in the model with leverage, with jumps both in the volatility and in\nthe returns, all those measures are different, whereas in the model without\nleverage, with jumps in the volatility only and a continuous return process,\nseveral measures coincide, some simplifications can be made and the results are\nmore explicit. We illustrate our results with parametric examples used in the\nliterature.\n"
    },
    {
        "paper_id": 807.1253,
        "authors": "Dorje C. Brody, Mark H. A. Davis, Robyn L. Friedman, Lane P. Hughston",
        "title": "Informed Traders",
        "comments": "20 pages, 5 figures. Version to appear in the Proceedings of the\n  Royal Society A",
        "journal-ref": "Proceedings of the Royal Society London A465, 1103-1122 (2009)",
        "doi": "10.1098/rspa.2008.0465",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An asymmetric information model is introduced for the situation in which\nthere is a small agent who is more susceptible to the flow of information in\nthe market than the general market participant, and who tries to implement\nstrategies based on the additional information. In this model market\nparticipants have access to a stream of noisy information concerning the future\nreturn of an asset, whereas the informed trader has access to a further\ninformation source which is obscured by an additional noise that may be\ncorrelated with the market noise. The informed trader uses the extraneous\ninformation source to seek statistical arbitrage opportunities, while at the\nsame time accommodating the additional risk. The amount of information\navailable to the general market participant concerning the asset return is\nmeasured by the mutual information of the asset price and the associated cash\nflow. The worth of the additional information source is then measured in terms\nof the difference of mutual information between the general market participant\nand the informed trader. This difference is shown to be nonnegative when the\nsignal-to-noise ratio of the information flow is known in advance. Explicit\ntrading strategies leading to statistical arbitrage opportunities, taking\nadvantage of the additional information, are constructed, illustrating how\nexcess information can be translated into profit.\n"
    },
    {
        "paper_id": 807.1639,
        "authors": "Paul Ormerod",
        "title": "Global recessions as a cascade phenomenon with heterogenous, interacting\n  agents",
        "comments": "invited paper, ESHIA, Warsaw June 2008",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I examine global recessions as a cascade phenomenon. In other words, how\nrecessions arising in one or more countries might percolate across a network of\nconnected economies. A heterogeneous agent based model is set up in which the\nagents are Western economies. A country has a probability of entering a\nrecession in any given year and one of emerging from it the next. In addition,\nthe agents have a unique threshold propensity to import a recession from the\nagents with which they have the strongest connections. They are connected on a\nsmall world topology, and an agent's neighbours at any time are either in\n(state 1) or out (state 0) of recession. If the weighted sum exceeds the\nthreshold, the agent goes into recession. Annual real GDP growth for 17 Western\ncountries 1871-2006 is used as the data set. The distribution of the number of\ncountries in recession in any given year is exponential, as is the duration of\nrecessions within individual countries. The model is calibrated against these\ntwo facts, plus the 'wait time' between recessions. It is able to replicate\nthem successfully. The network structure is essential for the agents to\nreplicate the stylised facts. The country-specific probabilities of entering\nand emerging from recession by themselves give results very different to the\nactual data.\n"
    },
    {
        "paper_id": 807.1771,
        "authors": "Paul Ormerod",
        "title": "Random matrix theory and the evolution of business cycle synchronisation\n  1886-2006",
        "comments": "accepted subject to drafting revisions by Economics E-Journal",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The major study by Bordo and Helbing (2003) analyses the business cycle in\nWestern economies 1881-2001. They examine four distinct periods in economic\nhistory, and conclude that there is a secular trend towards greater\nsynchronisation for much of the 20th century. Their analysis, in common with\nthe standard economic literature on business cycle synchronisation, relies upon\nthe estimation of an empirical correlation matrix of time series data of\nmacroeconomic aggregates. However because of the small number of observations\nand economies, the empirical correlation matrix may contain considerable noise.\nRandom matrix theory was developed to overcome this problem. I use random\nmatrix theory, and the associated technique of agglomerative hierarchical\nclustering, to examine the evolution of business cycle synchronisation between\nthe capitalist economies in the long-run. Contrary to the findings of Bordo and\nHelbing, it is not possible to speak of a 'secular trend' towards greater\nsynchronisation over the period as a whole. During the pre-First World War\nperiod, the cross-country correlations of annual real GDP growth are\nindistinguishable from those which could be generated by a purely random\nmatrix. The periods 1920-38 and 1948-72 do show a certain degree of\nsynchronisation, but it is very weak. In particular, the cycles of the major\neconomies cannot be said to be synchronised. Such synchronisation as exists in\nthe overall data is due to meaningful co-movements in sub-groups. So the degree\nof synchronisation has evolved fitfully. It is only in the most recent\n1973-2006 period that we can speak meaningfully of anything resembling an\ninternational business cycle.\n"
    },
    {
        "paper_id": 807.1818,
        "authors": "Fei Ren, Liang Guo, and Wei-Xing Zhou",
        "title": "Statistical properties of volatility return intervals of Chinese stocks",
        "comments": "8 pages, 8 figures",
        "journal-ref": "Physica A 388 (6), 881-890 (2009)",
        "doi": "10.1016/j.physa.2008.12.005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The statistical properties of the return intervals $\\tau_q$ between\nsuccessive 1-min volatilities of 30 liquid Chinese stocks exceeding a certain\nthreshold $q$ are carefully studied. The Kolmogorov-Smirnov (KS) test shows\nthat 12 stocks exhibit scaling behaviors in the distributions of $\\tau_q$ for\ndifferent thresholds $q$. Furthermore, the KS test and weighted KS test shows\nthat the scaled return interval distributions of 6 stocks (out of the 12\nstocks) can be nicely fitted by a stretched exponential function\n$f(\\tau/\\bar{\\tau})\\sim e^{- \\alpha (\\tau/\\bar{\\tau})^{\\gamma}}$ with\n$\\gamma\\approx0.31$ under the significance level of 5%, where $\\bar{\\tau}$ is\nthe mean return interval. The investigation of the conditional probability\ndistribution $P_q(\\tau | \\tau_0)$ and the mean conditional return interval\n$<\\tau| \\tau_0>$ demonstrates the existence of short-term correlation between\nsuccessive return interval intervals. We further study the mean return interval\n$<\\tau| \\tau_0>$ after a cluster of $n$ intervals and the fluctuation $F(l)$\nusing detrended fluctuation analysis and find that long-term memory also exists\nin the volatility return intervals.\n"
    },
    {
        "paper_id": 807.1823,
        "authors": "Gur Yaari and Sorin Solomon",
        "title": "Cooperation Evolution in Random Multiplicative Environments",
        "comments": "20 pages 7 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Most real life systems have a random component: the multitude of endogenous\nand exogenous factors influencing them result in stochastic fluctuations of the\nparameters determining their dynamics. These empirical systems are in many\ncases subject to noise of multiplicative nature. The special properties of\nmultiplicative noise as opposed to additive noise have been noticed for a long\nwhile. Even though apparently and formally the difference between free additive\nvs. multiplicative random walks consists in just a move from normal to\nlog-normal distributions, in practice the implications are much more far\nreaching. While in an additive context the emergence and survival of\ncooperation requires special conditions (especially some level of reward,\npunishment, reciprocity), we find that in the multiplicative random context the\nemergence of cooperation is much more natural and effective. We study the\nvarious implications of this observation and its applications in various\ncontexts.\n"
    },
    {
        "paper_id": 807.1831,
        "authors": "Paul Ormerod",
        "title": "The evolution of EU business cycle synchronisation 1981-2007",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Most of the analytical techniques used in the business cycle synchronisation\nliterature rely upon the estimation of an empirical correlation matrix of time\nseries data of macroeconomic aggregates, real GDP usually being the key\nvariable. But the small number of available observations and small number of\neconomies mean that the empirical correlation matrix may contain considerable\nnoise. Random matrix theory was developed in physics to overcome this problem.\nThe largest eigenvalue of the correlation matrix informs us directly about the\ndegree to which movements of the economies are genuinely correlated. The\nevolution of business cycle synchronisation can be analysed with the temporal\nevolution of the largest eigenvalue over a fixed window of data. I analyse\nquarterly real GDP data 1981Q1-2008Q1 for the core EU economies - Germany,\nFrance, Italy, Spain, Netherlands, Belgium - along with the UK, which is a\nmember of the EU but not the Euro, and the US as a comparator. The core EU\neconomies have shown varying but strong synchronisation over the whole period.\nIn contrast, the UK and the US are much more synchronised with each other than\nthey are with the core EU economies.\n"
    },
    {
        "paper_id": 807.1888,
        "authors": "V.Alfi, L. Pietronero and A. Zaccaria",
        "title": "Minimal Agent Based Model For The Origin And Self-Organization Of\n  Stylized Facts In Financial Markets",
        "comments": "9 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a minimal Agent Based Model with two classes of agents,\nfundamentalists (stabilizing) and chartists (destabilizing) and we focus on the\nessential features which can generate the stylized facts. This leads to a\ndetailed understanding of the origin of fat tails and volatility clustering and\nwe propose a mechanism for the self-organization of the market dynamics in the\nquasi-critical state. The stylized facts are shown to correspond to finite size\neffects which, however, can be active at different time scales. This implies\nthat universality cannot be expected in describing these properties in terms of\neffective critical exponents. The introduction of a threshold in the agents'\naction (small price fluctuations lead to no-action) triggers the\nself-organization towards the quasi-critical state. Non-stationarity in the\nnumber of active agents and in their action plays a fundamental role. The model\ncan be easily generalized to more realistic variants in a systematic way.\n"
    },
    {
        "paper_id": 807.2083,
        "authors": "G.L. Buchbinder and K.M. Chistilin",
        "title": "Market dynamics after large financial crash",
        "comments": "6 pages, 6 figures, RevTex",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The model describing market dynamics after a large financial crash is\nconsidered in terms of the stochastic differential equation of Ito. Physically,\nthe model presents an overdamped Brownian particle moving in the nonstationary\none-dimensional potential $U$ under the influence of the variable noise\nintensity, depending on the particle position $x$. Based on the empirical data\nthe approximate estimation of the Kramers-Moyal coefficients $D_{1,2}$ allow to\npredicate quite definitely the behavior of the potential introduced by $D_1 = -\n\\partial U /\\partial x$ and the volatility $\\sim \\sqrt{D_2}$. It has been shown\nthat the presented model describes well enough the best known empirical facts\nrelative to the large financial crash of October 1987. \\\n"
    },
    {
        "paper_id": 807.2124,
        "authors": "Andrea Macrina",
        "title": "An Information-Based Framework for Asset Pricing: X-Factor Theory and\n  its Applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A new framework for asset pricing based on modelling the information\navailable to market participants is presented. Each asset is characterised by\nthe cash flows it generates. Each cash flow is expressed as a function of one\nor more independent random variables called market factors or \"X-factors\". Each\nX-factor is associated with a \"market information process\", the values of which\nbecome available to market participants. In addition to true information about\nthe X-factor, the information process contains an independent \"noise\" term\nmodelled here by a Brownian bridge. The information process thus gives partial\ninformation about the X-factor, and the value of the market factor is only\nrevealed at the termination of the process. The market filtration is assumed to\nbe generated by the information processes associated with the X-factors. The\nprice of an asset is given by the risk-neutral expectation of the sum of the\ndiscounted cash flows, conditional on the information available from the\nfiltration. The theory is developed in some detail, with a variety of\napplications to credit risk management, share prices, interest rates, and\ninflation. A number of new exactly solvable models are obtained for the price\nprocesses of various types of assets and derivative securities; and a novel\nmechanism is proposed to account for the dynamics of stochastic volatility and\ndynamic correlation. A discrete-time version of the information-based framework\nis also developed, and is used to construct a new class of models for the real\nand nominal interest rate term structures, and the dynamics of the associated\nprice index.\n"
    },
    {
        "paper_id": 807.2526,
        "authors": "Teemu Pennanen",
        "title": "Arbitrage and deflators in illiquid markets",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/s00780-009-0118-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a stochastic model for discrete-time trading in financial\nmarkets where trading costs are given by convex cost functions and portfolios\nare constrained by convex sets. The model does not assume the existence of a\ncash account/numeraire. In addition to classical frictionless markets and\nmarkets with transaction costs or bid-ask spreads, our framework covers markets\nwith nonlinear illiquidity effects for large instantaneous trades. In the\npresence of nonlinearities, the classical notion of arbitrage turns out to have\ntwo equally meaningful generalizations, a marginal and a scalable one. We study\ntheir relations to state price deflators by analyzing two auxiliary market\nmodels describing the local and global behavior of the cost functions and\nconstraints.\n"
    },
    {
        "paper_id": 807.2583,
        "authors": "Fulvio Baldovin and Attilio L. Stella",
        "title": "Scaling and efficiency determine the irreversible evolution of a market",
        "comments": "5 pages, 4 figures",
        "journal-ref": "Proc. Natl. Acad. Sci {\\bf 104}, 19741 (2007)",
        "doi": "10.1073/pnas.0706046104",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In setting up a stochastic description of the time evolution of a financial\nindex, the challenge consists in devising a model compatible with all stylized\nfacts emerging from the analysis of financial time series and providing a\nreliable basis for simulating such series. Based on constraints imposed by\nmarket efficiency and on an inhomogeneous-time generalization of standard\nsimple scaling, we propose an analytical model which accounts simultaneously\nfor empirical results like the linear decorrelation of successive returns, the\npower law dependence on time of the volatility autocorrelation function, and\nthe multiscaling associated to this dependence. In addition, our approach gives\na justification and a quantitative assessment of the irreversible character of\nthe index dynamics. This irreversibility enters as a key ingredient in a novel\nsimulation strategy of index evolution which demonstrates the predictive\npotential of the model.\n"
    },
    {
        "paper_id": 807.2962,
        "authors": "Teemu Pennanen",
        "title": "Superhedging in illiquid markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study contingent claims in a discrete-time market model where trading\ncosts are given by convex functions and portfolios are constrained by convex\nsets. In addition to classical frictionless markets and markets with\ntransaction costs or bid-ask spreads, our framework covers markets with\nnonlinear illiquidity effects for large instantaneous trades. We derive dual\ncharacterizations of superhedging conditions for contingent claim processes in\na market without a cash account. The characterizations are given in terms of\nstochastic discount factors that correspond to martingale densities in a market\nwith a cash account. The dual representations are valid under a topological\ncondition and a weak consistency condition reminiscent of the ``law of one\nprice'', both of which are implied by the no arbitrage condition in the case of\nclassical perfectly liquid market models. We give alternative sufficient\nconditions that apply to market models with nonlinear cost functions and\nportfolio constraints.\n"
    },
    {
        "paper_id": 807.3059,
        "authors": "Erika Fille Legara, Anthony Longjas, and Rene Batac",
        "title": "Agent-based model of competition in a social structure",
        "comments": "7 pages, 3 figures This paper has been withdrawn due to claims that\n  have been proven to be false",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Indirect competition emerged from the complex organization of human\nsocieties, and knowledge of the existing network topology may aid in developing\neffective strategies for success. Here, we propose an agent-based model of\ncompetition with systems co-existing in a `small-world' social network. We show\nthat within the range of parameter values obtained from the model and empirical\ndata, the network evolution is highly dependent on $k$, the local parameter\ndescribing the density of neighbors in the network. The model applied to\nlanguage death and competition of telecommunication companies show strong\ncorrespondence with empirical data.\n"
    },
    {
        "paper_id": 807.3464,
        "authors": "Friedrich Hubalek and Petra Posedel",
        "title": "Joint analysis and estimation of stock prices and trading volume in\n  Barndorff-Nielsen and Shephard stochastic volatility models",
        "comments": "26 pages, 16 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a variant of the Barndorff-Nielsen and Shephard stochastic\nvolatility model where the non Gaussian Ornstein-Uhlenbeck process describes\nsome measure of trading intensity like trading volume or number of trades\ninstead of unobservable instantaneous variance. We develop an explicit\nestimator based on martingale estimating functions in a bivariate model that is\nnot a diffusion, but admits jumps. It is assumed that both the quantities are\nobserved on a discrete grid of fixed width, and the observation horizon tends\nto infinity. We show that the estimator is consistent and asymptotically normal\nand give explicit expressions of the asymptotic covariance matrix. Our method\nis illustrated by a finite sample experiment and a statistical analysis on the\nInternational Business Machines Corporation (IBM) stock from the New York Stock\nExchange (NYSE) and the Microsoft Corporation (MSFT) stock from Nasdaq during a\nhistory of five years.\n"
    },
    {
        "paper_id": 807.3479,
        "authors": "Friedrich Hubalek and Petra Posedel",
        "title": "Asymptotic analysis for a simple explicit estimator in Barndorff-Nielsen\n  and Shephard stochastic volatility models",
        "comments": "26 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a simple explicit estimator for discretely observed\nBarndorff-Nielsen and Shephard models, prove rigorously consistency and\nasymptotic normality based on the single assumption that all moments of the\nstationary distribution of the variance process are finite, and give explicit\nexpressions for the asymptotic covariance matrix.\n  We develop in detail the martingale estimating function approach for a\nbivariate model, that is not a diffusion, but admits jumps. We do not use\nergodicity arguments.\n  We assume that both, logarithmic returns and instantaneous variance are\nobserved on a discrete grid of fixed width, and the observation horizon tends\nto infinity. As the instantaneous variance is not observable in practice, our\nresults cannot be applied immediately. Our purpose is to provide a theoretical\nanalysis as a starting point and benchmark for further developments concerning\noptimal martingale estimating functions, and for theoretical and empirical\ninvestigations, that replace the variance process with a substitute, such as\nnumber or volume of trades or implied variance from option data.\n"
    },
    {
        "paper_id": 807.38,
        "authors": "Yonathan Schwarzkopf and J. Doyne Farmer",
        "title": "What drives mutual fund asset concentration?",
        "comments": "33 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.81.066113",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Is the large influence that mutual funds assert on the U.S. financial system\nspread across many funds, or is it is concentrated in only a few? We argue that\nthe dominant economic factor that determines this is market efficiency, which\ndictates that fund performance is size independent and fund growth is\nessentially random. The random process is characterized by entry, exit and\ngrowth. We present a new time-dependent solution for the standard equations\nused in the industrial organization literature and show that relaxation to the\nsteady-state solution is extremely slow. Thus, even if these processes were\nstationary (which they are not), the steady-state solution, which is a very\nheavy-tailed power law, is not relevant. The distribution is instead\nwell-approximated by a less heavy-tailed log-normal. We perform an empirical\nanalysis of the growth of mutual funds, propose a new, more accurate\nsize-dependent model, and show that it makes a good prediction of the\nempirically observed size distribution. While mutual funds are in many respects\nlike other firms, market efficiency introduces effects that make their growth\nprocess distinctly different. Our work shows that a simple model based on\nmarket efficiency provides a good explanation of the concentration of assets,\nsuggesting that other effects, such as transaction costs or the behavioral\naspects of investor choice, play a smaller role.\n"
    },
    {
        "paper_id": 807.3814,
        "authors": "D. Sornette (ETH Zurich)",
        "title": "Interdisciplinarity in Socio-economics, mathematical analysis and\n  predictability of complex systems",
        "comments": "15 pages, reflections on the nature of interdisciplinarity and the\n  contribution of physics to socio-economics",
        "journal-ref": "Sociological Economic Review 6, 27-38 (2008)",
        "doi": "10.1093/ser/mwn015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this essay, I attempt to provide supporting evidence as well as some\nbalance for the thesis on `Transforming socio-economics with a new\nepistemology' presented by Hollingworth and Mueller (2008). First, I review a\npersonal highlight of my own scientific path that illustrates the power of\ninterdisciplinarity as well as unity of the mathematical description of natural\nand social processes. I also argue against the claim that complex systems are\nin general `not susceptible to mathematical analysis, but must be understood by\nletting them evolve over time or with simulation analysis'. Moreover, I present\nevidence of the limits of the claim that scientists working within Science II\ndo not make predictions about the future because it is too complex. I stress\nthe potentials for a third `Quantum Science' and its associated conceptual and\nphilosophical revolutions, and finally point out some limits of the `new'\ntheory of networks.\n"
    },
    {
        "paper_id": 807.3898,
        "authors": "L. Bertini, L. Passalacqua",
        "title": "Modelling interest rates by correlated multi-factor CIR-like processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the joint description of the interest-rate term stuctures of\nItaly and an AAA-rated European country by mean of a --here proposed--\ncorrelated CIR-like bivariate model where one of the state variables is\ninterpreted as a benchmark risk-free rate and the other as a credit spread. The\nmodel is constructed by requiring the strict positivity of interest rates and\nthe asymptotic decoupling of the joint distribution of the two state variables\non a long time horizon. The second condition is met by imposing the\nreversibility of the process with respect to a product measure, the first is\nthen implemented by using the tools of potential theory. It turns out that\nthese conditions select a class of non-affine models, out of which we choose\none that is quadratic in the two state variables both in the drift and\ndiffusion matrix. We perform a numerical analysis of the model by investigating\na cross section of the term structures comparing the results with those\nobtained with an uncoupled bivariate CIR model.\n"
    },
    {
        "paper_id": 807.396,
        "authors": "Ivar Ekeland",
        "title": "Existence, uniqueness and efficiency of equilibrium in hedonic markets\n  with multidimenstional types",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study equilibrium in hedonic markets, when consumers and suppliers have\nreservation utilities, and the utility functions are separable with respect to\nprice. There is one indivisible good, which comes in different qualities; each\nconsumer buys 0 or 1 unit, and each supplier sells 0 or 1 unit. Consumer types,\nsupplier types and qualities can be either discrete of continuous, in which\ncase they are allowed to be multidimensional. Prices play a double role: they\nkeep some agents out of the market, and they match the remaining ones pairwise.\nWe define equilibrium prices and equilibrium distributions, and we prove that\nequilibria exist, we investigate to what extend equilibrium prices and\ndistributions are unique, and we prove that equilibria are efficient. In the\nparticular case when there is a continuum of types, and a generalized\nSpence-Mirrlees condition is satisfied, we prove the existence of a pure\nequilibrium, where demand distributions are in fact demand functions, and we\nshow to what extent it is unique. The proofs rely on convex analysis, and care\nhas been given to illustrate the theory with examples.\n"
    },
    {
        "paper_id": 807.4163,
        "authors": "Damien Challet and Pier Paolo Peirano",
        "title": "The Ups and Downs of Modeling Financial Time Series with Wiener Process\n  Mixtures",
        "comments": "28 pages, 7 figures, major changes, added a new section with the full\n  mathematical characterization of the process family",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Starting from inhomogeneous time scaling and linear decorrelation between\nsuccessive price returns, Baldovin and Stella recently proposed a way to build\na model describing the time evolution of a financial index. We first make it\nfully explicit by using Student distributions instead of power law-truncated\nL\\'evy distributions; we also show that the analytic tractability of the model\nextends to the larger class of symmetric generalized hyperbolic distributions\nand provide a full computation of their multivariate characteristic functions;\nmore generally, the stochastic processes arising in this framework are\nrepresentable as mixtures of Wiener processes. The Baldovin and Stella model,\nwhile mimicking well volatility relaxation phenomena such as the Omori law,\nfails to reproduce other stylized facts such as the leverage effect or some\ntime reversal asymmetries. We discuss how to modify the dynamics of this\nprocess in order to reproduce real data more accurately.\n"
    },
    {
        "paper_id": 807.4394,
        "authors": "Tetsuya Takaishi",
        "title": "Financial Time Series Analysis of SV Model by Hybrid Monte Carlo",
        "comments": "8 pages, 3 figures, to be published in LNCS",
        "journal-ref": "Lecture Notes in Computer Science Volume 5226 (2008) 929-936",
        "doi": "10.1007/978-3-540-87442-3_114",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We apply the hybrid Monte Carlo (HMC) algorithm to the financial time sires\nanalysis of the stochastic volatility (SV) model for the first time. The HMC\nalgorithm is used for the Markov chain Monte Carlo (MCMC) update of volatility\nvariables of the SV model in the Bayesian inference. We compute parameters of\nthe SV model from the artificial financial data and compare the results from\nthe HMC algorithm with those from the Metropolis algorithm. We find that the\nHMC decorrelates the volatility variables faster than the Metropolis algorithm.\nWe also make an empirical analysis based on the Yen/Dollar exchange rates.\n"
    },
    {
        "paper_id": 807.4484,
        "authors": "Sebastian D. Guala",
        "title": "Taxes in a simple wealth distribution model by inelastically scattering\n  particles",
        "comments": "7 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we use an inelastic scattering process of particles to propose a\nmodel able to reproduce the salient features of the wealth distribution in an\neconomy by including taxes to each trading process and redistributing that\ncollected among the population according to a given criterion. Additionally, we\nshow that different optimal levels of taxes may exist depending on the\nredistribution criterion.\n"
    },
    {
        "paper_id": 807.4639,
        "authors": "Gao-Feng Gu (ECUST), Wei-Xing Zhou (ECUST)",
        "title": "Emergence of long memory in stock volatility from a modified Mike-Farmer\n  model",
        "comments": "6 pages, 6 figures and 1 table",
        "journal-ref": "EPL 86, 48002 (2009)",
        "doi": "10.1209/0295-5075/86/48002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Mike-Farmer (MF) model was constructed empirically based on the\ncontinuous double auction mechanism in an order-driven market, which can\nsuccessfully reproduce the cubic law of returns and the diffusive behavior of\nstock prices at the transaction level. However, the volatility (defined by\nabsolute return) in the MF model does not show sound long memory. We propose a\nmodified version of the MF model by including a new ingredient, that is, long\nmemory in the aggressiveness (quantified by the relative prices) of incoming\norders, which is an important stylized fact identified by analyzing the order\nflows of 23 liquid Chinese stocks. Long memory emerges in the volatility\nsynthesized from the modified MF model with the DFA scaling exponent close to\n0.76, and the cubic law of returns and the diffusive behavior of prices are\nalso produced at the same time. We also find that the long memory of order\nsigns has no impact on the long memory property of volatility, and the memory\neffect of order aggressiveness has little impact on the diffusiveness of stock\nprices.\n"
    },
    {
        "paper_id": 807.4958,
        "authors": "Delia Coculescu and Ashkan Nikeghbali",
        "title": "Hazard processes and martingale hazard processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we provide a solution to two problems which have been open in\ndefault time modeling in credit risk. We first show that if $\\tau$ is an\narbitrary random (default) time such that its Az\\'ema's supermartingale\n$Z_t^\\tau=\\P(\\tau>t|\\F_t)$ is continuous, then $\\tau$ avoids stopping times. We\nthen disprove a conjecture about the equality between the hazard process and\nthe martingale hazard process, which first appeared in \\cite{jenbrutk1}, and we\nshow how it should be modified to become a theorem. The pseudo-stopping times,\nintroduced in \\cite{AshkanYor}, appear as the most general class of random\ntimes for which these two processes are equal. We also show that these two\nprocesses always differ when $\\tau$ is an honest time.\n"
    },
    {
        "paper_id": 807.5001,
        "authors": "Raouf Ghomrasni and Olivier Menoukeu Pamen",
        "title": "Decomposition of order statistics of semimartingales using local times",
        "comments": "11 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a recent work \\cite{BG}, given a collection of continuous semimartingales,\nauthors derive a semimartingale decomposition from the corresponding ranked\nprocesses in the case that the ranked processes can meet more than two original\nprocesses at the same time. This has led to a more general decomposition of\nranked processes. In this paper, we derive a more general result for\nsemimartingales (not necessarily continuous) using a simpler approach.\nFurthermore, we also give a generalization of Ouknine \\cite{O1, O2} and Yan's\n\\cite{Y1} formula for local times of ranked processes\n"
    },
    {
        "paper_id": 808.0372,
        "authors": "Naoya Sazuka, Jun-ichi Inoue, Enrico Scalas",
        "title": "The distribution of first-passage times and durations in FOREX and\n  future markets",
        "comments": "26pages, 15figures, using elsart.cls",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2009.03.027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Possible distributions are discussed for intertrade durations and\nfirst-passage processes in financial markets. The view-point of renewal theory\nis assumed. In order to represent market data with relatively long durations,\ntwo types of distributions are used, namely, a distribution derived from the\nso-called Mittag-Leffler survival function and the Weibull distribution. For\nMittag-Leffler type distribution, the average waiting time (residual life time)\nis strongly dependent on the choice of a cut-off parameter t_ max, whereas the\nresults based on the Weibull distribution do not depend on such a cut-off.\nTherefore, a Weibull distribution is more convenient than a Mittag-Leffler type\none if one wishes to evaluate relevant statistics such as average waiting time\nin financial markets with long durations. On the other side, we find that the\nGini index is rather independent of the cut-off parameter. Based on the above\nconsiderations, we propose a good candidate for describing the distribution of\nfirst-passage time in a market: The Weibull distribution with a power-law tail.\nThis distribution compensates the gap between theoretical and empirical results\nmuch more efficiently than a simple Weibull distribution. We also give a useful\nformula to determine an optimal crossover point minimizing the difference\nbetween the empirical average waiting time and the one predicted from renewal\ntheory. Moreover, we discuss the limitation of our distributions by applying\nour distribution to the analysis of the BTP future and calculating the average\nwaiting time. We find that our distribution is applicable as long as durations\nfollow a Weibull-law for short times and do not have too heavy a tail.\n"
    },
    {
        "paper_id": 808.109,
        "authors": "Shane T. Jensen and Stephen H. Shore",
        "title": "Changes in the Distribution of Income Volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent research has documented a significant rise in the volatility (e.g.,\nexpected squared change) of individual incomes in the U.S. since the 1970s.\nExisting measures of this trend abstract from individual heterogeneity,\neffectively estimating an increase in average volatility. We decompose this\nincrease in average volatility and find that it is far from representative of\nthe experience of most people: there has been no systematic rise in volatility\nfor the vast majority of individuals. The rise in average volatility has been\ndriven almost entirely by a sharp rise in the income volatility of those\nexpected to have the most volatile incomes, identified ex-ante by large income\nchanges in the past. We document that the self-employed and those who\nself-identify as risk-tolerant are much more likely to have such volatile\nincomes; these groups have experienced much larger increases in income\nvolatility than the population at large. These results color the policy\nimplications one might draw from the rise in average volatility. While the\nbasic results are apparent from PSID summary statistics, providing a complete\ncharacterization of the dynamics of the volatility distribution is a\nmethodological challenge. We resolve these difficulties with a Markovian\nhierarchical Dirichlet process that builds on work from the non-parametric\nBayesian statistics literature.\n"
    },
    {
        "paper_id": 808.1538,
        "authors": "Jerome Coulon, Yannick Malevergne",
        "title": "Heterogeneous expectations and long range correlation of the volatility\n  of asset returns",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Inspired by the recent literature on aggregation theory, we aim at relating\nthe long range correlation of the stocks return volatility to the heterogeneity\nof the investors' expectations about the level of the future volatility. Based\non a semi-parametric model of investors' anticipations, we make the connection\nbetween the distributional properties of the heterogeneity parameters and the\nauto-covariance/auto-correlation functions of the realized volatility. We\nreport different behaviors, or change of convention, whose observation depends\non the market phase under consideration. In particular, we report and justify\nthe fact that the volatility exhibits significantly longer memory during the\nphases of speculative bubble than during the phase of recovery following the\ncollapse of a speculative bubble.\n"
    },
    {
        "paper_id": 808.1655,
        "authors": "R. Alexander Bentley, Paul Ormerod, Mark E. Madsen",
        "title": "Shelf space strategy in long-tail markets",
        "comments": "10 pages, 3 figures",
        "journal-ref": "Physica A, 388 (2008) 691-696",
        "doi": "10.1016/j.physa.2008.11.009",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Internet is known to have had a powerful impact on on-line retailer\nstrategies in markets characterised by long-tail distribution of sales. Such\nretailers can exploit the long tail of the market, since they are effectively\nwithout physical limit on the number of choices on offer. Here we examine two\nextensions of this phenomenon. First, we introduce turnover into the long-tail\ndistribution of sales. Although over any given period such as a week or a\nmonth, the distribution is right-skewed and often power law distributed, over\ntime there is considerable turnover in the rankings of sales of individual\nproducts. Second, we establish some initial results on the implications for\nshelf-space strategy of physical retailers in such markets.\n"
    },
    {
        "paper_id": 808.171,
        "authors": "Kostas Triantafyllopoulos and Giovanni Montana",
        "title": "Dynamic modeling of mean-reverting spreads for statistical arbitrage",
        "comments": "34 pages, 6 figures. Submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Statistical arbitrage strategies, such as pairs trading and its\ngeneralizations, rely on the construction of mean-reverting spreads enjoying a\ncertain degree of predictability. Gaussian linear state-space processes have\nrecently been proposed as a model for such spreads under the assumption that\nthe observed process is a noisy realization of some hidden states. Real-time\nestimation of the unobserved spread process can reveal temporary market\ninefficiencies which can then be exploited to generate excess returns. Building\non previous work, we embrace the state-space framework for modeling spread\nprocesses and extend this methodology along three different directions. First,\nwe introduce time-dependency in the model parameters, which allows for quick\nadaptation to changes in the data generating process. Second, we provide an\non-line estimation algorithm that can be constantly run in real-time. Being\ncomputationally fast, the algorithm is particularly suitable for building\naggressive trading strategies based on high-frequency data and may be used as a\nmonitoring device for mean-reversion. Finally, our framework naturally provides\ninformative uncertainty measures of all the estimated parameters. Experimental\nresults based on Monte Carlo simulations and historical equity data are\ndiscussed, including a co-integration relationship involving two\nexchange-traded funds.\n"
    },
    {
        "paper_id": 808.1828,
        "authors": "A. Saichev, Y. Malevergne and D. Sornette",
        "title": "Theory of Zipf's Law and of General Power Law Distributions with\n  Gibrat's law of Proportional Growth",
        "comments": "11 pages, 1 figure with 4 panels, summary of a book in press",
        "journal-ref": "Theory of Zipf's Law and beyond, Lecture Notes in Economics and\n  Mathematical Systems, Volume 632, Springer (November 2009) ISBN:\n  978-3-642-02945-5",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We summarize a book under publication with his title written by the three\npresent authors, on the theory of Zipf's law, and more generally of power laws,\ndriven by the mechanism of proportional growth. The preprint is available upon\nrequest from the authors.\n  For clarity, consistence of language and conciseness, we discuss the origin\nand conditions of the validity of Zipf's law using the terminology of firms'\nasset values. We use firms at the entities whose size distributions are to be\nexplained. It should be noted, however, that most of the relations discussed in\nthis book, especially the intimate connection between Zipf's and Gilbrat's\nlaws, underlie Zipf's law in diverse scientific areas. The same models and\nvariations thereof can be straightforwardly applied to any of the other domains\nof application.\n"
    },
    {
        "paper_id": 808.2892,
        "authors": "Ashkan Nikeghbali and Eckhard Platen",
        "title": "On honest times in financial modeling",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper demonstrates the usefulness and importance of the concept of\nhonest times to financial modeling. It studies a financial market with asset\nprices that follow jump-diffusions with negative jumps. The central building\nblock of the market model is its growth optimal portfolio (GOP), which\nmaximizes the growth rate of strictly positive portfolios. Primary security\naccount prices, when expressed in units of the GOP, turn out to be nonnegative\nlocal martingales. In the proposed framework an equivalent risk neutral\nprobability measure need not exist. Derivative prices are obtained as\nconditional expectations of corresponding future payoffs, with the GOP as\nnumeraire and the real world probability as pricing measure. The time when the\nglobal maximum of a portfolio with no positive jumps, when expressed in units\nof the GOP, is reached, is shown to be a generic representation of an honest\ntime. We provide a general formula for the law of such honest times and compute\nthe conditional distributions of the global maximum of a portfolio in this\nframework. Moreover, we provide a stochastic integral representation for\nuniformly integrable martingales whose terminal values are functions of the\nglobal maximum of a portfolio. These formulae are model independent and\nuniversal. We also specialize our results to some examples where we hedge a\npayoff that arrives at an honest time.\n"
    },
    {
        "paper_id": 808.3196,
        "authors": "Anindya S. Chakrabarti, Bikas K. Chakrabarti",
        "title": "Queue-length Variations In A Two-Restaurant Problem",
        "comments": "7 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper attempts to find out numerically the distribution of the\nqueue-length ratio in the context of a model of preferential attachment. Here\nwe consider two restaurants only and a large number of customers (agents) who\ncome to these restaurants. Each day the same number of agents sequentially\narrives and decides which restaurant to enter. If all the agents literally\nfollow the crowd then there is no difference between this model and the famous\n`P\\'olya's Urn' model. But as agents alter their strategies different kind of\ndynamics of the model is seen. It is seen from numerical results that the\nexistence of a distribution of the fixed points is quite robust and it is also\nseen that in some cases the variations in the ratio of the queue-lengths follow\na power-law.\n"
    },
    {
        "paper_id": 808.32,
        "authors": "Fengzhong Wang, Kazuko Yamasaki, Shlomo Havlin and H. Eugene Stanley",
        "title": "Multifactor Analysis of Multiscaling in Volatility Return Intervals",
        "comments": "16 pages, 6 figures",
        "journal-ref": "Phys. Rev. E 79, 016103 (2009)",
        "doi": "10.1103/PhysRevE.79.016103",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the volatility time series of 1137 most traded stocks in the US\nstock markets for the two-year period 2001-02 and analyze their return\nintervals $\\tau$, which are time intervals between volatilities above a given\nthreshold $q$. We explore the probability density function of $\\tau$,\n$P_q(\\tau)$, assuming a stretched exponential function, $P_q(\\tau) \\sim\ne^{-\\tau^\\gamma}$. We find that the exponent $\\gamma$ depends on the threshold\nin the range between $q=1$ and 6 standard deviations of the volatility. This\nfinding supports the multiscaling nature of the return interval distribution.\nTo better understand the multiscaling origin, we study how $\\gamma$ depends on\nfour essential factors, capitalization, risk, number of trades and return. We\nshow that $\\gamma$ depends on the capitalization, risk and return but almost\ndoes not depend on the number of trades. This suggests that $\\gamma$ relates to\nthe portfolio selection but not on the market activity. To further characterize\nthe multiscaling of individual stocks, we fit the moments of $\\tau$, $\\mu_m\n\\equiv <(\\tau/<\\tau>)^m>^{1/m}$, in the range of $10 < <\\tau> \\le 100$ by a\npower-law, $\\mu_m \\sim <\\tau>^\\delta$. The exponent $\\delta$ is found also to\ndepend on the capitalization, risk and return but not on the number of trades,\nand its tendency is opposite to that of $\\gamma$. Moreover, we show that\n$\\delta$ decreases with $\\gamma$ approximately by a linear relation. The return\nintervals demonstrate the temporal structure of volatilities and our findings\nsuggest that their multiscaling features may be helpful for portfolio\noptimization.\n"
    },
    {
        "paper_id": 808.3269,
        "authors": "Alexander S. Balankin",
        "title": "Dynamic scaling approach to study time series fluctuations",
        "comments": "25 pages, 7 figures, 1 table",
        "journal-ref": "PHYSICAL REVIEW E 76, 056120 (2007)",
        "doi": "10.1103/PhysRevE.76.056120",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new approach for properly analyzing stochastic time series by\nmapping the dynamics of time series fluctuations onto a suitable nonequilibrium\nsurface-growth problem. In this framework, the fluctuation sampling time\ninterval plays the role of time variable, whereas the physical time is treated\nas the analog of spatial variable. In this way we found that the fluctuations\nof many real-world time series satisfy the analog of the Family-Viscek dynamic\nscaling ansatz. This finding permits to use the powerful tools of kinetic\nroughening theory to classify, model, and forecast the fluctuations of\nreal-world time series.\n"
    },
    {
        "paper_id": 808.3339,
        "authors": "Kota Watanabe, Hideki Takayasu and Misako Takayasu",
        "title": "Random walker in a temporally deforming higher-order potential forces\n  observed in financial crisis",
        "comments": "5 pages, 13 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.80.056110",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Basic peculiarities of market price fluctuations are known to be well\ndescribed by a recently developed random walk model in a temporally deforming\nquadric potential force whose center is given by a moving average of past price\ntraces [Physica A 370, pp91-97, 2006]. By analyzing high-frequency financial\ntime series of exceptional events such as bubbles and crashes, we confirm the\nappearance of nonlinear potential force in the markets. We show statistical\nsignificance of its existence by applying the information criterion. This new\ntime series analysis is expected to be applied widely for detecting a\nnon-stationary symptom in random phenomena.\n"
    },
    {
        "paper_id": 808.336,
        "authors": "Stanislaw Drozdz, Jaroslaw Kwapien, Pawel Oswiecimka",
        "title": "Criticality Characteristics of Current Oil Price Dynamics",
        "comments": "to appear in Acta Physica Polonica A",
        "journal-ref": "Acta Physica Polonica A 114, 699-702 (2008)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Methodology that recently lead us to predict to an amazing accuracy the date\n(July 11, 2008) of reverse of the oil price up trend is briefly summarized and\nsome further aspects of the related oil price dynamics elaborated. This\nmethodology is based on the concept of discrete scale invariance whose\nfinance-prediction-oriented variant involves such elements as log-periodic\nself-similarity, the universal preferred scaling factor lambda=2, and allows a\nphenomenon of the \"super-bubble\". From this perspective the present (as of\nAugust 22, 2008) violent - but still log-periodically decelerating - decrease\nof the oil prices is associated with the decay of such a \"super- bubble\" that\nhas started developing about one year ago on top of the longer-term oil price\nincreasing phase (normal bubble) whose ultimate termination is evaluated to\noccur in around mid 2010.\n"
    },
    {
        "paper_id": 808.3562,
        "authors": "V. Alfi, M. Cristelli, L. Pietronero, A. Zaccaria",
        "title": "Minimal Agent Based Model for Financial Markets I: Origin and\n  Self-Organization of Stylized Facts",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1140/epjb/e2009-00028-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a minimal Agent Based Model for financial markets to understand\nthe nature and Self-Organization of the Stylized Facts. The model is minimal in\nthe sense that we try to identify the essential ingredients to reproduce the\nmain most important deviations of price time series from a Random Walk\nbehavior. We focus on four essential ingredients: fundamentalist agents which\ntend to stabilize the market; chartist agents which induce destabilization;\nanalysis of price behavior for the two strategies; herding behavior which\ngoverns the possibility of changing strategy. Bubbles and crashes correspond to\nsituations dominated by chartists, while fundamentalists provide a long time\nstability (on average). The Stylized Facts are shown to correspond to an\nintermittent behavior which occurs only for a finite value of the number of\nagents N. Therefore they correspond to finite size effect which, however, can\noccur at different time scales. We propose a new mechanism for the\nSelf-Organization of this state which is linked to the existence of a threshold\nfor the agents to be active or not active. The feedback between price\nfluctuations and number of active agents represent a crucial element for this\nstate of Self-Organized-Intermittency. The model can be easily generalized to\nconsider more realistic variants.\n"
    },
    {
        "paper_id": 808.3565,
        "authors": "V. Alfi, M. Cristelli, L.Pietronero, A. Zaccaria",
        "title": "Minimal Agent Based Model for Financial Markets II: Statistical\n  Properties of the Linear and Multiplicative Dynamics",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1140/epjb/e2009-00029-3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a detailed study of the statistical properties of an Agent Based\nModel and of its generalization to the multiplicative dynamics. The aim of the\nmodel is to consider the minimal elements for the understanding of the origin\nof the Stylized Facts and their Self-Organization. The key elements are\nfundamentalist agents, chartist agents, herding dynamics and price behavior.\nThe first two elements correspond to the competition between stability and\ninstability tendencies in the market. The herding behavior governs the\npossibility of the agents to change strategy and it is a crucial element of\nthis class of models. The linear approximation permits a simple interpretation\nof the model dynamics and, for many properties, it is possible to derive\nanalytical results. The generalized non linear dynamics results to be extremely\nmore sensible to the parameter space and much more difficult to analyze and\ncontrol. The main results for the nature and Self-Organization of the Stylized\nFacts are, however, very similar in the two cases. The main peculiarity of the\nnon linear dynamics is an enhancement of the fluctuations and a more marked\nevidence of the Stylized Facts. We will also discuss some modifications of the\nmodel to introduce more realistic elements with respect to the real markets.\n"
    },
    {
        "paper_id": 808.4012,
        "authors": "Alexander M. G. Cox and Jan K. Ob{\\l}\\'oj",
        "title": "Robust hedging of double touch barrier options",
        "comments": "34 pages, 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider model-free pricing of digital options, which pay out if the\nunderlying asset has crossed both upper and lower barriers. We make only weak\nassumptions about the underlying process (typically continuity), but assume\nthat the initial prices of call options with the same maturity and all strikes\nare known. Under such circumstances, we are able to give upper and lower bounds\non the arbitrage-free prices of the relevant options, and further, using\ntechniques from the theory of Skorokhod embeddings, to show that these bounds\nare tight. Additionally, martingale inequalities are derived, which provide the\ntrading strategies with which we are able to realise any potential arbitrages.\nWe show that, depending of the risk aversion of the investor, the resulting\nhedging strategies can outperform significantly the standard delta/vega-hedging\nin presence of market frictions and/or model misspecification.\n"
    },
    {
        "paper_id": 809.0241,
        "authors": "Giacomo Bormetti, Maria Elena De Giuli, Danilo Delpini and Claudia\n  Tarantola",
        "title": "Bayesian Analysis of Value-at-Risk with Product Partition Models",
        "comments": "30 pages, 6 figures and 6 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a novel Bayesian methodology for Value-at-Risk\ncomputation based on parametric Product Partition Models. Value-at-Risk is a\nstandard tool to measure and control the market risk of an asset or a\nportfolio, and it is also required for regulatory purposes. Its popularity is\npartly due to the fact that it is an easily understood measure of risk. The use\nof Product Partition Models allows us to remain in a Normal setting even in\npresence of outlying points, and to obtain a closed-form expression for\nValue-at-Risk computation. We present and compare two different scenarios: a\nproduct partition structure on the vector of means and a product partition\nstructure on the vector of variances. We apply our methodology to an Italian\nstock market data set from Mib30. The numerical results clearly show that\nProduct Partition Models can be successfully exploited in order to quantify\nmarket risk exposure. The obtained Value-at-Risk estimates are in full\nagreement with Maximum Likelihood approaches, but our methodology provides\nricher information about the clustering structure of the data and the presence\nof outlying points.\n"
    },
    {
        "paper_id": 809.025,
        "authors": "Fei Ren and Wei-Xing Zhou",
        "title": "Multiscaling behavior in the volatility return intervals of Chinese\n  indices",
        "comments": "6 pages, 4 figures, 2 tables",
        "journal-ref": "EPL 84, 68001 (2008)",
        "doi": "10.1209/0295-5075/84/68001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the probability distribution of the return intervals $\\tau$\nbetween successive 1-min volatilities of two Chinese indices exceeding a\ncertain threshold $q$. The Kolmogorov-Smirnov (KS) tests show that the two\nindices exhibit multiscaling behavior in the distribution of $\\tau$, which\nfollows a stretched exponential form $f_q(\\tau/< \\tau >)\\sim e^{- a(\\tau/ <\n\\tau >)^{\\gamma}}$ with different correlation exponent $\\gamma$ for different\nthreshold $q$, where $<\\tau>$ is the mean return interval corresponding to a\ncertain value of $q$. An extended self-similarity analysis of the moments\nprovides further evidence of multiscaling in the return intervals.\n"
    },
    {
        "paper_id": 809.0301,
        "authors": "Ernst Eberlein, Antonis Papapantoleon, Albert N. Shiryaev",
        "title": "Esscher transform and the duality principle for multidimensional\n  semimartingales",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP600 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 5, 1944-1971",
        "doi": "10.1214/09-AAP600",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The duality principle in option pricing aims at simplifying valuation\nproblems that depend on several variables by associating them to the\ncorresponding dual option pricing problem. Here, we analyze the duality\nprinciple for options that depend on several assets. The asset price processes\nare driven by general semimartingales, and the dual measures are constructed\nvia an Esscher transformation. As an application, we can relate swap and quanto\noptions to standard call and put options. Explicit calculations for jump models\nare also provided.\n"
    },
    {
        "paper_id": 809.0437,
        "authors": "A Z Gorski, S. Drozdz, J. Kwapien",
        "title": "Minimal Spanning Tree graphs and power like scaling in FOREX networks",
        "comments": "9 pages, 7 figures",
        "journal-ref": "Acta. Phys. Pol. A114 (2008) 531",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Correlation matrices of foreign exchange rate time series are investigated\nfor 60 world currencies. Minimal Spanning Tree (MST) graphs for the gold,\nsilver and platinum are presented. Inverse power like scaling is discussed for\nthese graphs as well as for four distinct currency groups (major, liquid, less\nliquid and non-tradable). The worst scaling has been found for USD and related\ncurrencies.\n"
    },
    {
        "paper_id": 809.0448,
        "authors": "Eric Engle",
        "title": "The Stock Market as a Game: An Agent Based Approach to Trading in Stocks",
        "comments": "21 pages and accompanying program",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Just as war is sometimes fallaciously represented as a zero sum game -- when\nin fact war is a negative sum game - stock market trading, a positive sum game\nover time, is often erroneously represented as a zero sum game. This is called\nthe \"zero sum fallacy\" -- the erroneous belief that one trader in a stock\nmarket exchange can only improve their position provided some other trader's\nposition deteriorates. However, a positive sum game in absolute terms can be\nrecast as a zero sum game in relative terms. Similarly it appears that negative\nsum games in absolute terms have been recast as zero sum games in relative\nterms: otherwise, why would zero sum games be used to represent situations of\nwar? Such recasting may have heuristic or pedagogic interest but recasting must\nbe clearly explicited or risks generating confusion.\n  Keywords: Game theory, stock trading and agent based AI.\n"
    },
    {
        "paper_id": 809.0481,
        "authors": "Kenta Yamada, Hideki Takayasu, Takatoshi Ito and Misako Takayasu",
        "title": "Solvable Stochastic Dealer Models for Financial Markets",
        "comments": "10 pages, 12 figures, 1 table",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.79.051120",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce solvable stochastic dealer models, which can reproduce basic\nempirical laws of financial markets such as the power law of price change.\nStarting from the simplest model that is almost equivalent to a Poisson random\nnoise generator, the model becomes fairly realistic by adding only two effects,\nthe self-modulation of transaction intervals and a forecasting tendency, which\nuses a moving average of the latest market price changes. Based on the present\nmicroscopic model of markets, we find a quantitative relation with market\npotential forces, which has recently been discovered in the study of market\nprice modeling based on random walks.\n"
    },
    {
        "paper_id": 809.0739,
        "authors": "Gordan \\v{Z}itkovi\\'c",
        "title": "A dual characterization of self-generation and exponential forward\n  performances",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP607 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 6, 2176-2210",
        "doi": "10.1214/09-AAP607",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a mathematical framework for the study of a family of random\nfields--called forward performances--which arise as numerical representation of\ncertain rational preference relations in mathematical finance. Their spatial\nstructure corresponds to that of utility functions, while the temporal one\nreflects a Nisio-type semigroup property, referred to as self-generation. In\nthe setting of semimartingale financial markets, we provide a dual formulation\nof self-generation in addition to the original one, and show equivalence\nbetween the two, thus giving a dual characterization of forward performances.\nThen we focus on random fields with an exponential structure and provide\nnecessary and sufficient conditions for self-generation in that case. Finally,\nwe illustrate our methods in financial markets driven by It\\^o-processes, where\nwe obtain an explicit parametrization of all exponential forward performances.\n"
    },
    {
        "paper_id": 809.0822,
        "authors": "Jean-Philippe Bouchaud, J. Doyne Farmer, Fabrizio Lillo",
        "title": "How markets slowly digest changes in supply and demand",
        "comments": "111 pages, 24 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we revisit the classic problem of tatonnement in price\nformation from a microstructure point of view, reviewing a recent body of\ntheoretical and empirical work explaining how fluctuations in supply and demand\nare slowly incorporated into prices. Because revealed market liquidity is\nextremely low, large orders to buy or sell can only be traded incrementally,\nover periods of time as long as months. As a result order flow is a highly\npersistent long-memory process. Maintaining compatibility with market\nefficiency has profound consequences on price formation, on the dynamics of\nliquidity, and on the nature of impact. We review a body of theory that makes\ndetailed quantitative predictions about the volume and time dependence of\nmarket impact, the bid-ask spread, order book dynamics, and volatility.\nComparisons to data yield some encouraging successes. This framework suggests a\nnovel interpretation of financial information, in which agents are at best only\nweakly informed and all have a similar and extremely noisy impact on prices.\nMost of the processed information appears to come from supply and demand\nitself, rather than from external news. The ideas reviewed here are relevant to\nmarket microstructure regulation, agent-based models, cost-optimal execution\nstrategies, and understanding market ecologies.\n"
    },
    {
        "paper_id": 809.0979,
        "authors": "Ramon Huerta, Fernando Corbacho, Luis F. Lago-Fernandez",
        "title": "A housing-demographic multi-layered nonlinear model to test regulation\n  strategies",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a novel multi-layered nonlinear model that is able to capture and\npredict the housing-demographic dynamics of the real-state market by simulating\nthe transitions of owners among price-based house layers. This model allows us\nto determine which parameters are most effective to smoothen the severity of a\npotential market crisis. The International Monetary Fund (IMF) has issued\nsevere warnings about the current real-state bubble in the United States, the\nUnited Kingdom, Ireland, the Netherlands, Australia and Spain in the last\nyears. Madrid (Spain), in particular, is an extreme case of this bubble. It is,\ntherefore, an excellent test case to analyze housing dynamics in the context of\nthe empirical data provided by the Spanish National Institute of Statistics and\nother sources of data. The model is able to predict the mean house occupancy,\nand shows that i) the house market conditions in Madrid are unstable but not\ncritical; and ii) the regulation of the construction rate is more effective\nthan interest rate changes. Our results indicate that to accommodate the\nconstruction rate to the total population of first-time buyers is the most\neffective way to maintain the system near equilibrium conditions. In addition,\nwe show that to raise interest rates will heavily affect the poorest housing\nbands of the population while the middle class layers remain nearly unaffected.\n"
    },
    {
        "paper_id": 809.104,
        "authors": "J.B. Glattfelder, A. Dupuis and R.B. Olsen",
        "title": "Patterns in high-frequency FX data: Discovery of 12 empirical scaling\n  laws",
        "comments": "26 pages, 3 figures, 23 tables,2nd version (text made more concise\n  and readable, algorithm pseudocode, results unchanged), 5-year datasets\n  (USD-JPY, EUR-USD) provided at http://www.olsen.ch/more/datasets/",
        "journal-ref": "Quant. Financ. 11(4), 599 - 614 (2011) - published online Oct.\n  2010",
        "doi": "10.1080/14697688.2010.481632",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have discovered 12 independent new empirical scaling laws in foreign\nexchange data-series that hold for close to three orders of magnitude and\nacross 13 currency exchange rates. Our statistical analysis crucially depends\non an event-based approach that measures the relationship between different\ntypes of events. The scaling laws give an accurate estimation of the length of\nthe price-curve coastline, which turns out to be surprisingly long. The new\nlaws substantially extend the catalogue of stylised facts and sharply constrain\nthe space of possible theoretical explanations of the market mechanisms.\n"
    },
    {
        "paper_id": 809.1139,
        "authors": "M. Momeni, I. Kourakis, K. Talebi",
        "title": "Fractality feature in oil price fluctuations",
        "comments": "7 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/publicdomain/",
        "abstract": "  The scaling properties of oil price fluctuations are described as a\nnon-stationary stochastic process realized by a time series of finite length.\nAn original model is used to extract the scaling exponent of the fluctuation\nfunctions within a non-stationary process formulation. It is shown that, when\nreturns are measured over intervals less than 10 days, the Probability Density\nFunctions (PDFs) exhibit self-similarity and monoscaling, in contrast to the\nmultifractal behavior of the PDFs at macro-scales (typically larger than one\nmonth). We find that the time evolution of the distributions are well fitted by\na Levy distribution law at micro-scales. The relevance of a Levy distribution\nis made plausible by a simple model of nonlinear transfer\n"
    },
    {
        "paper_id": 809.1393,
        "authors": "I. Onur Filiz, Xin Guo, Jason Morton, Bernd Sturmfels",
        "title": "Graphical models for correlated defaults",
        "comments": "30 pages, 16 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A simple graphical model for correlated defaults is proposed, with explicit\nformulas for the loss distribution. Algebraic geometry techniques are employed\nto show that this model is well posed for default dependence: it represents any\ngiven marginal distribution for single firms and pairwise correlation matrix.\nThese techniques also provide a calibration algorithm based on maximum\nlikelihood estimation. Finally, the model is compared with standard normal\ncopula model in terms of tails of the loss distribution and implied correlation\nsmile.\n"
    },
    {
        "paper_id": 809.1516,
        "authors": "Nicolas Privault, Anthony R\\'eveillac",
        "title": "SURE shrinkage of Gaussian paths and signal identification",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using integration by parts on Gaussian space we construct a Stein Unbiased\nRisk Estimator (SURE) for the drift of Gaussian processes using their local and\noccupation times. By almost-sure minimization of the SURE risk of shrinkage\nestimators we derive an estimation and de-noising procedure for an input signal\nperturbed by a continuous-time Gaussian noise.\n"
    },
    {
        "paper_id": 809.1534,
        "authors": "Katarzyna Sznajd-Weron, Rafa{\\l} Weron and Maja W{\\l}oszczowska",
        "title": "Outflow Dynamics in Modeling Oligopoly Markets: The Case of the Mobile\n  Telecommunications Market in Poland",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1088/1742-5468/2008/11/P11018",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce two models of opinion dynamics in oligopoly\nmarkets and apply them to a situation, where a new entrant challenges two\nincumbents of the same size. The models differ in the way the two forces\ninfluencing consumer choice -- (local) social interactions and (global)\nadvertising -- interact. We study the general behavior of the models using the\nMean Field Approach and Monte Carlo simulations and calibrate the models to\ndata from the Polish telecommunications market. For one of the models\ncriticality is observed -- below a certain critical level of advertising the\nmarket approaches a lock-in situation, where one market leader dominates the\nmarket and all other brands disappear. Interestingly, for both models the best\nfits to real data are obtained for conformity level $p \\in (0.3,0.4)$. This\nagrees very well with the conformity level found by Solomon Asch in his famous\nsocial experiment.\n"
    },
    {
        "paper_id": 809.1612,
        "authors": "Mark M. Meerschaert, Erkan Nane, Yimin Xiao",
        "title": "Correlated continuous time random walks",
        "comments": "13 pages",
        "journal-ref": "Statistics & Probability Letters, 79 (2009), 1194-1202.",
        "doi": "10.1016/j.spl.2009.01.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Continuous time random walks impose a random waiting time before each\nparticle jump. Scaling limits of heavy tailed continuous time random walks are\ngoverned by fractional evolution equations. Space-fractional derivatives\ndescribe heavy tailed jumps, and the time-fractional version codes heavy tailed\nwaiting times. This paper develops scaling limits and governing equations in\nthe case of correlated jumps. For long-range dependent jumps, this leads to\nfractional Brownian motion or linear fractional stable motion, with the time\nparameter replaced by an inverse stable subordinator in the case of heavy\ntailed waiting times. These scaling limits provide an interesting class of\nnon-Markovian, non-Gaussian self-similar processes.\n"
    },
    {
        "paper_id": 809.1747,
        "authors": "Aleksandar Mijatovic",
        "title": "Local time and the pricing of time-dependent barrier options",
        "comments": "32 pages, to appear in Finance and Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A time-dependent double-barrier option is a derivative security that delivers\nthe terminal value $\\phi(S_T)$ at expiry $T$ if neither of the continuous\ntime-dependent barriers $b_\\pm:[0,T]\\to \\RR_+$ have been hit during the time\ninterval $[0,T]$. Using a probabilistic approach we obtain a decomposition of\nthe barrier option price into the corresponding European option price minus the\nbarrier premium for a wide class of payoff functions $\\phi$, barrier functions\n$b_\\pm$ and linear diffusions $(S_t)_{t\\in[0,T]}$. We show that the barrier\npremium can be expressed as a sum of integrals along the barriers $b_\\pm$ of\nthe option's deltas $\\Delta_\\pm:[0,T]\\to\\RR$ at the barriers and that the pair\nof functions $(\\Delta_+,\\Delta_-)$ solves a system of Volterra integral\nequations of the first kind. We find a semi-analytic solution for this system\nin the case of constant double barriers and briefly discus a numerical\nalgorithm for the time-dependent case.\n"
    },
    {
        "paper_id": 809.1985,
        "authors": "Christa Cuchiero, Damir Filipovic, Josef Teichmann",
        "title": "Affine Models",
        "comments": "(short) review article to be published in Encyclopedia of\n  Quantitative Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Affine term structure models have gained significant attention in the finance\nliterature, mainly due to their analytical tractability and statistical\nflexibility. The aim of this article is to present both theoretical foundations\nas well as empirical aspects of the affine model class. Starting from the\noriginal one-factor short-rate models of Vasi\\v{c}ek and Cox \\emph{et al,} we\nprovide an overview of the properties of regular affine processes and explain\ntheir relationship to affine term structure models. Methods for securities\npricing and for parameter estimation are also discussed, demonstrating how the\nanalytical tractability of affine models can be exploited for practical\npurposes.\n"
    },
    {
        "paper_id": 809.227,
        "authors": "Micha{\\l} Barski, Jacek Jakubowski, Jerzy Zabczyk",
        "title": "On incompleteness of bond markets with infinite number of random factors",
        "comments": "18 pages",
        "journal-ref": "Mathematical Finance, (2011), 21, 3, pp. 541-556",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The completeness of a bond market model with infinite number of sources of\nrandomness on a finite time interval in the Heath-Jarrow-Morton framework is\nstudied. It is proved that the market is not complete. A construction of a\nbounded contingent claim, which can not be replicated, is provided.\n"
    },
    {
        "paper_id": 809.2878,
        "authors": "Satya N. Majumdar and Jean-Philippe Bouchaud",
        "title": "Optimal Time to Sell a Stock in Black-Scholes Model: Comment on \"Thou\n  shall buy and hold\", by A. Shiryaev, Z. Xu and X.Y. Zhou",
        "comments": "10 pages, 6 figures included",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We reconsider the problem of optimal time to sell a stock studied recently by\nShiryaev, Xu and Zhou using path integral methods. This method allows us to\nconfirm the results obtained by these authors and extend them to a parameter\nregion inaccessible to the method used by Shiryaev et. al. We also obtain the\nfull distribution of the time t_m at which the maximum of the price is reached\nfor arbitrary values of the drift.\n"
    },
    {
        "paper_id": 809.306,
        "authors": "Masashi Tomoyose, Shouji Fujimoto and Atushi Ishikawa",
        "title": "Non-Gibrat's law in the middle scale region",
        "comments": "8 pages, 14 figures",
        "journal-ref": null,
        "doi": "10.1143/PTPS.179.114",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By using numerical simulation, we confirm that Takayasu--Sato--Takayasu (TST)\nmodel which leads Pareto's law satisfies the detailed balance under Gibrat's\nlaw. In the simulation, we take an exponential tent-shaped function as the\ngrowth rate distribution. We also numerically confirm the reflection law\nequivalent to the equation which gives the Pareto index $\\mu$ in TST model.\nMoreover, we extend the model modifying the stochastic coefficient under a\nNon-Gibrat's law. In this model, the detailed balance is also numerically\nobserved. The resultant pdf is power-law in the large scale Gibrat's law\nregion, and is the log-normal distribution in the middle scale Non-Gibrat's\none. These are accurately confirmed in the numerical simulation.\n"
    },
    {
        "paper_id": 809.3305,
        "authors": "Michael Roper",
        "title": "Implied volatility explosions: European calls and implied volatilities\n  close to expiry in exponential L\\'evy models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We examine the small expiry behaviour of European call options in stock price\nmodels of exponential L\\'evy type. In most cases of interest, we are able to\nidentify the exact small expiry asymptotics. In \"complete generality\" we are\nable to show that the time value of the call option has O(\\tau) decay as \\tau\n(time to expiry) goes to zero. Using our results on the behaviour of call\noptions close to expiry we show that implied volatility explodes as\n$\\tau\\to0^+$ in \"most\" exponential L\\'evy models. Attention is restricted to\ncalls and implied volatilities that are not at-the-money.\n"
    },
    {
        "paper_id": 809.3375,
        "authors": "Stefano Ciliberti, Jean-Philippe Bouchaud, Marc Potters (CFM)",
        "title": "Smile dynamics -- a theory of the implied leverage effect",
        "comments": "Submitted to Wilmott",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study in details the skew of stock option smiles, which is induced by the\nso-called leverage effect on the underlying -- i.e. the correlation between\npast returns and future square returns. This naturally explains the anomalous\ndependence of the skew as a function of maturity of the option. The market cap\ndependence of the leverage effect is analyzed using a one-factor model. We show\nhow this leverage correlation gives rise to a non-trivial smile dynamics, which\nturns out to be intermediate between the \"sticky strike\" and the \"sticky delta\"\nrules. Finally, we compare our result with stock option data, and find that\noption markets overestimate the leverage effect by a large factor, in\nparticular for long dated options.\n"
    },
    {
        "paper_id": 809.3405,
        "authors": "Ernst Eberlein, Kathrin Glau and Antonis Papapantoleon",
        "title": "Analysis of Fourier transform valuation formulas and applications",
        "comments": "26 pages, 3 figures, to appear in Appl. Math. Finance",
        "journal-ref": "Applied Mathematical Finance 2010, Vol. 17, No. 3, 211-240",
        "doi": "10.1080/13504860903326669",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this article is to provide a systematic analysis of the conditions\nsuch that Fourier transform valuation formulas are valid in a general\nframework; i.e. when the option has an arbitrary payoff function and depends on\nthe path of the asset price process. An interplay between the conditions on the\npayoff function and the process arises naturally. We also extend these results\nto the multi-dimensional case, and discuss the calculation of Greeks by Fourier\ntransform methods. As an application, we price options on the minimum of two\nassets in L\\'evy and stochastic volatility models.\n"
    },
    {
        "paper_id": 809.3418,
        "authors": "Teresa Vaz Martins, Tanya Araujo, Maria Augusta Santos, Miguel St\n  Aubyn",
        "title": "Network effects in a human capital based economic growth model",
        "comments": "to appear in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2009.02.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit a recently introduced agent model[ACS {\\bf 11}, 99 (2008)], where\neconomic growth is a consequence of education (human capital formation) and\ninnovation, and investigate the influence of the agents' social network, both\non an agent's decision to pursue education and on the output of new ideas.\nRegular and random networks are considered. The results are compared with the\npredictions of a mean field (representative agent) model.\n"
    },
    {
        "paper_id": 809.3541,
        "authors": "Hideaki Aoyama, Hiroshi Yoshikawa, Hiroshi Iyetomi and Yoshi Fujiwara",
        "title": "Labour Productivity Superstatistics",
        "comments": "13 pages including figures",
        "journal-ref": null,
        "doi": "10.1143/PTPS.179.80",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss superstatistics theory of labour productivity. Productivity\ndistribution across workers, firms and industrial sectors are studied\nempirically and found to obey power-distributions, in sharp contrast to the\nequilibrium theories of mainstream economics. The Pareto index is found to\ndecrease with the level of aggregation, {\\it i.e.}, from workers to firms and\nto industrial sectors. In order to explain these phenomenological laws, we\npropose a superstatistics framework, where the role of the fluctuating\ntemperature is played by the fluctuating demand.\n"
    },
    {
        "paper_id": 809.3714,
        "authors": "Laurent Gosse (CNR BARI), Olof Runborg",
        "title": "Existence, uniqueness and a constructive solution algorithm for a class\n  of finite Markov moment problems",
        "comments": null,
        "journal-ref": "SIAM J. Appl. Math. 68, 6 (2008) 1618-1640",
        "doi": "10.1137/070692510",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a class of finite Markov moment problems with arbitrary number of\npositive and negative branches. We show criteria for the existence and\nuniqueness of solutions, and we characterize in detail the non-unique solution\nfamilies. Moreover, we present a constructive algorithm to solve the moment\nproblems numerically and prove that the algorithm computes the right solution.\n"
    },
    {
        "paper_id": 809.3824,
        "authors": "Jocelyne Bion-Nadal",
        "title": "Time Consistent Dynamic Limit Order Books Calibrated on Options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an incomplete financial market, the axiomatic of Time Consistent Pricing\nProcedure (TCPP), recently introduced, is used to assign to any financial asset\na dynamic limit order book, taking into account both the dynamics of basic\nassets and the limit order books for options.\n  Kreps-Yan fundamental theorem is extended to that context. A characterization\nof TCPP calibrated on options is given in terms of their dual representation.\nIn case of perfectly liquid options, these options can be used as the basic\nassets to hedge dynamically. A generic family of TCPP calibrated on option\nprices is constructed, from cadlag BMO martingales.\n"
    },
    {
        "paper_id": 809.3902,
        "authors": "Alessandro De Gregorio, Stefano Maria Iacus",
        "title": "Clustering of discretely observed diffusion processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper a new dissimilarity measure to identify groups of assets\ndynamics is proposed. The underlying generating process is assumed to be a\ndiffusion process solution of stochastic differential equations and observed at\ndiscrete time. The mesh of observations is not required to shrink to zero. As\ndistance between two observed paths, the quadratic distance of the\ncorresponding estimated Markov operators is considered. Analysis of both\nsynthetic data and real financial data from NYSE/NASDAQ stocks, give evidence\nthat this distance seems capable to catch differences in both the drift and\ndiffusion coefficients contrary to other commonly used metrics.\n"
    },
    {
        "paper_id": 809.3978,
        "authors": "Karol Wawrzyniak, Wojciech Wislicki",
        "title": "Multi-market minority game: breaking the symmetry of choice",
        "comments": "15 pages, 12 figures, Accepted to 'Advances in Complex Systems'",
        "journal-ref": "Adv.Complex Syst. 12:423-437,2009",
        "doi": "10.1142/S0219525909002313",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Generalization of the minority game to more than one market is considered. At\neach time step every agent chooses one of its strategies and acts on the market\nrelated to this strategy. If the payoff function allows for strong fluctuation\nof utility then market occupancies become inhomogeneous with preference given\nto this market where the fluctuation occured first. There exists a critical\nsize of agent population above which agents on bigger market behave\ncollectively. In this regime there always exists a history of decisions for\nwhich all agents on a bigger market react identically.\n"
    },
    {
        "paper_id": 809.4139,
        "authors": "Matus Medo",
        "title": "Breakdown of the mean-field approximation in a wealth distribution model",
        "comments": "11 pages, 3 figures",
        "journal-ref": "Journal of Statistical Mechanics, P02014 (2009)",
        "doi": "10.1088/1742-5468/2009/02/P02014",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One of the key socioeconomic phenomena to explain is the distribution of\nwealth. Bouchaud and M\\'ezard have proposed an interesting model of economy\n[Bouchaud and M\\'ezard (2000)] based on trade and investments of agents. In the\nmean-field approximation, the model produces a stationary wealth distribution\nwith a power-law tail. In this paper we examine characteristic time scales of\nthe model and show that for any finite number of agents, the validity of the\nmean-field result is time-limited and the model in fact has no stationary\nwealth distribution. Further analysis suggests that for heterogeneous agents,\nthe limitations are even stronger. We conclude with general implications of the\npresented results.\n"
    },
    {
        "paper_id": 809.4372,
        "authors": "Henrik Hult, Filip Lindskog",
        "title": "Ruin probabilities under general investments and heavy-tailed claims",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study the asymptotic decay of finite time ruin probabilities\nfor an insurance company that faces heavy-tailed claims, uses predictable\ninvestment strategies and makes investments in risky assets whose prices evolve\naccording to quite general semimartingales. We show that the ruin problem\ncorresponds to determining hitting probabilities for the solution to a randomly\nperturbed stochastic integral equation. We derive a large deviation result for\nthe hitting probabilities that holds uniformly over a family of semimartingales\nand show that this result gives the asymptotic decay of finite time ruin\nprobabilities under arbitrary investment strategies, including optimal\ninvestment strategies.\n"
    },
    {
        "paper_id": 809.457,
        "authors": "Sonia R. Bentes, Rui Menezes, Diana A. Mendes",
        "title": "Stock market volatility: An approach based on Tsallis entropy",
        "comments": "15 pages, 2 figures, 2 tables, presented at SigmaPhi2008 Conference",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  One of the major issues studied in finance that has always intrigued, both\nscholars and practitioners, and to which no unified theory has yet been\ndiscovered, is the reason why prices move over time. Since there are several\nwell-known traditional techniques in the literature to measure stock market\nvolatility, a central point in this debate that constitutes the actual scope of\nthis paper is to compare this common approach in which we discuss such popular\ntechniques as the standard deviation and an innovative methodology based on\nEconophysics. In our study, we use the concept of Tsallis entropy to capture\nthe nature of volatility. More precisely, what we want to find out is if\nTsallis entropy is able to detect volatility in stock market indexes and to\ncompare its values with the ones obtained from the standard deviation. Also, we\nshall mention that one of the advantages of this new methodology is its ability\nto capture nonlinear dynamics. For our purpose, we shall basically focus on the\nbehaviour of stock market indexes and consider the CAC 40, MIB 30, NIKKEI 225,\nPSI 20, IBEX 35, FTSE 100 and SP 500 for a comparative analysis between the\napproaches mentioned above.\n"
    },
    {
        "paper_id": 809.4615,
        "authors": "M. Tumminello, F. Lillo, R.N. Mantegna",
        "title": "Correlation, hierarchies, and networks in financial markets",
        "comments": "37 pages, 9 figures, 3 tables",
        "journal-ref": "J. Econ. Behav. Organ. 75, pp. 40-58 (2010)",
        "doi": "10.1016/j.jebo.2010.01.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss some methods to quantitatively investigate the properties of\ncorrelation matrices. Correlation matrices play an important role in portfolio\noptimization and in several other quantitative descriptions of asset price\ndynamics in financial markets. Specifically, we discuss how to define and\nobtain hierarchical trees, correlation based trees and networks from a\ncorrelation matrix. The hierarchical clustering and other procedures performed\non the correlation matrix to detect statistically reliable aspects of the\ncorrelation matrix are seen as filtering procedures of the correlation matrix.\nWe also discuss a method to associate a hierarchically nested factor model to a\nhierarchical tree obtained from a correlation matrix. The information retained\nin filtering procedures and its stability with respect to statistical\nfluctuations is quantified by using the Kullback-Leibler distance.\n"
    },
    {
        "paper_id": 809.4781,
        "authors": "Michail Anthropelos, Nikolaos E. Frangos, Stylianos Z. Xanthopoulos,\n  Athanasios N. Yannacopoulos",
        "title": "On contingent claims pricing in incomplete markets: A risk sharing\n  approach",
        "comments": "This paper has been withdrawn by the author since its revised version\n  includes several modifications",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an incomplete market setting, we consider two financial agents, who wish\nto price and trade a non-replicable contingent claim. Assuming that the agents\nare utility maximizers, we propose a transaction price which is a result of the\nminimization of a convex combination of their utility differences. We call this\nprice the risk sharing price, we prove its existence for a large family of\nutility functions and we state some of its properties. As an example, we\nanalyze extensively the case where both agents report exponential utility.\n"
    },
    {
        "paper_id": 810.0055,
        "authors": "Samuel N. Cohen, Robert J. Elliott",
        "title": "Comparisons for backward stochastic differential equations on Markov\n  chains and related no-arbitrage conditions",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP619 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 1, 267-311",
        "doi": "10.1214/09-AAP619",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Most previous contributions to BSDEs, and the related theories of nonlinear\nexpectation and dynamic risk measures, have been in the framework of continuous\ntime diffusions or jump diffusions. Using solutions of BSDEs on spaces related\nto finite state, continuous time Markov chains, we develop a theory of\nnonlinear expectations in the spirit of [Dynamically consistent nonlinear\nevaluations and expectations (2005) Shandong Univ.]. We prove basic properties\nof these expectations and show their applications to dynamic risk measures on\nsuch spaces. In particular, we prove comparison theorems for scalar and vector\nvalued solutions to BSDEs, and discuss arbitrage and risk measures in the\nscalar case.\n"
    },
    {
        "paper_id": 810.0678,
        "authors": "Roman Naryshkin and Matt Davison",
        "title": "Portfolio Optimization under Habit Formation",
        "comments": "19 pages, 17 figures, presented at MOPTA 2008, August 18 - 20, 2008,\n  University of Guelph, Guelph, Ontario, Canada",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The \"standard\" Merton formulation of optimal investment and consumption\ninvolves optimizing the integrated lifetime utility of consumption, suitably\ndiscounted, together with the discounted future bequest. In this formulation\nthe utility of consumption at any given time depends only on the amount\nconsumed at that time. However, it is both theoretically and empirically\nreasonable that an individuals utility of consumption would depend on past\nconsumption history. Economists term this \"Habit Formation\". We introduce a new\nformulation of habit formation which allows non-addictive consumption patterns\nfor a wide variety of utility specification. In this paper we construct a\nsimple mathematical description of this habit formation and present numerical\nsolutions. We compare the results with the standard ones and draw insights\nobtained from the habit formation. The consumption path tends to increase with\ntime and be less sensitive to the market fluctuations, which perfectly reflects\nthe existence of habit persistence of an investor. At the same time, his\ndecreasing risk aversion, which seems to be in contradiction with the empirical\nevidence, can be explained within the limitations of the model.\n"
    },
    {
        "paper_id": 810.0917,
        "authors": "Moawia Alghalith",
        "title": "Hedging and production decisions under uncertainty: A survey",
        "comments": "Submitted to the Probability Surveys (http://www.i-journals.org/ps/)\n  by the Institute of Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper synthesizes and analyzes some important current and recent\ncontributions to the theory of the firm under uncertainty. In so doing, it\nexamines the production and hedging decisions of the competitive firm under a\nsingle source and multiple sources of uncertainty.\n"
    },
    {
        "paper_id": 810.1059,
        "authors": "Ju-Yi Yen, Marc Yor",
        "title": "Measuring the \"non-stopping timeness\" of ends of previsible sets",
        "comments": "7 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we propose several \"measurements\" of the \"non-stopping\ntimeness\" of ends g of previsible sets, such that g avoids stopping times, in\nan ambiant filtration. We then study several explicit examples, involving last\npassage times of some remarkable martingales.\n"
    },
    {
        "paper_id": 810.1215,
        "authors": "A. Z. Gorski, S. Drozdz, J. Kwapien",
        "title": "Scale free effects in world currency exchange network",
        "comments": "Eur. Phys. J. B (2008) in press",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2008-00376-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A large collection of daily time series for 60 world currencies' exchange\nrates is considered. The correlation matrices are calculated and the\ncorresponding Minimal Spanning Tree (MST) graphs are constructed for each of\nthose currencies used as reference for the remaining ones. It is shown that\nmultiplicity of the MST graphs' nodes to a good approximation develops a power\nlike, scale free distribution with the scaling exponent similar as for several\nother complex systems studied so far. Furthermore, quantitative arguments in\nfavor of the hierarchical organization of the world currency exchange network\nare provided by relating the structure of the above MST graphs and their\nscaling exponents to those that are derived from an exactly solvable\nhierarchical network model. A special status of the USD during the period\nconsidered can be attributed to some departures of the MST features, when this\ncurrency (or some other tied to it) is used as reference, from characteristics\ntypical to such a hierarchical clustering of nodes towards those that\ncorrespond to the random graphs. Even though in general the basic structure of\nthe MST is robust with respect to changing the reference currency some trace of\na systematic transition from somewhat dispersed -- like the USD case -- towards\nmore compact MST topology can be observed when correlations increase.\n"
    },
    {
        "paper_id": 810.1625,
        "authors": "Bernardo Spagnolo and Davide Valenti",
        "title": "Volatility Effects on the Escape Time in Financial Market Models",
        "comments": "12 pages, 9 figures, to appear in Int. J. of Bifurcation and Chaos,\n  2008",
        "journal-ref": "Intern. Journ. of Bifurcation and Chaos, Vol. 18, No. 9, 2775 -\n  2786 (2008)",
        "doi": "10.1142/S0218127408022007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We shortly review the statistical properties of the escape times, or hitting\ntimes, for stock price returns by using different models which describe the\nstock market evolution. We compare the probability function (PF) of these\nescape times with that obtained from real market data. Afterwards we analyze in\ndetail the effect both of noise and different initial conditions on the escape\ntime in a market model with stochastic volatility and a cubic nonlinearity. For\nthis model we compare the PF of the stock price returns, the PF of the\nvolatility and the return correlation with the same statistical characteristics\nobtained from real market data.\n"
    },
    {
        "paper_id": 810.1922,
        "authors": "Gilles Daniel, Didier Sornette and Peter Wohrmann",
        "title": "Look-Ahead Benchmark Bias in Portfolio Performance Evaluation",
        "comments": "16 pages, 1 table, 4 figures",
        "journal-ref": "Journal of Portfolio Management 36 (1), 121-130 (Fall 2009)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Performance of investment managers are evaluated in comparison with\nbenchmarks, such as financial indices. Due to the operational constraint that\nmost professional databases do not track the change of constitution of\nbenchmark portfolios, standard tests of performance suffer from the \"look-ahead\nbenchmark bias,\" when they use the assets constituting the benchmarks of\nreference at the end of the testing period, rather than at the beginning of the\nperiod. Here, we report that the \"look-ahead benchmark bias\" can exhibit a\nsurprisingly large amplitude for portfolios of common stocks (up to 8% annum\nfor the S&P500 taken as the benchmark) -- while most studies have emphasized\nrelated survival biases in performance of mutual and hedge funds for which the\nbiases can be expected to be even larger. We use the CRSP database from 1926 to\n2006 and analyze the running top 500 US capitalizations to demonstrate that\nthis bias can account for a gross overestimation of performance metrics such as\nthe Sharpe ratio as well as an underestimation of risk, as measured for\ninstance by peak-to-valley drawdowns. We demonstrate the presence of a\nsignificant bias in the estimation of the survival and look-ahead biases\nstudied in the literature. A general methodology to test the properties of\ninvestment strategies is advanced in terms of random strategies with similar\ninvestment constraints.\n"
    },
    {
        "paper_id": 810.2016,
        "authors": "Teemu Pennanen and Irina Penner",
        "title": "Hedging of claims with physical delivery under convex transaction costs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study superhedging of contingent claims with physical delivery in a\ndiscrete-time market model with convex transaction costs. Our model extends\nKabanov's currency market model by allowing for nonlinear illiquidity effects.\nWe show that an appropriate generalization of Schachermayer's robust no\narbitrage condition implies that the set of claims hedgeable with zero cost is\nclosed in probability. Combined with classical techniques of convex analysis,\nthe closedness yields a dual characterization of premium processes that are\nsufficient to superhedge a given claim process. We also extend the fundamental\ntheorem of asset pricing for general conical models.\n"
    },
    {
        "paper_id": 810.2508,
        "authors": "Rui Gon\\c{c}alves, Alberto Pinto",
        "title": "Universality in the stock exchange",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the constituents stocks of the Dow Jones Industrial Average\n(DJIA30) and the Standard & Poor's 100 index (S&P100) of the NYSE stock\nexchange market. Surprisingly, we discover the data collapse of the histograms\nof the DJIA30 price fluctuations and of the S&P100 price fluctuations to the\nuniversal non-parametric Bramwell-Holdsworth-Pinton (BHP) distribution. Since\nthe BHP probability density function appears in several other dissimilar\nphenomena, our result reveals an universal feature of the stock exchange\nmarket.\n"
    },
    {
        "paper_id": 810.4,
        "authors": "Victor Lebreton (CES)",
        "title": "Le trading algorithmique",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The algorithmic trading comes from digitalisation of the processing of\ntrading assets on financial markets. Since 1980 the computerization of the\nstock market offers real time processing of financial information. This\ntechnological revolution has offered processes and mathematic methods to\nidentify best return on transactions. Current research relates to autonomous\ntransaction systems programmed in certain periods and some algorithms. This\noffers return opportunities where traders can not intervene. There are about\nthirty algorithms to assist the traders, the best known are the VWAP, the TWAP,\nTVOL. The algorithms offer the latest strategies and decision-making are the\nsubject of much research. These advances in modeling decision-making autonomous\nagent can envisage a rich future for these technologies, the players already in\nuse for more than 30% of their trading.\n"
    },
    {
        "paper_id": 810.4409,
        "authors": "Sergey Zaitsev, Alexander Zaitsev, Andrei Leonidov, Vladimir Trainin",
        "title": "Market Mill Dependence Pattern in the Stock Market: Multiscale\n  Conditional Dynamics",
        "comments": "Typo's corrected",
        "journal-ref": "Physica A, 388, Issue 21, 2009, 4624-4634",
        "doi": "10.1016/j.physa.2009.07.014",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Market Mill is a complex dependence pattern leading to nonlinear correlations\nand predictability in intraday dynamics of stock prices. The present paper puts\ntogether previous efforts to build a dynamical model reflecting the market mill\nasymmetries. We show that certain properties of the conditional dynamics at a\nsingle time scale such as a characteristic shape of an asymmetry generating\ncomponent of the conditional probability distribution result in the\n\"elementary\" market mill pattern. This asymmetry generating component matches\nthe empirical distribution obtained from the market data. We discuss these\nproperties as a mixture of trend-preserving and contrarian strategies used by\nmarket agents. Three basic types of asymmetry patterns characterizing\nindividual stocks are outlined. Multiple time scale considerations make the\nresulting \"composite\" mill similar to the empirical market mill patterns.\nMultiscale model also reflects a multi-agent nature of the market.\n"
    },
    {
        "paper_id": 810.4608,
        "authors": "D. Sornette",
        "title": "Trust! Why it Has Been Lost and How to Regain It",
        "comments": "7 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This essay suggests that a proper assessment of the presently unfolding\nfinancial crisis, and its cure, requires going back at least to the late 1990s,\naccounting for the cumulative effect of the ITC, real-estate and financial\nderivative bubbles. We focus on the deep loss of trust, not only in Wall\nStreet, but more importantly in Main Street, and how to recover it on the short\nand long terms. A multi-disciplinary approach is needed to deal with the\nnonlinear complex systems of the present world, in order to develop a culture\nof fairness, and of upside opportunities associated with a risky world.\n"
    },
    {
        "paper_id": 810.4844,
        "authors": "Miquel Montero",
        "title": "Predator-Prey Model for Stock Market Fluctuations",
        "comments": "revtex, 31 pages in preprint style, 12 figures; new material added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a dynamical model for the price evolution of financial assets. The\nmodel is based in a two level structure. In the first stage one finds an\nagent-based model that describes the present state of the investors' beliefs,\nperspectives or strategies. The dynamics is inspired by a model for describing\npredator-prey population evolution: agents change their mind through self- or\nmutual interaction, and the decision is adopted on a random basis, with no\ndirect influence of the price itself. One of the most appealing properties of\nsuch a system is the presence of large oscillations in the number of agents\nsharing the same perspective, what may be linked with the existence of bullish\nand bearish periods in financial markets. In the second stage one has the\npricing mechanism, which will be driven by the relative population in the\ndifferent investors' groups. The price equation will depend on the specific\nnature of the species, and thus it may change from one market to the other: we\nwill firstly present a simple model of excess demand, and subsequently consider\na more elaborate liquidity model. The outcomes of both models are analysed and\ncompared.\n"
    },
    {
        "paper_id": 810.4912,
        "authors": "Simone Bianco, Fulvio Corsi, Roberto Reno'",
        "title": "Serial correlation and heterogeneous volatility in financial markets:\n  beyond the LeBaron effect",
        "comments": "7 Pages, 2 figures, 1 table. Submitted version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the relation between serial correlation of financial returns and\nvolatility at intraday level for the S&P500 stock index. At daily and weekly\nlevel, serial correlation and volatility are known to be negatively correlated\n(LeBaron effect). While confirming that the LeBaron effect holds also at\nintraday level, we go beyond it and, complementing the efficient market\nhyphotesis (for returns) with the heterogenous market hyphotesis (for\nvolatility), we test the impact of unexpected volatility, defined as the part\nof volatility which cannot be forecasted, on the presence of serial\ncorrelations in the time series. We show that unexpected volatility is instead\npositively correlated with intraday serial correlation.\n"
    },
    {
        "paper_id": 810.5146,
        "authors": "Michael Schmutz",
        "title": "Semi-static hedging for certain Margrabe type options with barriers",
        "comments": "18 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It turns out that in the bivariate Black-Scholes economy Margrabe type\noptions exhibit symmetry properties leading to semi-static hedges of rather\ngeneral barrier options. Some of the results are extended to variants obtained\nby means of Brownian subordination. In order to increase the liquidity of the\nhedging instruments for certain currency options, the duality principle can be\napplied to set up hedges in a foreign market by using only European vanilla\noptions sometimes along with a risk-less bond. Since the semi-static hedges in\nthe Black-Scholes economy are exact, closed form valuation formulas for certain\nbarrier options can be easily derived.\n"
    },
    {
        "paper_id": 810.5306,
        "authors": "Jean-Philippe Bouchaud (CFM)",
        "title": "Economics need a scientific revolution",
        "comments": "An edited version of this essay appeared in Nature",
        "journal-ref": "Nature, vol 455, p. 1181 (2008)",
        "doi": "10.1038/4551181a",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I argue that the current financial crisis highlights the crucial need of a\nchange of mindset in economics and financial engineering, that should move away\nfrom dogmatic axioms and focus more on data, orders of magnitudes, and\nplausible, albeit non rigorous, arguments.\n"
    },
    {
        "paper_id": 810.5698,
        "authors": "Said Hamadene and Jianfeng Zhang",
        "title": "The Continuous Time Nonzero-sum Dynkin Game Problem and Application in\n  Game Options",
        "comments": "16 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we study the nonzero-sum Dynkin game in continuous time which\nis a two player non-cooperative game on stopping times. We show that it has a\nNash equilibrium point for general stochastic processes. As an application, we\nconsider the problem of pricing American game contingent claims by the utility\nmaximization approach.\n"
    },
    {
        "paper_id": 811.0182,
        "authors": "William T. Shaw",
        "title": "A model of returns for the post-credit-crunch reality: Hybrid Brownian\n  motion with price feedback",
        "comments": "3 figures; Aug 30: Further corrections and citations; Aug 09 update:\n  links to integrals of exponential Brownian motion; more exact solutions;\n  relations to other work. previous update: Simple VaR, more exact solutions,\n  relation to Legendre equation. In Update: Corrections; better history; more\n  exact solutions; discussion of market states",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The market events of 2007-2009 have reinvigorated the search for realistic\nreturn models that capture greater likelihoods of extreme movements. In this\npaper we model the medium-term log-return dynamics in a market with both\nfundamental and technical traders. This is based on a Poisson trade arrival\nmodel with variable size orders. With simplifications we are led to a hybrid\nSDE mixing both arithmetic and geometric Brownian motions, whose solution is\ngiven by a class of integrals of exponentials of one Brownian motion against\nanother, in forms considered by Yor and collaborators. The reduction of the\nhybrid SDE to a single Brownian motion leads to an SDE of the form considered\nby Nagahara, which is a type of \"Pearson diffusion\", or equivalently a\nhyperbolic OU SDE. Various dynamics and equilibria are possible depending on\nthe balance of trades. Under mean-reverting circumstances we arrive naturally\nat an equilibrium fat-tailed return distribution with a Student or Pearson Type\nIV form. Under less restrictive assumptions richer dynamics are possible,\nincluding bimodal structures. The phenomenon of variance explosion is\nidentified that gives rise to much larger price movements that might have a\npriori been expected, so that \"$25\\sigma$\" events are significantly more\nprobable. We exhibit simple example solutions of the Fokker-Planck equation\nthat shows how such variance explosion can hide beneath a standard Gaussian\nfacade. These are elementary members of an extended class of distributions with\na rich and varied structure, capable of describing a wide range of market\nbehaviours. Several approaches to the density function are possible, and an\nexample of the computation of a hyperbolic VaR is given. The model also\nsuggests generalizations of the Bougerol identity.\n"
    },
    {
        "paper_id": 811.0352,
        "authors": "Ivan O. Kitov",
        "title": "Evolution of the personal income distribution in the USA: High incomes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The personal income distribution (PID) above the Pareto threshold is studied\nand modeled. A microeconomic model is proposed to simulate the PID and its\nevolution below and above the Pareto income threshold. The model balances\nprocesses of income production and dissipation for any person above 15 years of\nage. The model accurately predicts the observed dependence of the number of\npeople reaching the Pareto threshold on work experience and the functional\ndependence of the relationship on the per capita real GDP growth for the period\nfrom 1994 to 2002. Predictions of the income distribution depending on age are\ngiven for past and future. In future, relatively less rich people are observed\nin the younger age groups and the peak of the relative number shifts to older\nages with time. The effect of the power law distribution extending itself to\nvery high incomes is speculated to be the cause of low performance of socialist\ncountries.\n"
    },
    {
        "paper_id": 811.0356,
        "authors": "Ivan O. Kitov",
        "title": "Modeling the evolution of Gini coefficient for personal incomes in the\n  USA between 1947 and 2005",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The evolution of Gini coefficient for personal incomes in the USA between\n1947 and 2005 is analyzed and modeled. There are several versions of personal\nincome distribution (PID) provided by the US Census Bureau (US CB) for this\nperiod with various levels of resolution. Effectively, these PIDs result in\ndifferent Gini coefficients due to the differences between discrete and\ncontinuous representations. When all persons of 15 years of age and over are\nincluded in the PIDs, Gini coefficient drops from 0.64 in 1947 to 0.54 in 1990.\nThis effect is observed due to a significant decrease in the portion of people\nwithout income. For the PIDs not including persons without income, Gini\ncoefficient is varying around 0.51 between 1960 and 2005 with standard\ndeviation of 0.004, i.e. is in fact constant. This Gini coefficient is\npractically independent on the portion of population included in the PIDs\naccording to any revision of income definitions. The driving force of the model\ndescribing the evolution of individual incomes (microeconomic level) and their\naggregate value (macroeconomic level) is the change in nominal GDP per capita.\nThe model accurately predicts the evolution of Gini coefficient for the PIDs\nfor people with income. The model gives practically unchanged (normalized) PIDs\nand Gini coefficient between 1947 and 2005. The empirical Gini curves converge\nto the predicted one when the number of people without income decreases.\nAsymptotically, the empirical curves should collapse to the theoretical one\nwhen all the working age population obtains an appropriate definition of\nincome. Therefore the model Gini coefficient potentially better describes true\nbehavior of inequality in the USA because the definitions of income used by the\nUS Census Bureau apparently fail to describe true income distribution.\n"
    },
    {
        "paper_id": 811.0376,
        "authors": "Ivan O. Kitov, Oleg I. Kitov",
        "title": "Exact prediction of S&P 500 returns",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A linear link between S&P 500 return and the change rate of the number of\nnine-year-olds in the USA has been found. The return is represented by a sum of\nmonthly returns during previous twelve months. The change rate of the specific\nage population is represented by moving averages. The period between January\n1990 and December 2003 is described by monthly population intercensal estimates\nas provided by the US Census Bureau. Four years before 1990 are described using\nthe estimates of the number of 17 year-olds shifted 8 years back. The\nprediction of S&P 500 returns for the months after 2003, including those beyond\n2007, are obtained using the number of 3 year-olds between 1990 and 2003\nshifted by 6 years ahead and quarterly estimates of real GDP per capita. A\nprediction is available for the period beyond 2007. There are two sharp drops\nin the predicted returns - in 2007 and 2009, and one strong rally in 2008.\nEquivalently, S&P 500 index should drop in 2007 and 2009 to the level observed\none year before. Potential link between S&P 500 returns and 9-year-old\npopulation is tested for cointegration. The Engle-Granger and Johansen tests\ndemonstrate the presence of a long-term equilibrium (cointegrating) relation\nbetween these variables. This makes valid standard statistical estimates.\nCorrelation between the predicted and observed indices, including RMS\ndifference, linear regression, and VAR demonstrate good prediction accuracy at\ntwo-year horizon, when the prediction uses 7-year-olds instead of 9-year-olds.\nThe RMS difference between the observed and predicted returns for the period\nbetween 1992 and 2003 is only 0.09 with standard deviation of the observed\nseries for the same period of 0.12 and the naive (random walk) RMS deference of\n0.18.\n"
    },
    {
        "paper_id": 811.0448,
        "authors": "Cheoljun Eom, Okyu Kwon, Woo-Sung Jung",
        "title": "Statistical properties of information flow in financial time series",
        "comments": "This paper has been withdrawn by the authors",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper has been withdrawn by the authors.\n"
    },
    {
        "paper_id": 811.0473,
        "authors": "B. Stehlikova, D. Sevcovic",
        "title": "On non-existence of a one factor interest rate model for volatility\n  averaged generalized Fong-Vasicek term structures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this paper is to study the generalized Fong--Vasicek\ntwo-factor interest rate model with stochastic volatility. In this model the\ndispersion of the stochastic short rate (square of volatility) is assumed to be\nstochastic as well and it follows a non-negative process with volatility\nproportional to the square root of dispersion. The drift of the stochastic\nprocess for the dispersion is assumed to be in a rather general form including,\nin particular, linear function having one root (yielding the original\nFong--Vasicek model or a cubic like function having three roots (yielding a\ngeneralized Fong--Vasicek model for description of the volatility clustering).\nWe consider averaged bond prices with respect to the limiting distribution of\nstochastic dispersion. The averaged bond prices depend on time and current\nlevel of the short rate like it is the case in many popular one-factor interest\nrate model including in particular the Vasicek and Cox--Ingersoll-Ross model.\nHowever, as a main result of this paper we show that there is no such\none-factor model yielding the same bond prices as the averaged values described\nabove.\n"
    },
    {
        "paper_id": 811.0489,
        "authors": "Ivan O. Kitov",
        "title": "Modelling the average income dependence on work experience",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The average and median income dependence on work experience and time is\nanalyzed and modeled for the USA. The original data set providing the mean and\nmedian income estimates in 10 year long intervals spans a long time period of\nalmost 35 years ? from 1967 to 2003. A microeconomic model linking personal\nincome, population age structure and GDP per capita is used to predict the mean\nincome values in various age groups and their relative evolution in time. Also\nmodeled is the value of work experience where the mean income growth ends and\nit starts to drop exponentially with increasing age. This work experience\nincreases through time as the square root of the per capita GDP growth.\nPrediction for the following 20 years is given for each age group considering\npotential per capita growth rate of 1.6%. The USA mean income dependence on\nwork experience for 1987 coincides with that for 2002 in the UK ? the years\nwhen per capita GDP were equal in the countries.\n"
    },
    {
        "paper_id": 811.049,
        "authors": "Ivan O. Kitov, Oleg I. Kitov, Svetlana A. Dolinskaya",
        "title": "Modelling real GDP per capita in the USA: cointegration test",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A two-component model for the evolution of real GDP per capita in the USA is\npresented and tested. The first component of the GDP growth rate represents an\neconomic trend and is inversely proportional to the attained level of real GDP\nper capita itself, with the nominator being constant through time. The second\ncomponent is responsible for fluctuations around the economic trend and is\ndefined as a half of the growth rate of the number of 9-year-olds. This\nnonlinear relationship between the growth rate of real GDP per capita and the\nnumber of 9-year-olds in the USA is tested for cointegration. For linearization\nof the problem, a predicted population time series is calculated using the\noriginal relationship. Both single year of age population time series, the\nmeasured and predicted one, are shown to be integrated of order 1. The\nEngel-Granger approach is applied to the difference of the measured and\npredicted time series and to the residuals or corresponding linear regression.\nBoth tests show the existence of a cointegrating relation. The Johansen test\nresults in the cointegrating rank 1. Since a cointegrating relation between the\nmeasured and predicted number of 9-year-olds does exist, the VAR, VECM, and\nlinear regression are used in estimation of the goodness of fit and root\nmean-square errors, RMSE. The highest R2=0.95 and the best RMSE is obtained in\nthe VAR representation. Econometrically, the tests for cointegration show that\nthe deviations of real economic growth in the USA from the economic trend, as\ndefined by the constant annual increment of real per capita GDP, are driven by\nthe change in the number of 9-year-olds.\n"
    },
    {
        "paper_id": 811.0591,
        "authors": "B. Stehlikova, D. Sevcovic",
        "title": "On the singular limit of solutions to the CIR interest rate model with\n  stochastic volatility",
        "comments": "submitted",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we are interested in term structure models for pricing zero\ncoupon bonds under rapidly oscillating stochastic volatility. We analyze\nsolutions to the generalized Cox-Ingersoll-Ross two factors model describing\nclustering of interest rate volatilities. The main goal is to derive an\nasymptotic expansion of the bond price with respect to a singular parameter\nrepresenting the fast scale for the stochastic volatility process. We derive\nthe second order asymptotic expansion of a solution to the two factors\ngeneralized CIR model and we show that the first two terms in the expansion are\nindependent of the variable representing stochastic volatility.\n"
    },
    {
        "paper_id": 811.08,
        "authors": "Istvan Varga-Haszonits, Imre Kondor",
        "title": "The instability of downside risk measures",
        "comments": "19 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the feasibility and noise sensitivity of portfolio optimization\nunder some downside risk measures (Value-at-Risk, Expected Shortfall, and\nsemivariance) when they are estimated by fitting a parametric distribution on a\nfinite sample of asset returns. We find that the existence of the optimum is a\nprobabilistic issue, depending on the particular random sample, in all three\ncases. At a critical combination of the parameters of these problems we find an\nalgorithmic phase transition, separating the phase where the optimization is\nfeasible from the one where it is not. This transition is similar to the one\ndiscovered earlier for Expected Shortfall based on historical time series. We\nemploy the replica method to compute the phase diagram, as well as to obtain\nthe critical exponent of the estimation error that diverges at the critical\npoint. The analytical results are corroborated by Monte Carlo simulations.\n"
    },
    {
        "paper_id": 811.0889,
        "authors": "Ivan O. Kitov",
        "title": "Real GDP per capita in developed countries",
        "comments": "39 pages, 27 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Growth rate of real GDP per capita is represented as a sum of two components\n-- a monotonically decreasing economic trend and fluctuations related to a\nspecific age population change. The economic trend is modeled by an inverse\nfunction of real GDP per capita with a numerator potentially constant for the\nlargest developed economies. Statistical analysis of 19 selected OECD countries\nfor the period between 1950 and 2004 shows a very weak linear trend in the\nannual GDP per capita increment for the largest economies: the USA, Japan,\nFrance, Italy, and Spain. The UK, Australia, and Canada show a larger positive\nlinear trend. The fluctuations around the trend values are characterized by a\nquasi-normal distribution with potentially Levy distribution for far tails.\nDeveloping countries demonstrate the increment values far below the mean\nincrement for the most developed economies. This indicates an underperformance\nin spite of large relative growth rates.\n"
    },
    {
        "paper_id": 811.0892,
        "authors": "Ivan O. Kitov, Oleg I. Kitov, Svetlana A. Dolinskaya",
        "title": "Inflation as a function of labor force change rate: cointegration test\n  for the USA",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A linear and lagged relationship between inflation and labor force change\nrate, p(t)= A1dLF(t-t1)/LF(t-t1)+A2 was found for developed economies. For the\nUSA, A1=4.0, A2=-0.03075, and t1=2 years. It provides a RMS forecasting error\n(RMFSE) of 0.8% at a two-year horizon for the period between 1965 and 2002 (the\nbest among other inflation forecasting models). This relationship is tested for\ncointegration. Both variables are integrated of order one according to the\npresence of a unit root in the series and its absence in their first\ndifferences. Two methods of cointegration testing are applied: the\nEngle-Granger one based on the unit root test of the residuals including a\nvariety of specification tests and the Johansen cointegration rank test based\non the VAR representation. Both approaches demonstrate that the variables are\ncointegrated and the long-run equilibrium relation revealed in previous study\nholds. According to the Granger causality test, the labor force change is\nproved to be a weakly exogenous variable - a natural result considering the\ntime lead and the existence of a cointegrating relation. VAR and VECM\nrepresentations do not provide any significant improvement in RMSFE. There are\nnumerous applications of the equation: from purely theoretical - a robust\nfundamental relation between macroeconomic and population variables, to a\npractical one - an accurate out-of-sample inflation forecasting at a two-year\nhorizon and a long-term prediction based on labor force projections. The\npredictive power of the relationship is inversely proportional to the\nuncertainty of labor force estimates. Therefore, future inflation research\nprograms should start from a significant improvement in the accuracy of labor\nforce estimations.\n"
    },
    {
        "paper_id": 811.0896,
        "authors": "Ivan O. Kitov, Oleg I. Kitov, Svetlana A. Dolinskaya",
        "title": "Relationship between inflation, unemployment and labor force change rate\n  in France: cointegration test",
        "comments": "52 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A linear and lagged relationship between inflation, unemployment and labor\nforce change rate, p(t)=A0UE(t-t0)+A1dLF(t-t1)/LF(t-t1)+ A2, where A0, A1, and\nA2 are empirical country-specific coefficients, was found for developed\neconomies. The relationship obtained for France is characterized by A0=-1,\nA1=4, A2=0.095, t0=4 years, and t1=4 years. For GDP deflator, it provides a RMS\nforecasting error (RMFSE) of 1.0% at a four-year horizon for the period between\n1971 and 2004. The relationship is tested for cointegration. All three\nvariables involved in the relationship are proved to be integrated of order\none. Two methods of cointegration testing are used. First is the Engle-Granger\napproach based on the unit root test in the residuals of linear regression,\nwhich also includes a number of specification tests. Second method is the\nJohansen cointegration rank test based on a VAR representation, which is also\nproved to be an adequate one via a set of appropriate tests. Both approaches\ndemonstrate that the variables are cointegrated and the long-run equilibrium\nrelation revealed in previous study holds together with statistical estimates\nof goodness-of-fit and RMSFE. Relationships between inflation and labor force\nand between unemployment and labor force are tested separately in appropriate\ntime intervals, where the Banque de France monetary policy introduced in 1995\ndoes not disturb the long-term links. All the individual relationships are\ncointegrated in corresponding intervals. The VAR and vector error correction\n(VEC) models are estimated and provide just a marginal improvement in RMSFE at\nthe four-year horizon both for GDP deflator (down to 0.9%) and CPI (~1.1%) on\nthe results obtained in the regression study.\n"
    },
    {
        "paper_id": 811.1064,
        "authors": "J. Gonzalez-Estevez, M. G. Cosenza, O. Alvarez-Llamoza and R.\n  Lopez-Ruiz",
        "title": "Transition from Pareto to Boltzmann-Gibbs behavior in a deterministic\n  economic model",
        "comments": "10 pages, 14 figures. Submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2009.04.031",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The one-dimensional deterministic economic model recently studied by\nGonzalez-Estevez et al. [Physica A 387, 4367 (2008)] is considered on a\ntwo-dimensional square lattice with periodic boundary conditions. In this\nmodel, the evolution of each agent is described by a map coupled with its\nnearest neighbors. The map has two factors: a linear term that accounts for the\nagent's own tendency to grow and an exponential term that saturates this growth\nthrough the control effect of the environment. The regions in the parameter\nspace where the system displays Pareto and Boltzmann-Gibbs statistics are\ncalculated for the cases of von Neumann and of Moore's neighborhoods. It is\nfound that, even when the parameters in the system are kept fixed, a transition\nfrom Pareto to Boltzmann-Gibbs behavior can occur when the number of neighbors\nof each agent increases.\n"
    },
    {
        "paper_id": 811.1182,
        "authors": "Ivan O. Kitov",
        "title": "Modelling the transition from a socialist to capitalist economic system",
        "comments": "51 pages, 36 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The transition of several East and Central European countries and the\ncountries of the Former Soviet Union from the socialist economic system to the\ncapitalist one is studied. A recently developed microeconomic model for the\npersonal income distribution and its evolution and a simple functional\nrelationship between the rate of the per capita GDP growth and the attained\nlevel of the per capita GDP are used to describe the transition process. The\ndeveloped transition model contains only three defining parameters and\ndescribes the process of real GDP per capita evolution during the last 15\nyears. It is found that the transition process finished in the Central European\ncountries several years ago and their economic evolution is defined by pure\ncapitalist rules. In the long run, this means that the future of these\ncountries has to follow the same path, i.e. dependence on the per capita GDP\ngrowth rate of the per capita GDP itself, as the developed countries have had\nin the past. If the best GDP evolution scenario occurs for the studied\ncountries, they will be able to maintain the absolute lag in per capita GDP\nrelative to most developed countries including the USA. But they will never\ncatch the advanced countries if they follow the same rules of development. In\nRussia and some countries of the Former Soviet Union the transition process is\nstill far from complete.\n"
    },
    {
        "paper_id": 811.1561,
        "authors": "Michel Fliess (LIX, INRIA Saclay - Ile de France), C\\'edric Join\n  (INRIA Saclay - Ile de France, CRAN)",
        "title": "Time Series Technical Analysis via New Fast Estimation Methods: A\n  Preliminary Study in Mathematical Finance",
        "comments": null,
        "journal-ref": "IAR-ACD08 (23rd IAR Workshop on Advanced Control and Diagnosis)\n  (2008)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  New fast estimation methods stemming from control theory lead to a fresh look\nat time series, which bears some resemblance to \"technical analysis\". The\nresults are applied to a typical object of financial engineering, namely the\nforecast of foreign exchange rates, via a \"model-free\" setting, i.e., via\nrepeated identifications of low order linear difference equations on sliding\nshort time windows. Several convincing computer simulations, including the\nprediction of the position and of the volatility with respect to the forecasted\ntrendline, are provided. $\\mathcal{Z}$-transform and differential algebra are\nthe main mathematical tools.\n"
    },
    {
        "paper_id": 811.1896,
        "authors": "Yan Dolinsky, Yuri Kifer",
        "title": "Binomial approximations of shortfall risk for game options",
        "comments": "Published in at http://dx.doi.org/10.1214/07-AAP503 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2008, Vol. 18, No. 5, 1737-1770",
        "doi": "10.1214/07-AAP503",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that the shortfall risk of binomial approximations of game (Israeli)\noptions converges to the shortfall risk in the corresponding Black--Scholes\nmarket considering Lipschitz continuous path-dependent payoffs for both\ndiscrete- and continuous-time cases. These results are new also for usual\nAmerican style options. The paper continues and extends the study of Kifer\n[Ann. Appl. Probab. 16 (2006) 984--1033] where estimates for binomial\napproximations of prices of game options were obtained. Our arguments rely, in\nparticular, on strong invariance principle type approximations via the\nSkorokhod embedding, estimates from Kifer [Ann. Appl. Probab. 16 (2006)\n984--1033] and the existence of optimal shortfall hedging in the discrete time\nestablished by Dolinsky and Kifer [Stochastics 79 (2007) 169--195].\n"
    },
    {
        "paper_id": 811.2084,
        "authors": "Edward W. Piotrowski and Jan Sladkowski",
        "title": "A model of subjective supply-demand: the maximum Boltzmann/Shannon\n  entropy solution",
        "comments": "Presented at the SIGMAPHI 08 Conference",
        "journal-ref": null,
        "doi": "10.1088/1742-5468/2009/03/P03035",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate activities that have different periods of duration. We define\nthe profit intensity as a measure of this economic category. The profit\nintensity in a repeated trading has a unique property of attaining its maximum\nat a fixed point regardless of the shape of demand curves for a wide class of\nprobability distributions of random reverse transaction (ie closing of the\nposition). This type of market games is often considered in the research aiming\nat finding an algorithm that maximizes profit of a trader who negotiates prices\nwith the Rest of the World (a collective opponent) that posses a definite and\nobjective supply profile. Such idealization neglects the sometimes important\ninfluence of an individual trader on the demand/supply profile of the Rest of\nthe World and in extreme cases questions the very idea of demand/supply\nprofile. Therefore we put forward a trading model in which the demand/supply\nprofile of the Rest of the World induces the (rational) trader to\n(subjectively) presume that he/she lacks (almost) all knowledge concerning the\nmarket but his/hers average frequency of trade. This point of view introduces\nmaximum entropy principles into the model and broadens the range of economics\nphenomena that can be perceived as a sort of thermodynamical system. As a\nconsequence, the profit intensity has a fixed point:the profit in tensity\nreaches its maximum when the probability of transaction is given by the Golden\nRatio rule $\\frac{\\sqrt{5}-1}{2}$.\n"
    },
    {
        "paper_id": 811.2124,
        "authors": "Ivan O. Kitov, Oleg I. kitov",
        "title": "The driving force of labor productivity",
        "comments": "pages 20, figures 12",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Labor productivity in developed countries is analyzed and modeled. Modeling\nis based on our previous finding that the rate of labor force participation is\na unique function of GDP per capita. Therefore, labor productivity is fully\ndetermined by the rate of economic growth, and thus, is a secondary economic\nvariable. Initially, we assess a model for the U.S. and then test it using data\nfor Japan, France, the UK, Italy, and Canada. Results obtained for these\ncountries validate those for the U.S. The evolution of labor force productivity\nis predictable at least at an 11-year horizon\n"
    },
    {
        "paper_id": 811.2125,
        "authors": "Ivan O. Kitov",
        "title": "GDP growth rate and population",
        "comments": "pages 60, figures 35",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Real GDP growth rate in developed countries is found to be a sum of two\nterms. The first term is the reciprocal value of the duration of the period of\nmean income growth with work experience, Tcr. The current value of Tcr in the\nUSA is 40 years. The second term is inherently related to population and\ndefined by the relative change in the number of people with a specific age (9\nyears in the USA), (1/2)*dN9(t) /N9(t), where N9(t) is the number of\n9-year-olds at time t. The Tcr grows as the square root of real GDP per capita.\nHence, evolution of real GDP is defined by only one parameter - the number of\npeople of the specific age. Predictions for the USA, the UK, and France are\npresented and discussed. A similar relationship is derived for real GDP per\ncapita. Annual increment of GDP per capita is also a combination of economic\ntrend term and the same specific age population term. The economic trend term\nduring last 55 years is equal to $400 (2002 US dollars) divided by the attained\nlevel of real GDP per capita. Thus, the economic trend term has an asymptotic\nvalue of zero. Inversion of the measured GDP values is used to recover the\ncorresponding change of the specific age population between 1955 and 2003. The\npopulation recovery method based on GDP potentially is of a higher accuracy\nthan routine censuses.\n"
    },
    {
        "paper_id": 811.3122,
        "authors": "Johannes Vitalis Siven, Jeffrey Todd Lins, Jonas Lundbek Hansen",
        "title": "A multiscale view on inverse statistics and gain/loss asymmetry in\n  financial time series",
        "comments": null,
        "journal-ref": "J. Stat. Mech. (2009) P02004",
        "doi": "10.1088/1742-5468/2009/02/P02004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Researchers have studied the first passage time of financial time series and\nobserved that the smallest time interval needed for a stock index to move a\ngiven distance is typically shorter for negative than for positive price\nmovements. The same is not observed for the index constituents, the individual\nstocks. We use the discrete wavelet transform to illustrate that this is a long\nrather than short time scale phenomenon -- if enough low frequency content of\nthe price process is removed, the asymmetry disappears. We also propose a new\nmodel, which explain the asymmetry by prolonged, correlated down movements of\nindividual stocks.\n"
    },
    {
        "paper_id": 811.313,
        "authors": "Karl Svozil",
        "title": "An Apology for Money",
        "comments": "23 pages, completely revised, a proof of Goedel-type incompleteness\n  is included; contribution to the timesup.org Data Ecologies Symposium in\n  Brussels, Belgium, 31st October 2009",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This review is about the convenience, the benefits, as well as the\ndestructive capacities of money. It deals with various aspects of money\ncreation, with its value, and its appropriation. All sorts of money tend to get\ncorrupted by eventually creating too much of them. In the long run, this\nrenders money worthless and deprives people holding it. This misuse of money\ncreation is inevitable and should come as no surprise. Abusive money creation\ncomes in various forms. In the present fiat money system \"suspended in free\nthought\" and sustained merely by our belief in and our conditioning to it,\nmoney is conveniently created out of \"thin air\" by excessive government\nspending and speculative credit creation. Alas, any too tight money supply\ncould ruin an economy by inviting all sorts of unfriendly takeovers, including\nwars or competition. Therefore the ambivalence of money as benefactor and\ndestroyer should be accepted as destiny.\n"
    },
    {
        "paper_id": 811.3749,
        "authors": "Przemyslaw Klusik, Zbigniew Palmowski, Jakub Zwierz",
        "title": "Quantile hedging for an insider",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider the problem of the quantile hedging from the point\nof view of a better informed agent acting on the market. The additional\nknowledge of the agent is modelled by a filtration initially enlarged by some\nrandom variable. By using equivalent martingale measures introduced in\nAmendinger (2000) and Amendinger, Imkeller and Schweizer (1998) we solve the\nproblem for the complete case, by extending the results obtained in F{\\\"o}llmer\nand Leukert (1999) to the insider context. Finally, we consider the examples\nwith the explicit calculations within the standard Black-Scholes model.\n"
    },
    {
        "paper_id": 811.3885,
        "authors": "H.E. Roman, R.A. Siliprandi, C. Dose, C. Riccardi, and M. Porto",
        "title": "Fluctuations of company yearly profits versus scaled revenue: Fat tail\n  distribution of Levy type",
        "comments": "6 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1209/0295-5075/84/68003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze annual revenues and earnings data for the 500 largest-revenue U.S.\ncompanies during the period 1954-2007. We find that mean year profits are\nproportional to mean year revenues, exception made for few anomalous years,\nfrom which we postulate a linear relation between company expected mean profit\nand revenue. Mean annual revenues are used to scale both company profits and\nrevenues. Annual profit fluctuations are obtained as difference between actual\nannual profit and its expected mean value, scaled by a power of the revenue to\nget a stationary behavior as a function of revenue. We find that profit\nfluctuations are broadly distributed having approximate power-law tails with a\nLevy-type exponent $\\alpha \\simeq 1.7$, from which we derive the associated\nbreak-even probability distribution. The predictions are compared with\nempirical data.\n"
    },
    {
        "paper_id": 811.3889,
        "authors": "Luciano Campi and Mark P. Owen",
        "title": "Multivariate utility maximization with proportional transaction costs",
        "comments": "Addition of two examples (Examples 3.2 and 3.13) and a few other,\n  minor presentational improvements",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present an optimal investment theorem for a currency exchange model with\nrandom and possibly discontinuous proportional transaction costs. The\ninvestor's preferences are represented by a multivariate utility function,\nallowing for simultaneous consumption of any prescribed selection of the\ncurrencies at a given terminal date. We prove the existence of an optimal\nportfolio process under the assumption of asymptotic satiability of the value\nfunction. Sufficient conditions for asymptotic satiability of the value\nfunction include reasonable asymptotic elasticity of the utility function, or a\ngrowth condition on its dual function. We show that the portfolio optimization\nproblem can be reformulated in terms of maximization of a terminal liquidation\nutility function, and that both problems have a common optimizer.\n"
    },
    {
        "paper_id": 811.3988,
        "authors": "Daniel J. Fenn, Mason A. Porter, Mark McDonald, Stacy Williams, Neil\n  F. Johnson and Nick S. Jones",
        "title": "Dynamic communities in multichannel data: An application to the foreign\n  exchange market during the 2007--2008 credit crisis",
        "comments": "8 pages, 6 figures, accepted for publication in Chaos",
        "journal-ref": "Chaos, Vol. 19, No. 3: 033119 (2009)",
        "doi": "10.1063/1.3184538",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the cluster dynamics of multichannel (multivariate) time series by\nrepresenting their correlations as time-dependent networks and investigating\nthe evolution of network communities. We employ a node-centric approach that\nallows us to track the effects of the community evolution on the functional\nroles of individual nodes without having to track entire communities. As an\nexample, we consider a foreign exchange market network in which each node\nrepresents an exchange rate and each edge represents a time-dependent\ncorrelation between the rates. We study the period 2005-2008, which includes\nthe recent credit and liquidity crisis. Using dynamical community detection, we\nfind that exchange rates that are strongly attached to their community are\npersistently grouped with the same set of rates, whereas exchange rates that\nare important for the transfer of information tend to be positioned on the\nedges of communities. Our analysis successfully uncovers major trading changes\nthat occurred in the market during the credit crisis.\n"
    },
    {
        "paper_id": 811.4021,
        "authors": "Cheoljun Eom, Woo-Sung Jung, Taisei Kaizoji, Seunghwan Kim",
        "title": "Effect of changing data size on eigenvalues in the Korean and Japanese\n  stock markets",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2009.07.023",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this study, we attempted to determine how eigenvalues change, according to\nrandom matrix theory (RMT), in stock market data as the number of stocks\ncomprising the correlation matrix changes. Specifically, we tested for changes\nin the eigenvalue properties as a function of the number and type of stocks in\nthe correlation matrix. We determined that the value of the eigenvalue\nincreases in proportion with the number of stocks. Furthermore, we noted that\nthe largest eigenvalue maintains its identical properties, regardless of the\nnumber and type, whereas other eigenvalues evidence different features.\n"
    },
    {
        "paper_id": 811.4039,
        "authors": "Christophette Blanchet-Scalliet (ICJ), Anne Eyraud-Loisel (SAF),\n  Manuela Royer-Carenzi (LATP)",
        "title": "Hedging of Defaultable Contingent Claims using BSDE with uncertain time\n  horizon",
        "comments": null,
        "journal-ref": "Le bulletin fran\\c{c}ais d'actuariat 20, 10 (2010)\n  http://www.institutdesactuaires.com/bfa/",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article focuses on the mathematical problem of existence and uniqueness\nof BSDE with a random terminal time which is a general random variable but not\na stopping time, as it has been usually the case in the previous literature of\nBSDE with random terminal time. The main motivation of this work is a financial\nor actuarial problem of hedging of defaultable contingent claims or life\ninsurance contracts, for which the terminal time is a default time or a death\ntime, which are not stopping times. We have to use progressive enlargement of\nthe Brownian filtration, and to solve the obtained BSDE under this enlarged\nfiltration. This work gives a solution to the mathematical problem and proves\nthe existence and uniqueness of solutions of such BSDE under certain general\nconditions. This approach is applied to the financial problem of hedging of\ndefaultable contingent claims, and an expression of the hedging strategy is\ngiven for a defaultable contingent claim or a life insurance contract.\n"
    },
    {
        "paper_id": 811.4256,
        "authors": "V. Alfi, M. Cristelli, L. Pietronero, A. Zaccaria",
        "title": "Mechanisms of Self-Organization and Finite Size Effects in a Minimal\n  Agent Based Model",
        "comments": "14 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1088/1742-5468/2009/03/P03016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a detailed analysis of the self-organization phenomenon in which\nthe stylized facts originate from finite size effects with respect to the\nnumber of agents considered and disappear in the limit of an infinite\npopulation. By introducing the possibility that agents can enter or leave the\nmarket depending on the behavior of the price, it is possible to show that the\nsystem self-organizes in a regime with a finite number of agents which\ncorresponds to the stylized facts. The mechanism to enter or leave the market\nis based on the idea that a too stable market is unappealing for traders while\nthe presence of price movements attracts agents to enter and speculate on the\nmarket. We show that this mechanism is also compatible with the idea that\nagents are scared by a noisy and risky market at shorter time scales. We also\nshow that the mechanism for self-organization is robust with respect to\nvariations of the exit/entry rules and that the attempt to trigger the system\nto self-organize in a region without stylized facts leads to an unrealistic\ndynamics. We study the self-organization in a specific agent based model but we\nbelieve that the basic ideas should be of general validity.\n"
    },
    {
        "paper_id": 811.4613,
        "authors": "Eduard Rotenstein",
        "title": "Pricing financial derivatives by a minimizing method",
        "comments": "This paper has been withdrawn by the author",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We shall study backward stochastic differential equations and we will present\na new approach for the existence of the solution. This type of equation appears\nvery often in the valuation of financial derivatives in complete markets.\nTherefore, the identification of the solution as the unique element in a\ncertain Banach space where a suitably chosen functional attains its minimum\nbecomes interesting for numerical computations.\n"
    },
    {
        "paper_id": 811.4678,
        "authors": "V. P. Maslov (1 and 2) and V. E. Nazaikinskii (2) ((1) Moscow State\n  University, (2) Institute for Problems in Mechanics, RAS, Moscow)",
        "title": "Mathematics underlying the 2008 financial crisis, and a possible remedy",
        "comments": "This paper has been withdrawn by the authors",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper has been withdrawn by the authors, because it has been made\nobsolete by the detailed expositions in our papers in arXiv:0812.4885 (the\nmathematics part) and arXiv:0812.4737 (the economics part).\n"
    },
    {
        "paper_id": 811.4715,
        "authors": "Thomas Lim (PMA), Marie-Claire Quenez (PMA)",
        "title": "Utility maximization in incomplete markets with default",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We adress the maximization problem of expected utility from terminal wealth.\nThe special feature of this paper is that we consider a financial market where\nthe price process of risky assets can have a default time. Using dynamic\nprogramming, we characterize the value function with a backward stochastic\ndifferential equation and the optimal portfolio policies. We separately treat\nthe cases of exponential, power and logarithmic utility.\n"
    },
    {
        "paper_id": 812.0033,
        "authors": "Constantinos Kardaras, Eckhard Platen",
        "title": "Multiplicative approximation of wealth processes involving no-short-sale\n  strategies via simple trading",
        "comments": "11 pages. Revised version. This is the 2nd part of what comprised the\n  older arxiv submission \"On financial markets where only buy-and-hold trading\n  is possible\" from the two authors",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A financial market model with general semimartingale asset-price processes\nand where agents can only trade using no-short-sales strategies is considered.\nWe show that wealth processes using continuous trading can be approximated very\nclosely by wealth processes using simple combinations of buy-and-hold trading.\nThis approximation is based on controlling the proportions of wealth invested\nin the assets. As an application, the utility maximization problem is\nconsidered and it is shown that optimal expected utilities and wealth processes\nresulting from continuous trading can be approximated arbitrarily well by the\nuse of simple combinations of buy-and-hold strategies.\n"
    },
    {
        "paper_id": 812.0136,
        "authors": "Daniel Andersson",
        "title": "A mixed relaxed singular maximum principle for linear SDEs with random\n  coefficients",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study singular stochastic control of a two dimensional stochastic\ndifferential equation, where the first component is linear with random and\nunbounded coefficients. We derive existence of an optimal relaxed control and\nnecessary conditions for optimality in the form of a mixed relaxed-singular\nmaximum principle in a global form. A motivating example is given in the form\nof an optimal investment and consumption problem with transaction costs, where\nwe consider a portfolio with a continuum of bonds and where the portfolio\nweights are modeled as measure-valued processes on the set of times to\nmaturity.\n"
    },
    {
        "paper_id": 812.0208,
        "authors": "Yuichi Ikeda and Wataru Souma",
        "title": "International Comparison of Labor Productivity Distribution for\n  Manufacturing and Non-Manufacturing Firms",
        "comments": "9 pages including figures",
        "journal-ref": null,
        "doi": "10.1143/PTPS.179.93",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Labor productivity was studied at the microscopic level in terms of\ndistributions based on individual firm financial data from Japan and the US. A\npower-law distribution in terms of firms and sector productivity was found in\nboth countries' data. The labor productivities were not equal for nation and\nsectors, in contrast to the prevailing view in the field of economics. It was\nfound that the low productivity of the Japanese non-manufacturing sector\nreported in macro-economic studies was due to the low productivity of small\nfirms.\n"
    },
    {
        "paper_id": 812.0449,
        "authors": "Mstislav Elagin",
        "title": "Locally adaptive estimation methods with application to univariate time\n  series",
        "comments": "Submitted to the Electronic Journal of Statistics\n  (http://www.i-journals.org/ejs/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper offers a unified approach to the study of three locally adaptive\nestimation methods in the context of univariate time series from both\ntheoretical and empirical points of view. A general procedure for the\ncomputation of critical values is given. The underlying model encompasses all\ndistributions from the exponential family providing for great flexibility. The\nprocedures are applied to simulated and real financial data distributed\naccording to the Gaussian, volatility, Poisson, exponential and Bernoulli\nmodels. Numerical results exhibit a very reasonable performance of the methods.\n"
    },
    {
        "paper_id": 812.0556,
        "authors": "Miquel Montero",
        "title": "Perpetual American vanilla option pricing under single regime change\n  risk. An exhaustive study",
        "comments": "iopart, 23 pages, 4 figures; revised version",
        "journal-ref": "J. Stat. Mech., P07016 (2009)",
        "doi": "10.1088/1742-5468/2009/07/P07016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Perpetual American options are financial instruments that can be readily\nexercised and do not mature. In this paper we study in detail the problem of\npricing this kind of derivatives, for the most popular flavour, within a\nframework in which some of the properties |volatility and dividend policy| of\nthe underlying stock can change at a random instant of time, but in such a way\nthat we can forecast their final values. Under this assumption we can model\nactual market conditions because most relevant facts usually entail sharp\npredictable consequences. The effect of this potential risk on perpetual\nAmerican vanilla options is remarkable: the very equation that will determine\nthe fair price depends on the solution to be found. Sound results are found\nunder the optics both of finance and physics. In particular, a parallelism\namong the overall outcome of this problem and a phase transition is\nestablished.\n"
    },
    {
        "paper_id": 812.0761,
        "authors": "Nikita Ratanov",
        "title": "Option Pricing Model Based on a Markov-modulated Diffusion with Jumps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper proposes a class of financial market models which are based on\ninhomogeneous telegraph processes and jump diffusions with alternating\nvolatilities. It is assumed that the jumps occur when the tendencies and\nvolatilities are switching. We argue that such a model captures well the stock\nprice dynamics under periodic financial cycles. The distribution of this\nprocess is described in detail. For this model we obtain the structure of the\nset of martingale measures. This incomplete model can be completed by adding\nanother asset based on the same sources of randomness. Explicit closed-form\nformulae for prices of the standard European options are obtained for the\ncompleted market model.\n"
    },
    {
        "paper_id": 812.0913,
        "authors": "Daniel J. Fenn, Sam D. Howison, Mark McDonald, Stacy Williams, Neil F.\n  Johnson",
        "title": "The Mirage of Triangular Arbitrage in the Spot Foreign Exchange Market",
        "comments": null,
        "journal-ref": "International Journal of Theoretical and Applied Finance, Vol. 12,\n  Issue 8: 1105-1123 (2009)",
        "doi": "10.1142/S0219024909005609",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate triangular arbitrage within the spot foreign exchange market\nusing high-frequency executable prices. We show that triangular arbitrage\nopportunities do exist, but that most have short durations and small\nmagnitudes. We find intra-day variations in the number and length of arbitrage\nopportunities, with larger numbers of opportunities with shorter mean durations\noccurring during more liquid hours. We demonstrate further that the number of\narbitrage opportunities has decreased in recent years, implying a corresponding\nincrease in pricing efficiency. Using trading simulations, we show that a\ntrader would need to beat other market participants to an unfeasibly large\nproportion of arbitrage prices to profit from triangular arbitrage over a\nprolonged period of time. Our results suggest that the foreign exchange market\nis internally self-consistent and provide a limited verification of market\nefficiency.\n"
    },
    {
        "paper_id": 812.1512,
        "authors": "Guo-Hua Mu, Wei Chen, J\\'anos Kert\\'esz, Wei-Xing Zhou",
        "title": "Preferred numbers and the distribution of trade sizes and trading\n  volumes in the Chinese stock market",
        "comments": "7 pages, 5 figures and 4 tables",
        "journal-ref": "Eur. Phys. J. B 68, 145-152 (2009)",
        "doi": "10.1140/epjb/e2009-00059-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The distribution of trade sizes and trading volumes are investigated based on\nthe limit order book data of 22 liquid Chinese stocks listed on the Shenzhen\nStock Exchange in the whole year 2003. We observe that the size distribution of\ntrades for individual stocks exhibits jumps, which is caused by the number\npreference of traders when placing orders. We analyze the applicability of the\n\"$q$-Gamma\" function for fitting the distribution by the Cram\\'{e}r-von Mises\ncriterion. The empirical PDFs of trading volumes at different timescales\n$\\Delta{t}$ ranging from 1 min to 240 min can be well modeled. The\napplicability of the $q$-Gamma functions for multiple trades is restricted to\nthe transaction numbers $\\Delta{n}\\leqslant8$. We find that all the PDFs have\npower-law tails for large volumes. Using careful estimation of the average tail\nexponents $\\alpha$ of the distribution of trade sizes and trading volumes, we\nget $\\alpha>2$, well outside the L{\\'e}vy regime.\n"
    },
    {
        "paper_id": 812.2,
        "authors": "Mark B. Wise and Vineer Bhansali",
        "title": "Correlated Random Walks and the Joint Survival Probability",
        "comments": "12 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  First passage models, where corporate assets undergo correlated random walks\nand a company defaults if its assets fall below a threshold provide an\nattractive framework for modeling the default process. Typical one year default\ncorrelations are small, i.e., of order a few percent, but nonetheless including\ncorrelations is very important, for managing portfolio credit risk and pricing\nsome credit derivatives (e.g. first to default baskets). In first passage\nmodels the exact dependence of the joint survival probability of more than two\nfirms on their asset correlations is not known. We derive an expression for the\ndependence of the joint survival probability of $n$ firms on their asset\ncorrelations using first order perturbation theory in the correlations. It\nincludes all terms that are linear in the correlations but neglects effects of\nquadratic and higher order. For constant time independent correlations we\ncompare the first passage model expression for the joint survival probability\nwith what a multivariate normal Copula function gives. As a practical\napplication of our results we calculate the dependence of the five year joint\nsurvival probability for five basic industrials on their asset correlations.\n"
    },
    {
        "paper_id": 812.2148,
        "authors": "Javier Villarroel, Miquel Montero",
        "title": "On properties of Continuous-Time Random Walks with Non-Poissonian\n  jump-times",
        "comments": "elsart, 12 pages, 3 figures, accepted for publication in Chaos,\n  Solitons & Fractals",
        "journal-ref": "Chaos, Solitons and Fractals 42, 128-137 (2009)",
        "doi": "10.1016/j.chaos.2008.11.015",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The usual development of the continuous-time random walk (CTRW) proceeds by\nassuming that the present is one of the jumping times. Under this restrictive\nassumption integral equations for the propagator and mean escape times have\nbeen derived. We generalize these results to the case when the present is an\narbitrary time by recourse to renewal theory. The case of Erlang distributed\ntimes is analyzed in detail. Several concrete examples are considered.\n"
    },
    {
        "paper_id": 812.244,
        "authors": "Alexandre F. Roch",
        "title": "Liquidity Risk, Price Impacts and the Replication Problem",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend a linear version of the liquidity risk model of Cetin et al. (2004)\nto allow for price impacts. We show that the impact of a market order on prices\ndepends on the size of the transaction and the level of liquidity. We obtain a\nsimple characterization of self-financing trading strategies and a sufficient\ncondition for no arbitrage. We consider a stochastic volatility model in which\nthe volatility is partly correlated with the liquidity process and show that,\nwith the use of variance swaps, contingent claims whose payoffs depend on the\nvalue of the asset can be approximately replicated in this setting. The\nreplicating costs of such payoffs are obtained from the solutions of BSDEs with\nquadratic growth and analytical properties of these solutions are investigated.\n"
    },
    {
        "paper_id": 812.2444,
        "authors": "Alexandre F. Roch",
        "title": "Viscosity Solutions and American Option Pricing in a Stochastic\n  Volatility Model of the Ornstein-Uhlenbeck Type",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the valuation of American type derivatives in the\nstochastic volatility model of Barndorff-Nielsen and Shephard (2001). We\ncharacterize the value of such derivatives as the unique viscosity solution of\nan integral-partial differential equation when the payoff function satisfies a\nLipschitz condition.\n"
    },
    {
        "paper_id": 812.2449,
        "authors": "T. Kaizoji and D. Sornette",
        "title": "Market bubbles and crashes",
        "comments": "25 pages, long version of a shorter review written for the\n  Encyclopedia of Quantitative Finance (Wiley)\n  http://www.wiley.com//legacy/wileychi/eqf/",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Episodes of market crashes have fascinated economists for centuries. Although\nmany academics, practitioners and policy makers have studied questions related\nto collapsing asset price bubbles, there is little consensus yet about their\ncauses and effects. This review and essay evaluates some of the hypotheses\noffered to explain the market crashes that often follow asset price bubbles.\nStarting from historical accounts and syntheses of past bubbles and crashes, we\nput the problem in perspective with respect to the development of the efficient\nmarket hypothesis. We then present the models based on heterogeneous agents and\nthe limits to arbitrage that prevent rational agents from bursting bubbles\nbefore they inflate. Then, we explore another set of explanations of why\nrational traders would be led to actually profit from and surf on bubbles, by\nanticipating the behavior of noise traders or by realizing the difficulties in\nsynchronizing their actions. We then end by discussing a complex system\napproach of social imitation leading to collective market regimes like herding\nand the phenomenon of bifurcation (or phase transition) that rationalize what\ncrash can occur in unstable market regimes. The key insight is that diagnosing\nbubbles may be feasible when taking into account the positive feedback\nmechanisms that give rise to transient \"super-exponential\" price growth, the\nbubbles.\n"
    },
    {
        "paper_id": 812.2603,
        "authors": "Andy Kirou, Blazej Ruszczycki, Markus Walser and Neil F. Johnson",
        "title": "Computational modeling of collective human behavior: Example of\n  financial markets",
        "comments": "Draft of keynote lecture at International Conference on Computational\n  Science (June, 2008). Final version published in LNCS M. Bubak et al. (Eds.)\n  p. 33 (Springer-Verlag, Berlin, 2008)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss how minimal financial market models can be constructed by bridging\nthe gap between two existing, but incomplete, market models: a model in which a\npopulation of virtual traders make decisions based on common global information\nbut lack local information from their social network, and a model in which the\ntraders form a dynamically evolving social network but lack any decision-making\nbased on global information. We show that a suitable combination of these two\nmodels -- in particular, a population of virtual traders with access to both\nglobal and local information -- produces results for the price return\ndistribution which are closer to the reported stylized facts. We believe that\nthis type of model can be applied across a wide range of systems in which\ncollective human activity is observed.\n"
    },
    {
        "paper_id": 812.2604,
        "authors": "Jianqing Fan, Jingjin Zhang, Ke Yu",
        "title": "Asset Allocation and Risk Assessment with Gross Exposure Constraints for\n  Vast Portfolios",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Markowitz (1952, 1959) laid down the ground-breaking work on the\nmean-variance analysis. Under his framework, the theoretical optimal allocation\nvector can be very different from the estimated one for large portfolios due to\nthe intrinsic difficulty of estimating a vast covariance matrix and return\nvector. This can result in adverse performance in portfolio selected based on\nempirical data due to the accumulation of estimation errors. We address this\nproblem by introducing the gross-exposure constrained mean-variance portfolio\nselection. We show that with gross-exposure constraint the theoretical optimal\nportfolios have similar performance to the empirically selected ones based on\nestimated covariance matrices and there is no error accumulation effect from\nestimation of vast covariance matrices. This gives theoretical justification to\nthe empirical results in Jagannathan and Ma (2003). We also show that the\nno-short-sale portfolio is not diversified enough and can be improved by\nallowing some short positions. As the constraint on short sales relaxes, the\nnumber of selected assets varies from a small number to the total number of\nstocks, when tracking portfolios or selecting assets. This achieves the optimal\nsparse portfolio selection, which has close performance to the theoretical\noptimal one. Among 1000 stocks, for example, we are able to identify all\noptimal subsets of portfolios of different sizes, their associated allocation\nvectors, and their estimated risks. The utility of our new approach is\nillustrated by simulation and empirical studies on the 100 Fama-French\nindustrial portfolios and the 400 stocks randomly selected from Russell 3000.\n"
    },
    {
        "paper_id": 812.2664,
        "authors": "Newton J. Moura Jr. (1), Marcelo B. Ribeiro (2) ((1) IBGE - Brazilian\n  Institute for Geography and Statistics, Geosciences Directorate, Rio de\n  Janeiro, (2) Physics Institute, University of Brazil - UFRJ, Rio de Janeiro)",
        "title": "Evidence for the Gompertz Curve in the Income Distribution of Brazil\n  1978-2005",
        "comments": "22 pages, 15 figures, 4 tables. LaTeX. Accepted for publication in\n  \"The European Physical Journal B\"",
        "journal-ref": "Eur.Phys.J. B 67 (2009) 101-120",
        "doi": "10.1140/epjb/e2008-00469-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work presents an empirical study of the evolution of the personal income\ndistribution in Brazil. Yearly samples available from 1978 to 2005 were studied\nand evidence was found that the complementary cumulative distribution of\npersonal income for 99% of the economically less favorable population is well\nrepresented by a Gompertz curve of the form $G(x)=\\exp [\\exp (A-Bx)]$, where\n$x$ is the normalized individual income. The complementary cumulative\ndistribution of the remaining 1% richest part of the population is well\nrepresented by a Pareto power law distribution $P(x)= \\beta x^{-\\alpha}$. This\nresult means that similarly to other countries, Brazil's income distribution is\ncharacterized by a well defined two class system. The parameters $A$, $B$,\n$\\alpha$, $\\beta$ were determined by a mixture of boundary conditions,\nnormalization and fitting methods for every year in the time span of this\nstudy. Since the Gompertz curve is characteristic of growth models, its\npresence here suggests that these patterns in income distribution could be a\nconsequence of the growth dynamics of the underlying economic system. In\naddition, we found out that the percentage share of both the Gompertzian and\nParetian components relative to the total income shows an approximate cycling\npattern with periods of about 4 years and whose maximum and minimum peaks in\neach component alternate at about every 2 years. This finding suggests that the\ngrowth dynamics of Brazil's economic system might possibly follow a\nGoodwin-type class model dynamics based on the application of the\nLotka-Volterra equation to economic growth and cycle.\n"
    },
    {
        "paper_id": 812.3083,
        "authors": "Edie Miglio, Carlo Sgarra",
        "title": "A Finite Element Framework for Option Pricing with the Bates Model",
        "comments": "15 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper we present a finite element approach for option pricing\nin the framework of a well-known stochastic volatility model with jumps, the\nBates model. In this model the asset log-returns are assumed to follow a\njump-diffusion model where the jump component consists of a Levy process of\ncompound Poisson type, while the volatility behavior is described by a\nstochastic differential equation of CIR type, with a mean-reverting drift term\nand a diffusion component correlated with that of the log-returns. Like in all\nthe Levy models, the option pricing problem can be formulated in terms of an\nintegro-differential equation: for the Bates model the unknown F(S, V, t) (the\noption price) of the pricing equation depends on three independent variables\nand the differential operator part turns out to be of parabolic kind, while the\nnonlocal integral operator is calculated with respect to the Levy measure of\nthe jumps. In this paper we will present a variational formulation of the\nproblem suitable for a finite element approach. The numerical results obtained\nfor european options will be compared with those obtained with different\nmethods.\n"
    },
    {
        "paper_id": 812.3117,
        "authors": "Marc Jeannin and Martijn Pistorius",
        "title": "Pricing and hedging barrier options in a hyper-exponential additive\n  model",
        "comments": "26 pages, 8 figures. To appear in IJTAF",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we develop an algorithm to calculate the prices and Greeks of\nbarrier options in a hyper-exponential additive model with piecewise constant\nparameters. We obtain an explicit semi-analytical expression for the\nfirst-passage probability. The solution rests on a randomization and an\nexplicit matrix Wiener-Hopf factorization. Employing this result we derive\nexplicit expressions for the Laplace-Fourier transforms of the prices and\nGreeks of barrier options. As a numerical illustration, the prices and Greeks\nof down-and-in digital and down-and-in call options are calculated for a set of\nparameters obtained by a simultaneous calibration to Stoxx50E call options\nacross strikes and four different maturities. By comparing the results with\nMonte-Carlo simulations, we show that the method is fast, accurate, and stable.\n"
    },
    {
        "paper_id": 812.3128,
        "authors": "Marc Jeannin and Martijn Pistorius",
        "title": "A transform approach to compute prices and greeks of barrier options\n  driven by a class of Levy processes",
        "comments": "27 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we propose a transform method to compute the prices and greeks\nof barrier options driven by a class of Levy processes. We derive analytical\nexpressions for the Laplace transforms in time of the prices and sensitivities\nof single barrier options in an exponential Levy model with hyper-exponential\njumps. Inversion of these single Laplace transform yields rapid, accurate\nresults. These results are employed to construct an approximation of the prices\nand sensitivities of barrier options in exponential generalised\nhyper-exponential (GHE) Levy models. The latter class includes many of the Levy\nmodels employed in quantitative finance such as the variance gamma (VG), KoBoL,\ngeneralised hyperbolic, and the normal inverse Gaussian (NIG) models.\nConvergence of the approximating prices and sensitivities is proved. To provide\na numerical illustration, this transform approach is compared with Monte Carlo\nsimulation in the cases that the driving process is a VG and a NIG Levy\nprocess. Parameters are calibrated to Stoxx50E call options.\n"
    },
    {
        "paper_id": 812.3378,
        "authors": "U. Krey (Inst. fuer Physik II der Universitaet Regensburg)",
        "title": "On the Financial Crisis 2008 from a Physicist's viewpoint: A Spin-Glass\n  Interpretation",
        "comments": "Internal report, not to be published, four pages. Updated version\n  (AT-line!) as of 14 Jan., 2009",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an informal way, a number of thoughts on the financial crisis 2008 are\npresented from a physicist's viewpoint, considering the problem as a\nnonergodicity transition of a spin-glass type of system. Some tentative\nsuggestions concerning the way out of the crisis are also discussed, concerning\nKeynesian \"deficit spending\" methods, tax reductions, and finally the method\n\"ruin and recreate\" known from optimization theory. Also the de\nAlmeida-Thouless instability line of spin-glass theory is given a financial\ninterpretation.\n"
    },
    {
        "paper_id": 812.3381,
        "authors": "Olivier Aj Bardou (PMA, GDF-RDD), Noufel Frikha (PMA, GDF-RDD), G.\n  Pag\\`es (PMA)",
        "title": "Computation of VaR and CVaR using stochastic approximations and\n  unconstrained importance sampling",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR) are two risk\nmeasures which are widely used in the practice of risk management. This paper\ndeals with the problem of computing both VaR and CVaR using stochastic\napproximation (with decreasing steps): we propose a first Robbins-Monro\nprocedure based on Rockaffelar-Uryasev's identity for the CVaR. The convergence\nrate of this algorithm to its target satisfies a Gaussian Central Limit\nTheorem. As a second step, in order to speed up the initial procedure, we\npropose a recursive importance sampling (I.S.) procedure which induces a\nsignificant variance reduction of both VaR and CVaR procedures. This idea,\nwhich goes back to the seminal paper of B. Arouna, follows a new approach\nintroduced by V. Lemaire and G. Pag\\`es. Finally, we consider a deterministic\nmoving risk level to speed up the initialization phase of the algorithm. We\nprove that the convergence rate of the resulting procedure is ruled by a\nCentral Limit Theorem with minimal variance and its efficiency is illustrated\nby considering several typical energy portfolios.\n"
    },
    {
        "paper_id": 812.3538,
        "authors": "A. Alvarez, F. Panloup, M. Pontier, N. Savy",
        "title": "Estimation of the instantaneous volatility",
        "comments": "Submitted to Statistical Inference for Stochastic Processes. 28\n  pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is concerned with the estimation of the volatility process in a\nstochastic volatility model of the following form: $dX_t=a_tdt+\\sigma_tdW_t$,\nwhere $X$ denotes the log-price and $\\sigma$ is a c\\`adl\\`ag semi-martingale.\nIn the spirit of a series of recent works on the estimation of the cumulated\nvolatility, we here focus on the instantaneous volatility for which we study\nestimators built as finite differences of the \\textit{power variations} of the\nlog-price. We provide central limit theorems with an optimal rate depending on\nthe local behavior of $\\sigma$. In particular, these theorems yield some\nconfidence intervals for $\\sigma_t$.\n"
    },
    {
        "paper_id": 812.3705,
        "authors": "Damiano Brigo and Agostino Capponi",
        "title": "Bilateral counterparty risk valuation with stochastic dynamical models\n  and application to Credit Default Swaps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce the general arbitrage-free valuation framework for counterparty\nrisk adjustments in presence of bilateral default risk, including default of\nthe investor. We illustrate the symmetry in the valuation and show that the\nadjustment involves a long position in a put option plus a short position in a\ncall option, both with zero strike and written on the residual net value of the\ncontract at the relevant default times. We allow for correlation between the\ndefault times of the investor, counterparty and underlying portfolio risk\nfactors. We use arbitrage-free stochastic dynamical models. We then specialize\nour analysis to Credit Default Swaps (CDS) as underlying portfolio,\ngeneralizing the work of Brigo and Chourdakis (2008) [5] who deal with\nunilateral and asymmetric counterparty risk. We introduce stochastic intensity\nmodels and a trivariate copula function on the default times exponential\nvariables to model default dependence. Similarly to [5], we find that both\ndefault correlation and credit spread volatilities have a relevant and\nstructured impact on the adjustment. Differently from [5], the two parties will\nnow agree on the credit valuation adjustment. We study a case involving British\nAirways, Lehman Brothers and Royal Dutch Shell, illustrating the bilateral\nadjustments in concrete crisis situations.\n"
    },
    {
        "paper_id": 812.401,
        "authors": "Damiano Brigo and Fabio Mercurio",
        "title": "Discrete Time vs Continuous Time Stock-price Dynamics and implications\n  for Option Pricing",
        "comments": "A short version of this paper by the same authors has appeared in\n  Finance and Stochastics 4, february 2000",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper we construct stock price processes with the same\nmarginal log-normal law as that of a geometric Brownian motion and also with\nthe same transition density (and returns' distributions) between any two\ninstants in a given discrete-time grid. We then illustrate how option prices\nbased on such processes differ from Black and Scholes', in that option prices\ncan be either arbitrarily close to the option intrinsic value or arbitrarily\nclose to the underlying stock price. We also explain that this is due to the\nparticular way one models the stock-price process in between the grid time\ninstants which are relevant for trading. The theoretical result concerning\nscalar stochastic differential equations with prescribed diffusion coefficient\nwhose densities evolve in a prescribed exponential family, on which part of the\npaper is based, is presented in detail.\n"
    },
    {
        "paper_id": 812.4028,
        "authors": "Viktor I. Shapovalov",
        "title": "Steady coexistence of the subjects of the market representing the\n  private and state capital",
        "comments": "Keywords: Nonlinear model of the market, Subharmonic cascade,\n  Economic crises",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The sustainability conditions for the market participants with a different\nownership model were also determined. It was revealed, that the nonlinear form\nof the equations describing the market behavior with the prevailing private\ncapital, predetermines the development of such a market according to the\nsubharmonic cascade scenario. The latter is presumably the reason of the\nperiodically arising economic crises.\n"
    },
    {
        "paper_id": 812.405,
        "authors": "Damiano Brigo and Bernard Hanzon",
        "title": "On three filtering problems arising in mathematical finance",
        "comments": "A short version appeared in \"Insurance. Mathematics and Economics\",\n  22 (1) (1998) pp. 53-64",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Three situations in which filtering theory is used in mathematical finance\nare illustrated at different levels of detail. The three problems originate\nfrom the following different works: 1) On estimating the stochastic volatility\nmodel from observed bilateral exchange rate news, by R. Mahieu, and P.\nSchotman; 2) A state space approach to estimate multi-factors CIR models of the\nterm structure of interest rates, by A.L.J. Geyer, and S. Pichler; 3)\nRisk-minimizing hedging strategies under partial observation in pricing\nfinancial derivatives, by P. Fischer, E. Platen, and W. J. Runggaldier; In the\nfirst problem we propose to use a recent nonlinear filtering technique based on\ngeometry to estimate the volatility time series from observed bilateral\nexchange rates. The model used here is the stochastic volatility model. The\nfilters that we propose are known as projection filters, and a brief derivation\nof such filters is given. The second problem is introduced in detail, and a\npossible use of different filtering techniques is hinted at. In fact the\nfilters used for this problem in 2) and part of the literature can be\ninterpreted as projection filters and we will make some remarks on how more\ngeneral and possibly more suitable projection filters can be constructed. The\nthird problem is only presented shortly.\n"
    },
    {
        "paper_id": 812.4052,
        "authors": "Damiano Brigo",
        "title": "The general mixture-diffusion SDE and its relationship with an\n  uncertain-volatility option model with volatility-asset decorrelation",
        "comments": null,
        "journal-ref": "Related publication in Brigo, D., Mercurio, F., and Sartorelli,\n  G., Alternative Asset Price Dynamics and Volatility Smile, Quantitative\n  Finance, Vol 3, N. 3. (2003) pp. 173-183",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present paper, given an evolving mixture of probability densities, we\ndefine a candidate diffusion process whose marginal law follows the same\nevolution. We derive as a particular case a stochastic differential equation\n(SDE) admitting a unique strong solution and whose density evolves as a mixture\nof Gaussian densities. We present an interesting result on the comparison\nbetween the instantaneous and the terminal correlation between the obtained\nprocess and its squared diffusion coefficient. As an application to\nmathematical finance, we construct diffusion processes whose marginal densities\nare mixtures of lognormal densities. We explain how such processes can be used\nto model the market smile phenomenon. We show that the lognormal mixture\ndynamics is the one-dimensional diffusion version of a suitable uncertain\nvolatility model, and suitably reinterpret the earlier correlation result. We\nexplore numerically the relationship between the future smile structures of\nboth the diffusion and the uncertain volatility versions.\n"
    },
    {
        "paper_id": 812.4156,
        "authors": "Massimo Morini and Damiano Brigo",
        "title": "Arbitrage-free Pricing of Credit Index Options: The no-armageddon\n  pricing measure and the role of correlation after the subprime crisis",
        "comments": "Updated version accepted for publication in Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we consider three problems of the standard market approach to\npricing of credit index options: the definition of the index spread is not\nvalid in general, the usually considered payoff leads to a pricing which is not\nalways defined, and the candidate numeraire one would use to define a pricing\nmeasure is not strictly positive, which would lead to a non-equivalent pricing\nmeasure.\n  We give a general mathematical solution to the three problems, based on a\nnovel way of modeling the flow of information through the definition of a new\nsubfiltration. Using this subfiltration, we take into account consistently the\npossibility of default of all names in the portfolio, that is neglected in the\nstandard market approach. We show that, while the related mispricing can be\nnegligible for standard options in normal market conditions, it can become\nhighly relevant for different options or in stressed market conditions.\n  In particular, we show on 2007 market data that after the subprime credit\ncrisis the mispricing of the market formula compared to the no arbitrage\nformula we propose has become financially relevant even for the liquid\nCrossover Index Options.\n"
    },
    {
        "paper_id": 812.4159,
        "authors": "Damiano Brigo",
        "title": "Constant Maturity Credit Default Swap Pricing with Market Models",
        "comments": null,
        "journal-ref": "Short version in Risk Magazine, june 2006 issue, and related paper\n  in \"Credit Risk: Models, Derivatives and Management\", Taylor & Francis, 2008",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we derive an approximated no-arbitrage market valuation formula\nfor Constant Maturity Credit Default Swaps (CMCDS). We move from the CDS\noptions market model in Brigo (2004), and derive a formula for CMCDS that is\nthe analogous of the formula for constant maturity swaps in the default free\nswap market under the LIBOR market model. A \"convexity adjustment\"-like\ncorrection is present in the related formula. Without such correction, or with\nzero correlations, the formula returns an obvious deterministic-credit-spread\nexpression for the CMCDS price. To obtain the result we derive a joint dynamics\nof forward CDS rates under a single pricing measure, as in Brigo (2004).\nNumerical examples of the \"convexity adjustment\" impact complete the paper.\n"
    },
    {
        "paper_id": 812.4163,
        "authors": "Damiano Brigo, Andrea Pallavicini and Roberto Torresetti",
        "title": "Default correlation, cluster dynamics and single names: The GPCL\n  dynamical loss model",
        "comments": null,
        "journal-ref": "Short version in \"International Journal of Theoretical and Applied\n  Finance\", Vol 10, n. 4, and in \"Credit Correlation - Life After Copulas\",\n  World Scientific, 2007",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We extend the common Poisson shock framework reviewed for example in Lindskog\nand McNeil (2003) to a formulation avoiding repeated defaults, thus obtaining a\nmodel that can account consistently for single name default dynamics, cluster\ndefault dynamics and default counting process. This approach allows one to\nintroduce significant dynamics, improving on the standard \"bottom-up\"\napproaches, and to achieve true consistency with single names, improving on\nmost \"top-down\" loss models. Furthermore, the resulting GPCL model has\nimportant links with the previous GPL dynamical loss model in Brigo,\nPallavicini and Torresetti (2006a,b), which we point out. Model extensions\nallowing for more articulated spread and recovery dynamics are hinted at.\nCalibration to both DJi-TRAXX and CDX index and tranche data across attachments\nand maturities shows that the GPCL model has the same calibration power as the\nGPL model while allowing for consistency with single names\n"
    },
    {
        "paper_id": 812.4199,
        "authors": "Damiano Brigo and Naoufel El-Bachir",
        "title": "An exact formula for default swaptions' pricing in the SSRJD stochastic\n  intensity model",
        "comments": "Accepted for publication in Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop and test a fast and accurate semi-analytical formula for\nsingle-name default swaptions in the context of a shifted square root jump\ndiffusion (SSRJD) default intensity model. The model can be calibrated to the\nCDS term structure and a few default swaptions, to price and hedge other credit\nderivatives consistently. We show with numerical experiments that the model\nimplies plausible volatility smiles.\n"
    },
    {
        "paper_id": 812.421,
        "authors": "Damiano Brigo, Antonio Dalessandro, Matthias Neugebauer, Fares Triki",
        "title": "A Stochastic Processes Toolkit for Risk Management",
        "comments": "Updated version accepted for publication in the Journal of Risk\n  Management for Financial Institutions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In risk management it is desirable to grasp the essential statistical\nfeatures of a time series representing a risk factor. This tutorial aims to\nintroduce a number of different stochastic processes that can help in grasping\nthe essential features of risk factors describing different asset classes or\nbehaviors. This paper does not aim at being exhaustive, but gives examples and\na feeling for practically implementable models allowing for stylised features\nin the data. The reader may also use these models as building blocks to build\nmore complex models, although for a number of risk management applications the\nmodels developed here suffice for the first step in the quantitative analysis.\nThe broad qualitative features addressed here are {fat tails} and {mean\nreversion}. We give some orientation on the initial choice of a suitable\nstochastic process and then explain how the process parameters can be estimated\nbased on historical data. Once the process has been calibrated, typically\nthrough maximum likelihood estimation, one may simulate the risk factor and\nbuild future scenarios for the risky portfolio. On the terminal simulated\ndistribution of the portfolio one may then single out several risk measures,\nalthough here we focus on the stochastic processes estimation preceding the\nsimulation of the risk factors Finally, this first survey report focuses on\nsingle time series. Correlation or more generally dependence across risk\nfactors, leading to multivariate processes modeling, will be addressed in\nfuture work.\n"
    },
    {
        "paper_id": 812.4455,
        "authors": "Robert Kitt, Maksim Sakki, Jaan Kalda",
        "title": "Probability of Large Movements in Financial Markets",
        "comments": "8 pages, 5 figures",
        "journal-ref": "Physica A 388 (2009) 4838-4844",
        "doi": "10.1016/j.physa.2009.07.027",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on empirical financial time-series, we show that the \"silence-breaking\"\nprobability follows a super-universal power law: the probability of observing a\nlarge movement is inversely proportional to the length of the on-going\nlow-variability period. Such a scaling law has been previously predicted\ntheoretically [R. Kitt, J. Kalda, Physica A 353 (2005) 480], assuming that the\nlength-distribution of the low-variability periods follows a multiscaling power\nlaw.\n"
    },
    {
        "paper_id": 812.4548,
        "authors": "Bjorn Eriksson, Martijn Pistorius",
        "title": "A method of moments approach to pricing double barrier contracts driven\n  by a general class of jump diffusions",
        "comments": "22 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present the method of moments approach to pricing barrier-type options\nwhen the underlying is modelled by a general class of jump diffusions. By\ngeneral principles the option prices are linked to certain infinite dimensional\nlinear programming problems. Subsequently approximating those systems by finite\ndimensional linear programming problems, upper and lower bounds for the prices\nof such options are found. As numerical illustration we apply the method to the\nvaluation of several barrier-type options (double barrier knockout option,\nAmerican corridor and double no touch) under a number of different models,\nincluding a case with deterministic interest rates, and compare with Monte\nCarlo simulation results. In all cases we find tight bounds with short\nexecution times. Theoretical convergence results are also provided.\n"
    },
    {
        "paper_id": 812.4737,
        "authors": "V.P. Maslov",
        "title": "Economic law of increase of Kolmogorov complexity. Transition from\n  financial crisis 2008 to the zero-order phase transition (social explosion)",
        "comments": "Latex, 24 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In Maslov (2003), a two level model of the occurrence of financial pyramid\n(bubbles) has been considered. We also considered the mathematical analogy of\nthis model to Bose condensation. In the present paper, we explain why Ponzi\nschemes and bubbles result in a crisis in real economics. In Maslov (2005), the\nlaw of increase of entropy in financial systems, and consequently increase of\nKolmogorov complexity, is formulated. If this law is broken, the financial\nsystem makes a phase transition to a different state. In Maslov (2005) the\nauthor considered a two level model of the zeroth-order phase transition which\nwas interpreted in Maslov (2006) as an analog of social catastrophe. In the\npresent paper we also examine this model.\n"
    },
    {
        "paper_id": 812.4978,
        "authors": "Zhengjun Jiang and Martijn Pistorius",
        "title": "Optimal dividend distribution under Markov-regime switching",
        "comments": "25 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the problem of optimal dividend distribution for a company in\nthe presence of regime shifts. We consider a company whose cumulative net\nrevenues evolve as a Brownian motion with positive drift that is modulated by a\nfinite state Markov chain, and model the discount rate as a deterministic\nfunction of the current state of the chain. In this setting the objective of\nthe company is to maximize the expected cumulative discounted dividend payments\nuntil the moment of bankruptcy, which is taken to be the first time that the\ncash reserves (the cumulative net revenues minus cumulative dividend payments)\nare zero. We show that, if the drift is positive in each state, it is optimal\nto adopt a barrier strategy at certain positive regime-dependent levels, and\nprovide an explicit characterization of the value function as the fixed point\nof a contraction. In the case that the drift is small and negative in one\nstate, the optimal strategy takes a different form, which we explicitly\nidentify if there are two regimes. We also provide a numerical illustration of\nthe sensitivities of the optimal barriers and the influence of\nregime-switching.\n"
    },
    {
        "paper_id": 901.0033,
        "authors": "Abel Rodriguez and Enrique ter Horst",
        "title": "Measuring expectations in options markets: An application to the SP500\n  index",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Extracting market expectations has always been an important issue when making\nnational policies and investment decisions in financial markets. In option\nmarkets, the most popular way has been to extract implied volatilities to\nassess the future variability of the underlying with the use of the Black and\nScholes formula. In this manuscript, we propose a novel way to extract the\nwhole time varying distribution of the market implied asset price from option\nprices. We use a Bayesian nonparametric method that makes use of the Sethuraman\nrepresentation for Dirichlet processes to take into account the evolution of\ndistributions in time. As an illustration, we present the analysis of options\non the SP500 index.\n"
    },
    {
        "paper_id": 901.0091,
        "authors": "Ulrich Horst, Felix Naujokat",
        "title": "Illiquidity and Derivative Valuation",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In illiquid markets, option traders may have an incentive to increase their\nportfolio value by using their impact on the dynamics of the underlying. We\nprovide a mathematical framework within which to value derivatives under market\nimpact in a multi-player framework by introducing strategic interactions into\nthe Almgren & Chriss (2001) model. Specifically, we consider a financial market\nmodel with several strategically interacting players that hold European\ncontingent claims and whose trading decisions have an impact on the price\nevolution of the underlying. We establish existence and uniqueness of\nequilibrium results and show that the equilibrium dynamics can be characterized\nin terms of a coupled system of possibly non-linear PDEs. For the linear cost\nfunction used in Almgren & Chriss (2001), we obtain (semi) closed form\nsolutions for risk neutral or CARA investors. Finally, we indicate how spread\ncrossing costs discourage market manipulation.\n"
    },
    {
        "paper_id": 901.0401,
        "authors": "Adom Giffin",
        "title": "From Physics to Economics: An Econometric Example Using Maximum Relative\n  Entropy",
        "comments": "This paper has been accepted in Physica A. 19 Pages, 3 Figures",
        "journal-ref": "Physica A 388 (2009), pp. 1610-1620",
        "doi": "10.1016/j.physa.2008.12.066",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Econophysics, is based on the premise that some ideas and methods from\nphysics can be applied to economic situations. We intend to show in this paper\nhow a physics concept such as entropy can be applied to an economic problem. In\nso doing, we demonstrate how information in the form of observable data and\nmoment constraints are introduced into the method of Maximum relative Entropy\n(MrE). A general example of updating with data and moments is shown. Two\nspecific econometric examples are solved in detail which can then be used as\ntemplates for real world problems. A numerical example is compared to a large\ndeviation solution which illustrates some of the advantages of the MrE method.\n"
    },
    {
        "paper_id": 901.0434,
        "authors": "William T. Shaw, Ian R.C. Buckley",
        "title": "The alchemy of probability distributions: beyond Gram-Charlier\n  expansions, and a skew-kurtotic-normal distribution from a rank transmutation\n  map",
        "comments": "Presentation at 2007 IMA First Conference on Computational Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by the need for parametric families of rich and yet tractable\ndistributions in financial mathematics, both in pricing and risk management\nsettings, but also considering wider statistical applications, we investigate a\nnovel technique for introducing skewness or kurtosis into a symmetric or other\ndistribution. We use a \"transmutation\" map, which is the functional composition\nof the cumulative distribution function of one distribution with the inverse\ncumulative distribution (quantile) function of another. In contrast to the\nGram-Charlier approach, this is done without resorting to an asymptotic\nexpansion, and so avoids the pathologies that are often associated with it.\nExamples of parametric distributions that we can generate in this way include\nthe skew-uniform, skew-exponential, skew-normal, and skew-kurtotic-normal.\n"
    },
    {
        "paper_id": 901.0447,
        "authors": "Andreas Krause",
        "title": "Evaluating the performance of adapting trading strategies with different\n  memory lengths",
        "comments": "12 pages with 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a prediction model based on the minority game in which traders\ncontinuously evaluate a complete set of trading strategies with different\nmemory lengths using the strategies' past performance. Based on the chosen\ntrading strategy they determine their prediction of the movement for the\nfollowing time period of a single asset. We find empirically using stocks from\nthe S&P500 that our prediction model yields a high success rate of over 51.5%\nand produces higher returns than a buy-and-hold strategy. Even when taking into\naccount trading costs we find that using the predictions will generate superior\ninvestment portfolios.\n"
    },
    {
        "paper_id": 901.0495,
        "authors": "Bence Toth, Janos Kertesz, J. Doyne Farmer",
        "title": "Studies of the limit order book around large price changes",
        "comments": "19 pages, 7 figures",
        "journal-ref": "Eur. Phys. J. B 71, 499-510 (2009)",
        "doi": "10.1140/epjb/e2009-00297-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the dynamics of the limit order book of liquid stocks after\nexperiencing large intra-day price changes. In the data we find large\nvariations in several microscopical measures, e.g., the volatility the bid-ask\nspread, the bid-ask imbalance, the number of queuing limit orders, the activity\n(number and volume) of limit orders placed and canceled, etc. The relaxation of\nthe quantities is generally very slow that can be described by a power law of\nexponent $\\approx0.4$. We introduce a numerical model in order to understand\nthe empirical results better. We find that with a zero intelligence deposition\nmodel of the order flow the empirical results can be reproduced qualitatively.\nThis suggests that the slow relaxations might not be results of agents'\nstrategic behaviour. Studying the difference between the exponents found\nempirically and numerically helps us to better identify the role of strategic\nbehaviour in the phenomena.\n"
    },
    {
        "paper_id": 901.0638,
        "authors": "William T. Shaw, Thomas Luu, Nick Brickman",
        "title": "Quantile Mechanics II: Changes of Variables in Monte Carlo methods and\n  GPU-Optimized Normal Quantiles",
        "comments": "This revision adds substantial discussion of precision and\n  optimization issues, new code for float and double precision operation.\n  Timings for GTX 285, 480, Quadro 4000, Tesla C2050, and comparisons with most\n  major competing approaches",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article presents differential equations and solution methods for the\nfunctions of the form $Q(x) = F^{-1}(G(x))$, where $F$ and $G$ are cumulative\ndistribution functions. Such functions allow the direct recycling of Monte\nCarlo samples from one distribution into samples from another. The method may\nbe developed analytically for certain special cases, and illuminate the idea\nthat it is a more precise form of the traditional Cornish-Fisher expansion. In\nthis manner the model risk of distributional risk may be assessed free of the\nMonte Carlo noise associated with resampling. Examples are given of equations\nfor converting normal samples to Student t, and converting exponential to\nhyperbolic, variance gamma and normal. In the case of the normal distribution,\nthe change of variables employed allows the sampling to take place to good\naccuracy based on a single rational approximation over a very wide range of the\nsample space. The avoidance of any branching statement is of use in optimal GPU\ncomputations as it avoids the effect of {\\it warp divergence}, and we give\nexamples of branch-free normal quantiles that offer performance improvements in\na GPU environment, while retaining the best precision characteristics of\nwell-known methods. We also offer models based on a low-probability of warp\ndivergence. Comparisons of new and old forms are made on the Nvidia Quadro\n4000, GTX 285 and 480, and Tesla C2050 GPUs. We argue that in single-precision\nmode, the change-of-variables approach offers performance competitive with the\nfastest existing scheme while substantially improving precision, and that in\ndouble-precision mode, this approach offers the most GPU-optimal Gaussian\nquantile yet, and without compromise on precision for Monte Carlo applications,\nworking twice as fast as the CUDA 4 library function with increased precision.\n"
    },
    {
        "paper_id": 901.0674,
        "authors": "Alexander M.G. Cox, Jan Obloj",
        "title": "Robust pricing and hedging of double no-touch options",
        "comments": "32 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Double no-touch options, contracts which pay out a fixed amount provided an\nunderlying asset remains within a given interval, are commonly traded,\nparticularly in FX markets. In this work, we establish model-free bounds on the\nprice of these options based on the prices of more liquidly traded options\n(call and digital call options). Key steps are the construction of super- and\nsub-hedging strategies to establish the bounds, and the use of Skorokhod\nembedding techniques to show the bounds are the best possible.\n  In addition to establishing rigorous bounds, we consider carefully what is\nmeant by arbitrage in settings where there is no {\\it a priori} known\nprobability measure. We discuss two natural extensions of the notion of\narbitrage, weak arbitrage and weak free lunch with vanishing risk, which are\nneeded to establish equivalence between the lack of arbitrage and the existence\nof a market model.\n"
    },
    {
        "paper_id": 901.0903,
        "authors": "V. Gontis, J. Ruseckas and A. Kononovicius",
        "title": "A long-range memory stochastic model of the return in financial markets",
        "comments": "9 pages, 3 figures",
        "journal-ref": "Physica A 389 (2010) 100-106",
        "doi": "10.1016/j.physa.2009.09.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a nonlinear stochastic differential equation (SDE) which mimics\nthe probability density function (PDF) of the return and the power spectrum of\nthe absolute return in financial markets. Absolute return as a measure of\nmarket volatility is considered in the proposed model as a long-range memory\nstochastic variable. The SDE is obtained from the analogy with earlier proposed\nmodel of trading activity in the financial markets and generalized within the\nnonextensive statistical mechanics framework. The proposed stochastic model\ngenerates time series of the return with two power law statistics, i.e., the\nPDF and the power spectral density, reproducing the empirical data for the one\nminute trading return in the NYSE.\n"
    },
    {
        "paper_id": 901.0992,
        "authors": "Tetsuya Takaishi",
        "title": "An Adaptive Markov Chain Monte Carlo Method for GARCH Model",
        "comments": "11 pages, 6 figures",
        "journal-ref": "Lecture Notes of the Institute for Computer Sciences, Social\n  Informatics and Telecommunications Engineering. Complex Sciences, vol. 5\n  (2009) 1424-1434",
        "doi": "10.1007/978-3-642-02469-6_22",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a method to construct a proposal density for the\nMetropolis-Hastings algorithm in Markov Chain Monte Carlo (MCMC) simulations of\nthe GARCH model. The proposal density is constructed adaptively by using the\ndata sampled by the MCMC metho d itself. It turns out that autocorrelations\nbetween the data generated with our adaptive proposal density are greatly\nreduced. Thus it is concluded that the adaptive construction method is very\nefficient and works well for the MCMC simulations of the GARCH model.\n"
    },
    {
        "paper_id": 901.1038,
        "authors": "Carmen Pellicer-Lostao and Ricardo Lopez-Ruiz",
        "title": "Economic Models with Chaotic Money Exchange",
        "comments": "10 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a novel study on gas-like models for economic systems.\nThe interacting agents and the amount of exchanged money at each trade are\nselected with different levels of randomness, from a purely random way to a\nmore chaotic one. Depending on the interaction rules, these statistical models\ncan present different asymptotic distributions of money in a community of\nindividuals with a closed economy.\n"
    },
    {
        "paper_id": 901.1099,
        "authors": "Damiano Brigo, Kyriakos Chourdakis, Imane Bakkar",
        "title": "Counterparty risk valuation for Energy-Commodities swaps: Impact of\n  volatilities and correlation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is commonly accepted that Commodities futures and forward prices, in\nprinciple, agree under some simplifying assumptions. One of the most relevant\nassumptions is the absence of counterparty risk. Indeed, due to margining,\nfutures have practically no counterparty risk. Forwards, instead, may bear the\nfull risk of default for the counterparty when traded with brokers or outside\nclearing houses, or when embedded in other contracts such as swaps. In this\npaper we focus on energy commodities and on Oil in particular. We use a hybrid\ncommodities-credit model to asses impact of counterparty risk in pricing\nformulas, both in the gross effect of default probabilities and on the subtler\neffects of credit spread volatility, commodities volatility and\ncredit-commodities correlation. We illustrate our general approach with a case\nstudy based on an oil swap, showing that an accurate valuation of counterparty\nrisk depends on volatilities and correlation and cannot be accounted for\nprecisely through a pre-defined multiplier.\n"
    },
    {
        "paper_id": 901.1218,
        "authors": "Louis Paulot and Xavier Lacroze",
        "title": "Efficient Pricing of CPPI using Markov Operators",
        "comments": "40 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Constant Proportion Portfolio Insurance (CPPI) is a strategy designed to give\nparticipation in a risky asset while protecting the invested capital. Some gap\nrisk due to extreme events is often kept by the issuer of the product: a put\noption on the CPPI strategy is included in the product. In this paper we\npresent a new method for the pricing of CPPIs and options on CPPIs, which is\nmuch faster and more accurate than the usual Monte-Carlo method. Provided the\nunderlying follows a homogeneous process, the path-dependent CPPI strategy is\nreformulated into a Markov process in one variable, which allows to use\nefficient linear algebra techniques. Tail events, which are crucial in the\npricing are handled smoothly. We incorporate in this framework linear\nthresholds, profit lock-in, performance coupons... The American exercise of\nopen-ended CPPIs is handled naturally through backward propagation. Finally we\nuse our pricing scheme to study the influence of various features on the gap\nrisk of CPPI strategies.\n"
    },
    {
        "paper_id": 901.1315,
        "authors": "Abel Rodriguez and Henryk Gzyl and German Molina and Enrique ter Horst",
        "title": "Stochastic Volatility Models Including Open, Close, High and Low Prices",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Mounting empirical evidence suggests that the observed extreme prices within\na trading period can provide valuable information about the volatility of the\nprocess within that period. In this paper we define a class of stochastic\nvolatility models that uses opening and closing prices along with the minimum\nand maximum prices within a trading period to infer the dynamics underlying the\nvolatility process of asset prices and compares it with similar models that\nhave been previously presented in the literature. The paper also discusses\nsequential Monte Carlo algorithms to fit this class of models and illustrates\nits features using both a simulation study and data form the SP500 index.\n"
    },
    {
        "paper_id": 901.1392,
        "authors": "Reginald D. Smith",
        "title": "The Spread of the Credit Crisis: View from a Stock Correlation Network",
        "comments": "4 pages, 3 figures; to appear in the Journal of the Physical Society\n  of Korea; animations of credit crisis spread available at:\n  http://reggiesmithsci.googlepages.com/creditcrisis",
        "journal-ref": "J Korean Phys. Soc. 54, 6, p. 2460-2463 (2009)",
        "doi": "10.3938/jkps.54.2460",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The credit crisis roiling the world's financial markets will likely take\nyears and entire careers to fully understand and analyze. A short empirical\ninvestigation of the current trends, however, demonstrates that the losses in\ncertain markets, in this case the US equity markets, follow a cascade or\nepidemic flow like model along the correlations of various stocks. This\nphenomenon will be shown by the graphical display of stock returns across the\nnetwork as well as the dependence of stock returns on topological measures.\nFinally, whether the idea of \"epidemic\" or a \"cascade\" is a metaphor or model\nfor this crisis will be discussed.\n"
    },
    {
        "paper_id": 901.15,
        "authors": "Hideaki Aoyama, Yoshi Fujiwara, Yuichi Ikeda, Hiroshi Iyetomi, and\n  Wataru Souma",
        "title": "Superstatistics of Labour Productivity in Manufacturing and\n  Nonmanufacturing Sectors",
        "comments": "15 pages, including 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Labour productivity distribution (dispersion) is studied both theoretically\nand empirically. Superstatistics is presented as a natural theoretical\nframework for productivity. The demand index $\\kappa$ is proposed within this\nframework as a new business index. Japanese productivity data covering\nsmall-to-medium to large firms from 1996 to 2006 is analyzed and the power-law\nfor both firms and workers is established. The demand index $\\kappa$ is\nevaluated in the manufacturing sector. A new discovery is reported for the\nnonmanufacturing (service) sector, which calls for expansion of the\nsuperstatistics framework to negative temperature range.\n"
    },
    {
        "paper_id": 901.1776,
        "authors": "Marc Henrard",
        "title": "Efficient swaptions price in Hull-White one factor model",
        "comments": "10 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Hull-White one factor model is used to price interest rate options. The\nparameters of the model are often calibrated to simple liquid instruments, in\nparticular European swaptions. It is therefore very important to have very\nefficient pricing formula for simple instruments. Such a formula is proposed\nhere for European swaption. Based on a very efficient corrector type\napproximation the approximation is efficient both in term of precision and in\nterm of spped. In our implementation the approximation is more than ten time\nfaster than the direct pricing formula and more than twenty time faster than\nthe Jamshidian trick.\n"
    },
    {
        "paper_id": 901.1794,
        "authors": "Hiroshi Iyetomi, Hideaki Aoyama, Yoshi Fujiwara, Yuichi Ikeda, Wataru\n  Souma",
        "title": "Agent-Based Model Approach to Complex Phenomena in Real Economy",
        "comments": "11 page, submitted to Progress of Theoretical Physics Supplement",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An agent-based model for firms' dynamics is developed. The model consists of\nfirm agents with identical characteristic parameters and a bank agent. Dynamics\nof those agents is described by their balance sheets. Each firm tries to\nmaximize its expected profit with possible risks in market. Infinite growth of\na firm directed by the \"profit maximization\" principle is suppressed by a\nconcept of \"going concern\". Possibility of bankruptcy of firms is also\nintroduced by incorporating a retardation effect of information on firms'\ndecision. The firms, mutually interacting through the monopolistic bank, become\nheterogeneous in the course of temporal evolution. Statistical properties of\nfirms' dynamics obtained by simulations based on the model are discussed in\nlight of observations in the real economy.\n"
    },
    {
        "paper_id": 901.1945,
        "authors": "Michel Fliess (LIX, INRIA Saclay - Ile de France), C\\'edric Join\n  (INRIA Saclay - Ile de France, CRAN)",
        "title": "A mathematical proof of the existence of trends in financial time series",
        "comments": null,
        "journal-ref": "Systems Theory: Modelling, Analysis and Control (2009) 43-62",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We are settling a longstanding quarrel in quantitative finance by proving the\nexistence of trends in financial time series thanks to a theorem due to P.\nCartier and Y. Perrin, which is expressed in the language of nonstandard\nanalysis (Integration over finite sets, F. & M. Diener (Eds): Nonstandard\nAnalysis in Practice, Springer, 1995, pp. 195--204). Those trends, which might\ncoexist with some altered random walk paradigm and efficient market hypothesis,\nseem nevertheless difficult to reconcile with the celebrated Black-Scholes\nmodel. They are estimated via recent techniques stemming from control and\nsignal theory. Several quite convincing computer simulations on the forecast of\nvarious financial quantities are depicted. We conclude by discussing the r\\^ole\nof probability theory.\n"
    },
    {
        "paper_id": 901.207,
        "authors": "Jose E. Figueroa-Lopez and Jin Ma",
        "title": "State-dependent utility maximization in L\\'evy markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit Merton's portfolio optimization problem under boun-ded\nstate-dependent utility functions, in a market driven by a L\\'evy process $Z$\nextending results by Karatzas et. al. (1991) and Kunita (2003). The problem is\nsolved using a dual variational problem as it is customarily done for\nnon-Markovian models. One of the main features here is that the domain of the\ndual problem enjoys an explicit \"parametrization\", built on a multiplicative\noptional decomposition for nonnegative supermartingales due to F\\\"ollmer and\nKramkov (1997). As a key step in obtaining the representation result we prove a\nclosure property for integrals with respect to Poisson random measures, a\nresult of interest on its own that extends the analog property for integrals\nwith respect to a fixed semimartingale due to M\\'emin (1980). In the case that\n(i) the L\\'evy measure of $Z$ is atomic with a finite number of atoms or that\n(ii) $\\Delta S_{t}/S_{t^{-}}=\\zeta_{t} \\vartheta(\\Delta Z_{t})$ for a process\n$\\zeta$ and a deterministic function $\\vartheta$, we explicitly characterize\nthe admissible trading strategies and show that the dual solution is a\nrisk-neutral local martingale.\n"
    },
    {
        "paper_id": 901.208,
        "authors": "Constantinos Kardaras, Eckhard Platen",
        "title": "On the Dybvig-Ingersoll-Ross Theorem",
        "comments": "12 pages; second revised version, text rearranged and some content\n  added.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The Dybvig-Ingersoll-Ross (DIR) theorem states that, in arbitrage-free term\nstructure models, long-term yields and forward rates can never fall. We present\na refined version of the DIR theorem, where we identify the reciprocal of the\nmaturity date as the maximal order that long-term rates at earlier dates can\ndominate long-term rates at later dates. The viability assumption imposed on\nthe market model is weaker than those appearing previously in the literature.\n"
    },
    {
        "paper_id": 901.2271,
        "authors": "Erik Van der Straeten and Christian Beck",
        "title": "Superstatistical fluctuations in time series: Applications to\n  share-price dynamics and turbulence",
        "comments": null,
        "journal-ref": "Phys. Rev. E 80, 036108 (2009)",
        "doi": "10.1103/PhysRevE.80.036108",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We report a general technique to study a given experimental time series with\nsuperstatistics. Crucial for the applicability of the superstatistics concept\nis the existence of a parameter $\\beta$ that fluctuates on a large time scale\nas compared to the other time scales of the complex system under consideration.\nThe proposed method extracts the main superstatistical parameters out of a\ngiven data set and examines the validity of the superstatistical model\nassumptions. We test the method thoroughly with surrogate data sets. Then the\napplicability of the superstatistical approach is illustrated using real\nexperimental data. We study two examples, velocity time series measured in\nturbulent Taylor-Couette flows and time series of log returns of the closing\nprices of some stock market indices.\n"
    },
    {
        "paper_id": 901.2275,
        "authors": "Gilles Zumbach",
        "title": "Volatility forecasts and the at-the-money implied volatility: a\n  multi-components ARCH approach and its relation with market models",
        "comments": "21 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a given time horizon DT, this article explores the relationship between\nthe realized volatility (the volatility that will occur between t and t+DT),\nthe implied volatility (corresponding to at-the-money option with expiry at\nt+DT), and several forecasts for the volatility build from multi-scales linear\nARCH processes. The forecasts are derived from the process equations, and the\nparameters set a priori. An empirical analysis across multiple time horizons DT\nshows that a forecast provided by an I-GARCH(1) process (1 time scale) does not\ncapture correctly the dynamic of the realized volatility. An I-GARCH(2) process\n(2 time scales, similar to GARCH(1,1)) is better, while a long memory LM-ARCH\nprocess (multiple time scales) replicates correctly the dynamic of the realized\nvolatility and delivers consistently good forecast for the implied volatility.\nThe relationship between market models for the forward variance and the\nvolatility forecasts provided by ARCH processes is investigated. The structure\nof the forecast equations is identical, but with different coefficients. Yet\nthe process equations for the variance are very different (postulated for a\nmarket model, induced by the process equations for an ARCH model), and not of\nany usual diffusive type when derived from ARCH.\n"
    },
    {
        "paper_id": 901.2377,
        "authors": "Yoshi Fujiwara, Hideaki Aoyama, Yuichi Ikeda, Hiroshi Iyetomi, and\n  Wataru Souma",
        "title": "Structure and temporal change of the credit network between banks and\n  large firms in Japan",
        "comments": null,
        "journal-ref": "Economics E-Journal 3 (2009) 2009-7",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new approach to understanding credit relationships between\ncommercial banks and quoted firms, and with this approach, examine the temporal\nchange in the structure of the Japanese credit network from 1980 to 2005. At\neach year, the credit network is regarded as a weighted bipartite graph where\nedges correspond to the relationships and weights refer to the amounts of\nloans. Reduction in the supply of credit affects firms as debtor, and failure\nof a firm influences banks as creditor. To quantify the dependency and\ninfluence between banks and firms, we propose a set of scores of banks and\nfirms, which can be calculated by solving an eigenvalue problem determined by\nthe weight of the credit network. We found that a few largest eigenvalues and\ncorresponding eigenvectors are significant by using a null hypothesis of random\nbipartite graphs, and that the scores can quantitatively describe the stability\nor fragility of the credit network during the 25 years.\n"
    },
    {
        "paper_id": 901.2381,
        "authors": "Yoshi Fujiwara",
        "title": "Visualizing a large-scale structure of production network by N-body\n  simulation",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1143/PTPS.179.167",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our recent study of a nation-wide production network uncovered a community\nstructure, namely how firms are connected by supplier-customer links into\ntightly-knit groups with high density in intra-groups and with lower\nconnectivity in inter-groups. Here we propose a method to visualize the\ncommunity structure by a graph layout based on a physical analogy. The layout\ncan be calculated in a practical computation-time and is possible to be\naccelerated by a special-purpose device of GRAPE (gravity pipeline) developed\nfor astrophysical N-body simulation. We show that the method successfully\nidentifies the communities in a hierarchical way by applying it to the\nmanufacturing sector comprising tenth million nodes and a half million edges.\nIn addition, we discuss several limitations of this method, and propose a\npossible way to avoid all those problems.\n"
    },
    {
        "paper_id": 901.2384,
        "authors": "G. De Masi, Y. Fujiwara, M. Gallegati, B. Greenwald, J. E. Stiglitz",
        "title": "An Analysis of the Japanese Credit Network",
        "comments": "23 pages with 14 figures; revised and Figure 14 added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An analysis of the Japanese credit market in 2004 between banks and quoted\nfirms is done in this paper using the tools of the networks theory. It can be\npointed out that: (i) a backbone of the credit channel emerges, where some\nlinks play a crucial role; (ii) big banks privilege long-term contracts; the\n\"minimal spanning trees\" (iii) disclose a highly hierarchical backbone, where\nthe central positions are occupied by the largest banks, and emphasize (iv) a\nstrong geographical characterization, while (v) the clusters of firms do not\nhave specific common properties. Moreover, (vi) while larger firms have\nmultiple lending in large, (vii) the demand for credit (long vs. short term\ndebt and multi-credit lines) of firms with similar sizes is very heterogeneous.\n"
    },
    {
        "paper_id": 901.2484,
        "authors": "Jesus Marin-Solano, Jorge Navas",
        "title": "Consumption and Portfolio Rules for Time-Inconsistent Investors",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper extends the classical consumption and portfolio rules model in\ncontinuous time (Merton 1969, 1971) to the framework of decision-makers with\ntime-inconsistent preferences. The model is solved for different utility\nfunctions for both, naive and sophisticated agents, and the results are\ncompared. In order to solve the problem for sophisticated agents, we derive a\nmodified HJB (Hamilton-Jacobi-Bellman) equation. It is illustrated how for CRRA\nfunctions within the family of HARA functions (logarithmic and potential cases)\nthe optimal portfolio rule does not depend on the discount rate, but this is\nnot the case for a general utility function, such as the exponential (CARA)\nutility function.\n"
    },
    {
        "paper_id": 901.2586,
        "authors": "Richard Nock, Brice Magdalou, Nicolas Sanz, Eric Briys, Fred Celimene,\n  Frank Nielsen",
        "title": "Information geometries and Microeconomic Theories",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  More than thirty years ago, Charnes, Cooper and Schinnar (1976) established\nan enlightening contact between economic production functions (EPFs) -- a\ncornerstone of neoclassical economics -- and information theory, showing how a\ngeneralization of the Cobb-Douglas production function encodes homogeneous\nfunctions.\n  As expected by Charnes \\textit{et al.}, the contact turns out to be much\nbroader: we show how information geometry as pioneered by Amari and others\nunderpins static and dynamic descriptions of microeconomic cornerstones.\n  We show that the most popular EPFs are fundamentally grounded in a very weak\naxiomatization of economic transition costs between inputs. The strength of\nthis characterization is surprising, as it geometrically bonds altogether a\nwealth of collateral economic notions\n  -- advocating for applications in various economic fields --: among all, it\ncharacterizes (i) Marshallian and Hicksian demands and their geometric duality,\n(ii) Slutsky-type properties for the transformation paths, (iii) Roy-type\nproperties for their elementary variations.\n"
    },
    {
        "paper_id": 901.2826,
        "authors": "Maxim Bobrov",
        "title": "Optimal systems of subalgebras for a nonlinear Black-Scholes equation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main object of our study is a four dimensional Lie algebra which\ndescribes the symmetry properties of a nonlinear Black-Scholes model. This\nmodel implements a feedback effect which is typical for an illiquid market. The\nstructure of the Lie algebra depends on one parameter, i.e. we have to do with\na one-parametric family of algebras. We provide a classification of these\nalgebras using Patera--Winternitz method. Optimal systems of one-, two- and\nthree- dimensional subalgebras are described for the family of symmetry\nalgebras of the nonlinear Black-Scholes equation. The optimal systems give us\nthe possibility to describe a complete set of invariant solutions to the\nequation.\n"
    },
    {
        "paper_id": 901.2857,
        "authors": "Arnab Chatterjee",
        "title": "Kinetic models for wealth exchange on directed networks",
        "comments": "6 pages, 5 figs, RevTeX4",
        "journal-ref": "Eur. Phys. J. B 67 (2009) 593-598",
        "doi": "10.1140/epjb/e2009-00044-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose some kinetic models of wealth exchange and investigate their\nbehavior on directed networks though numerical simulations. We observe that\nnetwork topology and directedness yields a variety of interesting features in\nthese models. The nature of asset distribution in such directed networks show\nvaried results, the degree of asset inequality increased with the degree of\ndisorder in the graphs.\n"
    },
    {
        "paper_id": 901.3003,
        "authors": "J. A. Bergstra, C. A. Middelburg",
        "title": "Timed tuplix calculus and the Wesseling and van den Bergh equation",
        "comments": "17 pages; phrasing improved, references updated; substantially\n  improved; remarks added",
        "journal-ref": "Scientific Annals of Computer Science 23(2):169--190, 2013",
        "doi": "10.7561/SACS.2013.2.169",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop an algebraic framework for the description and analysis of\nfinancial behaviours, that is, behaviours that consist of transferring certain\namounts of money at planned times. To a large extent, analysis of financial\nproducts amounts to analysis of such behaviours. We formalize the cumulative\ninterest compliant conservation requirement for financial products proposed by\nWesseling and van den Bergh by an equation in the framework developed and\ndefine a notion of financial product behaviour using this formalization. We\nalso present some properties of financial product behaviours. The development\nof the framework has been influenced by previous work on the process algebra\nACP.\n"
    },
    {
        "paper_id": 901.3318,
        "authors": "Michail Anthropelos, Gordan Zitkovic",
        "title": "Partial Equilibria with Convex Capital Requirements: Existence,\n  Uniqueness and Stability",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an incomplete semimartingale model of a financial market, we consider\nseveral risk-averse financial agents who negotiate the price of a bundle of\ncontingent claims. Assuming that the agents' risk preferences are modelled by\nconvex capital requirements, we define and analyze their demand functions and\npropose a notion of a partial equilibrium price. In addition to sufficient\nconditions for the existence and uniqueness, we also show that the equilibrium\nprices are stable with respect to misspecifications of agents' risk\npreferences.\n"
    },
    {
        "paper_id": 901.3398,
        "authors": "Matthias Arnsdorf and Igor Halperin",
        "title": "BSLP: Markovian Bivariate Spread-Loss Model for Portfolio Credit\n  Derivatives",
        "comments": "42 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  BSLP is a two-dimensional dynamic model of interacting portfolio-level loss\nand spread (more exactly, loss intensity) processes. The model is similar to\nthe top-down HJM-like frameworks developed by Schonbucher (2005) and\nSidenius-Peterbarg-Andersen (SPA) (2005), however is constructed as a\nMarkovian, short-rate intensity model. This property of the model enables fast\nlattice methods for pricing various portfolio credit derivatives such as\ntranche options, forward-starting tranches, leveraged super-senior tranches\netc. A non-parametric model specification is used to achieve nearly perfect\ncalibration to liquid tranche quotes across strikes and maturities. A\nnon-dynamic version of the model obtained in the zero volatility limit of\nstochastic intensity is useful on its own as an arbitrage-free interpolation\nmodel to price non-standard index tranches off the standard ones.\n"
    },
    {
        "paper_id": 901.3404,
        "authors": "Igor Halperin and Pascal Tomecek",
        "title": "Climbing Down from the Top: Single Name Dynamics in Credit Top Down\n  Models",
        "comments": "34 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the top-down approach to multi-name credit modeling, calculation of singe\nname sensitivities appears possible, at least in principle, within the\nso-called random thinning (RT) procedure which dissects the portfolio risk into\nindividual contributions. We make an attempt to construct a practical RT\nframework that enables efficient calculation of single name sensitivities in a\ntop-down framework, and can be extended to valuation and risk management of\nbespoke tranches. Furthermore, we propose a dynamic extension of the RT method\nthat enables modeling of both idiosyncratic and default-contingent individual\nspread dynamics within a Monte Carlo setting in a way that preserves the\nportfolio \"top\"-level dynamics. This results in a model that is not only\ncalibrated to tranche and single name spreads, but can also be tuned to\napproximately match given levels of spread volatilities and correlations of\nnames in the portfolio.\n"
    },
    {
        "paper_id": 901.3812,
        "authors": "Philip Maymin",
        "title": "The Minimal Model of Financial Complexity",
        "comments": "changed from LaTeX to Word; accepted for publication in Quantitative\n  Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A representative investor generates realistic and complex security price\npaths by following this trading strategy: if, a few ticks ago, the market asset\nhad two consecutive upticks or two consecutive downticks, then sell, and\notherwise buy. This simple, unique, and robust model is the smallest possible\ndeterministic model of financial complexity, and its generalization leads to\ncomplex variety. Compared to a random walk, the minimal model generates time\nseries with fatter tails and more frequent crashes, thus more closely matching\nthe real world. It does all this without any parameter fitting.\n"
    },
    {
        "paper_id": 901.4447,
        "authors": "C.P. Kwong",
        "title": "Mathematical analysis of Soros's theory of reflexivity",
        "comments": "22 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The mathematical model proposed by George Soros for his theory of reflexivity\nis analyzed under the framework of discrete dynamical systems. We show the\nimportance of the notion of fixed points for explaining the behavior of a\nreflexive system governed by its cognitive and manipulative functions. The\ninterrelationship between these two functions induces fixed points with\ndifferent characteristics, which in turn generate various system behaviors\nincluding the so-called \"boom then bust\" phenomenon in Soros's theory.\n"
    },
    {
        "paper_id": 901.4604,
        "authors": "Hyoseop Lee and Dongwoo Sheen",
        "title": "Laplace transformation method for the Black-Scholes equation",
        "comments": "17 pages, 2 figures; to appear in International Journal on Numerical\n  Analysis and Modeling (2009)",
        "journal-ref": "International Journal of Numerical Analysis and Modeling 6 (4),\n  2009, 642--658",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we apply the innovative Laplace transformation method\nintroduced by Sheen, Sloan, and Thom\\'ee (IMA J. Numer. Anal., 2003) to solve\nthe Black-Scholes equation. The algorithm is of arbitrary high convergence rate\nand naturally parallelizable. It is shown that the method is very efficient for\ncalculating various options. Existence and uniqueness properties of the Laplace\ntransformed Black-Scholes equation are analyzed. Also a transparent boundary\ncondition associated with the Laplace transformation method is proposed.\nSeveral numerical results for various options under various situations confirm\nthe efficiency, convergence and parallelization property of the proposed\nscheme.\n"
    },
    {
        "paper_id": 901.4793,
        "authors": "Jaroslaw Kwapien, Sylwia Gworek, Stanislaw Drozdz",
        "title": "Structure and evolution of the foreign exchange networks",
        "comments": null,
        "journal-ref": "Acta Phys. Pol. B 40, 175-194 (2009)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate topology and temporal evolution of the foreign currency\nexchange market viewed from a weighted network perspective. Based on exchange\nrates for a set of 46 currencies (including precious metals), we construct\ndifferent representations of the FX network depending on a choice of the base\ncurrency. Our results show that the network structure is not stable in time,\nbut there are main clusters of currencies, which persist for a long period of\ntime despite the fact that their size and content are variable. We find a\nlong-term trend in the network's evolution which affects the USD and EUR nodes.\nIn all the network representations, the USD node gradually loses its\ncentrality, while, on contrary, the EUR node has become slightly more central\nthan it used to be in its early years. Despite this directional trend, the\noverall evolution of the network is noisy.\n"
    },
    {
        "paper_id": 901.4914,
        "authors": "Ilya Molchanov and Michael Schmutz",
        "title": "Exchangeability type properties of asset prices",
        "comments": "The final version of the paper \"Semi-static hedging under\n  exchangeability type conditions\". To appear in Advances in Applied\n  Probability",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we analyse financial implications of exchangeability and\nsimilar properties of finite dimensional random vectors. We show how these\nproperties are reflected in prices of some basket options in view of the\nwell-known put-call symmetry property and the duality principle in option\npricing. A particular attention is devoted to the case of asset prices driven\nby Levy processes. Based on this, concrete semi-static hedging techniques for\nmulti-asset barrier options, such as certain weighted barrier spread options,\nweighted barrier swap options or weighted barrier quanto-swap options are\nsuggested.\n"
    },
    {
        "paper_id": 902.0075,
        "authors": "F. Clementi, M. Gallegati, G. Kaniadakis",
        "title": "A k-generalized statistical mechanics approach to income analysis",
        "comments": "LaTeX2e; 15 pages with 1 figure; corrected typos",
        "journal-ref": "Journal of Statistical Mechanics: Theory and Experiment, 16\n  February 2009, start page: P02037",
        "doi": "10.1088/1742-5468/2009/02/P02037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes a statistical mechanics approach to the analysis of\nincome distribution and inequality. A new distribution function, having its\nroots in the framework of k-generalized statistics, is derived that is\nparticularly suitable to describe the whole spectrum of incomes, from the\nlow-middle income region up to the high-income Pareto power-law regime.\nAnalytical expressions for the shape, moments and some other basic statistical\nproperties are given. Furthermore, several well-known econometric tools for\nmeasuring inequality, which all exist in a closed form, are considered. A\nmethod for parameter estimation is also discussed. The model is shown to fit\nremarkably well the data on personal income for the United States, and the\nanalysis of inequality performed in terms of its parameters reveals very\npowerful.\n"
    },
    {
        "paper_id": 902.01,
        "authors": "Dmitriy Cherkashin, J. Doyne Farmer, Seth Lloyd",
        "title": "The Reality Game",
        "comments": "21 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce an evolutionary game with feedback between perception and\nreality, which we call the reality game. It is a game of chance in which the\nprobabilities for different objective outcomes (e.g., heads or tails in a coin\ntoss) depend on the amount wagered on those outcomes. By varying the `reality\nmap', which relates the amount wagered to the probability of the outcome, it is\npossible to move continuously from a purely objective game in which\nprobabilities have no dependence on wagers to a purely subjective game in which\nprobabilities equal the amount wagered. We study self-reinforcing games, in\nwhich betting more on an outcome increases its odds, and self-defeating games,\nin which the opposite is true. This is investigated in and out of equilibrium,\nwith and without rational players, and both numerically and analytically. We\nintroduce a method of measuring the inefficiency of the game, similar to\nmeasuring the magnitude of the arbitrage opportunities in a financial market.\nWe prove that convergence to equilibrium is is a power law with an extremely\nslow rate of convergence: The more subjective the game, the slower the\nconvergence.\n"
    },
    {
        "paper_id": 902.0188,
        "authors": "Subrata Chakrabarty",
        "title": "A Conceptual Model for Bidirectional Service, Information and Product\n  Quality in an IS Outsourcing Collaboration Environment",
        "comments": null,
        "journal-ref": "Proceedings of the 39th Hawaii International Conference on System\n  Sciences 1 (2006) 1-10",
        "doi": "10.1109/HICSS.2006.7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper advances theory on the process of collaboration between entities\nand its implications on the quality of services, information, and/or products\n(SIPs) that the collaborating entities provide to each other. It investigates\nthe scenario of outsourced IS projects (such as custom software development)\nwhere the extent of collaboration between a client and vendor is high. Using\nthe social exchange theory, the proposed conceptual model tries to establish\nthe \"bidirectional\" nature of SIP quality in a collaborative environment, where\nthe SIPs exchanged are possibly \"dependent\" on each other, and if any entity\nwishes to receive high SIP quality then it should make efforts to provide high\nSIP quality in return too. Furthermore, it advocates increasing efforts to link\nfinancial stakes (tangible or intangible monetary benefits or risks) to the\nquality of SIP being continuously exchanged throughout the project lifecycle.\n"
    },
    {
        "paper_id": 902.0504,
        "authors": "Linyuan L\\\"u, Matus Medo, Yi-Cheng Zhang",
        "title": "The role of a matchmaker in buyer-vendor interactions",
        "comments": "7 pages, 5 figures, minor modifications",
        "journal-ref": "European Physical Journal B 71, 565-571 (2009)",
        "doi": "10.1140/epjb/e2009-00315-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a simple market where a vendor offers multiple variants of a\ncertain product and preferences of both the vendor and potential buyers are\nheterogeneous and possibly even antagonistic. Optimization of the joint benefit\nof the vendor and the buyers turns the toy market into a combinatorial matching\nproblem. We compare the optimal solutions found with and without a matchmaker,\nexamine the resulting inequality between the market participants, and study the\nimpact of correlations on the system.\n"
    },
    {
        "paper_id": 902.0713,
        "authors": "Amparo Baillo",
        "title": "Correction to \"Leverage and volatility feedback effects in\n  high-frequency data\" [J. Financial Econometrics 4 (2006) 353--384]",
        "comments": "3 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Bollerslev et al. (2006) study the cross-covariances for squared returns\nunder the Heston (1993) stochastic volatility model. In order to obtain these\ncross-covariances the authors use an incorrect expression for the distribution\nof the squared returns. Here we will obtain the correct distribution of the\nsquared returns and check that, under this new distribution, the result in\nAppendix A.2 in Bollerslev et al. (2006) still holds.\n"
    },
    {
        "paper_id": 902.0878,
        "authors": "J.B. Glattfelder, S. Battiston",
        "title": "Backbone of complex networks of corporations: The flow of control",
        "comments": "24 pages, 12 figures, 2nd version (text made more concise and\n  readable, results unchanged)",
        "journal-ref": "Phys. Rev. E 80, 036104 (2009)",
        "doi": "10.1103/PhysRevE.80.036104",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a methodology to extract the backbone of complex networks based on\nthe weight and direction of links, as well as on nontopological properties of\nnodes. We show how the methodology can be applied in general to networks in\nwhich mass or energy is flowing along the links. In particular, the procedure\nenables us to address important questions in economics, namely, how control and\nwealth are structured and concentrated across national markets. We report on\nthe first cross-country investigation of ownership networks, focusing on the\nstock markets of 48 countries around the world. On the one hand, our analysis\nconfirms results expected on the basis of the literature on corporate control,\nnamely, that in Anglo-Saxon countries control tends to be dispersed among\nnumerous shareholders. On the other hand, it also reveals that in the same\ncountries, control is found to be highly concentrated at the global level,\nnamely, lying in the hands of very few important shareholders. Interestingly,\nthe exact opposite is observed for European countries. These results have\npreviously not been reported as they are not observable without the kind of\nnetwork analysis developed here.\n"
    },
    {
        "paper_id": 902.1328,
        "authors": "Laurent Carraro, Nicole El Karoui, Jan Ob{\\l}\\'oj",
        "title": "On Az\\'ema-Yor processes, their optimal properties and the\n  Bachelier-drawdown equation",
        "comments": "Published in at http://dx.doi.org/10.1214/10-AOP614 the Annals of\n  Probability (http://www.imstat.org/aop/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Probability 2012, Vol. 40, No. 1, 372-400",
        "doi": "10.1214/10-AOP614",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the class of Az\\'ema-Yor processes defined from a general\nsemimartingale with a continuous running maximum process. We show that they\narise as unique strong solutions of the Bachelier stochastic differential\nequation which we prove is equivalent to the drawdown equation. Solutions of\nthe latter have the drawdown property: they always stay above a given function\nof their past maximum. We then show that any process which satisfies the\ndrawdown property is in fact an Az\\'ema-Yor process. The proofs exploit group\nstructure of the set of Az\\'ema-Yor processes, indexed by functions, which we\nintroduce. We investigate in detail Az\\'ema-Yor martingales defined from a\nnonnegative local martingale converging to zero at infinity. We establish\nrelations between average value at risk, drawdown function, Hardy-Littlewood\ntransform and its inverse. In particular, we construct Az\\'ema-Yor martingales\nwith a given terminal law and this allows us to rediscover the Az\\'ema-Yor\nsolution to the Skorokhod embedding problem. Finally, we characterize\nAz\\'ema-Yor martingales showing they are optimal relative to the concave\nordering of terminal variables among martingales whose maximum dominates\nstochastically a given benchmark.\n"
    },
    {
        "paper_id": 902.1576,
        "authors": "H. Iyetomi, H. Aoyama, Y. Fujiwara, Y. Ikeda, and W. Souma",
        "title": "A Paradigm Shift from Production Function to Production Copula:\n  Statistical Description of Production Activity of Firms",
        "comments": "27pages, including 15 figures and 4 tables. Revised extensively in\n  Ver.3 (Nov. 2010)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Heterogeneity of economic agents is emphasized in a new trend of\nmacroeconomics. Accordingly the new emerging discipline requires one to replace\nthe production function, one of key ideas in the conventional economics, by an\nalternative which can take an explicit account of distribution of firms'\nproduction activities. In this paper we propose a new idea referred to as\nproduction copula; a copula is an analytic means for modeling dependence among\nvariables. Such a production copula predicts value added yielded by firms with\ngiven capital and labor in a probabilistic way. It is thereby in sharp contrast\nto the production function where the output of firms is completely\ndeterministic. We demonstrate empirical construction of a production copula\nusing financial data of listed firms in Japan. Analysis of the data shows that\nthere are significant correlations among their capital, labor and value added\nand confirms that the values added are too widely scattered to be represented\nby a production function. We employ four models for the production copula, that\nis, trivariate versions of Frank, Gumbel and survival Clayton and\nnon-exchangeable trivariate Gumbel; the last one works best.\n"
    },
    {
        "paper_id": 902.1721,
        "authors": "Rasoul Behboudi, You-Lan Zhu",
        "title": "Existence & Regularity of Weak Solutions of Degenerate Parabolic PDE\n  Models for the Pricing of Security Derivatives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work is focused on the solvability of initial-boundary value problems\nfor degenerate parabolic partial differential equations that arise in the\npricing of Asian options, and on the investigation of differential and certain\nqualitative properties of solutions of such equations. The generalized\nsolvability for such models with degeneracy at the boundaries is proven by\nemploying solutions obtained from finite difference numerical schemes.\nFurthermore, the regularity of such solutions is studied.\n"
    },
    {
        "paper_id": 902.2065,
        "authors": "M. Ali Saif and Prashant M. Gade",
        "title": "Emergence of Power Law in a Market with Mixed Models",
        "comments": "18 pages and 9 figures",
        "journal-ref": "Physica A 384 (2007) 448",
        "doi": "10.1016/j.physa.2007.03.058",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the problem of wealth distribution from the viewpoint of asset\nexchange. Robust nature of Pareto's law across economies, ideologies and\nnations suggests that this could be an outcome of trading strategies. However,\nthe simple asset exchange models fail to reproduce this feature. A yardsale(YS)\nmodel in which amount put on the bet is a fraction of minimum of the two\nplayers leads to condensation of wealth in hands of some agent while theft and\nfraud(TF) model in which the amount to be exchanged is a fraction of loser's\nwealth leads to an exponential distribution of wealth. We show that if we allow\nfew agents to follow a different model than others, {\\it i.e.} there are some\nagents following TF model while rest follow YS model, it leads to distribution\nwith power law tails. Similar effect is observed when one carries out\ntransactions for a fraction of one's wealth using TF model and for the rest YS\nmodel is used. We also observe a power law tail in wealth distribution if we\nallow the agents to follow either of the models with some probability.\n"
    },
    {
        "paper_id": 902.207,
        "authors": "M. Ali Saif and Prashant M. Gade",
        "title": "Effects of introduction of new resources and fragmentation of existing\n  resources on limiting wealth distribution in asset exchange models",
        "comments": "15 pages and 6 figures",
        "journal-ref": "Physica A 388 (2009) 697",
        "doi": "10.1016/j.physa.2008.11.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Pareto law, which states that wealth distribution in societies have a\npower-law tail, has been a subject of intensive investigations in statistical\nphysics community. Several models have been employed to explain this behavior.\nHowever, most of the agent based models assume the conservation of number of\nagents and wealth. Both these assumptions are unrealistic. In this paper, we\nstudy the limiting wealth distribution when one or both of these assumptions\nare not valid. Given the universality of the law, we have tried to study the\nwealth distribution from the asset exchange models point of view. We consider\nmodels in which a) new agents enter the market at constant rate b) richer\nagents fragment with higher probability introducing newer agents in the system\nc) both fragmentation and entry of new agents is taking place. While models a)\nand c) do not conserve total wealth or number of agents, model b) conserves\ntotal wealth. All these models lead to a power-law tail in the wealth\ndistribution pointing to the possibility that more generalized asset exchange\nmodels could help us to explain emergence of power-law tail in wealth\ndistribution.\n"
    },
    {
        "paper_id": 902.2429,
        "authors": "Shipra Agrawal, Erick Delage, Mark Peters, Zizhuo Wang, Yinyu Ye",
        "title": "A Unified Framework for Dynamic Pari-Mutuel Information Market Design",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recently, several new pari-mutuel mechanisms have been introduced to organize\nmarkets for contingent claims. Hanson introduced a market maker derived from\nthe logarithmic scoring rule, and later Chen and Pennock developed a cost\nfunction formulation for the market maker. On the other hand, the SCPM model of\nPeters et al. is based on ideas from a call auction setting using a convex\noptimization model. In this work, we develop a unified framework that bridges\nthese seemingly unrelated models for centrally organizing contingent claim\nmarkets. The framework, developed as a generalization of the SCPM, will support\nmany desirable properties such as proper scoring, truthful bidding (in a myopic\nsense), efficient computation, and guarantees on worst case loss. In fact, our\nunified framework will allow us to express various proper scoring rules,\nexisting or new, from classical utility functions in a convex optimization\nproblem representing the market organizer. Additionally, we utilize concepts\nfrom duality to show that the market model is equivalent to a risk minimization\nproblem where a convex risk measure is employed. This will allow us to more\nclearly understand the differences in the risk attitudes adopted by various\nmechanisms, and particularly deepen our intuition about popular mechanisms like\nHanson's market-maker. In aggregate, we believe this work advances our\nunderstanding of the objectives that the market organizer is optimizing in\npopular pari-mutuel mechanisms by recasting them into one unified framework.\n"
    },
    {
        "paper_id": 902.2479,
        "authors": "Erhan Bayraktar, Hao Xing",
        "title": "Regularity of the Optimal Stopping Problem for Jump Diffusions",
        "comments": "To Appear in the SIAM Journal on Control and Optimization",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The value function of an optimal stopping problem for jump diffusions is\nknown to be a generalized solution of a variational inequality. Assuming that\nthe diffusion component of the process is nondegenerate and a mild assumption\non the singularity of the L\\'{e}vy measure, this paper shows that the value\nfunction of this optimal stopping problem on an unbounded domain with\nfinite/infinite variation jumps is in $W^{2,1}_{p, loc}$ with $p\\in(1,\n\\infty)$. As a consequence, the smooth-fit property holds.\n"
    },
    {
        "paper_id": 902.2516,
        "authors": "Erhan Bayraktar and Mike Ludkovski",
        "title": "Optimal Trade Execution in Illiquid Markets",
        "comments": null,
        "journal-ref": "Mathematical Finance 21(4), pp. 681-701, 2011",
        "doi": "10.1111/j.1467-9965.2010.00446",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study optimal trade execution strategies in financial markets with\ndiscrete order flow. The agent has a finite liquidation horizon and must\nminimize price impact given a random number of incoming trade counterparties.\nAssuming that the order flow $N$ is given by a Poisson process, we give a full\nanalysis of the properties and computation of the optimal dynamic execution\nstrategy. Extensions, whereby (a) $N$ is a fully-observed regime-switching\nPoisson process; and (b) $N$ is a Markov-modulated compound Poisson process\ndriven by a hidden Markov chain, are also considered.\n  We derive and compare the properties of the three cases and illustrate our\nresults with computational examples.\n"
    },
    {
        "paper_id": 902.2735,
        "authors": "Jaume Masoliver, Josep Perello",
        "title": "First-passage and risk evaluation under stochastic volatility",
        "comments": "36 pages, 11 figures",
        "journal-ref": "Phys. Rev. E 80, 016108 (2009) [15 pages]",
        "doi": "10.1103/PhysRevE.80.016108",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We solve the first-passage problem for the Heston random diffusion model. We\nobtain exact analytical expressions for the survival and hitting probabilities\nto a given level of return. We study several asymptotic behaviors and obtain\napproximate forms of these probabilities which prove, among other interesting\nproperties, the non-existence of a mean first-passage time. One significant\nresult is the evidence of extreme deviations --which implies a high risk of\ndefault-- when certain dimensionless parameter, related to the strength of the\nvolatility fluctuations, increases. We believe that this may provide an\neffective tool for risk control which can be readily applicable to real\nmarkets.\n"
    },
    {
        "paper_id": 902.2756,
        "authors": "Erick Trevino Aguilar",
        "title": "Monitoring dates of maximal risk",
        "comments": "Working Paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Monitoring means to observe a system for any changes which may occur over\ntime, using a monitor or measuring device of some sort. In this paper we\nformulate a problem of monitoring dates of maximal risk of a financial\nposition. Thus, the systems we are going to observe arise from situations in\nfinance. The measuring device we are going to use is a time-consistent measure\nof risk.\n  In the first part of the paper we discuss the numerical representation of\nconditional convex risk measures which are defined in a space Lp(F,R) and take\nvalues in L1(G,R). This will allow us to consider time-consistent convex risk\nmeasures in L1(R).\n  In the second part of the paper we use a time-consistent convex risk measure\nin order to define an abstract problem of monitoring stopping times of maximal\nrisk. The penalty function involved in the robust representation changes\nqualitatively the time when maximal risk is for the first time identified. A\nphenomenon which we discuss from the point of view of robust statistics.\n"
    },
    {
        "paper_id": 902.2965,
        "authors": "Ole Peters",
        "title": "Optimal leverage from non-ergodicity",
        "comments": "17 pages, 3 figures. Updated figures and extended discussion of\n  ergodicity",
        "journal-ref": "Quant. Fin., Vol. 11, Issue 11, 1593--1602, 2011 (open access)",
        "doi": "10.1080/14697688.2010.513338",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In modern portfolio theory, the balancing of expected returns on investments\nagainst uncertainties in those returns is aided by the use of utility\nfunctions. The Kelly criterion offers another approach, rooted in information\ntheory, that always implies logarithmic utility. The two approaches seem\nincompatible, too loosely or too tightly constraining investors' risk\npreferences, from their respective perspectives. The conflict can be understood\non the basis that the multiplicative models used in both approaches are\nnon-ergodic which leads to ensemble-average returns differing from time-average\nreturns in single realizations. The classic treatments, from the very beginning\nof probability theory, use ensemble-averages, whereas the Kelly-result is\nobtained by considering time-averages. Maximizing the time-average growth rates\nfor an investment defines an optimal leverage, whereas growth rates derived\nfrom ensemble-average returns depend linearly on leverage. The latter measure\ncan thus incentivize investors to maximize leverage, which is detrimental to\ntime-average growth and overall market stability. The Sharpe ratio is\ninsensitive to leverage. Its relation to optimal leverage is discussed. A\nbetter understanding of the significance of time-irreversibility and\nnon-ergodicity and the resulting bounds on leverage may help policy makers in\nreshaping financial risk controls.\n"
    },
    {
        "paper_id": 902.3456,
        "authors": "Wolfgang Kluge and Antonis Papapantoleon",
        "title": "On the valuation of compositions in L\\'evy term structure models",
        "comments": "17 pages, 2 figures, to appear in Quant. Finance",
        "journal-ref": "Quantitative Finance 2009, Vol. 9, No. 8, 951-959",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive explicit valuation formulae for an exotic path-dependent interest\nrate derivative, namely an option on the composition of LIBOR rates. The\nformulae are based on Fourier transform methods for option pricing. We consider\ntwo models for the evolution of interest rates: an HJM-type forward rate model\nand a LIBOR-type forward price model. Both models are driven by a\ntime-inhomogeneous L\\'evy process.\n"
    },
    {
        "paper_id": 902.3643,
        "authors": "T. R. Hurd and Zhuowei Zhou",
        "title": "A Fourier transform method for spread option pricing",
        "comments": "16 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Spread options are a fundamental class of derivative contract written on\nmultiple assets, and are widely used in a range of financial markets. There is\na long history of approximation methods for computing such products, but as yet\nthere is no preferred approach that is accurate, efficient and flexible enough\nto apply in general models. The present paper introduces a new formula for\ngeneral spread option pricing based on Fourier analysis of the spread option\npayoff function. Our detailed investigation proves the effectiveness of a fast\nFourier transform implementation of this formula for the computation of prices.\nIt is found to be easy to implement, stable, efficient and applicable in a wide\nvariety of asset pricing models.\n"
    },
    {
        "paper_id": 902.3836,
        "authors": "Cheoljun Eom, Jongwon Park, Woo-Sung Jung, Taisei Kaizoji, Yong H. Kim",
        "title": "The Effects of Market Properties on Portfolio Diversification in the\n  Korean and Japanese Stock Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this study, we have investigated empirically the effects of market\nproperties on the degree of diversification of investment weights among stocks\nin a portfolio. The weights of stocks within a portfolio were determined on the\nbasis of Markowitz's portfolio theory. We identified that there was a negative\nrelationship between the influence of market properties and the degree of\ndiversification of the weights among stocks in a portfolio. Furthermore, we\nnoted that the random matrix theory method could control the properties of\ncorrelation matrix between stocks; this may be useful in improving portfolio\nmanagement for practical application.\n"
    },
    {
        "paper_id": 902.384,
        "authors": "Samuel E. Vazquez",
        "title": "Scale Invariance, Bounded Rationality and Non-Equilibrium Economics",
        "comments": "40 pages, 17 figs",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a class of heterogeneous agent-based models which are based on a\nbasic set of principles, and the most fundamental operations of an economic\nsystem: trade and product transformations.\n  A basic guiding principle is scale invariance, which means that the dynamics\nof the economy should not depend on the units used to measure the different\nproducts. We develop the idea of a \"near-equilibrium\" expansion which allow us\nto study the dynamics of fluctuations around economic equilibrium. This is\nsimilar to the familiar \"perturbation theory\" studied in many areas of physics.\nWe study some simple models of both centralized and decentralized markets. We\nshow the relaxation to equilibrium when appropriate. More interestingly, we\nstudy a simple model of a decentralized market that shows a spontaneous\ntransition into a monetary phase. We use mean field theory analysis to provide\na statistical interpretation of the monetary phase. Furthermore, we show that\nsuch phase can be dynamically unstable. Finally, we study some simple\ncentralized financial markets, one of which shows a speculative bubble and a\ncrash.\n"
    },
    {
        "paper_id": 902.4159,
        "authors": "M. Cristelli, V. Alfi, L. Pietronero, A. Zaccaria",
        "title": "Liquidity Crisis, Granularity of the Order Book and Price Fluctuations",
        "comments": "18 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2009-00353-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a microscopic model for the dynamics of the order book to study\nhow the lack of liquidity influences price fluctuations. We use the average\ndensity of the stored orders (granularity $g$) as a proxy for liquidity. This\nleads to a Price Impact Surface which depends on both volume $\\omega$ and $g$.\nThe dependence on the volume (averaged over the granularity) of the Price\nImpact Surface is found to be a concave power law function\n$<\\phi(\\omega,g)>_g\\sim\\omega^\\delta$ with $\\delta\\approx 0.59$. Instead the\ndependence on the granularity is $\\phi(\\omega,g|\\omega)\\sim g^\\alpha$ with\n$\\alpha\\approx-1$, showing a divergence of price fluctuations in the limit\n$g\\to 0$. Moreover, even in intermediate situations of finite liquidity, this\neffect can be very large and it is a natural candidate for understanding the\norigin of large price fluctuations.\n"
    },
    {
        "paper_id": 902.4245,
        "authors": "Erick Trevino Aguilar",
        "title": "T-Systems and the lower Snell envelope",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The dynamical analysis of American options has motivated the development of\nrobust versions of the classical Snell envelopes. The cost of superhedging an\nAmerican option is characterized by the upper Snell envelope. The infimum of\nthe arbitrage free prices is characterized by the lower Snell envelope. In this\npaper we focus on the lower Snell envelope. We construct a regular version of\nthis stochastic process. To this end, we apply results due to Dellacherie and\nLenglart on regularization of stochastic processes and T -Systems.\n"
    },
    {
        "paper_id": 902.4274,
        "authors": "Lee Smolin",
        "title": "Time and symmetry in models of economic markets",
        "comments": "41 pages, one figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  These notes discuss several topics in neoclassical economics and\nalternatives, with an aim of reviewing fundamental issues in modeling economic\nmarkets. I start with a brief, non-rigorous summary of the basic Arrow-Debreu\nmodel of general equilibrium, as well as its extensions to include time and\ncontingency. I then argue that symmetries due to similarly endowed individuals\nand similar products are generically broken by the constraints of scarcity,\nleading to the existence of multiple equilibria.\n  This is followed by an evaluation of the strengths and weaknesses of the\nmodel generally. Several of the weaknesses are concerned with the treatments of\ntime and contingency. To address these we discuss a class of agent based\nmodels.\n  Another set of issues has to do with the fundamental meaning of prices and\nthe related question of what the observables of a non-equilibrium, dynamic\nmodel of an economic market should be. We argue that these issues are addressed\nby formulating economics in the language of a gauge theory, as proposed\noriginally by Malaney and Weinstein. We review some of their work and provide a\nsketch of how gauge invariance can be incorporated into the formulation of\nagent based models.\n"
    },
    {
        "paper_id": 902.4684,
        "authors": "L.M. Dieng",
        "title": "Quantized Interest Rate at the Money for American Options",
        "comments": "10 pages, 1 figure. Presented at the American Physical Society\n  meeting",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we expand the idea of Samuelson[3] and Shepp[2,5,6] for stock\noptimization using the Bachelier model [4] as our models for the stock price at\nthe money (X[stock price]= K[strike price]) for the American call and put\noptions [1]. At the money (X= K) for American options, the expected payoff of\nboth the call and put options is zero. Shepp investigated several stochastic\noptimization problems using martingale and stopping time theories [2,5,6]. One\nof the problems he investigated was how to optimize the stock price using both\nthe Black-Scholes (multiplicative) and the Bachelier (additive) models [7,6]\nfor the American option above the strike price K (exercise price) to a stopping\npoint. In order to explore the non-relativistic quantum effect on the expected\npayoff for both the call and put options at the money, we assumed the stock\nprice to undergo a stochastic process governed by the Bachelier (additive)\nmodel [4]. Further, using Ito calculus and martingale theory, we obtained a\ndifferential equation for the expected payoff for both the call and put options\nin terms of delta and gamma. We also obtained the solution to the\nnon-relativistic Schroedinger equation as the expected payoff for both the call\nand put options. Then, we expressed the stochastic process that is the expected\npayoff for both the call and put options at the money in terms of the solution\nto the Schroedinger equation. We concluded the stochastic process that is the\nexpected payoff at the money for both options to be an oscillatory function\nwith quantized interest rates.\n"
    },
    {
        "paper_id": 903.001,
        "authors": "Alexander M. Petersen, Fengzhong Wang, Shlomo Havlin, H. Eugene\n  Stanley",
        "title": "Quantitative law describing market dynamics before and after\n  interest-rate change",
        "comments": "16 pages (2-column), 9 Figures, 1 Table; Changes in final version\n  made in response to referee comments",
        "journal-ref": "Phys. Rev. E 81, 066121 (2010)",
        "doi": "10.1103/PhysRevE.81.066121",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the behavior of U.S. markets both before and after U.S. Federal Open\nMarket Committee (FOMC) meetings, and show that the announcement of a U.S.\nFederal Reserve rate change causes a financial shock, where the dynamics after\nthe announcement is described by an analogue of the Omori earthquake law. We\nquantify the rate n(t) of aftershocks following an interest rate change at time\nT, and find power-law decay which scales as n(t-T) (t-T)^-$\\Omega$, with\n$\\Omega$ positive. Surprisingly, we find that the same law describes the rate\nn'(|t-T|) of \"pre-shocks\" before the interest rate change at time T. This is\nthe first study to quantitatively relate the size of the market response to the\nnews which caused the shock and to uncover the presence of quantifiable\npreshocks. We demonstrate that the news associated with interest rate change is\nresponsible for causing both the anticipation before the announcement and the\nsurprise after the announcement. We estimate the magnitude of financial news\nusing the relative difference between the U. S. Treasury Bill and the Federal\nFunds Effective rate. Our results are consistent with the \"sign effect,\" in\nwhich \"bad news\" has a larger impact than \"good news.\" Furthermore, we observe\nsignificant volatility aftershocks, confirming a \"market underreaction\" that\nlasts at least 1 trading day.\n"
    },
    {
        "paper_id": 903.0203,
        "authors": "Ivan O. Kitov",
        "title": "Mechanical Model of Personal Income Distribution",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A microeconomic model is developed, which accurately predicts the shape of\npersonal income distribution (PID) in the United States and the evolution of\nthe shape over time. The underlying concept is borrowed from geo-mechanics and\nthus can be considered as mechanics of income distribution. The model allows\nthe resolution of empirical and definitional problems associated with personal\nincome measurements. It also serves as a firm fundament for definitions of\nincome inequality as secondary derivatives from personal income distribution.\nIt is found that in relative terms the PID in the US has not been changing\nsince 1947. Effectively, the Gini coefficient has been almost constant during\nthe last 60 years, as reported by the Census Bureau.\n"
    },
    {
        "paper_id": 903.0282,
        "authors": "Arnab K. Ray",
        "title": "A dynamic nonlinear model for saturation in industrial growth",
        "comments": "ReVTeX, 5 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A general nonlinear logistic equation has been proposed to model long-time\nsaturation in industrial growth. An integral solution of this equation has been\nderived for any arbitrary degree of nonlinearity. A time scale for the onset of\nnonlinear saturation in industrial growth can be estimated from an\nequipartition condition between nonlinearity and purely exponential growth.\nPrecise predictions can be made about the limiting values of the annual revenue\nand the human resource content that an industrial organisation may attain.\nThese variables have also been modelled to set up an autonomous first-order\ndynamical system, whose equilibrium condition forms a stable node (an attractor\nstate) in a related phase portrait. The theoretical model has received close\nsupport from all relevant data pertaining to the well-known global company,\nIBM.\n"
    },
    {
        "paper_id": 903.0286,
        "authors": "Ivan O. Kitov",
        "title": "What is the best firm size to invest?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Significant differences in the evolution of firm size distribution for\nvarious industries in the United States have been revealed and documented. For\ntheoretical considerations, this finding puts major constraints on the\nmodelling of firm growth. For practical purposes, the observed differences\ncreate a solid basis for selective investment strategies.\n"
    },
    {
        "paper_id": 903.068,
        "authors": "Vladimir G. Ivancevic",
        "title": "Quantum Neural Computation for Option Price Modelling",
        "comments": "15 pages, 6 figures, Latex",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new cognitive framework for option price modelling, using\nquantum neural computation formalism. Briefly, when we apply a classical\nnonlinear neural-network learning to a linear quantum Schr\\\"odinger equation,\nas a result we get a nonlinear Schr\\\"odinger equation (NLS), performing as a\nquantum stochastic filter. In this paper, we present a bidirectional quantum\nassociative memory model for the Black--Scholes--like option price evolution,\nconsisting of a pair of coupled NLS equations, one governing the stochastic\nvolatility and the other governing the option price, both self-organizing in an\nadaptive `market heat potential', trained by continuous Hebbian learning. This\nstiff pair of NLS equations is numerically solved using the method of lines\nwith adaptive step-size integrator.\n  Keywords: Option price modelling, Quantum neural computation, nonlinear\nSchr\\\"odinger equations, leverage effect, bidirectional associative memory\n"
    },
    {
        "paper_id": 903.0993,
        "authors": "Fengzhong Wang, Shwu-Jane Shieh, Shlomo Havlin, H. Eugene Stanley",
        "title": "Statistical analysis of the overnight and daytime return",
        "comments": "22 pages, 8 figures, 2 tables",
        "journal-ref": "Phys. Rev. E 79, 056109 (2009)",
        "doi": "10.1103/PhysRevE.79.056109",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the two components of the total daily return (close-to-close),\nthe overnight return (close-to-open) and the daytime return (open-to-close), as\nwell as the corresponding volatilities of the 2215 NYSE stocks from 1988 to\n2007. The tail distribution of the volatility, the long-term memory in the\nsequence, and the cross-correlation between different returns are analyzed. Our\nresults suggest that: (i) The two component returns and volatilities have\nsimilar features as that of the total return and volatility. The tail\ndistribution follows a power law for all volatilities, and long-term\ncorrelations exist in the volatility sequences but not in the return sequences.\n(ii) The daytime return contributes more to the total return. Both the tail\ndistribution and the long-term memory of the daytime volatility are more\nsimilar to that of the total volatility, compared to the overnight records. In\naddition, the cross-correlation between the daytime return and the total return\nis also stronger. (iii) The two component returns tend to be anti-correlated.\nMoreover, we find that the cross-correlations between the three different\nreturns (total, overnight, and daytime) are quite stable over the entire\n20-year period.\n"
    },
    {
        "paper_id": 903.1525,
        "authors": "Gilles Zumbach",
        "title": "The empirical properties of large covariance matrices",
        "comments": "21 pages,9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The salient properties of large empirical covariance and correlation matrices\nare studied for three datasets of size 54, 55 and 330. The covariance is\ndefined as a simple cross product of the returns, with weights that decay\nlogarithmically slowly. The key general properties of the covariance matrices\nare the following. The spectrum of the covariance is very static, except for\nthe top three to ten eigenvalues, and decay exponentially fast toward zero. The\nmean spectrum and spectral density show no particular feature that would\nseparate \"meaningful\" from \"noisy\" eigenvalues. The spectrum of the correlation\nis more static, with three to five eigenvalues that have distinct dynamics. The\nmean projector of rank k on the leading subspace shows instead that most of the\ndynamics occur in the eigenvectors, including deep in the spectrum. Together,\nthis implies that the reduction of the covariance to a few leading eigenmodes\nmisses most of the dynamics, and that a covariance estimator correctly\nevaluates both volatilities and correlations.\n"
    },
    {
        "paper_id": 903.1531,
        "authors": "Gilles Zumbach",
        "title": "Inference on multivariate ARCH processes with large sizes",
        "comments": "22 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The covariance matrix is formulated in the framework of a linear multivariate\nARCH process with long memory, where the natural cross product structure of the\ncovariance is generalized by adding two linear terms with their respective\nparameter. The residuals of the linear ARCH process are computed using\nhistorical data and the (inverse square root of the) covariance matrix. Simple\nmeasure of qualities assessing the independence and unit magnitude of the\nresidual distributions are proposed. The salient properties of the computed\nresiduals are studied for three data sets of size 54, 55 and 330. Both new\nterms introduced in the covariance help in producing uncorrelated residuals,\nbut the residual magnitudes are very different from unity. The large sizes of\nthe inferred residuals are due to the limited information that can be extracted\nfrom the empirical data when the number of time series is large, and denotes a\nfundamental limitation to the inference that can be achieved.\n"
    },
    {
        "paper_id": 903.1592,
        "authors": "William T. Shaw, Jonathan McCabe",
        "title": "Monte Carlo sampling given a Characteristic Function: Quantile Mechanics\n  in Momentum Space",
        "comments": "Version 1",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In mathematical finance and other applications of stochastic processes, it is\nfrequently the case that the characteristic function may be known but explicit\nforms for density functions are not available. The simulation of any\ndistribution is greatly facilitated by a knowledge of the quantile function, by\nwhich uniformly distributed samples may be converted to samples of the given\ndistribution. This article analyzes the calculation of a quantile function\ndirect from the characteristic function of a probability distribution, without\nexplicit knowledge of the density. We form a non-linear integro-differential\nequation that despite its complexity admits an iterative solution for the power\nseries of the quantile about the median. We give some examples including tail\nmodels and show how to generate C-code for examples.\n"
    },
    {
        "paper_id": 903.1629,
        "authors": "Mauro Politi, Enrico Scalas, Daniel Fulger, and Guido Germano",
        "title": "Spectral densities of Wishart-Levy free stable random matrices:\n  Analytical results and Monte Carlo validation",
        "comments": "10 pages, 1 figure, submitted to Eur. Phys. J. B",
        "journal-ref": "European Physical Journal B 79 (1), 13-22, 2010",
        "doi": "10.1140/epjb/e2009-00360-7",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Random matrix theory is used to assess the significance of weak correlations\nand is well established for Gaussian statistics. However, many complex systems,\nwith stock markets as a prominent example, exhibit statistics with power-law\ntails, that can be modelled with Levy stable distributions. We review\ncomprehensively the derivation of an analytical expression for the spectra of\ncovariance matrices approximated by free Levy stable random variables and\nvalidate it by Monte Carlo simulation.\n"
    },
    {
        "paper_id": 903.1643,
        "authors": "K. Rajaratnam",
        "title": "A Simplified Approach to modeling the credit-risk of CMO",
        "comments": "This article is withdrawn",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The credit crisis of 2007 and 2008 has thrown much focus on the models used\nto price mortgage backed securities. Many institutions have relied heavily on\nthe credit ratings provided by credit agency. The relationships between\nmanagement of credit agencies and debt issuers may have resulted in conflict of\ninterest when pricing these securities which has lead to incorrect risk\nassumptions and value expectations from institutional buyers. Despite the\nexistence of sophisticated models, institutional buyers have relied on these\nratings when considering the risks involved with these products. Institutional\ninvestors interested in non-agency MBS are particularly vulnerable due to both\nthe credit risks as well as prepayment risks. This paper describes a simple\nsimulation model that model non-agency MBS and CMO. The simulation model builds\non existing models for agency MBS. It incorporates credit risks of mortgage\nbuyers using existing models used in capital requirements as specified by the\nBasel II Accord.\n"
    },
    {
        "paper_id": 903.2099,
        "authors": "Yik Wen Goo, Tong Wei Lian, Wei Guang Ong, Wen Ting Choi, and Siew-Ann\n  Cheong",
        "title": "Financial Atoms and Molecules",
        "comments": "19 pages in RevTeX4 format, 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Atoms and molecules are important conceptual entities we invented to\nunderstand the physical world around us. The key to their usefulness lies in\nthe organization of nuclear and electronic degrees of freedom into a single\ndynamical variable whose time evolution we can better imagine. The use of such\neffective variables in place of the true microscopic variables is possible\nbecause of the separation between nuclear/electronic and atomic/molecular time\nscales. Where separation of time scales occurs, identification of analogous\nobjects in financial markets can help advance our understanding of their\ndynamics. To detect separated time scales and identify their associated\neffective degrees of freedom in financial markets, we devised a two-stage\nstatistical clustering scheme to analyze the price movements of stocks in\nseveral equity markets. Through this two-time-scale clustering analysis, we\ndiscovered a hierarchy of levels of self-organization in real financial\nmarkets. We call these statistically robust self-organized dynamical structures\nfinancial atoms, financial molecules, and financial supermolecules. In general,\nthe detailed compositions of these dynamical structures cannot be deduced based\non raw financial intuition alone, and must be explained in terms of the\nunderlying portfolios, and investment strategies of market players. More\ninterestingly, we find that major market events such as the Chinese Correction\nand the Subprime Crisis leave many tell-tale signs within the correlational\nstructures of financial molecules.\n"
    },
    {
        "paper_id": 903.2243,
        "authors": "Edward D. Weinberger",
        "title": "Pragmatic Information Rates, Generalizations of the Kelly Criterion, and\n  Financial Market Efficiency",
        "comments": "Revised to clarify the text",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is part of an ongoing investigation of \"pragmatic information\",\ndefined in Weinberger (2002) as \"the amount of information actually used in\nmaking a decision\". Because a study of information rates led to the Noiseless\nand Noisy Coding Theorems, two of the most important results of Shannon's\ntheory, we begin the paper by defining a pragmatic information rate, showing\nthat all of the relevant limits make sense, and interpreting them as the\nimprovement in compression obtained from using the correct distribution of\ntransmitted symbols.\n  The first of two applications of the theory extends the information theoretic\nanalysis of the Kelly Criterion, and its generalization, the horse race, to a\nseries of races where the stochastic process of winning horses, payoffs, and\nstrategies depend on some stationary process, including, but not limited to the\nhistory of previous races. If the bettor is receiving messages (side\ninformation) about the probability distribution of winners, the doubling rate\nof the bettor's winnings is bounded by the pragmatic information of the\nmessages.\n  A second application is to the question of market efficiency. An efficient\nmarket is, by definition, a market in which the pragmatic information of the\n\"tradable past\" with respect to current prices is zero. Under this definition,\nmarkets whose returns are characterized by a GARCH(1,1) process cannot be\nefficient.\n  Finally, a pragmatic informational analogue to Shannon's Noisy Coding Theorem\nsuggests that a cause of market inefficiency is that the underlying\nfundamentals are changing so fast that the price discovery mechanism simply\ncannot keep up. This may happen most readily in the run-up to a financial\nbubble, where investors' willful ignorance degrade the information processing\ncapabilities of the market.\n"
    },
    {
        "paper_id": 903.2428,
        "authors": "J.P. Bouchaud (Capital Fund Management)",
        "title": "Price Impact",
        "comments": "Entry for the upcoming \"Encyclopedia of Quantitative Finance\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We define what \"Price Impact\" means, and how it is measured and modelled in\nthe recent literature. Although this notion seems to convey the idea of a\nforceful and intuitive mechanism, we discuss why things might not be that\nsimple. Empirical studies show that while the correlation between signed order\nflow and price changes is strong, the impact of trades on prices is neither\nlinear in volume nor permanent. Impact allows private information to be\nreflected in prices, but by the same token, random fluctuations in order flow\nmust also contribute to the volatility of markets.\n"
    },
    {
        "paper_id": 903.291,
        "authors": "Yingdong Lv, Bernhard K. Meister",
        "title": "Application of the Kelly Criterion to Ornstein-Uhlenbeck Processes",
        "comments": "presented at Complex'2009 (Shanghai, Feb. 23-25)",
        "journal-ref": null,
        "doi": "10.1007/978-3-642-02466-5_105",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the Kelly criterion in the continuous time framework\nbuilding on the work of E.O. Thorp and others. The existence of an optimal\nstrategy is proven in a general setting and the corresponding optimal wealth\nprocess is found. A simple formula is provided for calculating the optimal\nportfolio for a set of price processes satisfying some simple conditions.\nProperties of the optimal investment strategy for assets governed by multiple\nOrnstein-Uhlenbeck processes are studied. The paper ends with a short\ndiscussion of the implications of these ideas for financial markets.\n"
    },
    {
        "paper_id": 903.3254,
        "authors": "David B. Saakian",
        "title": "Mapping markets to the statistical mechanics: the derivatives act\n  against the self-regulation of stock market",
        "comments": "3 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Mapping the economy to the some statistical physics models we get strong\nindications that, in contrary to the pure stock market, the stock market with\nderivatives could not self-regulate.\n"
    },
    {
        "paper_id": 903.3346,
        "authors": "S. Zverovich",
        "title": "The Transfer Pricing Problem with Non-Linearities",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A number of approaches to solving the well-known transfer pricing problem are\nknown. However, few models satisfactorily resolve the core problem of allowing\nboth the source and receiving divisions to earn a profit on transfers during a\nperiod in such a way that sub-optimal output levels are avoided. In 1969,\nSamuel proposed to use a transfer price schedule instead of just a single\ntransfer price. An essential improvement of Samuels' model was given by Tomkins\n(1990) in his pragmatic-analytical transfer pricing approach, which is a\ncombination of a single cost-plus transfer price and the pragmatic process of\nnegotiation. This fundamental approach was developed under the assumption that\nthe net average revenue curve for the final product is linear.\n  In this paper, Tomkins' pragmatic-analytical model is further developed for\nnon-linear net average revenue curves. In particular, typical quadratic\nfunctions are considered and corresponding transfer price schedules are\ndetermined. A similar technique can be used for the transfer pricing problem\nwith any net average revenue curve.\n"
    },
    {
        "paper_id": 903.3657,
        "authors": "Lampros Boukas, Diogo Pinheiro, Alberto Pinto, Stylianos Xanthopoulos,\n  Athanasios Yannacopoulos",
        "title": "Behavioural and Dynamical Scenarios for Contingent Claims Valuation in\n  Incomplete Markets",
        "comments": "18 pages. To appear in Journal of Difference Equations and\n  Applications",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the problem of determination of asset prices in an incomplete market\nproposing three different but related scenarios. One scenario uses a market\ngame approach whereas the other two are based on risk sharing or regret\nminimizing considerations. Dynamical schemes modeling the convergence of the\nbuyer's and of the seller's prices to a unique price are proposed.\n"
    },
    {
        "paper_id": 903.3736,
        "authors": "Constantinos Kardaras",
        "title": "Num\\'{e}raire-invariant preferences in financial modeling",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP669 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 5, 1697-1728",
        "doi": "10.1214/09-AAP669",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide an axiomatic foundation for the representation of\nnum\\'{e}raire-invariant preferences of economic agents acting in a financial\nmarket. In a static environment, the simple axioms turn out to be equivalent to\nthe following choice rule: the agent prefers one outcome over another if and\nonly if the expected (under the agent's subjective probability) relative rate\nof return of the latter outcome with respect to the former is nonpositive. With\nthe addition of a transitivity requirement, this last preference relation has\nan extension that can be numerically represented by expected logarithmic\nutility. We also treat the case of a dynamic environment where consumption\nstreams are the objects of choice. There, a novel result concerning a canonical\nrepresentation of unit-mass optional measures enables us to explicitly solve\nthe investment--consumption problem by separating the two aspects of investment\nand consumption. Finally, we give an application to the problem of optimal\nnum\\'{e}raire investment with a random time-horizon.\n"
    },
    {
        "paper_id": 903.4216,
        "authors": "H. Quevedo and M.N. Quevedo",
        "title": "Statistical thermodynamics of economic systems",
        "comments": "Discussions added, typos corrected",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We formulate thermodynamics of economic systems in terms of an arbitrary\nprobability distribution for a conserved economic quantity. As in statistical\nphysics, thermodynamic macroeconomic variables emerge as the mean value of\nmicroeconomic variables and their determination is reduced to the computation\nof the partition function, starting from an arbitrary function. Explicit\nhypothetical examples are given which include linear and nonlinear economic\nsystems, as well as multiplicative systems such as those dominated by a Pareto\nlaw distribution. We propose to use the formalism of phase transitions to study\nsevere changes of macroeconomic variables.\n"
    },
    {
        "paper_id": 903.4475,
        "authors": "Richard B. Sowers",
        "title": "Exact Pricing Asymptotics of Investment-Grade Tranches of Synthetic\n  CDO's Part I: A Large Homogeneous Pool",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use the theory of large deviations to study the pricing of\ninvestment-grade tranches of synthetic CDO's. In this paper, we consider a\nsimplified model which will allow us to introduce some of the concepts and\ncalculations.\n"
    },
    {
        "paper_id": 903.4478,
        "authors": "Richard B. Sowers",
        "title": "Exact Pricing Asymptotics for Investment-Grade Tranches of Synthetic\n  CDO's. Part II: A Large Heterogeneous Pool",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use the theory of large deviations to study the pricing of\ninvestment-grade tranches of synthetic CDO's. In this paper, we consider a\nheterogeneous pool of names. Our main tool is a large-deviations analysis which\nallows us to precisely study the behavior of a large amount of idiosyncratic\nrandomness. Our calculations allow a fairly general treatment of correlation.\n"
    },
    {
        "paper_id": 903.4542,
        "authors": "C. Neri (Lloyds Banking Group, London, UK) and L. Schneider (EMLYON\n  Business School, Lyon, France)",
        "title": "Maximum Entropy Distributions Inferred from Option Portfolios on an\n  Asset",
        "comments": "23 pages, 5 figures, to appear in Finance and Stochastics",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We obtain the maximum entropy distribution for an asset from call and digital\noption prices. A rigorous mathematical proof of its existence and exponential\nform is given, which can also be applied to legitimise a formal derivation by\nBuchen and Kelly. We give a simple and robust algorithm for our method and\ncompare our results to theirs. We present numerical results which show that our\napproach implies very realistic volatility surfaces even when calibrating only\nto at-the-money options. Finally, we apply our approach to options on the S&P\n500 index.\n"
    },
    {
        "paper_id": 903.4783,
        "authors": "V. P. Maslov",
        "title": "Threshold levels in Economics",
        "comments": "28p., 2figs., Latex, explanations added, minor misprints corrected",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present theorems specifying the critical values for series\nassociated with debts arranged in the order of their duration.\n"
    },
    {
        "paper_id": 903.4833,
        "authors": "Erik Ekstr\\\"om, David Hobson",
        "title": "Recovering a time-homogeneous stock price process from perpetual option\n  prices",
        "comments": "Published in at http://dx.doi.org/10.1214/10-AAP720 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2011, Vol. 21, No. 3, 1102-1135",
        "doi": "10.1214/10-AAP720",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is well known how to determine the price of perpetual American options if\nthe underlying stock price is a time-homogeneous diffusion. In the present\npaper we consider the inverse problem, that is, given prices of perpetual\nAmerican options for different strikes, we show how to construct a\ntime-homogeneous stock price model which reproduces the given option prices.\n"
    },
    {
        "paper_id": 903.5064,
        "authors": "Ivan Kitov, Oleg Kitov",
        "title": "Unemployment and inflation in Western Europe: solution by the boundary\n  element method",
        "comments": "27 pages, 22 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using an analog of the boundary element method in engineering and science, we\nanalyze and model unemployment rate in Austria, Italy, the Netherlands, Sweden,\nSwitzerland, and the United States as a function of inflation and the change in\nlabor force. Originally, the model linking unemployment to inflation and labor\nforce was developed and successfully tested for Austria, Canada, France,\nGermany, Japan, and the United States. Autoregressive properties of neither of\nthese variables are used to predict their evolution. In this sense, the model\nis a self-consistent and completely deterministic one without any stochastic\ncomponent (external shocks) except that associated with measurement errors and\nchanges in measurement units. Nevertheless, the model explains between 65% and\n95% of the variability in unemployment and inflation. For Italy, the rate of\nunemployment is predicted at a time horizon of nine years with pseudo\nout-of-sample root-mean-square forecasting error of 0.55% for the period\nbetween 1973 and 2006. One can expect that the u nemployment will be growing\nsince 2008 and will reach 11.4% near 2012. After 2012, unemployment in Italy\nwill start to descend.\n"
    },
    {
        "paper_id": 904.0344,
        "authors": "C. Pellicer-Lostao and R. Lopez-Ruiz",
        "title": "Introducing Chaos in Economic Gas-like Models",
        "comments": "8 pages, 4 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers ideal gas-like models of trading markets, where each\nagent is identified as a gas molecule that interacts with others trading in\nelastic or money-conservative collisions. Traditionally, these models introduce\ndifferent rules of random selection and exchange between pair agents. Unlike\nthese traditional models, this work introduces a chaotic procedure able of\nbreaking the pairing symmetry of agents (i,j)->(j,i). Its results show that,\nthe asymptotic money distributions of a market under chaotic evolution can\nexhibit a transition from Gibbs to Pareto distributions, as the pairing\nsymmetry is progressively broken.\n"
    },
    {
        "paper_id": 904.0555,
        "authors": "Martin Keller-Ressel, Antonis Papapantoleon, Josef Teichmann",
        "title": "The affine LIBOR models",
        "comments": "32 pages, 2 figures, submitted. Valuation formulas for swaptions in\n  multi-factor models added",
        "journal-ref": "Mathematical Finance 2013, Vol. 23, 627-658",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a general and flexible approach to LIBOR modeling based on the\nclass of affine factor processes. Our approach respects the basic economic\nrequirement that LIBOR rates are non-negative, and the basic requirement from\nmathematical finance that LIBOR rates are analytically tractable martingales\nwith respect to their own forward measure. Additionally, and most importantly,\nour approach also leads to analytically tractable expressions of multi-LIBOR\npayoffs. This approach unifies therefore the advantages of well-known forward\nprice models with those of classical LIBOR rate models. Several examples are\nadded and prototypical volatility smiles are shown. We believe that the\nCIR-process based LIBOR model might be of particular interest for applications,\nsince closed form valuation formulas for caps and swaptions are derived.\n"
    },
    {
        "paper_id": 904.0624,
        "authors": "Juan-Pablo Ortega and Rainer Pullirsch and Josef Teichmann and Julian\n  Wergieluk",
        "title": "A new approach for scenario generation in Risk management",
        "comments": "6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a new dynamic approach to scenario generation for the purposes of\nrisk management in the banking industry. We connect ideas from conventional\ntechniques -- like historical and Monte Carlo simulation -- and we come up with\na hybrid method that shares the advantages of standard procedures but\neliminates several of their drawbacks. Instead of considering the static\nproblem of constructing one or ten day ahead distributions for vectors of risk\nfactors, we embed the problem into a dynamic framework, where any time horizon\ncan be consistently simulated. Additionally, we use standard models from\nmathematical finance for each risk factor, whence bridging the worlds of\ntrading and risk management.\n  Our approach is based on stochastic differential equations (SDEs), like the\nHJM-equation or the Black-Scholes equation, governing the time evolution of\nrisk factors, on an empirical calibration method to the market for the chosen\nSDEs, and on an Euler scheme (or high-order schemes) for the numerical\nevaluation of the respective SDEs. The empirical calibration procedure\npresented in this paper can be seen as the SDE-counterpart of the so called\nFiltered Historical Simulation method; the behavior of volatility stems in our\ncase out of the assumptions on the underlying SDEs. Furthermore, we are able to\neasily incorporate \"middle-size\" and \"large-size\" events within our framework\nalways making a precise distinction between the information obtained from the\nmarket and the one coming from the necessary a-priori intuition of the risk\nmanager.\n  Results of one concrete implementation are provided.\n"
    },
    {
        "paper_id": 904.0729,
        "authors": "Ivan O. Kitov",
        "title": "Does economics need a scientific revolution?",
        "comments": "6 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Economics does not need a scientific revolution. Economics needs accurate\nmeasurements according to high standards of natural sciences and meticulous\nwork on revealing empirical relationships between measured variables.\n"
    },
    {
        "paper_id": 904.0756,
        "authors": "S.I. Chernyshov, A.V. Voronin, S.A. Razumovsky",
        "title": "The Problem of Modeling of Economic Dynamics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The correctness of Harrods model in the differential form is studied. The\ninadequacy of exponential growth of economy is shown; an alternative result is\nobtained. By example of Phillips model, an approach to correction of\nmacroeconomic models (in terms of initial prerequisites) is generalized. A\nmethodology based on balance relations for modelling of economic dynamics,\nincluding obtaining forecast estimates, is developed. The problems thus\nconsidered are reduced to the solution of Volterra and Fredholm integral\nequations of the second kind.\n"
    },
    {
        "paper_id": 904.0805,
        "authors": "Jean-Philippe Bouchaud",
        "title": "The (unfortunate) complexity of the economy",
        "comments": null,
        "journal-ref": "Physics World, April 2009, p.28-32",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article is a follow-up of a short essay that appeared in Nature 455,\n1181 (2008) [arXiv:0810.5306]. It has become increasingly clear that the\nerratic dynamics of markets is mostly endogenous and not due to the rational\nprocessing of exogenous news. I elaborate on the idea that spin-glass type of\nproblems, where the combination of competition and heterogeneities generically\nleads to long epochs of statis interrupted by crises and hyper-sensitivity to\nsmall changes of the environment, could be metaphors for the complexity of\neconomic systems. I argue that the most valuable contribution of physics to\neconomics might end up being of methodological nature, and that simple models\nfrom physics and agent based numerical simulations, although highly stylized,\nare more realistic than the traditional models of economics that assume\nrational agents with infinite foresight and infinite computing abilities.\n"
    },
    {
        "paper_id": 904.083,
        "authors": "Xiaolin Luo, Pavel V. Shevchenko",
        "title": "Computing Tails of Compound Distributions Using Direct Numerical\n  Integration",
        "comments": null,
        "journal-ref": "Journal of Computational Finance. 13(2), 73-111. (2009)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An efficient adaptive direct numerical integration (DNI) algorithm is\ndeveloped for computing high quantiles and conditional Value at Risk (CVaR) of\ncompound distributions using characteristic functions. A key innovation of the\nnumerical scheme is an effective tail integration approximation that reduces\nthe truncation errors significantly with little extra effort. High precision\nresults of the 0.999 quantile and CVaR were obtained for compound losses with\nheavy tails and a very wide range of loss frequencies using the DNI, Fast\nFourier Transform (FFT) and Monte Carlo (MC) methods. These results,\nparticularly relevant to operational risk modelling, can serve as benchmarks\nfor comparing different numerical methods. We found that the adaptive DNI can\nachieve high accuracy with relatively coarse grids. It is much faster than MC\nand competitive with FFT in computing high quantiles and CVaR of compound\ndistributions in the case of moderate to high frequencies and heavy tails.\n"
    },
    {
        "paper_id": 904.087,
        "authors": "Sovan Mitra",
        "title": "Risk Measures in Quantitative Finance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper was presented and written for two seminars: a national UK\nUniversity Risk Conference and a Risk Management industry workshop. The target\naudience is therefore a cross section of Academics and industry professionals.\n  The current ongoing global credit crunch has highlighted the importance of\nrisk measurement in Finance to companies and regulators alike. Despite risk\nmeasurement's central importance to risk management, few papers exist reviewing\nthem or following their evolution from its foremost beginnings up to the\npresent day risk measures.\n  This paper reviews the most important portfolio risk measures in Financial\nMathematics, from Bernoulli (1738) to Markowitz's Portfolio Theory, to the\npresently preferred risk measures such as CVaR (conditional Value at Risk). We\nprovide a chronological review of the risk measures and survey less commonly\nknown risk measures e.g. Treynor ratio.\n"
    },
    {
        "paper_id": 904.0896,
        "authors": "F. Bagarello",
        "title": "An operatorial approach to stock markets",
        "comments": null,
        "journal-ref": "J. Phys. A, {\\bf 39}, 6823-6840 (2006)",
        "doi": "10.1088/0305-4470/39/22/001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose and discuss some toy models of stock markets using the same\noperatorial approach adopted in quantum mechanics. Our models are suggested by\nthe discrete nature of the number of shares and of the cash which are exchanged\nin a real market, and by the existence of conserved quantities, like the total\nnumber of shares or some linear combination of cash and shares. The same\nframework as the one used in the description of a gas of interacting bosons is\nadopted.\n"
    },
    {
        "paper_id": 904.09,
        "authors": "Zoltan Eisler, Jean-Philippe Bouchaud, Julien Kockelkoren",
        "title": "The price impact of order book events: market orders, limit orders and\n  cancellations",
        "comments": "31 pages, 30 figures, accepted to Quantitative Finance; slightly\n  modified text, a changed figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  While the long-ranged correlation of market orders and their impact on prices\nhas been relatively well studied in the literature, the corresponding studies\nof limit orders and cancellations are scarce. We provide here an empirical\nstudy of the cross-correlation between all these different events, and their\nrespective impact on future price changes. We define and extract from the data\nthe \"bare\" impact these events would have, if they were to happen in isolation.\nFor large tick stocks, we show that a model where the bare impact of all events\nis permanent and non-fluctuating is in good agreement with the data. For small\ntick stocks, however, bare impacts must contain a history dependent part,\nreflecting the internal fluctuations of the order book. We show that this\neffect can be accurately described by an autoregressive model on the past order\nflow. This framework allows us to decompose the impact of an event into three\nparts: an instantaneous jump component, the modification of the future rates of\nthe different events, and the modification of the future gaps behind the best\nquotes. We compare in detail the present formalism with the temporary impact\nmodel that was proposed earlier to describe the impact of market orders when\nother types of events are not observed. Finally, we extend the model to\ndescribe the dynamics of the bid-ask spread.\n"
    },
    {
        "paper_id": 904.1042,
        "authors": "Guo-Hua Mu, Wei Chen, J\\'anos Kert\\'esz, Wei-Xing Zhou",
        "title": "Long-term correlations and multifractal analysis of trading volumes for\n  Chinese stocks",
        "comments": "12 pages, 6 figures, 1 table",
        "journal-ref": "Physics Procedia,Volume 3, Issue 5, August 2010, Pages 1631-1640",
        "doi": "10.1016/j.phpro.2010.07.003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the temporal correlations and multifractal nature of trading\nvolume of 22 liquid stocks traded on the Shenzhen Stock Exchange in 2003. We\nfind that the trading volume exhibit size-dependent non-universal long memory\nand multifractal nature. No crossover in the power-law dependence of the\ndetrended fluctuation functions is observed. Our results show that the intraday\npattern in the trading volume has negligible impact on the long memory and\nmultifractality.\n"
    },
    {
        "paper_id": 904.1067,
        "authors": "P. V. Shevchenko and M. V. W\\\"uthrich",
        "title": "The Structural Modelling of Operational Risk via Bayesian inference:\n  Combining Loss Data with Expert Opinions",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 1(3), pp. 3-26, 2006.\n  www.journalofoperationalrisk.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To meet the Basel II regulatory requirements for the Advanced Measurement\nApproaches, the bank's internal model must include the use of internal data,\nrelevant external data, scenario analysis and factors reflecting the business\nenvironment and internal control systems. Quantification of operational risk\ncannot be based only on historical data but should involve scenario analysis.\nHistorical internal operational risk loss data have limited ability to predict\nfuture behaviour moreover, banks do not have enough internal data to estimate\nlow frequency high impact events adequately. Historical external data are\ndifficult to use due to different volumes and other factors. In addition,\ninternal and external data have a survival bias, since typically one does not\nhave data of all collapsed companies. The idea of scenario analysis is to\nestimate frequency and severity of risk events via expert opinions taking into\naccount bank environment factors with reference to events that have occurred\n(or may have occurred) in other banks. Scenario analysis is forward looking and\ncan reflect changes in the banking environment. It is important to not only\nquantify the operational risk capital but also provide incentives to business\nunits to improve their risk management policies, which can be accomplished\nthrough scenario analysis. By itself, scenario analysis is very subjective but\ncombined with loss data it is a powerful tool to estimate operational risk\nlosses. Bayesian inference is a statistical technique well suited for combining\nexpert opinions and historical data. In this paper, we present examples of the\nBayesian inference methods for operational risk quantification.\n"
    },
    {
        "paper_id": 904.1074,
        "authors": "Fr\\'ed\\'eric Bossens, Gr\\'egory Ray\\'ee, Nikos S. Skantzos and\n  Griselda Deelstra",
        "title": "Vanna-Volga methods applied to FX derivatives : from theory to market\n  practice",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study Vanna-Volga methods which are used to price first generation exotic\noptions in the Foreign Exchange market. They are based on a rescaling of the\ncorrection to the Black-Scholes price through the so-called `probability of\nsurvival' and the `expected first exit time'. Since the methods rely heavily on\nthe appropriate treatment of market data we also provide a summary of the\nrelevant conventions. We offer a justification of the core technique for the\ncase of vanilla options and show how to adapt it to the pricing of exotic\noptions. Our results are compared to a large collection of indicative market\nprices and to more sophisticated models. Finally we propose a simple\ncalibration method based on one-touch prices that allows the Vanna-Volga\nresults to be in line with our pool of market data.\n"
    },
    {
        "paper_id": 904.1078,
        "authors": "Juan-Pablo Ortega",
        "title": "GARCH options via local risk minimization",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We apply a quadratic hedging scheme developed by Foellmer, Schweizer, and\nSondermann to European contingent products whose underlying asset is modeled\nusing a GARCH process and show that local risk-minimizing strategies with\nrespect to the physical measure do exist, even though an associated minimal\nmartingale measure is only available in the presence of bounded innovations.\nMore importantly, since those local risk-minimizing strategies are in general\nconvoluted and difficult to evaluate, we introduce Girsanov-like risk-neutral\nmeasures for the log-prices that yield more tractable and useful results.\nRegarding this subject, we focus on GARCH time series models with Gaussian\ninnovations and we provide specific sufficient conditions that have to do with\nthe finiteness of the kurtosis, under which those martingale measures are\nappropriate in the context of quadratic hedging. When this equivalent\nmartingale measure is adapted to the price representation we are able to\nrecover out of it the classical pricing formulas of Duan and Heston-Nandi, as\nwell as hedging schemes that improve the performance of those proposed in the\nliterature.\n"
    },
    {
        "paper_id": 904.1107,
        "authors": "Fei Ren, Gao-Feng Gu, and Wei-Xing Zhou",
        "title": "Scaling and memory in the return intervals of realized volatility",
        "comments": "12 pages, 6 figures, 2 tables",
        "journal-ref": "Physica A 388 (2009) 4787-4796",
        "doi": "10.1016/j.physa.2009.08.009",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform return interval analysis of 1-min {\\em{realized volatility}}\ndefined by the sum of absolute high-frequency intraday returns for the Shanghai\nStock Exchange Composite Index (SSEC) and 22 constituent stocks of SSEC. The\nscaling behavior and memory effect of the return intervals between successive\nrealized volatilities above a certain threshold $q$ are carefully investigated.\nIn comparison with the volatility defined by the closest tick prices to the\nminute marks, the return interval distribution for the realized volatility\nshows a better scaling behavior since 20 stocks (out of 22 stocks) and the SSEC\npass the Kolmogorov-Smirnov (KS) test and exhibit scaling behaviors, among\nwhich the scaling function for 8 stocks could be approximated well by a\nstretched exponential distribution revealed by the KS goodness-of-fit test\nunder the significance level of 5%. The improved scaling behavior is further\nconfirmed by the relation between the fitted exponent $\\gamma$ and the\nthreshold $q$. In addition, the similarity of the return interval distributions\nfor different stocks is also observed for the realized volatility. The\ninvestigation of the conditional probability distribution and the detrended\nfluctuation analysis (DFA) show that both short-term and long-term memory\nexists in the return intervals of realized volatility.\n"
    },
    {
        "paper_id": 904.1131,
        "authors": "Sovan Mitra",
        "title": "Optimisation of Stochastic Programming by Hidden Markov Modelling based\n  Scenario Generation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper formed part of a preliminary research report for a risk\nconsultancy and academic research. Stochastic Programming models provide a\npowerful paradigm for decision making under uncertainty. In these models the\nuncertainties are represented by a discrete scenario tree and the quality of\nthe solutions obtained is governed by the quality of the scenarios generated.\nWe propose a new technique to generate scenarios based on Gaussian Mixture\nHidden Markov Modelling. We show that our approach explicitly captures\nimportant time varying dynamics of stochastic processes (such as autoregression\nand jumps) as well as non-Gaussian distribution characteristics (such as\nskewness and kurtosis). Our scenario generation method enables richer\nrobustness and scenario analysis through exploiting the tractable properties of\nMarkov models and Gaussian mixture distributions. We demonstrate the benefits\nof our scenario generation method by conducting numerical experiments on\nFTSE-100 data.\n"
    },
    {
        "paper_id": 904.1157,
        "authors": "P. V. Shevchenko",
        "title": "Addressing the bias in Monte Carlo pricing of multi-asset options with\n  multiple barriers through discrete sampling",
        "comments": null,
        "journal-ref": "The Journal of Computational Finance 6(3), pp.1-20, 2003.\n  www.journalofcomputationalfinance.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  An efficient conditioning technique, the so-called Brownian Bridge\nsimulation, has previously been applied to eliminate pricing bias that arises\nin applications of the standard discrete-time Monte Carlo method to evaluate\noptions written on the continuous-time extrema of an underlying asset. It is\nbased on the simple and easy to implement analytic formulas for the\ndistribution of one-dimensional Brownian Bridge extremes. This paper extends\nthe technique to the valuation of multi-asset options with knock-out barriers\nimposed for all or some of the underlying assets. We derive formula for the\nunbiased option price estimator based on the joint distribution of the\nmulti-dimensional Brownian Bridge dependent extrema. As analytic formulas are\nnot available for the joint distribution in general, we develop upper and lower\nbiased option price estimators based on the distribution of independent extrema\nand the Fr\\'echet lower and upper bounds for the unknown distribution. All\nestimators are simple and easy to implement. They can always be used to bind\nthe true value by a confidence interval. Numerical tests indicate that our\nbiased estimators converge rapidly to the true option value as the number of\ntime steps for the asset path simulation increases in comparison to the\nestimator based on the standard discrete-time method. The convergence rate\ndepends on the correlation and barrier structures of the underlying assets.\n"
    },
    {
        "paper_id": 904.1292,
        "authors": "Sovan Mitra",
        "title": "A Review of Volatility and Option Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The literature on volatility modelling and option pricing is a large and\ndiverse area due to its importance and applications. This paper provides a\nreview of the most significant volatility models and option pricing methods,\nbeginning with constant volatility models up to stochastic volatility. We also\nsurvey less commonly known models e.g. hybrid models. We explain various\nvolatility types (e.g. realised and implied volatility) and discuss the\nempirical properties.\n"
    },
    {
        "paper_id": 904.1361,
        "authors": "Dominik D. Lambrigger, Pavel V. Shevchenko and Mario V. W\\\"uthrich",
        "title": "The Quantification of Operational Risk using Internal Data, Relevant\n  External Data and Expert Opinions",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 2(3), pp.3-27, 2007.\n  www.journalofoperationalrisk.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To quantify an operational risk capital charge under Basel II, many banks\nadopt a Loss Distribution Approach. Under this approach, quantification of the\nfrequency and severity distributions of operational risk involves the bank's\ninternal data, expert opinions and relevant external data. In this paper we\nsuggest a new approach, based on a Bayesian inference method, that allows for a\ncombination of these three sources of information to estimate the parameters of\nthe risk frequency and severity distributions.\n"
    },
    {
        "paper_id": 904.1402,
        "authors": "Samuel E. Vazquez, Simone Severini",
        "title": "Perturbation theory in a pure exchange non-equilibrium economy",
        "comments": "7 pages, 2 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.81.036102",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a formalism to study linearized perturbations around the\nequilibria of a pure exchange economy. With the use of mean field theory\ntechniques, we derive equations for the flow of products in an economy driven\nby heterogeneous preferences and probabilistic interaction between agents. We\nare able to show that if the economic agents have static preferences, which are\nalso homogeneous in any of the steady states, the final wealth distribution is\nindependent of the dynamics of the non-equilibrium theory. In particular, it is\ncompletely determined in terms of the initial conditions, and it is independent\nof the probability, and the network of interaction between agents. We show that\nthe main effect of the network is to determine the relaxation time via the\nusual eigenvalue gap as in random walks on graphs.\n"
    },
    {
        "paper_id": 904.1404,
        "authors": "Massimo Riccaboni, Fabio Pammolli, Sergey V. Buldyrev, Linda Ponta and\n  H. Eugene Stanley",
        "title": "The Size Variance Relationship of Business Firm Growth Rates",
        "comments": null,
        "journal-ref": "Proc. Natl. Acad. Sci. USA 105, 19595-19600 (2008)",
        "doi": "10.1073/pnas.0810478105",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The relationship between the size and the variance of firm growth rates is\nknown to follow an approximate power-law behavior $\\sigma(S) \\sim\nS^{-\\beta(S)}$ where $S$ is the firm size and $\\beta(S)\\approx 0.2$ is an\nexponent weakly dependent on $S$. Here we show how a model of proportional\ngrowth which treats firms as classes composed of various number of units of\nvariable size, can explain this size-variance dependence. In general, the model\npredicts that $\\beta(S)$ must exhibit a crossover from $\\beta(0)=0$ to\n$\\beta(\\infty)=1/2$. For a realistic set of parameters, $\\beta(S)$ is\napproximately constant and can vary in the range from 0.14 to 0.2 depending on\nthe average number of units in the firm. We test the model with a unique\nindustry specific database in which firm sales are given in terms of the sum of\nthe sales of all their products. We find that the model is consistent with the\nempirically observed size-variance relationship.\n"
    },
    {
        "paper_id": 904.1426,
        "authors": "Jacky Mallett",
        "title": "What are the limits on Commercial Bank Lending?",
        "comments": "19 pages, 6 figures, Accepted for Publication in Advances in Complex\n  Systems, August 2nd 2012",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Analysis of the 2007-8 credit crisis has concentrated on issues of relaxed\nlending standards, and the perception of irrational behaviour by speculative\ninvestors in real estate and other assets. Asset backed securities have been\nextensively criticised for creating a moral hazard in loan issuance and an\nassociated increase in default risk, by removing the immediate lender's\nincentive to ensure that the underlying loans could be repaid. However\nsignificant monetary issues can accompany any form of increased commercial bank\nlending, and these appear to have been overlooked by this analysis. In this\npaper we propose a general explanation for credit crises based on an\nexamination of the mechanics of the banking system, and in particular its\ninternal controls on the supply of credit. We suggest that the current credit\ncrisis is the result of multiple failures in the Basel regulatory framework,\nincluding the removal of central bank reserve requirements from some classes of\ndeposit accounts within the banking system, allowing financial instruments\nrepresenting debt to be used as regulatory capital, and in particular the\nintroduction of securitized lending which effectively removed a previously\nimplicit control over the total quantity of lending originating from the\nbanking system. We further argue that the interaction of these problems has led\nto a destabilising imbalance between total money and loan supply growth, in\nthat total lending sourced from the commercial bank sector increased at a\nfaster rate than accompanying growth in the money supply. This not only created\na multi-decade macro-economic debt spiral, but by increasing the ratio of debt\nto money within the monetary system acted to increase the risk of loan\ndefaults, and consequentially reduce the overall stability of the banking\nsystem.\n"
    },
    {
        "paper_id": 904.1483,
        "authors": "Gareth W. Peters, Pavel V. Shevchenko and Mario V. W\\\"uthrich",
        "title": "Model uncertainty in claims reserving within Tweedie's compound Poisson\n  models",
        "comments": null,
        "journal-ref": "ASTIN Bulletin 39(1), pp.1-33, 2009",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we examine the claims reserving problem using Tweedie's\ncompound Poisson model. We develop the maximum likelihood and Bayesian Markov\nchain Monte Carlo simulation approaches to fit the model and then compare the\nestimated models under different scenarios. The key point we demonstrate\nrelates to the comparison of reserving quantities with and without model\nuncertainty incorporated into the prediction. We consider both the model\nselection problem and the model averaging solutions for the predicted reserves.\nAs a part of this process we also consider the sub problem of variable\nselection to obtain a parsimonious representation of the model being fitted.\n"
    },
    {
        "paper_id": 904.15,
        "authors": "Sovan Mitra",
        "title": "Regime Switching Volatility Calibration by the Baum-Welch Method",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Regime switching volatility models provide a tractable method of modelling\nstochastic volatility. Currently the most popular method of regime switching\ncalibration is the Hamilton filter. We propose using the Baum-Welch algorithm,\nan established technique from Engineering, to calibrate regime switching models\ninstead. We demonstrate the Baum-Welch algorithm and discuss the significant\nadvantages that it provides compared to the Hamilton filter. We provide\ncomputational results of calibrating the Baum-Welch filter to S&P 500 data and\nvalidate its performance in and out of sample.\n"
    },
    {
        "paper_id": 904.1653,
        "authors": "Didier Rulli\\`ere (SAF), Diana Dorobantu (SAF), Areski Cousin (SAF)",
        "title": "An extension of Davis and Lo's contagion model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The present paper provides a multi-period contagion model in the credit risk\nfield. Our model is an extension of Davis and Lo's infectious default model. We\nconsider an economy of n firms which may default directly or may be infected by\nother defaulting firms (a domino effect being also possible). The spontaneous\ndefault without external influence and the infections are described by not\nnecessarily independent Bernoulli-type random variables. Moreover, several\ncontaminations could be required to infect another firm. In this paper we\ncompute the probability distribution function of the total number of defaults\nin a dependency context. We also give a simple recursive algorithm to compute\nthis distribution in an exchangeability context. Numerical applications\nillustrate the impact of exchangeability among direct defaults and among\ncontaminations, on different indicators calculated from the law of the total\nnumber of defaults. We then examine the calibration of the model on iTraxx data\nbefore and during the crisis. The dynamic feature together with the contagion\neffect seem to have a significant impact on the model performance, especially\nduring the recent distressed period.\n"
    },
    {
        "paper_id": 904.1756,
        "authors": "Sovan Mitra",
        "title": "Regime Switching Stochastic Volatility with Perturbation Based Option\n  Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Volatility modelling has become a significant area of research within\nFinancial Mathematics. Wiener process driven stochastic volatility models have\nbecome popular due their consistency with theoretical arguments and empirical\nobservations. However such models lack the ability to take into account long\nterm and fundamental economic factors e.g. credit crunch.\n  Regime switching models with mean reverting stochastic volatility are a new\nclass of stochastic volatility models that capture both short and long term\ncharacteristics. We propose a new general method of pricing options for these\nnew class of stochastic volatility models using Fouque's perturbation based\noption pricing method.\n  Using empirical data, we compare our option pricing method to Black-Scholes\nand Fouque's standard option pricing method and show that our pricing method\nprovides lower relative error compared to the other two methods.\n"
    },
    {
        "paper_id": 904.1771,
        "authors": "Pavel V. Shevchenko",
        "title": "Estimation of Operational Risk Capital Charge under Parameter\n  Uncertainty",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 3(1), pp. 51-63, 2008\n  www.journalofoperationalrisk.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many banks adopt the Loss Distribution Approach to quantify the operational\nrisk capital charge under Basel II requirements. It is common practice to\nestimate the capital charge using the 0.999 quantile of the annual loss\ndistribution, calculated using point estimators of the frequency and severity\ndistribution parameters. The uncertainty of the parameter estimates is\ntypically ignored. One of the unpleasant consequences for the banks accounting\nfor parameter uncertainty is an increase in the capital requirement. This paper\ndemonstrates how the parameter uncertainty can be taken into account using a\nBayesian framework that also allows for incorporation of expert opinions and\nexternal data into the estimation procedure.\n"
    },
    {
        "paper_id": 904.1772,
        "authors": "Hans B\\\"uhlmann, Pavel V. Shevchenko and Mario V. W\\\"uthrich",
        "title": "A \"Toy\" Model for Operational Risk Quantification using Credibility\n  Theory",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 2(1), pp. 3-19, 2007.\n  www.journalofoperationalrisk.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To meet the Basel II regulatory requirements for the Advanced Measurement\nApproaches in operational risk, the bank's internal model should make use of\nthe internal data, relevant external data, scenario analysis and factors\nreflecting the business environment and internal control systems. One of the\nunresolved challenges in operational risk is combining of these data sources\nappropriately. In this paper we focus on quantification of the low frequency\nhigh impact losses exceeding some high threshold. We suggest a full credibility\ntheory approach to estimate frequency and severity distributions of these\nlosses by taking into account bank internal data, expert opinions and industry\ndata.\n"
    },
    {
        "paper_id": 904.1798,
        "authors": "Constantinos Kardaras",
        "title": "Market viability via absence of arbitrage of the first kind",
        "comments": "15 pages. Updated, more self-contained version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a semimartingale financial market model, it is shown that there is\nequivalence between absence of arbitrage of the first kind (a weak viability\ncondition) and the existence of a strictly positive process that acts as a\nlocal martingale deflator on nonnegative wealth processes.\n"
    },
    {
        "paper_id": 904.1805,
        "authors": "Pavel V. Shevchenko",
        "title": "Implementing Loss Distribution Approach for Operational Risk",
        "comments": null,
        "journal-ref": "Applied Stochastic Models in Business and Industry (2010), volume\n  26 issue 3, pages: 277-307",
        "doi": "10.1002/asmb.812",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  To quantify the operational risk capital charge under the current regulatory\nframework for banking supervision, referred to as Basel II, many banks adopt\nthe Loss Distribution Approach. There are many modeling issues that should be\nresolved to use the approach in practice. In this paper we review the\nquantitative methods suggested in literature for implementation of the\napproach. In particular, the use of the Bayesian inference method that allows\nto take expert judgement and parameter uncertainty into account, modeling\ndependence and inclusion of insurance are discussed.\n"
    },
    {
        "paper_id": 904.1903,
        "authors": "Constantinos Kardaras, Eckhard Platen",
        "title": "Minimizing the expected market time to reach a certain wealth level",
        "comments": "13 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a financial market model, we consider variations of the problem of\nminimizing the expected time to upcross a certain wealth level. For exponential\nLevy markets, we show the asymptotic optimality of the growth-optimal portfolio\nfor the above problem and obtain tight bounds for the value function for any\nwealth level. In an Ito market, we employ the concept of market time, which is\na clock that runs according to the underlying market growth. We show the\noptimality of the growth-optimal portfolio for minimizing the expected market\ntime to reach any wealth level. This reveals a general definition of market\ntime which can be useful from an investor's point of view. We utilize this last\ndefinition to extend the previous results in a general semimartingale setting.\n"
    },
    {
        "paper_id": 904.2113,
        "authors": "Matthias Hanauske, Jennifer Kunz, Steffen Bernius, and Wolfgang\n  K\\\"onig",
        "title": "Doves and hawks in economics revisited. An evolutionary quantum game\n  theory-based analysis of financial crises",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2010.06.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The last financial and economic crisis demonstrated the dysfunctional\nlong-term effects of aggressive behaviour in financial markets. Yet,\nevolutionary game theory predicts that under the condition of strategic\ndependence a certain degree of aggressive behaviour remains within a given\npopulation of agents. However, as the consequences of the financial crisis\nexhibit, it would be desirable to change the 'rules of the game' in a way that\nprevents the occurrence of any aggressive behaviour and thereby also the danger\nof market crashes. The paper picks up this aspect. Through the extension of the\nin literature well-known Hawk-Dove game by a quantum approach, we can show that\ndependent on entanglement, also evolutionary stable strategies can emerge,\nwhich are not predicted by classical evolutionary game theory and where the\ntotal economic population uses a non aggressive quantum strategy.\n"
    },
    {
        "paper_id": 904.2376,
        "authors": "T. R. Hurd",
        "title": "Credit risk modeling using time-changed Brownian motion",
        "comments": "19 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by the interplay between structural and reduced form credit models,\nwe propose to model the firm value process as a time-changed Brownian motion\nthat may include jumps and stochastic volatility effects, and to study the\nfirst passage problem for such processes. We are lead to consider modifying the\nstandard first passage problem for stochastic processes to capitalize on this\ntime change structure and find that the distribution functions of such \"first\npassage times of the second kind\" are efficiently computable in a wide range of\nuseful examples. Thus this new notion of first passage can be used to define\nthe time of default in generalized structural credit models. Formulas for\ndefaultable bonds and credit default swaps are given that are both efficiently\ncomputable and lead to realistic spread curves. Finally, we show that by\ntreating joint firm value processes as dependent time changes of independent\nBrownian motions, one can obtain multifirm credit models with rich and\nplausible dynamics and enjoying the possibility of efficient valuation of\nportfolio credit derivatives.\n"
    },
    {
        "paper_id": 904.2731,
        "authors": "Sovan Mitra",
        "title": "An Introduction to Hedge Funds",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This report was originally written as an industry white paper on Hedge Funds.\nThis paper gives an overview to Hedge Funds, with a focus on risk management\nissues. We define and explain the general characteristics of Hedge Funds, their\nmain investment strategies and the risk models employed. We address the\nproblems in Hedge Fund modelling, survey current Hedge Funds available on the\nmarket and those that have been withdrawn. Finally, we summarise the supporting\nand opposing arguments for Hedge Fund usage. A unique value of this paper,\ncompared to other Hedge Fund literature freely available on the internet, is\nthat this review is fully sourced from academic references (such as peer\nreviewed journals) and is thus a bona fide study. This paper will be of\ninterest to: Hedge Fund and Mutual Fund Managers, Quantitative Analysts,\n\"Front\" and \"Middle\" office banking functions e.g. Treasury Management,\nRegulators concerned with Hedge Fund Financial Risk Management, Private and\nInstitutional Investors, Academic Researchers in the area of Financial Risk\nManagement and the general Finance community.\n"
    },
    {
        "paper_id": 904.291,
        "authors": "Xiaolin Luo, Pavel V. Shevchenko and John B. Donnelly",
        "title": "Addressing the Impact of Data Truncation and Parameter Uncertainty on\n  Operational Risk Estimates",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 2(4), 3-26, 2007\n  www.journalofoperationalrisk.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Typically, operational risk losses are reported above some threshold. This\npaper studies the impact of ignoring data truncation on the 0.999 quantile of\nthe annual loss distribution for operational risk for a broad range of\ndistribution parameters and truncation levels. Loss frequency and severity are\nmodelled by the Poisson and Lognormal distributions respectively. Two cases of\nignoring data truncation are studied: the \"naive model\" - fitting a Lognormal\ndistribution with support on a positive semi-infinite interval, and \"shifted\nmodel\" - fitting a Lognormal distribution shifted to the truncation level. For\nall practical cases, the \"naive model\" leads to underestimation (that can be\nsevere) of the 0.999 quantile. The \"shifted model\" overestimates the 0.999\nquantile except some cases of small underestimation for large truncation\nlevels. Conservative estimation of capital charge is usually acceptable and the\nuse of the \"shifted model\" can be justified while the \"naive model\" should not\nbe allowed. However, if parameter uncertainty is taken into account (in\npractice it is often ignored), the \"shifted model\" can lead to considerable\nunderestimation of capital charge. This is demonstrated with a practical\nexample.\n"
    },
    {
        "paper_id": 904.2913,
        "authors": "Constantinos Kardaras",
        "title": "Generalized supermartingale deflators under limited information",
        "comments": "13 pages; (hopefully) final version. To appear in \"Mathematical\n  Finance\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We undertake a study of markets from the perspective of a financial agent\nwith limited access to information. The set of wealth processes available to\nthe agent is structured with reasonable economic properties, instead of the\nusual practice of taking it to consist of stochastic integrals against a\nsemimartingale integrator. We obtain the equivalence of the boundedness in\nprobability of the set of terminal wealth outcomes (which in turn is equivalent\nto the weak market viability condition of absence of arbitrage of the first\nkind) with the existence of at least one strictly positive deflator that makes\nthe deflated wealth processes have a generalized supermartingale property.\n"
    },
    {
        "paper_id": 904.3,
        "authors": "Pierre Patie",
        "title": "Law of the exponential functional of one-sided L\\'evy processes and\n  Asian options",
        "comments": null,
        "journal-ref": "C. R. Acad. Sci. Paris, Ser. I 347, 407-411, 2009",
        "doi": "10.1016/j.crma.2009.02.013",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this note is to describe, in terms of a power series, the\ndistribution function of the exponential functional, taken at some independent\nexponential time, of a spectrally negative L\\'evy process \\xi with unbounded\nvariation. We also derive a Geman-Yor type formula for Asian options prices in\na financial market driven by e^\\xi.\n"
    },
    {
        "paper_id": 904.3004,
        "authors": "Wong Jian Cheng, Lian Heng, and Cheong Siew Ann",
        "title": "Macroeconomic Phase Transitions Detected from the Dow Jones Industrial\n  Average Time Series",
        "comments": "elsarticle, 18 pages, 3 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we perform statistical segmentation and clustering analysis of\nthe Dow Jones Industrial Average time series between January 1997 and August\n2008. Modeling the index movements and log-index movements as stationary\nGaussian processes, we find a total of 116 and 119 statistically stationary\nsegments respectively. These can then be grouped into between five to seven\nclusters, each representing a different macroeconomic phase. The macroeconomic\nphases are distinguished primarily by their volatilities. We find the US\neconomy, as measured by the DJI, spends most of its time in a low-volatility\nphase and a high-volatility phase. The former can be roughly associated with\neconomic expansion, while the latter contains the economic contraction phase in\nthe standard economic cycle. Both phases are interrupted by a\nmoderate-volatility market, but extremely-high-volatility market crashes are\nfound mostly within the high-volatility phase. From the temporal distribution\nof various phases, we see a high-volatility phase from mid-1998 to mid-2003,\nand another starting mid-2007 (the current global financial crisis).\nTransitions from the low-volatility phase to the high-volatility phase are\npreceded by a series of precursor shocks, whereas the transition from the\nhigh-volatility phase to the low-volatility phase is preceded by a series of\ninverted shocks. The time scale for both types of transitions is about a year.\nWe also identify the July 1997 Asian Financial Crisis to be the trigger for the\nmid-1998 transition, and an unnamed May 2006 market event related to\ncorrections in the Chinese markets to be the trigger for the mid-2007\ntransition.\n"
    },
    {
        "paper_id": 904.321,
        "authors": "F. Bagarello",
        "title": "Stock markets and quantum dynamics: a second quantized description",
        "comments": null,
        "journal-ref": "Physica A, {\\bf 386}, 283-302 (2007)",
        "doi": "10.1016/j.physa.2007.08.031",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we continue our descriptions of stock markets in terms of some\nnon abelian operators which are used to describe the portfolio of the various\ntraders and other {\\em observable} quantities. After a first prototype model\nwith only two traders, we discuss a more realistic model of market with an\narbitrary number of traders. For both models we find approximated solutions for\nthe time evolution of the portfolio of each trader. In particular, for the more\nrealistic model, we use the {\\em stochastic limit} approach and a {\\em fixed\npoint like} approximation.\n"
    },
    {
        "paper_id": 904.3213,
        "authors": "F. Bagarello",
        "title": "Simplified stock markets described by number operators",
        "comments": "Rep. on Math. Phys., in press",
        "journal-ref": null,
        "doi": "10.1016/S0034-4877(09)90010-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we continue our systematic analysis of the operatorial approach\npreviously proposed in an economical context and we discuss a {\\em mixed} toy\nmodel of a simplified stock market, i.e. a model in which the price of the\nshares is given as an input. We deduce the time evolution of the portfolio of\nthe various traders of the market, as well as of other {\\em observable}\nquantities. As in a previous paper, we solve the equations of motion by means\nof a {\\em fixed point like} approximation.\n"
    },
    {
        "paper_id": 904.3929,
        "authors": "Ammar Kessab (GRANEM)",
        "title": "La Loi organique relative aux lois de finances (LOLF) dans les\n  institutions culturelles publiques du spectacle vivant en France",
        "comments": "10th International Conference on Arts and Cultural Management (AIMAC\n  2009), Dallas : \\'Etats-Unis d'Am\\'erique (2009)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a crisis of public finances, France bases all its hopes on the \"evaluation\nof performance\" to moderate the effects of a complex crisis. Under the banner\nof \"modernization of the State\", a new \"financial constitution\" called the\nOrganic Law on finance laws (LOLF) became the main lever of reform of public\nmanagement. Fully applied to the Cultural Affairs since 2006, the LOLF is based\non a set of performance indicators and sets the public performance arts\ninstitutions specific targets. This article defines and analyzes the pattern of\nthe design and the course of these indicators and targets. It also examines the\ncontroversy generated by this new mode of governance.\n"
    },
    {
        "paper_id": 904.4074,
        "authors": "Gareth W. Peters, Pavel V. Shevchenko and Mario V. W\\\"uthrich",
        "title": "Dynamic operational risk: modeling dependence and combining different\n  sources of information",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 4(2), pp. 69-104, 2009\n  www.journalofoperationalrisk.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we model dependence between operational risks by allowing risk\nprofiles to evolve stochastically in time and to be dependent. This allows for\na flexible correlation structure where the dependence between frequencies of\ndifferent risk categories and between severities of different risk categories\nas well as within risk categories can be modeled. The model is estimated using\nBayesian inference methodology, allowing for combination of internal data,\nexternal data and expert opinion in the estimation procedure. We use a\nspecialized Markov chain Monte Carlo simulation methodology known as Slice\nsampling to obtain samples from the resulting posterior distribution and\nestimate the model parameters.\n"
    },
    {
        "paper_id": 904.4075,
        "authors": "Pavel V. Shevchenko and Grigory Temnov",
        "title": "Modeling operational risk data reported above a time-varying threshold",
        "comments": null,
        "journal-ref": "The Journal of Operational Risk 4(2), pp. 19-42, 2009\n  www.journalofoperationalrisk.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Typically, operational risk losses are reported above a threshold. Fitting\ndata reported above a constant threshold is a well known and studied problem.\nHowever, in practice, the losses are scaled for business and other factors\nbefore the fitting and thus the threshold is varying across the scaled data\nsample. A reporting level may also change when a bank changes its reporting\npolicy. We present both the maximum likelihood and Bayesian Markov chain Monte\nCarlo approaches to fitting the frequency and severity loss distributions using\ndata in the case of a time varying threshold. Estimation of the annual loss\ndistribution accounting for parameter uncertainty is also presented.\n"
    },
    {
        "paper_id": 904.4099,
        "authors": "M. Bartolozzi and C. Mellen",
        "title": "Local Risk Decomposition for High-frequency Trading Systems",
        "comments": "12 pages and 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the present work we address the problem of evaluating the historical\nperformance of a trading strategy or a certain portfolio of assets. Common\nindicators such as the Sharpe ratio and the risk adjusted return have\nsignificant drawbacks. In particular, they are global indices, that is they do\nnot preserve any 'local' information about the performance dynamics either in\ntime or for a particular investment horizon. This information could be\nfundamental for practitioners as the past performance can be affected by the\nnon-stationarity of financial market. In order to highlight this feature, we\nintroduce the 'local risk decomposition' (LRD) formalism, where dynamical\ninformation about a strategy's performance is retained. This framework,\nmotivated by the multi-scaling techniques used in complex system theory, is\nparticularly suitable for high-frequency trading systems and can be applied\ninto problems of strategy optimization.\n"
    },
    {
        "paper_id": 904.4131,
        "authors": "Alexander Weiss",
        "title": "Executing large orders in a microscopic market model",
        "comments": "32 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a recent paper, Alfonsi, Fruth and Schied (AFS) propose a simple order\nbook based model for the impact of large orders on stock prices. They use this\nmodel to derive optimal strategies for the execution of large orders. We apply\nthese strategies to an agent-based stochastic order book model that was\nrecently proposed by Bovier, \\v{C}ern\\'{y} and Hryniv, but already the\ncalibration fails. In particular, from our simulations the recovery speed of\nthe market after a large order is clearly dependent on the order size, whereas\nthe AFS model assumes a constant speed. For this reason, we propose a\ngeneralization of the AFS model, the GAFS model, that incorporates this\ndependency, and prove the optimal investment strategies. As a corollary, we\nfind that we can derive the ``correct'' constant resilience speed for the AFS\nmodel from the GAFS model such that the optimal strategies of the AFS and the\nGAFS model coincide. Finally, we show that the costs of applying the optimal\nstrategies of the GAFS model to the artificial market environment still differ\nsignificantly from the model predictions, indicating that even the improved\nmodel does not capture all of the relevant details of a real market.\n"
    },
    {
        "paper_id": 904.4364,
        "authors": "Vladimir Vovk",
        "title": "Continuous-time trading and the emergence of probability",
        "comments": "54 pages, as compared with the previous version, the main result\n  (Theorem 6.3) slightly strengthened and a few further clarifications added",
        "journal-ref": "Finance and Stochastics 16:561-609 (2012)",
        "doi": "10.1007/s00780-012-0180-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper establishes a non-stochastic analogue of the celebrated result by\nDubins and Schwarz about reduction of continuous martingales to Brownian motion\nvia time change. We consider an idealized financial security with continuous\nprice path, without making any stochastic assumptions. It is shown that typical\nprice paths possess quadratic variation, where \"typical\" is understood in the\nfollowing game-theoretic sense: there exists a trading strategy that earns\ninfinite capital without risking more than one monetary unit if the process of\nquadratic variation does not exist. Replacing time by the quadratic variation\nprocess, we show that the price path becomes Brownian motion. This is\nessentially the same conclusion as in the Dubins-Schwarz result, except that\nthe probabilities (constituting the Wiener measure) emerge instead of being\npostulated. We also give an elegant statement, inspired by Peter McCullagh's\nunpublished work, of this result in terms of game-theoretic probability theory.\n"
    },
    {
        "paper_id": 904.443,
        "authors": "Pawe{\\l} Sieczka, Janusz A. Ho{\\l}yst",
        "title": "Collective firm bankruptcies and phase transition in rating dynamics",
        "comments": null,
        "journal-ref": "The European Physical Journal B 71 461-466 (2009)",
        "doi": "10.1140/epjb/e2009-00322-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a simple model of firm rating evolution. We consider two sources\nof defaults: individual dynamics of economic development and Potts-like\ninteractions between firms. We show that such a defined model leads to phase\ntransition, which results in collective defaults. The existence of the\ncollective phase depends on the mean interaction strength. For small\ninteraction strength parameters, there are many independent bankruptcies of\nindividual companies. For large parameters, there are giant collective defaults\nof firm clusters. In the case when the individual firm dynamics favors dumping\nof rating changes, there is an optimal strength of the firm's interactions from\nthe systemic risk point of view.\n"
    },
    {
        "paper_id": 904.462,
        "authors": "Josep J. Masdemont, Luis Ortiz-Gracia",
        "title": "Haar Wavelets-Based Approach for Quantifying Credit Portfolio Losses",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes a new methodology to compute Value at Risk (VaR) for\nquantifying losses in credit portfolios. We approximate the cumulative\ndistribution of the loss function by a finite combination of Haar wavelets\nbasis functions and calculate the coefficients of the approximation by\ninverting its Laplace transform. In fact, we demonstrate that only a few\ncoefficients of the approximation are needed, so VaR can be reached quickly. To\ntest the methodology we consider the Vasicek one-factor portfolio credit loss\nmodel as our model framework. The Haar wavelets method is fast, accurate and\nrobust to deal with small or concentrated portfolios, when the hypothesis of\nthe Basel II formulas are violated.\n"
    },
    {
        "paper_id": 904.4822,
        "authors": "Pavel V. Shevchenko",
        "title": "Implied Correlation for Pricing multi-FX options",
        "comments": null,
        "journal-ref": "Derivatives Week, 13 March 2006 pp. 8-9 and 20 March 2006 pp.\n  10-11. www.derivativesweek.com",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Option written on several foreign exchange rates (FXRs) depends on\ncorrelation between the rates. To evaluate the option, historical estimates for\ncorrelations can be used but usually they are not stable. More significantly,\npricing of the option using these estimates is usually inconsistent to the\ntraded vanilla contracts. To price options written on several FXRs with the\nsame denominating currency, financial practitioners and traders often use\nimplied correlations calculated from implied volatilities of FXRs that form\n\"currency triangles\". However, some options may have underlying FXRs with\ndifferent denominating currencies. In this paper, we present the formula for\nthe implied correlations between such FXRs. These can be used for valuation,\nfor example, barrier option on two FXRs with different denominating currencies\nwhere one FXR determines how much the option is in or out of the money at\nmaturity while another FXR is related to the barrier. Other relevant options\nare straightforward.\n"
    },
    {
        "paper_id": 905.0072,
        "authors": "Dorje C. Brody and Robyn L. Friedman (Imperial College London)",
        "title": "Information of Interest",
        "comments": "12 pages, 3 figures",
        "journal-ref": "Risk Magazine, December 2009, 105-110",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A pricing formula for discount bonds, based on the consideration of the\nmarket perception of future liquidity risk, is established. An\ninformation-based model for liquidity is then introduced, which is used to\nobtain an expression for the bond price. Analysis of the bond price dynamics\nshows that the bond volatility is determined by prices of certain weighted\nperpetual annuities. Pricing formulae for interest rate derivatives are\nderived.\n"
    },
    {
        "paper_id": 905.0128,
        "authors": "L. Lin, Ren R.E, and D. Sornette",
        "title": "A Consistent Model of `Explosive' Financial Bubbles With Mean-Reversing\n  Residuals",
        "comments": "32 pages with 2 figures and 7 tables",
        "journal-ref": "International Review of Financial Analysis 33, 210-225 (2014)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a self-consistent model for explosive financial bubbles, which\ncombines a mean-reverting volatility process and a stochastic conditional\nreturn which reflects nonlinear positive feedbacks and continuous updates of\nthe investors' beliefs and sentiments. The conditional expected returns exhibit\nfaster-than-exponential acceleration decorated by accelerating oscillations,\ncalled \"log-periodic power law.\" Tests on residuals show a remarkable low rate\n(0.2%) of false positives when applied to a GARCH benchmark. When tested on the\nS&P500 US index from Jan. 3, 1950 to Nov. 21, 2008, the model correctly\nidentifies the bubbles ending in Oct. 1987, in Oct. 1997, in Aug. 1998 and the\nITC bubble ending on the first quarter of 2000. Different unit-root tests\nconfirm the high relevance of the model specification. Our model also provides\na diagnostic for the duration of bubbles: applied to the period before Oct.\n1987 crash, there is clear evidence that the bubble started at least 4 years\nearlier. We confirm the validity and universality of the volatility-confined\nLPPL model on seven other major bubbles that have occurred in the World in the\nlast two decades. Using Bayesian inference, we find a very strong statistical\npreference for our model compared with a standard benchmark, in contradiction\nwith Chang and Feigenbaum (2006) which used a unit-root model for residuals.\n"
    },
    {
        "paper_id": 905.0129,
        "authors": "A. N. Gorban, E. V. Smirnova, T. A. Tyukina",
        "title": "Correlations, Risk and Crisis: From Physiology to Finance",
        "comments": "42 pages, 15 figures, misprints corrections, a proof is added,\n  improved journal version",
        "journal-ref": "Physica A 389 (2010), 3193-3217",
        "doi": "10.1016/j.physa.2010.03.035",
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  We study the dynamics of correlation and variance in systems under the load\nof environmental factors. A universal effect in ensembles of similar systems\nunder the load of similar factors is described: in crisis, typically, even\nbefore obvious symptoms of crisis appear, correlation increases, and, at the\nsame time, variance (and volatility) increases too. This effect is supported by\nmany experiments and observations of groups of humans, mice, trees, grassy\nplants, and on financial time series.\n  A general approach to the explanation of the effect through dynamics of\nindividual adaptation of similar non-interactive individuals to a similar\nsystem of external factors is developed. Qualitatively, this approach follows\nSelye's idea about adaptation energy.\n"
    },
    {
        "paper_id": 905.0155,
        "authors": "Zuzana Macova, Daniel Sevcovic",
        "title": "Weakly nonlinear analysis of the Hamilton-Jacobi-Bellman equation\n  arising from pension savings management",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The main purpose of this paper is to analyze solutions to a fully nonlinear\nparabolic equation arising from the problem of optimal portfolio construction.\nWe show how the problem of optimal stock to bond proportion in the management\nof pension fund portfolio can be formulated in terms of the solution to the\nHamilton-Jacobi-Bellman equation. We analyze the solution from qualitative as\nwell as quantitative point of view. We construct useful bounds of solution\nyielding estimates for the optimal value of the stock to bond proportion in the\nportfolio. Furthermore we construct asymptotic expansions of a solution in\nterms of a small model parameter. Finally, we perform sensitivity analysis of\nthe optimal solution with respect to various model parameters and compare\nanalytical results of this paper with the corresponding known results arising\nfrom time-discrete dynamic stochastic optimization model.\n"
    },
    {
        "paper_id": 905.022,
        "authors": "Didier Sornette and Ryan Woodard",
        "title": "Financial Bubbles, Real Estate bubbles, Derivative Bubbles, and the\n  Financial and Economic Crisis",
        "comments": "51 pages, 25 figures, to appear in the Proceedings of APFA7\n  (Applications of Physics in Financial Analysis), Conference series entitled\n  Applications of Physics in Financial Analysis focuses on the analysis of\n  large-scale Economic data, organized by Misako Takayasu and Tsutomu Watanabe\n  http://www.thic-apfa7.com/en/htm/index.html",
        "journal-ref": "in Proceedings of APFA7 (Applications of Physics in Financial\n  Analysis), \"New Approaches to the Analysis of Large-Scale Business and\n  Economic Data,'' Misako Takayasu, Tsutomu Watanabe and Hideki Takayasu, eds.,\n  Springer (2010)",
        "doi": "10.1007/978-4-431-53853-0_6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The financial crisis of 2008, which started with an initially well-defined\nepicenter focused on mortgage backed securities (MBS), has been cascading into\na global economic recession, whose increasing severity and uncertain duration\nhas led and is continuing to lead to massive losses and damage for billions of\npeople. Heavy central bank interventions and government spending programs have\nbeen launched worldwide and especially in the USA and Europe, with the hope to\nunfreeze credit and boltster consumption. Here, we present evidence and\narticulate a general framework that allows one to diagnose the fundamental\ncause of the unfolding financial and economic crisis: the accumulation of\nseveral bubbles and their interplay and mutual reinforcement has led to an\nillusion of a \"perpetual money machine\" allowing financial institutions to\nextract wealth from an unsustainable artificial process. Taking stock of this\ndiagnostic, we conclude that many of the interventions to address the so-called\nliquidity crisis and to encourage more consumption are ill-advised and even\ndangerous, given that precautionary reserves were not accumulated in the \"good\ntimes\" but that huge liabilities were. The most \"interesting\" present times\nconstitute unique opportunities but also great challenges, for which we offer a\nfew recommendations.\n"
    },
    {
        "paper_id": 905.0468,
        "authors": "Paulo F. C. Tilles, Fernando F. Ferreira, Gerson Francisco, Carlos de\n  B. Pereira and Flavia Mori Sarti",
        "title": "A Markovian Model Market - Akerlof's Lemmons and the Asymmetry of\n  Information",
        "comments": "13 pages and 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we study an economic agent based model under different\nasymmetric information degrees. This model is quite simple and can be treated\nanalytically since the buyers evaluate the quality of a certain good taking\ninto account only the quality of the last good purchased plus her perceptive\ncapacity \\beta . As a consequence the system evolves according to a stationary\nMarkovian stochastic process. The value of a product offered by the seller\nincreases with quality according to the exponent \\alpha, which is a measure of\ntechnology. It incorporates all the technological capacity of production\nsystems such as education, scientific development and techniques that change\nthe productivity growth. The technological level plays an important role to\nexplain how the asymmetry of information may affect the market evolution in\nthis model. We observe that, for high technological levels, the market can\ncontrol adverse selection. The model allows us to compute the maximum\nasymmetric information degree before market collapse. Below this critical point\nthe market evolves during a very limited time and then dies out completely.\nWhen \\beta is closer to 1(symmetric information), the market becomes more\nprofitable for high quality goods, although high and low quality markets\ncoexist. All the results we obtained from the model are analytical and the\nmaximum asymmetric information level is a consequence of an ergodicity\nbreakdown in the process of quality evaluation.\n"
    },
    {
        "paper_id": 905.0582,
        "authors": "Gao-Feng Gu, Fei Ren, Xiao-Hui Ni, Wei Chen, Wei-Xing Zhou",
        "title": "Empirical regularities of opening call auction in Chinese stock market",
        "comments": "11 pages, 6 figures, 3 tables",
        "journal-ref": "Physica A 389 (2), 278-286 (2010)",
        "doi": "10.1016/j.physa.2009.09.019",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the statistical regularities of opening call auction using the\nultra-high-frequency data of 22 liquid stocks traded on the Shenzhen Stock\nExchange in 2003. The distribution of the relative price, defined as the\nrelative difference between the order price in opening call auction and the\nclosing price of last trading day, is asymmetric and that the distribution\ndisplays a sharp peak at zero relative price and a relatively wide peak at\nnegative relative price. The detrended fluctuation analysis (DFA) method is\nadopted to investigate the long-term memory of relative order prices. We\nfurther study the statistical regularities of order sizes in opening call\nauction, and observe a phenomenon of number preference, known as order size\nclustering. The probability density function (PDF) of order sizes could be well\nfitted by a $q$-Gamma function, and the long-term memory also exists in order\nsizes. In addition, both the average volume and the average number of orders\ndecrease exponentially with the price level away from the best bid or ask price\nlevel in the limit-order book (LOB) established immediately after the opening\ncall auction, and a price clustering phenomenon is observed.\n"
    },
    {
        "paper_id": 905.0781,
        "authors": "Mikhail Voropaev",
        "title": "Variance-covariance based risk allocation in credit portfolios:\n  analytical approximation",
        "comments": "9 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  High precision analytical approximation is proposed for variance-covariance\nbased risk allocation in a portfolio of risky assets. A general case of a\nsingle-period multi-factor Merton-type model with stochastic recovery is\nconsidered. The accuracy of the approximation as well as its speed are compared\nto and shown to be superior to those of Monte Carlo simulation.\n"
    },
    {
        "paper_id": 905.1518,
        "authors": "Victor M. Yakovenko, J. Barkley Rosser",
        "title": "Colloquium: Statistical mechanics of money, wealth, and income",
        "comments": "24 pages, 13 figures; v.2 - minor stylistic changes and updates of\n  references corresponding to the published version",
        "journal-ref": "Reviews of Modern Physics 81, 1703 (2009)",
        "doi": "10.1103/RevModPhys.81.1703",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This Colloquium reviews statistical models for money, wealth, and income\ndistributions developed in the econophysics literature since the late 1990s. By\nanalogy with the Boltzmann-Gibbs distribution of energy in physics, it is shown\nthat the probability distribution of money is exponential for certain classes\nof models with interacting economic agents. Alternative scenarios are also\nreviewed. Data analysis of the empirical distributions of wealth and income\nreveals a two-class distribution. The majority of the population belongs to the\nlower class, characterized by the exponential (\"thermal\") distribution, whereas\na small fraction of the population in the upper class is characterized by the\npower-law (\"superthermal\") distribution. The lower part is very stable,\nstationary in time, whereas the upper part is highly dynamical and out of\nequilibrium.\n"
    },
    {
        "paper_id": 905.1882,
        "authors": "Giacomo Bormetti, Valentina Cazzola, Danilo Delpini",
        "title": "Option pricing under Ornstein-Uhlenbeck stochastic volatility: a linear\n  model",
        "comments": "Final version 17 pages, 5 figures, 3 tables. Accepted for publication\n  on Int. J. Theoretical Appl. Finance",
        "journal-ref": "Int. J. Theoretical Appl. Finance 7 (2010) 1047-1063",
        "doi": "10.1142/S0219024910006108",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of option pricing under stochastic volatility models,\nfocusing on the linear approximation of the two processes known as exponential\nOrnstein-Uhlenbeck and Stein-Stein. Indeed, we show they admit the same limit\ndynamics in the regime of low fluctuations of the volatility process, under\nwhich we derive the exact expression of the characteristic function associated\nto the risk neutral probability density. This expression allows us to compute\noption prices exploiting a formula derived by Lewis and Lipton. We analyze in\ndetail the case of Plain Vanilla calls, being liquid instruments for which\nreliable implied volatility surfaces are available. We also compute the\nanalytical expressions of the first four cumulants, that are crucial to\nimplement a simple two steps calibration procedure. It has been tested against\na data set of options traded on the Milan Stock Exchange. The data analysis\nthat we present reveals a good fit with the market implied surfaces and\ncorroborates the accuracy of the linear approximation.\n"
    },
    {
        "paper_id": 905.2043,
        "authors": "Cheoljun Eom, Okyu Kwon, Woo-Sung Jung, Seunghwan Kim",
        "title": "The effect of a market factor on information flow between stocks using\n  minimal spanning tree",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2009.12.044",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We empirically investigated the effects of market factors on the information\nflow created from N(N-1)/2 linkage relationships among stocks. We also examined\nthe possibility of employing the minimal spanning tree (MST) method, which is\ncapable of reducing the number of links to N-1. We determined that market\nfactors carry important information value regarding information flow among\nstocks. Moreover, the information flow among stocks evidenced time-varying\nproperties according to the changes in market status. In particular, we noted\nthat the information flow increased dramatically during periods of market\ncrises. Finally, we confirmed, via the MST method, that the information flow\namong stocks could be assessed effectively with the reduced linkage\nrelationships among all links between stocks from the perspective of the\noverall market.\n"
    },
    {
        "paper_id": 905.2091,
        "authors": "Claudio Albanese, Harry Lo, Aleksandar Mijatovi\\'c",
        "title": "Spectral methods for volatility derivatives",
        "comments": "to appear in Quantitative Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the first quarter of 2006 Chicago Board Options Exchange (CBOE)\nintroduced, as one of the listed products, options on its implied volatility\nindex (VIX). This created the challenge of developing a pricing framework that\ncan simultaneously handle European options, forward-starts, options on the\nrealized variance and options on the VIX. In this paper we propose a new\napproach to this problem using spectral methods. We use a regime switching\nmodel with jumps and local volatility defined in \\cite{FXrev} and calibrate it\nto the European options on the S&P 500 for a broad range of strikes and\nmaturities. The main idea of this paper is to \"lift\" (i.e. extend) the\ngenerator of the underlying process to keep track of the relevant path\ninformation, namely the realized variance. The lifted generator is too large a\nmatrix to be diagonalized numerically. We overcome this difficulty by applying\na new semi-analytic algorithm for block-diagonalization. This method enables us\nto evaluate numerically the joint distribution between the underlying stock\nprice and the realized variance, which in turn gives us a way of pricing\nconsistently European options, general accrued variance payoffs and\nforward-starting and VIX options.\n"
    },
    {
        "paper_id": 905.2366,
        "authors": "Randall A. LaViolette, Lory A. Ellebracht, Kevin L. Stamber, Charles\n  J. Gieseler, Benjamin K. Cook",
        "title": "Emergence of Price Divergence in a Model Short-Term Electric Power\n  Market",
        "comments": "21 pages, 7 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A minimal model of a market of myopic non-cooperative agents who trade\nbilaterally with random bids reproduces qualitative features of short-term\nelectric power markets, such as those in California and New England. Each agent\nknows its own budget and preferences but not those of any other agent. The\nnear-equilibrium price established mid-way through the trading session diverges\nto both much higher and much lower prices towards the end of the trading\nsession. This price divergence emerges in the model without any possibility\nthat the agents could have conspired to \"game\" the market. The results were\nweakly sensitive to the endowments but strongly sensitive to the nature of the\nagent's preferences and budget constraints.\n"
    },
    {
        "paper_id": 905.2546,
        "authors": "Hamza Fekir (LEG)",
        "title": "Presentation Du Nouvel Accord De Bale Sur Les Fonds Propres",
        "comments": "22 pages",
        "journal-ref": "Revue Management- Information-Finance (MIF), Number 5, Num\\'ero\n  ISSN : 1630-1889 (2005) Revue Management- Information-Finance (MIF) Num\\'ero\n  ISSN : 1630-1889",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In order to adapt to the liberalization of the financial sphere started in\nthe Eighties, marked in particular by the end of the framing of credit, the\ndisappearance of the various forms of protection of the State whose profited\nthe banks, and the privatization of the near total of the establishments in\nEurope, the banking regulation evolved to a prudential approach, perceived like\nthe only mode of regulation not entering in contradiction with the rules of the\nmarket. The current banking regulation is pressed on the supervision, the\ndiscipline of the market and the ratios prudential; in particular the ratios of\nthe minimal own capital stocks. The object of this article is the presentation\nof the architecture of the new agreement of Basle (1999) which is based on\nthree pillars consolidating it self mutually.\n"
    },
    {
        "paper_id": 905.277,
        "authors": "Marco Bianchetti",
        "title": "Two Curves, One Price: Pricing & Hedging Interest Rate Derivatives\n  Decoupling Forwarding and Discounting Yield Curves",
        "comments": "Working paper",
        "journal-ref": "A short version of this paper is published in Risk Magazine,\n  August 2010",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We revisit the problem of pricing and hedging plain vanilla single-currency\ninterest rate derivatives using multiple distinct yield curves for market\ncoherent estimation of discount factors and forward rates with different\nunderlying rate tenors.\n  Within such double-curve-single-currency framework, adopted by the market\nafter the credit-crunch crisis started in summer 2007, standard single-curve\nno-arbitrage relations are no longer valid, and can be recovered by taking\nproperly into account the forward basis bootstrapped from market basis swaps.\nNumerical results show that the resulting forward basis curves may display a\nricher micro-term structure that may induce appreciable effects on the price of\ninterest rate instruments.\n  By recurring to the foreign-currency analogy we also derive generalised\nno-arbitrage double-curve market-like formulas for basic plain vanilla interest\nrate derivatives, FRAs, swaps, caps/floors and swaptions in particular. These\nexpressions include a quanto adjustment typical of cross-currency derivatives,\nnaturally originated by the change between the numeraires associated to the two\nyield curves, that carries on a volatility and correlation dependence.\nNumerical scenarios confirm that such correction can be non negligible, thus\nmaking unadjusted double-curve prices, in principle, not arbitrage free.\n  Both the forward basis and the quanto adjustment find a natural financial\nexplanation in terms of counterparty risk.\n"
    },
    {
        "paper_id": 905.2926,
        "authors": "Louis Paulot and Xavier Lacroze",
        "title": "One-Dimensional Pricing of CPPI",
        "comments": "19 pages; v2: improved algorithm, error analysis",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Constant Proportion Portfolio Insurance (CPPI) is an investment strategy\ndesigned to give participation in the performance of a risky asset while\nprotecting the invested capital. This protection is however not perfect and the\ngap risk must be quantified. CPPI strategies are path-dependent and may have\nAmerican exercise which makes their valuation complex. A naive description of\nthe state of the portfolio would involve three or even four variables. In this\npaper we prove that the system can be described as a discrete-time Markov\nprocess in one single variable if the underlying asset follows a homogeneous\nprocess. This yields an efficient pricing scheme using transition\nprobabilities. Our framework is flexible enough to handle most features of\ntraded CPPIs including profit lock-in and other kinds of strategies with\ndiscrete-time reallocation.\n"
    },
    {
        "paper_id": 905.3326,
        "authors": "A. Mijatovic, H. Lo",
        "title": "Volatility derivatives in market models with jumps",
        "comments": "27 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  It is well documented that a model for the underlying asset price process\nthat seeks to capture the behaviour of the market prices of vanilla options\nneeds to exhibit both diffusion and jump features. In this paper we assume that\nthe asset price process $S$ is Markov with cadlag paths and propose a scheme\nfor computing the law of the realized variance of the log returns accrued while\nthe asset was trading in a prespecified corridor. We thus obtain an algorithm\nfor pricing and hedging volatility derivatives and derivatives on the\ncorridor-realized variance in such a market. The class of models under\nconsideration is large, as it encompasses jump-diffusion and Levy processes. We\nprove the weak convergence of the scheme and describe in detail the\nimplementation of the algorithm in the characteristic cases where $S$ is a CEV\nprocess (continuous trajectories), a variance gamma process (jumps with\nindependent increments) or an infinite activity jump-diffusion (discontinuous\ntrajectories with dependent increments).\n"
    },
    {
        "paper_id": 905.3601,
        "authors": "Erhan Bayraktar, Song Yao",
        "title": "Optimal Stopping for Non-linear Expectations",
        "comments": "Key Words: Nonlinear Expectations, Optimal Stopping, Snell envelope,\n  Stability, g-expectations",
        "journal-ref": "Stochastic Processes and Their Applications (2011), Vol 121 (2),\n  185-264",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a theory for solving continuous time optimal stopping problems for\nnon-linear expectations. Our motivation is to consider problems in which the\nstopper uses risk measures to evaluate future rewards.\n"
    },
    {
        "paper_id": 905.3701,
        "authors": "Aleksandar Mijatovic, Mikhail Urusov",
        "title": "On the Martingale Property of Certain Local Martingales",
        "comments": "Appendix on local time of diffusions added; 27 pages, 1 figure; to\n  appear in PTRF",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The stochastic exponential $Z_t=\\exp\\{M_t-M_0-(1/2) <M,M>_t\\}$ of a\ncontinuous local martingale $M$ is itself a continuous local martingale. We\ngive a necessary and sufficient condition for the process $Z$ to be a true\nmartingale in the case where $M_t=\\int_0^t b(Y_u)\\,dW_u$ and $Y$ is a\none-dimensional diffusion driven by a Brownian motion $W$. Furthermore, we\nprovide a necessary and sufficient condition for $Z$ to be a uniformly\nintegrable martingale in the same setting. These conditions are deterministic\nand expressed only in terms of the function $b$ and the drift and diffusion\ncoefficients of $Y$. As an application we provide a deterministic criterion for\nthe absence of bubbles in a one-dimensional setting.\n"
    },
    {
        "paper_id": 905.3803,
        "authors": "Amit K Chattopadhyay, Graeme J Ackland, Sushanta K Mallick",
        "title": "Income and Poverty in a Developing Economy",
        "comments": null,
        "journal-ref": "Europhysics Letters 91 (2010) 58003",
        "doi": "10.1209/0295-5075/91/58003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a stochastic agent-based model for the distribution of personal\nincomes in a developing economy. We start with the assumption that incomes are\ndetermined both by individual labour and by stochastic effects of trading and\ninvestment. The income from personal effort alone is distributed about a mean,\nwhile the income from trade, which may be positive or negative, is proportional\nto the trader's income. These assumptions lead to a Langevin model with\nmultiplicative noise, from which we derive a Fokker-Planck (FP) equation for\nthe income probability density function (IPDF) and its variation in time. We\nfind that high earners have a power-law income distribution while the low\nincome groups have a Levy IPDF. Comparing our analysis with the Indian survey\ndata (obtained from the world bank website) taken over many years we obtain a\nnear-perfect data collapse onto our model's equilibrium IPDF. The theory\nquantifies the economic notion of \"given other things\". Using survey data to\nrelate the IPDF to actual food consumption we define a poverty index, which is\nconsistent with traditional indices, but independent of an arbitrarily chosen\n\"poverty line\" and therefore less susceptible to manipulation.\n"
    },
    {
        "paper_id": 905.3808,
        "authors": "Mattheos K. Protopapas, Elias B. Kosmatopoulos",
        "title": "Simulation and Use of Heuristics for Peripheral Economic Policy",
        "comments": "14 pages, Macromodels 2007 International Conference",
        "journal-ref": "In Proceedings of the 34th International Conference MACROMODELS\n  2007, Eds. Welfe & Welfe, ISBN: 978-83-924305-6-8, pp. 101-114",
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  Recent trends in Agent Computational Economics research, envelop a government\nagent in the model of the economy, whose decisions are based on learning\nalgorithms. In this paper we try to evaluate the performance of simulated\nannealing in this context, by considering a model proposed earlier in the\nliterature, which has modeled an artificial economy consisting of\ngeographically dispersed companies modeled as agents, that try to maximize\ntheir profit, which is yielded by selling an homogeneous product in different\ncities, with different travel costs. The authors have used an evolutionary\nalgorithm there, for modeling the agents' decision process. Our extension\nintroduces a government agent that tries to affect supply and demand by\ndifferent taxation coefficients in the different markets, in order to equate\nthe quantities sold in each city. We have studied the situation that occurs\nwhen a simulated annealing algorithm and a simple search algorithm is used as\nthe government's learning algorithm, and we have evaluated the comparative\nperformance of the two.\n"
    },
    {
        "paper_id": 905.387,
        "authors": "Mohamed El Hedi Arouri (LEO), Julien Fouquau (LEO)",
        "title": "On the short-term influence of oil price changes on stock markets in GCC\n  countries: linear and nonlinear analyses",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines the short-run relationships between oil prices and GCC\nstock markets. Since GCC countries are major world energy market players, their\nstock markets may be susceptible to oil price shocks. To account for the fact\nthat stock markets may respond nonlinearly to oil price shocks, we have\nexamined both linear and nonlinear relationships. Our findings show that there\nare significant links between the two variables in Qatar, Oman, and UAE. Thus,\nstock markets in these countries react positively to oil price increases. For\nBahrain, Kuwait, and Saudi Arabia we found that oil price changes do not affect\nstock market returns.\n"
    },
    {
        "paper_id": 905.3871,
        "authors": "Mohamed El Hedi Arouri (LEO)",
        "title": "A la Recherche des Facteurs D\\'eterminants de l'Int\\'egration\n  Internationale des March\\'es Boursiers : une Analyse sur Donn\\'ees de Panel",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to identify the determinants of international stock\nmarkets integration. Intuitively we selected a great number of factors linked\nto financial integration. Then, we developed an international asset-pricing\nmodel with time-varying degree of integration. This model is estimated for 30\ncountries (10 developed countries and 20 emerging countries) using panel data\neconometrics. In order to investigate whether the financial integration in\nemerging markets and that in developed markets react differently to the\neconomic and financial innovations, we estimated the model as well jointly for\nall markets as separately for developed markets and emerging markets. Our\nresults show that trade openness exerts a positive effect on financial\nintegration across all markets, the global factors drive integration in\ndeveloped markets whereas the factors related to economic and political\nstability affect financial integration in emerging markets.\n"
    },
    {
        "paper_id": 905.3873,
        "authors": "Mohamed El Hedi Arouri (LEO), Jamel Jouini (GATE)",
        "title": "Structural Breaks in the Mexico's Integration into the World Stock\n  Market",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article investigates the evolution of the Mexican stock market\nintegration into the world market. First, we estimate the time-varying Mexican\ndegree of market integration using an international conditional version of the\nCAPM with segmentation effects. Second, we study the structural breaks in this\nseries. Finally, we relate the obtained results to important facts and economic\nevents\n"
    },
    {
        "paper_id": 905.3874,
        "authors": "Fredj Jawadi (LEO), Nicolas Million, Mohamed El Hedi Arouri (LEO)",
        "title": "Stock market integration in the Latin American markets: further evidence\n  from nonlinear modeling",
        "comments": null,
        "journal-ref": "Economics Bulletin 29, 1 (2009) 162-168",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article studies the financial integration between the six main Latin\nAmerican markets and the US market in a nonlinear framework. Using the\nthreshold cointegration techniques of Hansen and Seo (2002), we show\nsignificant threshold stock market linkages between Mexico, Chile and the US.\nThus, the dynamics of these markets depends simultaneously on local and global\nrisk factors. More importantly, our results show an on-off threshold financial\nintegration process that is activated only when the stock price adjustment\nexceeds some level.\n"
    },
    {
        "paper_id": 905.3875,
        "authors": "Mohamed El Hedi Arouri (LEO)",
        "title": "Are Stock Markets Integrated? Evidence from a Partially Segmented ICAPM\n  with Asymmetric Effects",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we test a partially segmented ICAPM for two developed markets,\ntwo emerging markets and World market, using an asymmetric extension of the\nmultivariate GARCH process of De Santis and Gerard (1997,1998). We find that\nthis asymmetric process provides a significantly better fit of the data than a\nstandard symmetric process. The evidence obtained from the whole period and\nsub-periods analysis supports the financial integration hypothesis and suggests\nthat domestic risk is not a priced factor.\n"
    },
    {
        "paper_id": 905.3891,
        "authors": "Mohamed El Hedi Arouri (LEO)",
        "title": "La prime de risque dans un cadre international : le risque de change\n  est-il appr\\'eci\\'e ?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we investigate whether exchange rate risk is priced. We use\na multivariate GARCH-in-Mean specification and test alternative conditional\ninternational CAPM versions. Our results support strongly the international\nasset-pricing model that includes exchange rate risk for both developed and\nemerging stock markets. However, there are important time and cross-country\nvariations in the relative size and dynamics of different risk premia.\n"
    },
    {
        "paper_id": 905.3928,
        "authors": "Dirk Tasche",
        "title": "Estimating discriminatory power and PD curves when the number of\n  defaults is small",
        "comments": "58 pages, 10 figures, 10 tables, minor corrections",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The intention with this paper is to provide all the estimation concepts and\ntechniques that are needed to implement a two-phases approach to the parametric\nestimation of probability of default (PD) curves. In the first phase of this\napproach, a raw PD curve is estimated based on parameters that reflect\ndiscriminatory power. In the second phase of the approach, the raw PD curve is\ncalibrated to fit a target unconditional PD. The concepts and techniques\npresented include a discussion of different definitions of area under the curve\n(AUC) and accuracy ratio (AR), a simulation study on the performance of\nconfidence interval estimators for AUC, a discussion of the one-parametric\napproach to the estimation of PD curves by van der Burgt (2008) and alternative\napproaches, as well as a simulation study on the performance of the presented\nPD curve estimators. The topics are treated in depth in order to provide the\nfull rationale behind them and to produce results that can be implemented\nimmediately.\n"
    },
    {
        "paper_id": 905.4171,
        "authors": "Alan Holland",
        "title": "A Prediction Market for Toxic Assets Prices",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose the development of a prediction market for forecasting prices for\n\"toxic assets\" to be transferred from Irish banks to the National Asset\nManagement Agency (NAMA). Such a market allows market participants to assume a\nstake in a security whose value is tied to a future event. We propose that\nsecurities are created whose value hinges on the transfer amount paid for loans\nfrom NAMA to a bank. In essence, bets are accepted on whether the price is\nhigher or lower than a certain quoted figure. The prices of the securities\nrepresent transfer prices for toxic assets increases or decreases in line with\nmarket opinion. Prediction markets offer a proven means of aggregating\ndistributed knowledge pertaining to fair market values in a scalable and\ntransparent manner. They are incentive compatible (i.e. induce truthful\nreporting) and robust to strategic manipulation. We propose that a prediction\nmarket is run in parallel with the pricing procedure recommended by the\nEuropean Commission. This procedure need not necessarily take heed of the\nprediction markets view in all cases but it may offer guidance and a means of\nanomaly detection. An online prediction market would offer everybody an\nopportunity to \"have their say\" in an open and transparent manner.\n"
    },
    {
        "paper_id": 905.4237,
        "authors": "Prasanta K. Panigrahi, Sayantan Ghosh, P. Manimaran, Dilip P. Ahalpara",
        "title": "Statistical Properties of Fluctuations: A Method to Check Market\n  Behavior",
        "comments": "9 pages, 6 figures, Econophys-IV, Kolkata, 2009",
        "journal-ref": "Econophysics & Economics of Games, Social Choices and Quantitative\n  Techniques, pp.110-118, Springer-Verlag, Milan (2009)",
        "doi": "10.1007/978-88-470-1501-2_13",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the Bombay stock exchange (BSE) price index over the period of\nlast 12 years. Keeping in mind the large fluctuations in last few years, we\ncarefully find out the transient, non-statistical and locally structured\nvariations. For that purpose, we make use of Daubechies wavelet and\ncharacterize the fractal behavior of the returns using a recently developed\nwavelet based fluctuation analysis method. the returns show a fat-tail\ndistribution as also weak non-statistical behavior. We have also carried out\ncontinuous wavelet as well as Fourier power spectral analysis to characterize\nthe periodic nature and correlation properties of the time series.\n"
    },
    {
        "paper_id": 905.4272,
        "authors": "Sadraoui Tarek (URDEE), Naceur Ben Zina",
        "title": "Complementarity between private and public investment in R&D: A Dynamic\n  Panel Data analysis",
        "comments": null,
        "journal-ref": "IAENG Conferences - WCE 2009 International Conference of\n  Computational Statistics and Data Engineering, London : Royaume-Uni (2009)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the relationship between private and public\ninvestment in R&D, while taking into account the effect of several instruments\npolicies such as subsidies and taxes. We design a new look of knowledge\nspillovers and R&D cooperation to explain the contribution of public and\nprivate R&D on growth. We propose a heterogeneous dynamic panel data model to\nconsider the endogenous effect of R&D investment. We also distinguish between\nthe estimated long and short run results. Our results based on a sample of 23\ncountries over the period 1992-2004 indicate that both public and private\ninvestments in R&D are complementary. By establishing an endogenous growth\nmodel, the estimates indicate that public and private R&D depends on the host\ncountry's human capital investment. Results indicate that foreign direct\ninvestment is a more significant spillover channel than imports.\n"
    },
    {
        "paper_id": 905.445,
        "authors": "Enrique Canessa",
        "title": "Stock Market and Motion of a Variable Mass Spring",
        "comments": null,
        "journal-ref": "Physica A 388 (2009) 2168",
        "doi": "10.1016/j.physa.2009.02.010",
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  We establish an analogy between the motion of spring whose mass increases\nlinearly with time and volatile stock markets dynamics within an economic model\nbased on simple temporal demand and supply functions [J. Phys. A: Math. Gen.\n33, 3637 (2000)]. The total system energy E_t is shown to be proportional to a\ndecreasing time dependent spring constant k_t. This model allows to derive\nlog-periodicity cos[log (t-t_{c})] on commodity prices and oscillations\n(surplus and shortages) in the level of stocks. We also made an attempt to\nconnect these results to the Tsallis statistics parameter q based on a possible\nforce-entropy correlation [Physica A 341, 165 (2004)] and find that the Tsallis\nsecond entropic term \\sum_{i=1}^{W} p_i^{q}/(q-1) relates to the square of the\ndemand (or supply) function.\n"
    },
    {
        "paper_id": 905.4657,
        "authors": "Sara Biagini, Marco Frittelli, Matheus R. Grasselli",
        "title": "Indifference price with general semimartingales",
        "comments": "Submitted to Mathematical Finance on April 18, 2008",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For utility functions $u$ finite valued on $\\mathbb{R}$, we prove a duality\nformula for utility maximization with random endowment in general\nsemimartingale incomplete markets. The main novelty of the paper is that\npossibly non locally bounded semimartingale price processes are allowed.\nFollowing Biagini and Frittelli \\cite{BiaFri06}, the analysis is based on the\nduality between the Orlicz spaces $(L^{\\widehat{u}}, (L^{\\widehat{u}})^*)$\nnaturally associated to the utility function. This formulation enables several\nkey properties of the indifference price $\\pi(B)$ of a claim $B$ satisfying\nconditions weaker than those assumed in literature. In particular, the\nindifference price functional $\\pi$ turns out to be, apart from a sign, a\nconvex risk measure on the Orlicz space $L^{\\widehat{u}}$.\n"
    },
    {
        "paper_id": 905.474,
        "authors": "Mark H.A. Davis and Sebastien Lleo",
        "title": "Jump-Diffusion Risk-Sensitive Asset Management",
        "comments": "35 pages. Uses SIAM style file siamltex.cls",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers a portfolio optimization problem in which asset prices\nare represented by SDEs driven by Brownian motion and a Poisson random measure,\nwith drifts that are functions of an auxiliary diffusion 'factor' process. The\ncriterion, following earlier work by Bielecki, Pliska, Nagai and others, is\nrisk-sensitive optimization (equivalent to maximizing the expected growth rate\nsubject to a constraint on variance.) By using a change of measure technique\nintroduced by Kuroda and Nagai we show that the problem reduces to solving a\ncertain stochastic control problem in the factor process, which has no jumps.\nThe main result of the paper is that the Hamilton-Jacobi-Bellman equation for\nthis problem has a classical solution. The proof uses Bellman's \"policy\nimprovement\" method together with results on linear parabolic PDEs due to\nLadyzhenskaya et al.\n"
    },
    {
        "paper_id": 905.4793,
        "authors": "Christian H. Sanabria, R. Huerta-Quintanilla and M. Rodriguez-Achach",
        "title": "Class formation in a social network with asset exchange",
        "comments": "10 pages, 14 figures in pdf format, accepted in Physica A",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study two kinds of economic exchange, additive and multiplicative, in a\nsystem of N agents. The work is divided in two parts, in the first one, the\nagents are free to interact with each other. The system evolves to a\nBoltzmann-Gibbs distribution with additive exchange and condenses with a\nmultiplicative one. If bankruptcy is introduced, both types of exchange lead to\ncondensation. Condensation times have been studied. In the second part, the\nagents are placed in a social network. We analyze the behavior of wealth\ndistributions in time, and the formation of economic classes was observed for\ncertain values of network connectivity.\n"
    },
    {
        "paper_id": 905.4815,
        "authors": "M. Ebert, W. Paul",
        "title": "Trading leads to scale-free self-organization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets display scale-free behavior in many different aspects. The\npower-law behavior of part of the distribution of individual wealth has been\nrecognized by Pareto as early as the nineteenth century. Heavy-tailed and\nscale-free behavior of the distribution of returns of different financial\nassets have been confirmed in a series of works. The existence of a Pareto-like\ndistribution of the wealth of market participants has been connected with the\nscale-free distribution of trading volumes and price-returns. The origin of the\nPareto-like wealth distribution, however, remained obscure. Here we show that\nit is the process of trading itself that under two mild assumptions\nspontaneously leads to a self-organization of the market with a Pareto-like\nwealth distribution for the market participants and at the same time to a\nscale-free behavior of return fluctuations. These assumptions are (i) everybody\ntrades proportional to his current capacity and (ii) supply and demand\ndetermine the relative value of the goods.\n"
    },
    {
        "paper_id": 905.4912,
        "authors": "Daniel J. Fenn, Mason A. Porter, Peter J. Mucha, Mark McDonald, Stacy\n  Williams, Neil F. Johnson, Nick S. Jones",
        "title": "Dynamical Clustering of Exchange Rates",
        "comments": "31 pages, 19 figures (some with multiple parts). Section added in v2.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use techniques from network science to study correlations in the foreign\nexchange (FX) market over the period 1991--2008. We consider an FX market\nnetwork in which each node represents an exchange rate and each weighted edge\nrepresents a time-dependent correlation between the rates. To provide insights\ninto the clustering of the exchange rate time series, we investigate dynamic\ncommunities in the network. We show that there is a relationship between an\nexchange rate's functional role within the market and its position within its\ncommunity and use a node-centric community analysis to track the time dynamics\nof this role. This reveals which exchange rates dominate the market at\nparticular times and also identifies exchange rates that experienced\nsignificant changes in market role. We also use the community dynamics to\nuncover major structural changes that occurred in the FX market. Our techniques\nare general and will be similarly useful for investigating correlations in\nother markets.\n"
    },
    {
        "paper_id": 906.0208,
        "authors": "Gordan Zitkovic",
        "title": "An example of a stochastic equilibrium with incomplete markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove existence and uniqueness of stochastic equilibria in a class of\nincomplete continuous-time financial environments where the market participants\nare exponential utility maximizers with heterogeneous risk-aversion\ncoefficients and general Markovian random endowments. The incompleteness\nfeatured in our setting - the source of which can be thought of as a credit\nevent or a catastrophe - is genuine in the sense that not only the prices, but\nalso the family of replicable claims itself is determined as a part of the\nequilibrium. Consequently, equilibrium allocations are not necessarily Pareto\noptimal and the related representative-agent techniques cannot be used.\nInstead, we follow a novel route based on new stability results for a class of\nsemilinear partial differential equations related to the\nHamilton-Jacobi-Bellman equation for the agents' utility-maximization problems.\nThis approach leads to a reformulation of the problem where the Banach fixed\npoint theorem can be used not only to show existence and uniqueness, but also\nto provide a simple and efficient numerical procedure for its computation.\n"
    },
    {
        "paper_id": 906.0392,
        "authors": "A. Gulisashvili and E. M. Stein",
        "title": "Asymptotic Behavior of the Stock Price Distribution Density and Implied\n  Volatility in Stochastic Volatility Models",
        "comments": "21pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the asymptotic behavior of distribution densities arising in stock\nprice models with stochastic volatility. The main objects of our interest in\nthe present paper are the density of time averages of the squared volatility\nprocess and the density of the stock price process in the Stein-Stein and the\nHeston model. We find explicit formulas for leading terms in asymptotic\nexpansions of these densities and give error estimates. As an application of\nour results, sharp asymptotic formulas for the implied volatility in the\nStein-Stein and the Heston model are obtained.\n"
    },
    {
        "paper_id": 906.0394,
        "authors": "A. Gulisashvili",
        "title": "Asymptotic Formulas with Error Estimates for Call Pricing Functions and\n  the Implied Volatility at Extreme Strikes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we obtain asymptotic formulas with error estimates for the\nimplied volatility associated with a European call pricing function. We show\nthat these formulas imply Lee's moment formulas for the implied volatility and\nthe tail-wing formulas due to Benaim and Friz. In addition, we analyze\nPareto-type tails of stock price distributions in uncorrelated Hull-White,\nStein-Stein, and Heston models and find asymptotic formulas with error\nestimates for call pricing functions in these models.\n"
    },
    {
        "paper_id": 906.048,
        "authors": "Jaroslaw Kwapien, Sylwia Gworek, Stanislaw Drozdz, Andrzej Gorski",
        "title": "Analysis of a network structure of the foreign currency exchange market",
        "comments": null,
        "journal-ref": "J. Econ. Interact. Coord. 4, 55-72 (2009)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze structure of the world foreign currency exchange (FX) market\nviewed as a network of interacting currencies. We analyze daily time series of\nFX data for a set of 63 currencies, including gold, silver and platinum. We\ngroup together all the exchange rates with a common base currency and study\neach group separately. By applying the methods of filtered correlation matrix\nwe identify clusters of closely related currencies. The clusters are formed\ntypically according to the economical and geographical factors. We also study\ntopology of weighted minimal spanning trees for different network\nrepresentations (i.e., for different base currencies) and find that in a\nmajority of representations the network has a hierarchical scale-free\nstructure. In addition, we analyze the temporal evolution of the network and\ndetect that its structure is not stable over time. A medium-term trend can be\nidentified which affects the USD node by decreasing its centrality. Our\nanalysis shows also an increasing role of euro in the world's currency market.\n"
    },
    {
        "paper_id": 906.0658,
        "authors": "Louis Paulot",
        "title": "Asymptotic Implied Volatility at the Second Order with Application to\n  the SABR Model",
        "comments": "27 pages; v2: typos fixed and a few notation changes; v3: published\n  version, typos fixed and comments added. in Large Deviations and Asymptotic\n  Methods in Finance, Springer (2015) 37-69",
        "journal-ref": null,
        "doi": "10.1007/978-3-319-11605-1_2",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a general method to compute a Taylor expansion in time of implied\nvolatility for stochastic volatility models, using a heat kernel expansion.\nBeyond the order 0 implied volatility which is already known, we compute the\nfirst order correction exactly at all strikes from the scalar coefficient of\nthe heat kernel expansion. Furthermore, the first correction in the heat kernel\nexpansion gives the second order correction for implied volatility, which we\nalso give exactly at all strikes. As an application, we compute this asymptotic\nexpansion at order 2 for the SABR model.\n"
    },
    {
        "paper_id": 906.0678,
        "authors": "Min Dai, Zuo Quan Xu, Xun Yu Zhou",
        "title": "Continuous-Time Markowitz's Model with Transaction Costs",
        "comments": "30 pages, 1 figure",
        "journal-ref": "Siam Journal on Financial Mathematics, vol.1, 2010, pp.96-125",
        "doi": "10.1137/080742889",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A continuous-time Markowitz's mean-variance portfolio selection problem is\nstudied in a market with one stock, one bond, and proportional transaction\ncosts. This is a singular stochastic control problem,inherently in a finite\ntime horizon. With a series of transformations, the problem is turned into a\nso-called double obstacle problem, a well studied problem in physics and\npartial differential equation literature, featuring two time-varying free\nboundaries. The two boundaries, which define the buy, sell, and no-trade\nregions, are proved to be smooth in time. This in turn characterizes the\noptimal strategy, via a Skorokhod problem, as one that tries to keep a certain\nadjusted bond-stock position within the no-trade region. Several features of\nthe optimal strategy are revealed that are remarkably different from its\nno-transaction-cost counterpart. It is shown that there exists a critical\nlength in time, which is dependent on the stock excess return as well as the\ntransaction fees but independent of the investment target and the stock\nvolatility, so that an expected terminal return may not be achievable if the\nplanning horizon is shorter than that critical length (while in the absence of\ntransaction costs any expected return can be reached in an arbitrary period of\ntime). It is further demonstrated that anyone following the optimal strategy\nshould not buy the stock beyond the point when the time to maturity is shorter\nthan the aforementioned critical length. Moreover, the investor would be less\nlikely to buy the stock and more likely to sell the stock when the maturity\ndate is getting closer. These features, while consistent with the widely\naccepted investment wisdom, suggest that the planning horizon is an integral\npart of the investment opportunities.\n"
    },
    {
        "paper_id": 906.0702,
        "authors": "Min Dai, Zuo Quan Xu",
        "title": "Optimal Redeeming Strategy of Stock Loans",
        "comments": "17 pages, 4 figures",
        "journal-ref": "Mathematical Finance, Volume21, Issue4, October 2011, Pages\n  775-793",
        "doi": "10.1111/j.1467-9965.2010.00449.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A stock loan is a loan, secured by a stock, which gives the borrower the\nright to redeem the stock at any time before or on the loan maturity. The way\nof dividends distribution has a significant effect on the pricing of the stock\nloan and the optimal redeeming strategy adopted by the borrower. We present the\npricing models sub ject to various ways of dividend distribution. Since\nclosed-form price formulas are generally not available, we provide a thorough\nanalysis to examine the optimal redeeming strategy. Numerical results are\npresented as well.\n"
    },
    {
        "paper_id": 906.0999,
        "authors": "Chun Hung Chiu and Xun Yu Zhou",
        "title": "The premium of dynamic trading",
        "comments": "24 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  It is well established that in a market with inclusion of a risk-free asset\nthe single-period mean-variance efficient frontier is a straight line tangent\nto the risky region, a fact that is the very foundation of the classical CAPM.\nIn this paper, it is shown that in a continuous-time market where the risky\nprices are described by Ito's processes and the investment opportunity set is\ndeterministic (albeit time-varying), any efficient portfolio must involve\nallocation to the risk-free asset at any time. As a result, the dynamic\nmean-variance efficient frontier, though still a straight line, is strictly\nabove the entire risky region. This in turn suggests a positive premium, in\nterms of the Sharpe ratio of the efficient frontier, arising from the dynamic\ntrading. Another implication is that the inclusion of a risk-free asset boosts\nthe Sharpe ratio of the efficient frontier, which again contrasts sharply with\nthe single-period case.\n"
    },
    {
        "paper_id": 906.1387,
        "authors": "A. Zaccaria, M. Cristelli, V. Alfi, F. Ciulla, L. Pietronero",
        "title": "Asymmetric statistics of order books: The role of discreteness and\n  evidence for strategic order placement",
        "comments": "18 pages, 12 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.81.066101",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that the statistics of spreads in real order books is characterized\nby an intrinsic asymmetry due to discreteness effects for even or odd values of\nthe spread. An analysis of data from the NYSE order book points out that\ntraders' strategies contribute to this asymmetry. We also investigate this\nphenomenon in the framework of a microscopic model and, by introducing a\nnon-uniform deposition mechanism for limit orders, we are able to\nquantitatively reproduce the asymmetry found in the experimental data.\nSimulations of our model also show a realistic dynamics with a sort of\nintermittent behavior characterized by long periods in which the order book is\ncompact and liquid interrupted by volatile configurations. The order placement\nstrategies produce a non-trivial behavior of the spread relaxation dynamics\nwhich is similar to the one observed in real markets.\n"
    },
    {
        "paper_id": 906.1444,
        "authors": "Yacine A\\\"it-Sahalia, Jialin Yu",
        "title": "High frequency market microstructure noise estimates and liquidity\n  measures",
        "comments": "Published in at http://dx.doi.org/10.1214/08-AOAS200 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 1, 422-457",
        "doi": "10.1214/08-AOAS200",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using recent advances in the econometrics literature, we disentangle from\nhigh frequency observations on the transaction prices of a large sample of NYSE\nstocks a fundamental component and a microstructure noise component. We then\nrelate these statistical measurements of market microstructure noise to\nobservable characteristics of the underlying stocks and, in particular, to\ndifferent financial measures of their liquidity. We find that more liquid\nstocks based on financial characteristics have lower noise and noise-to-signal\nratio measured from their high frequency returns. We then examine whether there\nexists a common, market-wide, factor in high frequency stock-level measurements\nof noise, and whether that factor is priced in asset returns.\n"
    },
    {
        "paper_id": 906.1462,
        "authors": "Matteo Marsili",
        "title": "Spiraling toward market completeness and financial instability",
        "comments": "22 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I study the limit of a large random economy, where a set of consumers invests\nin financial instruments engineered by banks, in order to optimize their future\nconsumption. This exercise shows that, even in the ideal case of perfect\ncompetition, where full information is available to all market participants,\nthe equilibrium develops a marked vulnerability (or susceptibility) to market\nimperfections, as markets approach completeness and transaction costs vanish.\nThe decrease in transaction costs arises because financial institutions exploit\ntrading instruments to hedge other instruments. This entails trading volumes in\nthe interbank market which diverge in the limit of complete markets.\n  These results suggest that the proliferation of financial instruments\nexacerbates the effects of market imperfections, calling for theories of market\nas interacting systems. From a different perspective, in order to prevent an\nescalation of perverse effects, markets may necessitate institutional\nstructures which are more and more conspicuous as their complexity expands.\n"
    },
    {
        "paper_id": 906.1512,
        "authors": "Davide Fiaschi and Matteo Marsili",
        "title": "Economic interactions and the distribution of wealth",
        "comments": "11 pages, 1 figure. Proceedings of the conference Econophys Kolkata\n  IV",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper analyzes the equilibrium distribution of wealth in an economy\nwhere firms' productivities are subject to idiosyncratic shocks, returns on\nfactors are determined in competitive markets, dynasties have linear\nconsumption functions and government imposes taxes on capital and labour\nincomes and equally redistributes the collected resources to dynasties. The\nequilibrium distribution of wealth is explicitly calculated and its shape\ncrucially depends on market incompleteness. In particular, a Paretian law in\nthe top tail only arises if capital markets are incomplete. The Pareto exponent\ndepends on the saving rate, on the net return on capital, on the growth rate of\npopulation and on portfolio diversification. On the contrary, the\ncharacteristics of the labour market mostly affects the bottom tail of the\ndistribution of wealth. The analysis also suggests a positive relationship\nbetween growth and wealth inequality.\n"
    },
    {
        "paper_id": 906.1899,
        "authors": "Carmen Pellicer-Lostao and Ricardo Lopez-Ruiz",
        "title": "Money Distributions in Chaotic Economies",
        "comments": "5 pages, 7 figures, 1 table ; NOMA-2009 Conference, Urbino (Italy)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the ideal gas-like model of trading markets, where each\nindividual is identified as a gas molecule that interacts with others trading\nin elastic or money-conservative collisions. Traditionally this model\nintroduces different rules of random selection and exchange between pair\nagents. Real economic transactions are complex but obviously non-random.\nConsequently, unlike this traditional model, this work implements chaotic\nelements in the evolution of an economic system. In particular, we use a\nchaotic signal that breaks the natural pairing symmetry\n$(i,j)\\Leftrightarrow(j,i)$ of a random gas-like model. As a result of that, it\nis found that a chaotic market like this can reproduce the referenced wealth\ndistributions observed in real economies (the Gamma, Exponential and Pareto\ndistributions).\n"
    },
    {
        "paper_id": 906.21,
        "authors": "Irmina Czarna and Zbigniew Palmowski",
        "title": "De Finetti's dividend problem and impulse control for a two-dimensional\n  insurance risk process",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider two insurance companies (or two branches of the same company) that\nreceive premiums at different rates and then split the amount they pay in fixed\nproportions for each claim (for simplicity we assume that they are equal). We\nmodel the occurrence of claims according to a Poisson process. The ruin is\nachieved when the corresponding two-dimensional risk process first leaves the\npositive quadrant. We will consider two scenarios of the controlled process:\nrefraction and impulse control. In the first case the dividends are payed out\nwhen the two-dimensional risk process exits the fixed region. In the second\nscenario, whenever the process hits the horizontal line, it is reduced by\npaying dividends to some fixed point in the positive quadrant where it waits\nfor the next claim to arrive. In both models we calculate the discounted\ncumulative dividend payments until the ruin. This paper is the first attempt to\nunderstand the effect of dependencies of two portfolios on the joint optimal\nstrategy of paying dividends. For example in case of proportional reinsurance\none can observe the interesting phenomenon that choice of the optimal barrier\ndepends on the initial reserves. This is in contrast with the one-dimensional\nCram\\'{e}r-Lundberg model where the optimal choice of the barrier is uniform\nfor all initial reserves.\n"
    },
    {
        "paper_id": 906.2271,
        "authors": "Carl Lindberg",
        "title": "Portfolio optimization when expected stock returns are determined by\n  exposure to risk",
        "comments": "Published in at http://dx.doi.org/10.3150/08-BEJ163 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)",
        "journal-ref": "Bernoulli 2009, Vol. 15, No. 2, 464-474",
        "doi": "10.3150/08-BEJ163",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is widely recognized that when classical optimal strategies are applied\nwith parameters estimated from data, the resulting portfolio weights are\nremarkably volatile and unstable over time. The predominant explanation for\nthis is the difficulty of estimating expected returns accurately. In this\npaper, we modify the $n$ stock Black--Scholes model by introducing a new\nparametrization of the drift rates. We solve Markowitz' continuous time\nportfolio problem in this framework. The optimal portfolio weights correspond\nto keeping $1/n$ of the wealth invested in stocks in each of the $n$ Brownian\nmotions. The strategy is applied out-of-sample to a large data set. The\nportfolio weights are stable over time and obtain a significantly higher Sharpe\nratio than the classical $1/n$ strategy.\n"
    },
    {
        "paper_id": 906.3421,
        "authors": "P. Di Francesco and R. Kedem",
        "title": "Q-system Cluster Algebras, Paths and Total Positivity",
        "comments": "Testing the form interface",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review the solution of the $A_r$ Q-systems in terms of the partition\nfunction of paths on a weighted graph, and show that it is possible to modify\nthe graphs and transfer matrices so as to provide an explicit connection to the\ntheory of planar networks introduced in the context of totally positive\nmatrices by Fomin and Zelevinsky.\n"
    },
    {
        "paper_id": 906.3425,
        "authors": "Laetitia Andrieu (EDF R&D), Michel De Lara (CERMICS), Babacar Seck\n  (CERMICS)",
        "title": "Conditional Value-at-Risk Constraint and Loss Aversion Utility Functions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide an economic interpretation of the practice consisting in\nincorporating risk measures as constraints in a classic expected return\nmaximization problem. For what we call the infimum of expectations class of\nrisk measures, we show that if the decision maker (DM) maximizes the\nexpectation of a random return under constraint that the risk measure is\nbounded above, he then behaves as a ``generalized expected utility maximizer''\nin the following sense. The DM exhibits ambiguity with respect to a family of\nutility functions defined on a larger set of decisions than the original one;\nhe adopts pessimism and performs first a minimization of expected utility over\nthis family, then performs a maximization over a new decisions set. This\neconomic behaviour is called ``Maxmin under risk'' and studied by Maccheroni\n(2002). This economic interpretation allows us to exhibit a loss aversion\nfactor when the risk measure is the Conditional Value-at-Risk.\n"
    },
    {
        "paper_id": 906.3841,
        "authors": "Austin Gerig, Javier Vicente, Miguel A. Fuentes",
        "title": "Model for Non-Gaussian Intraday Stock Returns",
        "comments": "5 pages, 2 figures",
        "journal-ref": "Physical Review E 80, 065102(R) (2009)",
        "doi": "10.1103/PhysRevE.80.065102",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Stock prices are known to exhibit non-Gaussian dynamics, and there is much\ninterest in understanding the origin of this behavior. Here, we present a model\nthat explains the shape and scaling of the distribution of intraday stock price\nfluctuations (called intraday returns) and verify the model using a large\ndatabase for several stocks traded on the London Stock Exchange. We provide\nevidence that the return distribution for these stocks is non-Gaussian and\nsimilar in shape, and that the distribution appears stable over intraday time\nscales. We explain these results by assuming the volatility of returns is\nconstant intraday, but varies over longer periods such that its inverse square\nfollows a gamma distribution. This produces returns that are Student\ndistributed for intraday time scales. The predicted results show excellent\nagreement with the data for all stocks in our study and over all regions of the\nreturn distribution.\n"
    },
    {
        "paper_id": 906.3968,
        "authors": "V. Aquaro, M. Bardoscia, R. Bellotti, A. Consiglio, F. De Carlo, G.\n  Ferri",
        "title": "A Bayesian Networks Approach to Operational Risk",
        "comments": null,
        "journal-ref": "Physica A 389 (2010), pp. 1721-1728",
        "doi": "10.1016/j.physa.2009.12.043",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A system for Operational Risk management based on the computational paradigm\nof Bayesian Networks is presented. The algorithm allows the construction of a\nBayesian Network targeted for each bank using only internal loss data, and\ntakes into account in a simple and realistic way the correlations among\ndifferent processes of the bank. The internal losses are averaged over a\nvariable time horizon, so that the correlations at different times are removed,\nwhile the correlations at the same time are kept: the averaged losses are thus\nsuitable to perform the learning of the network topology and parameters. The\nalgorithm has been validated on synthetic time series. It should be stressed\nthat the practical implementation of the proposed algorithm has a small impact\non the organizational structure of a bank and requires an investment in human\nresources limited to the computational area.\n"
    },
    {
        "paper_id": 906.4092,
        "authors": "Daniel T. Cassidy (McMaster University, Department of Engineering\n  Physics, Hamilton, ON, Canada), Michael J. Hamp (Scotiabank, Toronto, ON,\n  Canada), and Rachid Ouyed (Department of Physics&Astronomy, University of\n  Calgary, Calgary, AB, Canada and Origins Institute, McMaster University,\n  Hamilton, ON, Canada)",
        "title": "Pricing European Options with a Log Student's t-Distribution: a Gosset\n  Formula",
        "comments": "12 journal pages, 9 figures and 3 tables (Submitted to Physica A)",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2010.08.037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The distribution of the returns for a stock are not well described by a\nnormal probability density function (pdf). Student's t-distributions, which\nhave fat tails, are known to fit the distributions of the returns. We present\npricing of European call or put options using a log Student's t-distribution,\nwhich we call a Gosset approach in honour of W.S. Gosset, the author behind the\nnom de plume Student. The approach that we present can be used to price\nEuropean options using other distributions and yields the Black-Scholes formula\nfor returns described by a normal pdf.\n"
    },
    {
        "paper_id": 906.4112,
        "authors": "Yu Nakayama",
        "title": "Gravity Dual for Reggeon Field Theory and Non-linear Quantum Finance",
        "comments": "31 pages",
        "journal-ref": "Int.J.Mod.Phys.A24:6197-6222,2009",
        "doi": "10.1142/S0217751X09047594",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study scale invariant but not necessarily conformal invariant deformations\nof non-relativistic conformal field theories from the dual gravity viewpoint.\nWe present the corresponding metric that solves the Einstein equation coupled\nwith a massive vector field. We find that, within the class of metric we study,\nwhen we assume the Galilean invariance, the scale invariant deformation always\npreserves the non-relativistic conformal invariance. We discuss applications to\nscaling regime of Reggeon field theory and non-linear quantum finance. These\ntheories possess scale invariance but may or may not break the conformal\ninvariance, depending on the underlying symmetry assumptions.\n"
    },
    {
        "paper_id": 906.4456,
        "authors": "Jeroen P.A. Devreese, Damiaan Lemmens, Jacques Tempere",
        "title": "Path integral approach to Asian options in the Black-Scholes model",
        "comments": "13 pages, 3 figures, updated version has added references to path\n  integral literature",
        "journal-ref": "Physica A 389, 780-788 (2010)",
        "doi": "10.1016/j.physa.2009.10.020",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive a closed-form solution for the price of an average price as well as\nan average strike geometric Asian option, by making use of the path integral\nformulation. Our results are compared to a numerical Monte Carlo simulation. We\nalso develop a pricing formula for an Asian option with a barrier on a control\nprocess, combining the method of images with a partitioning of the set of paths\naccording to the average along the path. This formula is exact when the\ncorrelation is zero, and is approximate when the correlation increases.\n"
    },
    {
        "paper_id": 906.4838,
        "authors": "Siddhivinayak Kulkarni, Imad Haidar",
        "title": "Forecasting Model for Crude Oil Price Using Artificial Neural Networks\n  and Commodity Futures Prices",
        "comments": "8 Pages, International Journal of Computer Science and Information\n  Security (IJCSIS)",
        "journal-ref": "IJCSIS June 2009 Issue, Vol. 2, No. 1",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a model based on multilayer feedforward neural network to\nforecast crude oil spot price direction in the short-term, up to three days\nahead. A great deal of attention was paid on finding the optimal ANN model\nstructure. In addition, several methods of data pre-processing were tested. Our\napproach is to create a benchmark based on lagged value of pre-processed spot\nprice, then add pre-processed futures prices for 1, 2, 3,and four months to\nmaturity, one by one and also altogether. The results on the benchmark suggest\nthat a dynamic model of 13 lags is the optimal to forecast spot price direction\nfor the short-term. Further, the forecast accuracy of the direction of the\nmarket was 78%, 66%, and 53% for one, two, and three days in future\nconclusively. For all the experiments, that include futures data as an input,\nthe results show that on the short-term, futures prices do hold new information\non the spot price direction. The results obtained will generate comprehensive\nunderstanding of the crude oil dynamic which help investors and individuals for\nrisk managements.\n"
    },
    {
        "paper_id": 906.4853,
        "authors": "Christoph Hummel",
        "title": "Shaping tail dependencies by nesting box copulas",
        "comments": "25 pages, 3 figures, added reference, remarks in Section 6, corrected\n  typos",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a family of copulas which are locally piecewise uniform in the\ninterior of the unit cube of any given dimension. Within that family, the\nsimultaneous control of tail dependencies of all projections to faces of the\ncube is possible and we give an efficient sampling algorithm. The combination\nof these two properties may be appealing to risk modellers.\n"
    },
    {
        "paper_id": 906.5249,
        "authors": "Gernot Akemann, Jonit Fischmann and Pierpaolo Vivo",
        "title": "Universal Correlations and Power-Law Tails in Financial Covariance\n  Matrices",
        "comments": "18 pages, 27 figures",
        "journal-ref": "Physica A 389 (2010) 2566-2579",
        "doi": "10.1016/j.physa.2010.02.026",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Signatures of universality are detected by comparing individual eigenvalue\ndistributions and level spacings from financial covariance matrices to random\nmatrix predictions. A chopping procedure is devised in order to produce a\nstatistical ensemble of asset-price covariances from a single instance of\nfinancial data sets. Local results for the smallest eigenvalue and individual\nspacings are very stable upon reshuffling the time windows and assets. They are\nin good agreement with the universal Tracy-Widom distribution and Wigner\nsurmise, respectively. This suggests a strong degree of robustness especially\nin the low-lying sector of the spectra, most relevant for portfolio selections.\nConversely, the global spectral density of a single covariance matrix as well\nas the average over all unfolded nearest-neighbour spacing distributions\ndeviate from standard Gaussian random matrix predictions. The data are in fair\nagreement with a recently introduced generalised random matrix model, with\ncorrelations showing a power-law decay.\n"
    },
    {
        "paper_id": 906.5489,
        "authors": "T. Shinzato and I. Kaku",
        "title": "Improved and Developed Upper Bound of Price of Anarchy in Two Echelon\n  Case",
        "comments": "12 pages, 17 figures, the proceeding of the 2nd international\n  workshop on institutional supply chain management, however the original is\n  one column",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Price of anarchy, the performance ratio, which could characterize the loss of\nefficiency of the distributed supply chain management compared with the\nintegrated supply chain management is discussed by utilizing newsvendor problem\nin single period which is well-known. In particular, some of remarkable\ndistributed policies are handled, the performance ratios in each case which\nhave been investigated in the previous works are analyzed theoretically and the\ntighter upper bound of price of anarchy and the lower bound are presented.\nFurthermore our approach is developed based on a generalized framework and a\ngeometric interpretation of price of anarchy is appeared via the literature of\nconvex optimization.\n"
    },
    {
        "paper_id": 906.5581,
        "authors": "Antonis Papapantoleon, Maria Siopacha",
        "title": "Strong Taylor approximation of stochastic differential equations and\n  application to the L\\'evy LIBOR model",
        "comments": "16 pages, 4 figures, forthcoming in the Proceedings of the Actuarial\n  and Financial Mathematics Conference, Brussels, Belgium, 2010",
        "journal-ref": "Proceedings of the Actuarial and Financial Mathematics Conference,\n  pp. 47-62, 2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we develop a method for the strong approximation of\nstochastic differential equations (SDEs) driven by L\\'evy processes or general\nsemimartingales. The main ingredients of our method is the perturbation of the\nSDE and the Taylor expansion of the resulting parameterized curve. We apply\nthis method to develop strong approximation schemes for LIBOR market models. In\nparticular, we derive fast and precise algorithms for the valuation of\nderivatives in LIBOR models which are more tractable than the simulation of the\nfull SDE. A numerical example for the L\\'evy LIBOR model illustrates our\nmethod.\n"
    },
    {
        "paper_id": 907.0554,
        "authors": "Johannes Vitalis Siven, Jeffrey Todd Lins",
        "title": "Temporal structure and gain/loss asymmetry for real and artificial stock\n  indices",
        "comments": null,
        "journal-ref": "Phys. Rev. E 80, 057102 (2009)",
        "doi": "10.1103/PhysRevE.80.057102",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We demonstrate that the gain/loss asymmetry observed for stock indices\nvanishes if the temporal dependence structure is destroyed by scrambling the\ntime series. We also show that an artificial index constructed by a simple\naverage of a number of individual stocks display gain/loss asymmetry - this\nallows us to explicitly analyze the dependence between the index constituents.\nWe consider mutual information and correlation based measures and show that the\nstock returns indeed have a higher degree of dependence in times of market\ndownturns than upturns.\n"
    },
    {
        "paper_id": 907.0645,
        "authors": "Giorgia Callegaro, Abass Sagna (PMA)",
        "title": "An application to credit risk of a hybrid Monte Carlo-Optimal\n  quantization method",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we use a hybrid Monte Carlo-Optimal quantization method to\napproximate the conditional survival probabilities of a firm, given a\nstructural model for its credit defaul, under partial information. We consider\nthe case when the firm's value is a non-observable stochastic process $(V_t)_{t\n\\geq 0}$ and inverstors in the market have access to a process $(S_t)_{t \\geq\n0}$, whose value at each time t is related to $(V_s, s \\leq t)$. We are\ninterested in the computation of the conditional survival probabilities of the\nfirm given the \"investor information\". As a application, we analyse the shape\nof the credit spread curve for zero coupon bonds in two examples.\n"
    },
    {
        "paper_id": 907.0941,
        "authors": "Peter Imkeller, Anthony R\\'eveillac, Anja Richter",
        "title": "Differentiability of quadratic BSDEs generated by continuous martingales",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP769 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 1, 285-336",
        "doi": "10.1214/11-AAP769",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider a class of BSDEs with drivers of quadratic growth,\non a stochastic basis generated by continuous local martingales. We first\nderive the Markov property of a forward--backward system (FBSDE) if the\ngenerating martingale is a strong Markov process. Then we establish the\ndifferentiability of a FBSDE with respect to the initial value of its forward\ncomponent. This enables us to obtain the main result of this article, namely a\nrepresentation formula for the control component of its solution. The latter is\nrelevant in the context of securitization of random liabilities arising from\nexogenous risk, which are optimally hedged by investment in a given financial\nmarket with respect to exponential preferences. In a purely stochastic\nformulation, the control process of the backward component of the FBSDE steers\nthe system into the random liability and describes its optimal derivative hedge\nby investment in the capital market, the dynamics of which is given by the\nforward component.\n"
    },
    {
        "paper_id": 907.1221,
        "authors": "Stefan Ankirchner (Institut fur Angewandte Mathematik), Christophette\n  Blanchet-Scalliet (ICJ), Anne Eyraud-Loisel (SAF)",
        "title": "Credit risk premia and quadratic BSDEs with a single jump",
        "comments": null,
        "journal-ref": "International Journal of Theoretical and Applied Finance (IJTAF)\n  13, 7 (2010) 1103-1129",
        "doi": "10.1142/10.1142/S0219024910006133",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is concerned with the determination of credit risk premia of\ndefaultable contingent claims by means of indifference valuation principles.\nAssuming exponential utility preferences we derive representations of\nindifference premia of credit risk in terms of solutions of Backward Stochastic\nDifferential Equations (BSDE). The class of BSDEs needed for that\nrepresentation allows for quadratic growth generators and jumps at random\ntimes. Since the existence and uniqueness theory for this class of BSDEs has\nnot yet been developed to the required generality, the first part of the paper\nis devoted to fill that gap. By using a simple constructive algorithm, and\nknown results on continuous quadratic BSDEs, we provide sufficient conditions\nfor the existence and uniqueness of quadratic BSDEs with discontinuities at\nrandom times.\n"
    },
    {
        "paper_id": 907.1827,
        "authors": "K. Bastiaensen, P. Cauwels, D. Sornette, R. Woodard, W.-X. Zhou",
        "title": "The Chinese Equity Bubble: Ready to Burst",
        "comments": "3 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Amid the current financial crisis, there has been one equity index beating\nall others: the Shanghai Composite. Our analysis of this main Chinese equity\nindex shows clear signatures of a bubble build up and we go on to predict its\nmost likely crash date: July 17-27, 2009 (20%/80% quantile confidence\ninterval).\n"
    },
    {
        "paper_id": 907.1853,
        "authors": "Hazer Inaltekin, Robert Jarrow, Mehmet Saglam and Yildiray Yildirim",
        "title": "Housing Market Microstructure",
        "comments": "This paper was presented in part at INFORMS 2007 Annual Meeting,\n  Bachelier Finance Society 2008, and AREUEA 2008. It was among the finalists\n  for the best student research paper award at INFORMS 2007. This version was\n  submitted to Management Science in November 2008",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we develop a model for the evolution of real estate prices.\nA wide range of inputs, including stochastic interest rates and changing\ndemands for the asset, are considered. Maximizing their expected utility, home\nowners make optimal sale decisions given these changing market conditions.\nUsing these optimal sale decisions, we simulate the implied evolution of\nhousing prices providing insights into the recent subprime lending crisis.\n"
    },
    {
        "paper_id": 907.2203,
        "authors": "Paul Gassiat (PMA), Huyen Pham (PMA, CREST), Mihai Sirbu",
        "title": "Optimal investment on finite horizon with random discrete order flow in\n  illiquid markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the problem of optimal portfolio selection in an illiquid market\nwith discrete order flow. In this market, bids and offers are not available at\nany time but trading occurs more frequently near a terminal horizon. The\ninvestor can observe and trade the risky asset only at exogenous random times\ncorresponding to the order flow given by an inhomogenous Poisson process. By\nusing a direct dynamic programming approach, we first derive and solve the\nfixed point dynamic programming equation satisfied by the value function, and\nthen perform a verification argument which provides the existence and\ncharacterization of optimal trading strategies. We prove the convergence of the\noptimal performance, when the deterministic intensity of the order flow\napproaches infinity at any time, to the optimal expected utility for an\ninvestor trading continuously in a perfectly liquid market model with no-short\nsale constraints.\n"
    },
    {
        "paper_id": 907.2531,
        "authors": "Fabio Bagarello",
        "title": "A quantum statistical approach to simplified stock markets",
        "comments": "in press in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2009.07.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use standard perturbation techniques originally formulated in quantum\n(statistical) mechanics in the analysis of a toy model of a stock market which\nis given in terms of bosonic operators. In particular we discuss the\nprobability of transition from a given value of the {\\em portfolio} of a\ncertain trader to a different one. This computation can also be carried out\nusing some kind of {\\em Feynman graphs} adapted to the present context.\n"
    },
    {
        "paper_id": 907.2541,
        "authors": "Y.Dolinsky, Y.Iron, Y.Kifer",
        "title": "Perfect and partial hedging for swing game options in discrete time",
        "comments": null,
        "journal-ref": "Mathematical Finance 21 (2011), 447-474",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper introduces and studies hedging for game (Israeli) style extension\nof swing options considered as multiple exercise derivatives. Assuming that the\nunderlying security can be traded without restrictions we derive a formula for\nvaluation of multiple exercise options via classical hedging arguments.\nIntroducing the notion of the shortfall risk for such options we study also\npartial hedging which leads to minimization of this risk.\n"
    },
    {
        "paper_id": 907.2866,
        "authors": "Stanislaw Drozdz, Jaroslaw Kwapien, Pawel Oswiecimka, Rafal Rak",
        "title": "Quantitative features of multifractal subtleties in time series",
        "comments": null,
        "journal-ref": "EPL 88, 60003 (2009)",
        "doi": "10.1209/0295-5075/88/60003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on the Multifractal Detrended Fluctuation Analysis (MFDFA) and on the\nWavelet Transform Modulus Maxima (WTMM) methods we investigate the origin of\nmultifractality in the time series. Series fluctuating according to a qGaussian\ndistribution, both uncorrelated and correlated in time, are used. For the\nuncorrelated series at the border (q=5/3) between the Gaussian and the Levy\nbasins of attraction asymptotically we find a phase-like transition between\nmonofractal and bifractal characteristics. This indicates that these may solely\nbe the specific nonlinear temporal correlations that organize the series into a\ngenuine multifractal hierarchy. For analyzing various features of\nmultifractality due to such correlations, we use the model series generated\nfrom the binomial cascade as well as empirical series. Then, within the\ntemporal ranges of well developed power-law correlations we find a fast\nconvergence in all multifractal measures. Besides of its practical significance\nthis fact may reflect another manifestation of a conjectured q-generalized\nCentral Limit Theorem.\n"
    },
    {
        "paper_id": 907.2926,
        "authors": "Giuseppe Campolieti and Roman N. Makarov",
        "title": "Dual Stochastic Transformations of Solvable Diffusions",
        "comments": "37 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present new extensions to a method for constructing several families of\nsolvable one-dimensional time-homogeneous diffusions whose transition densities\nare obtainable in analytically closed-form. Our approach is based on a dual\napplication of the so-called diffusion canonical transformation method that\ncombines smooth monotonic mappings and measure changes via Doob-h transforms.\nThis gives rise to new multi-parameter solvable diffusions that are generally\ndivided into two main classes; the first is specified by having affine (linear)\ndrift with various resulting nonlinear diffusion coefficient functions, while\nthe second class allows for several specifications of a (generally nonlinear)\ndiffusion coefficient with resulting nonlinear drift function. The theory is\napplicable to diffusions with either singular and/or non-singular endpoints. As\npart of the results in this paper, we also present a complete boundary\nclassification and martingale characterization of the newly developed diffusion\nfamilies.\n"
    },
    {
        "paper_id": 907.3092,
        "authors": "Nicola Cufaro Petroni and Piergiacomo Sabino",
        "title": "Pricing and Hedging Asian Basket Options with Quasi-Monte Carlo\n  Simulations",
        "comments": "16 pages",
        "journal-ref": "Methodology and Computing in Applied Probability, 2013, vol. 15,\n  p. 147-163",
        "doi": "10.1007/s11009-011-9228-9",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we consider the problem of pricing and hedging\nhigh-dimensional Asian basket options by Quasi-Monte Carlo simulation. We\nassume a Black-Scholes market with time-dependent volatilities and show how to\ncompute the deltas by the aid of the Malliavin Calculus, extending the\nprocedure employed by Montero and Kohatsu-Higa (2003). Efficient\npath-generation algorithms, such as Linear Transformation and Principal\nComponent Analysis, exhibit a high computational cost in a market with\ntime-dependent volatilities. We present a new and fast Cholesky algorithm for\nblock matrices that makes the Linear Transformation even more convenient.\nMoreover, we propose a new-path generation technique based on a Kronecker\nProduct Approximation. This construction returns the same accuracy of the\nLinear Transformation used for the computation of the deltas and the prices in\nthe case of correlated asset returns while requiring a lower computational\ntime. All these techniques can be easily employed for stochastic volatility\nmodels based on the mixture of multi-dimensional dynamics introduced by Brigo\net al. (2004).\n"
    },
    {
        "paper_id": 907.3231,
        "authors": "Karol Wawrzyniak and Wojciech Wislicki",
        "title": "Phenomenology of minority games in efficient regime",
        "comments": null,
        "journal-ref": "Advances in Complex Systems 6(2009)619",
        "doi": "10.1142/S0219525909002398",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a comprehensive study of utility function of the minority game in\nits efficient regime. We develop an effective description of state of the game.\nFor the payoff function $g(x)=\\sgn (x)$ we explicitly represent the game as the\nMarkov process and prove the finitness of number of states. We also demonstrate\nboundedness of the utility function. Using these facts we can explain all\ninteresting observable features of the aggregated demand: appearance of strong\nfluctuations, their periodicity and existence of prefered levels. For another\npayoff, $g(x)=x$, the number of states is still finite and utility remains\nbounded but the number of states cannot be reduced and probabilities of states\nare not calculated. However, using properties of the utility and analysing the\ngame in terms of de Bruijn graphs, we can also explain distinct peaks of demand\nand their frequencies.\n"
    },
    {
        "paper_id": 907.3273,
        "authors": "Kei Takeuchi and Akimichi Takemura and Masayuki Kumon",
        "title": "New procedures for testing whether stock price processes are martingales",
        "comments": null,
        "journal-ref": "Computational Economics, vol.37, No.1, 67-88, 2010",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose procedures for testing whether stock price processes are\nmartingales based on limit order type betting strategies. We first show that\nthe null hypothesis of martingale property of a stock price process can be\ntested based on the capital process of a betting strategy. In particular with\nhigh frequency Markov type strategies we find that martingale null hypotheses\nare rejected for many stock price processes.\n"
    },
    {
        "paper_id": 907.3282,
        "authors": "Takashi Kato",
        "title": "An Optimal Execution Problem with Market Impact",
        "comments": "36 pages, 8 figures, a modified version of the article \"An optimal\n  execution problem with market impact\" in Finance and Stochastics (2014)",
        "journal-ref": "Finance and Stochastics, 18(3), pp.695-732 (2014)",
        "doi": "10.1007/s00780-014-0232-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study an optimal execution problem in a continuous-time market model that\nconsiders market impact. We formulate the problem as a stochastic control\nproblem and investigate properties of the corresponding value function. We find\nthat right-continuity at the time origin is associated with the strength of\nmarket impact for large sales, otherwise the value function is continuous.\nMoreover, we show the semi-group property (Bellman principle) and characterise\nthe value function as a viscosity solution of the corresponding\nHamilton-Jacobi-Bellman equation. We introduce some examples where the forms of\nthe optimal strategies change completely, depending on the amount of the\ntrader's security holdings and where optimal strategies in the Black-Scholes\ntype market with nonlinear market impact are not block liquidation but gradual\nliquidation, even when the trader is risk-neutral.\n"
    },
    {
        "paper_id": 907.3284,
        "authors": "Xi-Yuan Qian, Wei-Xing Zhou, Gao-Feng Gu (ECUST)",
        "title": "Modified detrended fluctuation analysis based on empirical mode\n  decomposition",
        "comments": "6 RevTex pages including 5 eps figures",
        "journal-ref": "Physica A 390, 4388-4395 (2011)",
        "doi": "10.1016/j.physa.2011.07.008",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Detrended fluctuation analysis (DFA) is a simple but very efficient method\nfor investigating the power-law long-term correlations of non-stationary time\nseries, in which a detrending step is necessary to obtain the local\nfluctuations at different timescales. We propose to determine the local trends\nthrough empirical mode decomposition (EMD) and perform the detrending operation\nby removing the EMD-based local trends, which gives an EMD-based DFA method.\nSimilarly, we also propose a modified multifractal DFA algorithm, called an\nEMD-based MFDFA. The performance of the EMD-based DFA and MFDFA methods is\nassessed with extensive numerical experiments based on fractional Brownian\nmotion and multiplicative cascading process. We find that the EMD-based DFA\nmethod performs better than the classic DFA method in the determination of the\nHurst index when the time series is strongly anticorrelated and the EMD-based\nMFDFA method outperforms the traditional MFDFA method when the moment order $q$\nof the detrended fluctuations is positive. We apply the EMD-based MFDFA to the\none-minute data of Shanghai Stock Exchange Composite index, and the presence of\nmultifractality is confirmed.\n"
    },
    {
        "paper_id": 907.3301,
        "authors": "Giordano Pola and Gianni Pola",
        "title": "A stochastic reachability approach to portfolio construction in finance\n  industry",
        "comments": "15 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In finance industry portfolio construction deals with how to divide the\ninvestors' wealth across an asset-classes' menu in order to maximize the\ninvestors' gain. Main approaches in use at the present are based on variations\nof the classical Markowitz model. However, recent evolutions of the world\nmarket showed limitations of this method and motivated many researchers and\npractitioners to study alternative methodologies to portfolio construction. In\nthis paper we propose one approach to optimal portfolio construction based on\nrecent results on stochastic reachability, which overcome some of the limits of\ncurrent approaches. Given a sequence of target sets that the investors would\nlike their portfolio to stay within, the optimal portfolio allocation is\nsynthesized in order to maximize the joint probability for the portfolio value\nto fulfill the target sets requirements. A case study in the US market is given\nwhich shows benefits from the proposed methodology in portfolio construction. A\ncomparison with traditional approaches is included.\n"
    },
    {
        "paper_id": 907.4093,
        "authors": "Michel De Lara (CERMICS)",
        "title": "Preferences Yielding the \"Precautionary Effect\"",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Consider an agent taking two successive decisions to maximize his expected\nutility under uncertainty. After his first decision, a signal is revealed that\nprovides information about the state of nature. The observation of the signal\nallows the decision-maker to revise his prior and the second decision is taken\naccordingly. Assuming that the first decision is a scalar representing\nconsumption, the \\emph{precautionary effect} holds when initial consumption is\nless in the prospect of future information than without (no signal).\n\\citeauthor{Epstein1980:decision} in \\citep*{Epstein1980:decision} has provided\nthe most operative tool to exhibit the precautionary effect. Epstein's Theorem\nholds true when the difference of two convex functions is either convex or\nconcave, which is not a straightforward property, and which is difficult to\nconnect to the primitives of the economic model. Our main contribution consists\nin giving a geometric characterization of when the difference of two convex\nfunctions is convex, then in relating this to the primitive utility model. With\nthis tool, we are able to study and unite a large body of the literature on the\nprecautionary effect.\n"
    },
    {
        "paper_id": 907.4136,
        "authors": "Yan Dolinsky and Yuri Kifer",
        "title": "Binomial Approximations for Barrier Options of Israeli Style",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that prices and shortfall risks of game (Israeli) barrier options in\na sequence of binomial approximations of the Black--Scholes (BS) market\nconverge to the corresponding quantities for similar game barrier options in\nthe BS market with path dependent payoffs and the speed of convergence is\nestimated, as well. The results are new also for usual American style options\nand they are interesting from the computational point of view, as well, since\nin binomial markets these quantities can be obtained via dynamical programming\nalgorithms. The paper continues the study of [11]and [7] but requires\nsubstantial additional arguments in view of pecularities of barrier options\nwhich, in particular, destroy the regularity of payoffs needed in the above\npapers.\n"
    },
    {
        "paper_id": 907.495,
        "authors": "A. A. Brown",
        "title": "Heterogeneous Beliefs with Partial Observations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper examines a heterogeneous beliefs model in which there is a process\nthat is only partially observed by the agents. The economy contains a risky\nasset producing dividends continuously in time. The dividends are observed by\nthe agents. The dividends are assumed to be a known function of some other\nunobserved process. The agents use filtering to estimate the value of this\nunobserved process. The agents have different beliefs about the dynamics of the\nunobserved process and therefore form different estimates. We analyse this\nmodel and derive the state price density. We use this to derive the riskless\nrate. We also characterise the price of the risky asset in terms of the\nsolution of a series of differential equations.\n"
    },
    {
        "paper_id": 907.4953,
        "authors": "A. A. Brown and L. C. G. Rogers",
        "title": "Heterogeneous Beliefs with Finite-Lived Agents",
        "comments": "6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper will examine a model with many agents, each of whom has a\ndifferent belief about the dynamics of a risky asset. The agents are Bayesian\nand so learn about the asset over time. All agents are assumed to have a finite\n(but random) lifetime. When an agent dies, he passes his wealth (but not his\nknowledge) onto his heir. As a result, the agents never become sure of the\ndynamics of the risky asset. We derive expressions for the stock price and\nriskless rate. We then use numerical examples to exhibit their behaviour.\n"
    },
    {
        "paper_id": 907.4964,
        "authors": "A. A. Brown",
        "title": "A note on heterogeneous beliefs with CRRA utilities",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This note will extend the research presented in Brown & Rogers (2009) to the\ncase of CRRA agents. We consider the model outlined in that paper in which\nagents had diverse beliefs about the dividends produced by a risky asset. We\nnow assume that the agents all have CRRA utility, with some integer coefficient\nof relative risk aversion. This is a generalisation of Brown & Rogers which\nconsidered logarithmic agents. We derive expressions for the state price\ndensity, riskless rate, stock price and wealths of the agents. This sheds light\non the effects of risk aversion in an equilibrium with diverse beliefs.\n"
    },
    {
        "paper_id": 907.5276,
        "authors": "Tetsuya Takaishi",
        "title": "Bayesian Inference on QGARCH Model Using the Adaptive Construction\n  Scheme",
        "comments": "ICIS2009",
        "journal-ref": "Eighth IEEE/ACIS International Conference on Computer and\n  Information Science, (ICIS2009) 525-529",
        "doi": "10.1109/ICIS.2009.173",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the performance of the adaptive construction scheme for a Bayesian\ninference on the Quadratic GARCH model which introduces the asymmetry in time\nseries dynamics. In the adaptive construction scheme a proposal density in the\nMetropolis-Hastings algorithm is constructed adaptively by changing the\nparameters of the density to fit the posterior density. Using artificial QGARCH\ndata we infer the QGARCH parameters by applying the adaptive construction\nscheme to the Bayesian inference of QGARCH model. We find that the adaptive\nconstruction scheme samples QGARCH parameters effectively, i.e. correlations\nbetween the sampled data are very small. We conclude that the adaptive\nconstruction scheme is an efficient method to the Bayesian estimation of the\nQGARCH model.\n"
    },
    {
        "paper_id": 907.5325,
        "authors": "Jan Lorenz, Stefano Battiston, Frank Schweitzer",
        "title": "Systemic Risk in a Unifying Framework for Cascading Processes on\n  Networks",
        "comments": "43 pages, 16 multipart figures",
        "journal-ref": "European Physical Journal B, vol 71, no 4 (2009) pp. 441-460",
        "doi": "10.1140/epjb/e2009-00347-4",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a general framework for models of cascade and contagion\nprocesses on networks, to identify their commonalities and differences. In\nparticular, models of social and financial cascades, as well as the fiber\nbundle model, the voter model, and models of epidemic spreading are recovered\nas special cases. To unify their description, we define the net fragility of a\nnode, which is the difference between its fragility and the threshold that\ndetermines its failure. Nodes fail if their net fragility grows above zero and\ntheir failure increases the fragility of neighbouring nodes, thus possibly\ntriggering a cascade. In this framework, we identify three classes depending on\nthe way the fragility of a node is increased by the failure of a neighbour. At\nthe microscopic level, we illustrate with specific examples how the failure\nspreading pattern varies with the node triggering the cascade, depending on its\nposition in the network and its degree. At the macroscopic level, systemic risk\nis measured as the final fraction of failed nodes, $X^\\ast$, and for each of\nthe three classes we derive a recursive equation to compute its value. The\nphase diagram of $X^\\ast$ as a function of the initial conditions, thus allows\nfor a prediction of the systemic risk as well as a comparison of the three\ndifferent model classes. We could identify which model class lead to a\nfirst-order phase transition in systemic risk, i.e. situations where small\nchanges in the initial conditions may lead to a global failure. Eventually, we\ngeneralize our framework to encompass stochastic contagion models. This\nindicates the potential for further generalizations.\n"
    },
    {
        "paper_id": 907.5363,
        "authors": "Jean-Pierre Marco",
        "title": "Dynamical complexity and symplectic integrability",
        "comments": "58 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce two numerical conjugacy invariants for dynamical systems -- the\ncomplexity and weak complexity indices -- which are well-suited for the study\nof \"completely integrable\" Hamiltonian systems. These invariants can be seen as\n\"slow entropies\", they describe the polynomial growth rate of the number of\nballs (for the usual \"dynamical\" distances) of coverings of the ambient space.\nWe then define a new class of integrable systems, which we call decomposable\nsystems, for which one can prove that the weak complexity index is smaller than\nthe number of degrees of freedom. Hamiltonian systems integrable by means of\nnon-degenerate integrals (in Eliasson-Williamson sense), subjected to natural\nadditional assumptions, are the main examples of decomposable systems. We\nfinally give explicit examples of computation of the complexity index, for\nMorse Hamiltonian systems on surfaces and for two-dimensional gradient systems.\n"
    },
    {
        "paper_id": 907.5599,
        "authors": "Denis Belomestny",
        "title": "Pricing Bermudan options using nonparametric regression: optimal rates\n  of convergence for lower estimates",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of pricing Bermudan options using Monte Carlo and a nonparametric\nregression is considered. We derive optimal non-asymptotic bounds for a lower\nbiased estimate based on the suboptimal stopping rule constructed using some\nestimates of continuation values. These estimates may be of different nature,\nthey may be local or global, with the only requirement being that the\ndeviations of these estimates from the true continuation values can be\nuniformly bounded in probability. As an illustration, we discuss a class of\nlocal polynomial estimates which, under some regularity conditions, yield\ncontinuation values estimates possessing this property.\n"
    },
    {
        "paper_id": 907.56,
        "authors": "Anca Gheorghiu, Ion Spanulescu",
        "title": "Macrostate Parameter, an Econophysics Approach for the Risk Analysis of\n  the Stock Exchange Market Transactions",
        "comments": "15 pages, 6 figures, 25 references",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we attempt to introduce an econophysics approach to evaluate\nsome aspects of the risks in financial markets. For this purpose, the\nthermodynamical methods and statistical physics results about entropy and\nequilibrium states in the physical systems are used. Some considerations on\neconomic value and financial information are made. Finally, on this basis, a\nnew index for the financial risk estimation of the stock-exchange market\ntransactions, named macrostate parameter, was introduced and discussed.\n  Keywords: econophysics, stock-exchange markets, financial risk, informational\nfascicle, entropy, macrostate parameter.\n"
    },
    {
        "paper_id": 908.0111,
        "authors": "Lisa Borland",
        "title": "Statistical Signatures in Times of Panic: Markets as a Self-Organizing\n  System",
        "comments": "32 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study properties of the cross-sectional distribution of returns. A\nsignificant anti-correlation between dispersion and cross-sectional kurtosis is\nfound such that dispersion is high but kurtosis is low in panic times, and the\nopposite in normal times. The co-movement of stock returns also increases in\npanic times. We define a simple statistic $s$, the normalized sum of signs of\nreturns on a given day, to capture the degree of correlation in the system. $s$\ncan be seen as the order parameter of the system because if $s= 0$ there is no\ncorrelation (a disordered state), whereas for $s \\ne 0$ there is correlation\namong stocks (an ordered state). We make an analogy to non-equilibrium phase\ntransitions and hypothesize that financial markets undergo self-organization\nwhen the external volatility perception rises above some critical value.\nIndeed, the distribution of $s$ is unimodal in normal times, shifting to\nbimodal in times of panic. This is consistent with a second order phase\ntransition. Simulations of a joint stochastic process for stocks use a multi\ntimescale process in the temporal direction and an equation for the order\nparameter $s$ for the dynamics of the cross-sectional correlation. Numerical\nresults show good qualitative agreement with the stylized facts of real data,\nin both normal and panic times.\n"
    },
    {
        "paper_id": 908.0202,
        "authors": "Esteban Moro, Javier Vicente, Luis G. Moyano, Austin Gerig, J. Doyne\n  Farmer, Gabriella Vaglica, Fabrizio Lillo and Rosario N. Mantegna",
        "title": "Market impact and trading profile of large trading orders in stock\n  markets",
        "comments": "9 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.80.066102",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We empirically study the market impact of trading orders. We are specifically\ninterested in large trading orders that are executed incrementally, which we\ncall hidden orders. These are reconstructed based on information about market\nmember codes using data from the Spanish Stock Market and the London Stock\nExchange. We find that market impact is strongly concave, approximately\nincreasing as the square root of order size. Furthermore, as a given order is\nexecuted, the impact grows in time according to a power-law; after the order is\nfinished, it reverts to a level of about 0.5-0.7 of its value at its peak. We\nobserve that hidden orders are executed at a rate that more or less matches\ntrading in the overall market, except for small deviations at the beginning and\nend of the order.\n"
    },
    {
        "paper_id": 908.0348,
        "authors": "Massimo Riccaboni, Stefano Schiavo",
        "title": "The Structure and Growth of Weighted Networks",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1088/1367-2630/12/2/023003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a simple theoretical framework for the evolution of weighted\nnetworks that is consistent with a number of stylized features of real-world\ndata. In our framework, the Barabasi-Albert model of network evolution is\nextended by assuming that link weights evolve according to a geometric Brownian\nmotion. Our model is verified by means of simulations and real world trade\ndata. We show that the model correctly predicts the intensity and growth\ndistribution of links, the size-variance relationships of the growth of link\nweights, the relationship between the degree and strength of nodes, as well as\nthe scale-free structure of the network.\n"
    },
    {
        "paper_id": 908.0682,
        "authors": "Andreas Martin Lisewski",
        "title": "Global risk minimization in financial markets",
        "comments": "8 pages; 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recurring international financial crises have adverse socioeconomic effects\nand demand novel regulatory instruments or strategies for risk management and\nmarket stabilization. However, the complex web of market interactions often\nimpedes rational decisions that would absolutely minimize the risk. Here we\nshow that, for any given expected return, investors can overcome this\ncomplexity and globally minimize their financial risk in portfolio selection\nmodels, which is mathematically equivalent to computing the ground state of\nspin glass models in physics, provided the margin requirement remains below a\ncritical, empirically measurable value. For markets with centrally regulated\nmargin requirements, this result suggests a potentially stabilizing\nintervention strategy.\n"
    },
    {
        "paper_id": 908.084,
        "authors": "R. Tevzadze and T. Uzunashvili",
        "title": "Robust mean-variance hedging in the single period model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give an explicit solution of robust mean-variance hedging problem in the\nsingle period model for some type of contingent claims. The alternative\napproach is also considered.\n"
    },
    {
        "paper_id": 908.0949,
        "authors": "H. Lamba",
        "title": "A queueing theory description of fat-tailed price returns in imperfect\n  financial markets",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1140/epjb/e2010-00248-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In a financial market, for agents with long investment horizons or at times\nof severe market stress, it is often changes in the asset price that act as the\ntrigger for transactions or shifts in investment position. This suggests the\nuse of price thresholds to simulate agent behavior over much longer timescales\nthan are currently used in models of order-books.\n  We show that many phenomena, routinely ignored in efficient market theory,\ncan be systematically introduced into an otherwise efficient market, resulting\nin models that robustly replicate the most important stylized facts.\n  We then demonstrate a close link between such threshold models and queueing\ntheory, with large price changes corresponding to the busy periods of a\nsingle-server queue. The distribution of the busy periods is known to have\nexcess kurtosis and non-exponential decay under various assumptions on the\nqueue parameters. Such an approach may prove useful in the development of\nmathematical models for rapid deleveraging and panics in financial markets, and\nthe stress-testing of financial institutions.\n"
    },
    {
        "paper_id": 908.1014,
        "authors": "Jacques du Toit, Goran Peskir",
        "title": "Selling a stock at the ultimate maximum",
        "comments": "Published in at http://dx.doi.org/10.1214/08-AAP566 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 3, 983-1014",
        "doi": "10.1214/08-AAP566",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Assuming that the stock price $Z=(Z_t)_{0\\leq t\\leq T}$ follows a geometric\nBrownian motion with drift $\\mu\\in\\mathbb{R}$ and volatility $\\sigma>0$, and\nletting $M_t=\\max_{0\\leq s\\leq t}Z_s$ for $t\\in[0,T]$, we consider the optimal\nprediction problems \\[V_1=\\inf_{0\\leq\\tau\\leq\nT}\\mathsf{E}\\biggl(\\frac{M_T}{Z_{\\tau}}\\biggr)\\quadand\\quad\nV_2=\\sup_{0\\leq\\tau\\leq T}\\mathsf{E}\\biggl(\\frac{Z_{\\tau}}{M_T}\\biggr),\\] where\nthe infimum and supremum are taken over all stopping times $\\tau$ of $Z$. We\nshow that the following strategy is optimal in the first problem: if $\\mu\\leq0$\nstop immediately; if $\\mu\\in (0,\\sigma^2)$ stop as soon as $M_t/Z_t$ hits a\nspecified function of time; and if $\\mu\\geq\\sigma^2$ wait until the final time\n$T$. By contrast we show that the following strategy is optimal in the second\nproblem: if $\\mu\\leq\\sigma^2/2$ stop immediately, and if $\\mu>\\sigma^2/2$ wait\nuntil the final time $T$. Both solutions support and reinforce the widely held\nfinancial view that ``one should sell bad stocks and keep good ones.'' The\nmethod of proof makes use of parabolic free-boundary problems and local\ntime--space calculus techniques. The resulting inequalities are unusual and\ninteresting in their own right as they involve the future and as such have a\npredictive element.\n"
    },
    {
        "paper_id": 908.1082,
        "authors": "Erhan Bayraktar, Constantinos Kardaras, Hao Xing",
        "title": "Strict Local Martingale Deflators and Pricing American Call-Type Options",
        "comments": "Key Words: Strict local martingales, deflators, American call options",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We solve the problem of pricing and optimal exercise of American call-type\noptions in markets which do not necessarily admit an equivalent local\nmartingale measure. This resolves an open question proposed by Fernholz and\nKaratzas [Stochastic Portfolio Theory: A Survey, Handbook of Numerical\nAnalysis, 15:89-168, 2009].\n"
    },
    {
        "paper_id": 908.1086,
        "authors": "Erhan Bayraktar, Hao Xing",
        "title": "On the uniqueness of classical solutions of Cauchy problems",
        "comments": "Key Words and Phrases: Cauchy problem, a necessary and sufficient\n  condition for uniqueness, European call-type options, Strict local\n  martingales",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Given that the terminal condition is of at most linear growth, it is well\nknown that a Cauchy problem admits a unique classical solution when the\ncoefficient multiplying the second derivative (i.e., the volatility) is also a\nfunction of at most linear growth. In this note, we give a condition on the\nvolatility that is necessary and sufficient for a Cauchy problem to admit a\nunique solution.\n"
    },
    {
        "paper_id": 908.1089,
        "authors": "Wei-Xing Zhou (ECUST)",
        "title": "The components of empirical multifractality in financial returns",
        "comments": "6 epl pages",
        "journal-ref": "EPL 88, 28004 (2009)",
        "doi": "10.1209/0295-5075/88/28004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform a systematic investigation on the components of the empirical\nmultifractality of financial returns using the daily data of Dow Jones\nIndustrial Average from 26 May 1896 to 27 April 2007 as an example. The\ntemporal structure and fat-tailed distribution of the returns are considered as\npossible influence factors. The multifractal spectrum of the original return\nseries is compared with those of four kinds of surrogate data: (1) shuffled\ndata that contain no temporal correlation but have the same distribution, (2)\nsurrogate data in which any nonlinear correlation is removed but the\ndistribution and linear correlation are preserved, (3) surrogate data in which\nlarge positive and negative returns are replaced with small values, and (4)\nsurrogate data generated from alternative fat-tailed distributions with the\ntemporal correlation preserved. We find that all these factors have influence\non the multifractal spectrum. We also find that the temporal structure (linear\nor nonlinear) has minor impact on the singularity width $\\Delta\\alpha$ of the\nmultifractal spectrum while the fat tails have major impact on $\\Delta\\alpha$,\nwhich confirms the earlier results. In addition, the linear correlation is\nfound to have only a horizontal translation effect on the multifractal spectrum\nin which the distance is approximately equal to the difference between its DFA\nscaling exponent and 0.5. Our method can also be applied to other financial or\nphysical variables and other multifractal formalisms.\n"
    },
    {
        "paper_id": 908.1211,
        "authors": "Gerardo Hernandez-del-Valle and Carlos Pacheco-Gonzalez",
        "title": "Optimal execution of Portfolio transactions with geometric price process",
        "comments": "15 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we derive the optimal execution trajectory for a trader who\nwishes to buy or sell a large position of shares which evolve as a geometric\nBrownian process in contrast to the arithmetic model which prevails in the\nexisting literature, and with a general temporary impact $h$. We provide a\ncouple of examples which illustrate the results. We would like to stress the\nfact that in this paper we use understandable user-friendly techniques.\n"
    },
    {
        "paper_id": 908.1444,
        "authors": "Alex Dannenberg (Pine Mountain Capital Management)",
        "title": "Portfolio Optimization Under Uncertainty",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Classical mean-variance portfolio theory tells us how to construct a\nportfolio of assets which has the greatest expected return for a given level of\nreturn volatility. Utility theory then allows an investor to choose the point\nalong this efficient frontier which optimally balances her desire for excess\nexpected return against her reluctance to bear risk. The means and covariances\nof the distributions of future asset returns are assumed to be known, so the\nonly source of uncertainty is the stochastic piece of the price evolution.\n  In the real world, we have another source of uncertainty - we estimate but\ndon't know with certainty the means and covariances of future asset returns.\nThis note explains how to construct mean-variance optimal portfolios of assets\nwhose future returns have uncertain means and covariances. The result is simple\nin form, intuitive, and can easily be incorporated in an optimizer.\n"
    },
    {
        "paper_id": 908.1555,
        "authors": "Stefan Thurner, J. Doyne Farmer, John Geanakoplos",
        "title": "Leverage Causes Fat Tails and Clustered Volatility",
        "comments": "19 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We build a simple model of leveraged asset purchases with margin calls.\nInvestment funds use what is perhaps the most basic financial strategy, called\n\"value investing\", i.e. systematically attempting to buy underpriced assets.\nWhen funds do not borrow, the price fluctuations of the asset are normally\ndistributed and uncorrelated across time. All this changes when the funds are\nallowed to leverage, i.e. borrow from a bank, to purchase more assets than\ntheir wealth would otherwise permit. During good times competition drives\ninvestors to funds that use more leverage, because they have higher profits. As\nleverage increases price fluctuations become heavy tailed and display clustered\nvolatility, similar to what is observed in real markets. Previous explanations\nof fat tails and clustered volatility depended on \"irrational behavior\", such\nas trend following. Here instead this comes from the fact that leverage limits\ncause funds to sell into a falling market: A prudent bank makes itself locally\nsafer by putting a limit to leverage, so when a fund exceeds its leverage\nlimit, it must partially repay its loan by selling the asset. Unfortunately\nthis sometimes happens to all the funds simultaneously when the price is\nalready falling. The resulting nonlinear feedback amplifies large downward\nprice movements. At the extreme this causes crashes, but the effect is seen at\nevery time scale, producing a power law of price disturbances. A standard\n(supposedly more sophisticated) risk control policy in which individual banks\nbase leverage limits on volatility causes leverage to rise during periods of\nlow volatility, and to contract more quickly when volatility gets high, making\nthese extreme fluctuations even worse.\n"
    },
    {
        "paper_id": 908.1677,
        "authors": "A. Saichev, D. Sornette, V. Filimonov",
        "title": "Most Efficient Homogeneous Volatility Estimators",
        "comments": "46 pages including 17 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a comprehensive theory of homogeneous volatility (and variance)\nestimators of arbitrary stochastic processes that fully exploit the OHLC (open,\nhigh, low, close) prices. For this, we develop the theory of most efficient\npoint-wise homogeneous OHLC volatility estimators, valid for any price\nprocesses. We introduce the \"quasi-unbiased estimators\", that can address any\ntype of desirable constraints. The main tool of our theory is the parsimonious\nencoding of all the information contained in the OHLC prices for a given time\ninterval in the form of the joint distributions of the high-minus-open,\nlow-minus-open and close-minus-open values, whose analytical expression is\nderived exactly for Wiener processes with drift. The distributions can be\ncalculated to yield the most efficient estimators associated with any\nstatistical properties of the underlying log-price stochastic process. Applied\nto Wiener processes for log-prices with drift, we provide explicit analytical\nexpressions for the most efficient point-wise volatility and variance\nestimators, based on the analytical expression of the joint distribution of the\nhigh-minus-open, low-minus-open and close-minus-open values. The efficiency of\nthe new proposed estimators is favorably compared with that of the\nGarman-Klass, Roger-Satchell and maximum likelihood estimators.\n"
    },
    {
        "paper_id": 908.1879,
        "authors": "Matteo Barigozzi, Giorgio Fagiolo, Diego Garlaschelli",
        "title": "Multinetwork of international trade: A commodity-specific analysis",
        "comments": "New accepted version",
        "journal-ref": "Physical Review E 81, 046104 (2010)",
        "doi": "10.1103/PhysRevE.81.046104",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the topological properties of the multinetwork of commodity-specific\ntrade relations among world countries over the 1992-2003 period, comparing them\nwith those of the aggregate-trade network, known in the literature as the\ninternational-trade network (ITN). We show that link-weight distributions of\ncommodity-specific networks are extremely heterogeneous and (quasi) log\nnormality of aggregate link-weight distribution is generated as a sheer outcome\nof aggregation. Commodity-specific networks also display average connectivity,\nclustering, and centrality levels very different from their aggregate\ncounterpart. We also find that ITN complete connectivity is mainly achieved\nthrough the presence of many weak links that keep commodity-specific networks\ntogether and that the correlation structure existing between topological\nstatistics within each single network is fairly robust and mimics that of the\naggregate network. Finally, we employ cross-commodity correlations between link\nweights to build hierarchies of commodities. Our results suggest that on the\ntop of a relatively time-invariant ``intrinsic\" taxonomy (based on inherent\nbetween-commodity similarities), the roles played by different commodities in\nthe ITN have become more and more dissimilar, possibly as the result of an\nincreased trade specialization. Our approach is general and can be used to\ncharacterize any multinetwork emerging as a nontrivial aggregation of several\ninterdependent layers.\n"
    },
    {
        "paper_id": 908.1926,
        "authors": "Benjamin Jourdain (CERMICS), Mohamed Sbai (CERMICS)",
        "title": "High order discretization schemes for stochastic volatility models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In usual stochastic volatility models, the process driving the volatility of\nthe asset price evolves according to an autonomous one-dimensional stochastic\ndifferential equation. We assume that the coefficients of this equation are\nsmooth. Using It\\^o's formula, we get rid, in the asset price dynamics, of the\nstochastic integral with respect to the Brownian motion driving this SDE.\nTaking advantage of this structure, we propose - a scheme, based on the\nMilstein discretization of this SDE, with order one of weak trajectorial\nconvergence for the asset price, - a scheme, based on the Ninomiya-Victoir\ndiscretization of this SDE, with order two of weak convergence for the asset\nprice. We also propose a specific scheme with improved convergence properties\nwhen the volatility of the asset price is driven by an Orstein-Uhlenbeck\nprocess. We confirm the theoretical rates of convergence by numerical\nexperiments and show that our schemes are well adapted to the multilevel Monte\nCarlo method introduced by Giles [2008a, 2008b].\n"
    },
    {
        "paper_id": 908.2086,
        "authors": "Giorgio Fagiolo",
        "title": "The International-Trade Network: Gravity Equations and Topological\n  Properties",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper begins to explore the determinants of the topological properties\nof the international - trade network (ITN). We fit bilateral-trade flows using\na standard gravity equation to build a \"residual\" ITN where trade-link weights\nare depurated from geographical distance, size, border effects, trade\nagreements, and so on. We then compare the topological properties of the\noriginal and residual ITNs. We find that the residual ITN displays, unlike the\noriginal one, marked signatures of a complex system, and is characterized by a\nvery different topological architecture. Whereas the original ITN is\ngeographically clustered and organized around a few large-sized hubs, the\nresidual ITN displays many small-sized but trade-oriented countries that,\nindependently of their geographical position, either play the role of local\nhubs or attract large and rich countries in relatively complex\ntrade-interaction patterns.\n"
    },
    {
        "paper_id": 908.2455,
        "authors": "Peter G. Shepard",
        "title": "Second Order Risk",
        "comments": "23 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Managing a portfolio to a risk model can tilt the portfolio toward weaknesses\nof the model. As a result, the optimized portfolio acquires downside exposure\nto uncertainty in the model itself, what we call \"second order risk.\" We\npropose a risk measure that accounts for this bias. Studies of real portfolios,\nin asset-by-asset and factor model contexts, demonstrate that second order risk\ncontributes significantly to realized volatility, and that the proposed measure\naccurately forecasts the out-of-sample behavior of optimized portfolios.\n"
    },
    {
        "paper_id": 908.2982,
        "authors": "Tetsuya Takaishi",
        "title": "Bayesian inference with an adaptive proposal density for GARCH models",
        "comments": null,
        "journal-ref": "J. Phys.: Conf. Ser. 221 (2010) 012011",
        "doi": "10.1088/1742-6596/221/1/012011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform the Bayesian inference of a GARCH model by the Metropolis-Hastings\nalgorithm with an adaptive proposal density. The adaptive proposal density is\nassumed to be the Student's t-distribution and the distribution parameters are\nevaluated by using the data sampled during the simulation. We apply the method\nfor the QGARCH model which is one of asymmetric GARCH models and make empirical\nstudies for for Nikkei 225, DAX and Hang indexes. We find that autocorrelation\ntimes from our method are very small, thus the method is very efficient for\ngenerating uncorrelated Monte Carlo data. The results from the QGARCH model\nshow that all the three indexes show the leverage effect, i.e. the volatility\nis high after negative observations.\n"
    },
    {
        "paper_id": 908.3043,
        "authors": "Samuel E. Vazquez, Simone Farinelli",
        "title": "Gauge Invariance, Geometry and Arbitrage",
        "comments": "45 pages, 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we identify the most general measure of arbitrage for any\nmarket model governed by It\\^o processes. We show that our arbitrage measure is\ninvariant under changes of num\\'{e}raire and equivalent probability. Moreover,\nsuch measure has a geometrical interpretation as a gauge connection. The\nconnection has zero curvature if and only if there is no arbitrage. We prove an\nextension of the Martingale pricing theorem in the case of arbitrage. In our\ncase, the present value of any traded asset is given by the expectation of\nfuture cash-flows discounted by a line integral of the gauge connection. We\ndevelop simple strategies to measure arbitrage using both simulated and real\nmarket data. We find that, within our limited data sample, the market is\nefficient at time horizons of one day or longer. However, we provide strong\nevidence for non-zero arbitrage in high frequency intraday data. Such events\nseem to have a decay time of the order of one minute.\n"
    },
    {
        "paper_id": 908.3196,
        "authors": "Matheus R Grasselli and Sebastiano Silla",
        "title": "A policyholder's utility indifference valuation model for the guaranteed\n  annuity option",
        "comments": "22 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Insurance companies often include very long-term guarantees in participating\nlife insurance products, which can turn out to be very valuable. Under a\nguaranteed annuity options (G.A.O), the insurer guarantees to convert a\npolicyholder's accumulated funds to a life annuity at a fixed rated when the\npolicy matures. Both financial and actuarial approaches have been used to\nvaluate of such options. In the present work, we present an indifference\nvaluation model for the guaranteed annuity option. We are interested in the\nadditional lump sum that the policyholder is willing to pay in order to have\nthe option to convert the accumulated funds into a lifelong annuity at a\nguaranteed rate.\n"
    },
    {
        "paper_id": 908.3661,
        "authors": "Yan Dolinsky",
        "title": "Applications of weak convergence for hedging of game options",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP675 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 5, 1891-1906",
        "doi": "10.1214/09-AAP675",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider Dynkin's games with payoffs which are functions of\nan underlying process. Assuming extended weak convergence of underlying\nprocesses $\\{S^{(n)}\\}_{n=0}^{\\infty}$ to a limit process $S$ we prove\nconvergence Dynkin's games values corresponding to $\\{S^{(n)}\\}_{n=0}^{\\infty}$\nto the Dynkin's game value corresponding to $S$. We use these results to\napproximate game options prices with path dependent payoffs in continuous time\nmodels by a sequence of game options prices in discrete time models which can\nbe calculated by dynamical programming algorithms. In comparison to previous\npapers we work under more general convergence of underlying processes, as well\nas weaker conditions on the payoffs.\n"
    },
    {
        "paper_id": 908.4028,
        "authors": "Aleksandar Mijatovic and Martijn Pistorius",
        "title": "Continuously monitored barrier options under Markov processes",
        "comments": "35 pages, 5 figures, to appear in Mathematical Finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we present an algorithm for pricing barrier options in\none-dimensional Markov models. The approach rests on the construction of an\napproximating continuous-time Markov chain that closely follows the dynamics of\nthe given Markov model. We illustrate the method by implementing it for a range\nof models, including a local Levy process and a local volatility\njump-diffusion. We also provide a convergence proof and error estimates for\nthis algorithm.\n"
    },
    {
        "paper_id": 908.4299,
        "authors": "Rodanthy Tzani, Alexios P. Polychronakos",
        "title": "Correlation breakdown, copula credit default models and arbitrage",
        "comments": "15 pages",
        "journal-ref": "Published in Global Association of Risk Professionals Magazine,\n  December 2008 Issue, p.37",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The recent \"correlation breakdown\" in the modeling of credit default swaps,\nin which model correlations had to exceed 100% in order to reproduce market\nprices of supersenior tranches, is analyzed and argued to be a fundamental\nmarket inconsistency rather than an inadequacy of the specific model. As a\nconsequence, markets under such conditions are exposed to the possibility of\narbitrage. The general construction of arbitrage portfolios under specific\nconditions is presented.\n"
    },
    {
        "paper_id": 908.4538,
        "authors": "Yuping Liu, Jin Ma",
        "title": "Optimal reinsurance/investment problems for general insurance models",
        "comments": "Published in at http://dx.doi.org/10.1214/08-AAP582 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 4, 1495-1528",
        "doi": "10.1214/08-AAP582",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper the utility optimization problem for a general insurance model\nis studied. The reserve process of the insurance company is described by a\nstochastic differential equation driven by a Brownian motion and a Poisson\nrandom measure, representing the randomness from the financial market and the\ninsurance claims, respectively. The random safety loading and stochastic\ninterest rates are allowed in the model so that the reserve process is\nnon-Markovian in general. The insurance company can manage the reserves through\nboth portfolios of the investment and a reinsurance policy to optimize a\ncertain utility function, defined in a generic way. The main feature of the\nproblem lies in the intrinsic constraint on the part of reinsurance policy,\nwhich is only proportional to the claim-size instead of the current level of\nreserve, and hence it is quite different from the optimal\ninvestment/consumption problem with constraints in finance. Necessary and\nsufficient conditions for both well posedness and solvability will be given by\nmodifying the ``duality method'' in finance and with the help of the\nsolvability of a special type of backward stochastic differential equations.\n"
    },
    {
        "paper_id": 908.458,
        "authors": "Jasmina Hasanhodzic, Andrew W. Lo, Emanuele Viola",
        "title": "A Computational View of Market Efficiency",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose to study market efficiency from a computational viewpoint.\nBorrowing from theoretical computer science, we define a market to be\n\\emph{efficient with respect to resources $S$} (e.g., time, memory) if no\nstrategy using resources $S$ can make a profit. As a first step, we consider\nmemory-$m$ strategies whose action at time $t$ depends only on the $m$ previous\nobservations at times $t-m,...,t-1$. We introduce and study a simple model of\nmarket evolution, where strategies impact the market by their decision to buy\nor sell. We show that the effect of optimal strategies using memory $m$ can\nlead to \"market conditions\" that were not present initially, such as (1) market\nbubbles and (2) the possibility for a strategy using memory $m' > m$ to make a\nbigger profit than was initially possible. We suggest ours as a framework to\nrationalize the technological arms race of quantitative trading firms.\n"
    },
    {
        "paper_id": 909.0065,
        "authors": "Tomoyuki Ichiba, Vassilios Papathanakos, Adrian Banner, Ioannis\n  Karatzas, Robert Fernholz",
        "title": "Hybrid Atlas models",
        "comments": "Published in at http://dx.doi.org/10.1214/10-AAP706 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2011, Vol. 21, No. 2, 609-644",
        "doi": "10.1214/10-AAP706",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study Atlas-type models of equity markets with local characteristics that\ndepend on both name and rank, and in ways that induce a stable capital\ndistribution. Ergodic properties and rankings of processes are examined with\nreference to the theory of reflected Brownian motions in polyhedral domains. In\nthe context of such models we discuss properties of various investment\nstrategies, including the so-called growth-optimal and universal portfolios.\n"
    },
    {
        "paper_id": 909.0123,
        "authors": "Fei Ren, Wei-Xing Zhou",
        "title": "Recurrence interval analysis of high-frequency financial returns and its\n  application to risk estimation",
        "comments": "17 pages, 10 figures, 1 table",
        "journal-ref": "New J. Phys. 12 (2010) 075030",
        "doi": "10.1088/1367-2630/12/7/075030",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the probability distributions of the recurrence intervals\n$\\tau$ between consecutive 1-min returns above a positive threshold $q>0$ or\nbelow a negative threshold $q<0$ of two indices and 20 individual stocks in\nChina's stock market. The distributions of recurrence intervals for positive\nand negative thresholds are symmetric, and display power-law tails tested by\nthree goodness-of-fit measures including the Kolmogorov-Smirnov (KS) statistic,\nthe weighted KS statistic and the Cram\\'er-von Mises criterion. Both long-term\nand shot-term memory effects are observed in the recurrence intervals for\npositive and negative thresholds $q$. We further apply the recurrence interval\nanalysis to the risk estimation for the Chinese stock markets based on the\nprobability $W_q(\\Delta{t},t)$, Value-at-Risk (VaR) analysis and VaR analysis\nconditioned on preceding recurrence intervals.\n"
    },
    {
        "paper_id": 909.0418,
        "authors": "Stanislaw Drozdz, Pawel Oswiecimka",
        "title": "World stock market: more sizeable trend reversal likely in\n  February/March 2010",
        "comments": "9 pages, 10 figures, includes an extended (on Nov 12, 2009) stock\n  market forecasting scenario and a newly generated gold market scenario",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Based on our \"finance-prediction-oriented\" methodology which involves such\nelements as log-periodic self-similarity, the universal preferred scaling\nfactor lambda=2, and allows a phenomenon of the \"super-bubble\" we analyze the\n2009 world stock market (here represented by the SP500, Hang Seng and WIG)\ndevelopment. We identify elements that indicate the third decade of September\n2009 as a time limit for the present bull market phase which is thus to be\nfollowed by a significant correction. In this context we also interpret the\nChinese stock market index SSE.\n  The third decade of September 2009 was accompanied with a stock market\ncorrection typically within the range of 4-5% worldwide. Taking into account\nthe market patterns that followed the time of delivering the previous scenario\nwe present an updated scenario whose critical time corresponds to October 28,\n2009.\n  Assuming quite evident (as of November 12, 2009) termination of the\ncorrection due to the above critical time we extend - consistently with our\nmethodology - the stock market forecasting scenario. The corresponding expected\nSP500 future trend is shown in Fig. 5 and it supports a potential average\ncontinuation of increases to as far into the future as the turn of\nFebruary/March 2010. We also indicate the log-periodic patterns on the gold\nmarket and they point to the end of November 2009 as the time when the trend\nreversal - likely local however - is expected to begin.\n"
    },
    {
        "paper_id": 909.1007,
        "authors": "Zhi-Qiang Jiang, Wei-Xing Zhou, Didier Sornette, Ryan Woodard, Ken\n  Bastiaensen, Peter Cauwels",
        "title": "Bubble Diagnosis and Prediction of the 2005-2007 and 2008-2009 Chinese\n  stock market bubbles",
        "comments": "Revised version after reviewers' comments (28 pages, 20 figures)",
        "journal-ref": "Journal of Economic Behavior & Organization 74 (3), 149-162 (2010)",
        "doi": "10.1016/j.jebo.2010.02.007",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By combining (i) the economic theory of rational expectation bubbles, (ii)\nbehavioral finance on imitation and herding of investors and traders and (iii)\nthe mathematical and statistical physics of bifurcations and phase transitions,\nthe log-periodic power law model has been developed as a flexible tool to\ndetect bubbles. The LPPL model considers the faster-than-exponential (power law\nwith finite-time singularity) increase in asset prices decorated by\naccelerating oscillations as the main diagnostic of bubbles. It embodies a\npositive feedback loop of higher return anticipations competing with negative\nfeedback spirals of crash expectations. We use the LPPL model in one of its\nincarnations to analyze two bubbles and subsequent market crashes in two\nimportant indexes in the Chinese stock markets between May 2005 and July 2009.\nBoth the Shanghai Stock Exchange Composite and Shenzhen Stock Exchange\nComponent indexes exhibited such behavior in two distinct time periods: 1) from\nmid-2005, bursting in Oct. 2007 and 2) from Nov. 2008, bursting in the\nbeginning of Aug. 2009. We successfully predicted time windows for both crashes\nin advance with the same methods used to successfully predict the peak in\nmid-2006 of the US housing bubble and the peak in July 2008 of the global oil\nbubble. The more recent bubble in the Chinese indexes was detected and its end\nor change of regime was predicted independently by two groups with similar\nresults, showing that the model has been well-documented and can be replicated\nby industrial practitioners. Here we present more detailed analysis of the\nindividual Chinese index predictions and of the methods used to make and test\nthem.\n"
    },
    {
        "paper_id": 909.1142,
        "authors": "Alec N. Kercheval, Juan F. Moreno",
        "title": "Optimal intervention in the foreign exchange market when interventions\n  affect market dynamics",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We address the problem of optimal Central Bank intervention in the exchange\nrate market when interventions create feedback in the rate dynamics. In\nparticular, we extend the work done on optimal impulse control by Cadenillas\nand Zapatero to incorporate temporary market reactions, of random duration and\nlevel, to Bank interventions, and to establish results for more general rate\nprocesses. We obtain new explicit optimal impulse control strategies that\naccount for these market reactions, and show that they cannot be obtained\nsimply by adjusting the intervention cost in a model without market reactions.\n"
    },
    {
        "paper_id": 909.1383,
        "authors": "Ivailo I. Dimov, Petter N. Kolm, Lee Maclin, and Dan Y. C. Shiber",
        "title": "Hidden Noise Structure and Random Matrix Models of Stock Correlations",
        "comments": "4 pages, 3 figures: author initials added, references added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We find a novel correlation structure in the residual noise of stock market\nreturns that is remarkably linked to the composition and stability of the top\nfew significant factors driving the returns, and moreover indicates that the\nnoise band is composed of multiple subbands that do not fully mix. Our findings\nallow us to construct effective generalized random matrix theory market models\nthat are closely related to correlation and eigenvector clustering. We show how\nto use these models in a simulation that incorporates heavy tails. Finally, we\ndemonstrate how a subtle purely stationary risk estimation bias can arise in\nthe conventional cleaning prescription.\n"
    },
    {
        "paper_id": 909.1478,
        "authors": "Tetsuya Takaishi",
        "title": "Markov Chain Monte Carlo on Asymmetric GARCH Model Using the Adaptive\n  Construction Scheme",
        "comments": "10 pages, 5 figures",
        "journal-ref": "Lecture Notes in Computer Science, 2009, Volume 5754/2009,\n  1112-1121",
        "doi": "10.1007/978-3-642-04070-2_117",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We perform Markov chain Monte Carlo simulations for a Bayesian inference of\nthe GJR-GARCH model which is one of asymmetric GARCH models. The adaptive\nconstruction scheme is used for the construction of the proposal density in the\nMetropolis-Hastings algorithm and the parameters of the proposal density are\ndetermined adaptively by using the data sampled by the Markov chain Monte Carlo\nsimulation. We study the performance of the scheme with the artificial\nGJR-GARCH data. We find that the adaptive construction scheme samples GJR-GARCH\nparameters effectively and conclude that the Metropolis-Hastings algorithm with\nthe adaptive construction scheme is an efficient method to the Bayesian\ninference of the GJR-GARCH model.\n"
    },
    {
        "paper_id": 909.169,
        "authors": "T.Bisig, A.Dupuis, V.Impagliazzo and R.B.Olsen",
        "title": "The scale of market quakes",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We define a methodology to quantify market activity on a 24 hour basis by\ndefining a scale, the so-called scale of market quakes (SMQ). The SMQ is\ndesigned within a framework where we analyse the dynamics of excess price moves\nfrom one directional change of price to the next. We use the SMQ to quantify\nthe FX market and evaluate the performance of the proposed methodology at major\nnews announcements. The evolution of SMQ magnitudes from 2003 to 2009 is\nanalysed across major currency pairs.\n"
    },
    {
        "paper_id": 909.1974,
        "authors": "Anirban Chakraborti, Ioane Muni Toke, Marco Patriarca and Frederic\n  Abergel",
        "title": "Econophysics: Empirical facts and agent-based models",
        "comments": "51 pages REVTeX format, review paper submitted to Quantitative\n  Finance",
        "journal-ref": "Quantitative Finance 11, 991-1012 (2011); Quantitative Finance 11,\n  1013-1041 (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article aims at reviewing recent empirical and theoretical developments\nusually grouped under the term Econophysics. Since its name was coined in 1995\nby merging the words Economics and Physics, this new interdisciplinary field\nhas grown in various directions: theoretical macroeconomics (wealth\ndistributions), microstructure of financial markets (order book modelling),\neconometrics of financial bubbles and crashes, etc. In the first part of the\nreview, we discuss on the emergence of Econophysics. Then we present empirical\nstudies revealing statistical properties of financial time series. We begin the\npresentation with the widely acknowledged stylized facts which describe the\nreturns of financial assets- fat tails, volatility clustering, autocorrelation,\netc.- and recall that some of these properties are directly linked to the way\ntime is taken into account. We continue with the statistical properties\nobserved on order books in financial markets. For the sake of illustrating this\nreview, (nearly) all the stated facts are reproduced using our own\nhigh-frequency financial database. Finally, contributions to the study of\ncorrelations of assets such as random matrix theory and graph theory are\npresented. In the second part of the review, we deal with models in\nEconophysics through the point of view of agent-based modelling. Amongst a\nlarge number of multi-agent-based models, we have identified three\nrepresentative areas. First, using previous work originally presented in the\nfields of behavioural finance and market microstructure theory, econophysicists\nhave developed agent-based models of order-driven markets that are extensively\npresented here. Second, kinetic theory models designed to explain some\nempirical facts on wealth distribution are reviewed. Third, we briefly\nsummarize game theory models by reviewing the now classic minority game and\nrelated problems.\n"
    },
    {
        "paper_id": 909.2341,
        "authors": "Erik Taflin",
        "title": "Generalized integrands and bond portfolios: Pitfalls and counter\n  examples",
        "comments": "Published in at http://dx.doi.org/10.1214/10-AAP694 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2011, Vol. 21, No. 1, 266-282",
        "doi": "10.1214/10-AAP694",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct Zero-Coupon Bond markets driven by a cylindrical Brownian motion\nin which the notion of generalized portfolio has important flaws: There exist\nbounded smooth random variables with generalized hedging portfolios for which\nthe price of their risky part is $+\\infty$ at each time. For these generalized\nportfolios, sequences of the prices of the risky part of approximating\nportfolios can be made to converges to any given extended real number in\n$[-\\infty,\\infty].$\n"
    },
    {
        "paper_id": 909.2624,
        "authors": "Romuald Elie (CREST, Ceremade)",
        "title": "Double Kernel estimation of sensitivities",
        "comments": null,
        "journal-ref": "Journal of Applied Probability 46, 3 (2009)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper adresses the general issue of estimating the sensitivity of the\nexpectation of a random variable with respect to a parameter characterizing its\nevolution. In finance for example, the sensitivities of the price of a\ncontingent claim are called the Greeks. A new way of estimating the Greeks has\nbeen recently introduced by Elie, Fermanian and Touzi through a randomization\nof the parameter of interest combined with non parametric estimation\ntechniques. This paper studies another type of those estimators whose interest\nis to be closely related to the score function, which is well known to be the\noptimal Greek weight. This estimator relies on the use of two distinct kernel\nfunctions and the main interest of this paper is to provide its asymptotic\nproperties. Under a little more stringent condition, its rate of convergence\nequals the one of those introduced by Elie, Fermanian and Touzi and outperforms\nthe finite differences estimator. In addition to the technical interest of the\nproofs, this result is very encouraging in the dynamic of creating new type of\nestimators for sensitivities.\n"
    },
    {
        "paper_id": 909.2885,
        "authors": "Frederic Abergel, Nicolas Huth, Ioane Muni Toke",
        "title": "Financial bubbles analysis with a cross-sectional estimator",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We highlight a very simple statistical tool for the analysis of financial\nbubbles, which has already been studied in [1]. We provide extensive empirical\ntests of this statistical tool and investigate analytically its link with\nstocks correlation structure.\n"
    },
    {
        "paper_id": 909.3219,
        "authors": "Xavier De Scheemaekere",
        "title": "Upper and lower bounds on dynamic risk indifference prices in incomplete\n  markets",
        "comments": "This is a shorter, thoroughly modified and rewritten version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the context of an incomplete market with a Brownian filtration and a fixed\nfinite time horizon, this paper proves that for general dynamic convex risk\nmeasures, the buyer's and seller's risk indifference prices of a contingent\nclaim are bounded from below and above by the dynamic lower and upper hedging\nprices, respectively.\n"
    },
    {
        "paper_id": 909.3244,
        "authors": "Fulvio Baldovin, Dario Bovina, Francesco Camana, and Attilio L. Stella",
        "title": "Modeling the non-Markovian, non-stationary scaling dynamics of financial\n  markets",
        "comments": "Throughout revision. 15 pages, 6 figures. Presented by A.L. Stella in\n  a Talk at the \"Econophysics - Kolkata V'' International Workshop, March 2010,\n  Saha Institute of Nuclear Physics, Kolkata, India",
        "journal-ref": null,
        "doi": "10.1007/978-88-470-1766-5_16",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A central problem of Quantitative Finance is that of formulating a\nprobabilistic model of the time evolution of asset prices allowing reliable\npredictions on their future volatility. As in several natural phenomena, the\npredictions of such a model must be compared with the data of a single process\nrealization in our records. In order to give statistical significance to such a\ncomparison, assumptions of stationarity for some quantities extracted from the\nsingle historical time series, like the distribution of the returns over a\ngiven time interval, cannot be avoided. Such assumptions entail the risk of\nmasking or misrepresenting non-stationarities of the underlying process, and of\ngiving an incorrect account of its correlations. Here we overcome this\ndifficulty by showing that five years of daily Euro/US-Dollar trading records\nin the about three hours following the New York market opening, provide a rich\nenough ensemble of histories. The statistics of this ensemble allows to propose\nand test an adequate model of the stochastic process driving the exchange rate.\nThis turns out to be a non-Markovian, self-similar process with non-stationary\nreturns. The empirical ensemble correlators are in agreement with the\npredictions of this model, which is constructed on the basis of the\ntime-inhomogeneous, anomalous scaling obeyed by the return distribution.\n"
    },
    {
        "paper_id": 909.3363,
        "authors": "Magdalena Kobylanski (LAMA), Marie-Claire Quenez (PMA), Elisabeth\n  Rouy-Mironescu (ICJ)",
        "title": "Optimal double stopping time",
        "comments": "6 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the optimal double stopping time problem defined for each\nstopping time $S$ by $v(S)=\\esssup\\{E[\\psi(\\tau_1, \\tau_2) | \\F_S], \\tau_1,\n\\tau_2 \\geq S \\}$. Following the optimal one stopping time problem, we study\nthe existence of optimal stopping times and give a method to compute them. The\nkey point is the construction of a {\\em new reward} $\\phi$ such that the value\nfunction $v(S)$ satisfies $v(S)=\\esssup\\{E[\\phi(\\tau) | \\F_S], \\tau \\geq S \\}$.\nFinally, we give an example of an american option with double exercise time.\n"
    },
    {
        "paper_id": 909.3441,
        "authors": "Alex Langnau",
        "title": "Introduction into \"Local Correlation Modelling\"",
        "comments": "Keywords: implied correlation, local correlation, stochastic\n  correlation, correlation skew, index skew, basket options, multi-asset Dupire\n  model, multi-asset local vol",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we provide evidence that financial option markets for equity\nindices give rise to non-trivial dependency structures between its\nconstituents. Thus, if the individual constituent distributions of an equity\nindex are inferred from the single-stock option markets and combined via a\nGaussian copula, for example, one fails to explain the steepness of the\nobserved volatility skew of the index. Intuitively, index option prices are\nencoding higher correlations in cases where the option is particularly\nsensitive to stress scenarios of the market. As a result, more complex\ndependency structures emerge than the ones described by Gaussian copulas or\n(state-independent) linear correlation structures.\n  In this paper we \"decode\" the index option market and extract this\ncorrelation information in order to extend the multi-asset version of Dupire's\n\"local volatility\" model by making correlations a dynamic variable of the\nmarket. A \"local correlation\" model (LCM) is introduced for the pricing of\nmulti-asset derivatives. We show how consistency with the index volatility data\ncan be achieved by construction.\n  LCM achieves consistency with both the constituent- and index option markets\nby construction while preserving the efficiency and easy implementation of\nDupire's model.\n"
    },
    {
        "paper_id": 909.3482,
        "authors": "Stefan Thurner, Peter Klimek, Rudolf Hanel",
        "title": "Schumpeterian economic dynamics as a quantifiable minimum model of\n  evolution",
        "comments": "21 pages, 11 figures",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/12/7/075029",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a simple quantitative model of Schumpeterian economic dynamics.\nNew goods and services are endogenously produced through combinations of\nexisting goods. As soon as new goods enter the market they may compete against\nalready existing goods, in other words new products can have destructive\neffects on existing goods. As a result of this competition mechanism existing\ngoods may be driven out from the market - often causing cascades of secondary\ndefects (Schumpeterian gales of destruction). The model leads to a generic\ndynamics characterized by phases of relative economic stability followed by\nphases of massive restructuring of markets - which could be interpreted as\nSchumpeterian business `cycles'. Model timeseries of product diversity and\nproductivity reproduce several stylized facts of economics timeseries on long\ntimescales such as GDP or business failures, including non-Gaussian fat tailed\ndistributions, volatility clustering etc. The model is phrased in an open,\nnon-equilibrium setup which can be understood as a self organized critical\nsystem. Its diversity dynamics can be understood by the time-varying topology\nof the active production networks.\n"
    },
    {
        "paper_id": 909.357,
        "authors": "Denis Belomestny",
        "title": "On the rates of convergence of simulation based optimization algorithms\n  for optimal stopping problems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/3.0/",
        "abstract": "  In this paper we study simulation based optimization algorithms for solving\ndiscrete time optimal stopping problems. This type of algorithms became popular\namong practioneers working in the area of quantitative finance. Using large\ndeviation theory for the increments of empirical processes, we derive optimal\nconvergence rates and show that they can not be improved in general. The rates\nderived provide a guide to the choice of the number of simulated paths needed\nin optimization step, which is crucial for the good performance of any\nsimulation based optimization algorithm. Finally, we present a numerical\nexample of solving optimal stopping problem arising in option pricing that\nillustrates our theoretical findings.\n"
    },
    {
        "paper_id": 909.3655,
        "authors": "Roman Naryshkin and Matt Davison",
        "title": "Utility Function and Optimum Consumption in the models with Habit\n  Formation and Catching up with the Joneses",
        "comments": "11 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper analyzes popular time-nonseparable utility functions that describe\n\"habit formation\" consumer preferences comparing current consumption with the\ntime averaged past consumption of the same individual and \"catching up with the\nJoneses\" (CuJ) models comparing individual consumption with a cross-sectional\naverage consumption level.\n  Few of these models give reasonable optimum consumption time series. We\nintroduce theoretically justified utility specifications leading to a plausible\nconsumption behavior to show that habit formation preferences must be described\nby a power CRRA utility function different from the exponential CARA used for\nCuJ.\n"
    },
    {
        "paper_id": 909.389,
        "authors": "Cesar A. Hidalgo, Ricardo Hausmann",
        "title": "The Building Blocks of Economic Complexity",
        "comments": "20 Pages (double space), 4 figures",
        "journal-ref": "Proc. Natl. Acad. Sci. (2009) 106(26):10570-10575",
        "doi": "10.1073/pnas.0900943106",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For Adam Smith, wealth was related to the division of labor. As people and\nfirms specialize in different activities, economic efficiency increases,\nsuggesting that development is associated with an increase in the number of\nindividual activities and with the complexity that emerges from the\ninteractions between them. Here we develop a view of economic growth and\ndevelopment that gives a central role to the complexity of a country's economy\nby interpreting trade data as a bipartite network in which countries are\nconnected to the products they export, and show that it is possible to quantify\nthe complexity of a country's economy by characterizing the structure of this\nnetwork. Furthermore, we show that the measures of complexity we derive are\ncorrelated with a country's level of income, and that deviations from this\nrelationship are predictive of future growth. This suggests that countries tend\nto converge to the level of income dictated by the complexity of their\nproductive structures, indicating that development efforts should focus on\ngenerating the conditions that would allow complexity to emerge in order to\ngenerate sustained growth and prosperity.\n"
    },
    {
        "paper_id": 909.3891,
        "authors": "Michael J. Neely",
        "title": "Stock Market Trading Via Stochastic Network Optimization",
        "comments": "14 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of dynamic buying and selling of shares from a\ncollection of $N$ stocks with random price fluctuations. To limit investment\nrisk, we place an upper bound on the total number of shares kept at any time.\nAssuming that prices evolve according to an ergodic process with a mild\ndecaying memory property, and assuming constraints on the total number of\nshares that can be bought and sold at any time, we develop a trading policy\nthat comes arbitrarily close to achieving the profit of an ideal policy that\nhas perfect knowledge of future events. Proximity to the optimal profit comes\nwith a corresponding tradeoff in the maximum required stock level and in the\ntimescales associated with convergence. We then consider arbitrary (possibly\nnon-ergodic) price processes, and show that the same algorithm comes close to\nthe profit of a frame based policy that can look a fixed number of slots into\nthe future. Our analysis uses techniques of Lyapunov Optimization that we\noriginally developed for stochastic network optimization problems.\n"
    },
    {
        "paper_id": 909.3978,
        "authors": "G. Bormetti, V. Cazzola, G. Livan, G. Montagna and O. Nicrosini",
        "title": "A Generalized Fourier Transform Approach to Risk Measures",
        "comments": "Feller's condition removed, some typos in Appendix A amended",
        "journal-ref": "J. Stat. Mech. (2010) P01005",
        "doi": "10.1088/1742-5468/2010/01/P01005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce the formalism of generalized Fourier transforms in the context\nof risk management. We develop a general framework to efficiently compute the\nmost popular risk measures, Value-at-Risk and Expected Shortfall (also known as\nConditional Value-at-Risk). The only ingredient required by our approach is the\nknowledge of the characteristic function describing the financial data in use.\nThis allows to extend risk analysis to those non-Gaussian models defined in the\nFourier space, such as Levy noise driven processes and stochastic volatility\nmodels. We test our analytical results on data sets coming from various\nfinancial indexes, finding that our predictions outperform those provided by\nthe standard Log-Normal dynamics and are in remarkable agreement with those of\nthe benchmark historical approach.\n"
    },
    {
        "paper_id": 909.3984,
        "authors": "Abhijit Chakraborty and S. S. Manna",
        "title": "Weighted Trade Network in a Model of Preferential Bipartite Transactions",
        "comments": "8 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.81.016111",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Using a model of wealth distribution where traders are characterized by\nquenched random saving propensities and trade among themselves by bipartite\ntransactions, we mimic the enhanced rates of trading of the rich by introducing\nthe preferential selection rule using a pair of continuously tunable\nparameters. The bipartite trading defines a growing trade network of traders\nlinked by their mutual trade relationships. With the preferential selection\nrule this network appears to be highly heterogeneous characterized by the\nscale-free nodal degree and the link weight distributions and presents\nsignatures of non-trivial strength-degree correlations. With detailed numerical\nsimulations and using finite-size scaling analysis we present evidence that the\nassociated critical exponents are continuous functions of the tuning\nparameters. However the wealth distribution has been observed to follow the\nwell-known Pareto law robustly for all positive values of the tuning\nparameters.\n"
    },
    {
        "paper_id": 909.4089,
        "authors": "Jacek Jakubowski, Mariusz Nieweglowski",
        "title": "Defaultable bonds with an infinite number of Levy factors",
        "comments": "24 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A market with defaultable bonds where the bond dynamics is in a\nHeath-Jarrow-Morton setting and the forward rates are driven by an infinite\nnumber of Levy factors is considered. The setting includes rating migrations\ndriven by a Markov chain. All basic types of recovery are investigated. We\nformulate necessary and sufficient conditions (generalized HJM conditions)\nunder which the market is arbitrage free. Connections with consistency\nconditions are discussed.\n"
    },
    {
        "paper_id": 909.473,
        "authors": "Wael Bahsoun, Igor V. Evstigneev and Michael I. Taksar",
        "title": "Growth-optimal investments and numeraire portfolios under transaction\n  costs: An analysis based on the von Neumann-Gale model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this work is to extend the capital growth theory developed by\nKelly, Breiman, Cover and others to asset market models with transaction costs.\nWe define a natural generalization of the notion of a numeraire portfolio\nproposed by Long and show how such portfolios can be used for constructing\ngrowth-optimal investment strategies. The analysis is based on the classical\nvon Neumann-Gale model of economic dynamics, a stochastic version of which we\nuse as a framework for the modelling of financial markets with frictions.\n"
    },
    {
        "paper_id": 909.4765,
        "authors": "Jacek Jakubowski and Maciej Wisniewolski",
        "title": "Linear stochastic volatility models",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we investigate general linear stochastic volatility models with\ncorrelated Brownian noises. In such models the asset price satisfies a linear\nSDE with coefficient of linearity being the volatility process. This class\ncontains among others Black-Scholes model, a log-normal stochastic volatility\nmodel and Heston stochastic volatility model. For a linear stochastic\nvolatility model we derive representations for the probability density function\nof the arbitrage price of a financial asset and the prices of European call and\nput options.\n  A closed-form formulae for the density function and the prices of European\ncall and put options are given for log-normal stochastic volatility model. We\nalso obtain present some new results for Heston and extended Heston stochastic\nvolatility models.\n"
    },
    {
        "paper_id": 909.4815,
        "authors": "Vladimir Belitsky, Antonio L. Pereira, Fernando P. de Almeida Prado",
        "title": "Stability analysis with applications of a two-dimensional dynamical\n  system arising from a stochastic model of an asset market",
        "comments": "LaTeX, 32 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the stability properties of equilibrium solutions and periodicity\nof orbits in a two-dimensional dynamical system whose orbits mimic the\nevolution of the price of an asset and the excess demand for that asset. The\nconstruction of the system is grounded upon a heterogeneous interacting agent\nmodel for a single risky asset market. An advantage of this construction\nprocedure is that the resulting dynamical system becomes a macroscopic market\nmodel which mirrors the market quantities and qualities that would typically be\ntaken into account solely at the microscopic level of modeling. The system's\nparameters correspond to: (a) the proportion of speculators in a market; (b)\nthe traders' speculative trend; (c) the degree of heterogeneity of\nidiosyncratic evaluations of the market agents with respect to the asset's\nfundamental value; and (d) the strength of the feedback of the population\nexcess demand on the asset price update increment. This correspondence allows\nus to employ our results in order to infer plausible causes for the emergence\nof price and demand fluctuations in a real asset market.\n  The employment of dynamical systems for studying evolution of stochastic\nmodels of socio-economic phenomena is quite usual in the area of heterogeneous\ninteracting agent models. However, in the vast majority of the cases present in\nthe literature, these dynamical systems are one-dimensional. Our work is among\nthe few in the area that construct and study two-dimensional dynamical systems\nand apply them for explanation of socio-economic phenomena.\n"
    },
    {
        "paper_id": 909.4948,
        "authors": "Erhan Bayraktar, Ioannis Karatzas, Song Yao",
        "title": "Optimal Stopping for Dynamic Convex Risk Measures",
        "comments": "Keywords: Convex risk measures, continuous-time optimal stopping,\n  robustness methods",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use martingale and stochastic analysis techniques to study a\ncontinuous-time optimal stopping problem, in which the decision maker uses a\ndynamic convex risk measure to evaluate future rewards. We also find a saddle\npoint for an equivalent zero-sum game of control and stopping, between an agent\n(the \"stopper\") who chooses the termination time of the game, and an agent (the\n\"controller\", or \"nature\") who selects the probability measure.\n"
    },
    {
        "paper_id": 909.5389,
        "authors": "Dejun Xie",
        "title": "A Steady State Solution to a Mortgage Pricing Problem",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers a mortgage contract where the borrower pays a fixed\nmortgage rate and has the choice of making prepayment. Assume the market\ninterest follows the CIR model, a free boundary problem is formulated. Here we\nfocus on the infinite horizon problem. Using variational method, we obtain an\nanalytical solution to the problem, where the free boundary is implicitly given\nby a transcendental algebraic equation.\n"
    },
    {
        "paper_id": 910.0064,
        "authors": "Fabio Caccioli, Matteo Marsili, Pierpaolo Vivo",
        "title": "Eroding market stability by proliferation of financial instruments",
        "comments": "26 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2009-00316-y",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We contrast Arbitrage Pricing Theory (APT), the theoretical basis for the\ndevelopment of financial instruments, with a dynamical picture of an\ninteracting market, in a simple setting. The proliferation of financial\ninstruments apparently provides more means for risk diversification, making the\nmarket more efficient and complete. In the simple market of interacting traders\ndiscussed here, the proliferation of financial instruments erodes systemic\nstability and it drives the market to a critical state characterized by large\nsusceptibility, strong fluctuations and enhanced correlations among risks. This\nsuggests that the hypothesis of APT may not be compatible with a stable market\ndynamics. In this perspective, market stability acquires the properties of a\ncommon good, which suggests that appropriate measures should be introduced in\nderivative markets, to preserve stability.\n"
    },
    {
        "paper_id": 910.0087,
        "authors": "A.N.Sekar Iyengar",
        "title": "Wavelet Based Volatility Clustering Estimation of Foreign Exchange Rates",
        "comments": "Time-Scale analysis, Intermittency, Nonlinearity, Chaos and finance",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have presented a novel technique of detecting intermittencies in a\nfinancial time series of the foreign exchange rate data of U.S.- Euro\ndollar(US/EUR) using a combination of both statistical and spectral techniques.\nThis has been possible due to Continuous Wavelet Transform (CWT) analysis which\nhas been popularly applied to fluctuating data in various fields science and\nengineering and is also being tried out in finance and economics. We have been\nable to qualitatively identify the presence of nonlinearity and chaos in the\ntime series of the foreign exchange rates for US/EURO (United States dollar to\nEuro Dollar) and US/UK (United States dollar to United Kingdom Pound)\ncurrencies. Interestingly we find that for the US-INDIA(United States dollar to\nIndian Rupee) foreign exchange rates, no such chaotic dynamics is observed.\nThis could be a result of the government control over the foreign exchange\nrates, instead of the market controlling them.\n"
    },
    {
        "paper_id": 910.0137,
        "authors": "Christa Cuchiero, Damir Filipovi\\'c, Eberhard Mayerhofer, Josef\n  Teichmann",
        "title": "Affine processes on positive semidefinite matrices",
        "comments": "Published in at http://dx.doi.org/10.1214/10-AAP710 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2011, Vol. 21, No. 2, 397-463",
        "doi": "10.1214/10-AAP710",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article provides the mathematical foundation for stochastically\ncontinuous affine processes on the cone of positive semidefinite symmetric\nmatrices. This analysis has been motivated by a large and growing use of\nmatrix-valued affine processes in finance, including multi-asset option pricing\nwith stochastic volatility and correlation structures, and fixed-income models\nwith stochastically correlated risk factors and default intensities.\n"
    },
    {
        "paper_id": 910.0236,
        "authors": "Noufel Frikha (PMA), Vincent Lemaire (PMA)",
        "title": "Joint Modelling of Gas and Electricity spot prices",
        "comments": null,
        "journal-ref": "Applied Mathematical Finance, Taylor & Francis (Routledge): SSH\n  Titles, 2012, 20 (1), pp.69-93",
        "doi": "10.1080/1350486X.2012.658220",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The recent liberalization of the electricity and gas markets has resulted in\nthe growth of energy exchanges and modelling problems. In this paper, we\nmodelize jointly gas and electricity spot prices using a mean-reverting model\nwhich fits the correlations structures for the two commodities. The dynamics\nare based on Ornstein processes with parameterized diffusion coefficients.\nMoreover, using the empirical distributions of the spot prices, we derive a\nclass of such parameterized diffusions which captures the most salient\nstatistical properties: stationarity, spikes and heavy-tailed distributions.\nThe associated calibration procedure is based on standard and efficient\nstatistical tools. We calibrate the model on French market for electricity and\non UK market for gas, and then simulate some trajectories which reproduce well\nthe observed prices behavior. Finally, we illustrate the importance of the\ncorrelation structure and of the presence of spikes by measuring the risk on a\npower plant portfolio.\n"
    },
    {
        "paper_id": 910.0545,
        "authors": "Pieter C. Allaart",
        "title": "A general \"bang-bang\" principle for predicting the maximum of a random\n  walk",
        "comments": "13 pages",
        "journal-ref": "J. Appl. Probab. 47, no. 4, 1072-1083 (2010)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Let $(B_t)_{0\\leq t\\leq T}$ be either a Bernoulli random walk or a Brownian\nmotion with drift, and let $M_t:=\\max\\{B_s: 0\\leq s\\leq t\\}$, $0\\leq t\\leq T$.\nThis paper solves the general optimal prediction problem \\sup_{0\\leq\\tau\\leq\nT}\\sE[f(M_T-B_\\tau)], where the supremum is over all stopping times $\\tau$\nadapted to the natural filtration of $(B_t)$, and $f$ is a nonincreasing convex\nfunction. The optimal stopping time $\\tau^*$ is shown to be of \"bang-bang\"\ntype: $\\tau^*\\equiv 0$ if the drift of the underlying process $(B_t)$ is\nnegative, and $\\tau^*\\equiv T$ is the drift is positive. This result\ngeneralizes recent findings by S. Yam, S. Yung and W. Zhou [{\\em J. Appl.\nProbab.} {\\bf 46} (2009), 651--668] and J. Du Toit and G. Peskir [{\\em Ann.\nAppl. Probab.} {\\bf 19} (2009), 983--1014], and provides additional\nmathematical justification for the dictum in finance that one should sell bad\nstocks immediately, but keep good ones as long as possible.\n"
    },
    {
        "paper_id": 910.1166,
        "authors": "Sophie Laruelle (PMA), Charles-Albert Lehalle, Gilles Pag\\`es (PMA)",
        "title": "Optimal split of orders across liquidity pools: a stochastic algorithm\n  approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Evolutions of the trading landscape lead to the capability to exchange the\nsame financial instrument on different venues. Because of liquidity issues, the\ntrading firms split large orders across several trading destinations to\noptimize their execution. To solve this problem we devised two stochastic\nrecursive learning procedures which adjust the proportions of the order to be\nsent to the different venues, one based on an optimization principle, the other\non some reinforcement ideas. Both procedures are investigated from a\ntheoretical point of view: we prove a.s. convergence of the optimization\nalgorithm under some light ergodic (or \"averaging\") assumption on the input\ndata process. No Markov property is needed. When the inputs are i.i.d. we show\nthat the convergence rate is ruled by a Central Limit Theorem. Finally, the\nmutual performances of both algorithms are compared on simulated and real data\nwith respect to an \"oracle\" strategy devised by an \"insider\" who knows a priori\nthe executed quantities by every venues.\n"
    },
    {
        "paper_id": 910.1205,
        "authors": "J.P. Bouchaud, M. Potters",
        "title": "Financial Applications of Random Matrix Theory: a short review",
        "comments": "To appear in the \"Handbook on Random Matrix Theory\", Oxford\n  University Press",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the applications of Random Matrix Theory in the context of\nfinancial markets and econometric models, a topic about which a considerable\nnumber of papers have been devoted to in the last decade. This mini-review is\nintended to guide the reader through various theoretical results (the\nMarcenko-Pastur spectrum and its various generalisations, random SVD, free\nmatrices, largest eigenvalue statistics, etc.) as well as some concrete\napplications to portfolio optimisation and out-of-sample risk estimation.\n"
    },
    {
        "paper_id": 910.1394,
        "authors": "Celia Anteneodo and Silvio M. Duarte Queiros",
        "title": "Statistical mixing and aggregation in Feller diffusion",
        "comments": "16 pages, 3 figures. To be published in Journal of Statistical\n  Mechanics: Theory and Experiment",
        "journal-ref": "J. Stat. Mech. (2009) P10023",
        "doi": "10.1088/1742-5468/2009/10/P10023",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider Feller mean-reverting square-root diffusion, which has been\napplied to model a wide variety of processes with linearly state-dependent\ndiffusion, such as stochastic volatility and interest rates in finance, and\nneuronal and populations dynamics in natural sciences. We focus on the\nstatistical mixing (or superstatistical) process in which the parameter related\nto the mean value can fluctuate - a plausible mechanism for the emergence of\nheavy-tailed distributions. We obtain analytical results for the associated\nprobability density function (both stationary and time dependent), its\ncorrelation structure and aggregation properties. Our results are applied to\nexplain the statistics of stock traded volume at different aggregation scales.\n"
    },
    {
        "paper_id": 910.143,
        "authors": "Ming Yuan",
        "title": "State price density estimation via nonparametric mixtures",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS246 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 3, 963-984",
        "doi": "10.1214/09-AOAS246",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider nonparametric estimation of the state price density encapsulated\nin option prices. Unlike usual density estimation problems, we only observe\noption prices and their corresponding strike prices rather than samples from\nthe state price density. We propose to model the state price density directly\nwith a nonparametric mixture and estimate it using least squares. We show that\nalthough the minimization is taken over an infinitely dimensional function\nspace, the minimizer always admits a finite dimensional representation and can\nbe computed efficiently. We also prove that the proposed estimate of the state\nprice density function converges to the truth at a ``nearly parametric'' rate.\n"
    },
    {
        "paper_id": 910.1671,
        "authors": "Simone Farinelli",
        "title": "Geometric Arbitrage Theory and Market Dynamics Reloaded",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have embedded the classical theory of stochastic finance into a\ndifferential geometric framework called Geometric Arbitrage Theory and show\nthat it is possible to:\n  --Write arbitrage as curvature of a principal fibre bundle.\n  --Parameterize arbitrage strategies by its holonomy.\n  --Give the Fundamental Theorem of Asset Pricing a differential homotopic\ncharacterization.\n  --Characterize Geometric Arbitrage Theory by five principles and show they\nthey are consistent with the classical theory of stochastic finance.\n  --Derive for a closed market the equilibrium solution for market portfolio\nand dynamics in the cases where:\n  -->Arbitrage is allowed but minimized.\n  -->Arbitrage is not allowed.\n  --Prove that the no-free-lunch-with-vanishing-risk condition implies the zero\ncurvature condition.\n"
    },
    {
        "paper_id": 910.2091,
        "authors": "Shige Peng, Xiaoming Xu",
        "title": "BSDEs with random default time and their applications to default risk",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we are concerned with backward stochastic differential\nequations with random default time and their applications to default risk. The\nequations are driven by Brownian motion as well as a mutually independent\nmartingale appearing in a defaultable setting. We show that these equations\nhave unique solutions and a comparison theorem for their solutions. As an\napplication, we get a saddle-point strategy for the related zero-sum stochastic\ndifferential game problem.\n"
    },
    {
        "paper_id": 910.2309,
        "authors": "Wen Cheng, Nick Costanzino, John Liechty, Anna Mazzucato, Victor\n  Nistor",
        "title": "Closed form asymptotics for local volatility models",
        "comments": "30 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We obtain new closed-form pricing formulas for contingent claims when the\nasset follows a Dupire-type local volatility model. To obtain the formulas we\nuse the Dyson-Taylor commutator method that we have recently developed in [5,\n6, 8] for short-time asymptotic expansions of heat kernels, and obtain a family\nof general closed-form approximate solutions for both the pricing kernel and\nderivative price. A bootstrap scheme allows us to extend our method to large\ntime. We also perform analytic as well as a numerical error analysis, and\ncompare our results to other known methods.\n"
    },
    {
        "paper_id": 910.2367,
        "authors": "Matthias Degen, Dominik D. Lambrigger, Johan Segers",
        "title": "Risk Concentration and Diversification: Second-Order Properties",
        "comments": "19 pages, 5 figures; status: submitted; references and introduction\n  revised with more discussion on Basel II, Solvency II, and risk\n  diversification",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The quantification of diversification benefits due to risk aggregation plays\na prominent role in the (regulatory) capital management of large firms within\nthe financial industry. However, the complexity of today's risk landscape makes\na quantifiable reduction of risk concentration a challenging task. In the\npresent paper we discuss some of the issues that may arise. The theory of\nsecond-order regular variation and second-order subexponentiality provides the\nideal methodological framework to derive second-order approximations for the\nrisk concentration and the diversification benefit.\n"
    },
    {
        "paper_id": 910.2447,
        "authors": "Elliot Martin, Amer Shreim, and Maya Paczuski",
        "title": "Activity Dependent Branching Ratios in Stocks, Solar X-ray Flux, and the\n  Bak-Tang-Wiesenfeld Sandpile Model",
        "comments": "7 pages, 11 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.81.016109",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We define an activity dependent branching ratio that allows comparison of\ndifferent time series $X_{t}$. The branching ratio $b_x$ is defined as $b_x=\nE[\\xi_x/x]$. The random variable $\\xi_x$ is the value of the next signal given\nthat the previous one is equal to $x$, so $\\xi_x=\\{X_{t+1}|X_t=x\\}$. If\n$b_x>1$, the process is on average supercritical when the signal is equal to\n$x$, while if $b_x<1$, it is subcritical. For stock prices we find $b_x=1$\nwithin statistical uncertainty, for all $x$, consistent with an ``efficient\nmarket hypothesis''. For stock volumes, solar X-ray flux intensities, and the\nBak-Tang-Wiesenfeld (BTW) sandpile model, $b_x$ is supercritical for small\nvalues of activity and subcritical for the largest ones, indicating a tendency\nto return to a typical value. For stock volumes this tendency has an\napproximate power law behavior. For solar X-ray flux and the BTW model, there\nis a broad regime of activity where $b_x \\simeq 1$, which we interpret as an\nindicator of critical behavior. This is true despite different underlying\nprobability distributions for $X_t$, and for $\\xi_x$. For the BTW model the\ndistribution of $\\xi_x$ is Gaussian, for $x$ sufficiently larger than one, and\nits variance grows linearly with $x$. Hence, the activity in the BTW model\nobeys a central limit theorem when sampling over past histories. The broad\nregion of activity where $b_x$ is close to one disappears once bulk dissipation\nis introduced in the BTW model -- supporting our hypothesis that it is an\nindicator of criticality.\n"
    },
    {
        "paper_id": 910.2474,
        "authors": "M. Piacquadio and F. O. Redelico",
        "title": "Multifractal analysis and instability index of prior-to-crash market\n  situations",
        "comments": "14 pp, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We take prior-to-crash market prices (NASDAQ, Dow Jones Industrial Average)\nas a signal, a function of time, we project these discrete values onto a\nvertical axis, thus obtaining a Cantordust. We study said cantordust with the\ntools of multifractal analysis, obtaining spectra by definition and by\nlagrangian coordinates. These spectra have properties that typify the\nprior-to-crash market situation. Any of these spectra entail elaborate\nprocessing of the raw signal data. With the unprocessed raw data we obtain an\ninstability index, also with properties that typify the prior-to-crisis market\nsituation. Both spectra and the instability index agree in characterizing such\ncrashes, and in giving an early warning of them.\n"
    },
    {
        "paper_id": 910.2524,
        "authors": "Meng-Cen Qian (Fudan), Zhi-Qiang Jiang (ECUST), and Wei-Xing Zhou\n  (ECUST)",
        "title": "Universal and nonuniversal allometric scaling behaviors in the\n  visibility graphs of world stock market indices",
        "comments": "7 pages including 5 figures",
        "journal-ref": "J. Phys. A: Math. Theor. 43 (2010) 335002 (12pp)",
        "doi": "10.1088/1751-8113/43/33/335002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The investigations of financial markets from a complex network perspective\nhave unveiled many phenomenological properties, in which the majority of these\nstudies map the financial markets into one complex network. In this work, we\ninvestigate 30 world stock market indices through their visibility graphs by\nadopting the visibility algorithm to convert each single stock index into one\nvisibility graph. A universal allometric scaling law is uncovered in the\nminimal spanning trees, whose scaling exponent is independent of the stock\nmarket and the length of the stock index. In contrast, the maximal spanning\ntrees and the random spanning trees do not exhibit universal allometric scaling\nbehaviors. There are marked discrepancies in the allometric scaling behaviors\nbetween the stock indices and the Brownian motions. Using surrogate time\nseries, we find that these discrepancies are caused by the fat-tailedness of\nthe return distribution, the nonlinear long-term correlation, and a coupling\neffect between these two influence factors.\n"
    },
    {
        "paper_id": 910.2696,
        "authors": "Igor Halperin",
        "title": "Implied Multi-Factor Model for Bespoke CDO Tranches and other Portfolio\n  Credit Derivatives",
        "comments": "40 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper introduces a new semi-parametric approach to the pricing and risk\nmanagement of bespoke CDO tranches, with a particular attention to bespokes\nthat need to be mapped onto more than one reference portfolio. The only user\ninput in our framework is a multi-factor model (a \"prior\" model hereafter) for\nindex portfolios, such as CDX.NA.IG or iTraxx Europe, that are chosen as\nbenchmark securities for the pricing of a given bespoke CDO. Parameters of the\nprior model are fixed, and not tuned to match prices of benchmark index\ntranches. Instead, our calibration procedure amounts to a proper reweightening\nof the prior measure using the Minimum Cross Entropy method. As the latter\nproblem reduces to convex optimization in a low dimensional space, our model is\ncomputationally efficient. Both the static (one-period) and dynamic versions of\nthe model are presented. The latter can be used for pricing and risk management\nof more exotic instruments referencing bespoke portfolios, such as\nforward-starting tranches or tranche options, and for calculation of credit\nvaluation adjustment (CVA) for bespoke tranches.\n"
    },
    {
        "paper_id": 910.2909,
        "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer, Thomas Guhr",
        "title": "Compensating asynchrony effects in the calculation of financial\n  correlations",
        "comments": "13 pages, 7 figures",
        "journal-ref": "Physica A Vol. 389, No. 4 (2010)",
        "doi": "10.1016/j.physa.2009.10.033",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a method to compensate statistical errors in the calculation of\ncorrelations on asynchronous time series. The method is based on the assumption\nof an underlying time series. We set up a model and apply it to financial data\nto examine the decrease of calculated correlations towards smaller return\nintervals (Epps effect). We show that this statistical effect is a major cause\nof the Epps effect. Hence, we are able to quantify and to compensate it using\nonly trading prices and trading times.\n"
    },
    {
        "paper_id": 910.3258,
        "authors": "David German",
        "title": "Hedging in an equilibrium-based model for a large investor",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study a financial model with a non-trivial price impact effect. In this\nmodel we consider the interaction of a large investor trading in an illiquid\nsecurity, and a market maker who is quoting prices for this security. We assume\nthat the market maker quotes the prices such that by taking the other side of\nthe investor's demand, the market maker will arrive at maturity with maximal\nexpected wealth. Within this model we concentrate on the issue of contingent\nclaims' hedging.\n"
    },
    {
        "paper_id": 910.3695,
        "authors": "Janusz Miskiewicz, Marcel Ausloos",
        "title": "Has the world economy reached its globalization limit?",
        "comments": "Presented at THIC & APFA7 Submitted to Physica A",
        "journal-ref": "Physica A 389 (2010) 797-806",
        "doi": "10.1016/j.physa.2009.10.029",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The economy globalization measure problem is discussed. Four macroeconomic\nindices of twenty among the \"richest\" countries are examined. Four types of\n\"distances\" are calculated.Two types of networks are next constructed for each\ndistance measure definition. It is shown that the globalization process can be\nbest characterised by an entropy measure, based on entropy Manhattan distance.\nIt is observed that a globalization maximum was reached in the interval\n1970-2000. More recently a deglobalization process is observed.\n"
    },
    {
        "paper_id": 910.3936,
        "authors": "Sara Biagini and Ale\\v{s} \\v{C}ern\\'y",
        "title": "Admissible Strategies in Semimartingale Portfolio Selection",
        "comments": "30 pages",
        "journal-ref": "SIAM J. Control Optim. 49(1) (2011) 42-72",
        "doi": "10.1137/090774458",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The choice of admissible trading strategies in mathematical modelling of\nfinancial markets is a delicate issue, going back to Harrison and Kreps (1979).\nIn the context of optimal portfolio selection with expected utility preferences\nthis question has been a focus of considerable attention over the last twenty\nyears. We propose a novel notion of admissibility that has many pleasant\nfeatures - admissibility is characterized purely under the objective measure;\neach admissible strategy can be approximated by simple strategies using finite\nnumber of trading dates; the wealth of any admissible strategy is a\nsupermartingale under all pricing measures; local boundedness of the price\nprocess is not required; neither strict monotonicity, strict concavity nor\ndifferentiability of the utility function are necessary; the definition\nencompasses both the classical mean-variance preferences and the monotone\nexpected utility. For utility functions finite on the whole real line, our\nclass represents a minimal set containing simple strategies which also contains\nthe optimizer, under conditions that are milder than the celebrated reasonable\nasymptotic elasticity condition on the utility function.\n"
    },
    {
        "paper_id": 910.4177,
        "authors": "Roman N. Makarov and Devin Glew",
        "title": "Exact Simulation of Bessel Diffusions",
        "comments": "22 page",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the exact path sampling of the squared Bessel process and some\nother continuous-time Markov processes, such as the CIR model, constant\nelasticity of variance diffusion model, and hypergeometric diffusions, which\ncan all be obtained from a squared Bessel process by using a change of\nvariable, time and scale transformation, and/or change of measure. All these\ndiffusions are broadly used in mathematical finance for modelling asset prices,\nmarket indices, and interest rates. We show how the probability distributions\nof a squared Bessel bridge and a squared Bessel process with or without\nabsorption at zero are reduced to randomized gamma distributions. Moreover, for\nabsorbing stochastic processes, we develop a new bridge sampling technique\nbased on conditioning on the first hitting time at zero. Such an approach\nallows us to simplify simulation schemes. New methods are illustrated with\npricing path-dependent options.\n"
    },
    {
        "paper_id": 910.4257,
        "authors": "Laura Monti, Andrea Pascucci",
        "title": "Obstacle problem for Arithmetic Asian options",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We prove existence, regularity and a Feynman-Ka\\v{c} representation formula\nof the strong solution to the free boundary problem arising in the financial\nproblem of the pricing of the American Asian option with arithmetic average.\n"
    },
    {
        "paper_id": 910.4348,
        "authors": "J. Speth, S. Drozdz, F. Gruemmer",
        "title": "Complex Systems: From Nuclear Physics to Financial Markets",
        "comments": "6 pages, 10 figures, elsarticle class",
        "journal-ref": null,
        "doi": "10.1016/j.nuclphysa.2010.05.010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We compare correlations and coherent structures in nuclei and financial\nmarkets. In the nuclear physics part we review giant resonances which can be\ninterpreted as a coherent structure embedded in chaos. With similar methods we\ninvestigate the financial empirical correlation matrix of the DAX and Dow\nJones. We will show, that if the time-zone delay is properly accounted for, the\ntwo distinct markets largely merge into one. This is reflected by the largest\neigenvalue that develops a gap relative to the remaining, chaotic eigenvalues.\nBy extending investigations of the specific character of financial collectivity\nwe also discuss the criticality-analog phenomenon of the financial\nlog-periodicity and show specific examples.\n"
    },
    {
        "paper_id": 910.4941,
        "authors": "Antonis Papapantoleon",
        "title": "Old and new approaches to LIBOR modeling",
        "comments": "18 pages, 2 figures, to appear in Statistica Neerlandica (special\n  issue)",
        "journal-ref": "Statistica Neerlandica 2010, Vol. 64, No. 3, 257-275",
        "doi": "10.1111/j.1467-9574.2010.00458.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article, we review the construction and properties of some popular\napproaches to modeling LIBOR rates. We discuss the following frameworks:\nclassical LIBOR market models, forward price models and Markov-functional\nmodels. We close with the recently developed affine LIBOR models.\n"
    },
    {
        "paper_id": 910.5033,
        "authors": "Jiro Akahori, Yuji Hishida, Josef Teichmann, Takahiro Tsuchiya",
        "title": "A Heat Kernel Approach to Interest Rate Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We construct default-free interest rate models in the spirit of the\nwell-known Markov funcional models: our focus is analytic tractability of the\nmodels and generality of the approach. We work in the setting of state price\ndensities and construct models by means of the so called propagation property.\nThe propagation property can be found implicitly in all of the popular state\nprice density approaches, in particular heat kernels share the propagation\nproperty (wherefrom we deduced the name of the approach). As a related matter,\nan interesting property of heat kernels is presented, too.\n"
    },
    {
        "paper_id": 910.5101,
        "authors": "Peter G. Lindberg",
        "title": "Optimal partial hedging in a discrete-time market as a knapsack problem",
        "comments": "17 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new approach for studying the problem of optimal hedging of a\nEuropean option in a finite and complete discrete-time market model. We\nconsider partial hedging strategies that maximize the success probability or\nminimize the expected shortfall under a cost constraint and show that these\nproblems can be treated as so called knapsack problems, which are a widely\nresearched subject in linear programming. This observation gives us better\nunderstanding of the problem of optimal hedging in discrete time.\n"
    },
    {
        "paper_id": 910.5185,
        "authors": "Bert van Es, Peter Spreij, Harry van Zanten",
        "title": "Nonparametric methods for volatility density estimation",
        "comments": null,
        "journal-ref": "Advanced Mathematical Methods for Finance, Chapter 11, 293-312,\n  Giulia di Nunno, Bernt {\\O}ksendal Eds., Springer (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Stochastic volatility modelling of financial processes has become\nincreasingly popular. The proposed models usually contain a stationary\nvolatility process. We will motivate and review several nonparametric methods\nfor estimation of the density of the volatility process. Both models based on\ndiscretely sampled continuous time processes and discrete time models will be\ndiscussed.\n  The key insight for the analysis is a transformation of the volatility\ndensity estimation problem to a deconvolution model for which standard methods\nexist. Three type of nonparametric density estimators are reviewed: the\nFourier-type deconvolution kernel density estimator, a wavelet deconvolution\ndensity estimator and a penalized projection estimator. The performance of\nthese estimators will be compared. Key words: stochastic volatility models,\ndeconvolution, density estimation, kernel estimator, wavelets, minimum contrast\nestimation, mixing\n"
    },
    {
        "paper_id": 910.5398,
        "authors": "Xuepeng Bai, Rainer Buckdahn",
        "title": "Inf-convolution of G-expectations",
        "comments": "23 pages",
        "journal-ref": "Science China Mathematics, 2010 Vol. 53 No. 8: 1957-1970",
        "doi": "10.1007/s11425-010-4031-6",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we will discuss the optimal risk transfer problems when risk\nmeasures are generated by G-expectations, and we present the relationship\nbetween inf-convolution of G-expectations and the inf-convolution of drivers G.\n"
    },
    {
        "paper_id": 910.5655,
        "authors": "Gilles Pag\\`es (PMA), Benedikt Wilbertz (PMA)",
        "title": "Dual Quantization for random walks with application to credit\n  derivatives",
        "comments": "22 pages",
        "journal-ref": "Journal of Computational Finance 16, 2 (2012) 33-60 ;",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a new Quantization algorithm for the approximation of\ninhomogeneous random walks, which are the key terms for the valuation of\nCDO-tranches in latent factor models. This approach is based on a dual\nquantization operator which posses an intrinsic stationarity and therefore\nautomatically leads to a second order error bound for the weak approximation.\nWe illustrate the numerical performance of our methods in case of the\napproximation of the conditional tranche function of synthetic CDO products and\ndraw comparisons to the approximations achieved by the saddlepoint method and\nStein's method.\n"
    },
    {
        "paper_id": 911.0057,
        "authors": "Xiao-Hui Ni (ECUST), Zhi-Qiang Jiang (ECUST), Gao-Feng Gu (ECUST), Fei\n  Ren (ECUST), Wei Chen (SZSE) and Wei-Xing Zhou (ECUST)",
        "title": "Scaling and memory in the non-poisson process of limit order cancelation",
        "comments": "13 Latex pages, 6 figures",
        "journal-ref": "Physica A 389 (2010) 2751-2761",
        "doi": "10.1016/j.physa.2010.02.040",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The order submission and cancelation processes are two crucial aspects in the\nprice formation of stocks traded in order-driven markets. We investigate the\ndynamics of order cancelation by studying the statistical properties of\ninter-cancelation durations defined as the waiting times between consecutive\norder cancelations of 22 liquid stocks traded on the Shenzhen Stock Exchange of\nChina in year 2003. Three types of cancelations are considered including\ncancelation of any limit orders, of buy limit orders and of sell limit orders.\nWe find that the distributions of the inter-cancelation durations of individual\nstocks can be well modeled by Weibulls for each type of cancelation and the\ndistributions of rescaled durations of each type of cancelations exhibit a\nscaling behavior for different stocks. Complex intraday patterns are also\nunveiled in the inter-cancelation durations. The detrended fluctuation analysis\n(DFA) and the multifractal DFA show that the inter-cancelation durations\npossess long-term memory and multifractal nature, which are not influenced by\nthe intraday patterns. No clear crossover phenomenon is observed in the\ndetrended fluctuation functions with respect to the time scale. These findings\nindicate that the cancelation of limit orders is a non-Poisson process, which\nhas potential worth in the construction of order-driven market models.\n"
    },
    {
        "paper_id": 911.0113,
        "authors": "Ljudmila A. Bordag",
        "title": "Study of the risk-adjusted pricing methodology model with methods of\n  Geometrical Analysis",
        "comments": "larger version with exact solutions, corrected typos, 13 pages,\n  Symposium on Optimal Stopping in Abo/Turku 2009",
        "journal-ref": "Stochastics: International Journal of Probability and Stochastic\n  processes, vol. 83, NN. 4-6, pp. 333- 345, 2011",
        "doi": "10.1080/17442508.2010.489642",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Families of exact solutions are found to a nonlinear modification of the\nBlack-Scholes equation. This risk-adjusted pricing methodology model (RAPM)\nincorporates both transaction costs and the risk from a volatile portfolio.\nUsing the Lie group analysis we obtain the Lie algebra admitted by the RAPM\nequation. It gives us the possibility to describe an optimal system of\nsubalgebras and correspondingly the set of invariant solutions to the model. In\nthis way we can describe the complete set of possible reductions of the\nnonlinear RAPM model. Reductions are given in the form of different second\norder ordinary differential equations. In all cases we provide solutions to\nthese equations in an exact or parametric form. We discuss the properties of\nthese reductions and the corresponding invariant solutions.\n"
    },
    {
        "paper_id": 911.0223,
        "authors": "Mikhail Voropaev",
        "title": "Analytical Framework for Credit Portfolios. Part I: Systematic Risk",
        "comments": "Obsolete, see \"Analytical Framework for Credit Portfolios\" instead",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Analytical, free of time consuming Monte Carlo simulations, framework for\ncredit portfolio systematic risk metrics calculations is presented. Techniques\nare described that allow calculation of portfolio-level systematic risk\nmeasures (standard deviation, VaR and Expected Shortfall) as well as allocation\nof risk down to individual transactions. The underlying model is the industry\nstandard multi-factor Merton-type model with arbitrary valuation function at\nhorizon (in contrast to the simplistic default-only case). High accuracy of the\nproposed analytical technique is demonstrated by benchmarking against Monte\nCarlo simulations.\n"
    },
    {
        "paper_id": 911.0373,
        "authors": "Ernst Eberlein, Kathrin Glau, Antonis Papapantoleon",
        "title": "Analyticity of the Wiener-Hopf factors and valuation of exotic options\n  in L\\'evy models",
        "comments": "22 pages, no figures. Forthcoming in the volume on \"Advanced\n  Mathematical Methods for Finance\"",
        "journal-ref": "Advanced Mathematical Methods for Finance, pp. 223-245, Springer,\n  2011",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers the valuation of exotic path-dependent options in L\\'evy\nmodels, in particular options on the supremum and the infimum of the asset\nprice process. Using the Wiener--Hopf factorization, we derive expressions for\nthe analytically extended characteristic function of the supremum and the\ninfimum of a L\\'evy process. Combined with general results on Fourier methods\nfor option pricing, we provide formulas for the valuation of one-touch options,\nlookback options and equity default swaps in L\\'evy models.\n"
    },
    {
        "paper_id": 911.0454,
        "authors": "Didier Sornette, Ryan Woodard, Maxim Fedorovsky, Stefan Reimann,\n  Hilary Woodard, Wei-Xing Zhou (The Financial Crisis Observatory)",
        "title": "The Financial Bubble Experiment: advanced diagnostics and forecasts of\n  bubble terminations",
        "comments": "20100514: Added final analysis and summary, including names of\n  assets.",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  On 2 November 2009, the Financial Bubble Experiment was launched within the\nFinancial Crisis Observatory (FCO) at ETH Zurich\n(\\url{http://www.er.ethz.ch/fco/}). In that initial report, we diagnosed and\nannounced three bubbles on three different assets. In this latest release of 23\nDecember 2009 in this ongoing experiment, we add a diagnostic of a new bubble\ndeveloping on a fourth asset.\n"
    },
    {
        "paper_id": 911.0562,
        "authors": "Martin Keller-Ressel, Josef Teichmann",
        "title": "A remark on Gatheral's 'most-likely path approximation' of implied\n  volatility",
        "comments": "6 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give a new proof of the representation of implied volatility as a\ntime-average of weighted expectations of local or stochastic volatility. With\nthis proof we clarify the question of existence of 'forward implied variance'\nin the original derivation of Gatheral, who introduced this representation in\nhis book 'The Volatility Surface'.\n"
    },
    {
        "paper_id": 911.075,
        "authors": "Lane P. Hughston and Andrea Macrina",
        "title": "Discrete-Time Interest Rate Modelling",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents an axiomatic scheme for interest rate models in discrete\ntime. We take a pricing kernel approach, which builds in the arbitrage-free\nproperty and provides a link to equilibrium economics. We require that the\npricing kernel be consistent with a pair of axioms, one giving the\ninter-temporal relations for dividend-paying assets, and the other ensuring the\nexistence of a money-market asset. We show that the existence of a\npositive-return asset implies the existence of a previsible money-market\naccount. A general expression for the price process of a limited-liability\nasset is derived. This expression includes two terms, one being the discounted\nrisk-adjusted value of the dividend stream, the other characterising retained\nearnings. The vanishing of the latter is given by a transversality condition.\nWe show (under the assumed axioms) that, in the case of a limited-liability\nasset with no permanently-retained earnings, the price process is given by the\nratio of a pair of potentials. Explicit examples of discrete-time models are\nprovided.\n"
    },
    {
        "paper_id": 911.0805,
        "authors": "Ulrich Kirchner",
        "title": "Market Implied Probability Distributions and Bayesian Skew Estimation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We review and illustrate how the volatility smile translates into a\nprobability distribution, the market-implied probability distribution\nrepresenting believes priced in. The effects of changes in the smile are\nexamined. Special attention is given to the effects of slope, which might\nappear at first counter-intuitive.\n  We then show how Bayesian methods can be used to deal with sparse real market\ndata. With each skew in a parametric model we associate a probability. This is\nillustrated with an example, for which multivariate parameter distributions are\nderived. We introduce the fuzzy smile (or fuzzy skew) as a visual illustration\nof the skew distribution.\n"
    },
    {
        "paper_id": 911.0928,
        "authors": "Aleksandar Mijatovic and Paul Schneider",
        "title": "Empirical asset pricing with nonlinear risk premia",
        "comments": "24 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce a simple continuous-time asset pricing framework,\nbased on general multi-dimensional diffusion processes, that combines\nsemi-analytic pricing with a nonlinear specification for the market price of\nrisk. Our framework guarantees existence of weak solutions of the nonlinear\nSDEs under the physical measure, thus allowing to work with nonlinear models\nfor the real world dynamics not considered in the literature so far. It emerges\nthat the additional flexibility in the time series modelling is econometrically\nrelevant: a nonlinear stochastic volatility diffusion model for the joint time\nseries of the S&P 100 and the VXO implied volatility index data shows superior\nforecasting power over the standard specifications for implied and realized\nvariance forecasting.\n"
    },
    {
        "paper_id": 911.1119,
        "authors": "Michal Baran, Jerzy Zabczyk",
        "title": "Bonds with volatilities proportional to forward rates",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The problem of existence of solution for the Heath-Jarrow-Morton equation\nwith linear volatility and purely jump random factor is studied. Sufficient\nconditions for existence and non-existence of the solution in the class of\nbounded fields are formulated. It is shown that if the first derivative of the\nLevy-Khinchin exponent grows slower then logarithmic function then the answer\nis positive and if it is bounded from below by a fractional power function of\nany positive order then the answer is negative. Numerous examples including\nmodels with Levy measures of stable type are presented.\n"
    },
    {
        "paper_id": 911.1575,
        "authors": "Hongzhong Zhang and Olympia Hadjiliadis",
        "title": "Formulas for the Laplace Transform of Stopping Times based on Drawdowns\n  and Drawups",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we study drawdowns and drawups of general diffusion processes.\nThe drawdown process is defined as the current drop of the process from its\nrunning maximum, while the drawup process is defined as the current increase\nover its running minimum. The drawdown and the drawup are the first hitting\ntimes of the drawdown and the drawup processes respectively. In particular, we\nderive a closed-form formula for the Laplace transform of the probability\ndensity of the drawdown of a units when it precedes the drawup of b units. We\nthen separately consider the special case of drifted Brownian motion, for which\nwe derive a closed form formula for the above-mentioned density by inverting\nthe Laplace transform. Finally, we apply the results to a problem of interest\nin financial risk-management and to the problem of transient signal detection\nand identification of two-sided changes in the drift of general diffusion\nprocesses.\n"
    },
    {
        "paper_id": 911.161,
        "authors": "Lane P. Hughston and Andrea Macrina",
        "title": "Pricing Fixed-Income Securities in an Information-Based Framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce a class of information-based models for the\npricing of fixed-income securities. We consider a set of continuous- time\ninformation processes that describe the flow of information about market\nfactors in a monetary economy. The nominal pricing kernel is at any given time\nassumed to be given by a function of the values of information processes at\nthat time. By use of a change-of-measure technique we derive explicit\nexpressions for the price processes of nominal discount bonds, and deduce the\nassociated dynamics of the short rate of interest and the market price of risk.\nThe interest rate positivity condition is expressed as a differential\ninequality. We proceed to the modelling of the price-level, which at any given\ntime is also taken to be a function of the values of the information processes\nat that time. A simple model for a stochastic monetary economy is introduced in\nwhich the prices of nominal discount bonds and inflation-linked notes can be\nexpressed in terms of aggregate consumption and the liquidity benefit generated\nby the money supply.\n"
    },
    {
        "paper_id": 911.1662,
        "authors": "Louis Paulot",
        "title": "A Dynamic Model for Credit Index Derivatives",
        "comments": "32 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a new model for credit index derivatives, in the top-down\napproach. This model has a dynamic loss intensity process with volatility and\njumps and can include counterparty risk. It handles CDS, CDO tranches,\nNth-to-default and index swaptions. Using properties of affine models, we\nderive closed formulas for the pricing of index CDS, CDO tranches and\nNth-to-default. For index swaptions, we give an exact pricing and an\napproximate faster method. We finally show calibration results on 2009 market\ndata.\n"
    },
    {
        "paper_id": 911.1694,
        "authors": "Susanne Still and Imre Kondor",
        "title": "Regularizing Portfolio Optimization",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1088/1367-2630/12/7/075034",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The optimization of large portfolios displays an inherent instability to\nestimation error. This poses a fundamental problem, because solutions that are\nnot stable under sample fluctuations may look optimal for a given sample, but\nare, in effect, very far from optimal with respect to the average risk. In this\npaper, we approach the problem from the point of view of statistical learning\ntheory. The occurrence of the instability is intimately related to over-fitting\nwhich can be avoided using known regularization methods. We show how\nregularized portfolio optimization with the expected shortfall as a risk\nmeasure is related to support vector regression. The budget constraint dictates\na modification. We present the resulting optimization problem and discuss the\nsolution. The L2 norm of the weight vector is used as a regularizer, which\ncorresponds to a diversification \"pressure\". This means that diversification,\nbesides counteracting downward fluctuations in some assets by upward\nfluctuations in others, is also crucial because it improves the stability of\nthe solution. The approach we provide here allows for the simultaneous\ntreatment of optimization and diversification in one framework that enables the\ninvestor to trade-off between the two, depending on the size of the available\ndata set.\n"
    },
    {
        "paper_id": 911.1834,
        "authors": "Vladimir G. Ivancevic",
        "title": "Adaptive-Wave Alternative for the Black-Scholes Option Pricing Model",
        "comments": "26 pages, 14 figures (higher-quality figures in PDF are available\n  upon request)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A nonlinear wave alternative for the standard Black-Scholes option-pricing\nmodel is presented. The adaptive-wave model, representing 'controlled Brownian\nbehavior' of financial markets, is formally defined by adaptive nonlinear\nSchr\\\"odinger (NLS) equations, defining the option-pricing wave function in\nterms of the stock price and time. The model includes two parameters:\nvolatility (playing the role of dispersion frequency coefficient), which can be\neither fixed or stochastic, and adaptive market potential that depends on the\ninterest rate. The wave function represents quantum probability amplitude,\nwhose absolute square is probability density function. Four types of analytical\nsolutions of the NLS equation are provided in terms of Jacobi elliptic\nfunctions, all starting from de Broglie's plane-wave packet associated with the\nfree quantum-mechanical particle. The best agreement with the Black-Scholes\nmodel shows the adaptive shock-wave NLS-solution, which can be efficiently\ncombined with adaptive solitary-wave NLS-solution. Adjustable 'weights' of the\nadaptive market-heat potential are estimated using either unsupervised Hebbian\nlearning, or supervised Levenberg-Marquardt algorithm. In the case of\nstochastic volatility, it is itself represented by the wave function, so we\ncome to the so-called Manakov system of two coupled NLS equations (that admits\nclosed-form solutions), with the common adaptive market potential, which\ndefines a bidirectional spatio-temporal associative memory.\n  Keywords: Black-Scholes option pricing, adaptive nonlinear Schr\\\"odinger\nequation, market heat potential, controlled stochastic volatility, adaptive\nManakov system, controlled Brownian behavior\n"
    },
    {
        "paper_id": 911.1921,
        "authors": "Li Lin, Didier Sornette",
        "title": "Diagnostics of Rational Expectation Financial Bubbles with Stochastic\n  Mean-Reverting Termination Times",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/publicdomain/",
        "abstract": "  We propose two rational expectation models of transient financial bubbles\nwith heterogeneous arbitrageurs and positive feedbacks leading to\nself-reinforcing transient stochastic faster-than-exponential price dynamics.\nAs a result of the nonlinear feedbacks, the termination of a bubble is found to\nbe characterized by a finite-time singularity in the bubble price formation\nprocess ending at some potential critical time $\\tilde{t}_c$, which follows a\nmean-reversing stationary dynamics. Because of the heterogeneity of the\nrational agents' expectations, there is a synchronization problem for the\noptimal exit times determined by these arbitrageurs, which leads to the\nsurvival of the bubble almost all the way to its theoretical end time. The\nexplicit exact analytical solutions of the two models provide nonlinear\ntransformations which allow us to develop novel tests for the presence of\nbubbles in financial time series. Avoiding the difficult problem of parameter\nestimation of the stochastic differential equation describing the price\ndynamics, the derived operational procedures allow us to diagnose bubbles that\nare in the making and to forecast their termination time. The tests performed\non three financial markets, the US S&P500 index from 1 February 1980 to 31\nOctober 2008, the US NASDAQ composite index from 1 January 1980 to 31 July 2008\nand the Hong Kong Hang Seng index from 1 December 1986 to 30 November 2008,\nsuggest the feasibility of advance bubble warning.\n"
    },
    {
        "paper_id": 911.2229,
        "authors": "Paul Lescot (LMRS)",
        "title": "Bernstein processes, Euclidean Quantum Mechanics and Interest Rate\n  Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give an exposition, following joint works with J.-C. Zambrini, of the link\nbetween Euclidean Quantum Mechanics, Bernstein processes and isovectors for the\nheat equation. A new application to Mathematical Finance is then discussed.\n"
    },
    {
        "paper_id": 911.2757,
        "authors": "Paul Lescot (LMRS)",
        "title": "On affine interest rate models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Bernstein processes are Brownian diffusions that appear in Euclidean Quantum\nMechanics. Knowledge of the symmetries of the Hamilton-Jacobi-Bellman equation\nassociated with these processes allows one to obtain relations between\nstochastic processes (Lescot-Zambrini, Progress in Probability, vols 58 and\n59). More recently it has appeared that each one--factor affine interest rate\nmodel (in the sense of Leblanc-Scaillet) could be described using such a\nBernstein process.\n"
    },
    {
        "paper_id": 911.2834,
        "authors": "Benjamin Jourdain (CERMICS), Mohamed Sbai (CERMICS)",
        "title": "Coupling Index and Stocks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we are interested in continuous time models in which the index\nlevel induces some feedback on the dynamics of its composing stocks. More\nprecisely, we propose a model in which the log-returns of each stock may be\ndecomposed into a systemic part proportional to the log-returns of the index\nplus an idiosyncratic part. We show that, when the number of stocks in the\nindex is large, this model may be approximated by a local volatility model for\nthe index and a stochastic volatility model for each stock with volatility\ndriven by the index. This result is useful in a calibration perspective : it\nsuggests that one should first calibrate the local volatility of the index and\nthen calibrate the dynamics of each stock. We explain how to do so in the\nlimiting simplified model and in the original model.\n"
    },
    {
        "paper_id": 911.2992,
        "authors": "Martin Forde, Antoine Jacquier and Aleksandar Mijatovic",
        "title": "Asymptotic formulae for implied volatility in the Heston model",
        "comments": "Presentation in Section 2 has been improved. Theorem 3.1 has been\n  slightly generalised. Figures 2 and 3 now include the at-the-money point.",
        "journal-ref": null,
        "doi": "10.1098/rspa.2009.0610",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we prove an approximate formula expressed in terms of\nelementary functions for the implied volatility in the Heston model. The\nformula consists of the constant and first order terms in the large maturity\nexpansion of the implied volatility function. The proof is based on saddlepoint\nmethods and classical properties of holomorphic functions.\n"
    },
    {
        "paper_id": 911.3043,
        "authors": "R. Tevzadze and T. Toronjadze",
        "title": "Robust utility maximization for diffusion market model with misspecified\n  coefficients",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper studies the robust maximization of utility of terminal wealth in\nthe diffusion financial market model. The underlying model consists with risky\ntradable asset, whose price is described by diffusion process with misspecified\ntrend and volatility coefficients, and non-tradable asset with a known\nparameter. The robust utility functional is defined in terms of a HARA utility\nfunction. We give explicit characterization of the solution of the problem by\nmeans of a solution of the HJBI equation.\n"
    },
    {
        "paper_id": 911.3045,
        "authors": "Sylwia Gworek, Jaroslaw Kwapien, Stanislaw Drozdz",
        "title": "Sign and amplitude representation of the forex networks",
        "comments": "Article based on talk by S. Gworek given at FENS'08 Conference,\n  Rzeszow, Poland",
        "journal-ref": "Acta Phys. Pol. A 117, 681-687 (2010)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We decompose the exchange rates returns of 41 currencies (incl. gold) into\ntheir sign and amplitude components. Then we group together all exchange rates\nwith a common base currency, construct Minimal Spanning Trees for each group\nindependently, and analyze properties of these trees. We show that both the\nsign and the amplitude time series have similar correlation properties as far\nas the core network structure is concerned. There exist however interesting\nperipheral differences that may open a new perspective to view the Forex\ndynamics.\n"
    },
    {
        "paper_id": 911.3099,
        "authors": "Kartik Anand, Prasanna Gai, Matteo Marsili",
        "title": "Financial crises and the evaporation of trust",
        "comments": "21 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Trust lies at the crux of most economic transactions, with credit markets\nbeing a notable example. Drawing on insights from the literature on\ncoordination games and network growth, we develop a simple model to clarify how\ntrust breaks down in financial systems. We show how the arrival of bad news\nabout a financial agent can lead others to lose confidence in it and how this,\nin turn, can spread across the entire system. Our results emphasize the role of\nhysteresis -- it takes considerable effort to regain trust once it has been\nbroken. Although simple, the model provides a plausible account of the credit\nfreeze that followed the global financial crisis of 2007/8, both in terms of\nthe sequence of events and the measures taken (and being proposed) by the\nauthorities.\n"
    },
    {
        "paper_id": 911.3117,
        "authors": "Albina Danilova, Michael Monoyios, Andrew Ng",
        "title": "Optimal investment with inside information and parameter uncertainty",
        "comments": "This paper has been withdrawn",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper has been withdrawn by the authors pending corrections.\n"
    },
    {
        "paper_id": 911.3194,
        "authors": "Nikolai Dokuchaev",
        "title": "Mutual Fund Theorem for continuous time markets with random coefficients",
        "comments": "17 pages",
        "journal-ref": "Theory and Decision (2014) v. 76, iss. 2, pp. 179--199",
        "doi": "10.1007/s11238-013-9368-1",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the optimal investment problem for a continuous time incomplete\nmarket model such that the risk-free rate, the appreciation rates and the\nvolatility of the stocks are all random; they are assumed to be independent\nfrom the driving Brownian motion, and they are supposed to be currently\nobservable. It is shown that some weakened version of Mutual Fund Theorem holds\nfor this market for general class of utilities; more precisely, it is shown\nthat the supremum of expected utilities can be achieved on a sequence of\nstrategies with a certain distribution of risky assets that does not depend on\nrisk preferences described by different utilities.\n"
    },
    {
        "paper_id": 911.3331,
        "authors": "Damiano Brigo, Andrea Pallavicini, Vasileios Papatheodorou",
        "title": "Bilateral counterparty risk valuation for interest-rate products: impact\n  of volatilities and correlations",
        "comments": "23 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The purpose of this paper is introducing rigorous methods and formulas for\nbilateral counterparty risk credit valuation adjustments (CVA's) on\ninterest-rate portfolios. In doing so, we summarize the general arbitrage-free\nvaluation framework for counterparty risk adjustments in presence of bilateral\ndefault risk, as developed more in detail in Brigo and Capponi (2008),\nincluding the default of the investor. We illustrate the symmetry in the\nvaluation and show that the adjustment involves a long position in a put option\nplus a short position in a call option, both with zero strike and written on\nthe residual net present value of the contract at the relevant default times.\nWe allow for correlation between the default times of the investor and\ncounterparty, and for correlation of each with the underlying risk factor,\nnamely interest rates. We also analyze the often neglected impact of credit\nspread volatility. We include Netting in our examples, although other\nagreements such as Margining and Collateral are left for future work.\n"
    },
    {
        "paper_id": 911.3472,
        "authors": "Alaeddine Faleh (SAF), Fr\\'ed\\'eric Planchet (SAF), Didier Rulli\\`ere\n  (SAF)",
        "title": "Les G\\'en\\'erateurs de Sc\\'enarios \\'Economiques : quelle utilisation en\n  assurance?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we present the principal components of an economic scenario\ngenerator (ESG), both for the theoretical design and for practical\nimplementation. The choice of these components should be linked to the ultimate\nvocation of the economic scenario generator, which can be either a tool for\npricing financial products or a tool for projection and risk management. We\nthen develop a study on some performance measure indicators of the ESG as an\ninput for the decision-making process, namely the indicators of stability and\nbias absence. Finally, a numerical application illustrates the main ideas of\nthe paper.\n"
    },
    {
        "paper_id": 911.3608,
        "authors": "Jan Kallsen, Johannes Muhle-Karbe",
        "title": "Utility maximization in models with conditionally independent increments",
        "comments": "16 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the problem of maximizing expected utility from terminal wealth\nin models with stochastic factors. Using martingale methods and a conditioning\nargument, we determine the optimal strategy for power utility under the\nassumption that the increments of the asset price are independent conditionally\non the factor process.\n"
    },
    {
        "paper_id": 911.3789,
        "authors": "Erhan Bayraktar, Mikko S. Pakkanen, Hasanjan Sayit",
        "title": "On the Existence of Consistent Price Systems",
        "comments": "To appear in \"Stochastic Analysis and Applications\". Keywords:\n  Consistent pricing systems, No-arbitrage, Transaction costs, Full support,\n  Conditional Full Support, Stability under Composition with Continuous\n  Functions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We formulate a sufficient condition for the existence of a consistent price\nsystem (CPS), which is weaker than the conditional full support condition (CFS)\nintroduced by Guasoni, Rasonyi, and Schachermayer [Ann. Appl. Probab.,\n18(2008), pp. 491-520] . We use the new condition to show the existence of CPSs\nfor certain processes that fail to have the CFS property. In particular this\ncondition gives sufficient conditions, under which a continuous function of a\nprocess with CFS admits a CPS, while the CFS property might be lost.\n"
    },
    {
        "paper_id": 911.3802,
        "authors": "David Wozabal and Ronald Hochreiter",
        "title": "A Coupled Markov Chain Approach to Credit Risk Modeling",
        "comments": null,
        "journal-ref": "Journal of Economic Dynamics and Control 36(3): 403-415. 2012",
        "doi": "10.1016/j.jedc.2011.09.011",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a Markov chain model for credit rating changes. We do not use any\ndistributional assumptions on the asset values of the rated companies but\ndirectly model the rating transitions process. The parameters of the model are\nestimated by a maximum likelihood approach using historical rating transitions\nand heuristic global optimization techniques.\n  We benchmark the model against a GLMM model in the context of bond portfolio\nrisk management. The proposed model yields stronger dependencies and higher\nrisks than the GLMM model. As a result, the risk optimal portfolios are more\nconservative than the decisions resulting from the benchmark model.\n"
    },
    {
        "paper_id": 911.403,
        "authors": "Cyril Coste, Raphael Douady, Ilija I. Zovko",
        "title": "The StressVaR: A New Risk Concept for Superior Fund Allocation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we introduce a novel approach to risk estimation based on\nnonlinear factor models - the \"StressVaR\" (SVaR). Developed to evaluate the\nrisk of hedge funds, the SVaR appears to be applicable to a wide range of\ninvestments. Its principle is to use the fairly short and sparse history of the\nhedge fund returns to identify relevant risk factors among a very broad set of\npossible risk sources. This risk profile is obtained by calibrating a\ncollection of nonlinear single-factor models as opposed to a single\nmulti-factor model. We then use the risk profile and the very long and rich\nhistory of the factors to asses the possible impact of known past crises on the\nfunds, unveiling their hidden risks and so called \"black swans\".\n  In backtests using data of 1060 hedge funds we demonstrate that the SVaR has\nbetter or comparable properties than several common VaR measures - shows less\nVaR exceptions and, perhaps even more importantly, in case of an exception, by\nsmaller amounts.\n  The ultimate test of the StressVaR however, is in its usage as a fund\nallocating tool. By simulating a realistic investment in a portfolio of hedge\nfunds, we show that the portfolio constructed using the StressVaR on average\noutperforms both the market and the portfolios constructed using common VaR\nmeasures.\n  For the period from Feb. 2003 to June 2009, the StressVaR constructed\nportfolio outperforms the market by about 6% annually, and on average the\ncompeting VaR measures by around 3%. The performance numbers from Aug. 2007 to\nJune 2009 are even more impressive. The SVaR portfolio outperforms the market\nby 20%, and the best competing measure by 4%.\n"
    },
    {
        "paper_id": 911.4039,
        "authors": "Nathalie Rey (CEPN)",
        "title": "Credit derivatives: instruments of hedging and factors of instability.\n  The example of ?Credit Default Swaps? on French reference entities",
        "comments": "27",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Through a long-period analysis of the inter-temporal relations between the\nFrench markets for credit default swaps (CDS), shares and bonds between 2001\nand 2008, this article shows how a financial innovation like CDS could heighten\nfinancial instability. After describing the operating principles of credit\nderivatives in general and CDS in particular, we construct two difference VAR\nmodels on the series: the share return rates, the variation in bond spreads and\nthe variation in CDS spreads for thirteen French companies, with the aim of\nbringing to light the relations between these three markets. According to these\nmodels, there is indeed an interdependence between the French share, CDS and\nbond markets, with a strong influence of the share market on the other two.\nThis interdependence increases during periods of tension on the markets\n(2001-2002, and since the summer of 2007).\n"
    },
    {
        "paper_id": 911.4207,
        "authors": "Rafael S. Calsaverini, Renato Vicente",
        "title": "An information theoretic approach to statistical dependence: copula\n  information",
        "comments": "to appear in Europhysics Letters",
        "journal-ref": "Europ. Phys. Lett. 88 68003 (2009)",
        "doi": "10.1209/0295-5075/88/68003",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the connection between information and copula theories by showing\nthat a copula can be employed to decompose the information content of a\nmultivariate distribution into marginal and dependence components, with the\nlatter quantified by the mutual information. We define the information excess\nas a measure of deviation from a maximum entropy distribution. The idea of\nmarginal invariant dependence measures is also discussed and used to show that\nempirical linear correlation underestimates the amplitude of the actual\ncorrelation in the case of non-Gaussian marginals. The mutual information is\nshown to provide an upper bound for the asymptotic empirical log-likelihood of\na copula. An analytical expression for the information excess of T-copulas is\nprovided, allowing for simple model identification within this family. We\nillustrate the framework in a financial data set.\n"
    },
    {
        "paper_id": 911.4258,
        "authors": "Fengzhong Wang, Kazuko Yamasaki, Shlomo Havlin, H. Eugene Stanley",
        "title": "Statistical Regularities of Equity Market Activity",
        "comments": "16 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Equity activity is an essential topic for financial market studies. To\nexplore its statistical regularities, we comprehensively examine the trading\nvalue, a measure of the equity activity, of the 3314 most-traded stocks in the\nU.S. equity market and find that (i) the trading values follow a log-normal\ndistribution; (ii) the standard deviation of the growth rate of the trading\nvalue obeys a power-law with the initial trading value, and the power-law\nexponent beta=0.14. Remarkably, both features hold for a wide range of sampling\nintervals, from 5 minutes to 20 trading days. Further, we show that all the\n3314 stocks have long-term correlations, and their Hurst exponents H follow a\nnormal distribution. Furthermore, we find that the Hurst exponent depends on\nthe size of the company. We also show that the relation between the scaling in\nthe growth rate and the long-term correlation is consistent with beta=1-H,\nsimilar to that found recently on human interaction activity by Rybski and\ncollaborators.\n"
    },
    {
        "paper_id": 911.4259,
        "authors": "Zhenya Yan",
        "title": "Financial rogue waves",
        "comments": "4 papges, 2 figures, Final version accepted in Commun. Theor. Phys.,\n  2010",
        "journal-ref": "Commun. Theor. Phys. 54 (2010) 947",
        "doi": "10.1088/0253-6102/54/5/31",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The financial rogue waves are reported analytically in the nonlinear option\npricing model due to Ivancevic, which is nonlinear wave alternative of the\nBlack-Scholes model. These solutions may be used to describe the possible\nphysical mechanisms for rogue wave phenomenon in financial markets and related\nfields.\n"
    },
    {
        "paper_id": 911.4679,
        "authors": "Johannes Vitalis Siven, Jeffrey Todd Lins",
        "title": "Gain/loss asymmetry in time series of individual stock prices and its\n  relationship to the leverage effect",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Previous research has shown that for stock indices, the most likely time\nuntil a return of a particular size has been observed is longer for gains than\nfor losses. We establish that this so-called gain/loss asymmetry is present\nalso for individual stocks and show that the phenomenon is closely linked to\nthe well-known leverage effect -- in the EGARCH model and a modified retarded\nvolatility model, the same parameter that governs the magnitude of the leverage\neffect also governs the gain/loss asymmetry.\n"
    },
    {
        "paper_id": 911.4763,
        "authors": "Gladys Hui Ting Lee, Yiting Zhang, Jian Cheng Wong, Manamohan Prusty,\n  Siew Ann Cheong",
        "title": "Causal Links Between US Economic Sectors",
        "comments": "elsarticle class, 64 pages, 18 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we perform a comparative segmentation and clustering analysis\nof the time series for the ten Dow Jones US economic sector indices between 14\nFebruary 2000 and 31 August 2008. From the temporal distributions of clustered\nsegments, we find that the US economy took one and a half years to recover from\nthe mid-1998-to-mid-2003 financial crisis, but only two months to completely\nenter the present financial crisis. We also find the oil & gas and basic\nmaterials sectors leading the recovery from the previous financial crisis,\nwhile the consumer goods and utilities sectors led the descent into the present\nfinancial crisis. On a macroscopic level, we find sectors going earlier into a\ncrisis emerge later from it, whereas sectors going later into the crisis emerge\nearlier. On the mesoscopic level, we find leading sectors experiencing stronger\nand longer volatility shocks, while trailing sectors experience weaker and\nshorter volatility shocks. In our shock-by-shock causal-link analysis, we also\nfind shorter delays between corresponding shocks in more closely related\neconomic sectors. In addition, our analysis reveals evidences for complex\nsectorial structures, as well as nonlinear amplification in the propagating\nvolatility shocks. From a perspective relevant to public policy, our study\nsuggests an endogeneous sectorial dynamics during the mid-2003 economic\nrecovery, in contrast to strong exogeneous driving by Federal Reserve interest\nrate cuts during the mid-2007 onset. Most interestingly, we find for the\nsequence of closely spaced interest rate cuts instituted in 2007/2008, the\nfirst few cuts effectively lowered market volatilities, while the next few cuts\ncounter-effectively increased market volatilities. Subsequent cuts evoked\nlittle response from the market.\n"
    },
    {
        "paper_id": 911.4801,
        "authors": "Jan Kallsen, Johannes Muhle-Karbe",
        "title": "Existence of Shadow Prices in Finite Probability Spaces",
        "comments": "11 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A shadow price is a process lying within the bid/ask prices of a market with\nproportional transaction costs, such that maximizing expected utility from\nconsumption in the frictionless market with this price process leads to the\nsame maximal utility as in the original market with transaction costs. For\nfinite probability spaces, this note provides an elementary proof for the\nexistence of such a shadow price.\n"
    },
    {
        "paper_id": 911.4859,
        "authors": "Stephan Denkl, Martina Goy, Jan Kallsen, Johannes Muhle-Karbe, Arnd\n  Pauwels",
        "title": "On the Performance of Delta Hedging Strategies in Exponential L\\'evy\n  Models",
        "comments": "25 pages, 5 figures. Second numerical example added",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the performance of non-optimal hedging strategies in exponential\nL\\'evy models. Given that both the payoff of the contingent claim and the\nhedging strategy admit suitable integral representations, we use the Laplace\ntransform approach of Hubalek et al. (2006) to derive semi-explicit formulas\nfor the resulting mean squared hedging error in terms of the cumulant\ngenerating function of the underlying L\\'evy process. In two numerical\nexamples, we apply these results to compare the efficiency of the Black-Scholes\nhedge and the model delta to the mean-variance optimal hedge in a normal\ninverse Gaussian and a diffusion-extended CGMY L\\'evy model.\n"
    },
    {
        "paper_id": 911.5048,
        "authors": "Sergey S. Stepanov",
        "title": "Resilience of Volatility",
        "comments": "30 pages with 33 figures, uses wrapfig.sty",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "abstract": "  The problem of non-stationarity in financial markets is discussed and related\nto the dynamic nature of price volatility. A new measure is proposed for\nestimation of the current asset volatility. A simple and illustrative\nexplanation is suggested of the emergence of significant serial\nautocorrelations in volatility and squared returns. It is shown that when\nnon-stationarity is eliminated, the autocorrelations substantially reduce and\nbecome statistically insignificant. The causes of non-Gaussian nature of the\nprobability of returns distribution are considered. For both stock and currency\nmarkets data samples, it is shown that removing the non-stationary component\nsubstantially reduces the kurtosis of distribution, bringing it closer to the\nGaussian one. A statistical criterion is proposed for controlling the degree of\nsmoothing of the empirical values of volatility. The hypothesis of smooth,\nnon-stochastic nature of volatility is put forward, and possible causes of\nvolatility shifts are discussed.\n"
    },
    {
        "paper_id": 911.5117,
        "authors": "Benjamin Jourdain (CERMICS), Michel Vellekoop",
        "title": "Regularity of the Exercise Boundary for American Put Options on Assets\n  with Discrete Dividends",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze the regularity of the optimal exercise boundary for the American\nPut option when the underlying asset pays a discrete dividend at a known time\n$t_d$ during the lifetime of the option. The ex-dividend asset price process is\nassumed to follow Black-Scholes dynamics and the dividend amount is a\ndeterministic function of the ex-dividend asset price just before the dividend\ndate. The solution to the associated optimal stopping problem can be\ncharacterised in terms of an optimal exercise boundary which, in contrast to\nthe case when there are no dividends, may no longer be monotone. In this paper\nwe prove that when the dividend function is positive and concave, then the\nboundary is non-increasing in a left-hand neighbourhood of $t_d$, and tends to\n$0$ as time tends to $t_d^-$ with a speed that we can characterize. When the\ndividend function is linear in a neighbourhood of zero, then we show continuity\nof the exercise boundary and a high contact principle in the left-hand\nneighbourhood of $t_d$. When it is globally linear, then right-continuity of\nthe boundary and the high contact principle are proved to hold globally.\nFinally, we show how all the previous results can be extended to multiple\ndividend payment dates in that case.\n"
    },
    {
        "paper_id": 911.5503,
        "authors": "Constantinos Kardaras",
        "title": "Finitely additive probabilities and the Fundamental Theorem of Asset\n  Pricing",
        "comments": "14 pages. Dedicated to Prof. Eckhard Platen, on the occasion of his\n  60th birthday. This is the 2nd part of what comprised the older arxiv\n  submission arXiv:0904.1798",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work aims at a deeper understanding of the mathematical implications of\nthe economically-sound condition of absence of arbitrages of the first kind in\na financial market. In the spirit of the Fundamental Theorem of Asset Pricing\n(FTAP), it is shown here that absence of arbitrages of the first kind in the\nmarket is equivalent to the existence of a finitely additive probability,\nweakly equivalent to the original and only locally countably additive, under\nwhich the discounted wealth processes become \"local martingales\". The\naforementioned result is then used to obtain an independent proof of the FTAP\nof Delbaen and Schachermayer. Finally, an elementary and short treatment of the\nprevious discussion is presented for the case of continuous-path semimartingale\nasset-price processes.\n"
    },
    {
        "paper_id": 911.5579,
        "authors": "Yuji Hishida and Kenji Yasutomi",
        "title": "Asymptotic behavior of prices of path dependent options",
        "comments": "16 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we give a numerical method for pricing long maturity, path\ndependent options by using the Markov property for each underlying asset. This\nenables us to approximate a path dependent option by using some kinds of plain\nvanillas. We give some examples whose underlying assets behave as some popular\nLevy processes. Moreover, we give some payoffs and functions used to\napproximate them.\n"
    },
    {
        "paper_id": 912.0372,
        "authors": "St\\'ephane Goutte (LAGA, OPTEA), Nadia Oudjane (LAGA), Francesco Russo\n  (LAGA, MathFi, CERMICS)",
        "title": "Variance Optimal Hedging for continuous time processes with independent\n  increments and applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For a large class of vanilla contingent claims, we establish an explicit\nF\\\"ollmer-Schweizer decomposition when the underlying is a process with\nindependent increments (PII) and an exponential of a PII process. This allows\nto provide an efficient algorithm for solving the mean variance hedging\nproblem. Applications to models derived from the electricity market are\nperformed.\n"
    },
    {
        "paper_id": 912.0434,
        "authors": "K.J. in 't Hout and J.A.C. Weideman",
        "title": "Appraisal of a contour integral method for the Black-Scholes and Heston\n  equations",
        "comments": "Paper has been published",
        "journal-ref": "SIAM J. Sc. Comp. 33, 763-785 (2011)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A contour integral method recently proposed by Weideman [IMA J. Numer. Anal.,\nto appear] for integrating semi-discrete advection-diffusion PDEs, is extended\nfor application to some of the important equations of mathematical finance.\nUsing estimates for the numerical range of the spatial operator, optimal\ncontour parameters are derived theoretically and tested numerically. Test\nexamples presented are the Black-Scholes PDE in one space dimension and the\nHeston PDE in two dimensions. In the latter case efficiency is compared to ADI\nsplitting schemes for solving this problem. In the examples it is found that\nthe contour integral method is superior for the range of medium to high\naccuracy requirements. Further improvements to the current implementation of\nthe contour integral method are suggested.\n"
    },
    {
        "paper_id": 912.0857,
        "authors": "Hiroshi Iyetomi, Yasuhiro Nakayama, Hiroshi Yoshikawa, Hideaki Aoyama,\n  Yoshi Fujiwara, Yuichi Ikeda, Wataru Souma",
        "title": "What Causes Business Cycles? Analysis of the Japanese Industrial\n  Production Data",
        "comments": "52 pages, 19 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We explore what causes business cycles by analyzing the Japanese industrial\nproduction data. The methods are spectral analysis and factor analysis. Using\nthe random matrix theory, we show that two largest eigenvalues are significant.\nTaking advantage of the information revealed by disaggregated data, we identify\nthe first dominant factor as the aggregate demand, and the second factor as\ninventory adjustment. They cannot be reasonably interpreted as technological\nshocks. We also demonstrate that in terms of two dominant factors, shipments\nlead production by four months. Furthermore, out-of-sample test demonstrates\nthat the model holds up even under the 2008-09 recession. Because a fall of\noutput during 2008-09 was caused by an exogenous drop in exports, it provides\nanother justification for identifying the first dominant factor as the\naggregate demand. All the findings suggest that the major cause of business\ncycles is real demand shocks.\n"
    },
    {
        "paper_id": 912.1037,
        "authors": "Mikhail I. Rumyantsev",
        "title": "About Some Applications of Kolmogorov Equations to the Simulation of\n  Financial Institutions Activity",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The goal of this article is to describe the concepts of system dynamics and\nits applications to the simulation modeling of financial institutions daily\nactivity. The hybrid method of the re-engineering of banking business processes\nbased upon combination of system dynamics, queuing theory and tools of ordinary\ndifferential equations (Kolmogorov equations) is offered.\n"
    },
    {
        "paper_id": 912.1321,
        "authors": "Tomas Bokes and Daniel Sevcovic",
        "title": "Early exercise boundary for American type of floating strike Asian\n  option and its numerical approximation",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we generalize and analyze the model for pricing American-style\nAsian options due to (Hansen and Jorgensen 2000) by including a continuous\ndividend rate $q$ and a general method of averaging of the floating strike. We\nfocus on the qualitative and quantitative analysis of the early exercise\nboundary. The first order Taylor series expansion of the early exercise\nboundary close to expiry is constructed. We furthermore propose an efficient\nnumerical algorithm for determining the early exercise boundary position based\non the front fixing method. Construction of the algorithm is based on a\nsolution to a nonlocal parabolic partial differential equation for the\ntransformed variable representing the synthesized portfolio. Various numerical\nresults and comparisons of our numerical method and the method developed by\n(Dai and Kwok 2006) are presented.\n"
    },
    {
        "paper_id": 912.1396,
        "authors": "Samuel N. Cohen and Robert J. Elliott",
        "title": "Time consistency and moving horizons for risk measures",
        "comments": "15 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider portfolio selection when decisions based on a dynamic risk\nmeasure are affected by the use of a moving horizon, and the possible\ninconsistencies that this creates. By giving a formal treatment of time\nconsistency which is independent of Bellman's equations, we show that there is\na new sense in which these decisions can be seen as consistent.\n"
    },
    {
        "paper_id": 912.1534,
        "authors": "Ronald Hochreiter",
        "title": "Evolutionary multi-stage financial scenario tree generation",
        "comments": null,
        "journal-ref": "Lecture Notes in Computer Science 6025:182-191. 2010.",
        "doi": "10.1007/978-3-642-12242-2_19",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Multi-stage financial decision optimization under uncertainty depends on a\ncareful numerical approximation of the underlying stochastic process, which\ndescribes the future returns of the selected assets or asset categories.\nVarious approaches towards an optimal generation of discrete-time,\ndiscrete-state approximations (represented as scenario trees) have been\nsuggested in the literature. In this paper, a new evolutionary algorithm to\ncreate scenario trees for multi-stage financial optimization models will be\npresented. Numerical results and implementation details conclude the paper.\n"
    },
    {
        "paper_id": 912.1617,
        "authors": "Alexander Saichev, Didier Sornette, Vladimir Filimonov and Fulvio\n  Corsi",
        "title": "Homogeneous Volatility Bridge Estimators",
        "comments": "25 pages, 9 figures",
        "journal-ref": "Quantitative Finance 14 (1), 87-89 (2013)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a theory of homogeneous volatility bridge estimators for log-price\nstochastic processes. The main tool of our theory is the parsimonious encoding\nof the information contained in the open, high and low prices of incomplete\nbridge, corresponding to given log-price stochastic process, and in its close\nvalue, for a given time interval. The efficiency of the new proposed estimators\nis favorably compared with that of the Garman-Klass and Parkinson estimators.\n"
    },
    {
        "paper_id": 912.1841,
        "authors": "Brice Franke, Michael Stolz",
        "title": "A duality approach to the worst case value at risk for a sum of\n  dependent random variables with known covariances",
        "comments": "13 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose an approach to the aggregation of risks which is based on\nestimation of simple quantities (such as covariances) associated to a vector of\ndependent random variables, and which avoids the use of parametric families of\ncopulae. Our main result demonstrates that the method leads to bounds on the\nworst case Value at Risk for a sum of dependent random variables. Its proof\napplies duality theory for infinite dimensional linear programs.\n"
    },
    {
        "paper_id": 912.1879,
        "authors": "Marcel Nutz",
        "title": "The Opportunity Process for Optimal Consumption and Investment with\n  Power Utility",
        "comments": "24 pages, forthcoming in 'Mathematics and Financial Economics'",
        "journal-ref": "Math. Financ. Econ., 3(3):139-159, 2010",
        "doi": "10.1007/s11579-010-0031-0",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the utility maximization problem for power utility random fields in\na semimartingale financial market, with and without intermediate consumption.\nThe notion of an opportunity process is introduced as a reduced form of the\nvalue process of the resulting stochastic control problem. We show how the\nopportunity process describes the key objects: optimal strategy, value\nfunction, and dual problem. The results are applied to obtain monotonicity\nproperties of the optimal consumption.\n"
    },
    {
        "paper_id": 912.1883,
        "authors": "Marcel Nutz",
        "title": "The Bellman equation for power utility maximization with semimartingales",
        "comments": "Published in at http://dx.doi.org/10.1214/11-AAP776 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2012, Vol. 22, No. 1, 363-406",
        "doi": "10.1214/11-AAP776",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study utility maximization for power utility random fields with and\nwithout intermediate consumption in a general semimartingale model with closed\nportfolio constraints. We show that any optimal strategy leads to a solution of\nthe corresponding Bellman equation. The optimal strategies are described\npointwise in terms of the opportunity process, which is characterized as the\nminimal solution of the Bellman equation. We also give verification theorems\nfor this equation.\n"
    },
    {
        "paper_id": 912.1885,
        "authors": "Marcel Nutz",
        "title": "Power Utility Maximization in Constrained Exponential L\\'evy Models",
        "comments": "22 pages; forthcoming in 'Mathematical Finance'",
        "journal-ref": "Mathematical Finance, Vol. 22, No. 4, pp. 690-709, 2012",
        "doi": "10.1111/j.1467-9965.2011.00480.x",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study power utility maximization for exponential L\\'evy models with\nportfolio constraints, where utility is obtained from consumption and/or\nterminal wealth. For convex constraints, an explicit solution in terms of the\nL\\'evy triplet is constructed under minimal assumptions by solving the Bellman\nequation. We use a novel transformation of the model to avoid technical\nconditions. The consequences for q-optimal martingale measures are discussed as\nwell as extensions to non-convex constraints.\n"
    },
    {
        "paper_id": 912.1925,
        "authors": "Irmingard Eder, Claudia Kl\\\"uppelberg",
        "title": "The first passage event for sums of dependent L\\'evy processes with\n  applications to insurance risk",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP601 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2009, Vol. 19, No. 6, 2047-2079",
        "doi": "10.1214/09-AAP601",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For the sum process $X=X^1+X^2$ of a bivariate L\\'evy process $(X^1,X^2)$\nwith possibly dependent components, we derive a quintuple law describing the\nfirst upwards passage event of $X$ over a fixed barrier, caused by a jump, by\nthe joint distribution of five quantities: the time relative to the time of the\nprevious maximum, the time of the previous maximum, the overshoot, the\nundershoot and the undershoot of the previous maximum. The dependence between\nthe jumps of $X^1$ and $X^2$ is modeled by a L\\'evy copula. We calculate these\nquantities for some examples, where we pay particular attention to the\ninfluence of the dependence structure. We apply our findings to the ruin event\nof an insurance risk process.\n"
    },
    {
        "paper_id": 912.1985,
        "authors": "Hiroshi Iyetomi, Yasuhiro Nakayama, Hideaki Aoyama, Yoshi Fujiwara,\n  Yuichi Ikeda, Wataru Souma",
        "title": "Fluctuation-Dissipation Theory of Input-Output Interindustrial\n  Correlations",
        "comments": "13 pages, 13 figures and 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this study, the fluctuation-dissipation theory is invoked to shed light on\ninput-output interindustrial relations at a macroscopic level by its\napplication to IIP (indices of industrial production) data for Japan.\nStatistical noise arising from finiteness of the time series data is carefully\nremoved by making use of the random matrix theory in an eigenvalue analysis of\nthe correlation matrix; as a result, two dominant eigenmodes are detected. Our\nprevious study successfully used these two modes to demonstrate the existence\nof intrinsic business cycles. Here a correlation matrix constructed from the\ntwo modes describes genuine interindustrial correlations in a statistically\nmeaningful way. Further it enables us to quantitatively discuss the\nrelationship between shipments of final demand goods and production of\nintermediate goods in a linear response framework. We also investigate\ndistinctive external stimuli for the Japanese economy exerted by the current\nglobal economic crisis. These stimuli are derived from residuals of moving\naverage fluctuations of the IIP remaining after subtracting the long-period\ncomponents arising from inherent business cycles. The observation reveals that\nthe fluctuation-dissipation theory is applicable to an economic system that is\nsupposed to be far from physical equilibrium.\n"
    },
    {
        "paper_id": 912.2016,
        "authors": "Chuang Liu and Wei-Xing Zhou (ECUST)",
        "title": "Superfamily classification of nonstationary time series based on DFA\n  scaling exponents",
        "comments": "5 pages, 5 figures",
        "journal-ref": "J. Phys. A: Math. Theor. 43 (2010) 495005",
        "doi": "10.1088/1751-8113/43/49/495005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The superfamily phenomenon of time series with different dynamics can be\ncharacterized by the motif rank patterns observed in the nearest-neighbor\nnetworks of the time series in phase space. However, the determinants of\nsuperfamily classification are unclear. We attack this problem by studying the\ninfluence of linear temporal correlations and multifractality using fractional\nBrownian motions (FBMs) and multifractal random walks (MRWs). Numerical\ninvestigations unveil that the classification of superfamily phenomenon is\nuniquely determined by the detrended fluctuation analysis (DFA) scaling\nexponent $\\alpha$ of the time series. Only four motif patterns are observed in\nthe simulated data, which are delimited by three DFA scaling exponents $\\alpha\n\\simeq 0.25$, $\\alpha \\simeq 0.35$ and $\\alpha \\simeq 0.45$. The validity of\nthe result is confirmed by stock market indexes and turbulence velocity\nsignals.\n"
    },
    {
        "paper_id": 912.2595,
        "authors": "Aleksandar Mijatovi\\'c and Martijn Pistorius",
        "title": "Exotic derivatives under stochastic volatility models with jumps",
        "comments": "Paper contains new convergence results. Section on the fluctuation\n  theory has been extended. To appear in the forthcoming AMaMeF Springer\n  volume. 47 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In equity and foreign exchange markets the risk-neutral dynamics of the\nunderlying asset are commonly represented by stochastic volatility models with\njumps. In this paper we consider a dense subclass of such models and develop\nanalytically tractable formulae for the prices of a range of first-generation\nexotic derivatives. We provide closed form formulae for the Fourier transforms\nof vanilla and forward starting option prices as well as a formula for the\nslope of the implied volatility smile for large strikes. A simple explicit\napproximation formula for the variance swap price is given. The prices of\nvolatility swaps and other volatility derivatives are given as a\none-dimensional integral of an explicit function. Analytically tractable\nformulae for the Laplace transform (in maturity) of the double-no-touch options\nand the Fourier-Laplace transform (in strike and maturity) of the double\nknock-out call and put options are obtained. The proof of the latter formulae\nis based on extended matrix Wiener-Hopf factorisation results. We also provide\nconvergence results.\n"
    },
    {
        "paper_id": 912.2816,
        "authors": "Christian Meyer",
        "title": "The Bivariate Normal Copula",
        "comments": "24 pages",
        "journal-ref": null,
        "doi": "10.1080/03610926.2011.611316",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We collect well known and less known facts about the bivariate normal\ndistribution and translate them into copula language. In addition, we prove a\nvery general formula for the bivariate normal copula, we compute Gini's gamma,\nand we provide improved bounds and approximations on the diagonal.\n"
    },
    {
        "paper_id": 912.3028,
        "authors": "Damiano Brigo, Marco Tarenghi",
        "title": "Credit Default Swap Calibration and Equity Swap Valuation under\n  Counterparty Risk with a Tractable Structural Model",
        "comments": "Reduced version in Proceedings of the FEA 2004 Conference at MIT,\n  Cambridge, Massachusetts, November 8-10, and in: Pykhtin, M. (Editor),\n  Counterparty Credit Risk Modeling: Risk Management, Pricing and Regulation.\n  Risk Books, 2005, London",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we develop a tractable structural model with analytical default\nprobabilities depending on some dynamics parameters, and we show how to\ncalibrate the model using a chosen number of Credit Default Swap (CDS) market\nquotes. We essentially show how to use structural models with a calibration\ncapability that is typical of the much more tractable credit-spread based\nintensity models. We apply the structural model to a concrete calibration case\nand observe what happens to the calibrated dynamics when the CDS-implied credit\nquality deteriorates as the firm approaches default. Finally we provide a\ntypical example of a case where the calibrated structural model can be used for\ncredit pricing in a much more convenient way than a calibrated reduced form\nmodel: The pricing of counterparty risk in an equity swap.\n"
    },
    {
        "paper_id": 912.3031,
        "authors": "Damiano Brigo, Marco Tarenghi",
        "title": "Credit Default Swap Calibration and Counterparty Risk Valuation with a\n  Scenario based First Passage Model",
        "comments": "Revised version included in D. Brigo, M. Morini, Structural credit\n  calibration, 2006, Risk Magazine, April issue",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work we develop a tractable structural model with analytical default\nprobabilities depending on a random default barrier and possibly random\nvolatility ideally associated with a scenario based underlying firm debt. We\nshow how to calibrate this model using a chosen number of reference Credit\nDefault Swap (CDS) market quotes. In general this model can be seen as a\npossible extension of the time-varying AT1P model in Brigo and Tarenghi (2004).\nThe calibration capability of the Scenario Volatility/Barrier model (SVBAT1P),\nwhen keeping time-constant volatility, appears inferior to the one of AT1P with\ntime-varying deterministic volatility. The SVBAT1P model, however, maintains\nthe benefits of time-homogeneity and can lead to satisfactory calibration\nresults, as we show in a case study where we compare different choices on\nscenarios and parameters. Similarly to AT1P, SVBAT1P is suited to pricing\nhybrid equity/credit derivatives and to evaluate counterparty risk in equity\npayoffs, and more generally to evaluate hybrid credit/equity payoffs. We\nconsider the equity return swap in Brigo and Tarenghi (2004) and show its\nvaluation under SVBAT1P with the same CDS and equity calibration input used\nearlier for AT1P, and further we hint at equity default swap valuation in the\nconclusions.\n"
    },
    {
        "paper_id": 912.3132,
        "authors": "Ying Jiao (PMA)",
        "title": "Multiple defaults and contagion risks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study multiple defaults where the global market information is modelled as\nprogressive enlargement of filtrations. We shall provide a general pricing\nformula by establishing a relationship between the enlarged filtration and the\nreference default-free filtration in the random measure framework. On each\ndefault scenario, the formula can be interpreted as a Radon-Nikodym derivative\nof random measures. The contagion risks are studied in the multi-defaults\nsetting where we consider the optimal investment problem in a contagion risk\nmodel and show that the optimization can be effectuated in a recursive manner\nwith respect to the default-free filtration.\n"
    },
    {
        "paper_id": 912.3362,
        "authors": "Jan Kallsen, Johannes Muhle-Karbe, Richard Vierthauer",
        "title": "Asymptotic Power Utility-Based Pricing and Hedging",
        "comments": "32 pages, 4 figures, to appear in \"Mathematics and Financial\n  Economics\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Kramkov and Sirbu (2006, 2007) have shown that first-order approximations of\npower utility-based prices and hedging strategies can be computed by solving a\nmean-variance hedging problem under a specific equivalent martingale measure\nand relative to a suitable numeraire. In order to avoid the introduction of an\nadditional state variable necessitated by the change of numeraire, we propose\nan alternative representation in terms of the original numeraire. More\nspecifically, we characterize the relevant quantities using semimartingale\ncharacteristics similarly as in Cerny and Kallsen (2007) for mean-variance\nhedging. These results are illustrated by applying them to exponential L\\'evy\nprocesses and stochastic volatility models of Barndorff-Nielsen and Shephard\ntype.\n"
    },
    {
        "paper_id": 912.339,
        "authors": "Dariusz Grech, Lukasz Czarnecki",
        "title": "Multifractal dynamics of stock markets",
        "comments": null,
        "journal-ref": "Acta Physica Polonica A 117 (2010) 623-629",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a comparative analysis of multifractal properties of financial\ntime series built on stock indices from developing (WIG) and developed (S&P500)\nfinancial markets. It is shown how the multifractal image of the market is\naltered with the change of the length of time series and with the economic\nsituation on the market. We emphasize that the proper adjustment of scaling\nrange for multiscaling power laws is essential to obtain the multifractal image\nof time series. We analyze in this paper multifractal properties of real\nfinancial time series using H\\\"older $f(\\alpha)$ representation and\nmultifractal-DFA method. It is also investigated how multifractal properties of\nstocks change with variety of \"surgeries\" done on the initial real financial\ntime series. This way we reveal main phenomena on the market influencing its\nmultifractal dynamics. In particular, we focus on examining how multifractal\npicture of real time series changes when one cuts off extreme events like\ncrashes or rupture points, and how fluctuations around the main trend in time\nseries influence the multifractal behavior of financial series in the long-time\nhorizon for both developed and developing markets.\n"
    },
    {
        "paper_id": 912.3516,
        "authors": "Hans Manner and Johan Segers",
        "title": "Tails of correlation mixtures of elliptical copulas",
        "comments": "21 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Correlation mixtures of elliptical copulas arise when the correlation\nparameter is driven itself by a latent random process. For such copulas, both\npenultimate and asymptotic tail dependence are much larger than for ordinary\nelliptical copulas with the same unconditional correlation. Furthermore, for\nGaussian and Student t-copulas, tail dependence at sub-asymptotic levels is\ngenerally larger than in the limit, which can have serious consequences for\nestimation and evaluation of extreme risk. Finally, although correlation\nmixtures of Gaussian copulas inherit the property of asymptotic independence,\nat the same time they fall in the newly defined category of near asymptotic\ndependence. The consequences of these findings for modeling are assessed by\nmeans of a simulation study and a case study involving financial time series.\n"
    },
    {
        "paper_id": 912.3652,
        "authors": "Edward Hoyle, Lane P. Hughston, Andrea Macrina",
        "title": "Levy Random Bridges and the Modelling of Financial Information",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The information-based asset-pricing framework of Brody, Hughston and Macrina\n(BHM) is extended to include a wider class of models for market information. In\nthe BHM framework, each asset is associated with a collection of random cash\nflows. The price of the asset is the sum of the discounted conditional\nexpectations of the cash flows. The conditional expectations are taken with\nrespect to a filtration generated by a set of \"information processes\". The\ninformation processes carry imperfect information about the cash flows. To\nmodel the flow of information, we introduce in this paper a class of processes\nwhich we term Levy random bridges (LRBs). This class generalises the Brownian\nbridge and gamma bridge information processes considered by BHM. An LRB is\ndefined over a finite time horizon. Conditioned on its terminal value, an LRB\nis identical in law to a Levy bridge. We consider in detail the case where the\nasset generates a single cash flow $X_T$ occurring at a fixed date $T$. The\nflow of market information about $X_T$ is modelled by an LRB terminating at the\ndate $T$ with the property that the (random) terminal value of the LRB is equal\nto $X_T$. An explicit expression for the price process of such an asset is\nfound by working out the discounted conditional expectation of $X_T$ with\nrespect to the natural filtration of the LRB. The prices of European options on\nsuch an asset are calculated.\n"
    },
    {
        "paper_id": 912.3771,
        "authors": "Jorgen Vitting Andersen, Andrzej Nowak, Giulia Rotundo and Lael\n  Parrott",
        "title": "Tremor price dynamics in the world's network of stock exchanges",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use insight from a model of earth tectonic plate movement to obtain a new\nunderstanding of the build up and release of stress in the price dynamics of\nthe worlds stock exchanges. Nonlinearity enters the model due to a behavioral\nattribute of humans reacting disproportionately to big changes. This nonlinear\nresponse allows us to classify price movements of a given stock index as either\nbeing generated due to specific economic news for the country in question, or\nby the ensemble of the worlds stock exchanges reacting together like a complex\nsystem. Similar in structure to the Capital Asset Pricing Model in Finance, the\nmodel predicts how an individual stock exchange should be priced in terms of\nthe performance of the global market of exchanges, but with human behavioral\ncharacteristics included in the pricing. A number of the models assumptions are\nvalidated against empirical data for 24 of the worlds leading stock exchanges.\nWe show how treshold effects can lead to synchronization in the global network\nof stock exchanges.\n"
    },
    {
        "paper_id": 912.4312,
        "authors": "Delia Coculescu",
        "title": "From the decompositions of a stopping time to risk premium\n  decompositions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We build a general model for pricing defaultable claims. In addition to the\nusual absence of arbitrage assumption, we assume that one defaultable asset (at\nleast) looses value when the default occurs. We prove that under this\nassumption, in some standard market filtrations, default times are totally\ninaccessible stopping times; we therefore proceed to a systematic construction\nof default times with particular emphasis on totally inaccessible stopping\ntimes. Surprisingly, this abstract mathematical construction, reveals a very\nspecific and useful way in which default models can be built, using both market\nfactors and idiosyncratic factors. We then provide all the relevant\ncharacteristics of a default time (i.e. the Az\\'ema supermartingale and its\nDoob-Meyer decomposition) given the information about these factors. We also\nprovide explicit formulas for the prices of defaultable claims and analyze the\nrisk premiums that form in the market in anticipation of losses which occur at\nthe default event. The usual reduced-form framework is extended in order to\ninclude possible economic shocks, in particular jumps of the recovery process\nat the default time. This formulas are not classic and we point out that the\nknowledge of the default compensator or the intensity process is not anymore a\nsufficient quantity for finding explicit prices, but we need indeed the Az\\'ema\nsupermartingale and its Doob-Meyer decomposition.\n"
    },
    {
        "paper_id": 912.4404,
        "authors": "Damiano Brigo, Massimo Morini, Marco Tarenghi",
        "title": "Credit Calibration with Structural Models: The Lehman case and Equity\n  Swaps under Counterparty Risk",
        "comments": "An extended and updated version of this paper with the title \"Credit\n  Calibration with Structural Models and Equity Return Swap valuation under\n  Counterparty Risk\" will appear in: Bielecki, T., Brigo, D., and Patras, F.\n  (Editors), Recent advancements in theory and practice of credit derivatives,\n  Bloomberg Press, 2010",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we develop structural first passage models (AT1P and SBTV) with\ntime-varying volatility and characterized by high tractability, moving from the\noriginal work of Brigo and Tarenghi (2004, 2005) [19] [20] and Brigo and Morini\n(2006)[15]. The models can be calibrated exactly to credit spreads using\nefficient closed-form formulas for default probabilities. Default events are\ncaused by the value of the firm assets hitting a safety threshold, which\ndepends on the financial situation of the company and on market conditions. In\nAT1P this default barrier is deterministic. Instead SBTV assumes two possible\nscenarios for the initial level of the default barrier, for taking into account\nuncertainty on balance sheet information. While in [19] and [15] the models are\nanalyzed across Parmalat's history, here we apply the models to exact\ncalibration of Lehman Credit Default Swap (CDS) data during the months\npreceding default, as the crisis unfolds. The results we obtain with AT1P and\nSBTV have reasonable economic interpretation, and are particularly realistic\nwhen SBTV is considered. The pricing of counterparty risk in an Equity Return\nSwap is a convenient application we consider, also to illustrate the\ninteraction of our credit models with equity models in hybrid products context.\n"
    },
    {
        "paper_id": 912.4533,
        "authors": "Rafa{\\l} {\\L}ochowski",
        "title": "Truncated Variation, Upward Truncated Variation and Downward Truncated\n  Variation of Brownian Motion with Drift - their Characteristics and\n  Applications",
        "comments": null,
        "journal-ref": "(2011) Stochastic Process. Appl. 121, 378--393",
        "doi": "10.1016/j.spa.2010.10.005",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the paper \"On Truncated Variation of Brownian Motion with Drift\" (Bull.\nPol. Acad. Sci. Math. 56 (2008), no.4, 267 - 281) we defined truncated\nvariation of Brownian motion with drift, $W_t = B_t + \\mu t, t\\geq 0,$ where\n$(B_t)$ is a standard Brownian motion. Truncated variation differs from regular\nvariation by neglecting jumps smaller than some fixed $c > 0$. We prove that\ntruncated variation is a random variable with finite moment-generating function\nfor any complex argument. We also define two closely related quantities -\nupward truncated variation and downward truncated variation. The defined\nquantities may have some interpretation in financial mathematics. Exponential\nmoment of upward truncated variation may be interpreted as the maximal possible\nreturn from trading a financial asset in the presence of flat commission when\nthe dynamics of the prices of the asset follows a geometric Brownian motion\nprocess. We calculate the Laplace transform with respect to time parameter of\nthe moment-generating functions of the upward and downward truncated\nvariations. As an application of the obtained formula we give an exact formula\nfor expected value of upward and downward truncated variations. We give also\nexact (up to universal constants) estimates of the expected values of the\nmentioned quantities.\n"
    },
    {
        "paper_id": 912.4609,
        "authors": "Arthur M. Berd, Roy Mashal, Peili Wang",
        "title": "Defining, Estimating and Using Credit Term Structures. Part 1:\n  Consistent Valuation Measures",
        "comments": "27 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this three-part series of papers, we argue that the conventional spread\nmeasures are not well defined for credit-risky bonds and introduce a set of\ncredit term structures which correct for the biases associated with the\nstrippable cash flow valuation assumption. We demonstrate that the resulting\nestimates are significantly more robust and remain meaningful even when applied\nto deeply distressed bonds. We also suggest a new definition of credit bond\nduration and convexity which remains consistent for distressed bonds and\nintroduce new relative value measures for individual bonds in the context of\nsector or issuer credit curves, as well as for the basis between cash bonds and\ncredit default swaps (CDS).\n"
    },
    {
        "paper_id": 912.4614,
        "authors": "Arthur M. Berd, Roy Mashal, Peili Wang",
        "title": "Defining, Estimating and Using Credit Term Structures. Part 2:\n  Consistent Risk Measures",
        "comments": "17 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the second part of our series we suggest new definitions of credit bond\nduration and convexity that remain consistent across all levels of credit\nquality including deeply distressed bonds and introduce additional risk\nmeasures that are consistent with the survival-based valuation framework. We\nthen show how to use these risk measures for the construction of market neutral\nportfolios.\n"
    },
    {
        "paper_id": 912.4618,
        "authors": "Arthur M. Berd, Roy Mashal, Peili Wang",
        "title": "Defining, Estimating and Using Credit Term Structures. Part 3:\n  Consistent CDS-Bond Basis",
        "comments": "20 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the third part of this series we introduce consistent relative value\nmeasures for CDS-Bond basis trades using the bond-implied CDS term structure\nderived from fitted survival rate curves. We explain why this measure is better\nthan the traditionally used Z-spread or Libor OAS and offer simplified hedging\nand trading strategies which take advantage of the relative value across the\nentire range of maturities of cash and synthetic credit markets.\n"
    },
    {
        "paper_id": 912.4621,
        "authors": "Arthur M. Berd",
        "title": "Dynamic Estimation of Credit Rating Transition Probabilities",
        "comments": "28 pages, 23 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a continuous-time maximum likelihood estimation methodology for\ncredit rating transition probabilities, taking into account the presence of\ncensored data. We perform rolling estimates of the transition matrices with\nexponential time weighting with varying horizons and discuss the underlying\ndynamics of transition generator matrices in the long-term and short-term\nestimation horizons.\n"
    },
    {
        "paper_id": 912.4623,
        "authors": "Arthur M. Berd",
        "title": "A Guide to Modeling Credit Term Structures",
        "comments": "54 pages, 13 figures (references fixed)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We give a comprehensive review of credit term structure modeling\nmethodologies. The conventional approach to modeling credit term structure is\nsummarized and shown to be equivalent to a particular type of the reduced form\ncredit risk model, the fractional recovery of market value approach. We argue\nthat the corporate practice and market observations do not support this\napproach. The more appropriate assumption is the fractional recovery of par,\nwhich explicitly violates the strippable cash flow valuation assumption that is\nnecessary for the conventional credit term structure definitions to hold. We\nformulate the survival-based valuation methodology and give alternative\nspecifications for various credit term structures that are consistent with\nmarket observations, and show how they can be empirically estimated from the\nobservable prices. We rederive the credit triangle relationship by considering\nthe replication of recovery swaps. We complete the exposition by presenting a\nconsistent measure of CDS-Bond basis and demonstrate its relation to a static\nhedging strategy, which remains valid for non-par bonds and non-flat term\nstructures of interest rates and credit risk.\n"
    },
    {
        "paper_id": 912.4723,
        "authors": "David Morton de Lachapelle and Damien Challet",
        "title": "Turnover, account value and diversification of real traders: evidence of\n  collective portfolio optimizing behavior",
        "comments": "26 pages, 9 figures, Fig. 8 fixed",
        "journal-ref": null,
        "doi": "10.1088/1367-2630/12/7/075039",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Despite the availability of very detailed data on financial market,\nagent-based modeling is hindered by the lack of information about real trader\nbehavior. This makes it impossible to validate agent-based models, which are\nthus reverse-engineering attempts. This work is a contribution to the building\nof a set of stylized facts about the traders themselves. Using the client\ndatabase of Swissquote Bank SA, the largest on-line Swiss broker, we find\nempirical relationships between turnover, account values and the number of\nassets in which a trader is invested. A theory based on simple mean-variance\nportfolio optimization that crucially includes variable transaction costs is\nable to reproduce faithfully the observed behaviors. We finally argue that our\nresults bring into light the collective ability of a population to construct a\nmean-variance portfolio that takes into account the structure of transaction\ncosts\n"
    },
    {
        "paper_id": 912.4782,
        "authors": "Wei-Xing Zhou (ECUST)",
        "title": "Finite-size effect and the components of multifractality in financial\n  volatility",
        "comments": "9 RevTex pages including 9 eps figures. Comments and suggestions are\n  warmly welcome",
        "journal-ref": "Chaos, Solitons & Fractals 45 (2), 147-155 (2012)",
        "doi": "10.1016/j.chaos.2011.11.004",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many financial variables are found to exhibit multifractal nature, which is\nusually attributed to the influence of temporal correlations and fat-tailedness\nin the probability distribution (PDF). Based on the partition function approach\nof multifractal analysis, we show that there is a marked finite-size effect in\nthe detection of multifractality, and the effective multifractality is the\napparent multifractality after removing the finite-size effect. We find that\nthe effective multifractality can be further decomposed into two components,\nthe PDF component and the nonlinearity component. Referring to the normal\ndistribution, we can determine the PDF component by comparing the effective\nmultifractality of the original time series and the surrogate data that have a\nnormal distribution and keep the same linear and nonlinear correlations as the\noriginal data. We demonstrate our method by taking the daily volatility data of\nDow Jones Industrial Average from 26 May 1896 to 27 April 2007 as an example.\nExtensive numerical experiments show that a time series exhibits effective\nmultifractality only if it possesses nonlinearity and the PDF has impact on the\neffective multifractality only when the time series possesses nonlinearity. Our\nmethod can also be applied to judge the presence of multifractality and\ndetermine its components of multifractal time series in other complex systems.\n"
    },
    {
        "paper_id": 912.4898,
        "authors": "Anand Banerjee, Victor M. Yakovenko",
        "title": "Universal patterns of inequality",
        "comments": "Accepted to New Journal of Physics. 27 pages (IOP preprint style), 8\n  figures. V.2: Updated figs. 3 and 8, many references added, all text edited.\n  V.3: Minor changes, last 3 references added. V.4: Minor stylistic changes and\n  reference updates in proofs",
        "journal-ref": "New Journal of Physics 12, 075032 (2010)",
        "doi": "10.1088/1367-2630/12/7/075032",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Probability distributions of money, income, and energy consumption per capita\nare studied for ensembles of economic agents. The principle of entropy\nmaximization for partitioning of a limited resource gives exponential\ndistributions for the investigated variables. A non-equilibrium difference of\nmoney temperatures between different systems generates net fluxes of money and\npopulation. To describe income distribution, a stochastic process with additive\nand multiplicative components is introduced. The resultant distribution\ninterpolates between exponential at the low end and power law at the high end,\nin agreement with the empirical data for USA. We show that the increase of\nincome inequality in USA originates primarily from the increase of the income\nfraction going to the upper tail, which now exceeds 20% of the total income.\nAnalyzing the data from the World Resources Institute, we find that the\ndistribution of energy consumption per capita around the world can be\napproximately described by the exponential function. Comparing the data for\n1990, 2000, and 2005, we discuss the effect of globalization on the inequality\nof energy consumption.\n"
    },
    {
        "paper_id": 912.4973,
        "authors": "Guanghui Huang, Jianping Wan",
        "title": "Probabilities of Positive Returns and Values of Call Options",
        "comments": "14 pages, 4 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The true probability of a European call option to achieve positive return is\ninvestigated under the Black-Scholes model. It is found that the probability is\ndetermined by those market factors appearing in the BS formula, besides the\ngrowth rate of stock price. Our numerical investigations indicate that the\nbiases of BS formula is correlated with the growth rate of stock price. An\nalternative method to price European call option is proposed, which adopts an\nequilibrium argument to determine option price through the probability of\npositive return. It is found that the BS values are on average larger than the\nvalues of proposed method for out-of-the-money options, and smaller than the\nvalues of proposed method for in-the-money options. A typical smile shape of\nimplied volatility is also observed in our numerical investigation. These\ntheoretical observations are similar to the empirical anomalies of BS values,\nwhich indicates that the proposed valuation method may have some merit.\n"
    },
    {
        "paper_id": 912.5013,
        "authors": "Victor Chernozhukov, Ivan Fernandez-Val",
        "title": "Inference for Extremal Conditional Quantile Models, with an Application\n  to Market and Birthweight Risks",
        "comments": "41 pages, 9 figures",
        "journal-ref": "Review of Economic Studies (2011) 78 (2): 559-589",
        "doi": "10.1093/restud/rdq020",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Quantile regression is an increasingly important empirical tool in economics\nand other sciences for analyzing the impact of a set of regressors on the\nconditional distribution of an outcome. Extremal quantile regression, or\nquantile regression applied to the tails, is of interest in many economic and\nfinancial applications, such as conditional value-at-risk, production\nefficiency, and adjustment bands in (S,s) models. In this paper we provide\nfeasible inference tools for extremal conditional quantile models that rely\nupon extreme value approximations to the distribution of self-normalized\nquantile regression statistics. The methods are simple to implement and can be\nof independent interest even in the non-regression case. We illustrate the\nresults with two empirical examples analyzing extreme fluctuations of a stock\nreturn and extremely low percentiles of live infants' birthweights in the range\nbetween 250 and 1500 grams.\n"
    },
    {
        "paper_id": 912.542,
        "authors": "Abhik Ghosh, Kausik Gangopadhyay, B. Basu",
        "title": "Consumer Expenditure Distribution in India, 1983-2007: Evidence of a\n  Long Pareto Tail",
        "comments": "13 pages, 8 figures, Typing errors are corrected final version\n  accepted in Physica A",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work presents an empirical study of the evolution of the consumer\nexpenditure distribution in India during 1982-2007. We have used the National\nSample Survey Organization data and analysed the expenditure distribution for\nthe urban and rural sectors. It is found that this distribution is a mixture of\ntwo distributions, more particularly, it follows a lognormal in the lower tail\nand a Pareto distribution in the higher end. The Pareto tail consists of a\nremarkable 30-40% of the population in the upper end and the lower end is\nsuitably modeled by the lognormal one. The goodness-of-fit tests endorse the\nproposed distribution. Moreover, the Pareto tail is widening over time for the\nrural sector. The Gini coefficient, a prominent measure for inequality, for the\nexpenditure distribution is found to be stable for the entire time span.\n"
    },
    {
        "paper_id": 912.5427,
        "authors": "Damiano Brigo, Andrea Pallavicini, Roberto Torresetti",
        "title": "Credit models and the crisis, or: how I learned to stop worrying and\n  love the CDOs",
        "comments": "A vastly extended and updated version of this paper will appear as a\n  book: \"Credit models and the crisis: a journey into CDOs, copulas,\n  correlations and dynamic models\", Wiley, Chichester, 2010",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We follow a long path for Credit Derivatives and Collateralized Debt\nObligations (CDOs) in particular, from the introduction of the Gaussian copula\nmodel and the related implied correlations to the introduction of\narbitrage-free dynamic loss models capable of calibrating all the tranches for\nall the maturities at the same time. En passant, we also illustrate the implied\ncopula, a method that can consistently account for CDOs with different\nattachment and detachment points but not for different maturities. The\ndiscussion is abundantly supported by market examples through history. The\ndangers and critics we present to the use of the Gaussian copula and of implied\ncorrelation had all been published by us, among others, in 2006, showing that\nthe quantitative community was aware of the model limitations before the\ncrisis. We also explain why the Gaussian copula model is still used in its base\ncorrelation formulation, although under some possible extensions such as random\nrecovery. Overall we conclude that the modeling effort in this area of the\nderivatives market is unfinished, partly for the lack of an operationally\nattractive single-name consistent dynamic loss model, and partly because of the\ndiminished investment in this research area.\n"
    },
    {
        "paper_id": 912.5448,
        "authors": "Miguel A. Fuentes, Austin Gerig, and Javier Vicente",
        "title": "Universal Behavior of Extreme Price Movements in Stock Markets",
        "comments": "4 pages, 3 figures",
        "journal-ref": "PLoS ONE 4(12) e8243 (2009)",
        "doi": "10.1371/journal.pone.0008243",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Many studies assume stock prices follow a random process known as geometric\nBrownian motion. Although approximately correct, this model fails to explain\nthe frequent occurrence of extreme price movements, such as stock market\ncrashes. Using a large collection of data from three different stock markets,\nwe present evidence that a modification to the random model -- adding a slow,\nbut significant, fluctuation to the standard deviation of the process --\naccurately explains the probability of different-sized price changes, including\nthe relative high frequency of extreme movements. Furthermore, we show that\nthis process is similar across stocks so that their price fluctuations can be\ncharacterized by a single curve. Because the behavior of price fluctuations is\nrooted in the characteristics of volatility, we expect our results to bring\nincreased interest to stochastic volatility models, and especially to those\nthat can produce the properties of volatility reported here.\n"
    },
    {
        "paper_id": 1001.0024,
        "authors": "Tetsuya Takaishi",
        "title": "Bayesian Inference of Stochastic Volatility Model by Hybrid Monte Carlo",
        "comments": "15 pages",
        "journal-ref": "Journal of Circuits, Systems, and Computers 18 (2009) 1381-1396",
        "doi": "10.1142/S0218126609005733",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The hybrid Monte Carlo (HMC) algorithm is applied for the Bayesian inference\nof the stochastic volatility (SV) model. We use the HMC algorithm for the\nMarkov chain Monte Carlo updates of volatility variables of the SV model. First\nwe compute parameters of the SV model by using the artificial financial data\nand compare the results from the HMC algorithm with those from the Metropolis\nalgorithm. We find that the HMC algorithm decorrelates the volatility variables\nfaster than the Metropolis algorithm. Second we make an empirical study for the\ntime series of the Nikkei 225 stock index by the HMC algorithm. We find the\nsimilar correlation behavior for the sampled data to the results from the\nartificial financial data and obtain a $\\phi$ value close to one ($\\phi \\approx\n0.977$), which means that the time series has the strong persistency of the\nvolatility shock.\n"
    },
    {
        "paper_id": 1001.0265,
        "authors": "Wanfeng Yan, Ryan Woodard, Didier Sornette",
        "title": "Diagnosis and Prediction of Tipping Points in Financial Markets: Crashes\n  and Rebounds",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  By combining (i) the economic theory of rational expectation bubbles, (ii)\nbehavioral finance on imitation and herding of investors and traders and (iii)\nthe mathematical and statistical physics of bifurcations and phase transitions,\nthe log-periodic power law (LPPL) model has been developed as a flexible tool\nto detect bubbles. The LPPL model considers the faster-than-exponential (power\nlaw with finite-time singularity) increase in asset prices decorated by\naccelerating oscillations as the main diagnostic of bubbles. It embodies a\npositive feedback loop of higher return anticipations competing with negative\nfeedback spirals of crash expectations. The power of the LPPL model is\nillustrated by two recent real-life predictions performed recently by our\ngroup: the peak of the Oil price bubble in early July 2008 and the burst of a\nbubble on the Shanghai stock market in early August 2009. We then present the\nconcept of \"negative bubbles\", which are the mirror images of positive bubbles.\nWe argue that similar positive feedbacks are at work to fuel these accelerated\ndownward price spirals. We adapt the LPPL model to these negative bubbles and\nimplement a pattern recognition method to predict the end times of the negative\nbubbles, which are characterized by rebounds (the mirror images of crashes\nassociated with the standard positive bubbles). The out-of-sample tests\nquantified by error diagrams demonstrate the high significance of the\nprediction performance.\n"
    },
    {
        "paper_id": 1001.0497,
        "authors": "Thomas Conlon, Heather J. Ruskin, Martin Crane",
        "title": "Multiscaled Cross-Correlation Dynamics in Financial Time-Series",
        "comments": null,
        "journal-ref": "Advances in Complex Systems, 12 (4-5) (2009), 439-454",
        "doi": "10.1142/S0219525909002325",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The cross correlation matrix between equities comprises multiple interactions\nbetween traders with varying strategies and time horizons. In this paper, we\nuse the Maximum Overlap Discrete Wavelet Transform to calculate correlation\nmatrices over different timescales and then explore the eigenvalue spectrum\nover sliding time windows. The dynamics of the eigenvalue spectrum at different\ntimes and scales provides insight into the interactions between the numerous\nconstituents involved.\n  Eigenvalue dynamics are examined for both medium and high-frequency equity\nreturns, with the associated correlation structure shown to be dependent on\nboth time and scale. Additionally, the Epps effect is established using this\nmultivariate method and analyzed at longer scales than previously studied. A\npartition of the eigenvalue time-series demonstrates, at very short scales, the\nemergence of negative returns when the largest eigenvalue is greatest. Finally,\na portfolio optimization shows the importance of timescale information in the\ncontext of risk management.\n"
    },
    {
        "paper_id": 1001.0615,
        "authors": "Vladimir G. Ivancevic",
        "title": "Adaptive Wave Models for Option Pricing Evolution: Nonlinear and Quantum\n  Schr\\\"odinger Approaches",
        "comments": "17 pages, 6 figures, Latex (high-quality figures can be obtained upon\n  request)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Adaptive wave model for financial option pricing is proposed, as a\nhigh-complexity alternative to the standard Black--Scholes model. The new\noption-pricing model, representing a controlled Brownian motion, includes two\nwave-type approaches: nonlinear and quantum, both based on (adaptive form of)\nthe Schr\\\"odinger equation. The nonlinear approach comes in two flavors: (i)\nfor the case of constant volatility, it is defined by a single adaptive\nnonlinear Schr\\\"odinger (NLS) equation, while for the case of stochastic\nvolatility, it is defined by an adaptive Manakov system of two coupled NLS\nequations. The linear quantum approach is defined in terms of de Broglie's\nplane waves and free-particle Schr\\\"odinger equation. In this approach,\nfinancial variables have quantum-mechanical interpretation and satisfy the\nHeisenberg-type uncertainty relations. Both models are capable of successful\nfitting of the Black--Scholes data, as well as defining Greeks.\n  Keywords: Black--Scholes option pricing, adaptive nonlinear Schr\\\"odinger\nequation, adaptive Manakov system, quantum-mechanical option pricing,\nmarket-heat potential\n  PACS: 89.65.Gh, 05.45.Yv, 03.65.Ge\n"
    },
    {
        "paper_id": 1001.0656,
        "authors": "Leilei Shi (1), Yiwen Wang (2), Ding Chen (3), Liyan Han (2), Yan Piao\n  and Chengling Gou (4) ((1) Complex System Research Group, Department of\n  Modern Physics University of Science and Technology of China (2) Department\n  of Finance, Beijing University of Aeronautics and Astronautics (3) Harvest\n  Fund Management Co. Ltd. (4) Department of Physics, Beijing University of\n  Aeronautics and Astronautics)",
        "title": "A Security Price Volatile Trading Conditioning Model",
        "comments": "23x2 pages, 7x2 figures, 1x2 tables and in both English and Chinese\n  versions",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a theoretical trading conditioning model subject to price\nvolatility and return information in terms of market psychological behavior,\nbased on analytical transaction volume-price probability wave distributions in\nwhich we use transaction volume probability to describe price volatility\nuncertainty and intensity. Applying the model to high frequent data test in\nChina stock market, we have main findings as follows: 1) there is, in general,\nsignificant positive correlation between the rate of mean return and that of\nchange in trading conditioning intensity; 2) it lacks significance in spite of\npositive correlation in two time intervals right before and just after bubble\ncrashes; and 3) it shows, particularly, significant negative correlation in a\ntime interval when SSE Composite Index is rising during bull market. Our model\nand findings can test both disposition effect and herd behavior simultaneously,\nand explain excessive trading (volume) and other anomalies in stock market.\n"
    },
    {
        "paper_id": 1001.0783,
        "authors": "Arthur M. Berd",
        "title": "Recovery Swaps",
        "comments": "9 pages, 2 figures",
        "journal-ref": "J. of Credit Risk, vol. 1(3), p. 61-70 (2005)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive an arbitrage free relationship between recovery swap rates, digital\ndefault swap spreads and conventional CDS spreads, and argue that the fair\nforward recovery rate used in recovery swaps must contain a convexity premium\nover the expected recovery value.\n"
    },
    {
        "paper_id": 1001.0786,
        "authors": "Arthur M. Berd, Robert F. Engle, Artem Voronov",
        "title": "The Underlying Dynamics of Credit Correlations",
        "comments": "37 pages, 10 figures, 2 tables",
        "journal-ref": "J. of Credit Risk, vol. 3(2), p. 27-62 (2007)",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a hybrid model of portfolio credit risk where the dynamics of the\nunderlying latent variables is governed by a one factor GARCH process. The\ndistinctive feature of such processes is that the long-term aggregate return\ndistributions can substantially deviate from the asymptotic Gaussian limit for\nvery long horizons. We introduce the notion of correlation surface as a\nconvenient tool for comparing portfolio credit loss generating models and\npricing synthetic CDO tranches. Analyzing alternative specifications of the\nunderlying dynamics, we conclude that the asymmetric models with TARCH\nvolatility specification are the preferred choice for generating significant\nand persistent credit correlation skews. The characteristic dependence of the\ncorrelation skew on term to maturity and portfolio hazard rate in these models\nhas a significant impact on both relative value analysis and risk management of\nCDO tranches.\n"
    },
    {
        "paper_id": 1001.088,
        "authors": "Leilei Shi (1)(2)(3) ((1)Department of Systems Science, School of\n  Management, Beijing Normal University (2) Complex System Research Group,\n  Department of Modern Physics, University of Science and Technology of China\n  (3) Generali-China Life Insurance Co., Ltd.)",
        "title": "Does Security Transaction Volume-Price Behavior Resemble a Probability\n  Wave?",
        "comments": "20 pages, 6 figures, and 2 Appendixes",
        "journal-ref": "Physica A 366 (2006), 419-436",
        "doi": "10.1016/j.physa.2005.10.016",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Motivated by how transaction amount constrain trading volume and price\nvolatility in stock market, we, in this paper, study the relation between\nvolume and price if amount of transaction is given. We find that accumulative\ntrading volume gradually emerges a kurtosis near the price mean value over a\ntrading price range when it takes a longer trading time, regardless of actual\nprice fluctuation path, time series, or total transaction volume in the time\ninterval. To explain the volume-price behavior, we, in terms of physics,\npropose a transaction energy hypothesis, derive a time-independent transaction\nvolume-price probability wave equation, and get two sets of analytical volume\ndistribution eigenfunctions over a trading price range. By empiric test, we\nshow the existence of coherence in stock market and demonstrate the model\nvalidation at this early stage. The volume-price behaves like a probability\nwave.\n"
    },
    {
        "paper_id": 1001.1184,
        "authors": "Constantinos Kardaras",
        "title": "Stochastic discount factors",
        "comments": "12 pages. To appear in the \"Encyclopedia of Quantitative Finance\"",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The valuation process that economic agents undergo for investments with\nuncertain payoff typically depends on their statistical views on possible\nfuture outcomes, their attitudes toward risk, and, of course, the payoff\nstructure itself. Yields vary across different investment opportunities and\ntheir interrelations are difficult to explain. For the same agent, a different\ndiscounting factor has to be used for every separate valuation occasion. If,\nhowever, one is ready to accept discounting that varies randomly with the\npossible outcomes, and therefore accepts the concept of a stochastic discount\nfactor, then an economically consistent theory can be developed. Asset\nvaluation becomes a matter of randomly discounting payoffs under different\nstates of nature and weighing them according to the agent's probability\nstructure. The advantages of this approach are obvious, since a single\ndiscounting mechanism suffices to describe how any asset is priced by the\nagent.\n"
    },
    {
        "paper_id": 1001.1379,
        "authors": "Mark Davis, Sebastien Lleo",
        "title": "Jump-Diffusion Risk-Sensitive Asset Management I: Diffusion Factor Model",
        "comments": "33 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers a portfolio optimization problem in which asset prices\nare represented by SDEs driven by Brownian motion and a Poisson random measure,\nwith drifts that are functions of an auxiliary diffusion factor process. The\ncriterion, following earlier work by Bielecki, Pliska, Nagai and others, is\nrisk-sensitive optimization (equivalent to maximizing the expected growth rate\nsubject to a constraint on variance.) By using a change of measure technique\nintroduced by Kuroda and Nagai we show that the problem reduces to solving a\ncertain stochastic control problem in the factor process, which has no jumps.\nThe main result of the paper is to show that the risk-sensitive jump diffusion\nproblem can be fully characterized in terms of a parabolic\nHamilton-Jacobi-Bellman PDE rather than a PIDE, and that this PDE admits a\nclassical C^{1,2} solution.\n"
    },
    {
        "paper_id": 1001.138,
        "authors": "Rama Cont and Amel Bentata",
        "title": "Forward equations for option prices in semimartingale models",
        "comments": "Proof shortened+ reference added. Final revision before publication",
        "journal-ref": "Finance and Stochastics, July 2015, Volume 19, Issue 3, pp 617-65",
        "doi": "10.1007/s00780-015-0265-z",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive a forward partial integro-differential equation for prices of call\noptions in a model where the dynamics of the underlying asset under the pricing\nmeasure is described by a -possibly discontinuous- semimartingale. A uniqueness\ntheorem is given for the solutions of this equation. This result generalizes\nDupire's forward equation to a large class of non-Markovian models with jumps.\n"
    },
    {
        "paper_id": 1001.1446,
        "authors": "Madalina Ecaterina Andreica, Mugurel Ionut Andreica, Marin Andreica",
        "title": "Using Financial Ratios to Identify Romanian Distressed Companies",
        "comments": "ISSN: 1454-0320",
        "journal-ref": "Economy Journal - Series Management, vol. 12, special issue no. 1,\n  pp. 46-55, 2009",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the context of the current financial crisis, when more companies are\nfacing bankruptcy or insolvency, the paper aims to find methods to identify\ndistressed firms by using financial ratios. The study will focus on identifying\na group of Romanian listed companies, for which financial data for the year\n2008 were available. For each company a set of 14 financial indicators was\ncalculated and then used in a principal component analysis, followed by a\ncluster analysis, a logit model, and a CHAID classification tree.\n"
    },
    {
        "paper_id": 1001.145,
        "authors": "Angus A Brown, L C G Rogers",
        "title": "Diverse Beliefs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a general framework for studying diverse beliefs in\ndynamic economies. Within this general framework, the characterization of a\ncentral-planner general equilbrium turns out to be very easy to derive, and\nleads to a range of interesting applications. We show how for an economy with\nlog investors holding diverse beliefs, rational overconfidence is to be\nexpected; volume-of-trade effects are effectively modelled; the Keynesian\n`beauty contest' can be modelled and analysed; and bubbles and crashes arise\nnaturally. We remark that models where agents receive private information can\nformally be considered as models of diverse beliefs.\n"
    },
    {
        "paper_id": 1001.1616,
        "authors": "Ulrich Kirchner",
        "title": "A Subjective and Probabilistic Approach to Derivatives",
        "comments": "12 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a probabilistic framework for pricing derivatives, which\nacknowledges that information and beliefs are subjective. Market prices can be\ntranslated into implied probabilities. In particular, futures imply returns for\nthese implied probability distributions. We argue that volatility is not risk,\nbut uncertainty. Non-normal distributions combine the risk in the left tail\nwith the opportunities in the right tail -- unifying the \"risk premium\" with\nthe possible loss. Risk and reward must be part of the same picture and\nexpected returns must include possible losses due to risks. We reinterpret the\nBlack-Scholes pricing formulas as prices for maximum-entropy probability\ndistributions, illuminating their importance from a new angle. Using these\nideas we show how derivatives can be priced under \"uncertain uncertainty\" and\nhow this creates a skew for the implied volatilities. We argue that the current\nstandard approach based on stochastic modelling and risk-neutral pricing fails\nto account for subjectivity in markets and mistreats uncertainty as risk.\nFurthermore, it is founded on a questionable argument -- that uncertainty is\neliminated at all cost.\n"
    },
    {
        "paper_id": 1001.1847,
        "authors": "Sanjay Dasari, Anindya Kumar Biswas",
        "title": "An Economic analogy to Electrodynamics",
        "comments": "19 pages, duality aspect added, expanded, to comply with journal\n  version",
        "journal-ref": "Modern Economy, 2013, 4, 723-732",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this note, we would like to find the laws of electrodynamics in simple\neconomic systems. In this direction, we identify the chief economic variables\nand parameters, scalar and vector, which are amenable to be put directly into\nthe crouch of the laws of electrodynamics, namely Maxwell's equations.\nMoreover, we obtain Phillp's curve, recession and Black-Scholes formula, as\nsample applications.\n"
    },
    {
        "paper_id": 1001.1867,
        "authors": "Fr\\'ed\\'eric Planchet (SAF), Pierre-Emanuel Th\\'erond (SAF)",
        "title": "Allocation d'actifs selon le crit\\`ere de maximisation des fonds propres\n  \\'economiques en assurance non-vie",
        "comments": null,
        "journal-ref": "Bulletin Fran\\c{c}ais d'Actuariat 7, 13 (2007) 10...38",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The economic equities maximization criterion (MFPE) leads to the choice of\nfinancial portfolio, which maximizes the ratio of the expected value of the\ninsurance company on the capital. This criterion is presented in the framework\nof a non-life insurance company and is applied within the framework of the\nFrench legislation and in a lawful context inspired of the works in progress\nabout the European project Solvency 2. In the French regulation case, the\nrequired solvency margin does not depend of the asset allocation. It is quite\ndifferent in the Solvency 2 framework because the target capital has to control\nthe global risk of the company. And the financial risk takes part of this\nglobal risk. Thus the economic equities maximization criterion leads to search\na couple asset allocation / equities which solves a stochastic program. A\nnumerical illustration makes it possible to analyze the consequences of the\nintroduction of a Solvency 2 framework on the technical reserves and the\nequities of a non-life insurance company and on the optimal allocation due to\nthe economic equities maximization criterion. Finally, the impact of a\nmisspecification of the risky asset model on the optimal allocation is\nillustrated.\n"
    },
    {
        "paper_id": 1001.1907,
        "authors": "Fr\\'ed\\'eric Planchet (SAF), Pascal Winter (SAF)",
        "title": "L'utilisation des splines bidimensionnels pour l'estimation de lois de\n  maintien en arr\\^et de travail",
        "comments": null,
        "journal-ref": "Bulletin Fran\\c{c}ais d'Acturiat 7, 13 (2007) 83...106",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to propose an operational two-dimensional parametric\nadjustment for laws of maintenance in disability. The method suggested rests on\nsplines in dimension 2; it is applied to a real data set, and the scale of\nreserving which results from it is compared with the scale of reference of the\nBCAC.\n"
    },
    {
        "paper_id": 1001.1908,
        "authors": "Jean-Paul F\\'elix (SAF), Fr\\'ed\\'eric Planchet (SAF)",
        "title": "Mesure des risques de march\\'e et de souscription vie en situation\n  d'information incompl\\`ete pour un portefeuille de pr\\'evoyance",
        "comments": null,
        "journal-ref": "Bulletin Fran\\c{c}ais d'Actuariat 9, 18 (2009) 79...105",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the framework of Embedded Value new standards, namely the MCEV norms, the\nlatest principles published in June 2008 address the issue of market and\nunderwriting risks measurement by using stochastic models of projection and\nvalorization. Knowing that stochastic models particularly data-consuming, the\nquestion which can arise is the treatment of insurance portfolios only\navailable in aggregate data or portfolios in situation of incomplete\ninformation. The aim of this article is to propose a pragmatic modeling of\nthese risks tied up with death covers of individual protection products in\nthese situations.\n"
    },
    {
        "paper_id": 1001.1909,
        "authors": "Fr\\'ed\\'eric Planchet (SAF), Pierre-Emanuel Th\\'erond (SAF)",
        "title": "Simulation de trajectoires de processus continus",
        "comments": null,
        "journal-ref": "Belgian Actuarial Bulletin 5, 1 (2005) 1...13",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Continuous time stochastic processes are useful models especially for\nfinancial and insurance purposes. The numerical simulation of such models is\ndependant of the time discrete discretization, of the parametric estimation and\nof the choice of a random number generator. The aim of this paper is to provide\nthe tools for the practical implementation of diffusion processes simulation,\nparticularly for insurance contexts.\n"
    },
    {
        "paper_id": 1001.1914,
        "authors": "Fr\\'ed\\'eric Planchet (SAF), Pierre-Emanuel Th\\'erond (SAF)",
        "title": "Rentes en cours de service : un nouveau crit\\`ere d'allocation d'actif",
        "comments": null,
        "journal-ref": "Bulletin Fran\\c{c}ais d'Actuariat 9, 17 (2009) 37...69",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to compare two asset allocation methods for a\npension scheme during the decumulation phase in the simplified portfolio\nselection between a risky asset following a geometric Brownian motion and a\nriskless asset. The two asset allocation criteria are the ruin probability of\nthe insurance company and the optimization of the economic capital. We first\nsolve the asset allocation problem with deterministic pension payments then\nwith stochastic mortality risk. We analyze the part of mortality risk in the\nglobal risk of the company. Then we show the impact of the indexation of the\npensions to the inflation on the asset allocation.\n"
    },
    {
        "paper_id": 1001.1916,
        "authors": "Fr\\'ed\\'eric Planchet (SAF), Vincent Lelieur (SAF)",
        "title": "Utilisation des m\\'ethodes de Lee-Carter et Log-Poisson pour\n  l'ajustement de tables de mortalit\\'e dans le cas de petits \\'echantillons",
        "comments": null,
        "journal-ref": "Bulletin Fran\\c{c}ais d'Actuariat (2007) 118...146",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to study the construction of prospective mortality\ntables from a low number of persons subjected to risk. The presented models are\nthe Lee-Carter and log-Poisson methods respectively. The low number of people\nsubjected to risk, particularly noticed for the persons who are getting on,\nimplies the use of an extrapolation method for the mortality rates. The\nLee-Carter and log-Poisson methods constitute twodimensional models, taking the\nyear and the age into account to calculate the mortality rates. The methods\nsuggested are applied to a real data set. The prospective tables, built in this\nway, allow to project the rates' evolution in the future, extrapolating the\ntemporal constituent. And then, it allows to compare this projection with the\nevolution predicted for the French population in its entirety. You determine\nthe best method through the nearness of the smoothed rates in comparison with\nthe raw rates and essentially through the caution of these models for the life\nannuities' calculation. The results stemed from these methods are too\nconfronted with the mortality rates obtained through a method of logistic fits.\n"
    },
    {
        "paper_id": 1001.1921,
        "authors": "Fr\\'ed\\'eric Planchet (SAF), Marc Juillard (SAF)",
        "title": "Mesure de l'incertitude tendancielle sur la mortalit\\'e ? application\n  \\`a un r\\'egime de rentes",
        "comments": null,
        "journal-ref": "Assurances et Gestion des Risques 75, 3 (2007) 1...10",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to propose a realistic and operational model to\nquantify the systematic risk of mortality included in an engagement of\nretirement. The model presented is built on the basis of model of Lee-Carter.\nThe stochastic prospective tables thus built make it possible to project the\nevolution of the random mortality rates in the future and to quantify the\nsystematic risk of mortality.\n"
    },
    {
        "paper_id": 1001.1922,
        "authors": "Fr\\'ed\\'eric Planchet (SAF), Laurent Faucillon (SAF), Marc Juillard\n  (SAF)",
        "title": "Etude du risque syst\\'ematique de mortalit\\'e",
        "comments": null,
        "journal-ref": "Assurances et Gestion des Risques 74, 3 (2006) 1...10",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The aim of this paper is to propose a realistic and operational model to\nquantify the systematic risk of mortality included in an engagement of\nretirement. The model presented is built on the basis of model of Lee-Carter.\nThe stochastic prospective tables thus built make it possible to project the\nevolution of the random mortality rates in the future and to quantify the\nsystematic risk of mortality.\n"
    },
    {
        "paper_id": 1001.2131,
        "authors": "Hiroaki Hata, Hideo Nagai, Shuenn-Jyi Sheu",
        "title": "Asymptotics of the probability minimizing a \"down-side\" risk",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP618 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 1, 52-89",
        "doi": "10.1214/09-AAP618",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a long-term optimal investment problem where an investor tries to\nminimize the probability of falling below a target growth rate. From a\nmathematical viewpoint, this is a large deviation control problem. This problem\nwill be shown to relate to a risk-sensitive stochastic control problem for a\nsufficiently large time horizon. Indeed, in our theorem we state a duality in\nthe relation between the above two problems. Furthermore, under a\nmultidimensional linear Gaussian model we obtain explicit solutions for the\nprimal problem.\n"
    },
    {
        "paper_id": 1001.2173,
        "authors": "Manuel S. Santos",
        "title": "Consistency properties of a simulation-based estimator for dynamic\n  processes",
        "comments": "Published in at http://dx.doi.org/10.1214/09-AAP608 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)",
        "journal-ref": "Annals of Applied Probability 2010, Vol. 20, No. 1, 196-213",
        "doi": "10.1214/09-AAP608",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper considers a simulation-based estimator for a general class of\nMarkovian processes and explores some strong consistency properties of the\nestimator. The estimation problem is defined over a continuum of invariant\ndistributions indexed by a vector of parameters. A key step in the method of\nproof is to show the uniform convergence (a.s.) of a family of sample\ndistributions over the domain of parameters. This uniform convergence holds\nunder mild continuity and monotonicity conditions on the dynamic process. The\nestimator is applied to an asset pricing model with technology adoption. A\nchallenge for this model is to generate the observed high volatility of stock\nmarkets along with the much lower volatility of other real economic aggregates.\n"
    },
    {
        "paper_id": 1001.2549,
        "authors": "Bence Toth, Fabrizio Lillo, J. Doyne Farmer",
        "title": "Segmentation algorithm for non-stationary compound Poisson processes",
        "comments": "11 pages, 11 figures",
        "journal-ref": "Eur. Phys. J. B 78, 235-243 (2010)",
        "doi": "10.1140/epjb/e2010-10046-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce an algorithm for the segmentation of a class of regime switching\nprocesses. The segmentation algorithm is a non parametric statistical method\nable to identify the regimes (patches) of the time series. The process is\ncomposed of consecutive patches of variable length, each patch being described\nby a stationary compound Poisson process, i.e. a Poisson process where each\ncount is associated to a fluctuating signal. The parameters of the process are\ndifferent in each patch and therefore the time series is non stationary. Our\nmethod is a generalization of the algorithm introduced by Bernaola-Galvan, et\nal., Phys. Rev. Lett., 87, 168105 (2001). We show that the new algorithm\noutperforms the original one for regime switching compound Poisson processes.\nAs an application we use the algorithm to segment the time series of the\ninventory of market members of the London Stock Exchange and we observe that\nour method finds almost three times more patches than the original one.\n"
    },
    {
        "paper_id": 1001.2639,
        "authors": "B. Kaulakys, M. Alaburda, V. Gontis",
        "title": "Point Processes Modeling of Time Series Exhibiting Power-Law Statistics",
        "comments": "4 pages, 2 figures",
        "journal-ref": "NOISE AND FLUCTUATIONS: 19th International Conference on Noise and\n  Fluctuations - ICNF 2007, AIP Conf. Proc. 922, p.535-538 (2007)",
        "doi": "10.1063/1.2759736",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider stochastic point processes generating time series exhibiting\npower laws of spectrum and distribution density (Phys. Rev. E 71, 051105\n(2005)) and apply them for modeling the trading activity in the financial\nmarkets and for the frequencies of word occurrences in the language.\n"
    },
    {
        "paper_id": 1001.2678,
        "authors": "Mark H.A. Davis, Jan Obloj, Vimal Raval",
        "title": "Arbitrage Bounds for Prices of Weighted Variance Swaps",
        "comments": "25 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop robust pricing and hedging of a weighted variance swap when market\nprices for a finite number of co--maturing put options are given. We assume the\ngiven prices do not admit arbitrage and deduce no-arbitrage bounds on the\nweighted variance swap along with super- and sub- replicating strategies which\nenforce them. We find that market quotes for variance swaps are surprisingly\nclose to the model-free lower bounds we determine. We solve the problem by\ntransforming it into an analogous question for a European option with a convex\npayoff. The lower bound becomes a problem in semi-infinite linear programming\nwhich we solve in detail. The upper bound is explicit.\n  We work in a model-independent and probability-free setup. In particular we\nuse and extend F\\\"ollmer's pathwise stochastic calculus. Appropriate notions of\narbitrage and admissibility are introduced. This allows us to establish the\nusual hedging relation between the variance swap and the 'log contract' and\nsimilar connections for weighted variance swaps. Our results take form of a\nFTAP: we show that the absence of (weak) arbitrage is equivalent to the\nexistence of a classical model which reproduces the observed prices via\nrisk-neutral expectations of discounted payoffs.\n"
    },
    {
        "paper_id": 1001.2831,
        "authors": "Salman Khan, M. Ramzan and M. K. Khan",
        "title": "Quantum Model of Bertrand Duopoly",
        "comments": "9 pages, 2 .eps figure",
        "journal-ref": "Chin. Phys. Lett. Vol. 27, No. 8 (2010) 080302",
        "doi": "10.1088/0256-307X/27/8/080302",
        "license": "http://creativecommons.org/licenses/publicdomain/",
        "abstract": "  We present the quantum model of Bertrand duopoly and study the entanglement\nbehavior on the profit functions of the firms. Using the concept of optimal\nresponse of each firm to the price of the opponent, we found only one Nash\nequilibirum point for maximally entangled initial state. The very presence of\nquantum entanglement in the initial state gives payoffs higher to the firms\nthan the classical payoffs at the Nash equilibrium. As a result the dilemma\nlike situation in the classical game is resolved.\n"
    },
    {
        "paper_id": 1001.3003,
        "authors": "P. Friz, S. Gerhold, A. Gulisashvili, S. Sturm",
        "title": "On refined volatility smile expansion in the Heston model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  It is known that Heston's stochastic volatility model exhibits moment\nexplosion, and that the critical moment $s_+$ can be obtained by solving\n(numerically) a simple equation. This yields a leading order expansion for the\nimplied volatility at large strikes: $\\sigma_{BS}( k,T)^{2}T\\sim \\Psi (s_+-1)\n\\times k$ (Roger Lee's moment formula). Motivated by recent \"tail-wing\"\nrefinements of this moment formula, we first derive a novel tail expansion for\nthe Heston density, sharpening previous work of Dragulescu and Yakovenko\n[Quant. Finance 2, 6 (2002), 443--453], and then show the validity of a refined\nexpansion of the type $\\sigma_{BS}( k,T) ^{2}T=(\n\\beta_{1}k^{1/2}+\\beta_{2}+...)^{2}$, where all constants are explicitly known\nas functions of $s_+$, the Heston model parameters, spot vol and maturity $T$.\nIn the case of the \"zero-correlation\" Heston model such an expansion was\nderived by Gulisashvili and Stein [Appl. Math. Optim. 61, 3 (2010), 287--315].\nOur methods and results may prove useful beyond the Heston model: the entire\nquantitative analysis is based on affine principles: at no point do we need\nknowledge of the (explicit, but cumbersome) closed form expression of the\nFourier transform of $\\log S_{T}$\\ (equivalently: Mellin transform of $S_{T}$\n); what matters is that these transforms satisfy ordinary differential\nequations of Riccati type. Secondly, our analysis reveals a new parameter\n(\"critical slope\"), defined in a model free manner, which drives the second and\nhigher order terms in tail- and implied volatility expansions.\n"
    },
    {
        "paper_id": 1001.3006,
        "authors": "Markus Rei\\ss",
        "title": "Asymptotic equivalence and sufficiency for volatility estimation under\n  microstructure noise",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The basic model for high-frequency data in finance is considered, where an\nefficient price process is observed under microstructure noise. It is shown\nthat this nonparametric model is in Le Cam's sense asymptotically equivalent to\na Gaussian shift experiment in terms of the square root of the volatility\nfunction $\\sigma$. As an application, simple rate-optimal estimators of the\nvolatility and efficient estimators of the integrated volatility are\nconstructed.\n"
    },
    {
        "paper_id": 1001.3054,
        "authors": "Lifen An, Shaolin Ji",
        "title": "Reflected Backward Stochastic Difference Equations with Finite State and\n  their applications",
        "comments": "We need to make a major change of this paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we first establish the reflected backward stochastic\ndifference equations with finite state (FS-RBSDEs for short). Then we explore\nthe Existence and Uniqueness Theorem as well as the Comparison Theorem by \"one\nstep\" method. The connections between FS-RBSDEs and optimal stopping time\nproblems are investigated and we also show that the optimal stopping problems\nwith multiple priors under Knightian uncertainty is a special case of our\nFS-RBSDEs. As a byproduct we develop the general theory of g-martingales in\ndiscrete time with finite state including Doob-Mayer Decomposition Theorem and\nOptional Sampling Theorem. Finally, we consider the pricing models of American\nOption in both complete and incomplete markets.\n"
    },
    {
        "paper_id": 1001.3176,
        "authors": "Fu-Tie Song, Wei-Xing Zhou (ECUST)",
        "title": "Analyzing the prices of the most expensive sheet iron all over the\n  world: Modeling, prediction and regime change",
        "comments": "10 pages including 5 figures and 4 tables",
        "journal-ref": "Physica A 389 (17), 3538-3545 (2010)",
        "doi": "10.1016/j.physa.2010.04.010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The private car license plates issued in Shanghai are bestowed the title of\n\"the most expensive sheet iron all over the world\", more expensive than gold. A\ncitizen has to bid in an monthly auction to obtain a license plate for his new\nprivate car. We perform statistical analysis to investigate the influence of\nthe minimal price $P_{\\min}$ of the bidding winners, the quota $N_{\\rm{quota}}$\nof private car license plates, the number $N_{\\rm{bidder}}$ of bidders, as well\nas two external shocks including the legality debate of the auction in 2004 and\nthe auction regime reform in January 2008 on the average price $P_{\\rm{mean}}$\nof all bidding winners. It is found that the legality debate of the auction had\nmarginal transient impact on the average price in a short time period. In\ncontrast, the change of the auction rules has significant permanent influence\non the average price, which reduces the price by about 3020 yuan Renminbi. It\nmeans that the average price exhibits nonlinear behaviors with a regime change.\nThe evolution of the average price is independent of the number\n$N_{\\rm{bidder}}$ of bidders in both regimes. In the early regime before\nJanuary 2008, the average price $P_{\\rm{mean}}$ was influenced only by the\nminimal price $P_{\\min}$ in the preceding month with a positive correlation. In\nthe current regime since January 2008, the average price is positively\ncorrelated with the minimal price and the quota in the preceding month and\nnegatively correlated with the quota in the same month. We test the predictive\npower of the two models using 2-year and 3-year moving windows and find that\nthe latter outperforms the former. It seems that the auction market becomes\nmore efficient after the auction reform since the prediction error increases.\n"
    },
    {
        "paper_id": 1001.3213,
        "authors": "Jean-Philippe Chancelier (CERMICS), J\\'er\\^ome Lelong (LJK), Bernard\n  Lapeyre (CERMICS)",
        "title": "Using Premia and Nsp for Constructing a Risk Management Benchmark for\n  Testing Parallel Architecture",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial institutions have massive computations to carry out overnight which\nare very demanding in terms of the consumed CPU. The challenge is to price many\ndifferent products on a cluster-like architecture. We have used the Premia\nsoftware to valuate the financial derivatives. In this work, we explain how\nPremia can be embedded into Nsp, a scientific software like Matlab, to provide\na powerful tool to valuate a whole portfolio. Finally, we have integrated an\nMPI toolbox into Nsp to enable to use Premia to solve a bunch of pricing\nproblems on a cluster. This unified framework can then be used to test\ndifferent parallel architectures.\n"
    },
    {
        "paper_id": 1001.3223,
        "authors": "Johannes Muhle-Karbe, Oliver Pfaffel, Robert Stelzer",
        "title": "Option Pricing in Multivariate Stochastic Volatility Models of OU Type",
        "comments": "28 pages, 5 figures, to appear in SIAM Journal on Financial\n  Mathematics",
        "journal-ref": null,
        "doi": "10.1137/100803687",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a multivariate stochastic volatility model with leverage, which is\nflexible enough to recapture the individual dynamics as well as the\ninterdependencies between several assets while still being highly analytically\ntractable.\n  First we derive the characteristic function and give conditions that ensure\nits analyticity and absolute integrability in some open complex strip around\nzero. Therefore we can use Fourier methods to compute the prices of multi-asset\noptions efficiently. To show the applicability of our results, we propose a\nconcrete specification, the OU-Wishart model, where the dynamics of each\nindividual asset coincide with the popular Gamma-OU BNS model. This model can\nbe well calibrated to market prices, which we illustrate with an example using\noptions on the exchange rates of some major currencies. Finally, we show that\ncovariance swaps can also be priced in closed form.\n"
    },
    {
        "paper_id": 1001.3289,
        "authors": "Boualem Djehiche (KTH Stockolm), Said Hamad\\`ene (LMM), Marie Am\\'elie\n  Morlais (LMM)",
        "title": "Optimal stopping of expected profit and cost yields in an investment\n  under uncertainty",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a finite horizon optimal stopping problem related to trade-off\nstrategies between expected profit and cost cash-flows of an investment under\nuncertainty. The optimal problem is first formulated in terms of a system of\nSnell envelopes for the profit and cost yields which act as obstacles to each\nother. We then construct both a minimal and a maximal solutions using an\napproximation scheme of the associated system of reflected backward SDEs. When\nthe dependence of the cash-flows on the sources of uncertainty, such as\nfluctuation market prices, assumed to evolve according to a diffusion process,\nis made explicit, we also obtain a connection between these solutions and\nviscosity solutions of a system of variational inequalities (VI) with\ninterconnected obstacles. We also provide two counter-examples showing that\nuniqueness of solutions of (VI) does not hold in general.\n"
    },
    {
        "paper_id": 1001.3308,
        "authors": "Rossella Agliardi",
        "title": "A comprehensive method for exotic option pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This work illustrates how several new pricing formulas for exotic options can\nbe derived within a Levy framework by employing a unique pricing expression.\nMany existing pricing formulas of the traditional Gaussian model are obtained\nas a by-product.\n"
    },
    {
        "paper_id": 1001.3455,
        "authors": "Michael Ludkovski",
        "title": "Stochastic Switching Games and Duopolistic Competition in Emissions\n  Markets",
        "comments": "Revised version, 24 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study optimal behavior of energy producers under a CO_2 emission abatement\nprogram. We focus on a two-player discrete-time model where each producer is\nsequentially optimizing her emission and production schedules. The\ngame-theoretic aspect is captured through a reduced-form price-impact model for\nthe CO_2 allowance price. Such duopolistic competition results in a new type of\na non-zero-sum stochastic switching game on finite horizon. Existence of game\nNash equilibria is established through generalization to randomized switching\nstrategies. No uniqueness is possible and we therefore consider a variety of\ncorrelated equilibrium mechanisms. We prove existence of correlated equilibrium\npoints in switching games and give a recursive description of equilibrium game\nvalues. A simulation-based algorithm to solve for the game values is\nconstructed and a numerical example is presented.\n"
    },
    {
        "paper_id": 1001.3492,
        "authors": "Sorin Vlad, Paul Pascu and Nicolae Morariu",
        "title": "Chaos Models in Economics",
        "comments": null,
        "journal-ref": "Journal of Computing, Vol. 2, Issue 1, January 2010",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper discusses the main ideas of the chaos theory and presents mainly\nthe importance of the nonlinearities in the mathematical models. Chaos and\norder are apparently two opposite terms. The fact that in chaos can be found a\ncertain precise symmetry (Feigenbaum numbers) is even more surprising. As an\nillustration of the ubiquity of chaos, three models among many other existing\nmodels that have chaotic features are presented here: the nonlinear feedback\nprofit model, one model for the simulation of the exchange rate and one\napplication of the chaos theory in the capital markets.\n"
    },
    {
        "paper_id": 1001.3551,
        "authors": "Bernard Lapeyre (CERMICS), J\\'er\\^ome Lelong (LJK)",
        "title": "A framework for adaptive Monte-Carlo procedures",
        "comments": null,
        "journal-ref": "Monte Carlo Methods and Applications 17, 1 (2011) 77-98",
        "doi": "10.1515/MCMA.2011.002",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Adaptive Monte Carlo methods are recent variance reduction techniques. In\nthis work, we propose a mathematical setting which greatly relaxes the\nassumptions needed by for the adaptive importance sampling techniques presented\nby Vazquez-Abad and Dufresne, Fu and Su, and Arouna. We establish the\nconvergence and asymptotic normality of the adaptive Monte Carlo estimator\nunder local assumptions which are easily verifiable in practice. We present one\nway of approximating the optimal importance sampling parameter using a randomly\ntruncated stochastic algorithm. Finally, we apply this technique to some\nexamples of valuation of financial derivatives.\n"
    },
    {
        "paper_id": 1001.357,
        "authors": "Andrea Macrina and Priyanka A. Parbhoo",
        "title": "Security Pricing with Information-Sensitive Discounting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper incomplete-information models are developed for the pricing of\nsecurities in a stochastic interest rate setting. In particular we consider\ncredit-risky assets that may include random recovery upon default. The market\nfiltration is generated by a collection of information processes associated\nwith economic factors, on which interest rates depend, and information\nprocesses associated with market factors used to model the cash flows of the\nsecurities. We use information-sensitive pricing kernels to give rise to\nstochastic interest rates. Semi-analytical expressions for the price of\ncredit-risky bonds are derived, and a number of recovery models are constructed\nwhich take into account the perceived state of the economy at the time of\ndefault. The price of European-style call bond options is deduced, and it is\nshown how examples of hybrid securities, like inflation-linked credit-risky\nbonds, can be valued. Finally, a cumulative information process is employed to\ndevelop pricing kernels that respond to the amount of aggregate debt of an\neconomy.\n"
    },
    {
        "paper_id": 1001.3644,
        "authors": "Marco Frittelli and Marco Maggis",
        "title": "Dual Representation of Quasiconvex Conditional Maps",
        "comments": "Date changed Added one remark on assumption (c), page 6",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We provide a dual representation of quasiconvex maps between two lattices of\nrandom variables in terms of conditional expectations. This generalizes the\ndual representation of quasiconvex real valued functions and the dual\nrepresentation of conditional convex maps.\n"
    },
    {
        "paper_id": 1001.3728,
        "authors": "K. Borovkov, G. Decrouez, J. Hinz",
        "title": "Jump-diffusion modeling in emission markets",
        "comments": "25 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Mandatory emission trading schemes are being established around the world.\nParticipants of such market schemes are always exposed to risks. This leads to\nthe creation of an accompanying market for emission-linked derivatives. To\nevaluate the fair prices of such financial products, one needs appropriate\nmodels for the evolution of the underlying assets, emission allowance\ncertificates. In this paper, we discuss continuous time diffusion and\njump-diffusion models, the latter enabling one to model information shocks that\ncause jumps in allowance prices. We show that the resulting martingale dynamics\ncan be described in terms of non-linear partial differential and\nintegro-differential equations and use a finite difference method to\ninvestigate numerical properties of their discretizations. The results are\nillustrated by a small numerical study.\n"
    },
    {
        "paper_id": 1001.3731,
        "authors": "Jie-Jun Tseng, Sai-Ping Li, Sun-Chong Wang",
        "title": "Experimental evidence for the interplay between individual wealth and\n  transaction network",
        "comments": "6 pages, 7 figures",
        "journal-ref": "Eur. Phys. J. B 73, 69 - 74 (2010)",
        "doi": "10.1140/epjb/e2009-00424-8",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We conduct a market experiment with human agents in order to explore the\nstructure of transaction networks and to study the dynamics of wealth\naccumulation. The experiment is carried out on our platform for 97 days with\n2,095 effective participants and 16,936 times of transactions. From these data,\nthe hybrid distribution (log-normal bulk and power-law tail) in the wealth is\nobserved and we demonstrate that the transaction networks in our market are\nalways scale-free and disassortative even for those with the size of the order\nof few hundred. We further discover that the individual wealth is correlated\nwith its degree by a power-law function which allows us to relate the exponent\nof the transaction network degree distribution to the Pareto index in wealth\ndistribution.\n"
    },
    {
        "paper_id": 1001.3972,
        "authors": "Guenter Last and Mathew D. Penrose",
        "title": "Martingale representation for Poisson processes with applications to\n  minimal variance hedging",
        "comments": "19 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider a Poisson process $\\eta$ on a measurable space\n$(\\BY,\\mathcal{Y})$ equipped with a partial ordering, assumed to be strict\nalmost everwhwere with respect to the intensity measure $\\lambda$ of $\\eta$. We\ngive a Clark-Ocone type formula providing an explicit representation of square\nintegrable martingales (defined with respect to the natural filtration\nassociated with $\\eta$), which was previously known only in the special case,\nwhen $\\lambda$ is the product of Lebesgue measure on $\\R_+$ and a\n$\\sigma$-finite measure on another space $\\BX$. Our proof is new and based on\nonly a few basic properties of Poisson processes and stochastic integrals. We\nalso consider the more general case of an independent random measure in the\nsense of It\\^o of pure jump type and show that the Clark-Ocone type\nrepresentation leads to an explicit version of the Kunita-Watanabe\ndecomposition of square integrable martingales. We also find the explicit\nminimal variance hedge in a quite general financial market driven by an\nindependent random measure.\n"
    },
    {
        "paper_id": 1001.4031,
        "authors": "Mathias Beiglboeck, Peter Friz, Stephan Sturm",
        "title": "Is the minimum value of an option on variance generated by local\n  volatility?",
        "comments": null,
        "journal-ref": "SIAM J. Finan. Math. 2, 213-220 (2011)",
        "doi": "10.1137/100800166",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the possibility of obtaining model-free bounds on volatility\nderivatives, given present market data in the form of a calibrated local\nvolatility model. A counter-example to a wide-spread conjecture is given.\n"
    },
    {
        "paper_id": 1001.4098,
        "authors": "Minh Q. Truong",
        "title": "Extra-Dimensional Approach to Option Pricing and Stochastic Volatility",
        "comments": "Ease the time-independent restriction on the extra dimensional\n  coordinates. Fixed typos and expand the conclusion",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The generalized 5D Black-Scholes differential equation with stochastic\nvolatility is derived. The projections of the stochastic evolutions associated\nwith the random variables from an enlarged space or superspace onto an ordinary\nspace can be achieved via higher-dimensional operators. The stochastic nature\nof the securities and volatility associated with the 3D Merton-Garman equation\ncan then be interpreted as the effects of the extra dimensions. We showed that\nthe Merton-Garman equation is the first excited state, i.e. n=m=1, within a\nfamily which contain an infinite numbers of Merton-Garman-like equations.\n"
    },
    {
        "paper_id": 1001.4151,
        "authors": "Vladimir G. Ivancevic",
        "title": "New Financial Research Program: General Option-Price Wave Modeling",
        "comments": "5 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recently, a novel adaptive wave model for financial option pricing has been\nproposed in the form of adaptive nonlinear Schr\\\"{o}dinger (NLS) equation\n[Ivancevic a], as a high-complexity alternative to the linear\nBlack-Scholes-Merton model [Black-Scholes-Merton]. Its quantum-mechanical basis\nhas been elaborated in [Ivancevic b]. Both the solitary and shock-wave\nsolutions of the nonlinear model, as well as its linear (periodic) quantum\nsimplification are shown to successfully fit the Black-Scholes data, and define\nthe financial Greeks. This initial wave model (called the Ivancevic option\npricing model) has been further extended in [Yan], by providing the new NLS\nsolutions in the form of rogue waves (one-rogon and two-rogon solutions). In\nthis letter, I propose a new financial research program, with a goal to develop\na general wave-type model for realistic option-pricing prediction and control.\n  Keywords: General option-price wave modeling, new financial research program\n"
    },
    {
        "paper_id": 1001.427,
        "authors": "Ting Wang, Virginia R. Young",
        "title": "Optimal Reversible Annuities to Minimize the Probability of Lifetime\n  Ruin",
        "comments": "50 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We find the minimum probability of lifetime ruin of an investor who can\ninvest in a market with a risky and a riskless asset and who can purchase a\nreversible life annuity. The surrender charge of a life annuity is a proportion\nof its value. Ruin occurs when the total of the value of the risky and riskless\nassets and the surrender value of the life annuity reaches zero. We find the\noptimal investment strategy and optimal annuity purchase and surrender\nstrategies in two situations: (i) the value of the risky and riskless assets is\nallowed to be negative, with the imputed surrender value of the life annuity\nkeeping the total positive; or (ii) the value of the risky and riskless assets\nis required to be non-negative. In the first case, although the individual has\nthe flexiblity to buy or sell at any time, we find that the individual will not\nbuy a life annuity unless she can cover all her consumption via the annuity and\nshe will never sell her annuity. In the second case, the individual surrenders\njust enough annuity income to keep her total assets positive. However, in this\nsecond case, the individual's annuity purchasing strategy depends on the size\nof the proportional surrender charge. When the charge is large enough, the\nindividual will not buy a life annuity unless she can cover all her\nconsumption, the so-called safe level. When the charge is small enough, the\nindividual will buy a life annuity at a wealth lower than this safe level.\n"
    },
    {
        "paper_id": 1001.4401,
        "authors": "F. Shayeganfar, M. Holling, J. Peinke, and M. Reza Rahimi Tabar",
        "title": "The level crossing and inverse statistic analysis of German stock market\n  index (DAX) and daily oil price time series",
        "comments": "19 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2011.07.037",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The level crossing and inverse statistics analysis of DAX and oil price time\nseries are given. We determine the average frequency of positive-slope\ncrossings, $\\nu_{\\alpha}^+$, where $T_{\\alpha} =1/\\nu_{\\alpha}^+ $ is the\naverage waiting time for observing the level $\\alpha$ again. We estimate the\nprobability $P(K, \\alpha)$, which provides us the probability of observing $K$\ntimes of the level $\\alpha$ with positive slope, in time scale $T_{\\alpha}$.\nFor analyzed time series we found that maximum $K$ is about 6. We show that by\nusing the level crossing analysis one can estimate how the DAX and oil time\nseries will develop. We carry out same analysis for the increments of DAX and\noil price log-returns,(which is known as inverse statistics) and provide the\ndistribution of waiting times to observe some level for the increments.\n"
    },
    {
        "paper_id": 1001.4762,
        "authors": "Peijie Wang, Trefor Jones",
        "title": "A Spectral Analysis of Business Cycle Patterns in UK Sectoral Output",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies business cycle patterns in UK sectoral output. It analyzes\nthe distinction between white noise processes and their non-white noise\ncounterparts in the frequency domain and further examines the associated\nfeatures and patterns for the process where white noise conditions are\nviolated. The characteristics of these sectors, arising from their\ninstitutional features that may influence business cycles behavior and\npatterns, are discussed. The study then investigates the output of UK GDP\nsectors empirically, revealing their similarities and differences in their\nbusiness cycle patterns.\n"
    }
]