[
    {
        "paper_id": 2406.07286,
        "authors": "Mykhaylo Shkolnikov, Lane Chun Yeung",
        "title": "From rank-based models with common noise to pathwise entropy solutions\n  of SPDEs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study the mean field limit of a rank-based model with common noise, which\narises as an extension to models for the market capitalization of firms in\nstochastic portfolio theory. We show that, under certain conditions on the\ndrift and diffusion coefficients, the empirical cumulative distribution\nfunction converges to the solution of a stochastic PDE. A key step in the\nproof, which is of independent interest, is to show that any solution to an\nassociated martingale problem is also a pathwise entropy solution to the\nstochastic PDE, a notion introduced in a recent series of papers [32, 33, 19,\n16, 17].\n"
    },
    {
        "paper_id": 2406.07354,
        "authors": "James B. Glattfelder and Richard B. Olsen",
        "title": "The Theory of Intrinsic Time: A Primer",
        "comments": "12 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The concept of time mostly plays a subordinate role in finance and economics.\nThe assumption is that time flows continuously and that time series data should\nbe analyzed at regular, equidistant intervals. Nonetheless, already nearly 60\nyears ago, the concept of an event-based measure of time was first introduced.\nThis paper expands on this theme by discussing the paradigm of intrinsic time,\nits origins, history, and modern applications. Departing from traditional,\ncontinuous measures of time, intrinsic time proposes an event-based,\nalgorithmic framework that captures the dynamic and fluctuating nature of\nreal-world phenomena more accurately. Unsuspected implications arise in general\nfor complex systems and specifically for financial markets. For instance, novel\nstructures and regularities are revealed, otherwise obscured by any analysis\nutilizing equidistant time intervals. Of particular interest is the emergence\nof a multiplicity of scaling laws, a hallmark signature of an underlying\norganizational principle in complex systems. Moreover, a central insight from\nthis novel paradigm is the realization that universal time does not exist;\ninstead, time is observer-dependent, shaped by the intrinsic activity unfolding\nwithin complex systems. This research opens up new avenues for economic\nmodeling and forecasting, paving the way for a deeper understanding of the\ninvisible forces that guide the evolution and emergence of market dynamics and\nfinancial systems. An exciting and rich landscape of possibilities emerges\nwithin the paradigm of intrinsic time.\n"
    },
    {
        "paper_id": 2406.07388,
        "authors": "Markus Bibinger",
        "title": "Probabilistic models and statistics for electronic financial markets in\n  the digital age",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1365/s13291-024-00283-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The scope of this manuscript is to review some recent developments in\nstatistics for discretely observed semimartingales which are motivated by\napplications for financial markets. Our journey through this area stops to take\ncloser looks at a few selected topics discussing recent literature. We moreover\nhighlight and explain the important role played by some classical concepts of\nprobability and statistics. We focus on three main aspects: Testing for jumps;\nrough fractional stochastic volatility; and limit order microstructure noise.\nWe review jump tests based on extreme value theory and complement the\nliterature proposing new statistical methods. They are based on asymptotic\ntheory of order statistics and the R\\'{e}nyi representation. The second stage\nof our journey visits a recent strand of research showing that volatility is\nrough. We further investigate this and establish a minimax lower bound\nexploring frontiers to what extent the regularity of latent volatility can be\nrecovered in a more general framework. Finally, we discuss a stochastic\nboundary model with one-sided microstructure noise for high-frequency limit\norder prices and its probabilistic and statistical foundation.\n"
    },
    {
        "paper_id": 2406.07464,
        "authors": "Gilles Pag\\`es, Christian Yeo",
        "title": "Convex ordering for stochastic control: the swing contracts case",
        "comments": "32 Pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate propagation of convexity and convex ordering on a typical\nstochastic optimal control problem, namely the pricing of\n\\q{\\emph{Take-or-Pay}} swing option, a financial derivative product commonly\ntraded on energy markets. The dynamics of the underlying asset is modelled by\nan \\emph{ARCH} model with convex coefficients. We prove that the value function\nassociated to the stochastic optimal control problem is a convex function of\nthe underlying asset price. We also introduce a domination criterion offering\ninsights into the monotonicity of the value function with respect to parameters\nof the underlying \\emph{ARCH} coefficients. We particularly focus on the\none-dimensional setting where, by means of Stein's formula and regularization\ntechniques, we show that the convexity assumption for the \\emph{ARCH}\ncoefficients can be relaxed with a semi-convexity assumption. To validate the\nresults presented in this paper, we also conduct numerical illustrations.\n"
    },
    {
        "paper_id": 2406.07523,
        "authors": "Mathias Beiglb\\\"ock, Gudmund Pammer, Lorenz Riess",
        "title": "Change of numeraire for weak martingale transport",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Change of numeraire is a classical tool in mathematical finance.\nCampi-Laachir-Martini established its applicability to martingale optimal\ntransport. We note that the results of Campi-Laachir-Martini extend to the case\nof weak martingale transport. We apply this to shadow couplings, continuous\ntime martingale transport problems in the framework of Huesmann-Trevisan and in\nparticular to establish the correspondence between stretched Brownian motion\nwith its geometric counterpart.\n  Note: We emphasize that we learned about the geometric stretched Brownian\nmotion gSBM (defined in PDE terms) in a presentation of Loeper \\cite{Lo23}\nbefore our work on this topic started. We noticed that a change of numeraire\ntransformation in the spirit of \\cite{CaLaMa14} allows for an alternative\nviewpoint in the weak optimal transport framework. We make our work public\nfollowing the publication of Backhoff-Loeper-Obloj's work \\cite{BaLoOb24} on\narxiv.org. The article \\cite{BaLoOb24} derives gSBM using PDE techniques as\nwell as through an independent probabilistic approach which is close to the one\nwe give in the present article.\n"
    },
    {
        "paper_id": 2406.07525,
        "authors": "Haibo Wang, Lutfu S. Sua, Jun Huang, Jaime Ortiz and Bahram Alidaee",
        "title": "Will Southeast Asia be the next global manufacturing hub? A multiway\n  cointegration, causality, and dynamic connectedness analyses on factors\n  influencing offshore decisions",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The COVID-19 pandemic has compelled multinational corporations to diversify\ntheir global supply chain risk and to relocate their factories to Southeast\nAsian countries beyond China. Such recent phenomena provide a good opportunity\nto understand the factors that influenced offshore decisions in the last two\ndecades. We propose a new conceptual framework based on econometric approaches\nto examine the relationships between these factors. Firstly, the Vector Auto\nRegression (VAR) for multi-way cointegration analysis by a Johansen test as\nwell as the embedding Granger causality analysis to examine offshore\ndecisions--innovation, technology readiness, infrastructure, foreign direct\ninvestment (FDI), and intermediate imports. Secondly, a Quantile Vector\nAutoregressive (QVAR) model is used to assess the dynamic connectedness among\nSoutheast Asian countries based on the offshore factors. This study explores a\nsystem-wide experiment to evaluate the spillover effects of offshore decisions.\nIt reports a comprehensive analysis using time-series data collected from the\nWorld Bank. The results of the cointegration, causality, and dynamic\nconnectedness analyses show that a subset of Southeast Asian countries have\nspillover effects on each other. These countries present a multi-way\ncointegration and dynamic connectedness relationship. The study contributes to\npolicymaking by providing a data-driven innovative approach through a new\nconceptual framework.\n"
    },
    {
        "paper_id": 2406.07564,
        "authors": "Lina D\\\"oring, Felix Grumbach, Pascal Reusch",
        "title": "Optimizing Sales Forecasts through Automated Integration of Market\n  Indicators",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Recognizing that traditional forecasting models often rely solely on\nhistorical demand, this work investigates the potential of data-driven\ntechniques to automatically select and integrate market indicators for\nimproving customer demand predictions. By adopting an exploratory methodology,\nwe integrate macroeconomic time series, such as national GDP growth, from the\n\\textit{Eurostat} database into \\textit{Neural Prophet} and \\textit{SARIMAX}\nforecasting models. Suitable time series are automatically identified through\ndifferent state-of-the-art feature selection methods and applied to sales data\nfrom our industrial partner. It could be shown that forecasts can be\nsignificantly enhanced by incorporating external information. Notably, the\npotential of feature selection methods stands out, especially due to their\ncapability for automation without expert knowledge and manual selection effort.\nIn particular, the Forward Feature Selection technique consistently yielded\nsuperior forecasting accuracy for both SARIMAX and Neural Prophet across\ndifferent company sales datasets. In the comparative analysis of the errors of\nthe selected forecasting models, namely Neural Prophet and SARIMAX, it is\nobserved that neither model demonstrates a significant superiority over the\nother.\n"
    },
    {
        "paper_id": 2406.07641,
        "authors": "Wei Wang and Haibo Wang",
        "title": "Interconnected Markets: Exploring the Dynamic Relationship Between BRICS\n  Stock Markets and Cryptocurrency",
        "comments": "34 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study uses data from the BRICS stock market index, cryptocurrencies, and\ninvestor sentiment indicators from January 6, 2015, to June 29, 2023. BRICS\nnations emerge as pivotal representatives of emerging economies. This study\nemploys a time-varying parameter vector autoregression model to unravel the\nintricate interdependence between traditional stock assets and the evolving\nlandscape of cryptocurrencies. The analysis investigates spillover effects\nbetween BRICS stock markets and cryptocurrencies, revealing increasing\ninterconnectedness during highly uncertain events like COVID-19, but no\nsignificant impact on major US stock market indices.\n"
    },
    {
        "paper_id": 2406.08013,
        "authors": "Sven Golu\\v{z}a, Tomislav Kova\\v{c}evi\\'c, Tessa Bauman, Zvonko\n  Kostanj\\v{c}ar",
        "title": "Deep reinforcement learning with positional context for intraday trading",
        "comments": null,
        "journal-ref": "Evolving Systems, 2024",
        "doi": "10.1007/s12530-024-09593-6",
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Deep reinforcement learning (DRL) is a well-suited approach to financial\ndecision-making, where an agent makes decisions based on its trading strategy\ndeveloped from market observations. Existing DRL intraday trading strategies\nmainly use price-based features to construct the state space. They neglect the\ncontextual information related to the position of the strategy, which is an\nimportant aspect given the sequential nature of intraday trading. In this\nstudy, we propose a novel DRL model for intraday trading that introduces\npositional features encapsulating the contextual information into its sparse\nstate space. The model is evaluated over an extended period of almost a decade\nand across various assets including commodities and foreign exchange\nsecurities, taking transaction costs into account. The results show a notable\nperformance in terms of profitability and risk-adjusted metrics. The feature\nimportance results show that each feature incorporating contextual information\ncontributes to the overall performance of the model. Additionally, through an\nexploration of the agent's intraday trading activity, we unveil patterns that\nsubstantiate the effectiveness of our proposed model.\n"
    },
    {
        "paper_id": 2406.08041,
        "authors": "Francesco Audrino and Jonathan Chassot",
        "title": "HARd to Beat: The Overlooked Impact of Rolling Windows in the Era of\n  Machine Learning",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "abstract": "  We investigate the predictive abilities of the heterogeneous autoregressive\n(HAR) model compared to machine learning (ML) techniques across an\nunprecedented dataset of 1,455 stocks. Our analysis focuses on the role of\nfitting schemes, particularly the training window and re-estimation frequency,\nin determining the HAR model's performance. Despite extensive hyperparameter\ntuning, ML models fail to surpass the linear benchmark set by HAR when\nutilizing a refined fitting approach for the latter. Moreover, the simplicity\nof HAR allows for an interpretable model with drastically lower computational\ncosts. We assess performance using QLIKE, MSE, and realized utility metrics,\nfinding that HAR consistently outperforms its ML counterparts when both rely\nsolely on realized volatility and VIX as predictors. Our results underscore the\nimportance of a correctly specified fitting scheme. They suggest that properly\nfitted HAR models provide superior forecasting accuracy, establishing robust\nguidelines for their practical application and use as a benchmark. This study\nnot only reaffirms the efficacy of the HAR model but also provides a critical\nperspective on the practical limitations of ML approaches in realized\nvolatility forecasting.\n"
    },
    {
        "paper_id": 2406.08357,
        "authors": "Andrea Albanese, Bart Cockx, Muriel Dejemeppe",
        "title": "Long-Term Effects of Hiring Subsidies for Low-Educated Unemployed Youths",
        "comments": "Accepted version",
        "journal-ref": "Journal of Public Economics, Volume 235, 105137, July 2024",
        "doi": "10.1016/j.jpubeco.2024.105137",
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  We use regression discontinuity design and difference-in-differences methods\nto estimate the impact of a one-time hiring subsidy for low-educated unemployed\nyouths in Belgium during the recovery from the Great Recession. Within a year\nof unemployment, the subsidy increases job-finding in the private sector by 10\npercentage points. Over six years, high school graduates secure 2.8 more\nquarters of private employment. However, they transition from public jobs and\nself-employment, resulting in no net increase in overall employment, albeit\nwith better wages. High school dropouts experience no lasting benefits.\nAdditionally, in tight labor markets near Luxembourg's employment hub, the\nsubsidy results in a complete deadweight loss.\n"
    },
    {
        "paper_id": 2406.08448,
        "authors": "Jiho Park",
        "title": "Heterogeneous Beliefs Model of Stock Market Predictability",
        "comments": "5 Propositions, 2 Models",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper proposes a theory of stock market predictability patterns based on\na model of heterogeneous beliefs. In a discrete finite time framework, some\nagents receive news about an asset's fundamental value through a noisy signal.\nThe investors are heterogeneous in that they have different beliefs about the\nstochastic supply. A momentum in the stock price arises from those agents who\nincorrectly underestimate the signal accuracy, dampening the initial price\nimpact of the signal. A reversal in price occurs because the price reverts to\nthe fundamental value in the long run. An extension of the model to multiple\nassets case predicts co-movement and lead-lag effect, in addition to\ncross-sectional momentum and reversal. The heterogeneous beliefs of investors\nabout news demonstrate how the main predictability anomalies arise endogenously\nin a model of bounded rationality.\n"
    },
    {
        "paper_id": 2406.08727,
        "authors": "Carlos G\\'oes",
        "title": "Trade, Growth, and Product Innovation",
        "comments": "14 figures; text: 42 pages; appendix: 35 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "abstract": "  Can trade integration induce product innovation? I document that countries\nthat joined the European Union (EU) started producing more product varieties,\ninvesting more in R&D, and trading more compared to candidate countries that\ndid not join at a given horizon. Additionally, I show that a plausibly\nexogenous increase in market access increases the probability of a given\ncountry starting production of and exporting a given product. To rationalize\nthis reduced-form evidence, I propose a new quantitative framework that\nintegrates the forces of specialization and market size. This is a dynamic\ngeneral equilibrium model of frictional trade and endogenous growth with\narbitrarily many asymmetric countries that nests the Eaton-Kortum model of\ntrade and the Romer growth model as special cases. The key result is an\nanalytical expression to decompose gains from trade into dynamic and static\ncomponents. In this framework, the product innovation growth rate increases\nwith higher market access. Finally, a quantitative version of the model\nsuggests that: (a) the EU enlargement increased its long-run yearly growth rate\nby about 0.10pp; and (b) dynamic gains can account for between 65-90% of total\nwelfare gains from trade.\n"
    },
    {
        "paper_id": 2406.08742,
        "authors": "Joel Ong and Dorien Herremans",
        "title": "DeepUnifiedMom: Unified Time-series Momentum Portfolio Construction via\n  Multi-Task Learning with Multi-Gate Mixture of Experts",
        "comments": "21 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This paper introduces DeepUnifiedMom, a deep learning framework that enhances\nportfolio management through a multi-task learning approach and a multi-gate\nmixture of experts. The essence of DeepUnifiedMom lies in its ability to create\nunified momentum portfolios that incorporate the dynamics of time series\nmomentum across a spectrum of time frames, a feature often missing in\ntraditional momentum strategies. Our comprehensive backtesting, encompassing\ndiverse asset classes such as equity indexes, fixed income, foreign exchange,\nand commodities, demonstrates that DeepUnifiedMom consistently outperforms\nbenchmark models, even after factoring in transaction costs. This superior\nperformance underscores DeepUnifiedMom's capability to capture the full\nspectrum of momentum opportunities within financial markets. The findings\nhighlight DeepUnifiedMom as an effective tool for practitioners looking to\nexploit the entire range of momentum opportunities. It offers a compelling\nsolution for improving risk-adjusted returns and is a valuable strategy for\nnavigating the complexities of portfolio management.\n"
    },
    {
        "paper_id": 2406.09226,
        "authors": "Kobi Abayomi",
        "title": "How & Why To Use Audience Segmentation to Maximize (Listener) Demand\n  Across Digital Music Portfolio",
        "comments": "15 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Digital delivery of songs has radically changed the way people can enjoy\nmusic, the sort of music available for listening, and the manner by which\nrights holders are compensated for their contributions to songs. Listeners\nenjoy an unlimited potpourri of sounds, uniquely free of incremental\nacquisition or switching costs which have been replaced by subscription or\nrentier fees. This regime shift has revealed listening patterns governed by\naffinity, boredom, attention budget, etc.: instantaneous, dynamic, organic or\nprogrammatic song selection. This regime shift in demand availability -- with\nthe commensurate translation of revenue implications -- deprecates current\northodoxy for content curation. The impulse to point-of-sale model is\ninsufficient in a regime where demand revenue is proportional to demand\naffinity and each are strongly dependent time series processes. We explore\nstrategies & implications -- which are generalizable to any media rights\nholding firm -- from a prediction & optimization point of view for two\nstraightforward demand models.\n"
    },
    {
        "paper_id": 2406.09488,
        "authors": "\\'Alvaro Romaniega",
        "title": "Note on a Theoretical Justification for Approximations of Arithmetic\n  Forwards",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This brief note explores the theoretical justification for some\napproximations of arithmetic forwards ($F_a$) with weighted averages of\novernight (ON) forwards ($F_k$). The central equation presented in this\nanalysis is: \\begin{equation*}\nF_a(0;T_s,T_e)=\\frac{1}{\\tau(T_s,T_e)}\\sum_{k=1}^K \\tau_k \\mathcal{A}_k F_k\\,,\n\\end{equation*} with $\\mathcal{A}_k$ being explicit model-dependent quantities\nthat, under certain market scenarios, are close to one. We will present\ncomputationally cheaper methods that approximate $F_a$, i.e., we will define\nsome $\\{\\tilde{\\mathcal{A}}_k\\}_{k=1}^K$ such that \\begin{equation*}\nF_a(0;T_s,T_e)\\approx \\frac{1}{\\tau(T_s,T_e)}\\sum_{k=1}^K \\tilde{\\mathcal{A}}_k\n\\tau_k F_k\\,. \\end{equation*} We also demonstrate that one of these forms can\nbe closely aligned with an approximation suggested by Katsumi Takada in his\nwork on the valuation of arithmetic averages of Fed Funds rates.\n"
    },
    {
        "paper_id": 2406.0949,
        "authors": "Emily Silcock and Abhishek Arora and Luca D'Amico-Wong and Melissa\n  Dell",
        "title": "Newswire: A Large-Scale Structured Database of a Century of Historical\n  News",
        "comments": "arXiv admin note: text overlap with arXiv:2306.17810,\n  arXiv:2308.12477",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In the U.S. historically, local newspapers drew their content largely from\nnewswires like the Associated Press. Historians argue that newswires played a\npivotal role in creating a national identity and shared understanding of the\nworld, but there is no comprehensive archive of the content sent over\nnewswires. We reconstruct such an archive by applying a customized deep\nlearning pipeline to hundreds of terabytes of raw image scans from thousands of\nlocal newspapers. The resulting dataset contains 2.7 million unique public\ndomain U.S. newswire articles, written between 1878 and 1977. Locations in\nthese articles are georeferenced, topics are tagged using customized neural\ntopic classification, named entities are recognized, and individuals are\ndisambiguated to Wikipedia using a novel entity disambiguation model. To\nconstruct the Newswire dataset, we first recognize newspaper layouts and\ntranscribe around 138 millions structured article texts from raw image scans.\nWe then use a customized neural bi-encoder model to de-duplicate reproduced\narticles, in the presence of considerable abridgement and noise, quantifying\nhow widely each article was reproduced. A text classifier is used to ensure\nthat we only include newswire articles, which historically are in the public\ndomain. The structured data that accompany the texts provide rich information\nabout the who (disambiguated individuals), what (topics), and where\n(georeferencing) of the news that millions of Americans read over the course of\na century. We also include Library of Congress metadata information about the\nnewspapers that ran the articles on their front pages. The Newswire dataset is\nuseful both for large language modeling - expanding training data beyond what\nis available from modern web texts - and for studying a diversity of questions\nin computational linguistics, social science, and the digital humanities.\n"
    },
    {
        "paper_id": 2406.09554,
        "authors": "A. Balaraman, S. Maokosy, L. Slaton, R. Cardona, P. Maokosy, N. Gaitan",
        "title": "California Community Colleges: Designing mentoring networks for access\n  to social capital",
        "comments": "8 pages, 4 Tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Successful careers are built on Skills (what you know), Occupational Identity\n(what you believe you can be) and Social Capital (who you know). Higher-ed\nspends significant resources in addressing the first, sometimes to the\nexclusion of the other two - which are difficult and expensive to teach and\nadminister. This research specifically explores how near-peer mentoring\nprograms, rather than a stand-alone opt-in guidance, can be integrated into the\ninstruction/pedagogy by faculty at California community colleges. The research\nwas conducted at 5 California community colleges (Reedley, Porterville,\nCoalinga, Solano and Glendale). A mixed-methods approach was used to gather\nsocial cognitive measures of student self-efficacy, occupational identity and\nsocial capital access. Measures were collected using survey instruments at the\nbeginning of the mentoring program, and at its culmination. One of the most\nconsistent measures observed across all the pilots was the increase in student\nself-efficacy of skills and competencies (3% - 7%) across colleges,\ngeographies, and course formats after the mentoring program. Additionally, the\nresearch offers insights in implementing peer and near-peer mentoring programs\nthat improve course completion, with significant instructional (and\nnon-instructional) cost advantages.\n"
    },
    {
        "paper_id": 2406.09578,
        "authors": "Yizhan Shu and Chenyu Yu and John M. Mulvey",
        "title": "Dynamic Asset Allocation with Asset-Specific Regime Forecasts",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article introduces a novel hybrid regime identification-forecasting\nframework designed to enhance multi-asset portfolio construction by integrating\nasset-specific regime forecasts. Unlike traditional approaches that focus on\nbroad economic regimes affecting the entire asset universe, our framework\nleverages both unsunpervised and supervised learning to generate tailored\nregime forecasts for individual assets. Initially, we use the statistical jump\nmodel, a robust unsupervised regime identification model, to derive regime\nlabels for historical periods, classifying them into bullish or bearish states\nbased on features extracted from an asset return series. Following this, a\nsupervised gradient-boosted decision tree classifier is trained to predict\nthese regimes using a combination of asset-specific return features and\ncross-asset macro-features. We apply this framework individually to each asset\nin our universe. Subsequently, return and risk forecasts which incorporate\nthese regime predictions are input into Markowitz mean-variance optimization to\ndetermine optimal asset allocation weights. We demonstrate the efficacy of our\napproach through an empirical study on a multi-asset portfolio comprising\ntwelve risky assets, including global equity, bond, real estate, and commodity\nindexes spanning from 1991 to 2023. The results consistently show\noutperformance across various portfolio models, including minimum-variance,\nmean-variance, and naive-diversified portfolios, highlighting the advantages of\nintegrating asset-specific regime forecasts into dynamic asset allocation.\n"
    },
    {
        "paper_id": 2406.09765,
        "authors": "Liyang Wang, Yu Cheng, Ao Xiang, Jingyu Zhang, Haowei Yang",
        "title": "Application of Natural Language Processing in Financial Risk Detection",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper explores the application of Natural Language Processing (NLP) in\nfinancial risk detection. By constructing an NLP-based financial risk detection\nmodel, this study aims to identify and predict potential risks in financial\ndocuments and communications. First, the fundamental concepts of NLP and its\ntheoretical foundation, including text mining methods, NLP model design\nprinciples, and machine learning algorithms, are introduced. Second, the\nprocess of text data preprocessing and feature extraction is described.\nFinally, the effectiveness and predictive performance of the model are\nvalidated through empirical research. The results show that the NLP-based\nfinancial risk detection model performs excellently in risk identification and\nprediction, providing effective risk management tools for financial\ninstitutions. This study offers valuable references for the field of financial\nrisk management, utilizing advanced NLP techniques to improve the accuracy and\nefficiency of financial risk detection.\n"
    },
    {
        "paper_id": 2406.09959,
        "authors": "Linn Engstr\\\"om, Sigrid K\\\"allblad, Johan Karlsson",
        "title": "Computation of Robust Option Prices via Structured Multi-Marginal\n  Martingale Optimal Transport",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce an efficient computational framework for solving a class of\nmulti-marginal martingale optimal transport problems, which includes many\nrobust pricing problems of large financial interest. Such problems are\ntypically computationally challenging due to the martingale constraint,\nhowever, by extending the state space we can identify them with problems that\nexhibit a certain sequential martingale structure. Our method exploits such\nstructures in combination with entropic regularisation, enabling fast\ncomputation of optimal solutions and allowing us to solve problems with a large\nnumber of marginals. We demonstrate the method by using it for computing robust\nprice bounds for different options, such as lookback options and Asian options.\n"
    },
    {
        "paper_id": 2406.10136,
        "authors": "Matthew Polisson and John K.-H. Quah",
        "title": "Rationalizability, Cost-Rationalizability, and Afriat's Efficiency Index",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This note explains the equivalence between approximate rationalizability and\napproximate cost-rationalizability within the context of consumer demand. In\nconnection with these results, we interpret Afriat's (1973) critical cost\nefficiency index (CCEI) as a measure of approximate rationalizability through\ncost inefficiency, in the sense that an agent is spending more money than is\nrequired to achieve her utility targets.\n"
    },
    {
        "paper_id": 2406.10214,
        "authors": "Francesca Biagini, Lukas Gonon, Niklas Walter",
        "title": "Universal randomised signatures for generative time series modelling",
        "comments": "33 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Randomised signature has been proposed as a flexible and easily implementable\nalternative to the well-established path signature. In this article, we employ\nrandomised signature to introduce a generative model for financial time series\ndata in the spirit of reservoir computing. Specifically, we propose a novel\nWasserstein-type distance based on discrete-time randomised signatures. This\nmetric on the space of probability measures captures the distance between\n(conditional) distributions. Its use is justified by our novel universal\napproximation results for randomised signatures on the space of continuous\nfunctions taking the underlying path as an input. We then use our metric as the\nloss function in a non-adversarial generator model for synthetic time series\ndata based on a reservoir neural stochastic differential equation. We compare\nthe results of our model to benchmarks from the existing literature.\n"
    },
    {
        "paper_id": 2406.10465,
        "authors": "Xiaomin Shi, Zuo Quan Xu",
        "title": "Constrained mean-variance investment-reinsurance under the\n  Cram\\'er-Lundberg model with random coefficients",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study an optimal mean-variance investment-reinsurance\nproblem for an insurer (she) under a Cram\\'er-Lundberg model with random\ncoefficients. At any time, the insurer can purchase reinsurance or acquire new\nbusiness and invest her surplus in a security market consisting of a risk-free\nasset and multiple risky assets, subject to a general convex cone investment\nconstraint. We reduce the problem to a constrained stochastic linear-quadratic\ncontrol problem with jumps whose solution is related to a system of partially\ncoupled stochastic Riccati equations (SREs). Then we devote ourselves to\nestablishing the existence and uniqueness of solutions to the SREs by pure\nbackward stochastic differential equation (BSDE) techniques. We achieve this\nwith the help of approximation procedure, comparison theorems for BSDEs with\njumps, log transformation and BMO martingales. The efficient\ninvestment-reinsurance strategy and efficient mean-variance frontier are\nexplicitly given through the solutions of the SREs, which are shown to be a\nlinear feedback form of the wealth process and a half-line, respectively.\n"
    },
    {
        "paper_id": 2406.10648,
        "authors": "H\\'el\\`ene Cossette, Etienne Marceau, Alessandro Mutti, Patrizia\n  Semeraro",
        "title": "Generalized FGM dependence: Geometrical representation and convex bounds\n  on sums",
        "comments": "31 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Building on the one-to-one relationship between generalized FGM copulas and\nmultivariate Bernoulli distributions, we prove that the class of multivariate\ndistributions with generalized FGM copulas is a convex polytope. Therefore, we\nfind sharp bounds in this class for many aggregate risk measures, such as\nvalue-at-risk, expected shortfall, and entropic risk measure, by enumerating\ntheir values on the extremal points of the convex polytope. This is infeasible\nin high dimensions. We overcome this limitation by considering the aggregation\nof identically distributed risks with generalized FGM copula specified by a\ncommon parameter $p$. In this case, the analogy with the geometrical structure\nof the class of Bernoulli distribution allows us to provide sharp analytical\nbounds for convex risk measures.\n"
    },
    {
        "paper_id": 2406.10695,
        "authors": "Adam Korniejczuk, Robert \\'Slepaczuk",
        "title": "Statistical arbitrage in multi-pair trading strategy based on graph\n  clustering algorithms in US equities market",
        "comments": "33 pages, 18 tables, 16 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The study seeks to develop an effective strategy based on the novel framework\nof statistical arbitrage based on graph clustering algorithms. Amalgamation of\nquantitative and machine learning methods, including the Kelly criterion, and\nan ensemble of machine learning classifiers have been used to improve\nrisk-adjusted returns and increase immunity to transaction costs over existing\napproaches. The study seeks to provide an integrated approach to optimal signal\ndetection and risk management. As a part of this approach, innovative ways of\noptimizing take profit and stop loss functions for daily frequency trading\nstrategies have been proposed and tested. All of the tested approaches\noutperformed appropriate benchmarks. The best combinations of the techniques\nand parameters demonstrated significantly better performance metrics than the\nrelevant benchmarks. The results have been obtained under the assumption of\nrealistic transaction costs, but are sensitive to changes in some key\nparameters.\n"
    },
    {
        "paper_id": 2406.10719,
        "authors": "Orson Mengara",
        "title": "Trading Devil: Robust backdoor attack via Stochastic investment models\n  and Bayesian approach",
        "comments": "(Last update!, a constructive comment from arxiv led to this latest\n  update ) Stochastic investment models and a Bayesian approach to better\n  modeling of uncertainty : adversarial machine learning or Stochastic market.\n  arXiv admin note: substantial text overlap with arXiv:2402.05967 (see this\n  link to the paper by : Orson Mengara)",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  With the growing use of voice-activated systems and speech recognition\ntechnologies, the danger of backdoor attacks on audio data has grown\nsignificantly. This research looks at a specific type of attack, known as a\nStochastic investment-based backdoor attack (MarketBack), in which adversaries\nstrategically manipulate the stylistic properties of audio to fool speech\nrecognition systems. The security and integrity of machine learning models are\nseriously threatened by backdoor attacks, in order to maintain the reliability\nof audio applications and systems, the identification of such attacks becomes\ncrucial in the context of audio data. Experimental results demonstrated that\nMarketBack is feasible to achieve an average attack success rate close to 100%\nin seven victim models when poisoning less than 1% of the training data.\n"
    },
    {
        "paper_id": 2406.10978,
        "authors": "Christoph B\\\"orgers and Claude Greengard",
        "title": "Local wealth condensation for yard-sale models with wealth-dependent\n  biases",
        "comments": "8 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  In Chakraborti's yard-sale model of an economy, identical agents engage in\npairwise trades, resulting in wealth exchanges that conserve each agent's\nexpected wealth. Doob's martingale convergence theorem immediately implies\nalmost sure wealth condensation, i.e., convergence to a state in which a single\nagent owns the entire economy. If some pairs of agents are not allowed to trade\nwith each other, the martingale convergence theorem still implies local wealth\ncondensation, i.e., convergence to a state in which some agents are wealthy,\nwhile all their trading partners are impoverished. In this note, we propose a\nnew, more elementary proof of this result. Unlike the proof based on the\nmartingale convergence theorem, our argument applies to models with a\nwealth-acquired advantage, and even to certain models with a poverty-acquired\nadvantage.\n"
    },
    {
        "paper_id": 2406.11426,
        "authors": "Ayato Kitadai, Sinndy Dayana Rico Lugo, Yudai Tsurusaki, Yusuke\n  Fukasawa and Nariaki Nishino",
        "title": "Can AI with High Reasoning Ability Replicate Human-like Decision Making\n  in Economic Experiments?",
        "comments": "10 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Economic experiments offer a controlled setting for researchers to observe\nhuman decision-making and test diverse theories and hypotheses; however,\nsubstantial costs and efforts are incurred to gather many individuals as\nexperimental participants. To address this, with the development of large\nlanguage models (LLMs), some researchers have recently attempted to develop\nsimulated economic experiments using LLMs-driven agents, called generative\nagents. If generative agents can replicate human-like decision-making in\neconomic experiments, the cost problem of economic experiments can be\nalleviated. However, such a simulation framework has not been yet established.\nConsidering the previous research and the current evolutionary stage of LLMs,\nthis study focuses on the reasoning ability of generative agents as a key\nfactor toward establishing a framework for such a new methodology. A\nmulti-agent simulation, designed to improve the reasoning ability of generative\nagents through prompting methods, was developed to reproduce the result of an\nactual economic experiment on the ultimatum game. The results demonstrated that\nthe higher the reasoning ability of the agents, the closer the results were to\nthe theoretical solution than to the real experimental result. The results also\nsuggest that setting the personas of the generative agents may be important for\nreproducing the results of real economic experiments. These findings are\nvaluable for the future definition of a framework for replacing human\nparticipants with generative agents in economic experiments when LLMs are\nfurther developed.\n"
    },
    {
        "paper_id": 2406.1152,
        "authors": "Lukas Gonon, Antoine Jacquier, Ruben Wiedemann",
        "title": "Operator Deep Smoothing for Implied Volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We devise a novel method for implied volatility smoothing based on neural\noperators. The goal of implied volatility smoothing is to construct a smooth\nsurface that links the collection of prices observed at a specific instant on a\ngiven option market. Such price data arises highly dynamically in ever-changing\nspatial configurations, which poses a major limitation to foundational machine\nlearning approaches using classical neural networks. While large models in\nlanguage and image processing deliver breakthrough results on vast corpora of\nraw data, in financial engineering the generalization from big historical\ndatasets has been hindered by the need for considerable data pre-processing. In\nparticular, implied volatility smoothing has remained an instance-by-instance,\nhands-on process both for neural network-based and traditional parametric\nstrategies. Our general operator deep smoothing approach, instead, directly\nmaps observed data to smoothed surfaces. We adapt the graph neural operator\narchitecture to do so with high accuracy on ten years of raw intraday S&P 500\noptions data, using a single set of weights. The trained operator adheres to\ncritical no-arbitrage constraints and is robust with respect to subsampling of\ninputs (occurring in practice in the context of outlier removal). We provide\nextensive historical benchmarks and showcase the generalization capability of\nour approach in a comparison with SVI, an industry standard parametrization for\nimplied volatility. The operator deep smoothing approach thus opens up the use\nof neural networks on large historical datasets in financial engineering.\n"
    },
    {
        "paper_id": 2406.11886,
        "authors": "Haoren Zhu, Pengfei Zhao, Wilfred Siu Hung NG, Dik Lun Lee",
        "title": "Financial Assets Dependency Prediction Utilizing Spatiotemporal Patterns",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Financial assets exhibit complex dependency structures, which are crucial for\ninvestors to create diversified portfolios to mitigate risk in volatile\nfinancial markets. To explore the financial asset dependencies dynamics, we\npropose a novel approach that models the dependencies of assets as an Asset\nDependency Matrix (ADM) and treats the ADM sequences as image sequences. This\nallows us to leverage deep learning-based video prediction methods to capture\nthe spatiotemporal dependencies among assets. However, unlike images where\nneighboring pixels exhibit explicit spatiotemporal dependencies due to the\nnatural continuity of object movements, assets in ADM do not have a natural\norder. This poses challenges to organizing the relational assets to reveal\nbetter the spatiotemporal dependencies among neighboring assets for ADM\nforecasting. To tackle the challenges, we propose the Asset Dependency Neural\nNetwork (ADNN), which employs the Convolutional Long Short-Term Memory\n(ConvLSTM) network, a highly successful method for video prediction. ADNN can\nemploy static and dynamic transformation functions to optimize the\nrepresentations of the ADM. Through extensive experiments, we demonstrate that\nour proposed framework consistently outperforms the baselines in the ADM\nprediction and downstream application tasks. This research contributes to\nunderstanding and predicting asset dependencies, offering valuable insights for\nfinancial market participants.\n"
    },
    {
        "paper_id": 2406.11903,
        "authors": "Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M. Mulvey, H. Vincent Poor,\n  Qingsong Wen, Stefan Zohren",
        "title": "A Survey of Large Language Models for Financial Applications: Progress,\n  Prospects and Challenges",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recent advances in large language models (LLMs) have unlocked novel\nopportunities for machine learning applications in the financial domain. These\nmodels have demonstrated remarkable capabilities in understanding context,\nprocessing vast amounts of data, and generating human-preferred contents. In\nthis survey, we explore the application of LLMs on various financial tasks,\nfocusing on their potential to transform traditional practices and drive\ninnovation. We provide a discussion of the progress and advantages of LLMs in\nfinancial contexts, analyzing their advanced technologies as well as\nprospective capabilities in contextual understanding, transfer learning\nflexibility, complex emotion detection, etc. We then highlight this survey for\ncategorizing the existing literature into key application areas, including\nlinguistic tasks, sentiment analysis, financial time series, financial\nreasoning, agent-based modeling, and other applications. For each application\narea, we delve into specific methodologies, such as textual analysis,\nknowledge-based analysis, forecasting, data augmentation, planning, decision\nsupport, and simulations. Furthermore, a comprehensive collection of datasets,\nmodel assets, and useful codes associated with mainstream applications are\npresented as resources for the researchers and practitioners. Finally, we\noutline the challenges and opportunities for future research, particularly\nemphasizing a number of distinctive aspects in this field. We hope our work can\nhelp facilitate the adoption and further development of LLMs in the financial\nsector.\n"
    },
    {
        "paper_id": 2406.11908,
        "authors": "Run-Xuan Tang",
        "title": "Research on Trends in Illegal Wildlife Trade based on Comprehensive\n  Growth Dynamic Model",
        "comments": "7 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This paper presents an innovative Comprehensive Growth Dynamic Model (CGDM).\nCGDM is designed to simulate the temporal evolution of an event, incorporating\neconomic and social factors. CGDM is a regression of logistic regression, power\nlaw regression, and Gaussian perturbation term. CGDM is comprised of logistic\nregression, power law regression, and Gaussian perturbation term. CGDM can\neffectively forecast the temporal evolution of an event, incorporating economic\nand social factors. The illicit trade in wildlife has a deleterious impact on\nthe ecological environment. In this paper, we employ CGDM to forecast the\ntrajectory of illegal wildlife trade from 2024 to 2034 in China. The mean\nsquare error is utilized as the loss function. The model illuminates the future\ntrajectory of illegal wildlife trade, with a minimum point occurring in 2027\nand a maximum point occurring in 2029. The stability of contemporary society\ncan be inferred. CGDM's robust and generalizable nature is also evident.\n"
    },
    {
        "paper_id": 2406.11913,
        "authors": "Bogdan Oancea",
        "title": "Big data in economics",
        "comments": "Knowledge for the market use, Conference Proceedings, 2018, Olomouc,\n  Czech Republic",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The term of big data was used since 1990s, but it became very popular around\n2012. A recent definition of this term says that big data are information\nassets characterized by high volume, velocity, variety and veracity that need\nspecial analytical methods and software technologies to extract value form\nthem. While big data was used at the beginning mostly in information technology\nfield, now it can be found in every area of activity: in governmental\ndecision-making processes, manufacturing, education, healthcare, economics,\nengineering, natural sciences, sociology. The rise of Internet, mobile phones,\nsocial media networks, different types of sensors or satellites provide\nenormous quantities of data that can have profound effects on economic\nresearch. The data revolution that we are facing transformed the way we measure\nthe human behavior and economic activities. Unemployment, consumer price index,\npopulation mobility, financial transactions are only few examples of economic\nphenomena that can be analyzed using big data sources. In this paper we will\nstart with a taxonomy of big data sources and show how these new data sources\ncan be used in empirical analyses and to build economic indicators very fast\nand with reduced costs.\n"
    },
    {
        "paper_id": 2406.12098,
        "authors": "Peter Klimek, Maximilian Hess, Markus Gerschberger, Stefan Thurner",
        "title": "Circular transformation of the European steel industry renders scrap\n  metal a strategic resource",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The steel industry is a major contributor to CO2 emissions, accounting for 7%\nof global emissions. The European steel industry is seeking to reduce its\nemissions by increasing the use of electric arc furnaces (EAFs), which can\nproduce steel from scrap, marking a major shift towards a circular steel\neconomy. Here, we show by combining trade with business intelligence data that\nthis shift requires a deep restructuring of the global and European scrap\ntrade, as well as a substantial scaling of the underlying business ecosystem.\nWe find that the scrap imports of European countries with major EAF\ninstallations have steadily decreased since 2007 while globally scrap trade\nstarted to increase recently. Our statistical modelling shows that every 1,000\ntonnes of EAF capacity installed is associated with an increase in annual\nimports of 550 tonnes and a decrease in annual exports of 1,000 tonnes of\nscrap, suggesting increased competition for scrap metal as countries ramp up\ntheir EAF capacity. Furthermore, each scrap company enables an increase of\naround 79,000 tonnes of EAF-based steel production per year in the EU. Taking\nthese relations as causal and extrapolating to the currently planned EAF\ncapacity, we find that an additional 730 (SD 140) companies might be required,\nemploying about 35,000 people (IQR 29,000-50,000) and generating an additional\nestimated turnover of USD 35 billion (IQR 27-48). Our results thus suggest that\nscrap metal is likely to become a strategic resource. They highlight the need\nfor a massive restructuring of the industry's supply networks and identify the\nresulting growth opportunities for companies.\n"
    },
    {
        "paper_id": 2406.12305,
        "authors": "Kexin Chen, Kyunghyun Park, Hoi Ying Wong",
        "title": "Robust dividend policy: Equivalence of Epstein-Zin and Maenhout\n  preferences",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In a continuous-time economy, this study formulates the Epstein-Zin (EZ)\npreference for the discounted dividend (or cash payouts) of stockholders as an\nEZ singular control utility. We show that such a problem is well-defined and\nequivalent to the robust dividend policy set by the firm's executive in the\nsense of Maenhout's ambiguity-averse preference. While the firm's executive\nannounces the expected future earnings in financial reports, they also signal\nthe firm's confidence in the expected earnings through dividend or cash\npayouts. The robust dividend policy can then be characterized by a\nHamilton-Jacobi-Bellman (HJB) variational inequality (VI). By constructing a\nnovel shooting method for the HJB-VI, we theoretically prove that the robust\ndividend policy is a threshold strategy on the firm's surplus process.\nTherefore, dividend-caring investors can choose firms that match their\npreferences by examining stock's dividend policies and financial statements,\nwhereas executives can make use of dividend to signal their confidence, in the\nform of ambiguity aversion, on realizing the earnings implied by their\nfinancial statements.\n"
    },
    {
        "paper_id": 2406.12417,
        "authors": "Abe Alexander, Jesse Moestaredjo, Mart Heuvelmans, Lars Fritz",
        "title": "Role of fee choice in revenue generation of AMMs: A quantitative study",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In the ever evolving landscape of decentralized finance automated market\nmakers (AMMs) play a key role: they provide a market place for trading assets\nin a decentralized manner. For so-called bluechip pairs, arbitrage activity\nprovides a major part of the revenue generation of AMMs but also a major source\nof loss due to the so-called 'informed orderflow'. Finding ways to minimize\nthose losses while still keeping uninformed trading activity alive is a major\nproblem in the field. In this paper we will investigate the mechanics of said\narbitrage and try to understand how AMMs can maximize the revenue creation or\nin other words minimize the losses. To that end, we model the dynamics of\narbitrage activity for a concrete implementation of a pool and study its\nsensitivity to the choice of fee aiming to maximize the revenue for the AMM. We\nidentify dynamical fees that mimic the directionality of the price due to\nasymmetric fee choices as a promising avenue to mitigate losses to toxic flow.\nThis work is based on and extends a recent article by some of the authors.\n"
    },
    {
        "paper_id": 2406.12445,
        "authors": "Lukas K\\\"ung, George M. Giaglis",
        "title": "DAOs' Business Value from an Open Systems Perspective: A Best-Fit\n  Framework Synthesis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Decentralized autonomous organizations (DAOs) are emerging innovative\norganizational structures, enabling collective coordination, and reshaping\ndigital collaboration. Despite the promising and transformative characteristics\nof DAOs, the potential technological advancements and the understanding of the\nbusiness value that organizations derive from implementing DAO characteristics\nare limited. This research applies a systematic review of DAOs' business\napplicability from an open systems perspective following a best-fit framework\nmethodology. Within our approach, combining both framework and thematic\nanalysis, we discuss how the open business principles apply to DAOs and present\na new DAO business framework comprising of four core business elements: i)\ntoken, ii) transactions, iii) value system and iv) strategy with their\ncorresponding sub-characteristics. This paper offers a preliminary DAO business\nframework that enhances the understanding of DAOs' transformative potential and\nguides organizations in innovating more inclusive business models (BMs), while\nalso providing a theoretical foundation for researchers to build upon.\n"
    },
    {
        "paper_id": 2406.12983,
        "authors": "Samuel Atkins, Ali Fathi, Sammy Assefa",
        "title": "Reinforcement Learning for Corporate Bond Trading: A Sell Side\n  Perspective",
        "comments": "Working Paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A corporate bond trader in a typical sell side institution such as a bank\nprovides liquidity to the market participants by buying/selling securities and\nmaintaining an inventory. Upon receiving a request for a buy/sell price quote\n(RFQ), the trader provides a quote by adding a spread over a \\textit{prevalent\nmarket price}. For illiquid bonds, the market price is harder to observe, and\ntraders often resort to available benchmark bond prices (such as MarketAxess,\nBloomberg, etc.). In \\cite{Bergault2023ModelingLI}, the concept of \\textit{Fair\nTransfer Price} for an illiquid corporate bond was introduced which is derived\nfrom an infinite horizon stochastic optimal control problem (for maximizing the\ntrader's expected P\\&L, regularized by the quadratic variation). In this paper,\nwe consider the same optimization objective, however, we approach the\nestimation of an optimal bid-ask spread quoting strategy in a data driven\nmanner and show that it can be learned using Reinforcement Learning.\nFurthermore, we perform extensive outcome analysis to examine the\nreasonableness of the trained agent's behavior.\n"
    },
    {
        "paper_id": 2406.12995,
        "authors": "Baridhi Malakar",
        "title": "Essays on Responsible and Sustainable Finance",
        "comments": "PhD thesis",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The dissertation consists of three essays on responsible and sustainable\nfinance. I show that local communities should be seen as stakeholders to\ndecisions made by corporations. In the first essay, I examine whether the\nimposition of fiduciary duty on municipal advisors affects bond yields and\nadvising fees. Using a difference-in-differences analysis, I show that bond\nyields reduce by 9\\% after the imposition of the SEC Municipal Advisor Rule. In\nthe second essay, we analyze the impact of USD 40 billion of corporate\nsubsidies given by U.S. local governments on their borrowing costs. We find\nthat winning counties experience a 15 bps increase in bond yield spread as\ncompared to the losing counties. In the third essay, we provide new evidence\nthat the bankruptcy filing of a locally-headquartered and publicly-listed\nmanufacturing firm imposes externalities on the local governments. Compared to\nmatched counties with similar economic trends, municipal bond yields for\naffected counties increase by 10 bps within a year of the firm filing for\nbankruptcy. The final essay examines whether managers walk the talk on the\nenvironmental and social discussion. We train a deep-learning model on various\ncorporate sustainability frameworks to construct a comprehensive Environmental\nand Social (E and S) dictionary. Using this dictionary, we find that the\ndiscussion of environmental topics in the earnings conference calls of U.S.\npublic firms is associated with higher pollution abatement and more future\ngreen patents.\n"
    },
    {
        "paper_id": 2406.12999,
        "authors": "Marcelo Righi",
        "title": "Robust convex risk measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the general properties of robust convex risk measures as worst-case\nvalues under uncertainty on random variables. We establish general concrete\nresults regarding convex conjugates and sub-differentials. We refine some\nresults for closed forms of worstcase law invariant convex risk measures under\ntwo concrete cases of uncertainty sets for random variables: based on the first\ntwo moments and Wasserstein balls.\n"
    },
    {
        "paper_id": 2406.13166,
        "authors": "Haibo Wang, Lutfu S.Sua, and Bahram Alidaee",
        "title": "Enhancing supply chain security with automated machine learning",
        "comments": "22 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study tackles the complexities of global supply chains, which are\nincreasingly vulnerable to disruptions caused by port congestion, material\nshortages, and inflation. To address these challenges, we explore the\napplication of machine learning methods, which excel in predicting and\noptimizing solutions based on large datasets. Our focus is on enhancing supply\nchain security through fraud detection, maintenance prediction, and material\nbackorder forecasting. We introduce an automated machine learning framework\nthat streamlines data analysis, model construction, and hyperparameter\noptimization for these tasks. By automating these processes, our framework\nimproves the efficiency and effectiveness of supply chain security measures.\nOur research identifies key factors that influence machine learning\nperformance, including sampling methods, categorical encoding, feature\nselection, and hyperparameter optimization. We demonstrate the importance of\nconsidering these factors when applying machine learning to supply chain\nchallenges. Traditional mathematical programming models often struggle to cope\nwith the complexity of large-scale supply chain problems. Our study shows that\nmachine learning methods can provide a viable alternative, particularly when\ndealing with extensive datasets and complex patterns. The automated machine\nlearning framework presented in this study offers a novel approach to supply\nchain security, contributing to the existing body of knowledge in the field.\nIts comprehensive automation of machine learning processes makes it a valuable\ncontribution to the domain of supply chain management.\n"
    },
    {
        "paper_id": 2406.13486,
        "authors": "Duy Khanh Lam",
        "title": "Mean-Variance Portfolio Selection in Long-Term Investments with Unknown\n  Distribution: Online Estimation, Risk Aversion under Ambiguity, and\n  Universality of Algorithms",
        "comments": "21 pages, working paper, first draft version (may contain errors)",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The standard approach for constructing a Mean-Variance portfolio involves\nestimating parameters for the model using collected samples. However, since the\ndistribution of future data may not resemble that of the training set, the\nout-of-sample performance of the estimated portfolio is worse than one derived\nwith true parameters, which has prompted several innovations for better\nestimation. Instead of treating the data without a timing aspect as in the\ncommon training-backtest approach, this paper adopts a perspective where data\ngradually and continuously reveal over time. The original model is recast into\nan online learning framework, which is free from any statistical assumptions,\nto propose a dynamic strategy of sequential portfolios such that its empirical\nutility, Sharpe ratio, and growth rate asymptotically achieve those of the true\nportfolio, derived with perfect knowledge of the future data.\n  When the distribution of future data has a normal shape, the growth rate of\nwealth is shown to increase by lifting the portfolio along the efficient\nfrontier through the calibration of risk aversion. Since risk aversion cannot\nbe appropriately predetermined, another proposed algorithm updating this\ncoefficient over time forms a dynamic strategy approaching the optimal\nempirical Sharpe ratio or growth rate associated with the true coefficient. The\nperformance of these proposed strategies is universally guaranteed under\nspecific stochastic markets. Furthermore, in stationary and ergodic markets,\nthe so-called Bayesian strategy utilizing true conditional distributions, based\non observed past market information during investment, almost surely does not\nperform better than the proposed strategies in terms of empirical utility,\nSharpe ratio, or growth rate, which, in contrast, do not rely on conditional\ndistributions.\n"
    },
    {
        "paper_id": 2406.13508,
        "authors": "Oriol Zamora Font",
        "title": "Pricing VIX options under the Heston-Hawkes stochastic volatility model",
        "comments": "28 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We derive a semi-analytical pricing formula for European VIX call options\nunder the Heston-Hawkes stochastic volatility model introduced in\narXiv:2210.15343. This arbitrage-free model incorporates the volatility\nclustering feature by adding an independent compound Hawkes process to the\nHeston volatility. Using the Markov property of the exponential Hawkes an\nexplicit expression of $\\text{VIX}^2$ is derived as a linear combination of the\nvariance and the Hawkes intensity. We apply qualitative ODE theory to study the\nexistence of some generalized Riccati ODEs. Thereafter, we compute the joint\ncharacteristic function of the variance and the Hawkes intensity exploiting the\nexponential affine structure of the model. Finally, the pricing formula is\nobtained by applying standard Fourier techniques.\n"
    },
    {
        "paper_id": 2406.13539,
        "authors": "Xia Han and Peng Liu",
        "title": "Robust Lambda-quantiles and extreme probabilities",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we investigate the robust models for $\\Lambda$-quantiles with\npartial information regarding the loss distribution, where $\\Lambda$-quantiles\nextend the classical quantiles by replacing the fixed probability level with a\nprobability/loss function $\\Lambda$. We find that, under some assumptions, the\nrobust $\\Lambda$-quantiles equal the $\\Lambda$-quantiles of the extreme\nprobabilities. This finding allows us to obtain the robust $\\Lambda$-quantiles\nby applying the results of robust quantiles in the literature. Our results are\napplied to uncertainty sets characterized by three different constraints\nrespectively: moment constraints, probability distance constraints via\nWasserstein metric, and marginal constraints in risk aggregation. We obtain\nsome explicit expressions for robust $\\Lambda$-quantiles by deriving the\nextreme probabilities for each uncertainty set. Those results are applied to\noptimal portfolio selection under model uncertainty.\n"
    },
    {
        "paper_id": 2406.13563,
        "authors": "Tariq Khan",
        "title": "Serotonin as a Creativity Pump",
        "comments": "18 pages, 17 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "abstract": "  The location of Western Civilization defined nations in Europe and in the\nUnited States within the largest global pollen environments on the planet is\nproposed as a key factor leading to their success. Environments with dense\npollen concentrations will cause large up and down changes in serum histamine\ndirectly causing reductions and increases in brain serotonin i.e., a larger\nserotonin slope, linked to higher levels of creativity. The pollen ecosystem in\nnorthern latitude nations is thus considered the hidden driver of the success\nof these populations as the biochemical interaction between histamine and\nserotonin leads to a creativity pump that is proposed as the fundamental driver\nof intelligence in micro and macro human populations.\n"
    },
    {
        "paper_id": 2406.13726,
        "authors": "Zhouzhou Gu, Mathieu Lauri\\`ere, Sebastian Merkel, Jonathan Payne",
        "title": "Global Solutions to Master Equations for Continuous Time Heterogeneous\n  Agent Macroeconomic Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We propose and compare new global solution algorithms for continuous time\nheterogeneous agent economies with aggregate shocks. First, we approximate the\nagent distribution so that equilibrium in the economy can be characterized by a\nhigh, but finite, dimensional non-linear partial differential equation. We\nconsider different approximations: discretizing the number of agents,\ndiscretizing the agent state variables, and projecting the distribution onto a\nfinite set of basis functions. Second, we represent the value function using a\nneural network and train it to solve the differential equation using deep\nlearning tools. We refer to the solution as an Economic Model Informed Neural\nNetwork (EMINN). The main advantage of this technique is that it allows us to\nfind global solutions to high dimensional, non-linear problems. We demonstrate\nour algorithm by solving important models in the macroeconomics and spatial\nliteratures (e.g. Krusell and Smith (1998), Khan and Thomas (2007), Bilal\n(2023)).\n"
    },
    {
        "paper_id": 2406.13789,
        "authors": "John C. Stevenson",
        "title": "Death, Taxes, and Inequality. Can a Minimal Model Explain Real Economic\n  Inequality?",
        "comments": "16 pages, 6 figures, 1 table, 1 algorithm table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Income inequalities and redistribution policies are modeled with a minimal,\nendogenous model of a simple foraging economy. The model is scaled to match\nhuman lifespans and overall death rates. Stochastic income distributions from\nthe model are compared to empirical data from actual economies. Empirical data\nare fit to implied distributions providing necessary resolution for comparison.\nThe impacts of redistribution policies on total wealth, income distributions,\nand inequality are shown to be similar for the empirical data and the model.\nThese comparisons enable detailed determinations of population welfare beyond\nwhat is possible with total wealth and inequality metrics. Estate taxes in the\nmodel appear quite effective in reducing inequality without reducing total\nwealth. Significant income inequality emerges for the model for a population of\nequally capable individuals presented with equal opportunities. Stochastic\npopulation instability at both the high and low ends of infertility are\nconsidered.\n"
    },
    {
        "paper_id": 2406.13794,
        "authors": "Viraj Nadkarni, Sanjeev Kulkarni, Pramod Viswanath",
        "title": "Adaptive Curves for Optimally Efficient Market Making",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Automated Market Makers (AMMs) are essential in Decentralized Finance (DeFi)\nas they match liquidity supply with demand. They function through liquidity\nproviders (LPs) who deposit assets into liquidity pools. However, the asset\ntrading prices in these pools often trail behind those in more dynamic,\ncentralized exchanges, leading to potential arbitrage losses for LPs. This\nissue is tackled by adapting market maker bonding curves to trader behavior,\nbased on the classical market microstructure model of Glosten and Milgrom. Our\napproach ensures a zero-profit condition for the market maker's prices. We\nderive the differential equation that an optimal adaptive curve should follow\nto minimize arbitrage losses while remaining competitive. Solutions to this\noptimality equation are obtained for standard Gaussian and Lognormal price\nmodels using Kalman filtering. A key feature of our method is its ability to\nestimate the external market price without relying on price or loss oracles. We\nalso provide an equivalent differential equation for the implied dynamics of\ncanonical static bonding curves and establish conditions for their optimality.\nOur algorithms demonstrate robustness to changing market conditions and\nadversarial perturbations, and we offer an on-chain implementation using\nUniswap v4 alongside off-chain AI co-processors.\n"
    },
    {
        "paper_id": 2406.14074,
        "authors": "Scander Mustapha",
        "title": "Strong existence and uniqueness of a calibrated local stochastic\n  volatility model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study a two-dimensional McKean-Vlasov stochastic differential equation,\nwhose volatility coefficient depends on the conditional distribution of the\nsecond component with respect to the first component. We prove the strong\nexistence and uniqueness of the solution, establishing the well-posedness of a\ntwo-factor local stochastic volatility (LSV) model calibrated to the market\nprices of European call options. In the spirit of [Jourdain and Zhou, 2020,\nExistence of a calibrated regime switching local volatility model.], we assume\nthat the factor driving the volatility of the log-price takes finitely many\nvalues. Additionally, the propagation of chaos of the particle system is\nestablished, giving theoretical justification for the algorithm [Julien Guyon\nand Henry-Labord\\`ere, 2012, Being particular about calibration.].\n"
    },
    {
        "paper_id": 2406.14238,
        "authors": "Sugandha Srivastav, Michael Zaehringer",
        "title": "The Economics of Coal Phaseouts: Auctions as a Novel Policy Instrument\n  for the Energy Transition",
        "comments": null,
        "journal-ref": "Climate Policy, pp.1-12 (2024)",
        "doi": "10.1080/14693062.2024.2358114",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The combustion of coal, the most polluting form of energy, must be\nsignificantly curtailed to limit global average temperature increase to well\nbelow 2 degrees C. The effectiveness of carbon pricing is frequently undermined\nby sub-optimally low prices and rigid market structures. Consequently,\nalternative approaches such as compensation for the early closure of coal-fired\npower plants are being considered. While bilateral negotiations can lead to\nexcessive compensation due to asymmetric information, a competitive auction can\ndiscover the true cost of closure and help allocate funds more efficiently and\ntransparently. Since Germany is the only country till date to have implemented\na coal phaseout auction, we use it to analyse the merits and demerits of the\npolicy, drawing comparisons with other countries that have phased out coal\nthrough other means. The German experience with coal phaseout auctions\nillustrates the necessity of considering additionality and interaction with\nexisting climate policies, managing dynamic incentives, and evaluating impacts\non security of supply. While theoretically auctions have attractive properties,\nin practice, their design must address these concerns to unlock the full\nbenefits. Where auctions are not appropriate due to a concentration in coal\nplant ownership, alternative strategies include enhanced incentives for\nscrappage and repurposing of coal assets.\n"
    },
    {
        "paper_id": 2406.14382,
        "authors": "Henri Ker\\\"anen, Sakari L\\\"ahdem\\\"aki",
        "title": "Identification of fiscal SVAR-IVs in small open economies",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  We propose a novel instrumental variable to identify fiscal shocks in small\nopen economies. Under the assumptions that unexpected changes in trading\npartners correlate with output of an open economy and unexpected fiscal shocks\nof a small economy are unrelated to its trading partners' forecast errors, we\nuse forecast errors of trading partner economies to proxy unexpected shocks in\ndomestic output. We show that this instrument is relevant and find evidence\nthat supports its exogeneity. Using this IV strategy, we find that the two-year\ncumulative spending multiplier is around 1 for Canada and 0.5 for euro area\nsmall open economies.\n"
    },
    {
        "paper_id": 2406.14537,
        "authors": "Chuqiao Zong, Chaojie Wang, Molei Qin, Lei Feng, Xinrun Wang, Bo An",
        "title": "MacroHFT: Memory Augmented Context-aware Reinforcement Learning On High\n  Frequency Trading",
        "comments": "Accepted to KDD 2024",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  High-frequency trading (HFT) that executes algorithmic trading in short time\nscales, has recently occupied the majority of cryptocurrency market. Besides\ntraditional quantitative trading methods, reinforcement learning (RL) has\nbecome another appealing approach for HFT due to its terrific ability of\nhandling high-dimensional financial data and solving sophisticated sequential\ndecision-making problems, \\emph{e.g.,} hierarchical reinforcement learning\n(HRL) has shown its promising performance on second-level HFT by training a\nrouter to select only one sub-agent from the agent pool to execute the current\ntransaction. However, existing RL methods for HFT still have some defects: 1)\nstandard RL-based trading agents suffer from the overfitting issue, preventing\nthem from making effective policy adjustments based on financial context; 2)\ndue to the rapid changes in market conditions, investment decisions made by an\nindividual agent are usually one-sided and highly biased, which might lead to\nsignificant loss in extreme markets. To tackle these problems, we propose a\nnovel Memory Augmented Context-aware Reinforcement learning method On HFT,\n\\emph{a.k.a.} MacroHFT, which consists of two training phases: 1) we first\ntrain multiple types of sub-agents with the market data decomposed according to\nvarious financial indicators, specifically market trend and volatility, where\neach agent owns a conditional adapter to adjust its trading policy according to\nmarket conditions; 2) then we train a hyper-agent to mix the decisions from\nthese sub-agents and output a consistently profitable meta-policy to handle\nrapid market fluctuations, equipped with a memory mechanism to enhance the\ncapability of decision-making. Extensive experiments on various cryptocurrency\nmarkets demonstrate that MacroHFT can achieve state-of-the-art performance on\nminute-level trading tasks.\n"
    },
    {
        "paper_id": 2406.14776,
        "authors": "Mahmood Alaghmandan and Olga Streltchenko",
        "title": "Lessons From Model Risk Management in Financial Institutions for\n  Academic Research",
        "comments": "27 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we discuss aspects of model risk management in financial\ninstitutions which could be adopted by academic institutions to improve the\nprocess of conducting academic research, identify and mitigate existing\nlimitations, decrease the possibility of erroneous results, and prevent\nfraudulent activities.\n"
    },
    {
        "paper_id": 2406.15197,
        "authors": "Baridhi Malakar",
        "title": "Fiduciary Duty in the Municipal Bonds Market",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  I examine whether the imposition of fiduciary duty on municipal advisors\naffects bond yields and advising fees. Using a difference-in-differences\nanalysis, I show that bond yields reduce by $\\sim$9\\% after the imposition of\nthe SEC Municipal Advisor Rule due to lower underwriting spreads. Larger\nmunicipalities are more likely to recruit advisors after the rule is effective\nand experience a greater reduction in yields. However, smaller issuers do not\nexperience a reduction in offering yields after the SEC Rule. Instead, their\nborrowing cost increases if their primary advisor exits the market. Using novel\nhand-collected data, I find that the average advising fees paid by issuers does\nnot increase after the regulation. Overall, my results suggest that while\nfiduciary duty may mitigate the principal-agent problem between some issuers\nand advisors, there is heterogeneity among issuers.\n"
    },
    {
        "paper_id": 2406.15215,
        "authors": "Muhammad Zia Hydari, Yangfan Liang, Rahul Telang",
        "title": "Sound and Fury, Signifying Nothing? Impact of Data Breach Disclosure\n  Laws",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Data breach disclosure (DBD) is presumed to improve firms' cybersecurity\npractices by inducing fear of subsequent revenue loss. This revenue loss, the\ntheory goes, will occur if customers punish an offending firm by refusing to\nbuy from them and is assumed to be the primary mechanism through which DBD laws\nwill change firm behavior ex ante. However, our analysis of a large-scale data\nbreach at a US retailer reveals no evidence of a decline in revenue. Using a\ndifference-in-difference design on revenue data from 302 stores over a 20-week\nperiod around the breach disclosure, we found no evidence of a decline either\nacross all stores or when sub-sampling by prior revenue size (to account for\nany heterogeneity in prior revenue size). Therefore, we posit that the presumed\nprimary mechanism of DBD laws, and thus these laws may be ineffective and\nmerely a lot of \"sound and fury, signifying nothing.\"\n"
    },
    {
        "paper_id": 2406.15373,
        "authors": "Lan Chen, Yufei Ji, Xichen Yao, Hengshu Zhu",
        "title": "Occupation Life Cycle",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper explores the evolution of occupations within the context of\nindustry and technology life cycles, highlighting the critical yet\nunderexplored intersection between occupational trends and broader economic\ndynamics. Introducing the Occupation Life Cycle (OLC) model, we delineate five\nstages (i.e., growth, peak, fluctuation, maturity, and decline) to\nsystematically explore the trajectory of occupations. Utilizing job posting\ndata from one of China's largest recruitment platforms as a novel proxy, our\nstudy meticulously tracks the fluctuations and emerging trends in the labor\nmarket from 2018 to 2023. Through a detailed examination of representative\nroles, such as short video operators and data analysts, alongside emerging\noccupations within the artificial intelligence (AI) sector, our findings\nallocate occupations to specific life cycle stages, revealing insightful\npatterns of occupational development and decline. Our findings offer a unique\nperspective on the interplay between occupational evolution and economic\nfactors, with a particular focus on the rapidly changing Chinese labor market.\nThis study not only contributes to the theoretical understanding of OLC but\nalso provides practical insights for policymakers, educators, and industry\nleaders facing the challenges of workforce planning and development in the face\nof technological advancement and market shifts.\n"
    },
    {
        "paper_id": 2406.15505,
        "authors": "Luigi Caputi, Anna Pidnebesna, Jaroslav Hlinka",
        "title": "Integral Betti signature confirms the hyperbolic geometry of brain,\n  climate, and financial networks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper extends the possibility to examine the underlying curvature of\ndata through the lens of topology by using the Betti curves, tools of\nPersistent Homology, as key topological descriptors, building on the clique\ntopology approach. It was previously shown that Betti curves distinguish random\nfrom Euclidean geometric matrices - i.e. distance matrices of points randomly\ndistributed in a cube with Euclidean distance. In line with previous\nexperiments, we consider their low-dimensional approximations named integral\nBetti values, or signatures that effectively distinguish not only Euclidean,\nbut also spherical and hyperbolic geometric matrices, both from purely random\nmatrices as well as among themselves. To prove this, we analyse the behaviour\nof Betti curves for various geometric matrices -- i.e. distance matrices of\npoints randomly distributed on manifolds of constant sectional curvature,\nconsidering the classical models of curvature 0, 1, -1, given by the Euclidean\nspace, the sphere, and the hyperbolic space. We further investigate the\ndependence of integral Betti signatures on factors including the sample size\nand dimension. This is important for assessment of real-world connectivity\nmatrices, as we show that the standard approach to network construction gives\nrise to (spurious) spherical geometry, with topology dependent on sample\ndimensions. Finally, we use the manifolds of constant curvature as comparison\nmodels to infer curvature underlying real-world datasets coming from\nneuroscience, finance and climate. Their associated topological features\nexhibit a hyperbolic character: the integral Betti signatures associated to\nthese datasets sit in between Euclidean and hyperbolic (of small curvature).\nThe potential confounding ``hyperbologenic effect'' of intrinsic low-rank\nmodular structures is also evaluated through simulations.\n"
    },
    {
        "paper_id": 2406.15508,
        "authors": "Raeid Saqur",
        "title": "What Teaches Robots to Walk, Teaches Them to Trade too -- Regime\n  Adaptive Execution using Informed Data and LLMs",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2405.09747",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Machine learning techniques applied to the problem of financial market\nforecasting struggle with dynamic regime switching, or underlying correlation\nand covariance shifts in true (hidden) market variables. Drawing inspiration\nfrom the success of reinforcement learning in robotics, particularly in agile\nlocomotion adaptation of quadruped robots to unseen terrains, we introduce an\ninnovative approach that leverages world knowledge of pretrained LLMs (aka.\n'privileged information' in robotics) and dynamically adapts them using\nintrinsic, natural market rewards using LLM alignment technique we dub as\n\"Reinforcement Learning from Market Feedback\" (**RLMF**). Strong empirical\nresults demonstrate the efficacy of our method in adapting to regime shifts in\nfinancial markets, a challenge that has long plagued predictive models in this\ndomain. The proposed algorithmic framework outperforms best-performing SOTA LLM\nmodels on the existing (FLARE) benchmark stock-movement (SM) tasks by more than\n15\\% improved accuracy. On the recently proposed NIFTY SM task, our adaptive\npolicy outperforms the SOTA best performing trillion parameter models like\nGPT-4. The paper details the dual-phase, teacher-student architecture and\nimplementation of our model, the empirical results obtained, and an analysis of\nthe role of language embeddings in terms of Information Gain.\n"
    },
    {
        "paper_id": 2406.15576,
        "authors": "Abhishek Arora, Emily Silcock, Leander Heldring, Melissa Dell",
        "title": "Contrastive Entity Coreference and Disambiguation for Historical Texts",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Massive-scale historical document collections are crucial for social science\nresearch. Despite increasing digitization, these documents typically lack\nunique cross-document identifiers for individuals mentioned within the texts,\nas well as individual identifiers from external knowledgebases like\nWikipedia/Wikidata. Existing entity disambiguation methods often fall short in\naccuracy for historical documents, which are replete with individuals not\nremembered in contemporary knowledgebases. This study makes three key\ncontributions to improve cross-document coreference resolution and\ndisambiguation in historical texts: a massive-scale training dataset replete\nwith hard negatives - that sources over 190 million entity pairs from Wikipedia\ncontexts and disambiguation pages - high-quality evaluation data from\nhand-labeled historical newswire articles, and trained models evaluated on this\nhistorical benchmark. We contrastively train bi-encoder models for\ncoreferencing and disambiguating individuals in historical texts, achieving\naccurate, scalable performance that identifies out-of-knowledgebase\nindividuals. Our approach significantly surpasses other entity disambiguation\nmodels on our historical newswire benchmark. Our models also demonstrate\ncompetitive performance on modern entity disambiguation benchmarks,\nparticularly certain news disambiguation datasets.\n"
    },
    {
        "paper_id": 2406.15593,
        "authors": "Brevin Franklin, Emily Silcock, Abhishek Arora, Tom Bryan, Melissa\n  Dell",
        "title": "News Deja Vu: Connecting Past and Present with Semantic Search",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Social scientists and the general public often analyze contemporary events by\ndrawing parallels with the past, a process complicated by the vast, noisy, and\nunstructured nature of historical texts. For example, hundreds of millions of\npage scans from historical newspapers have been noisily transcribed.\nTraditional sparse methods for searching for relevant material in these vast\ncorpora, e.g., with keywords, can be brittle given complex vocabularies and OCR\nnoise. This study introduces News Deja Vu, a novel semantic search tool that\nleverages transformer large language models and a bi-encoder approach to\nidentify historical news articles that are most similar to modern news queries.\nNews Deja Vu first recognizes and masks entities, in order to focus on broader\nparallels rather than the specific named entities being discussed. Then, a\ncontrastively trained, lightweight bi-encoder retrieves historical articles\nthat are most similar semantically to a modern query, illustrating how\nphenomena that might seem unique to the present have varied historical\nprecedents. Aimed at social scientists, the user-friendly News Deja Vu package\nis designed to be accessible for those who lack extensive familiarity with deep\nlearning. It works with large text datasets, and we show how it can be deployed\nto a massive scale corpus of historical, open-source news articles. While human\nexpertise remains important for drawing deeper insights, News Deja Vu provides\na powerful tool for exploring parallels in how people have perceived past and\npresent.\n"
    },
    {
        "paper_id": 2406.15612,
        "authors": "Parisa Davar, Fr\\'ed\\'eric Godin, Jose Garrido",
        "title": "Catastrophic-risk-aware reinforcement learning with\n  extreme-value-theory-based policy gradients",
        "comments": "The Python code to replicate the various numerical experiments of\n  this paper is available at\n  https://github.com/parisadavar/EVT-policy-gradient-RL",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper tackles the problem of mitigating catastrophic risk (which is risk\nwith very low frequency but very high severity) in the context of a sequential\ndecision making process. This problem is particularly challenging due to the\nscarcity of observations in the far tail of the distribution of cumulative\ncosts (negative rewards). A policy gradient algorithm is developed, that we\ncall POTPG. It is based on approximations of the tail risk derived from extreme\nvalue theory. Numerical experiments highlight the out-performance of our method\nover common benchmarks, relying on the empirical distribution. An application\nto financial risk management, more precisely to the dynamic hedging of a\nfinancial option, is presented.\n"
    },
    {
        "paper_id": 2406.15687,
        "authors": "Devin Mounts and Robin M. Cross",
        "title": "Canceled: A New Reliability Incentive for Energy-Only Electricity\n  Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper considers the reliability problem in energy-only markets.\nFollowing widespread blackouts in 2011, Texas introduced a reliability price\nincentive to attract two GW of net additional natural gas-generating capacity.\nThe incentive is unusual because energy buyers pay the incentive directly to\nproducers in a real-time spot market. The program has created $13 billion in\ndirect payments to generators annually since 2015 and is now being implemented\nor considered in several major energy markets in the US and abroad. We assess\nthe incentive's impact on the Texas market from three perspectives: First, we\nderive the incentive's equilibrium effect on the electricity price in a\nmonopolistic market from first principles using a standard partial equilibrium\neconomic model. We then empirically test whether the incentive encouraged net\nentry into the market or the generating applicant pool, controlling for market\nand climatic conditions using monthly capacity data. Finally, we look for\ndirect evidence of an incentive response among active traders using real-time\nmarket trading data. The three approaches suggest buyers and producers cancel\nout the incentive, and the price-only program does not encourage new generation\ncapacity to enter the market.\n"
    },
    {
        "paper_id": 2406.15867,
        "authors": "Thomas Cook, Patrick Flaherty",
        "title": "Hedging in Sequential Experiments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Experimentation involves risk. The investigator expends time and money in the\npursuit of data that supports a hypothesis. In the end, the investigator may\nfind that all of these costs were for naught and the data fail to reject the\nnull. Furthermore, the investigator may not be able to test other hypotheses\nwith the same data set in order to avoid false positives due to p-hacking.\nTherefore, there is a need for a mechanism for investigators to hedge the risk\nof financial and statistical bankruptcy in the business of experimentation.\n  In this work, we build on the game-theoretic statistics framework to enable\nan investigator to hedge their bets against the null hypothesis and thus avoid\nruin. First, we describe a method by which the investigator's test martingale\nwealth process can be capitalized by solving for the risk-neutral price. Then,\nwe show that a portfolio that comprises the risky test martingale and a\nrisk-free process is still a test martingale which enables the investigator to\nselect a particular risk-return position using Markowitz portfolio theory.\nFinally, we show that a function that is derivative of the test martingale\nprocess can be constructed and used as a hedging instrument by the investigator\nor as a speculative instrument by a risk-seeking investor who wants to\nparticipate in the potential returns of the uncertain experiment wealth\nprocess. Together, these instruments enable an investigator to hedge the risk\nof ruin and they enable a investigator to efficiently hedge experimental risk.\n"
    },
    {
        "paper_id": 2406.15905,
        "authors": "Emily Quiroga and Michael Tanner",
        "title": "Revealing risk preferences Evidence from Turkeys 2023 Earthquake",
        "comments": "Paper summited to the EAERE 2024 conference",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The study on risk preferences and its potential changes amid natural\ncatastrophes has been subject of recent study, producing contradictory\nfindings. An often proposed explanation specifically distinguishes between the\nopposite effect of realized and unrealized losses on risk preferences.\nMoreover, higher-order risk preferences and its relation to post-disaster\nbehaviors remain unexplored, despite potential theoretical implications. We\naddress these gaps in the literature by conducting experiments with 600\nindividuals post Turkeys 2023 catastrophic earthquake, specifically heavily\naffected individuals who are displaced, those who are not and a control group.\nResults indicate higher risk-taking in heavily affected individuals when\ncompared to unaffected individuals. Our results are specifically driven by\naffected females. We find no pre existing differences in risk preferences\nbetween earthquake and control areas using 2012 data. Within the heavily\naffected group of individuals, higher house damage, our proxy for realized\nlosses, increases risk aversion. Regarding higher-order risk preferences for\nindividuals heavily affected by the earthquake, we find that prudence is\npositively associated with selfprotective behaviors after the earthquake,\nspecifically internal migration and/or displacement. While precautionary\nsavings shows initially no correlation to prudence, a positive association\nemerges when considering that prudence is also related to occupational choices,\nwith individuals with stable incomes and who save being more prudent. Our\nresults contribute insights into how disasters influence risk preferences,\nspecifically aiming to address contradictory findings in the literature, while\npresenting novel evidence on the relationship between prudence and post-natural\ndisaster behaviors.\n"
    },
    {
        "paper_id": 2406.16131,
        "authors": "Peter K. Friz and Jim Gatheral",
        "title": "Computing the SSR",
        "comments": "22 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The skew-stickiness-ratio (SSR), examined in detail by Bergomi in his book,\nis critically important to options traders, especially market makers. We\npresent a model-free expression for the SSR in terms of the characteristic\nfunction. In the diffusion setting, it is well-known that the short-term limit\nof the SSR is 2; a corollary of our results is that this limit is $H+3/2$ where\n$H$ is the Hurst exponent of the volatility process. The general formula for\nthe SSR simplifies and becomes particularly tractable in the affine forward\nvariance case. We explain the qualitative behavior of the SSR with respect to\nthe shape of the forward variance curve, and thus also path-dependence of the\nSSR.\n"
    },
    {
        "paper_id": 2406.16199,
        "authors": "Carlo Bottai and Jacopo Di Iorio and Martina Iori",
        "title": "Reinterpreting Economic Complexity: A co-clustering approach",
        "comments": "19 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Economic growth results from countries' accumulation of organizational and\ntechnological capabilities. The Economic and Product Complexity Indices,\nintroduced as an attempt to measure these capabilities from a country's basket\nof exported products, have become popular to study economic development, the\ngeography of innovation, and industrial policies. Despite this reception, the\ninterpretation of these indicators proved difficult. Although the original\nMethod of Reflections suggested a direct interconnection between country and\nproduct metrics, it has been proved that the Economic and Product Complexity\nIndices result from a spectral clustering algorithm that separately groups\nsimilar countries or similar products, respectively. This recent approach to\neconomic and product complexity conflicts with the original one and treats\nseparately countries and products. However, building on previous\ninterpretations of the indices and the recent evolution in spectral clustering,\nwe show that these indices simultaneously identify two co-clusters of similar\ncountries and products. This viewpoint reconciles the spectral clustering\ninterpretation of the indices with the original Method of Reflections\ninterpretation. By proving the often neglected intimate relationship between\ncountry and product complexity, this approach emphasizes the role of a selected\nset of products in determining economic development while extending the range\nof applications of these indicators in economics.\n"
    },
    {
        "paper_id": 2406.164,
        "authors": "Jinniao Qiu, Antony Ware, Yang Yang",
        "title": "Stochastic Path-Dependent Volatility Models for Price-Storage Dynamics\n  in Natural Gas Markets and Discrete-Time Swing Option Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper is devoted to the price-storage dynamics in natural gas markets. A\nnovel stochastic path-dependent volatility model is introduced with\npath-dependence in both price volatility and storage increments. Model\ncalibrations are conducted for both the price and storage dynamics. Further, we\ndiscuss the pricing problem of discrete-time swing options using the dynamic\nprogramming principle, and a deep learning-based method is proposed for\nnumerical approximations. A numerical algorithm is provided, followed by a\nconvergence analysis result for the deep-learning approach.\n"
    },
    {
        "paper_id": 2406.16505,
        "authors": "Feng Xu, Yan Yin, Xinyu Zhang, Tianyuan Liu, Shengyi Jiang, Zongzhang\n  Zhang",
        "title": "$\\text{Alpha}^2$: Discovering Logical Formulaic Alphas using Deep\n  Reinforcement Learning",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Alphas are pivotal in providing signals for quantitative trading. The\nindustry highly values the discovery of formulaic alphas for their\ninterpretability and ease of analysis, compared with the expressive yet\noverfitting-prone black-box alphas. In this work, we focus on discovering\nformulaic alphas. Prior studies on automatically generating a collection of\nformulaic alphas were mostly based on genetic programming (GP), which is known\nto suffer from the problems of being sensitive to the initial population,\nconverting to local optima, and slow computation speed. Recent efforts\nemploying deep reinforcement learning (DRL) for alpha discovery have not fully\naddressed key practical considerations such as alpha correlations and validity,\nwhich are crucial for their effectiveness. In this work, we propose a novel\nframework for alpha discovery using DRL by formulating the alpha discovery\nprocess as program construction. Our agent, $\\text{Alpha}^2$, assembles an\nalpha program optimized for an evaluation metric. A search algorithm guided by\nDRL navigates through the search space based on value estimates for potential\nalpha outcomes. The evaluation metric encourages both the performance and the\ndiversity of alphas for a better final trading strategy. Our formulation of\nsearching alphas also brings the advantage of pre-calculation dimensional\nanalysis, ensuring the logical soundness of alphas, and pruning the vast search\nspace to a large extent. Empirical experiments on real-world stock markets\ndemonstrates $\\text{Alpha}^2$'s capability to identify a diverse set of logical\nand effective alphas, which significantly improves the performance of the final\ntrading strategy. The code of our method is available at\nhttps://github.com/x35f/alpha2.\n"
    },
    {
        "paper_id": 2406.1651,
        "authors": "Magnus Lundgren",
        "title": "Large Language Models in Student Assessment: Comparing ChatGPT and Human\n  Graders",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study investigates the efficacy of large language models (LLMs) as tools\nfor grading master-level student essays. Utilizing a sample of 60 essays in\npolitical science, the study compares the accuracy of grades suggested by the\nGPT-4 model with those awarded by university teachers. Results indicate that\nwhile GPT-4 aligns with human grading standards on mean scores, it exhibits a\nrisk-averse grading pattern and its interrater reliability with human raters is\nlow. Furthermore, modifications in the grading instructions (prompt\nengineering) do not significantly alter AI performance, suggesting that GPT-4\nprimarily assesses generic essay characteristics such as language quality\nrather than adapting to nuanced grading criteria. These findings contribute to\nthe understanding of AI's potential and limitations in higher education,\nhighlighting the need for further development to enhance its adaptability and\nsensitivity to specific educational assessment requirements.\n"
    },
    {
        "paper_id": 2406.16573,
        "authors": "Yu Zhang, Tao Yan, Jianhong Lin, Benjamin Kraner, Claudio Tessone",
        "title": "An Improved Algorithm to Identify More Arbitrage Opportunities on\n  Decentralized Exchanges",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  In decentralized exchanges (DEXs), the arbitrage paths exist abundantly in\nthe form of both arbitrage loops (e.g. the arbitrage path starts from token A\nand back to token A again in the end, A, B,..., A) and non-loops (e.g. the\narbitrage path starts from token A and stops at a different token N, A, B,...,\nN). The Moore-Bellman-Ford algorithm, often coupled with the ``walk to the\nroot\" technique, is commonly employed for detecting arbitrage loops in the\ntoken graph of decentralized exchanges (DEXs) such as Uniswap. However, a\nlimitation of this algorithm is its ability to recognize only a limited number\nof arbitrage loops in each run. Additionally, it cannot specify the starting\ntoken of the detected arbitrage loops, further constraining its effectiveness\nin certain scenarios. Another limitation of this algorithm is its incapacity to\ndetect non-loop arbitrage paths between any specified pairs of tokens. In this\npaper, we develop a new method to solve these problems by combining the line\ngraph and a modified Moore-Bellman-Ford algorithm (MMBF). This method can help\nto find more arbitrage loops by detecting at least one arbitrage loop starting\nfrom any specified tokens in the DEXs and can detect the non-loop arbitrage\npaths between any pair of tokens. Then, we applied our algorithm to Uniswap V2\nand found more arbitrage loops and non-loops indeed compared with applying the\nMoore-Bellman-Ford (MBF) combined algorithm. The found arbitrage profit by our\nmethod in some arbitrage paths can be even as high as one million dollars, far\nlarger than that found by the MBF combined algorithm. Finally, we statistically\ncompare the distribution of arbitrage path lengths and the arbitrage profit\ndetected by both our method and the MBF combined algorithm, and depict how\npotential arbitrage opportunities change with time by our method.\n"
    },
    {
        "paper_id": 2406.16587,
        "authors": "Yu Zhang, Mostafa Chegeni, Claudio Tessone",
        "title": "Velocity, Holding Time and Lifespan of Cryptocurrency in Transactions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  The measurement of the velocity of money is still a significant topic. In\nthis paper, we proposed a method to calculate the velocity of money by\ncombining the holding-time distribution and lifespan distribution. By\nderivation, the velocity of money equals the holding-time distribution's value\nat zero. When we have much holding-time data, this problem can be converted to\na regression problem. After a numeric simulation, we find that the calculating\naccuracy is high even if we used only a small part of the holding time data,\nwhich implies a potential application in measuring the velocity of money in\nreality, such as digital money. We also tested the methods on Cardano and found\nthat the method can also provide a reasonable estimation of velocity in some\ncases.\n"
    },
    {
        "paper_id": 2406.166,
        "authors": "Yu Zhang, Zichen Li, Tao Yan, Qianyu Liu, Nicolo Vallarano, Claudio\n  Tessone",
        "title": "Profit Maximization In Arbitrage Loops",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Cyclic arbitrage chances exist abundantly among decentralized exchanges\n(DEXs), like Uniswap V2. For an arbitrage cycle (loop), researchers or\npractitioners usually choose a specific token, such as Ether as input, and\noptimize their input amount to get the net maximal amount of the specific token\nas arbitrage profit. By considering the tokens' prices from CEXs in this paper,\nthe new arbitrage profit, called monetized arbitrage profit, will be quantified\nas the product of the net number of a specific token we got from the arbitrage\nloop and its corresponding price in CEXs. Based on this concept, we put forward\nthree different strategies to maximize the monetized arbitrage profit for each\narbitrage loop. The first strategy is called the MaxPrice strategy. Under this\nstrategy, arbitrageurs start arbitrage only from the token with the highest CEX\nprice. The second strategy is called the MaxMax strategy. Under this strategy,\nwe calculate the monetized arbitrage profit for each token as input in turn in\nthe arbitrage loop. Then, we pick up the most maximal monetized arbitrage\nprofit among them as the monetized arbitrage profit of the MaxMax strategy. The\nthird one is called the Convex Optimization strategy. By mapping the MaxMax\nstrategy to a convex optimization problem, we proved that the Convex\nOptimization strategy could get more profit in theory than the MaxMax strategy,\nwhich is proved again in a given example. We also proved that if no arbitrage\nprofit exists according to the MaxMax strategy, then the Convex Optimization\nstrategy can not detect any arbitrage profit, either. However, the empirical\ndata analysis denotes that the profitability of the Convex Optimization\nstrategy is almost equal to that of the MaxMax strategy, and the MaxPrice\nstrategy is not reliable in getting the maximal monetized arbitrage profit\ncompared to the MaxMax strategy.\n"
    },
    {
        "paper_id": 2406.17155,
        "authors": "Sung Min Yoon",
        "title": "Optimizing Sparse Mean-Reverting Portfolio",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Mean-reverting behavior of individuals assets is widely known in financial\nmarkets. In fact, we can construct a portfolio that has mean-reverting behavior\nand use it in trading strategies to extract profits. In this paper, we show\nthat we are able to find the optimal weights of stocks to construct portfolio\nthat has the fastest mean-reverting behavior. We further add minimum variance\nand sparsity constraints to the optimization problem and transform into\nSemidefinite Programming (SDP) problem to find the optimal weights. Using the\noptimal weights, we empirically compare the performance of contrarian\nstrategies between non-sparse mean-reverting portfolio and sparse\nmean-reverting portfolio to argue that the latter provides higher returns when\nwe take into account of transaction costs.\n"
    },
    {
        "paper_id": 2406.17308,
        "authors": "Zuzanna Kostecka, Robert \\'Slepaczuk",
        "title": "Improving Realized LGD Approximation: A Novel Framework with XGBoost for\n  Handling Missing Cash-Flow Data",
        "comments": "36 pages, 5 figures, 9 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The scope for the accurate calculation of the Loss Given Default (LGD)\nparameter is comprehensive in terms of financial data. In this research, we aim\nto explore methods for improving the approximation of realized LGD in\nconditions of limited access to the cash-flow data. We enhance the performance\nof the method which relies on the differences between exposure values (delta\noutstanding approach) by employing machine learning (ML) techniques. The\nresearch utilizes the data from the mortgage portfolio of one of the European\ncountries and assumes a close resemblance to similar economic contexts. It\nincorporates non-financial variables and macroeconomic data related to the\nhousing market, improving the accuracy of loss severity approximation. The\nproposed methodology attempts to mitigate the country-specific (related to the\nlocal legal) or portfolio-specific factors in aim to show the general advantage\nof applying ML techniques, rather than case-specific relation. We developed an\nXGBoost model that does not rely on cash-flow data yet enhances the accuracy of\nrealized LGD estimation compared to results obtained with the delta outstanding\napproach. A novel aspect of our work is the detailed exploration of the delta\noutstanding approach and the methodology for addressing conditions of limited\naccess to cash-flow data through machine learning models.\n"
    },
    {
        "paper_id": 2406.17528,
        "authors": "R\\\"udiger Frey and Theresa Traxler",
        "title": "Playing with Fire? A Mean Field Game Analysis of Fire Sales and Systemic\n  Risk under Regulatory Capital Constraints",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the impact of regulatory capital constraints on fire sales and\nfinancial stability in a large banking system using a mean field game model. In\nour model banks adjust their holdings of a risky asset via trading strategies\nwith finite trading rate in order to maximize expected profits. Moreover, a\nbank is liquidated if it violates a stylized regulatory capital constraint. We\nassume that the drift of the asset value is affected by the average change in\nthe position of the banks in the system. This creates strategic interaction\nbetween the trading behavior of banks and thus leads to a game. The equilibria\nof this game are characterized by a system of coupled PDEs. We solve this\nsystem explicitly for a test case without regulatory constraints and\nnumerically for the regulated case. We find that capital constraints can lead\nto a systemic crisis where a substantial proportion of the banking system\ndefaults simultaneously. Moreover, we discuss proposals from the literature on\nmacroprudential regulation. In particular, we show that in our setup a systemic\ncrisis does not arise if the banking system is sufficiently well capitalized or\nif improved mechanisms for the resolution of banks violating the risk capital\nconstraints are in place.\n"
    },
    {
        "paper_id": 2406.18121,
        "authors": "Battulga Gankhuu",
        "title": "The Merton's Default Risk Model for Public Company",
        "comments": "18 pages. arXiv admin note: substantial text overlap with\n  arXiv:2201.06012; text overlap with arXiv:2208.01974",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this paper, we developed the Merton's structural model for public\ncompanies under an assumption that liabilities of the companies are observed.\nUsing Campbell and Shiller's approximation method, we obtain formulas of\nrisk-neutral equity and liability values and default probabilities for the\npublic companies. Also, the paper provides ML estimators of suggested model's\nparameters.\n"
    },
    {
        "paper_id": 2406.18123,
        "authors": "Camille Horvath, C\\'eline Raimbert, Gwena\\\"elle Raton",
        "title": "Is the logistical engagement of stakeholders in short food chains a\n  crucible of alternativity?",
        "comments": "in French language",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In response to the negative environmental, social, and economic externalities\nof the dominant food model, a consensus is emerging on the need to develop\nalternative food systems capable of facilitating a transition to a more\nsustainable model. Among these alternatives, short food supply chains (SFSCs)\nare identified as potential crucibles of alternativity. Defined as distribution\nchannels with a maximum of one intermediary between producer and consumer,\nSFSCs can contribute to the reterritorialization of food flows and the creation\nof relational and geographical proximities among food chain actors. This study\nexamines how logistical engagement translates into the choice of SFSC points of\nsale by consumers and farmers. It evaluates this engagement through the travel\ntimes farmers and consumers are willing to endure to sell or buy at an SFSC\npoint of sale, and the prices they are willing to accept or pay for SFSC\nproducts. A discrete choice experiment conducted in 2022 with 154 farm managers\nand 1022 consumers analyzed preferences regarding types of points of sale,\nsales prices, travel times, and relational proximity. The results show that\nconsumers engaged in SFSCs favour alternative points of sale such as farms and\nassociations, even for longer travel times. Farmers also value these points of\nsale, with logistical engagement more pronounced among those already marketing\nthrough SFSCs. Supermarkets appear less attractive to alternative profiles but\nserve as entry points for new participants in SFSCs. Relational proximity\nbetween farmers and consumers is important, with a preference for direct\nexchanges during sales. This study highlights the importance of actor\nengagement in SFSCs and offers perspectives for developing alternative\nlogistics by valuing relational proximity and using conventional points of sale\nas entry points for new actors in the SFSCs.\n"
    },
    {
        "paper_id": 2406.18174,
        "authors": "Tetsuya Hattori",
        "title": "An elementary proof of representation of submodular function as an\n  supremum of measures on $\\sigma$-algebra with totally ordered generating\n  class",
        "comments": "9 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  We give an alternative proof of a fact that a finite continuous\nnon-decreasing submodular set function on a measurable space can be expressed\nas a supremum of measures dominated by the function, if there exists a class of\nsets which is totally ordered with respect to inclusion and generates the\nsigma-algebra of the space. The proof is elementary in the sense that the\nmeasure attaining the supremum in the claim is constructed by a standard\nextension theorem of measures. As a consequence, a uniquness of the supremum\nattaining measure also follows. A Polish space is an examples of the measurable\nspace which has a class of totally ordered sets that generates the Borel\nsigma-algebra.\n"
    },
    {
        "paper_id": 2406.18194,
        "authors": "Robert van der Veen (1) and Loek Groot (2) ((1) University of\n  Amsterdam, (2) University of Utrecht)",
        "title": "Revisiting the capitalist road to communism: unconditional basic income\n  and the post-labor world",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  The thesis of a capitalist road to communism (van der Veen and Van Parijs,\n1986) asserts that Marx realm of freedom can be reached from within welfare\ncapitalism, skipping socialism, by using a tax-financed unconditional basic\nincome until it is close to disposable income per head, so that the very\ndistinction between paid work and free time is cancelled as a result. We\nrevisit and update this thesis for two reasons: the recent prospect of a\npost-labor society following the automation revolution in technology, and that\nwelfare capitalism has become more inegalitarian and less hospitable to basic\nincome. We use a simple economic model which incorporates an upward adjustment\nof basic income to labor-saving technical change and distinguishes between\ncapital that complements labor and capital that is fully substitutable with\nlabor. A baseline simulation of the model shows the economic feasibility of a\ncapitalist transition to communism. Two versions of a scenario incorporating\ninterplay between technical change and market socialist institutional reforms\nare set out which make the transition politically viable to some extent,\ndepending on the social distribution of power over technology. The most\npromising version is one in which the productivity of labor and automation\ncapital grow at similar rates. We show in which respects it approximates the\nideal of communism. One finding is that communism does not require reaching the\nfinal stage of a post-labor society. We conclude with a reflection on the\nrelevance of our present update for the more immediate future of unconditional\nbasic income.\n"
    },
    {
        "paper_id": 2406.18206,
        "authors": "Kamil Kashif, Robert \\'Slepaczuk",
        "title": "LSTM-ARIMA as a Hybrid Approach in Algorithmic Investment Strategies",
        "comments": "44 pages, 11 figures, 10 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study focuses on building an algorithmic investment strategy employing a\nhybrid approach that combines LSTM and ARIMA models referred to as LSTM-ARIMA.\nThis unique algorithm uses LSTM to produce final predictions but boosts the\nresults of this RNN by adding the residuals obtained from ARIMA predictions\namong other inputs. The algorithm is tested across three equity indices (S&P\n500, FTSE 100, and CAC 40) using daily frequency data from January 2000 to\nAugust 2023. The testing architecture is based on the walk-forward procedure\nfor the hyperparameter tunning phase that uses Random Search and backtesting\nthe algorithms. The selection of the optimal model is determined based on\nadequately selected performance metrics focused on risk-adjusted return\nmeasures. We considered two strategies for each algorithm: Long-Only and\nLong-Short to present the situation of two various groups of investors with\ndifferent investment policy restrictions. For each strategy and equity index,\nwe compute the performance metrics and visualize the equity curve to identify\nthe best strategy with the highest modified information ratio. The findings\nconclude that the LSTM-ARIMA algorithm outperforms all the other algorithms\nacross all the equity indices which confirms the strong potential behind hybrid\nML-TS (machine learning - time series) models in searching for the optimal\nalgorithmic investment strategies.\n"
    },
    {
        "paper_id": 2406.18394,
        "authors": "Hao Shi, Cuicui Luo, Weili Song, Xinting Zhang, Xiang Ao",
        "title": "AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha\n  Factors",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The variability and low signal-to-noise ratio in financial data, combined\nwith the necessity for interpretability, make the alpha factor mining workflow\na crucial component of quantitative investment. Transitioning from early manual\nextraction to genetic programming, the most advanced approach in this domain\ncurrently employs reinforcement learning to mine a set of combination factors\nwith fixed weights. However, the performance of resultant alpha factors\nexhibits inconsistency, and the inflexibility of fixed factor weights proves\ninsufficient in adapting to the dynamic nature of financial markets. To address\nthis issue, this paper proposes a two-stage formulaic alpha generating\nframework AlphaForge, for alpha factor mining and factor combination. This\nframework employs a generative-predictive neural network to generate factors,\nleveraging the robust spatial exploration capabilities inherent in deep\nlearning while concurrently preserving diversity. The combination model within\nthe framework incorporates the temporal performance of factors for selection\nand dynamically adjusts the weights assigned to each component alpha factor.\nExperiments conducted on real-world datasets demonstrate that our proposed\nmodel outperforms contemporary benchmarks in formulaic alpha factor mining.\nFurthermore, our model exhibits a notable enhancement in portfolio returns\nwithin the realm of quantitative investment.\n"
    },
    {
        "paper_id": 2406.1844,
        "authors": "Peng Yifeng, Gao Chen",
        "title": "New intelligent empowerment for digital transformation",
        "comments": "28 pages, 3 figures, 10 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This study proposes an innovative evaluation method based on large language\nmodels (LLMs) specifically designed to measure the digital transformation (DT)\nprocess of enterprises. By analyzing the annual reports of 4407 companies\nlisted on the New York Stock Exchange and Nasdaq from 2005 to 2022, a\ncomprehensive set of DT indicators was constructed. The findings revealed that\nDT significantly improves a company's financial performance, however, different\ndigital technologies exhibit varying effects on financial performance.\nSpecifically, blockchain technology has a relatively limited positive impact on\nfinancial performance. In addition, this study further discovered that DT can\npromote the growth of financial performance by enhancing operational efficiency\nand reducing costs. This study provides a novel DT evaluation tool for the\nacademic community, while also expanding the application scope of generative\nartificial intelligence technology in economic research.\n"
    },
    {
        "paper_id": 2406.18457,
        "authors": "Darcy W. E. Allen, Jason Potts, Julian Waters-Lynch and Max Parasol",
        "title": "Costly Signalling in DAOs",
        "comments": "European DAO Workshop 24",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Decentralised Autonomous Organisations (DAOs) are a new type of digital\norganisation that uses blockchain infrastructure (e.g. smart contracts, tokens)\nto coordinate a group of people around a shared mission. Like all\norganisations, DAOs must attract sources of funding and other resources, and\ndiscover and retain a talented community and workforce. To do this, they must\nsignal their true quality. Yet the characteristics of the environment that DAOs\noperate in (pseudonymous actors, global scale, permissionless entry and exit)\nmakes this difficult. We apply costly signalling theory to explore the\ninformation asymmetry problem in DAOs and some of the strategies (behaviours\nand investments) and institutional solutions (including better signalling\nmechanisms) that have evolved to solve this problem.\n"
    },
    {
        "paper_id": 2406.18936,
        "authors": "Helmut Wasserbacher, Martin Spindler",
        "title": "Credit Ratings: Heterogeneous Effect on Capital Structure",
        "comments": "288 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Why do companies choose particular capital structures? A compelling answer to\nthis question remains elusive despite extensive research. In this article, we\nuse double machine learning to examine the heterogeneous causal effect of\ncredit ratings on leverage. Taking advantage of the flexibility of random\nforests within the double machine learning framework, we model the relationship\nbetween variables associated with leverage and credit ratings without imposing\nstrong assumptions about their functional form. This approach also allows for\ndata-driven variable selection from a large set of individual company\ncharacteristics, supporting valid causal inference. We report three findings:\nFirst, credit ratings causally affect the leverage ratio. Having a rating, as\nopposed to having none, increases leverage by approximately 7 to 9 percentage\npoints, or 30\\% to 40\\% relative to the sample mean leverage. However, this\nresult comes with an important caveat, captured in our second finding: the\neffect is highly heterogeneous and varies depending on the specific rating. For\nAAA and AA ratings, the effect is negative, reducing leverage by about 5\npercentage points. For A and BBB ratings, the effect is approximately zero.\nFrom BB ratings onwards, the effect becomes positive, exceeding 10 percentage\npoints. Third, contrary to what the second finding might imply at first glance,\nthe change from no effect to a positive effect does not occur abruptly at the\nboundary between investment and speculative grade ratings. Rather, it is\ngradual, taking place across the granular rating notches (\"+/-\") within the BBB\nand BB categories.\n"
    },
    {
        "paper_id": 2406.19105,
        "authors": "Matthew J. Schneider, Rufus Rankin, Prabir Burman, Alexander Aue",
        "title": "Benchmarking M6 Competitors: An Analysis of Financial Metrics and\n  Discussion of Incentives",
        "comments": "Forecasting Competitions, M Competitions, Financial Analysis,\n  Investment Management, Hedge Fund, Portfolio Optimization",
        "journal-ref": null,
        "doi": "10.13140/RG.2.2.34990.11847/1",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The M6 Competition assessed the performance of competitors using a ranked\nprobability score and an information ratio (IR). While these metrics do well at\npicking the winners in the competition, crucial questions remain for investors\nwith longer-term incentives. To address these questions, we compare the\ncompetitors' performance to a number of conventional (long-only) and\nalternative indices using standard industry metrics. We apply factor models to\nmeasure the competitors' value-adds above industry-standard benchmarks and find\nthat competitors with more extreme performance are less dependent on the\nbenchmarks. We also uncover that most competitors could not generate\nsignificant out-performance compared to randomly selected long-only and\nlong-short portfolios but did generate out-performance compared to short-only\nportfolios. We further introduce two new strategies by picking the competitors\nwith the best (Superstars) and worst (Superlosers) recent performance and show\nthat it is challenging to identify skill amongst investment managers. We also\ndiscuss the incentives of winning the competition compared to professional\ninvestors, where investors wish to maximize fees over an extended period of\ntime.\n"
    },
    {
        "paper_id": 2406.19222,
        "authors": "L\\'aszl\\'o Csat\\'o and D\\'ora Gr\\'eta Petr\\'oczy",
        "title": "The myth of declining competitive balance in the UEFA Champions League\n  group stage",
        "comments": "11 pages, 1 figure, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  According to previous studies, competitive balance has significantly declined\nin the UEFA Champions League group stage over the recent decades. Our paper\nintroduces six alternative indices for measuring ex ante and ex post\ncompetitive balance in order to explore the robustness of these results. The ex\nante measures are based on Elo ratings, while the ex post measures compare the\ngroup ranking to reasonable benchmarks. We find no evidence of any trend in the\ncompetitive balance of the UEFA Champions League group stage between the\n2003/04 and 2023/24 seasons.\n"
    },
    {
        "paper_id": 2406.19242,
        "authors": "Corrado De Vecchi, Max Nendel, Jan Streicher",
        "title": "Upper Comonotonicity and Risk Aggregation under Dependence Uncertainty",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "abstract": "  In this paper, we study dependence uncertainty and the resulting effects on\ntail risk measures, which play a fundamental role in modern risk management. We\nintroduce the notion of a regular dependence measure, defined on multi-marginal\ncouplings, as a generalization of well-known correlation statistics such as the\nPearson correlation. The first main result states that even an arbitrarily\nsmall positive dependence between losses can result in perfectly correlated\ntails beyond a certain threshold and seemingly complete independence before\nthis threshold. In a second step, we focus on the aggregation of individual\nrisks with known marginal distributions by means of arbitrary nondecreasing\nleft-continuous aggregation functions. In this context, we show that under an\narbitrarily small positive dependence, the tail risk of the aggregate loss\nmight coincide with the one of perfectly correlated losses. A similar result is\nderived for expectiles under mild conditions. In a last step, we discuss our\nresults in the context of credit risk, analyzing the potential effects on the\nvalue at risk for weighted sums of Bernoulli distributed losses.\n"
    },
    {
        "paper_id": 2406.19261,
        "authors": "Jesper Kristensen and David Wender and Carl Anthony",
        "title": "Commodification of Compute",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  The rapid advancements in artificial intelligence, big data analytics, and\ncloud computing have precipitated an unprecedented demand for computational\nresources. However, the current landscape of computational resource allocation\nis characterized by significant inefficiencies, including underutilization and\nprice volatility. This paper addresses these challenges by introducing a novel\nglobal platform for the commodification of compute hours, termed the Global\nCompute Exchange (GCX) (Patent Pending). The GCX leverages blockchain\ntechnology and smart contracts to create a secure, transparent, and efficient\nmarketplace for buying and selling computational power. The GCX is built in a\nlayered fashion, comprising Market, App, Clearing, Risk Management, Exchange\n(Offchain), and Blockchain (Onchain) layers, each ensuring a robust and\nefficient operation. This platform aims to revolutionize the computational\nresource market by fostering a decentralized, efficient, and transparent\necosystem that ensures equitable access to computing power, stimulates\ninnovation, and supports diverse user needs on a global scale. By transforming\ncompute hours into a tradable commodity, the GCX seeks to optimize resource\nutilization, stabilize pricing, and democratize access to computational\nresources. This paper explores the technological infrastructure, market\npotential, and societal impact of the GCX, positioning it as a pioneering\nsolution poised to drive the next wave of innovation in commodities and\ncompute.\n"
    },
    {
        "paper_id": 2406.19399,
        "authors": "Andrew Estornell, Stylianos Loukas Vasileiou, William Yeoh, Daniel\n  Borrajo, Rui Silva",
        "title": "Predicting Customer Goals in Financial Institution Services: A\n  Data-Driven LSTM Approach",
        "comments": "Accepted at the FinPlan 2023 workshop at ICAPS 2023",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In today's competitive financial landscape, understanding and anticipating\ncustomer goals is crucial for institutions to deliver a personalized and\noptimized user experience. This has given rise to the problem of accurately\npredicting customer goals and actions. Focusing on that problem, we use\nhistorical customer traces generated by a realistic simulator and present two\nsimple models for predicting customer goals and future actions -- an LSTM model\nand an LSTM model enhanced with state-space graph embeddings. Our results\ndemonstrate the effectiveness of these models when it comes to predicting\ncustomer goals and actions.\n"
    },
    {
        "paper_id": 2406.19401,
        "authors": "Shubham Singh",
        "title": "An empirical study of market risk factors for Bitcoin",
        "comments": "10 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The study examines whether fama-french equity factors can effectively explain\nthe idiosyncratic risk and return characteristics of Bitcoin. By incorporating\nFama-french factors, the explanatory power of these factors on Bitcoin's excess\nreturns over various moving average periods is tested through applications of\nseveral statistical methods. The analysis aims to determine if equity market\nfactors are significant in explaining and modeling systemic risk in Bitcoin.\n"
    },
    {
        "paper_id": 2406.19402,
        "authors": "Creighton Heaukulani, Abhinav Pandey, Lancelot F. James",
        "title": "Modelling financial volume curves with hierarchical Poisson processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Modeling the trading volume curves of financial instruments throughout the\nday is of key interest in financial trading applications. Predictions of these\nso-called volume profiles guide trade execution strategies, for example, a\ncommon strategy is to trade a desired quantity across many orders in line with\nthe expected volume curve throughout the day so as not to impact the price of\nthe instrument. The volume curves (for each day) are naturally grouped by stock\nand can be further gathered into higher-level groupings, such as by industry.\nIn order to model such admixtures of volume curves, we introduce a hierarchical\nPoisson process model for the intensity functions of admixtures of inhomogenous\nPoisson processes, which represent the trading times of the stock throughout\nthe day. The model is based on the hierarchical Dirichlet process, and an\nefficient Markov Chain Monte Carlo (MCMC) algorithm is derived following the\nslice sampling framework for Bayesian nonparametric mixture models. We\ndemonstrate the method on datasets of different stocks from the Trade and Quote\nrepository maintained by Wharton Research Data Services, including the most\nliquid stock on the NASDAQ stock exchange, Apple, demonstrating the scalability\nof the approach.\n"
    },
    {
        "paper_id": 2406.19403,
        "authors": "Wojciech Wisniewski, Yuri Kalnishkan, David Lindsay, Si\\^an Lindsay",
        "title": "Temporal distribution of clusters of investors and their application in\n  prediction with expert advice",
        "comments": "20 pages, technical report",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Financial organisations such as brokers face a significant challenge in\nservicing the investment needs of thousands of their traders worldwide. This\ntask is further compounded since individual traders will have their own risk\nappetite and investment goals. Traders may look to capture short-term trends in\nthe market which last only seconds to minutes, or they may have longer-term\nviews which last several days to months. To reduce the complexity of this task,\nclient trades can be clustered. By examining such clusters, we would likely\nobserve many traders following common patterns of investment, but how do these\npatterns vary through time? Knowledge regarding the temporal distributions of\nsuch clusters may help financial institutions manage the overall portfolio of\nrisk that accumulates from underlying trader positions. This study contributes\nto the field by demonstrating that the distribution of clusters derived from\nthe real-world trades of 20k Foreign Exchange (FX) traders (from 2015 to 2017)\nis described in accordance with Ewens' Sampling Distribution. Further, we show\nthat the Aggregating Algorithm (AA), an on-line prediction with expert advice\nalgorithm, can be applied to the aforementioned real-world data in order to\nimprove the returns of portfolios of trader risk. However we found that the AA\n'struggles' when presented with too many trader ``experts'', especially when\nthere are many trades with similar overall patterns. To help overcome this\nchallenge, we have applied and compared the use of Statistically Validated\nNetworks (SVN) with a hierarchical clustering approach on a subset of the data,\ndemonstrating that both approaches can be used to significantly improve results\nof the AA in terms of profitability and smoothness of returns.\n"
    },
    {
        "paper_id": 2406.19405,
        "authors": "Andrei Renatovich Batyrov",
        "title": "Electricity Spot Prices Forecasting Using Stochastic Volatility Models",
        "comments": "Master's thesis, 55 pages, 30 figures, 10 tables, 2 algorithms",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  There are several approaches to modeling and forecasting time series as\napplied to prices of commodities and financial assets. One of the approaches is\nto model the price as a non-stationary time series process with heteroscedastic\nvolatility (variance of price). The goal of the research is to generate\nprobabilistic forecasts of day-ahead electricity prices in a spot marker\nemploying stochastic volatility models. A typical stochastic volatility model -\nthat treats the volatility as a latent stochastic process in discrete time - is\nexplored first. Then the research focuses on enriching the baseline model by\nintroducing several exogenous regressors. A better fitting model - as compared\nto the baseline model - is derived as a result of the research. Out-of-sample\nforecasts confirm the applicability and robustness of the enriched model. This\nmodel may be used in financial derivative instruments for hedging the risk\nassociated with electricity trading. Keywords: Electricity spot prices\nforecasting, Stochastic volatility, Exogenous regressors, Autoregression,\nBayesian inference, Stan\n"
    },
    {
        "paper_id": 2406.19406,
        "authors": "Borko Stosic and Tatijana Stosic",
        "title": "Dissecting Multifractal detrended cross-correlation analysis",
        "comments": "14 pages, 3 figures and 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this work we address the question of the Multifractal detrended\ncross-correlation analysis method that has been subject to some controversies\nsince its inception almost two decades ago. To this end we propose several new\noptions to deal with negative cross-covariance among two time series, that may\nserve to construct a more robust view of the multifractal spectrum among the\nseries. We compare these novel options with the proposals already existing in\nthe literature, and we provide fast code in C, R and Python for both new and\nthe already existing proposals. We test different algorithms on synthetic\nseries with an exact analytical solution, as well as on daily price series of\nethanol and sugar in Brazil from 2010 to 2023.\n"
    },
    {
        "paper_id": 2406.19408,
        "authors": "Patrick Geraghty",
        "title": "Modeling a Financial System with Memory via Fractional Calculus and\n  Fractional Brownian Motion",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial markets have long since been modeled using stochastic methods such\nas Brownian motion, and more recently, rough volatility models have been built\nusing fractional Brownian motion. This fractional aspect brings memory into the\nsystem. In this project, we describe and analyze a financial model based on the\nfractional Langevin equation with colored noise generated by fractional\nBrownian motion. Physics-based methods of analysis are used to examine the\nphase behavior and dispersion relations of the system upon varying input\nparameters. A type of anomalous marginal glass phase is potentially seen in\nsome regions, which motivates further exploration of this model and expanded\nuse of phase behavior and dispersion relation methods to analyze financial\nmodels.\n"
    },
    {
        "paper_id": 2406.19412,
        "authors": "Dennis Schroers",
        "title": "Dynamically Consistent Analysis of Realized Covariations in Term\n  Structure Models",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2401.16286",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we show how to analyze the covariation of bond prices\nnonparametrically and robustly, staying consistent with a general no-arbitrage\nsetting. This is, in particular, motivated by the problem of identifying the\nnumber of statistically relevant factors in the bond market under minimal\nconditions. We apply this method in an empirical study which suggests that a\nhigh number of factors is needed to describe the term structure evolution and\nthat the term structure of volatility varies over time.\n"
    },
    {
        "paper_id": 2406.19414,
        "authors": "Parley R Yang and Alexander Y Shestopaloff",
        "title": "Stock Volume Forecasting with Advanced Information by Conditional\n  Variational Auto-Encoder",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We demonstrate the use of Conditional Variational Encoder (CVAE) to improve\nthe forecasts of daily stock volume time series in both short and long term\nforecasting tasks, with the use of advanced information of input variables such\nas rebalancing dates. CVAE generates non-linear time series as out-of-sample\nforecasts, which have better accuracy and closer fit of correlation to the\nactual data, compared to traditional linear models. These generative forecasts\ncan also be used for scenario generation, which aids interpretation. We further\ndiscuss correlations in non-stationary time series and other potential\nextensions from the CVAE forecasts.\n"
    },
    {
        "paper_id": 2406.19424,
        "authors": "Battulga Gankhuu",
        "title": "Gordon Growth Model with Vector Autoregressive Process",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this study, we introduce a Gordon's dividend discount model, based on\nVector Autoregressive Process (VAR). We provide two Propositions, which are\nrelated to generic Gordon growth model and Gordon growth model, which is based\non the VAR process.\n"
    },
    {
        "paper_id": 2406.19938,
        "authors": "Iones Kelanemer Holban",
        "title": "Non-Linearities in International Spillovers of the ECB$^\\prime$s\n  Monetary Policy. The Case of Non-ERM II Countries and Anti-Fragmentation\n  Policy",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  We investigate the presence of sign and size non-linearities in the impact of\nthe European Central Bank$^\\prime$s Anti-Fragmentation Policy on non-ERM II, EU\ncountries. After identifying three orthogonal monetary policy shock using the\nmethod of Fanelli and Marsi [2022], we then select an optimal specification and\nestimate both linear and non linear impulse response functions using local\nprojections (Dufour and Renault [1998], Goncalves et al. [2021]). The choice of\nnon-linear transformations to separate sign and size effects is based on\nCaravello and Martinez-Bruera [Working Paper, 2024]. Lastly we compare the\nlinear model to the non-linear ones using a battery of Wald tests and find\nsignificant evidence of sign non-linearities in the international spillovers of\nECB policy.\n"
    },
    {
        "paper_id": 2406.20027,
        "authors": "Will Hicks",
        "title": "Information Entropy of the Financial Market: Modelling Random Processes\n  Using Open Quantum Systems",
        "comments": "37 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the role of information entropy on the behaviour of random\nprocesses, and how this might take effect in the dynamics of financial market\nprices. We then go on to show how the Open Quantum Systems approach can be used\nas a more flexible alternative to classical methods in terms of modelling the\nentropy gain of a random process. We start by describing an open quantum system\nthat can be used to model the state of a financial market. We then go on to\nshow how to represent an essentially classical diffusion in this framework.\nFinally, we show how by relaxing certain assumptions, one can generate\ninteresting and essentially non-classical results, which are highlighted\nthrough numerical simulations.\n"
    },
    {
        "paper_id": 2406.20045,
        "authors": "David McCune",
        "title": "Single Transferable Vote and Paradoxes of Negative and Positive\n  Involvement",
        "comments": "This will appear, in slightly modified form, in an upcoming issue of\n  Mathematics Magazine",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We analyze a type of voting paradox which we term an involvement paradox, in\nwhich a candidate who loses an election could be made into a winner if more of\nthe candidate's non-supporters participated in the election, or a winner could\nbe made into a loser if more of the candidate's supporters participated. Such\nparadoxical outcomes are possible under the voting method of single\ntransferable vote (STV), which is widely used for political elections\nthroughout the world. We provide a worst-case analysis of involvement paradoxes\nunder STV and show several interesting examples of these paradoxes from\nelections in Scotland.\n"
    },
    {
        "paper_id": 2406.20063,
        "authors": "Bahman Angoshtari, Xiang Yu, Fengyi Yuan",
        "title": "Optimal consumption under loss-averse multiplicative habit-formation\n  preferences",
        "comments": "42 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies a loss-averse version of the multiplicative habit\nformation preference and the corresponding optimal investment and consumption\nstrategies over an infinite horizon. The agent's consumption preference is\ndepicted by a general S-shaped utility function of her consumption-to-habit\nratio. By considering the concave envelope of the S-shaped utility and the\nassociated dual value function, we provide a thorough analysis of the HJB\nequation for the concavified problem via studying a related nonlinear free\nboundary problem. Based on established properties of the solution to this free\nboundary problem, we obtain the optimal consumption and investment policies in\nfeedback form. Some new and technical verification arguments are developed to\ncope with generality of the utility function. The equivalence between the\noriginal problem and the concavified problem readily follows from the structure\nof the feedback policies. We also discuss some quantitative properties of the\noptimal policies under several commonly used S-shaped utilities, complemented\nby illustrative numerical examples and their financial implications.\n"
    },
    {
        "paper_id": 2407.00022,
        "authors": "Martin Pomares Calero",
        "title": "Entropy and Economics",
        "comments": "10 pages, 5 figures, chapter of a book",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Entropy is a very useful concept from physics that tries to explain how a\nsystem behaves from a point of view of the thermodynamics. However, there are\ntwo ways to explain entropy, and it depends on if we are studying a microsystem\nor a microsystem. From a macroscopically point of view, it is important to\ndescribe if the system is a reversible system or not. However, form the\nmicroscopically point of view, the concept of chaos is related to entropy. In\nsuch case, entropy measures the amount of disorder into the system. Otherwise,\nthe idea of connecting at the same time the analysis of the macro and micro\nsystem with the use of entropy it is not very common.\n"
    },
    {
        "paper_id": 2407.00199,
        "authors": "Charlie Pilgrim and Joshua Becker",
        "title": "Communication Reliably Improves Individual But Not Group Accuracy",
        "comments": "36 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Prior research offers mixed evidence on whether and when communication\nimproves belief accuracy for numeric estimates. Experiments on one-to-one\nadvice suggest that communication between peers usually benefits accuracy,\nwhile group experiments indicate that communication networks produce highly\nvariable outcomes. Notably, it is possible for a group's average estimate to\nbecome less accurate even as its individual group members -- on average --\nbecome more accurate. However, the conditions under which communication\nimproves group and/or individual outcomes remain poorly characterised. We\nanalyse an empirically supported model of opinion formation to derive these\nconditions, formally explicating the relationship between group-level effects\nand individual outcomes. We reanalyze previously published experimental data,\nfinding that empirical dynamics are consistent with theoretical expectations.\nWe show that 3 measures completely describe asymptotic opinion dynamics: the\ninitial crowd bias; the degree of influence centralisation; and the correlation\nbetween influence and initial biases. We find analytic expressions for the\nchange in crowd and individual accuracy as a function of the product of these\nthree measures, which we describe as the truth alignment. We show how truth\nalignment can be decomposed into calibration (influence/accuracy correlation),\nand herding (influence/averageness correlation), and how these measures relate\nto changes in accuracy. Overall, we find that individuals can and usually do\nimprove even when groups get worse.\n"
    },
    {
        "paper_id": 2407.00266,
        "authors": "Igor Cialenco and Gabriela Kov\\'a\\v{c}ov\\'a",
        "title": "Vector-valued robust stochastic control",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study a dynamic stochastic control problem subject to Knightian\nuncertainty with multi-objective (vector-valued) criteria. Assuming the\npreferences across expected multi-loss vectors are represented by a given, yet\ngeneral, preorder, we address the model uncertainty by adopting a robust or\nminimax perspective, minimizing expected loss across the worst-case model. For\nloss functions taking real (or scalar) values, there is no ambiguity in\ninterpreting supremum and infimum. In contrast to the scalar case, major\nchallenges for multi-loss control problems include properly defining and\ninterpreting the notions of supremum and infimum, and addressing the\nnon-uniqueness of these suprema and infima. To deal with these, we employ the\nnotion of an ideal point vector-valued supremum for the robust part of the\nproblem, while we view the control part as a multi-objective (or vector)\noptimization problem. Using a set-valued framework, we derive both a weak and\nstrong version of the dynamic programming principle (DPP) or Bellman equations\nby taking the value function as the collection of all worst expected losses\nacross all feasible actions. The weak version of Bellman's principle is proved\nunder minimal assumptions. To establish a stronger version of DPP, we introduce\nthe rectangularity property with respect to a general preorder. We also further\nstudy a particular, but important, case of component-wise partial order of\nvectors, for which we additionally derive DPP under a different set-valued\nnotion for the value function, the so-called upper image of the multi-objective\nproblem. Finally, we provide illustrative examples motivated by financial\nproblems.\n  These results will serve as a foundation for addressing time-inconsistent\nproblems subject to model uncertainty through the lens of a set-valued\nframework, as well as for studying multi-portfolio allocation problems under\nmodel uncertainty.\n"
    },
    {
        "paper_id": 2407.00698,
        "authors": "Sydney Balboni, Grace Ivey, Brett Storoe, John Cisler, Tyge Plater,\n  Caitlyn Grant, Ella Bruce, Benjamin Paulson",
        "title": "NourishNet: Proactive Severity State Forecasting of Food Commodity\n  Prices for Global Warning Systems",
        "comments": "MICS 2024 1st Place Paper, MSOE AI-Club Research Group",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Price volatility in global food commodities is a critical signal indicating\npotential disruptions in the food market. Understanding forthcoming changes in\nthese prices is essential for bolstering food security, particularly for\nnations at risk. The Food and Agriculture Organization of the United Nations\n(FAO) previously developed sophisticated statistical frameworks for the\nproactive prediction of food commodity prices, aiding in the creation of global\nearly warning systems. These frameworks utilize food security indicators to\nproduce accurate forecasts, thereby facilitating preparations against potential\nfood shortages. Our research builds on these foundations by integrating robust\nprice security indicators with cutting-edge deep learning (DL) methodologies to\nreveal complex interdependencies. DL techniques examine intricate dynamics\namong diverse factors affecting food prices. Through sophisticated time-series\nforecasting models coupled with a classification model, our approach enhances\nexisting models to better support communities worldwide in advancing their food\nsecurity initiatives.\n"
    },
    {
        "paper_id": 2407.00751,
        "authors": "Bertrand Kian Hassani, Yacoub Bahini",
        "title": "Crosswashing in Sustainable Investing: Unveiling Strategic Practices\n  Impacting ESG Scores",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper introduces and defines a novel concept in sustainable investing,\ntermed crosswashing, and explore its impact on ESG (Environmental, Social, and\nGovernance) ratings through quantitative analysis using a Multi-Criteria\nDecision Making (MCDM) model. The study emphasises that this specific form of\ngreenwashing is not currently considered in existing ESG assessments,\npotentially leading to an inflated perception of corporate ethical practices.\nUnlike traditional greenwashing, crosswashing involves companies strategically\ninvesting in sustainable activities to boost Environmental, Social, and\nGovernance (ESG) scores while preserving nonsustainable core operations. By\nunveiling the nuances of crosswashing, the research contributes to a more\nnuanced understanding of sustainable investing, offering insights for improved\nevaluation and regulation of corporate environmental and ethical\nresponsibilities.\n"
    },
    {
        "paper_id": 2407.00813,
        "authors": "Qi Deng, Zhong-guo Zhou",
        "title": "Liquidity Jump, Liquidity Diffusion, and Portfolio of Assets with\n  Extreme Liquidity",
        "comments": "50 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We model a portfolio of crypto assets that does not respond well to\nmultivariate autoregressive models because of discontinuity in conditional\ncovariance matrix and posterior covariance matrix caused by extreme liquidity.\nWe adjust asset-level return and volatility with liquidity to reduce such\ndiscontinuity, and restore the effectiveness of a set of liquidity-adjusted\nVECM-DCC/ADCC-BL models at extreme liquidity. We establish two distinctive yet\ncomplementary portfolio liquidity measures: portfolio liquidity jump that\nquantifies the effect of liquidity adjustment in forecasting the conditional\ncovariance matrix, and portfolio liquidity diffusion that quantifies the effect\nof liquidity adjustment in estimating the posterior covariance matrix.\n"
    },
    {
        "paper_id": 2407.00887,
        "authors": "Cristiano Arbex Valle",
        "title": "Portfolio optimisation: bridging the gap between theory and practice",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Portfolio optimisation is widely acknowledged for its significance in\ninvestment decision-making. Yet, existing methodologies face several\nlimitations, among them converting optimal theoretical portfolios into real\ninvestment is not always straightforward. Several classes of exogenous\n(real-world) constraints have been proposed in literature with the intent of\nreducing the gap between theory and practice, which have worked to an extent.\n  In this paper, we propose an optimisation-based framework which attempts to\nfurther reduce this gap. We have the explicit intention of producing portfolios\nthat can be immediately converted into financial holdings. Our proposed\nframework is generic in the sense that it can be used in conjunction with any\nportfolio selection model, and consists of splitting the portfolio selection\nproblem into two-stages. The main motivation behind this approach is in\nenabling automated investing with minimal human intervention, and thus the\nframework was built in such a way that real-world market features can be\nincorporated with relative ease. Among the novel contributions of this paper,\nthis is the first work, to the best of our knowledge, to combine futures\ncontracts and equities in a single framework, and also the first to consider\nborrowing costs in short positions.\n  We present extensive computational results to illustrate the applicability of\nour approach and to evaluate its overall quality. Among these experiments, we\nobserved that alternatives from literature are susceptible to numerical errors,\nwhereas our approach effectively mitigates this issue.\n"
    },
    {
        "paper_id": 2407.01057,
        "authors": "Ennio Bilancini, Leonardo Boncinelli, and Eugenio Vicario",
        "title": "AI-powered Chatbots: Effective Communication Styles for Sustainable\n  Development Goals",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This paper presents an analysis of two pre-registered experimental studies\nexamining the impact of `Motivational Interviewing' and `Directing Style' on\ndiscussions about Sustainable Development Goals. To evaluate the effectiveness\nof these communication styles in enhancing awareness and motivating action\ntoward the Sustainable Development Goals, we measured the engagement levels of\nparticipants, along with their self-reported interest and learning outcomes.\nOur results indicate that `Motivational Interviewing' is more effective than\n`Directing Style' for engagement and interest, while no appreciable difference\nis found on learning.\n"
    },
    {
        "paper_id": 2407.01364,
        "authors": "Thomas Cherico Wanger, Estelle Raveloaritiana, Siyan Zeng, Haixiu Gao,\n  Xueqing He, Yiwen Shao, Panlong Wu, Kris A.G. Wyckhuys, Wenwu Zhou, Yi Zou,\n  Zengrong Zhu, Ling Li, Haiyan Cen, Yunhui Liu, Shenggen Fan",
        "title": "Co-benefits of Agricultural Diversification and Technology for Food and\n  Nutrition Security in China",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  China is the leading crop producer and has successfully implemented\nsustainable development programs related to agriculture. Sustainable\nagriculture has been promoted to achieve national food security targets such as\nfood self-sufficiency through the well-facilitated farmland construction (WFFC)\napproach. The WFFC is introduced in Chinas current national 10-year plan to\nconsolidate farmlands into large and simplified production areas to maximise\nautomation, and improve soil fertility and productivity. However, research\nsuggests that diversified and smaller farms faciliate ecosystem services, can\nimprove yield resilience, defuse human health threats, and increase farm\nprofitability. Currently, WFFC has not considered ecological farmland\nimprovements and it may miss long-term environmental benefits including\necosystem service preservation conducive to yields. Moreover, the nutritional\nstatus in China has changed in recent decades with undernutrition being\ndramatically reduced, but the prevalence of overweight, obesity, and chronic\ndiseases being increased. While a strategic choice and management of crop and\nlivestock species can improve nutrition, the environmental and production\nbenefits of agricultural diversification are currently not well interlinked\nwith Chinas food and nutrition security discussions. Lastly, the role of\nagricultural technology for socioeconomic benefits and the link with\ndiversified agricultural production may provide vast benefits for food\nsecurity. Here, we focus on the opportunities and co-benefits of agricultural\ndiversification and technology innovations to advance food and nutrition\nsecurity in China through ecosystem service and yield benefits. Our applied\nfive-point research agenda can provide evidence-based opportunities to support\nChina in reaching its ambitious food security targets through agricultural\ndiversification with global ramifications.\n"
    },
    {
        "paper_id": 2407.01532,
        "authors": "Amrutha Muralidhar and Muralidhar Lakkanna",
        "title": "Regulating Cryptocurrency and Decentralized Finance for an Inclusive\n  Economy",
        "comments": "5 pages, 1 figure, Presented (Best Paper) in International Conference\n  on Flourishing Through Societal Change 2023, 2nd Dec 2023, CSP IISc,\n  Bangalore, India",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The evolution of cryptocurrency and decentralized finance (DeFi) marks a\nsignificant shift in the financial landscape, making it more accessible,\ninclusive, and participative for various societal groups. However, this\ntransition from traditional financial institutions to DeFi demands a meticulous\npolicy framework that strikes a balance between innovation and safeguarding\nconsumer interests, security, and regulatory compliance. In this script we\nexplore the imperative need for regulatory frameworks overseeing\ncryptocurrencies and DeFi, aiming to leverage their potential for inclusive\neconomic advancement. It underscores the prevalent challenges within\nconventional financial systems, juxtaposing them with the transformative\npotential offered by these emergent financial paradigms. By highlighting the\nrole of robust regulations, we examine their capacity to ensure user security,\nfortify market resilience, and spur innovative strides. We aim to proffer\nviable strategies for formulating regulatory structures that harmonize the twin\nobjectives of fostering innovation and upholding fairness within financial\necosystems.\n"
    },
    {
        "paper_id": 2407.01533,
        "authors": "Darul Wiyono, Rinaldi Tanjung, Hedi Setiadi, Sri Marini, Yayan\n  Sugiarto",
        "title": "Organizational transformation: The impact of servant leadership on work\n  ethic culture with burnout as a mediating factor in the hospitality industry",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Orientation: The study explores the connections among servant leadership,\nburnout, and work ethic culture in organizations. It aims to provide a detailed\nunderstanding of how servant leadership influences work ethic culture,\nespecially by considering the role of burnout. Research Purpose: This study\naims to understand how servant leadership influences work ethic culture and\nexplore the mediating role of burnout in this relationship. Motivation for the\nStudy: This study wants to fill gaps in our understanding of how servant\nleadership, burnout, and work ethic culture are connected. It seeks to add\nuseful insights to what we already know from previous research. Research\nApproach/Design and Method: The study, using surveys and statistics, examines\nthe links between servant leadership, burnout, and work ethic culture in 113\nhotels in Bandung, Indonesia, with 339 participants. A 183-sample, chosen with\na 0.05 margin of error, underwent SEM-PLS analysis using SmartPLS 3.0. Main\nFindings: The key findings underscore that servant leadership exerts a positive\ninfluence on work ethic culture, and burnout plays a pivotal mediating role in\nthis dynamic. The results shed light on the intricate dynamics shaping\norganizational cultures. Practical/Managerial Implications: The findings aid\norganizations in forming supportive leadership policies, promoting employee\nwell-being, and fostering ethical work culture. Managers can apply these\ninsights to enhance leadership practices and reduce burnout impact.\nContribution/Value-Add: This study clarifies the connection between servant\nleadership, burnout, and work ethic culture. The findings offer insights for\nfuture research and practical actions in organizational leadership.\n"
    },
    {
        "paper_id": 2407.01539,
        "authors": "Bo Li",
        "title": "Household Leverage Cycle Around the Great Recession",
        "comments": "76 pages, 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:2403.04104",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper provides the first causal evidence that credit supply expansion\ncaused the 1999-2010 U.S. business cycle mainly through the channel of\nhousehold leverage (debt-to-income ratio). Specifically, induced by net export\ngrowth, credit expansion in private-label mortgages, rather than\ngovernment-sponsored enterprise mortgages, causes a much stronger boom and bust\ncycle in household leverage in the high net-export-growth areas. In addition,\nsuch a stronger household leverage cycle creates a stronger boom and bust cycle\nin the local economy, including housing prices, residential construction\ninvestment, and house-related employment. Thus, our results are consistent with\nthe credit-driven household demand channel (Mian and Sufi, 2018). Further, we\nshow multiple pieces of evidence against the corporate channel, which is\nemphasized by other business cycle theories (hypotheses).\n"
    },
    {
        "paper_id": 2407.01542,
        "authors": "Eckhard Platen",
        "title": "Benchmark-Neutral Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The paper introduces benchmark-neutral pricing and hedging for long-term\ncontingent claims. It employs the growth optimal portfolio of the stocks as\nnumeraire and the new benchmark-neutral pricing measure for pricing. For a\nrealistic parsimonious model, this pricing measure turns out to be an\nequivalent probability measure, which is not the case for the risk-neutral\npricing measure. Many risk-neutral prices of long-term contracts are more\nexpensive than necessary. Benchmark-neutral pricing identifies the minimal\npossible prices of contingent claims, which is illustrated with remarkable\naccuracy for a long-term zero-coupon bond.\n"
    },
    {
        "paper_id": 2407.01545,
        "authors": "Jo-An Occhipinti, William Hynes, Ante Prodan, Harris A. Eyre, Roy\n  Green, Sharan Burrow, Marcel Tanner, John Buchanan, Goran Ujdur, Frederic\n  Destrebecq, Christine Song, Steven Carnevale, Ian B. Hickie, Mark Heffernan",
        "title": "In the Shadow of Smith`s Invisible Hand: Risks to Economic Stability and\n  Social Wellbeing in the Age of Intelligence",
        "comments": "10 pages, 5 figures, 1 table, an Appendix",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Work is fundamental to societal prosperity and mental health, providing\nfinancial security, identity, purpose, and social integration. The emergence of\ngenerative artificial intelligence (AI) has catalysed debate on job\ndisplacement. Some argue that many new jobs and industries will emerge to\noffset the displacement, while others foresee a widespread decoupling of\neconomic productivity from human input threatening jobs on an unprecedented\nscale. This study explores the conditions under which both may be true and\nexamines the potential for a self-reinforcing cycle of recessionary pressures\nthat would necessitate sustained government intervention to maintain job\nsecurity and economic stability. A system dynamics model was developed to\nundertake ex ante analysis of the effect of AI-capital deepening on labour\nunderutilisation and demand in the economy. Results indicate that even a\nmoderate increase in the AI-capital-to-labour ratio could increase labour\nunderutilisation to double its current level, decrease per capita disposable\nincome by 26% (95% interval, 20.6% - 31.8%), and decrease the consumption index\nby 21% (95% interval, 13.6% - 28.3%) by mid-2050. To prevent a reduction in per\ncapita disposable income due to the estimated increase in underutilization, at\nleast a 10.8-fold increase in the new job creation rate would be necessary.\nResults demonstrate the feasibility of an AI-capital- to-labour ratio threshold\nbeyond which even high rates of new job creation cannot prevent declines in\nconsumption. The precise threshold will vary across economies, emphasizing the\nurgent need for empirical research tailored to specific contexts. This study\nunderscores the need for governments, civic organisations, and business to work\ntogether to ensure a smooth transition to an AI- dominated economy to safeguard\nthe Mental Wealth of nations.\n"
    },
    {
        "paper_id": 2407.0155,
        "authors": "Maysam Khodayari Gharanchaei, Prabhu Prasad Panda, Xilin Chen",
        "title": "Quantitative Investment Diversification Strategies via Various Risk\n  Models",
        "comments": null,
        "journal-ref": "Journal of Advancements in Applied Business Research, June 2024",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper focuses on the developing of high-dimensional risk models to\nconstruct portfolios of securities in the US stock exchange. Investors seek to\ngain the highest profits and lowest risk in capital markets. We have developed\nvarious risk models and for each model different investment strategies are\ntested. Out of sample tests are performed on a long-term horizon from 1970\nuntil 2023.\n"
    },
    {
        "paper_id": 2407.01555,
        "authors": "Trinath Sai Subhash Reddy Pittala, Uma Maheswara R Meleti, Hemanth\n  Vasireddy",
        "title": "Unveiling Patterns in European Airbnb Prices: A Comprehensive Analytical\n  Study Using Machine Learning Techniques",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the burgeoning market of short-term rentals, understanding pricing\ndynamics is crucial for a range of stake-holders. This study delves into the\nfactors influencing Airbnb pricing in major European cities, employing a\ncomprehensive dataset sourced from Kaggle. We utilize advanced regression\ntechniques, including linear, polynomial, and random forest models, to analyze\na diverse array of determinants, such as location characteristics, property\ntypes, and host-related factors. Our findings reveal nuanced insights into the\nvariables most significantly impacting pricing, highlighting the varying roles\nof geographical, structural, and host-specific attributes. This research not\nonly sheds light on the complex pricing landscape of Airbnb accommodations in\nEurope but also offers valuable implications for hosts seeking to optimize\npricing strategies and for travelers aiming to understand pricing trends.\nFurthermore, the study contributes to the broader discourse on pricing\nmechanisms in the shared economy, suggesting avenues for future research in\nthis rapidly evolving sector.\n"
    },
    {
        "paper_id": 2407.01564,
        "authors": "Ran Yan and Minda Ma",
        "title": "Decarbonization analysis on residential end uses in the emerging\n  economies",
        "comments": "7 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:2306.13858",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study explores the historical emission patterns and decarbonization\nefforts of China and India, the largest emerging emitters in residential\nbuilding operations. Using a novel carbon intensity model and structural\ndecomposition approach, it assesses the operational decarbonization progress\nover the past two decades. Results show significant decarbonization, with China\nand India collectively reducing 1498.3 and 399.7 MtCO2, respectively.\nElectrification notably contributed to decarbonizing space cooling and\nappliances in both countries.\n"
    },
    {
        "paper_id": 2407.01566,
        "authors": "Fran\\c{c}ois Bachoc, Tommaso Cesari, Roberto Colomboni",
        "title": "A Contextual Online Learning Theory of Brokerage",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the role of contextual information in the online learning problem of\nbrokerage between traders. At each round, two traders arrive with secret\nvaluations about an asset they wish to trade. The broker suggests a trading\nprice based on contextual data about the asset. Then, the traders decide to buy\nor sell depending on whether their valuations are higher or lower than the\nbrokerage price.\n  We assume the market value of traded assets is an unknown linear function of\na $d$-dimensional vector representing the contextual information available to\nthe broker. Additionally, we model traders' valuations as independent bounded\nzero-mean perturbations of the asset's market value, allowing for potentially\ndifferent unknown distributions across traders and time steps. Consistently\nwith the existing online learning literature, we evaluate the performance of a\nlearning algorithm with the regret with respect to the gain from trade. If the\nnoise distributions admit densities bounded by some constant $L$, then, for any\ntime horizon $T$:\n  - If the agents' valuations are revealed after each interaction, we provide\nan algorithm achieving $O ( L d \\ln T )$ regret, and show a corresponding\nmatching lower bound of $\\Omega( Ld \\ln T )$.\n  - If only their willingness to sell or buy at the proposed price is revealed\nafter each interaction, we provide an algorithm achieving $O(\\sqrt{LdT \\ln T\n})$ regret, and show that this rate is optimal (up to logarithmic factors), via\na lower bound of $\\Omega(\\sqrt{LdT})$.\n  To complete the picture, we show that if the bounded density assumption is\nlifted, then the problem becomes unlearnable, even with full feedback.\n"
    },
    {
        "paper_id": 2407.01572,
        "authors": "Jaydip Sen, Hetvi Waghela, Sneha Rakshit",
        "title": "Exploring Sectoral Profitability in the Indian Stock Market Using Deep\n  Learning",
        "comments": "This is the pre-print of the paper that has been accepted for\n  publication in the Inderscience Journal \"International Journal of Business\n  Forecasting and Marketing Intelligence\". The paper is 35 pages long, and it\n  contains 37 figures and 20 tables. This is, however, not the final published\n  version",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper explores using a deep learning Long Short-Term Memory (LSTM) model\nfor accurate stock price prediction and its implications for portfolio design.\nDespite the efficient market hypothesis suggesting that predicting stock prices\nis impossible, recent research has shown the potential of advanced algorithms\nand predictive models. The study builds upon existing literature on stock price\nprediction methods, emphasizing the shift toward machine learning and deep\nlearning approaches. Using historical stock prices of 180 stocks across 18\nsectors listed on the NSE, India, the LSTM model predicts future prices. These\npredictions guide buy/sell decisions for each stock and analyze sector\nprofitability. The study's main contributions are threefold: introducing an\noptimized LSTM model for robust portfolio design, utilizing LSTM predictions\nfor buy/sell transactions, and insights into sector profitability and\nvolatility. Results demonstrate the efficacy of the LSTM model in accurately\npredicting stock prices and informing investment decisions. By comparing sector\nprofitability and prediction accuracy, the work provides valuable insights into\nthe dynamics of the current financial markets in India.\n"
    },
    {
        "paper_id": 2407.01577,
        "authors": "Xi Cheng, Jinghao Zhang, Yunan Zeng, Wenfang Xue",
        "title": "MOT: A Mixture of Actors Reinforcement Learning Method by Optimal\n  Transport for Algorithmic Trading",
        "comments": "13 pages, 5 figures, PAKDD2024 accepted",
        "journal-ref": null,
        "doi": "10.1007/978-981-97-2238-9_3",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Algorithmic trading refers to executing buy and sell orders for specific\nassets based on automatically identified trading opportunities. Strategies\nbased on reinforcement learning (RL) have demonstrated remarkable capabilities\nin addressing algorithmic trading problems. However, the trading patterns\ndiffer among market conditions due to shifted distribution data. Ignoring\nmultiple patterns in the data will undermine the performance of RL. In this\npaper, we propose MOT,which designs multiple actors with disentangled\nrepresentation learning to model the different patterns of the market.\nFurthermore, we incorporate the Optimal Transport (OT) algorithm to allocate\nsamples to the appropriate actor by introducing a regularization loss term.\nAdditionally, we propose Pretrain Module to facilitate imitation learning by\naligning the outputs of actors with expert strategy and better balance the\nexploration and exploitation of RL. Experimental results on real futures market\ndata demonstrate that MOT exhibits excellent profit capabilities while\nbalancing risks. Ablation studies validate the effectiveness of the components\nof MOT.\n"
    },
    {
        "paper_id": 2407.01818,
        "authors": "Paolo Barucca and Flaviano Morone",
        "title": "Predicting public market behavior from private equity deals",
        "comments": "21 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We process private equity transactions to predict public market behavior with\na logit model. Specifically, we estimate our model to predict quarterly returns\nfor both the broad market and for individual sectors. Our hypothesis is that\nprivate equity investments (in aggregate) carry predictive signal about\npublicly traded securities. The key source of such predictive signal is the\nfact that, during their diligence process, private equity fund managers are\nprivy to valuable company information that may not yet be reflected in the\npublic markets at the time of their investment. Thus, we posit that we can\ndiscover investors' collective near-term insight via detailed analysis of the\ntiming and nature of the deals they execute. We evaluate the accuracy of the\nestimated model by applying it to test data where we know the correct output\nvalue. Remarkably, our model performs consistently better than a null model\nsimply based on return statistics, while showing a predictive accuracy of up to\n70% in sectors such as Consumer Services, Communications, and Non Energy\nMinerals.\n"
    },
    {
        "paper_id": 2407.01953,
        "authors": "Yupeng Cao, Zhiyuan Yao, Zhi Chen, Zhiyang Deng",
        "title": "CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models\n  using Data Fusion in Financial Applications",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The integration of Large Language Models (LLMs) into financial analysis has\ngarnered significant attention in the NLP community. This paper presents our\nsolution to IJCAI-2024 FinLLM challenge, investigating the capabilities of LLMs\nwithin three critical areas of financial tasks: financial classification,\nfinancial text summarization, and single stock trading. We adopted Llama3-8B\nand Mistral-7B as base models, fine-tuning them through Parameter Efficient\nFine-Tuning (PEFT) and Low-Rank Adaptation (LoRA) approaches. To enhance model\nperformance, we combine datasets from task 1 and task 2 for data fusion. Our\napproach aims to tackle these diverse tasks in a comprehensive and integrated\nmanner, showcasing LLMs' capacity to address diverse and complex financial\ntasks with improved accuracy and decision-making capabilities.\n"
    },
    {
        "paper_id": 2407.02003,
        "authors": "Emiliano Toni, Pablo Paniagua, and Patricio \\'Ordenes",
        "title": "Policy Changes and Growth Slowdown: Assessing the Lost Decade of the\n  Latin American Miracle",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  The Latin American region has suffered an economic slowdown since the end of\nthe commodities boom. Within this context, Chile was the poster child of\neconomic growth and development up until 2014. Since then, Chile has also been\ntrapped in a decade of slow economic growth. Chile's sudden slowdown and recent\ngrowth path divergence have posed a puzzle for economic growth and development\neconomics. This paper examines this slowdown from an empirical perspective and\ndetermines how much can be attributed to internal and external causes. Using a\nsynthetic control approach and a structural time series Bayesian estimation,\nour findings suggest that at least two-thirds of the Chilean slowdown is\nattributable to internal causes driven by a policy regime change in 2014, with\nexternal factors playing a secondary role. The net effect of this set of\ninternal reforms resulted in a nearly 10% reduction in real GDP per capita over\nfive years and led to a 1.8% decline in average GDP growth rates from 2015 to\n2019. Our results are consistent with the literature that establishes that\nexternal shocks can explain only a small fraction of the poor economic\nperformance of developing countries, suggesting that internal factors are the\nprimary source of subpar performance. This research sheds light on the\npotential effects of policy regime shifts in economic growth, thus providing\nvaluable insights for development economics and, more specifically, emerging\neconomies.\n"
    },
    {
        "paper_id": 2407.02236,
        "authors": "Anishka Chauhan, Pratham Mayur, Yeshwanth Sai Gokarakonda, Pooriya\n  Jamie and Naman Mehrotra",
        "title": "Indian Stock Market Prediction using Augmented Financial Intelligence ML",
        "comments": "Keywords: Machine Learning, Artificial Intelligence, LSTM, GRU, ARMA,\n  CNN, NLP, ANN, SVM, BSE, NIFTY, MAE, MSE, BiLSTM . Published in SSRN Journal",
        "journal-ref": null,
        "doi": "10.2139/ssrn.4697853",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper presents price prediction models using Machine Learning algorithms\naugmented with Superforecasters predictions, aimed at enhancing investment\ndecisions. Five Machine Learning models are built, including Bidirectional\nLSTM, ARIMA, a combination of CNN and LSTM, GRU, and a model built using LSTM\nand GRU algorithms. The models are evaluated using the Mean Absolute Error to\ndetermine their predictive accuracy. Additionally, the paper suggests\nincorporating human intelligence by identifying Superforecasters and tracking\ntheir predictions to anticipate unpredictable shifts or changes in stock prices\n. The predictions made by these users can further enhance the accuracy of stock\nprice predictions when combined with Machine Learning and Natural Language\nProcessing techniques. Predicting the price of any commodity can be a\nsignificant task but predicting the price of a stock in the stock market deals\nwith much more uncertainty. Recognising the limited knowledge and exposure to\nstocks among certain investors, this paper proposes price prediction models\nusing Machine Learning algorithms. In this work, five Machine learning models\nare built using Bidirectional LSTM, ARIMA, a combination of CNN and LSTM, GRU\nand the last one is built using LSTM and GRU algorithms. Later these models are\nassessed using MAE scores to find which model is predicting with the highest\naccuracy. In addition to this, this paper also suggests the use of human\nintelligence to closely predict the shift in price patterns in the stock market\nThe main goal is to identify Superforecasters and track their predictions to\nanticipate unpredictable shifts or changes in stock prices. By leveraging the\ncombined power of Machine Learning and the Human Intelligence, predictive\naccuracy can be significantly increased.\n"
    },
    {
        "paper_id": 2407.02496,
        "authors": "Mark B. Richardson, Stefan Loesch",
        "title": "DeFi's Concentrated Liquidity From Scratch",
        "comments": "84 pages, 331 equations, 55 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The scope of this article includes the three preeminent descriptions of\nconcentrated liquidity from Bancor (2020 and 2022), and Uniswap (2021), as well\nas three additional descriptions informed by trigonometric analysis of the\nsame. The purpose of this contribution is to organize the seminal and\nderivative forms of this cornerstone DeFi technology, and algebraically and\ngeometrically elaborate these descriptions to achieve an authoritative and\nnear-exhaustive overview of the underlying theory powering the current\nstate-of-the-art in decentralized exchange infrastructure.\n  This material was created for the Token Engineering Academy Study Season\n2024, a cohort-based online program scheduled for April-July 2024. The Study\nSeason offers access to a bachelor-level online learning program, and\ncomplementary live tracks with the most influential practitioners and\nresearchers in the sector - all provided as free, public goods.\n"
    },
    {
        "paper_id": 2407.02536,
        "authors": "Subhankar Ghosh, Jayant Gupta, Arun Sharma, Shuai An, Shashi Shekhar",
        "title": "Reducing False Discoveries in Statistically-Significant\n  Regional-Colocation Mining: A Summary of Results",
        "comments": null,
        "journal-ref": null,
        "doi": "10.4230/LIPIcs.GIScience.2023.3",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Given a set \\emph{S} of spatial feature types, its feature instances, a study\narea, and a neighbor relationship, the goal is to find pairs $<$a region\n($r_{g}$), a subset \\emph{C} of \\emph{S}$>$ such that \\emph{C} is a\nstatistically significant regional-colocation pattern in $r_{g}$. This problem\nis important for applications in various domains including ecology, economics,\nand sociology. The problem is computationally challenging due to the\nexponential number of regional colocation patterns and candidate regions.\nPreviously, we proposed a miner \\cite{10.1145/3557989.3566158} that finds\nstatistically significant regional colocation patterns. However, the numerous\nsimultaneous statistical inferences raise the risk of false discoveries (also\nknown as the multiple comparisons problem) and carry a high computational cost.\nWe propose a novel algorithm, namely, multiple comparisons regional colocation\nminer (MultComp-RCM) which uses a Bonferroni correction. Theoretical analysis,\nexperimental evaluation, and case study results show that the proposed method\nreduces both the false discovery rate and computational cost.\n"
    },
    {
        "paper_id": 2407.02831,
        "authors": "Len Patrick Dominic M. Garces and Yang Shen",
        "title": "Robust optimal investment and consumption strategies with portfolio\n  constraints and stochastic environment",
        "comments": "30 pages, 6 figures (including sub-figures), 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate a continuous-time investment-consumption problem with model\nuncertainty in a general diffusion-based market with random model coefficients.\nWe assume that a power utility investor is ambiguity-averse, with the\npreference to robustness captured by the homothetic multiplier robust\nspecification, and the investor's investment and consumption strategies are\nconstrained to closed convex sets. To solve this constrained robust control\nproblem, we employ the stochastic Hamilton-Jacobi-Bellman-Isaacs equations,\nbackward stochastic differential equations, and bounded mean oscillation\nmartingale theory. Furthermore, we show the investor incurs (non-negative)\nutility loss, i.e. the loss in welfare, if model uncertainty is ignored. When\nthe model coefficients are deterministic, we establish formally the\nrelationship between the investor's robustness preference and the robust\noptimal investment-consumption strategy and the value function, and the impact\nof investment and consumption constraints on the investor's robust optimal\ninvestment-consumption strategy and value function. Extensive numerical\nexperiments highlight the significant impact of ambiguity aversion, consumption\nand investment constraints, on the investor's robust optimal\ninvestment-consumption strategy, utility loss, and value function. Key findings\ninclude: 1) short-selling restriction always reduces the investor's utility\nloss when model uncertainty is ignored; 2) the effect of consumption\nconstraints on utility loss is more delicate and relies on the investor's risk\naversion level.\n"
    },
    {
        "paper_id": 2407.02901,
        "authors": "Nicola F. Zaugg, Lech A. Grzelak",
        "title": "Basket Options with Volatility Skew: Calibrating a Local Volatility\n  Model by Sample Rearrangement",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The pricing of derivatives tied to baskets of assets demands a sophisticated\nframework that aligns with the available market information to capture the\nintricate non-linear dependency structure among the assets. We describe the\ndynamics of the multivariate process of constituents with a copula model and\npropose an efficient method to extract the dependency structure from the\nmarket. The proposed method generates coherent sets of samples of the\nconstituents process through systematic sampling rearrangement. These samples\nare then utilized to calibrate a local volatility model (LVM) of the basket\nprocess, which is used to price basket derivatives. We show that the method is\ncapable of efficiently pricing basket options based on a large number of basket\nconstituents, accomplishing the calibration process within a matter of seconds,\nand achieving near-perfect calibration to the index options of the market.\n"
    },
    {
        "paper_id": 2407.03285,
        "authors": "Zachary Feinstein, Grzegorz Halaj, Andreas Sojmark",
        "title": "The not-so-hidden risks of 'hidden-to-maturity' accounting: on depositor\n  runs and bank resilience",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We build a balance sheet-based model to capture run risk, i.e., a reduced\npotential to raise capital from liquidity buffers under stress, driven by\ndepositor scrutiny and further fueled by fire sales in response to withdrawals.\nThe setup is inspired by the Silicon Valley Bank (SVB) meltdown in March 2023\nand our model may serve as a supervisory analysis tool to monitor build-up of\nbalance sheet vulnerabilities. Specifically, we analyze which characteristics\nof the balance sheet are critical in order for banking system regulators to\nadequately assess run risk and resilience. By bringing a time series of SVB's\nbalance sheet data to our model, we are able to demonstrate how changes in the\nfunding and respective asset composition made SVB prone to run risk, as they\nwere increasingly relying on held-to-maturity, aka hidden-to-maturity,\naccounting standards, masking revaluation losses in securities portfolios.\nFinally, we formulate a tractable optimisation problem to address the\ndesignation of held-to-maturity assets and quantify banks' ability to hold\nthese assets without resorting to remarking. By calibrating this to SVB's\nbalance sheet data, we shed light on the bank's funding risk and implied risk\ntolerance in the years 2020--22 leading up to its collapse.\n"
    },
    {
        "paper_id": 2407.03431,
        "authors": "Marcelo Righi",
        "title": "Optimal hedging with variational preferences under convex risk measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We expose a theoretical hedging optimization framework with variational\npreferences under convex risk measures. We explore a general dual\nrepresentation for the composition between risk measures and utilities. We\nstudy the properties of the optimization problem as a convex and monotone map\nper se. We also derive results for optimality and indifference pricing\nconditions. We also explore particular examples inside our setup.\n"
    },
    {
        "paper_id": 2407.03504,
        "authors": "Michele Fioretti, Junnan He, Jorge Tamayo",
        "title": "Prices and Concentration: A U-shape? Theory and Evidence from Renewables",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  We study firms' strategic interactions when each firm may own multiple\nproduction technologies, each with its own marginal cost and capacity.\nIncreasing industry concentration by reallocating non-efficient capacity to the\nlargest and most efficient firm can decrease market prices as it incentivizes\nthe firm to outcompete its rivals. However, with large reallocations, the\nstandard monotonic relationship between concentration and prices re-emerges as\ncompetition weakens due to the rival's lower capacity. Thus, we demonstrate a\nU-shaped relationship between market prices and industry concentration when\nfirms are diversified. This result does not rely on economies of scale or\nscope. We find consistent evidence from the Colombian wholesale energy market,\nwhere strategic firms are diversified with fossil-fuel and renewable\ntechnologies, exploiting exogenous variation in renewable capacities. Our\nfindings not only apply to the green transition but also to other industries\nand suggest new insights for antitrust policies.\n"
    },
    {
        "paper_id": 2407.03517,
        "authors": "Victor Aguirregabiria, Robert Clark, Hui Wang",
        "title": "The geographic flow of bank funding and access to credit: Branch\n  networks, local synergies and competition",
        "comments": "75 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Geographic dispersion of depositors, borrowers, and banks may prevent funding\nfrom flowing to high loan demand areas, limiting credit access. Using\nbank-county-year level data, we provide evidence of the geographic imbalance of\ndeposits and loans and develop a methodology for investigating the contribution\nto this imbalance of branch networks, market power, and scope economies.\nResults are based on a novel measure of imbalance and estimation of a\nstructural model of bank competition that admits interconnections across\nlocations and between deposit and loan markets. Counterfactual experiments show\nbranch networks and competition contribute importantly to credit flow but\nbenefit more affluent markets.\n"
    },
    {
        "paper_id": 2407.03521,
        "authors": "Igor Sadoune, Marcelin Joanis, Andrea Lodi",
        "title": "Algorithmic Collusion And The Minimum Price Markov Game",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper introduces the Minimum Price Markov Game (MPMG), a dynamic variant\nof the Prisoner's Dilemma. The MPMG serves as a theoretical model and\nreasonable approximation of real-world first-price sealed-bid public auctions\nthat follow the minimum price rule. The goal is to provide researchers and\npractitioners with a framework to study market fairness and regulation in both\ndigitized and non-digitized public procurement processes, amidst growing\nconcerns about algorithmic collusion in online markets. We demonstrate, using\nmulti-agent reinforcement learning-driven artificial agents, that algorithmic\ntacit coordination is difficult to achieve in the MPMG when cooperation is not\nexplicitly engineered. Paradoxically, our results highlight the robustness of\nthe minimum price rule in an auction environment, but also show that it is not\nimpervious to full-scale algorithmic collusion. These findings contribute to\nthe ongoing debates about algorithmic pricing and its implications.\n"
    },
    {
        "paper_id": 2407.03527,
        "authors": "Matthew DeHaven, Hannah Firestone, Chris Webster",
        "title": "Minute-by-Minute: Financial Markets' Reaction to the 2020 U.S. Election",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We find striking correlations between the presidential election outcome\nprobability and major financial indicators, including USD currency pairs, bond\nprices, stock index futures, and a market volatility measure. The correlations\nare consistent with 'risk-on' behavior in markets, a term which describes\ninvestors moving toward riskier asset classes, as the election results became\nclearer. Further, we decompose the market reaction into a 'reduction in\nuncertainty' component and a 'probability of a Democratic party presidency'\ncomponent. This decomposition reveals how markets reacted to the increasing\ncertainty of the outcome as election results came in. Finally, we analyze the\ndiffering market reactions to the presidential election and the Senate\nelection, including data from the unique Georgia runoffs, and demonstrate that\nbond prices were particularly sensitive to the probability of a combined\nDemocratic Senate and Presidency.\n"
    },
    {
        "paper_id": 2407.03595,
        "authors": "Yanqing Yang, Xingcheng Xu, Jinfeng Ge, Yan Xu",
        "title": "Machine Learning for Economic Forecasting: An Application to China's GDP\n  Growth",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper aims to explore the application of machine learning in forecasting\nChinese macroeconomic variables. Specifically, it employs various machine\nlearning models to predict the quarterly real GDP growth of China, and analyzes\nthe factors contributing to the performance differences among these models. Our\nfindings indicate that the average forecast errors of machine learning models\nare generally lower than those of traditional econometric models or expert\nforecasts, particularly in periods of economic stability. However, during\ncertain inflection points, although machine learning models still outperform\ntraditional econometric models, expert forecasts may exhibit greater accuracy\nin some instances due to experts' more comprehensive understanding of the\nmacroeconomic environment and real-time economic variables. In addition to\nmacroeconomic forecasting, this paper employs interpretable machine learning\nmethods to identify the key attributive variables from different machine\nlearning models, aiming to enhance the understanding and evaluation of their\ncontributions to macroeconomic fluctuations.\n"
    },
    {
        "paper_id": 2407.03616,
        "authors": "Jianqing Fan, Yuling Yan, Yuheng Zheng",
        "title": "When can weak latent factors be statistically inferred?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This article establishes a new and comprehensive estimation and inference\ntheory for principal component analysis (PCA) under the weak factor model that\nallow for cross-sectional dependent idiosyncratic components under nearly\nminimal the factor strength relative to the noise level or signal-to-noise\nratio. Our theory is applicable regardless of the relative growth rate between\nthe cross-sectional dimension $N$ and temporal dimension $T$. This more\nrealistic assumption and noticeable result requires completely new technical\ndevice, as the commonly-used leave-one-out trick is no longer applicable to the\ncase with cross-sectional dependence. Another notable advancement of our theory\nis on PCA inference $ - $ for example, under the regime where $N\\asymp T$, we\nshow that the asymptotic normality for the PCA-based estimator holds as long as\nthe signal-to-noise ratio (SNR) grows faster than a polynomial rate of $\\log\nN$. This finding significantly surpasses prior work that required a polynomial\nrate of $N$. Our theory is entirely non-asymptotic, offering finite-sample\ncharacterizations for both the estimation error and the uncertainty level of\nstatistical inference. A notable technical innovation is our closed-form\nfirst-order approximation of PCA-based estimator, which paves the way for\nvarious statistical tests. Furthermore, we apply our theories to design\neasy-to-implement statistics for validating whether given factors fall in the\nlinear spans of unknown latent factors, testing structural breaks in the factor\nloadings for an individual unit, checking whether two units have the same risk\nexposures, and constructing confidence intervals for systematic risks. Our\nempirical studies uncover insightful correlations between our test results and\neconomic cycles.\n"
    },
    {
        "paper_id": 2407.0376,
        "authors": "Yuhui Jin",
        "title": "GraphCNNpred: A stock market indices prediction using a Graph based deep\n  learning system",
        "comments": "10 pages.Version 2",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The application of deep learning techniques for predicting stock market\nprices is a prominent and widely researched topic in the field of data science.\nTo effectively predict market trends, it is essential to utilize a diversified\ndataset. In this paper, we give a graph neural network based convolutional\nneural network (CNN) model, that can be applied on diverse source of data, in\nthe attempt to extract features to predict the trends of indices of\n\\text{S}\\&\\text{P} 500, NASDAQ, DJI, NYSE, and RUSSEL. The experiments show\nthat the associated models improve the performance of prediction in all indices\nover the baseline algorithms by about $4\\% \\text{ to } 15\\%$, in terms of\nF-measure. A trading simulation is generated from predictions and gained a\nSharpe ratio of over 3.\n"
    },
    {
        "paper_id": 2407.03781,
        "authors": "Lucija \\v{Z}igni\\'c, Stjepan Begu\\v{s}i\\'c, and Zvonko Kostanj\\v{c}ar",
        "title": "Block-diagonal idiosyncratic covariance estimation in high-dimensional\n  factor models for financial time series",
        "comments": null,
        "journal-ref": "Journal of Computational Science, Volume 81, 2024, 102348",
        "doi": "10.1016/j.jocs.2024.102348",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Estimation of high-dimensional covariance matrices in latent factor models is\nan important topic in many fields and especially in finance. Since the number\nof financial assets grows while the estimation window length remains of limited\nsize, the often used sample estimator yields noisy estimates which are not even\npositive definite. Under the assumption of latent factor models, the covariance\nmatrix is decomposed into a common low-rank component and a full-rank\nidiosyncratic component. In this paper we focus on the estimation of the\nidiosyncratic component, under the assumption of a grouped structure of the\ntime series, which may arise due to specific factors such as industries, asset\nclasses or countries. We propose a generalized methodology for estimation of\nthe block-diagonal idiosyncratic component by clustering the residual series\nand applying shrinkage to the obtained blocks in order to ensure positive\ndefiniteness. We derive two different estimators based on different clustering\nmethods and test their performance using simulation and historical data. The\nproposed methods are shown to provide reliable estimates and outperform other\nstate-of-the-art estimators based on thresholding methods.\n"
    },
    {
        "paper_id": 2407.0396,
        "authors": "Tahir Choulli, Ella Elazkany, Mich\\`ele Vanmaele",
        "title": "The second-order Esscher martingale densities for continuous-time market\n  models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we introduce the second-order Esscher pricing notion for\ncontinuous-time models. Depending whether the stock price $S$ or its logarithm\nis the main driving noise/shock in the Esscher definition, we obtained two\nclasses of second-order Esscher densities called linear class and exponential\nclass respectively. Using the semimartingale characteristics to parametrize\n$S$, we characterize the second-order Esscher densities (exponential and\nlinear) using pointwise equations. The role of the second order concept is\nhighlighted in many manners and the relationship between the two classes is\nsingled out for the one-dimensional case. Furthermore, when $S$ is a compound\nPoisson model, we show how both classes are related to the\nDelbaen-Haenzendonck's risk-neutral measure. Afterwards, we restrict our model\n$S$ to follow the jump-diffusion model, for simplicity only, and address the\nbounds of the stochastic Esscher pricing intervals. In particular, no matter\nwhat is the Esscher class, we prove that both bounds (upper and lower) are\nsolutions to the same linear backward stochastic differential equation (BSDE\nhereafter for short) but with two different constraints. This shows that BSDEs\nwith constraints appear also in a setting beyond the classical cases of\nconstraints on gain-processes or constraints on portfolios. We prove that our\nresulting constrained BSDEs have solutions in our framework for a large class\nof claims' payoffs including any bounded claim, in contrast to the literature,\nand we single out the monotonic sequence of BSDEs that ``naturally\" approximate\nit as well.\n"
    },
    {
        "paper_id": 2407.04088,
        "authors": "Cristian Chica and Yinglong Guo and Gilad Lerman",
        "title": "Artificial Intelligence and Algorithmic Price Collusion in Two-sided\n  Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Algorithmic price collusion facilitated by artificial intelligence (AI)\nalgorithms raises significant concerns. We examine how AI agents using\nQ-learning engage in tacit collusion in two-sided markets. Our experiments\nreveal that AI-driven platforms achieve higher collusion levels compared to\nBertrand competition. Increased network externalities significantly enhance\ncollusion, suggesting AI algorithms exploit them to maximize profits. Higher\nuser heterogeneity or greater utility from outside options generally reduce\ncollusion, while higher discount rates increase it. Tacit collusion remains\nfeasible even at low discount rates. To mitigate collusive behavior and inform\npotential regulatory measures, we propose incorporating a penalty term in the\nQ-learning algorithm.\n"
    },
    {
        "paper_id": 2407.04227,
        "authors": "Takeshi Fukasawa",
        "title": "Simple method for efficiently solving dynamic models with continuous\n  actions using policy gradient",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study proposes the Value Function-Policy Gradient Iteration-Spectral\n(VF-PGI-Spectral) algorithm, which efficiently solves discrete-time\ninfinite-horizon dynamic models with continuous actions. It combines the\nspectral algorithm to accelerate convergence. The method is applicable not only\nto single-agent dynamic optimization problems, but also to multi-agent dynamic\ngames, which previously proposed methods cannot deal with. Moreover, the\nproposed algorithm is not limited to models with specific functional forms, and\napplies to models with multiple continuous actions. This study shows the\nresults of numerical experiments, showing the effective performance of the\nproposed algorithm.\n"
    },
    {
        "paper_id": 2407.04354,
        "authors": "Johannes Muhle-Karbe, Eyal Neuman, Yonatan Shadmi",
        "title": "Fluid-Limits of Fragmented Limit-Order Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Maglaras, Moallemi, and Zheng (2021) have introduced a flexible queueing\nmodel for fragmented limit-order markets, whose fluid limit remains remarkably\ntractable. In the present study we prove that, in the limit of small and\nfrequent orders, the discrete system indeed converges to the fluid limit, which\nis characterized by a system of coupled nonlinear ODEs with singular\ncoefficients at the origin. Moreover, we establish that the fluid system is\nasymptotically stable for an arbitrary number of limit order books in that,\nover time, it converges to the stationary equilibrium state studied by Maglaras\net al. (2021).\n"
    },
    {
        "paper_id": 2407.045,
        "authors": "Philipp Wirth, Francesca Medda, Thomas Schr\\\"oder",
        "title": "Longitudinal market structure detection using a dynamic\n  modularity-spectral algorithm",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we introduce the Dynamic Modularity-Spectral Algorithm\n(DynMSA), a novel approach to identify clusters of stocks with high\nintra-cluster correlations and low inter-cluster correlations by combining\nRandom Matrix Theory with modularity optimisation and spectral clustering. The\nprimary objective is to uncover hidden market structures and find diversifiers\nbased on return correlations, thereby achieving a more effective risk-reducing\nportfolio allocation. We applied DynMSA to constituents of the S&P 500 and\ncompared the results to sector- and market-based benchmarks. Besides the\nconception of this algorithm, our contributions further include implementing a\nsector-based calibration for modularity optimisation and a correlation-based\ndistance function for spectral clustering. Testing revealed that DynMSA\noutperforms baseline models in intra- and inter-cluster correlation\ndifferences, particularly over medium-term correlation look-backs. It also\nidentifies stable clusters and detects regime changes due to exogenous shocks,\nsuch as the COVID-19 pandemic. Portfolios constructed using our clusters showed\nhigher Sortino and Sharpe ratios, lower downside volatility, reduced maximum\ndrawdown and higher annualised returns compared to an equally weighted market\nbenchmark.\n"
    },
    {
        "paper_id": 2407.0451,
        "authors": "Alexander Barzykin and Robert Boyce and Eyal Neuman",
        "title": "Unwinding Toxic Flow with Partial Information",
        "comments": "52 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We consider a central trading desk which aggregates the inflow of clients'\norders with unobserved toxicity, i.e. persistent adverse directionality. The\ndesk chooses either to internalise the inflow or externalise it to the market\nin a cost effective manner. In this model, externalising the order flow creates\nboth price impact costs and an additional market feedback reaction for the\ninflow of trades. The desk's objective is to maximise the daily trading P&L\nsubject to end of the day inventory penalization. We formulate this setting as\na partially observable stochastic control problem and solve it in two steps.\nFirst, we derive the filtered dynamics of the inventory and toxicity, projected\nto the observed filtration, which turns the stochastic control problem into a\nfully observed problem. Then we use a variational approach in order to derive\nthe unique optimal trading strategy. We illustrate our results for various\nscenarios in which the desk is facing momentum and mean-reverting toxicity. Our\nimplementation shows that the P&L performance gap between the partially\nobservable problem and the full information case are of order $0.01\\%$ in all\ntested scenarios.\n"
    },
    {
        "paper_id": 2407.0452,
        "authors": "Will Hicks",
        "title": "Modelling Uncertain Volatility Using Quantum Stochastic Calculus:\n  Unitary vs Non-Unitary Time Evolution",
        "comments": "18 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we look at stochastic processes with uncertain parameters,\nand consider different ways in which information is obtained when carrying out\nobservations. For example we focus on the case of a the random evolution of a\ntraded financial asset price with uncertain volatility. The quantum approach\npresented, allows us to encode different volatility levels in a state acting on\na Hilbert space. We consider different means of defining projective\nmeasurements in order to track the evolution of a traded market price, and\ndiscuss the results of different Monte-Carlo simulations.\n"
    },
    {
        "paper_id": 2407.04521,
        "authors": "Xiaoli Wei, Xiang Yu, Fengyi Yuan",
        "title": "Unified continuous-time q-learning for mean-field game and mean-field\n  control problems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the continuous-time q-learning in the mean-field\njump-diffusion models from the representative agent's perspective. To overcome\nthe challenge when the population distribution may not be directly observable,\nwe introduce the integrated q-function in decoupled form (decoupled\nIq-function) and establish its martingale characterization together with the\nvalue function, which provides a unified policy evaluation rule for both\nmean-field game (MFG) and mean-field control (MFC) problems. Moreover,\ndepending on the task to solve the MFG or MFC problem, we can employ the\ndecoupled Iq-function by different means to learn the mean-field equilibrium\npolicy or the mean-field optimal policy respectively. As a result, we devise a\nunified q-learning algorithm for both MFG and MFC problems by utilizing all\ntest policies stemming from the mean-field interactions. For several examples\nin the jump-diffusion setting, within and beyond the LQ framework, we can\nobtain the exact parameterization of the decoupled Iq-functions and the value\nfunctions, and illustrate our algorithm from the representative agent's\nperspective with satisfactory performance.\n"
    },
    {
        "paper_id": 2407.0486,
        "authors": "Sebastian Jaimungal and Silvana M. Pesenti",
        "title": "Kullback-Leibler Barycentre of Stochastic Processes",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  We consider the problem where an agent aims to combine the views and insights\nof different experts' models. Specifically, each expert proposes a diffusion\nprocess over a finite time horizon. The agent then combines the experts' models\nby minimising the weighted Kullback-Leibler divergence to each of the experts'\nmodels. We show existence and uniqueness of the barycentre model and proof an\nexplicit representation of the Radon-Nikodym derivative relative to the average\ndrift model. We further allow the agent to include their own constraints, which\nresults in an optimal model that can be seen as a distortion of the experts'\nbarycentre model to incorporate the agent's constraints.\n  Two deep learning algorithms are proposed to find the optimal drift of the\ncombined model, allowing for efficient simulations. The first algorithm aims at\nlearning the optimal drift by matching the change of measure, whereas the\nsecond algorithm leverages the notion of elicitability to directly estimate the\nvalue function. The paper concludes with a extended application to combine\nimplied volatility smiles models that were estimated on different datasets.\n"
    },
    {
        "paper_id": 2407.05142,
        "authors": "Dan Pirjol",
        "title": "Subleading correction to the Asian options volatility in the\n  Black-Scholes model",
        "comments": "17 pages, 5 figures. Expanded version of the published paper,\n  including also the convexity of the subleading Asian volatility",
        "journal-ref": "IJTAF vol 26, no. 2-3, 2350005, 2023",
        "doi": "10.1142/S021902492350005X",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The short maturity limit $T\\to 0$ for the implied volatility of an Asian\noption in the Black-Scholes model is determined by the large deviations\nproperty for the time-average of the geometric Brownian motion. In this note we\nderive the subleading $O(T)$ correction to this implied volatility, using an\nasymptotic expansion for the Hartman-Watson distribution. The result is used to\ncompute subleading corrections to Asian options prices in a small maturity\nexpansion, sharpening the leading order result obtained using large deviations\ntheory. We demonstrate good numerical agreement with precise benchmarks for\nAsian options pricing in the Black-Scholes model.\n"
    },
    {
        "paper_id": 2407.05146,
        "authors": "Alexander Lipton and Vladimir Lucic and Artur Sepp",
        "title": "Unified Approach for Hedging Impermanent Loss of Liquidity Provision",
        "comments": "34 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop static and dynamic approaches for hedging of the impermanent loss\n(IL) of liquidity provision (LP) staked at Decentralised Exchanges (DEXes)\nwhich employ Uniswap V2 and V3 protocols. We provide detailed definitions and\nformulas for computing the IL to unify different definitions occurring in the\nexisting literature. We show that the IL can be seen a contingent claim with a\nnon-linear payoff for a fixed maturity date. Thus, we introduce the contingent\nclaim termed as IL protection claim which delivers the negative of IL payoff at\nthe maturity date. We apply arbitrage-based methods for valuation and risk\nmanagement of this claim. First, we develop the static model-independent\nreplication method for the valuation of IL protection claim using traded\nEuropean vanilla call and put options. We extend and generalize an existing\nmethod to show that the IL protection claim can be hedged perfectly with\noptions if there is a liquid options market. Second, we develop the dynamic\nmodel-based approach for the valuation and hedging of IL protection claims\nunder a risk-neutral measure. We derive analytic valuation formulas using a\nwide class of price dynamics for which the characteristic function is available\nunder the risk-neutral measure. As base cases, we derive analytic valuation\nformulas for IL protection claim under the Black-Scholes-Merton model and the\nlog-normal stochastic volatility model. We finally discuss estimation of\nrisk-reward of LP staking using our results.\n"
    },
    {
        "paper_id": 2407.05866,
        "authors": "Anita Behme",
        "title": "Volatility modeling in a Markovian environment: Two\n  Ornstein-Uhlenbeck-related approaches",
        "comments": "2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce generalizations of the COGARCH model of Kl\\\"uppelberg et al.\nfrom 2004 and the volatility and price model of Barndorff-Nielsen and Shephard\nfrom 2001 to a Markov-switching environment. These generalizations allow for\nexogeneous jumps of the volatility at times of a regime switch. Both models are\nstudied within the framework of Markov-modulated generalized Ornstein-Uhlenbeck\nprocesses which allows to derive conditions for stationarity, formulas for\nmoments, as well as the autocovariance structure of volatility and price\nprocess. It turns out that both models inherit various properties of the\noriginal models and therefore are able to capture basic stylized facts of\nfinancial time-series such as uncorrelated log-returns, correlated squared\nlog-returns and non-existence of higher moments in the COGARCH case.\n"
    },
    {
        "paper_id": 2407.05912,
        "authors": "Maysam Khodayari Gharanchaei, Prabhu Prasad Panda",
        "title": "Constructing an Investment Fund through Stock Clustering and Integer\n  Programming",
        "comments": null,
        "journal-ref": "Journal of Advancements in Applied Business Research, June 2024",
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper focuses on the application of quantitative portfolio management by\nusing integer programming and clustering techniques. Investors seek to gain the\nhighest profits and lowest risk in capital markets. A data-oriented analysis of\nUS stock universe is used to provide portfolio managers a device to track\ndifferent Exchange Traded Funds. As an example, reconstructing of NASDAQ 100\nindex fund is presented.\n"
    },
    {
        "paper_id": 2407.05933,
        "authors": "Yujuan Qiu",
        "title": "Estimation of tail risk measures in finance: Approaches to extreme value\n  mixture modeling",
        "comments": "Master's Diss. Johns Hopkins University, 2019",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This thesis evaluates most of the extreme mixture models and methods that\nhave appended in the literature and implements them in the context of finance\nand insurance. The paper also reviews and studies extreme value theory, time\nseries, volatility clustering, and risk measurement methods in detail.\nComparing the performance of extreme mixture models and methods on different\nsimulated distributions shows that the method based on kernel density\nestimation does not have an absolute superior or close to the best performance,\nespecially for the estimation of the extreme upper or lower tail of the\ndistribution. Preprocessing time series data using a generalized autoregressive\nconditional heteroskedasticity model (GARCH) and applying extreme value mixture\nmodels on extracted residuals from GARCH can improve the goodness of fit and\nthe estimation of the tail distribution.\n"
    },
    {
        "paper_id": 2407.05974,
        "authors": "Maria Laura Victoria Marques, Ronaldo Seroa da Motta, Daniel de Abreu\n  Pereira Uhr, Julia Ziero Uhr",
        "title": "45 Years of Publications in Energy Economics: Evolution and Thematic\n  Trends",
        "comments": "Bibliometric Analysis",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The journal Energy Economics, a leading international peer-reviewed outlet\nfor economic theory in the energy sector, celebrates its 45th anniversary in\n2024. This article uses a bibliometric approach to present a retrospective of\nthe journal's contributions. The study includes all publications from the\njournal based on data from the Web of Science and Scopus databases. The\nresulting sample comprises 6,563 documents covering the period from 1979 to\nApril 2024. The annual publication rate increased by 1.02 percent, with an\naverage of 40.07 citations per document. Institutions from the United States of\nAmerica and China lead in the number of articles published in the journal. A\nco-occurrence analysis of keywords was conducted, complemented by a sub-sample\nanalysis, to provide a detailed view of thematic development and evolution over\ntime. Finally, the article highlights future thematic trends of the journal,\noffering insights for editorial guidelines and interested authors.\n"
    },
    {
        "paper_id": 2407.06215,
        "authors": "Carolin Bauerhenne, Jonathan Bard, Rainer Kolisch",
        "title": "Robust Routing and Scheduling of Home Healthcare Workers: A Nested\n  Branch-and-Price Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The global home healthcare market is growing rapidly due to aging\npopulations, advancements in healthcare technology, and patient preference for\nhome-based care. In this paper, we study the multi-day planning problem of\nsimultaneously deciding patient acceptance, assignment, routing, and scheduling\nunder uncertain travel and service times. Our approach ensures\ncardinality-constrained robustness with respect to timely patient care and the\nprevention of overtime. We take into account a wide range of criteria including\npatient time windows, caregiver availability and compatibility, a minimum time\ninterval between two visits of a patient, the total number of required visits,\ncontinuity of care, and profit. We use a novel systematic modeling scheme that\nprioritizes health-related criteria as hard constraints and optimizes cost and\npreference-related criteria as part of the objective function. We present a\nmixed-integer linear program formulation, along with a nested branch-and-price\ntechnique. Results from a case study in Austin, Texas demonstrate that\ninstances of realistic size can be solved to optimality within reasonable\nruntimes. The price of robustness primarily results from reduced patient load\nper caregiver. Interestingly, the criterion of geographical proximity appears\nto be of secondary priority when selecting new patients and assigning them to\ncaregivers.\n"
    },
    {
        "paper_id": 2407.06248,
        "authors": "O.A. Malafeyev, I.E.Khomenko",
        "title": "Auction theory and demography",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In economics, there are many ways to describe the interaction between a\n\"seller\" and a \"buyer\". The most common one, with which we interact almost\nevery day, is selling for a fixed price. This option is perfect for selling a\nmass product, when we have a number of sellers and many buyers, and the price\nfor the product varies depending on the conditions of the relationship between\nsupply and demand. Another situation meets us already in markets, where a\nproduct can be either mass-produced or more unique, so this option is already\ncloser to the object of our discussion.However, a one-on-one transaction is a\nmuch more unstable option, which is why it is also more difficult to model,\nsince it is determined not so much by algorithms as by psychology and the\ndifference in the bargaining ability of the two parties. An even closer example\nof an auction is price discrimination, when the price for the buyer is\ndetermined not only by supply and demand, but also by which group the buyer\nbelongs to. But in this case, the product is not unique, and the final seller\nis the only one. Thus, we have identified the main auction criteria and their\nfeatures of the \"game\".\n"
    },
    {
        "paper_id": 2407.06495,
        "authors": "Tatsuru Kikuchi",
        "title": "Impact Evaluation on the European Privacy Laws governing generative-AI\n  models -- Evidence in Relation between Internet Censorship and the Ban of\n  ChatGPT in Italy",
        "comments": "14 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We proceed an impact evaluation on the European Privacy Laws governing\ngenerative-AI models, especially, focusing on the effects of the Ban of ChatGPT\nin Italy. We investigate on the causal relationship between Internet Censorship\nData and the Ban of ChatGPT in Italy during the period from March 27, 2023 to\nApril 11, 2023. We analyze the relation based on the hidden Markov model with\nPoisson emissions. We find out that the HTTP Invalid Requests, which decreased\nduring those period, can be explained with seven-state model. Our findings\nshows the apparent inability for the users in the internet accesses as a result\nof EU regulations on the generative-AI.\n"
    },
    {
        "paper_id": 2407.06529,
        "authors": "Yu Cheng, Junjie Guo, Shiqing Long, You Wu, Mengfang Sun, Rong Zhang",
        "title": "Advanced Financial Fraud Detection Using GNN-CL Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The innovative GNN-CL model proposed in this paper marks a breakthrough in\nthe field of financial fraud detection by synergistically combining the\nadvantages of graph neural networks (gnn), convolutional neural networks (cnn)\nand long short-term memory (LSTM) networks. This convergence enables\nmultifaceted analysis of complex transaction patterns, improving detection\naccuracy and resilience against complex fraudulent activities. A key novelty of\nthis paper is the use of multilayer perceptrons (MLPS) to estimate node\nsimilarity, effectively filtering out neighborhood noise that can lead to false\npositives. This intelligent purification mechanism ensures that only the most\nrelevant information is considered, thereby improving the model's understanding\nof the network structure. Feature weakening often plagues graph-based models\ndue to the dilution of key signals. In order to further address the challenge\nof feature weakening, GNN-CL adopts reinforcement learning strategies. By\ndynamically adjusting the weights assigned to central nodes, it reinforces the\nimportance of these influential entities to retain important clues of fraud\neven in less informative data. Experimental evaluations on Yelp datasets show\nthat the results highlight the superior performance of GNN-CL compared to\nexisting methods.\n"
    },
    {
        "paper_id": 2407.06619,
        "authors": "Federico Gatta, Fabrizio Lillo, Piero Mazzarisi",
        "title": "CAESar: Conditional Autoregressive Expected Shortfall",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In financial risk management, Value at Risk (VaR) is widely used to estimate\npotential portfolio losses. VaR's limitation is its inability to account for\nthe magnitude of losses beyond a certain threshold. Expected Shortfall (ES)\naddresses this by providing the conditional expectation of such exceedances,\noffering a more comprehensive measure of tail risk. Despite its benefits, ES is\nnot elicitable on its own, complicating its direct estimation. However, joint\nelicitability with VaR allows for their combined estimation. Building on this,\nwe propose a new methodology named Conditional Autoregressive Expected\nShortfall (CAESar), inspired by the CAViaR model. CAESar handles dynamic\npatterns flexibly and includes heteroskedastic effects for both VaR and ES,\nwith no distributional assumption on price returns. CAESar involves a\nthree-step process: estimating VaR via CAViaR regression, formulating ES in an\nautoregressive manner, and jointly estimating VaR and ES while ensuring a\nmonotonicity constraint to avoid crossing quantiles. By employing various\nbacktesting procedures, we show the effectiveness of CAESar through extensive\nsimulations and empirical testing on daily financial data. Our results\ndemonstrate that CAESar outperforms existing regression methods in terms of\nforecasting performance, making it a robust tool for financial risk management.\n"
    },
    {
        "paper_id": 2407.06695,
        "authors": "Giacomo De Giorgi, Enrico Moretti, Harrison Wheeler",
        "title": "Gentrification, Mobility, and Consumption",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study the effect of localized housing price hikes on renters' mobility,\nconsumption, and credit outcomes. Consistent with a spatial equilibrium model,\nwe find that the consumption responses vary greatly for movers and stayers.\nWhile movers increase their consumption, purchase homes, and cars, stayers are\nrelatively unaffected.\n"
    },
    {
        "paper_id": 2407.06745,
        "authors": "Michael Sekatchev, Zhengxiang Zhou",
        "title": "Stochastic Approaches to Asset Price Analysis",
        "comments": "30 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this project, we propose to explore the Kalman filter's performance for\nestimating asset prices. We begin by introducing a stochastic mean-reverting\nprocesses, the Ornstein-Uhlenbeck (OU) model. After this we discuss the Kalman\nfilter in detail, and its application with this model. After a demonstration of\nthe Kalman filter on a simulated OU process and a discussion of maximum\nlikelihood estimation (MLE) for estimating model parameters, we apply the\nKalman filter with the OU process and trailing parameter estimation to real\nstock market data. We finish by proposing a simple day-trading algorithm using\nthe Kalman filter with the OU process and backtest its performance using\nApple's stock price. We then move to the Heston model, a combination of\nGeometric Brownian Motion and the OU process. Maximum likelihood estimation is\ncommonly used for Heston model parameter estimation, which results in very\ncomplex forms. Here we propose an alternative but easier way of parameter\nestimation, called the method of moments (MOM). After the derivation of these\nestimators, we again apply this method to real stock data to assess its\nperformance.\n"
    },
    {
        "paper_id": 2407.06808,
        "authors": "Eleonora Brandimarti, Giacomo De Giorgi, Jeremy Laurent-Lucchetti",
        "title": "Credit and Voting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  There is a tight connection between credit access and voting. We show that\nuncertainty in access to credit pushes voters toward more conservative\ncandidates in US elections. Using a 1% sample of the US population with valid\ncredit reports, we relate access to credit to voting outcomes in all\ncounty-by-congressional districts over the period 2004-2016. Specifically, we\nconstruct exogenous measures of uncertainty to credit access, i.e. credit score\nvalues around which individual total credit amount jumps the most (e.g. around\nwhich uncertainty on access to credit is the highest). We then show that a 10pp\nincrease in the share of marginal voters located just around these thresholds\nincreases republican votes by 2.7pp, and reduces that of democrats by 2.6pp.\nFurthermore, winning candidates in more uncertain constituencies tend to follow\na more conservative rhetoric.\n"
    },
    {
        "paper_id": 2407.071,
        "authors": "Eberhard Mayerhofer",
        "title": "Asymptotic methods for transaction costs",
        "comments": "33 pages, 4 figures",
        "journal-ref": "Risks, Special Issue: Optimal Investment and Risk Management, Vol.\n  12 No. 4 (2024), 64",
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We propose a general approximation method for determining optimal trading\nstrategies in markets with proportional transaction costs, with a polynomial\napproximation of the residual value function. The method is exemplified by\nseveral problems from optimally tracking benchmarks, hedging the Log contract,\nto maximizing utility from terminal wealth. Strategies are also approximated by\npractically executable, discrete trades. We identify the necessary trade-off\nbetween trading frequency and trade sizes to have satisfactory agreement with\nthe theoretically optimal, continuous strategies of infinite activity.\n"
    },
    {
        "paper_id": 2407.07201,
        "authors": "Carl Hase, Johannes Kasinger",
        "title": "The Pass-through of Retail Crime",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper shows that retailers increase prices in response to organized\nretail crime, revealing a substantial aspect of retail crime's social costs. We\nmatch detailed information on store-level crimes to administrative scanner data\nfrom the universe of transactions for cannabis retailers in Washington state.\nExploiting quasi-experimental variation from the timing of store-level\nrobberies and burglaries, we find that crimes cause a 1.8% increase in retail\nprices at victimized stores. Nearby rivals of victimized stores increase prices\nby a similar amount with a two-month lag. Retailers' price responses are not\ndriven by demand effects, increased wholesale costs, or strategic price\nresponses. Instead, they are consistent with precautionary security\nexpenditures. We find the largest pass-through rates for independent stores and\nin less concentrated markets. We estimate that crime imposes a 1% \"hidden\" unit\ntax on affected stores, implying an annual negative welfare effect of\napproximately $30.6 million, with consumers bearing two-thirds of this burden.\n"
    },
    {
        "paper_id": 2407.07573,
        "authors": "Shitab Ishmam, Heidi Heinrichs, Christoph Winkler, Bagher Bayat, Amin\n  Lahnaoui, Solomon Agbo, Edgar Ubaldo Pena Sanchez, David Franzmann, Nathan\n  Ojieabu, Celine Koerner, Youpele Micheal, Bamidele Oloruntoba, Carsten\n  Montzka, Harry Vereecken, Harrie-Jan Hendricks-Franssen, Jeerawan Brendt,\n  Simon Brauner, Wilhelm Kuckshinrichs, Sandra Venghaus, Daouda Kone, Bruno\n  Korgo, Kehinde Ogunjobi, Vasco Chiteculo, Jane Olwoch, Zachary Getenga,\n  Jochen Lin{\\ss}en, Detlef Stolten",
        "title": "Mapping Local Green Hydrogen Cost-Potentials by a Multidisciplinary\n  Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  For fast-tracking climate change response, green hydrogen is key for\nachieving greenhouse gas neutral energy systems. Especially Sub-Saharan Africa\ncan benefit from it enabling an increased access to clean energy through\nutilizing its beneficial conditions for renewable energies. However, developing\ngreen hydrogen strategies for Sub-Saharan Africa requires highly detailed and\nconsistent information ranging from technical, environmental, economic, and\nsocial dimensions, which is currently lacking in literature. Therefore, this\npaper provides a comprehensive novel approach embedding the required range of\ndisciplines to analyze green hydrogen cost-potentials in Sub-Saharan Africa.\nThis approach stretches from a dedicated land eligibility based on local\npreferences, a location specific renewable energy simulation, locally derived\nsustainable groundwater limitations under climate change, an optimization of\nlocal hydrogen energy systems, and a socio-economic indicator-based impact\nanalysis. The capability of the approach is shown for case study regions in\nSub-Saharan Africa highlighting the need for a unified, interdisciplinary\napproach.\n"
    },
    {
        "paper_id": 2407.07632,
        "authors": "Hanxin Zhao",
        "title": "The role of green ammonia in meeting challenges towards a sustainable\n  development in China",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper discusses the adoption of a green ammonia economy in meeting\nchallenges in China's sustainable development. First, key challenges in China's\nenergy transition, industry decarbonziation and regional sustainable\ndevelopment are explored. The coal-dominated energy consumption has placed\ngreat obstacles in achieving energy transition and led to massive CO2 emission\nsince the large-scale industrialization. The high dependency on oil and gas\nimport has threatened the energy security. A DEA model is applied for obtaining\ngreen total factor productivities of China's six administrative regions, with\nwhich, imbalanced and unsustainable regional development is identified. Second,\nthe role of green ammonia in meeting the sustainability challenges is analysed.\nAmmonia is examined to be a flexible and economic option for large-scale\nhydrogen transport and storage. Co-firing ammonia in coal power generation at\n3% rate is evaluated as an option for achieving low-carbon transition by 2030.\nThe adoption of a green ammonia economy in China is discussed from energy,\nenvironmental and economic aspects. The practice can decline fossil energy\nconsumption, enhance energy security, and facilitate renewable energy delivery\nand storage, industry decarbonization, and regional development. We assume the\nfindings and results contribute to addressing sustainability challenges and\nrealizing a hydrogen economy in China.\n"
    },
    {
        "paper_id": 2407.07652,
        "authors": "Lionel Fontagn\\'e, Francesca Micocci, Armando Rungi",
        "title": "The heterogeneous impact of the EU-Canada agreement with causal machine\n  learning",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This paper introduces a causal machine learning approach to investigate the\nimpact of the EU-Canada Comprehensive Economic Trade Agreement (CETA). We\npropose a matrix completion algorithm on French customs data to obtain\nmultidimensional counterfactuals at the firm, product and destination levels.\nWe find a small but significant positive impact on average at the product-level\nintensive margin. On the other hand, the extensive margin shows product\nchurning due to the treaty beyond regular entry-exit dynamics: one product in\neight that was not previously exported substitutes almost as many that are no\nlonger exported. When we delve into the heterogeneity, we find that the effects\nof the treaty are higher for products at a comparative advantage. Focusing on\nmultiproduct firms, we find that they adjust their portfolio in Canada by\nreallocating towards their first and most exported product due to increasing\nlocal market competition after trade liberalization. Finally, multidimensional\ncounterfactuals allow us to evaluate the general equilibrium effect of the\nCETA. Specifically, we observe trade diversion, as exports to other\ndestinations are re-directed to Canada.\n"
    },
    {
        "paper_id": 2407.07795,
        "authors": "Katarzyna Maciejowska and Weronika Nitka",
        "title": "Multiple split approach -- multidimensional probabilistic forecasting of\n  electricity markets",
        "comments": "32 pages, 7 figures. Working paper",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  In this article, a multiple split method is proposed that enables\nconstruction of multidimensional probabilistic forecasts of a selected set of\nvariables. The method uses repeated resampling to estimate uncertainty of\nsimultaneous multivariate predictions. This nonparametric approach links the\ngap between point and probabilistic predictions and can be combined with\ndifferent point forecasting methods. The performance of the method is evaluated\nwith data describing the German short-term electricity market. The results show\nthat the proposed approach provides highly accurate predictions. The gains from\nmultidimensional forecasting are the largest when functions of variables, such\nas price spread or residual load, are considered.\n  Finally, the method is used to support a decision process of a moderate\ngeneration utility that produces electricity from wind energy and sells it on\neither a day-ahead or an intraday market. The company makes decisions under\nhigh uncertainty because it knows neither the future production level nor the\nprices. We show that joint forecasting of both market prices and fundamentals\ncan be used to predict the distribution of a profit, and hence helps to design\na strategy that balances a level of income and a trading risk.\n"
    },
    {
        "paper_id": 2407.07898,
        "authors": "Carlos Alberto Durigan Junior, Mauro De Mesquita Spinola, Rodrigo\n  Franco Gon\\c{c}alves, Fernando Jos\\'e Barbin Laurindo",
        "title": "Central Bank Digital Currency: The Advent of its IT Governance in the\n  financial markets",
        "comments": "Keywords: Blockchain, Central Bank Digital Currency (CBDC), Digital\n  Economy, Distributed Ledger Technology (DLT), Information Technology (IT), IT\n  governance",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Central Bank Digital Currency (CBDC) can be defined as a virtual currency\nbased on node network and digital encryption algorithm issued by a country\nwhich has a legal credit protection. CBDCs are supported by Distributed Ledger\nTechnologies (DLTs), and they may allow a universal means of payments for the\ndigital era. There are many ways to proceed, they all require central banks to\ndevelop technological expertise. Considering these points, it is important to\nunderstand the new IT governance in the financial markets due to CBDC and\ndigital economy. Information Technology is an essential driver that will allow\nthe new financial industry design. This paper has the objective to answer two\nquestions through an updated Systematic Literature Review (SLR). The first\nquestion is What IT resources and tools have been considered or applied to set\nthe governance of CBDC adoption? The second; Identify IT governance models in\nthe financial market due to CBDC adoption. Bank for International Settlements\n(BIS) publications, Scopus and Web of Science were considered as sources of\nstudies. After the strings and including criteria were applied, fourteen papers\nwere analyzed. This paper finds many IT resources used in the CBDC adoption and\nsome preliminary IT design related to the IT governance of CBDC, in the results\nand discussion section the findings are more detailed. Finally, limitations and\nfuture work are considered. Keywords: Blockchain, Central Bank Digital Currency\n(CBDC), Digital Economy, Distributed Ledger Technology (DLT), Information\nTechnology (IT), IT governance.\n"
    },
    {
        "paper_id": 2407.08036,
        "authors": "Dragoljub Katic and Stefan Richter",
        "title": "Financial market geometry: The tube oscillator",
        "comments": "36 pages, 23 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Based on geometrical considerations, we propose a new oscillator for\ntechnical market analysis, the tube oscillator. This oscillator measures the\ntrending behavior of a fixed market instrument based on its past history. It is\nshown in an empirical analysis of the German DAX and the Forex EUR/USD exchange\nrate that a simple trading strategy based on this oscillator and fixed\nthreshold leads to consistent positive monthly returns of average magnitude of\n2% or more. The oscillator is derived from a broader understanding of the\ngeometric behavior of prices throughout a fixed period, which we term financial\nmarket geometry. The remarkable profit results of the presented technique show\nthat 1) prices of financial market instruments have a strong underlying\ndeterministic component which can be detected and quantified with a matching\napproach and 2) financial market geometry is capable of providing such\ndetectors.\n"
    },
    {
        "paper_id": 2407.08069,
        "authors": "An Pham Ngoc Nguyen, Thomas Conlon, Martin Crane, Marija Bezbradica",
        "title": "Herding Unmasked: Insights into Cryptocurrencies, Stocks and US ETFs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Herding behavior has become a familiar phenomenon to investors, carrying the\npotential danger of both undervaluing and overvaluing assets, while also\nthreatening market stability. This study contributes to the literature on\nherding behavior by using a more recent dataset to cover the most impactful\nevents of recent years. To our knowledge, this is the first study examining\nherding behavior across three different types of investment vehicle.\nFurthermore, this is also the first study observing herding at a community\n(subset) level. Specifically, we first explore this phenomenon in each separate\ntype of investment vehicle, namely stocks, US ETFs and cryptocurrencies, using\nthe widely recognized Cross Sectional Absolute Deviation (CSAD) model. We find\nsimilar herding patterns between stocks and US ETFs, while these traditional\nassets reveal a distinction from cryptocurrencies. Subsequently, the same\nexperiment is implemented on a combination of all three investment vehicle\ntypes. For a deeper investigation, we adopt graph-based techniques such as\nMinimum Spanning Tree (MST) and Louvain community detection to partition the\ngiven combination into smaller subsets whose assets are most similar to each\nother, then seek to detect the herding behavior on each subset. We find that\nherding behavior exists at all times across all types of investment vehicle at\na subset level, although the herding might not manifest at the superset level.\nAdditionally, this herding behavior tends to stem from specific events that\nsolely impact that subset of assets. Given these findings, investors can\nconstruct an appropriate investment strategy composed of their choice of\ninvestment vehicles they are interested in.\n"
    },
    {
        "paper_id": 2407.08312,
        "authors": "Jacek Pawlak, John Polak",
        "title": "Valuation of travel time savings in the presence of simultaneous\n  activities",
        "comments": "15 pages, 2 Figures, Presented at European Transport Conference 2010",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Time sharing between activities remains an indispensable part of everyday\nactivity pattern. However, the issue has not yet been fully acknowledged within\nthe existing time allocation models, potentially resulting in inaccuracies in\nvaluing travel time savings. Therefore this study is aimed at addressing this\ngap by investigating the potential impact of introducing time sharing within\nsuch a framework, as well as factors determining it as represented by travel\nactivities. In doing so, time constraint in the time allocation model of Small\nwas modified to enable sharing the same time interval between different\nactivities. The resulting expression indicated that such an augmentation could\nlead to lower estimates of value of time as a resource. On the other hand,\nempirical research based on the data from the National Passenger Survey 2004\nused for calibrating cross-nested logit model indicated a number of factors\naffecting the choice of travel activities. It was discovered that significant\ninclude possession of equipment allowing particular activities, e.g. newspaper,\npaperwork or ICT devices, companionship, gender, length of the journey,\nfrequency of using the service, possibility of working on the train, journey\nplanning in advance, first class travel, termination of the trip in central\nLondon, peak-time travel and availability of seating.\n"
    },
    {
        "paper_id": 2407.08332,
        "authors": "Sourish Das",
        "title": "Risk Analysis of Passive Portfolios",
        "comments": "5 figures, R code",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this work, we present an alternative passive investment strategy. The\npassive investment philosophy comes from the Efficient Market Hypothesis (EMH),\nand its adoption is widespread. If EMH is true, one cannot outperform market by\nactively managing their portfolio for a long time. Also, it requires little to\nno intervention. People can buy an exchange-traded fund (ETF) with a long-term\nperspective. As the economy grows over time, one expects the ETF to grow. For\nexample, in India, one can invest in NETF, which suppose to mimic the Nifty50\nreturn. However, the weights of the Nifty 50 index are based on market\ncapitalisation. These weights are not necessarily optimal for the investor. In\nthis work, we present that volatility risk and extreme risk measures of the\nNifty50 portfolio are uniformly larger than Markowitz's optimal portfolio.\nHowever, common people can't create an optimised portfolio. So we proposed an\nalternative passive investment strategy of an equal-weight portfolio. We show\nthat if one pushes the maximum weight of the portfolio towards equal weight,\nthe idiosyncratic risk of the portfolio would be minimal. The empirical\nevidence indicates that the risk profile of an equal-weight portfolio is\nsimilar to that of Markowitz's optimal portfolio. Hence instead of buying\nNifty50 ETFs, one should equally invest in the stocks of Nifty50 to achieve a\nuniformly better risk profile than the Nifty 50 ETF portfolio. We also present\nan analysis of how portfolios perform to idiosyncratic events like the Russian\ninvasion of Ukraine. We found that the equal weight portfolio has a uniformly\nlower risk than the Nifty 50 portfolio before and during the Russia-Ukraine\nwar. All codes are available on GitHub\n(\\url{https://github.com/sourish-cmi/quant/tree/main/Chap_Risk_Anal_of_Passive_Portfolio}).\n"
    },
    {
        "paper_id": 2407.08477,
        "authors": "Xinfu Chen, Yuchao Dong, Wenlin Huang, and Jin Liang",
        "title": "Optimal Carbon Emission Control With Allowances Purchasing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this paper, we consider a company can simultaneously reduce its emissions\nand buy carbon allowances at any time. We establish an optimal control model\ninvolving two stochastic processes with two control variables, which is a\nsingular control problem. This model can then be converted into a\nHamilton-Jacobi-Bellman (HJB) equation, which is a two-dimensional variational\nequality with gradient barrier, so that the free boundary is a surface. We\nprove the existence and uniqueness of the solution. Finally, some numerical\nresults are shown.\n"
    },
    {
        "paper_id": 2407.08748,
        "authors": "Lim Hao Shen Keith",
        "title": "Covariance Matrix Analysis for Optimal Portfolio Selection",
        "comments": "B.Sc. Dissertation",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In portfolio risk minimization, the inverse covariance matrix of returns is\noften unknown and has to be estimated in practice. This inverse covariance\nmatrix also prescribes the hedge trades in which a stock is hedged by all the\nother stocks in the portfolio. In practice with finite samples, however,\nmulticollinearity gives rise to considerable estimation errors, making the\nhedge trades too unstable and unreliable for use. By adopting ideas from\ncurrent methodologies in the existing literature, we propose 2 new estimators\nof the inverse covariance matrix, one which relies only on the l2 norm while\nthe other utilizes both the l1 and l2 norms. These 2 new estimators are\nclassified as shrinkage estimators in the literature. Comparing favorably with\nother methods (sample-based estimation, equal-weighting, estimation based on\nPrincipal Component Analysis), a portfolio formed on the proposed estimators\nachieves substantial out-of-sample risk reduction and improves the\nout-of-sample risk-adjusted returns of the portfolio, particularly in\nhigh-dimensional settings. Furthermore, the proposed estimators can still be\ncomputed even in instances where the sample covariance matrix is\nill-conditioned or singular\n"
    },
    {
        "paper_id": 2407.08756,
        "authors": "Carole Bernard and Stephan Sturm",
        "title": "Examples and Counterexamples of Cost-efficiency in Incomplete Markets",
        "comments": "21 pages, 2 tables, 3 figures. This paper contains the examples and\n  counterexamples originally contained in arXiv:2206.12511, as per request of\n  the journal editors",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a number of examples and counterexamples to illustrate the results\non cost-efficiency in an incomplete market obtained in [BS24]. These examples\nand counterexamples do not only illustrate the results obtained in [BS24], but\nshow the limitations of the results and the sharpness of the key assumptions.\nIn particular, we make use of a simple 3-state model in which we are able to\nrecover and illustrate all key results of the paper. This example also shows\nhow our characterization of perfectly cost-efficient claims allows to solve an\nexpected utility maximization problem in a simple incomplete market (trinomial\nmodel) and recover results from [DS06, Chapter 3], there obtained using\nduality.\n"
    },
    {
        "paper_id": 2407.08953,
        "authors": "Dangxing Chen, Yuan Gao",
        "title": "Attribution Methods in Asset Pricing: Do They Account for Risk?",
        "comments": null,
        "journal-ref": "2024 IEEE Symposium on Computational Intelligence for Financial\n  Engineering and Economics (CIFEr)",
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Over the past few decades, machine learning models have been extremely\nsuccessful. As a result of axiomatic attribution methods, feature contributions\nhave been explained more clearly and rigorously. There are, however, few\nstudies that have examined domain knowledge in conjunction with the axioms. In\nthis study, we examine asset pricing in finance, a field closely related to\nrisk management. Consequently, when applying machine learning models, we must\nensure that the attribution methods reflect the underlying risks accurately. In\nthis work, we present and study several axioms derived from asset pricing\ndomain knowledge. It is shown that while Shapley value and Integrated Gradients\npreserve most axioms, neither can satisfy all axioms. Using extensive\nanalytical and empirical examples, we demonstrate how attribution methods can\nreflect risks and when they should not be used.\n"
    },
    {
        "paper_id": 2407.09321,
        "authors": "Zaniar Ahmadi, Xiaowen Zhou",
        "title": "A note on Skew Brownian Motion with two-valued drift and an application",
        "comments": "26 pages, 3 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  For skew Brownian motion with two-valued drift, adopting a perturbation\napproach we find expressions of its potential densities. As applications, we\nrecover its transition density and study its long-time asymptotic behaviors. We\nalso compare with previous results on transition densities for skew Brownian\nmotions. We propose two approaches for generating quasi-random samples by\napproximating the cumulative distribution function and discussing their risk\nmeasurement application.\n"
    },
    {
        "paper_id": 2407.0934,
        "authors": "Fabrizio Lillo and Giorgio Rizzini",
        "title": "Modelling shock propagation and resilience in financial temporal\n  networks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Modelling how a shock propagates in a temporal network and how the system\nrelaxes back to equilibrium is challenging but important in many applications,\nsuch as financial systemic risk. Most studies so far have focused on shocks\nhitting a link of the network, while often it is the node and its propensity to\nbe connected that are affected by a shock. Using as starting point the\nconfiguration model, a specific Exponential Random Graph model, we propose a\nvector autoregressive (VAR) framework to analytically compute the Impulse\nResponse Function (IRF) of a network metric conditional to a shock on a node.\nUnlike the standard VAR, the model is a nonlinear function of the shock size\nand the IRF depends on the state of the network at the shock time. We propose a\nnovel econometric estimation method that combines the Maximum Likelihood\nEstimation and Kalman filter to estimate the dynamics of the latent parameters\nand compute the IRF, and we apply the proposed methodology to the dynamical\nnetwork describing the electronic Market of Interbank Deposit (e-MID).\n"
    },
    {
        "paper_id": 2407.09471,
        "authors": "Alessandro Chiusolo and Emma Hubert",
        "title": "A new approach to principal-agent problems with volatility control",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The recent work by Cvitani\\'c, Possama\\\"i, and Touzi (2018) [9] presents a\ngeneral approach for continuous-time principal-agent problems, through dynamic\nprogramming and second-order backward stochastic differential equations\n(BSDEs). In this paper, we provide an alternative formulation of the\nprincipal-agent problem, which can be solved simply by relying on the theory of\nBSDEs. This reformulation is strongly inspired by an important remark in [9],\nnamely that if the principal observes the output process in continuous-time,\nshe can compute its quadratic variation pathwise. While in [9], this\ninformation is used in the contract, our reformulation consists in assuming\nthat the principal could directly control this process, in a `first-best'\nfashion. The resolution approach for this alternative problem actually follows\nthe line of the so-called `Sannikov's trick' in the literature on\ncontinuous-time principal-agent problems, as originally introduced by Sannikov\n(2008) [28]. We then show that the solution to this `first-best' formulation is\nidentical to the solution of the original problem. More precisely, using the\ncontract form introduced in [9] as `penalisation contracts', we highlight that\nthis `first-best' scenario can be achieved even if the principal cannot\ndirectly control the quadratic variation. Nevertheless, we do not have to rely\non the theory of 2BSDEs to prove that such contracts are optimal, as their\noptimality is ensured by showing that the `first-best' scenario is achieved. We\nbelieve that this more straightforward approach to solve continuous-time\nprincipal-agent problems with volatility control will facilitate the\ndissemination of these problems across many fields, and its extension to even\nmore intricate problems.\n"
    },
    {
        "paper_id": 2407.0948,
        "authors": "Teng Ye, Jingnan Zheng, Junhui Jin, Jingyi Qiu, Wei Ai, Qiaozhu Mei",
        "title": "Using Artificial Intelligence to Unlock Crowdfunding Success for Small\n  Businesses",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  While small businesses are increasingly turning to online crowdfunding\nplatforms for essential funding, over 40% of these campaigns may fail to raise\nany money, especially those from low socio-economic areas. We utilize the\nlatest advancements in AI technology to identify crucial factors that influence\nthe success of crowdfunding campaigns and to improve their fundraising outcomes\nby strategically optimizing these factors. Our best-performing machine learning\nmodel accurately predicts the fundraising outcomes of 81.0% of campaigns,\nprimarily based on their textual descriptions. Interpreting the machine\nlearning model allows us to provide actionable suggestions on improving the\ntextual description before launching a campaign. We demonstrate that by\naugmenting just three aspects of the narrative using a large language model, a\ncampaign becomes more preferable to 83% human evaluators, and its likelihood of\nsecuring financial support increases by 11.9%. Our research uncovers the\neffective strategies for crafting descriptions for small business fundraising\ncampaigns and opens up a new realm in integrating large language models into\ncrowdfunding methodologies.\n"
    },
    {
        "paper_id": 2407.09487,
        "authors": "Carlos Alberto Durigan Junior, Kumiko Oshio Kissimoto, Fernando Jose\n  Barbin Laurindo",
        "title": "IT Enabling Factors in a new Industry Design: Open Banking and Digital\n  Economy",
        "comments": "Keywords: Digital Economy, Information Technology (IT), Open Banking",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  The fourth industrial revolution promotes the integration of Information\nTechnology (IT) and strategic resources. New IT demands and uses have been\nleading to changes in business processes and corporate governance. Lately, the\nfinancial industry has adopted a new integrated banking model known as Open\nBanking (OB) and the advent of cryptocurrencies has led to the Digital Economy\n(DE) materialization. Considering these facts, this paper expects to point out\nthrough literature review some IT enabling factors that allow the conception of\na new industry design (or governance) specifically in the financial industry\nillustrated by the cases of the Open Banking and Digital Economy. This paper is\nstructured mostly on literature review, accompanied by results, discussions,\nand finally, conclusions are presented. It was found five potential enabling\nfactors. Keywords: Digital Economy, Information Technology (IT), Open Banking.\n"
    },
    {
        "paper_id": 2407.09536,
        "authors": "Ravi Kashyap",
        "title": "The Blockchain Risk Parity Line: Moving From The Efficient Frontier To\n  The Final Frontier Of Investments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We engineer blockchain based risk managed portfolios by creating three funds\nwith distinct risk and return profiles: 1) Alpha - high risk portfolio; 2) Beta\n- mimics the wider market; and 3) Gamma - represents the risk free rate\nadjusted to beat inflation. Each of the sub-funds (Alpha, Beta and Gamma)\nprovides risk parity because the weight of each asset in the corresponding\nportfolio is set to be inversely proportional to the risk derived from\ninvesting in that asset. This can be equivalently stated as equal risk\ncontributions from each asset towards the overall portfolio risk.\n  We provide detailed mechanics of combining assets - including mathematical\nformulations - to obtain better risk managed portfolios. The descriptions are\nintended to show how a risk parity based efficient frontier portfolio\nmanagement engine - that caters to different risk appetites of investors by\nletting each individual investor select their preferred risk-return combination\n- can be created seamlessly on blockchain.\n  Any Investor - using decentralized ledger technology - can select their\ndesired level of risk, or return, and allocate their wealth accordingly among\nthe sub funds, which balance one another under different market conditions.\nThis evolution of the risk parity principle - resulting in a mechanism that is\ngeared to do well under all market cycles - brings more robust performance and\ncan be termed as conceptual parity.\n  We have given several numerical examples that illustrate the various\nscenarios that arise when combining Alpha, Beta and Gamma to obtain Parity.\n  The final investment frontier is now possible - a modification to the\nefficient frontier, thus becoming more than a mere theoretical construct - on\nblockchain since anyone from anywhere can participate at anytime to obtain\nwealth appreciation based on their financial goals.\n"
    },
    {
        "paper_id": 2407.09546,
        "authors": "Yuan Li, Bingqiao Luo, Qian Wang, Nuo Chen, Xu Liu, Bingsheng He",
        "title": "A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  The utilization of Large Language Models (LLMs) in financial trading has\nprimarily been concentrated within the stock market, aiding in economic and\nfinancial decisions. Yet, the unique opportunities presented by the\ncryptocurrency market, noted for its on-chain data's transparency and the\ncritical influence of off-chain signals like news, remain largely untapped by\nLLMs. This work aims to bridge the gap by developing an LLM-based trading\nagent, CryptoTrade, which uniquely combines the analysis of on-chain and\noff-chain data. This approach leverages the transparency and immutability of\non-chain data, as well as the timeliness and influence of off-chain signals,\nproviding a comprehensive overview of the cryptocurrency market. CryptoTrade\nincorporates a reflective mechanism specifically engineered to refine its daily\ntrading decisions by analyzing the outcomes of prior trading decisions. This\nresearch makes two significant contributions. Firstly, it broadens the\napplicability of LLMs to the domain of cryptocurrency trading. Secondly, it\nestablishes a benchmark for cryptocurrency trading strategies. Through\nextensive experiments, CryptoTrade has demonstrated superior performance in\nmaximizing returns compared to traditional trading strategies and time-series\nbaselines across various cryptocurrencies and market conditions. Our code and\ndata are available at\n\\url{https://anonymous.4open.science/r/CryptoTrade-Public-92FC/}.\n"
    },
    {
        "paper_id": 2407.09557,
        "authors": "Alireza Mohammadshafie, Akram Mirzaeinia, Haseebullah Jumakhan, Amir\n  Mirzaeinia",
        "title": "Deep Reinforcement Learning Strategies in Finance: Insights into Asset\n  Holding, Trading Behavior, and Purchase Diversity",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "abstract": "  Recent deep reinforcement learning (DRL) methods in finance show promising\noutcomes. However, there is limited research examining the behavior of these\nDRL algorithms. This paper aims to investigate their tendencies towards holding\nor trading financial assets as well as purchase diversity. By analyzing their\ntrading behaviors, we provide insights into the decision-making processes of\nDRL models in finance applications. Our findings reveal that each DRL algorithm\nexhibits unique trading patterns and strategies, with A2C emerging as the top\nperformer in terms of cumulative rewards. While PPO and SAC engage in\nsignificant trades with a limited number of stocks, DDPG and TD3 adopt a more\nbalanced approach. Furthermore, SAC and PPO tend to hold positions for shorter\ndurations, whereas DDPG, A2C, and TD3 display a propensity to remain stationary\nfor extended periods.\n"
    },
    {
        "paper_id": 2407.09638,
        "authors": "Matthew J. Baker and Joyce P. Jacobsen",
        "title": "Cultural Transmission, Technology, and Treatment of the Elderly",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We discuss the interrelationship between the treatment of the elderly, the\nnature of production, and the transmission of culture. Respect for the elderly\nis endogenous. Parents cultivate an interest in consuming culture in their\nchildren; when they are older, children compensate their elders proportional to\nthe degree to which their interests were previously cultivated. We show that\nthis model is functionally equivalent to one in which cultural goods are\ntransferred across generations. We focus on the relative well-being of the\nelderly and use the model to explain patterns in their relative well-being\nacross societies. An important theme is that the cultivation of culture and\nnorms for the respect and support of the elderly bear a nonlinear relationship\nwith many economic variables, such as capital and or land intensity in\nproduction. We also discuss the interaction of property rights with production,\nassets such as productive resources, and relative treatment of the elderly.\nInsecurity of some types of property rights, such as rights over output, may\nbenefit the elderly, while secure rights over productive resources may also\nbenefit the elderly. We discuss how the elderly could be affected by\ndemographic, technological and policy changes in both developing and developed\neconomies.\n"
    },
    {
        "paper_id": 2407.09695,
        "authors": "Fausto Hern\\'andez Trillo, C. Vladimir Rodr\\'iguez-Caballero, Daniel\n  Ventosa-Santaul\\`aria",
        "title": "Monopoly Unveiled: Telecom Breakups in the US and Mexico",
        "comments": "25 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper posits the decline in market capitalization following a monopoly\nbreakup serves as a means to gauge how financial markets assess market power.\nOur research, which employs univariate structural time series models to\nestimate the firm's value without the breakup and juxtapose it with actual\npost-divestiture values, reveals a staggering drop in AT&T's value by 65% and\nAMX's by 32% from their pre-breakup levels. These findings underscore the\ncontemporary valuation of monopoly rents as perceived by financial markets,\nhighlighting the significant impact of monopoly breakup on market\ncapitalization and the need for a deeper understanding of these dynamics.\n"
    },
    {
        "paper_id": 2407.09711,
        "authors": "Fahimeh Asgari, Seyedeh Gol Ara Ghoreishi, Matin Khajavi, Ali Foozoni,\n  Ali Ala, Ahmad Gholizadeh Lonbar",
        "title": "Data Analysis of Decision Support for Sustainable Welfare in The\n  Presence of GDP Threshold Effects: A Case Study of Interactive Data\n  Exploration",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Energy usage and GDP have been the subject of numerous studies over the past\ndecades. It has been overlooked by previous studies that energy consumption\ncorrelates with economic growth in relation to GDP. This study uses threshold\nregression and Granger causality testing to identify GDP-dependent causality in\nten OECD countries over the last 10 years. There is a significant correlation\nbetween economic growth and energy consumption. Energy consumption and\nshort-term economic growth are statistically significantly correlated. There is\na significant positive effect of energy consumption (EC) on GDP in the short\nrun below the threshold of $10,936 USD since the coefficient is 3.34 and the\np-value is 0.0252. There is a -0.0127-correlation coefficient and a 0.0327\np-value associated with GDP Granger-cause EC over the long run. EC and GDP are\nnot causally related for GDP per capita above $10,936 USD. In the long run, GDP\nGranger causes EC with a coefficient of -0.1638 and a p-value of 0.0675.\nAccording to the study, sustainable development requires sustainable use of\nnatural resources, technological investment, foreign direct investment, and\ngross fixed capital formation. Economic growth can be boosted while adhering to\nsustainability goals by implementing these recommendations.\n"
    },
    {
        "paper_id": 2407.09736,
        "authors": "Jacob Morrier, Amine Mahmassani and R. Michael Alvarez",
        "title": "Uncovering the Effect of Toxicity on Player Engagement and its\n  Propagation in Competitive Online Video Games",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This article seeks to provide accurate estimates of the causal effect of\nexposure to toxic language on player engagement and the proliferation of toxic\nlanguage. To this end, we analyze proprietary data from the first-person action\nvideo game Call of Duty: Modern Warfare III, published by Activision. To\novercome causal identification problems, we implement an instrumental variables\nestimation strategy. Our findings confirm that exposure to toxic language\nsignificantly affects player engagement and the probability that players use\nsimilar language. Accordingly, video game publishers have a vested interest in\naddressing toxic language. Further, we demonstrate that this effect varies\nsignificantly depending on whether toxic language originates from opponents or\nteammates, whether it originates from teammates in the same party or a\ndifferent party, and the match's outcome. This has meaningful implications\nregarding how resources for addressing toxicity should be allocated.\n"
    },
    {
        "paper_id": 2407.09738,
        "authors": "Zhaoxing Gao",
        "title": "Sparse Asymptotic PCA: Identifying Sparse Latent Factors Across Time\n  Horizon",
        "comments": "66 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper proposes a novel method for sparse latent factor modeling using a\nnew sparse asymptotic Principal Component Analysis (APCA). This approach\nanalyzes the co-movements of large-dimensional panel data systems over time\nhorizons within a general approximate factor model framework. Unlike existing\nsparse factor modeling approaches based on sparse PCA, which assume sparse\nloading matrices, our sparse APCA assumes that factor processes are sparse over\nthe time horizon, while the corresponding loading matrices are not necessarily\nsparse. This development is motivated by the observation that the assumption of\nsparse loadings may not be appropriate for financial returns, where exposure to\nmarket factors is generally universal and non-sparse. We propose a truncated\npower method to estimate the first sparse factor process and a sequential\ndeflation method for multi-factor cases. Additionally, we develop a data-driven\napproach to identify the sparsity of risk factors over the time horizon using a\nnovel cross-sectional cross-validation method. Theoretically, we establish that\nour estimators are consistent under mild conditions. Monte Carlo simulations\ndemonstrate that the proposed method performs well in finite samples.\nEmpirically, we analyze daily stock returns for a balanced panel of S&P 500\nstocks from January 2004 to December 2016. Through textual analysis, we examine\nspecific events associated with the identified sparse factors that\nsystematically influence the stock market. Our approach offers a new pathway\nfor economists to study and understand the systematic risks of economic and\nfinancial systems over time.\n"
    },
    {
        "paper_id": 2407.09795,
        "authors": "Hyoji Choi and Jonghyun Kim and Donghyeon Yu and Bogang Jun",
        "title": "Population Concentration in High-Complexity Regions within City during\n  the heat wave",
        "comments": "26 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study investigates the impact of the 2018 summer heat wave on urban\nmobility in Seoul and the role of economic complexity in the region's\nresilience. Findings from subway and mobile phone data indicate a significant\ndecrease in the floating population during extreme heat wave, underscoring the\nthermal vulnerability of urban areas. However, urban regions with higher\ncomplexity demonstrate resilience, attracting more visitors despite high\ntemperatures. Our results suggest the centrality of economic complexity in\nurban resilience against climate-induced stressors. Additionally, it implies\nthat high-complexity small businesses' clusters can serve as focal points for\nsustaining urban vitality in the face of thermal shocks within city. In the\nlong run perspective, our results imply the possibility that people are more\nconcentrated in high complexity region in the era of global warming.\n"
    },
    {
        "paper_id": 2407.09831,
        "authors": "Han Gui",
        "title": "Machine learning in weekly movement prediction",
        "comments": "29 pages, 32 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  To predict the future movements of stock markets, numerous studies\nconcentrate on daily data and employ various machine learning (ML) models as\nbenchmarks that often vary and lack standardization across different research\nworks. This paper tries to solve the problem from a fresh standpoint by aiming\nto predict the weekly movements, and introducing a novel benchmark of random\ntraders. This benchmark is independent of any ML model, thus making it more\nobjective and potentially serving as a commonly recognized standard. During\ntraining process, apart from the basic features such as technical indicators,\nscaling laws and directional changes are introduced as additional features,\nfurthermore, the training datasets are also adjusted by assigning varying\nweights to different samples, the weighting approach allows the models to\nemphasize specific samples. On back-testing, several trained models show good\nperformance, with the multi-layer perception (MLP) demonstrating stability and\nrobustness across extensive and comprehensive data that include upward,\ndownward and cyclic trends. The unique perspective of this work that focuses on\nweekly movements, incorporates new features and creates an objective benchmark,\ncontributes to the existing literature on stock market prediction.\n"
    },
    {
        "paper_id": 2407.10175,
        "authors": "Parley R Yang and Alexander Y Shestopaloff",
        "title": "Low Volatility Stock Portfolio Through High Dimensional Bayesian\n  Cointegration",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We employ a Bayesian modelling technique for high dimensional cointegration\nestimation to construct low volatility portfolios from a large number of\nstocks. The proposed Bayesian framework effectively identifies sparse and\nimportant cointegration relationships amongst large baskets of stocks across\nvarious asset spaces, resulting in portfolios with reduced volatility. Such\ncointegration relationships persist well over the out-of-sample testing time,\nproviding practical benefits in portfolio construction and optimization.\nFurther studies on drawdown and volatility minimization also highlight the\nbenefits of including cointegrated portfolios as risk management instruments.\n"
    },
    {
        "paper_id": 2407.10247,
        "authors": "Marc Schmitt",
        "title": "Strategic Integration of Artificial Intelligence in the C-Suite: The\n  Role of the Chief AI Officer",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The integration of Artificial Intelligence (AI) into corporate strategy has\nbecome a pivotal focus for organizations aiming to maintain a competitive\nadvantage in the digital age. As AI reshapes business operations and drives\ninnovation, the need for specialized leadership to effectively manage these\nchanges becomes increasingly apparent. In this paper, I explore the role of the\nChief AI Officer (CAIO) within the C-suite, emphasizing the necessity of this\nposition for successful AI strategy, integration, and governance. I analyze\nfuture scenarios based on current trends in three key areas: the AI Economy, AI\nOrganization, and Competition in the Age of AI. These explorations lay the\nfoundation for identifying the antecedents (environmental, structural, and\nstrategic factors) that justify the inclusion of a CAIO in top management\nteams. This sets the stage for a comprehensive examination of the CAIO's role\nand the broader implications of AI leadership. This paper advances the\ndiscussion on AI leadership by providing a rationale for the strategic\nintegration of AI at the executive level and examining the role of the Chief AI\nOfficer within organizations.\n"
    },
    {
        "paper_id": 2407.10284,
        "authors": "Jean-Philippe Bouchaud",
        "title": "The Self-Organized Criticality Paradigm in Economics & Finance",
        "comments": "Chapter for the proceedings of a Santa Fe summer school",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  ``Self-Organised Criticality'' (SOC) is the mechanism by which complex\nsystems spontaneously settle close to a *critical point*, at the edge between\nstability and chaos, and characterized by fat-tailed fluctuations and\nlong-memory correlations. Such a scenario may explain why insignificant\nperturbations can generate large disruptions, through the propagation of\n``avalanches'' across the system. In this short review, we discuss how SOC\ncould offer a plausible solution to the excess volatility puzzle in financial\nmarkets and the analogue ``small shocks, large business cycle puzzle'' for the\neconomy at large, as initially surmised by Per Bak et al. in 1993. We argue\nthat in general the quest for efficiency and the necessity of *resilience* may\nbe mutually incompatible and require specific policy considerations.\n"
    },
    {
        "paper_id": 2407.10426,
        "authors": "Yuval Boneh",
        "title": "Adaptive Money Market Interest Rate Strategy Utilizing Control Theory",
        "comments": null,
        "journal-ref": null,
        "doi": "10.2139/ssrn.4810469",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Decentralized Finance (DeFi) money markets have seen explosive growth in\nrecent years, with billions of dollars borrowed in various cryptocurrency\nassets. Key to the safety of money markets is the implementation of interest\nrates that determine the cost of borrowing, and govern counterparty exposure\nand return. In traditional markets, interest rates are set by risk managers,\nportfolio managers, the Federal Reserve, and a myriad of other sources\ndepending on the market function. DeFi enables an algorithmic approach that\ntypically relies on interest rates being directly dependent on market\nutilization. The benefit of algorithmic interest rate management is the\nsystem's continual response to market behaviors in real time, and thus an\ninherent ability to mitigate risks on behalf of protocols and users. These\ninterest rate strategies target an optimal utilization based on the protocol's\nrisk threshold, but historically lack the ability to compensate for excessive\nor diminished utilization over time. This research investigates contemporary\nDeFi interest rate management strategies and their limitations. Furthermore,\nthis paper introduces a time-weighted approach to interest rate management that\nimplements a Proportional-Integral-Derivative (PID) control system to\nconstantly adapt to market utilization patterns, addressing observed\nlimitations.\n"
    },
    {
        "paper_id": 2407.10561,
        "authors": "\\'Alvaro Cartea, Sebastian Jaimungal, Leandro S\\'anchez-Betancourt",
        "title": "Nash Equilibrium between Brokers and Traders",
        "comments": "24 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study the perfect information Nash equilibrium between a broker and her\nclients -- an informed trader and an uniformed trader. In our model, the broker\ntrades in the lit exchange where trades have instantaneous and transient price\nimpact with exponential resilience, while both clients trade with the broker.\nThe informed trader and the broker maximise expected wealth subject to\ninventory penalties, while the uninformed trader is not strategic and sends the\nbroker random buy and sell orders. We characterise the Nash equilibrium of the\ntrading strategies with the solution to a coupled system of forward-backward\nstochastic differential equations (FBSDEs). We solve this system explicitly and\nstudy the effect of information, profitability, and inventory control in the\ntrading strategies of the broker and the informed trader.\n"
    },
    {
        "paper_id": 2407.10659,
        "authors": "Carsten H. Chong and Viktor Todorov",
        "title": "A nonparametric test for rough volatility",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We develop a nonparametric test for deciding whether volatility of an asset\nfollows a standard semimartingale process, with paths of finite quadratic\nvariation, or a rough process with paths of infinite quadratic variation. The\ntest utilizes the fact that volatility is rough if and only if volatility\nincrements are negatively autocorrelated at high frequencies. It is based on\nthe sample autocovariance of increments of spot volatility estimates computed\nfrom high-frequency asset return data. By showing a feasible CLT for this\nstatistic under the null hypothesis of semimartingale volatility paths, we\nconstruct a test with fixed asymptotic size and an asymptotic power equal to\none. The test is derived under very general conditions for the data-generating\nprocess. In particular, it is robust to jumps with arbitrary activity and to\nthe presence of market microstructure noise. In an application of the test to\nSPY high-frequency data, we find evidence for rough volatility.\n"
    },
    {
        "paper_id": 2407.10773,
        "authors": "Arslan Ahmad, Ian Dobson",
        "title": "Quantifying distribution system resilience from utility data: large\n  event risk and benefits of investments",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We focus on large blackouts in electric distribution systems caused by\nextreme winds. Such events have a large cost and impact on customers. To\nquantify resilience to these events, we formulate large event risk and show how\nto calculate it from the historical outage data routinely collected by\nutilities' outage management systems. Risk is defined using an event cost\nexceedance curve. The tail of this curve and the large event risk is described\nby the probability of a large cost event and the slope magnitude of the tail on\na log-log plot. Resilience can be improved by planned investments to upgrade\nsystem components or speed up restoration. The benefits that these investments\nwould have had if they had been made in the past can be quantified by\n\"rerunning history\" with the effects of the investment included, and then\nrecalculating the large event risk to find the improvement in resilience. An\nexample using utility data shows a 12% and 22% reduction in the probability of\na large cost event due to 10% wind hardening and 10% faster restoration\nrespectively. This new data-driven approach to quantify resilience and\nresilience investments is realistic and much easier to apply than complicated\napproaches based on modeling all the phases of resilience. Moreover, an appeal\nto improvements to past lived experience may well be persuasive to customers\nand regulators in making the case for resilience investments.\n"
    },
    {
        "paper_id": 2407.10909,
        "authors": "Xiaohui Victor Li, Francesco Sanna Passino",
        "title": "FinDKG: Dynamic Knowledge Graphs with Large Language Models for\n  Detecting Global Trends in Financial Markets",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Dynamic knowledge graphs (DKGs) are popular structures to express different\ntypes of connections between objects over time. They can also serve as an\nefficient mathematical tool to represent information extracted from complex\nunstructured data sources, such as text or images. Within financial\napplications, DKGs could be used to detect trends for strategic thematic\ninvesting, based on information obtained from financial news articles. In this\nwork, we explore the properties of large language models (LLMs) as dynamic\nknowledge graph generators, proposing a novel open-source fine-tuned LLM for\nthis purpose, called the Integrated Contextual Knowledge Graph Generator\n(ICKG). We use ICKG to produce a novel open-source DKG from a corpus of\nfinancial news articles, called FinDKG, and we propose an attention-based GNN\narchitecture for analysing it, called KGTransformer. We test the performance of\nthe proposed model on benchmark datasets and FinDKG, demonstrating superior\nperformance on link prediction tasks. Additionally, we evaluate the performance\nof the KGTransformer on FinDKG for thematic investing, showing it can\noutperform existing thematic ETFs.\n"
    },
    {
        "paper_id": 2407.11465,
        "authors": "Hongjian Wang, Aaditya Ramdas",
        "title": "Testing by Betting while Borrowing and Bargaining",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Testing by betting has been a cornerstone of the game-theoretic statistics\nliterature. In this framework, a betting score (or more generally an\ne-process), as opposed to a traditional p-value, is used to quantify the\nevidence against a null hypothesis: the higher the betting score, the more\nmoney one has made betting against the null, and thus the larger the evidence\nthat the null is false. A key ingredient assumed throughout past works is that\none cannot bet more money than one currently has. In this paper, we ask what\nhappens if the bettor is allowed to borrow money after going bankrupt, allowing\nfurther financial flexibility in this game of hypothesis testing. We propose\nvarious definitions of (adjusted) evidence relative to the wealth borrowed,\nindebted, and accumulated. We also ask what happens if the bettor can\n\"bargain\", in order to obtain odds bettor than specified by the null\nhypothesis. The adjustment of wealth in order to serve as evidence appeals to\nthe characterization of arbitrage, interest rates, and num\\'eraire-adjusted\npricing in this setting.\n"
    },
    {
        "paper_id": 2407.11716,
        "authors": "Walter Hernandez Cruz, Jiahua Xu, Paolo Tasca, and Carlo Campajola",
        "title": "No Questions Asked: Effects of Transparency on Stablecoin Liquidity\n  During the Collapse of Silicon Valley Bank",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Fiat-pegged stablecoins are by nature exposed to spillover effects during\nmarket turmoil in Traditional Finance (TradFi). We observe a difference in\nTradFi market shocks impact between various stablecoins, in particular, USD\nCoin (USDC) and Tether USDT (USDT), the former with a higher reporting\nfrequency and transparency than the latter. We investigate this, using top USDC\nand USDT liquidity pools in Uniswap, by adapting the Marginal Cost of Immediacy\n(MCI) measure to Uniswap's Automated Market Maker, and then conducting\nDifference-in-Differences analysis on MCI and Total Value Locked (TVL) in USD,\nas well as measuring liquidity concentration across different providers.\nResults show that the Silicon Valley Bank (SVB) event reduced USDC's TVL\ndominance over USDT, increased USDT's liquidity cost relative to USDC, and\nliquidity provision remained concentrated with pool-specific trends. These\nfindings reveal a flight-to-safety behavior and counterintuitive effects of\nstablecoin transparency: USDC's frequent and detailed disclosures led to swift\nmarket reactions, while USDT's opacity and less frequent reporting provided a\nsafety net against immediate impacts.\n"
    },
    {
        "paper_id": 2407.11761,
        "authors": "Felix Fie{\\ss}inger and Mitja Stadje",
        "title": "Mean-Variance Optimization for Participating Life Insurance Contracts",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the equity holders' mean-variance optimal portfolio choice\nproblem for (non-)protected participating life insurance contracts. We derive\nexplicit formulas for the optimal terminal wealth and the optimal strategy in\nthe multi-dimensional Black-Scholes model, showing the existence of all\nnecessary parameters. In incomplete markets, we state Hamilton-Jacobi-Bellman\nequations for the value function. Moreover, we provide a numerical analysis of\nthe Black-Scholes market. The equity holders on average increase their\ninvestment into the risky asset in bad economic states and decrease their\ninvestment over time.\n"
    },
    {
        "paper_id": 2407.12032,
        "authors": "Brian Jabarian",
        "title": "Large Language Models for Behavioral Economics: Internal Validity and\n  Elicitation of Mental Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  In this article, we explore the transformative potential of integrating\ngenerative AI, particularly Large Language Models (LLMs), into behavioral and\nexperimental economics to enhance internal validity. By leveraging AI tools,\nresearchers can improve adherence to key exclusion restrictions and in\nparticular ensure the internal validity measures of mental models, which often\nrequire human intervention in the incentive mechanism. We present a case study\ndemonstrating how LLMs can enhance experimental design, participant engagement,\nand the validity of measuring mental models.\n"
    },
    {
        "paper_id": 2407.12044,
        "authors": "Aditya Saxena, Dr Parizad Dungore",
        "title": "Credit Risk Assessment Model for UAE Commercial Banks: A Machine\n  Learning Approach",
        "comments": null,
        "journal-ref": "National Undergraduate Research, Abu Dhabi University - 2021",
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Credit ratings are becoming one of the primary references for financial\ninstitutions of the country to assess credit risk in order to accurately\npredict the likelihood of business failure of an individual or an enterprise.\nFinancial institutions, therefore, depend on credit rating tools and services\nto help them predict the ability of creditors to meet financial persuasions.\nConventional credit rating is broadly categorized into two classes namely: good\ncredit and bad credit. This approach lacks adequate precision to perform credit\nrisk analysis in practice. Related studies have shown that data-driven machine\nlearning algorithms outperform many conventional statistical approaches in\nsolving this type of problem, both in terms of accuracy and efficiency. The\npurpose of this paper is to construct and validate a credit risk assessment\nmodel using Linear Discriminant Analysis as a dimensionality reduction\ntechnique to discriminate good creditors from bad ones and identify the best\nclassifier for credit assessment of commercial banks based on real-world data.\nThis will help commercial banks to avoid monetary losses and prevent financial\ncrisis\n"
    },
    {
        "paper_id": 2407.1215,
        "authors": "Ravi Kashyap",
        "title": "To Trade Or Not To Trade: Cascading Waterfall Round Robin Rebalancing\n  Mechanism for Cryptocurrencies",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have designed an innovative portfolio rebalancing mechanism termed the\nCascading Waterfall Round Robin Mechanism. This algorithmic approach recommends\nan ideal size and number of trades for each asset during the periodic\nrebalancing process, factoring in the gas fee and slippage. The essence of the\nmodel we have created gives indications regarding whether trades should be made\non individual assets depending on the uncertainty in the micro - asset level\ncharacteristics - and macro - aggregate market factors - environments. In the\nhyper-volatile crypto market, our approach to daily rebalancing will benefit\nfrom volatility. Price movements will cause our algorithm to buy assets that\ndrop in prices and sell as they soar. In fact, the buying and selling happen\nonly when certain boundaries are crossed in order to weed out any market noise\nand ensure sound trade execution. We have provided several numerical examples\nto illustrate the steps - including the calculation of several intermediate\nvariables - of our rebalancing mechanism. The Algorithm we have developed can\nbe easily applied outside blockchain to investment funds across all asset\nclasses at any trading frequency and rebalancing duration.\n  Shakespeare As A Crypto Trader:\n  To Trade Or Not To Trade, that is the Question,\n  Whether an Optimizer can Yield the Answer,\n  Against the Spikes and Crashes of Markets Gone Wild,\n  To Quench One's Thirst before Liquidity Runs Dry,\n  Or Wait till the Tide of Momentum turns Mild.\n"
    },
    {
        "paper_id": 2407.12683,
        "authors": "Riccardo De Blasis, Luca Galati, Rosanna Grassi, Giorgio Rizzini",
        "title": "Information Flow in the FTX Bankruptcy: A Network Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper investigates the cryptocurrency network of the FTX exchange during\nthe collapse of its native token, FTT, to understand how network structures\nadapt to significant financial disruptions, by exploiting vertex centrality\nmeasures. Using proprietary data on the transactional relationships between\nvarious cryptocurrencies, we construct the filtered correlation matrix to\nidentify the most significant relations in the FTX and Binance markets. By\nusing suitable centrality measures - closeness and information centrality - we\nassess network stability during FTX's bankruptcy. The findings document the\nappropriateness of such vertex centralities in understanding the resilience and\nvulnerabilities of financial networks. By tracking the changes in centrality\nvalues before and during the FTX crisis, this study provides useful insights\ninto the structural dynamics of the cryptocurrency market. Results reveal how\ndifferent cryptocurrencies experienced shifts in their network roles due to the\ncrisis. Moreover, our findings highlight the interconnectedness of\ncryptocurrency markets and how the failure of a single entity can lead to\nwidespread repercussions that destabilize other nodes of the network.\n"
    },
    {
        "paper_id": 2407.12754,
        "authors": "Gianmarco Del Sarto, Marta Leocata, Giulia Livieri",
        "title": "A Mean Field Game approach for pollution regulation of competitive firms",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We develop a model based on mean-field games of competitive firms producing\nsimilar goods according to a standard AK model with a depreciation rate of\ncapital generating pollution as a byproduct. Our analysis focuses on the\nwidely-used cap-and-trade pollution regulation. Under this regulation, firms\nhave the flexibility to respond by implementing pollution abatement, reducing\noutput, and participating in emission trading, while a regulator dynamically\nallocates emission allowances to each firm. The resulting mean-field game is of\nlinear quadratic type and equivalent to a mean-field type control problem,\ni.e., it is a potential game. We find explicit solutions to this problem\nthrough the solutions to differential equations of Riccati type. Further, we\ninvestigate the carbon emission equilibrium price that satisfies the market\nclearing condition and find a specific form of FBSDE of McKean-Vlasov type with\ncommon noise. The solution to this equation provides an approximate equilibrium\nprice. Additionally, we demonstrate that the degree of competition is vital in\ndetermining the economic consequences of pollution regulation.\n"
    },
    {
        "paper_id": 2407.12774,
        "authors": "Paul S. Koh",
        "title": "Market Definition: A Sensitivity Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Market definition holds significant importance in antitrust cases, yet\nachieving consensus on the correct approach remains elusive. As a result,\nanalysts routinely entertain multiple market definitions to ensure the\nresilience of their conclusions. I propose a simple framework for conducting\norganized sensitivity analysis with respect to market definition. I model\ncandidate market definitions as partially ordered and use a Hasse diagram, a\ndirected acyclic graph representing a finite partial order, to summarize the\nsensitivity analysis. I use the Shapley value and the Shapley-Shubik power\nindex to quantify the average marginal contribution of each firm in driving the\nconclusion. I illustrate the method's usefulness with an application to the\nAlbertsons/Safeway (2015) merger.\n"
    },
    {
        "paper_id": 2407.12775,
        "authors": "Kevin L. McKinney and John M. Abowd",
        "title": "Estimating the Potential Impact of Combined Race and Ethnicity Reporting\n  on Long-Term Earnings Statistics",
        "comments": "CRIW Conference Race, Ethnicity, and Economic Statistics for the 21st\n  Century, Spring 2024",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We use place of birth information from the Social Security Administration\nlinked to earnings data from the Longitudinal Employer-Household Dynamics\nProgram and detailed race and ethnicity data from the 2010 Census to study how\nlong-term earnings differentials vary by place of birth for different\nself-identified race and ethnicity categories. We focus on foreign-born persons\nfrom countries that are heavily Hispanic and from countries in the Middle East\nand North Africa (MENA). We find substantial heterogeneity of long-term\nearnings differentials within country of birth, some of which will be difficult\nto detect when the reporting format changes from the current two-question\nversion to the new single-question version because they depend on\nself-identifications that place the individual in two distinct categories\nwithin the single-question format, specifically, Hispanic and White or Black,\nand MENA and White or Black. We also study the USA-born children of these same\nimmigrants. Long-term earnings differences for the 2nd generation also vary as\na function of self-identified ethnicity and race in ways that changing to the\nsingle-question format could affect.\n"
    },
    {
        "paper_id": 2407.12837,
        "authors": "Tomohiro Uchiyama",
        "title": "Keynesian chaos revisited: odd period cycles and ergodic properties",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study two standard (Keynesian) dynamic macroeconomic models\n(one is piecewise linear and the other is nonlinear). Our purpose is twofold:\n(1)~For each model, we give a complete characterisation for the existence of a\ntopological chaos (of the GDP levels), (2)~Even if a chaos exists, using\nergodic theory, we show that it is possible to predict the future GDP levels\n\"on average\". This paper gives a new application of a celebrated result in\nergodic theory by A. Avila (2014 fields medalist). We believe that our\nmethod/strategy in this paper is generic enough to be used to analyse many\nother (seemingly untractable) chaotic economic models.\n"
    },
    {
        "paper_id": 2407.12924,
        "authors": "Paul S. Koh",
        "title": "Concentration-Based Inference for Evaluating Horizontal Mergers",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Antitrust authorities routinely rely on concentration measures to evaluate\nthe potential negative impacts of mergers. Using a first-order approximation\nargument with logit and CES demand, I show that the welfare effect of a merger\non consumer surplus is proportional to the change in the Herfindahl-Hirschman\nindex, where the proportionality coefficient depends on price responsiveness\nparameter, market size, and the distribution of merging firms' shares. This\npaper elucidates how HHI measures inform the market power effects of mergers.\n"
    },
    {
        "paper_id": 2407.12953,
        "authors": "Tillmann von Carnap (1), Reza M. Asiyabi (2 and 3), Paul Dingus (1),\n  Anna Tompsett (4 and 5) ((1) Center on Food Security and the Environment,\n  Stanford University, Stanford, United States of America, (2) Mistra Center\n  for Sustainable Markets, Stockholm School of Economics, Stockholm, Sweden,\n  (3) School of GeoScience, University of Edinburgh, Edinburgh, United Kingdom,\n  (4) Beijer Institute of Ecological Economics, The Royal Swedish Academy of\n  Sciences, Stockholm, Sweden, (5) Institute for International Economic\n  Studies, Stockholm University, Stockholm, Sweden)",
        "title": "Using satellite imagery to monitor remote rural economies at high\n  frequency",
        "comments": "12 pages with 4 figures, Supplementary Materials for 15 pages with 6\n  figures and 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Despite global progress in reducing extreme poverty, stubborn pockets remain,\noften in remote and fragile regions. A fundamental obstacle to further progress\nis that remoteness and fragility also constrain data collection on economic\nconditions. We present a new approach to monitor remote economies using\nsatellite images that capture activity at periodic markets, focal points for\nrural trade throughout history and much of the world today. We describe how to\ndetect markets without pre-existing maps and how to construct an up-to-weekly\nmeasure of their activity. We show that we successfully detect markets and that\nactivity correlates with other measures of economic conditions, captures\nseasonal patterns, and responds to local weather and conflict. The imagery's\nglobal availability and high frequency enable real-time monitoring independent\nof ground conditions.\n"
    },
    {
        "paper_id": 2407.13204,
        "authors": "Richard Audoly and Manudeep Bhuller and Tore Adam Reiremo",
        "title": "The Pay and Non-Pay Content of Job Ads",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  How informative are job ads about the actual pay and amenities offered by\nemployers? Using a comprehensive database of job ads posted by Norwegian\nemployers, we develop a methodology to systematically classify the information\non both pay and non-pay job attributes advertised in vacancy texts. We link\nthis information to measures of employer attractiveness, which we derive from a\njob search model estimated on observed wages and worker mobility flows. About\n55 percent of job ads provide information related to pay and nearly all ads\nfeature information on non-pay attributes. We show that publicly advertised job\nattributes are meaningful predictors of employer attractiveness, and non-pay\nattributes are about as predictive as pay-related attributes. High-pay\nemployers mention pay-related attributes more often, while high-amenity\nemployers are more likely to advertise flexible working hours and contract\nduration.\n"
    },
    {
        "paper_id": 2407.13213,
        "authors": "Ludovic Goudenege, Andrea Molent, Antonino Zanette",
        "title": "Leveraging Machine Learning for High-Dimensional Option Pricing within\n  the Uncertain Volatility Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper explores the application of Machine Learning techniques for\npricing high-dimensional options within the framework of the Uncertain\nVolatility Model (UVM). The UVM is a robust framework that accounts for the\ninherent unpredictability of market volatility by setting upper and lower\nbounds on volatility and the correlation among underlying assets. By leveraging\nhistorical data and extreme values of estimated volatilities and correlations,\nthe model establishes a confidence interval for future volatility and\ncorrelations, thus providing a more realistic approach to option pricing. By\nintegrating advanced Machine Learning algorithms, we aim to enhance the\naccuracy and efficiency of option pricing under the UVM, especially when the\noption price depends on a large number of variables, such as in basket or\npath-dependent options. Our approach evolves backward in time, dynamically\nselecting at each time step the most expensive volatility and correlation for\neach market state. Specifically, it identifies the particular values of\nvolatility and correlation that maximize the expected option value at the next\ntime step. This is achieved through the use of Gaussian Process regression, the\ncomputation of expectations via a single step of a multidimensional tree and\nthe Sequential Quadratic Programming optimization algorithm. The numerical\nresults demonstrate that the proposed approach can significantly improve the\nprecision of option pricing and risk management strategies compared with\nmethods already in the literature, particularly in high-dimensional contexts.\n"
    },
    {
        "paper_id": 2407.13232,
        "authors": "Yuval Boneh",
        "title": "Autonomous Money Supply Strategy Utilizing Control Theory",
        "comments": null,
        "journal-ref": null,
        "doi": "10.2139/ssrn.4844212",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Decentralized Finance (DeFi) has reshaped the possibilities of reserve\nbanking in the form of the Collateralized Debt Position (CDP). Key to the\nsafety of CDPs is the money supply architecture that enables issued debt to\nmaintain its value. In traditional markets, and with respect to the United\nStates Dollar system, interest rates are set by the Federal Reserve in an\nattempt to influence the effects of excessive inflation. DeFi enables a more\ntransparent approach that typically relies on interest rates or other debt\nrecovery mechanisms being directly informed by asset price. This research\ninvestigates contemporary DeFi money supply and debt management strategies and\ntheir limitations. Furthermore, this paper introduces a time-weighted approach\nto interest rate management that implements a Proportional-Integral-Derivative\ncontrol system to constantly adapt to market activities and protect the value\nof issued currency, while addressing observed limitations.\n"
    },
    {
        "paper_id": 2407.13547,
        "authors": "Tae Ung Gang, Jin Hyuk Choi",
        "title": "Unified Asymptotics For Investment Under Illiquidity: Transaction Costs\n  And Search Frictions",
        "comments": "45 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the optimal investment problem in a market with two\ntypes of illiquidity: transaction costs and search frictions. Extending the\nframework established by arXiv:2101.09936, we analyze a power-utility\nmaximization problem where an investor encounters proportional transaction\ncosts and trades only when a Poisson process triggers trading opportunities. We\nshow that the optimal trading strategy is described by a no-trade region. We\nintroduce a novel asymptotic framework applicable when both transaction costs\nand search frictions are small. Using this framework, we derive explicit\nasymptotics for the no-trade region and the value function along a specific\nparametric curve. This approach unifies existing asymptotic results for models\ndealing exclusively with either transaction costs or search frictions.\n"
    },
    {
        "paper_id": 2407.13659,
        "authors": "Kerri Lu, Stephen Bates, Sherrie Wang",
        "title": "Quantifying uncertainty in area and regression coefficient estimation\n  from remote sensing maps",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Remote sensing map products are used to obtain estimates of environmental\nquantities, such as deforested area or the effect of conservation zones on\ndeforestation. However, the quality of map products varies, and - because maps\nare outputs of complex machine learning algorithms that take in a variety of\nremotely sensed variables as inputs - errors are difficult to characterize.\nWithout capturing the biases that may be present, naive calculations of\npopulation-level estimates from such maps are statistically invalid. In this\npaper, we compare several uncertainty quantification methods - stratification,\nOlofsson area estimation method, and prediction-powered inference - that\ncombine a small amount of randomly sampled ground truth data with large-scale\nremote sensing map products to generate statistically valid estimates. Applying\nthese methods across four remote sensing use cases in area and regression\ncoefficient estimation, we find that they result in estimates that are more\nreliable than naively using the map product as if it were 100% accurate and\nhave lower uncertainty than using only the ground truth and ignoring the map\nproduct. Prediction-powered inference uses ground truth data to correct for\nbias in the map product estimate and (unlike stratification) does not require\nus to choose a map product before sampling. This is the first work to (1) apply\nprediction-powered inference to remote sensing estimation tasks, and (2)\nperform uncertainty quantification on remote sensing regression coefficients\nwithout assumptions on the structure of map product errors. To improve the\nutility of machine learning-generated remote sensing maps for downstream\napplications, we recommend that map producers provide a holdout ground truth\ndataset to be used for calibration in uncertainty quantification alongside\ntheir maps.\n"
    },
    {
        "paper_id": 2407.13685,
        "authors": "Fernando Berzal and Alberto Garcia",
        "title": "Beyond Trend Following: Deep Learning for Market Trend Prediction",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Trend following and momentum investing are common strategies employed by\nasset managers. Even though they can be helpful in the proper situations, they\nare limited in the sense that they work just by looking at past, as if we were\ndriving with our focus on the rearview mirror. In this paper, we advocate for\nthe use of Artificial Intelligence and Machine Learning techniques to predict\nfuture market trends. These predictions, when done properly, can improve the\nperformance of asset managers by increasing returns and reducing drawdowns.\n"
    },
    {
        "paper_id": 2407.13687,
        "authors": "Jing Xu, Yung-Cheng Hsu, William Biscarri",
        "title": "Dynamic Pricing in Securities Lending Market: Application in Revenue\n  Optimization for an Agent Lender Portfolio",
        "comments": "7 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Securities lending is an important part of the financial market structure,\nwhere agent lenders help long term institutional investors to lend out their\nsecurities to short sellers in exchange for a lending fee. Agent lenders within\nthe market seek to optimize revenue by lending out securities at the highest\nrate possible. Typically, this rate is set by hard-coded business rules or\nstandard supervised machine learning models. These approaches are often\ndifficult to scale and are not adaptive to changing market conditions. Unlike a\ntraditional stock exchange with a centralized limit order book, the securities\nlending market is organized similarly to an e-commerce marketplace, where agent\nlenders and borrowers can transact at any agreed price in a bilateral fashion.\nThis similarity suggests that the use of typical methods for addressing dynamic\npricing problems in e-commerce could be effective in the securities lending\nmarket. We show that existing contextual bandit frameworks can be successfully\nutilized in the securities lending market. Using offline evaluation on real\nhistorical data, we show that the contextual bandit approach can consistently\noutperform typical approaches by at least 15% in terms of total revenue\ngenerated.\n"
    },
    {
        "paper_id": 2407.13688,
        "authors": "Nacira Agram, Bernt {\\O}ksendal, Jan Rems",
        "title": "Deep learning for quadratic hedging in incomplete jump market",
        "comments": "Digit Finance (2024)",
        "journal-ref": null,
        "doi": "10.1007/s42521-024-00112-5",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We propose a deep learning approach to study the minimal variance pricing and\nhedging problem in an incomplete jump diffusion market. It is based upon a\nrigorous stochastic calculus derivation of the optimal hedging portfolio,\noptimal option price, and the corresponding equivalent martingale measure\nthrough the means of the Stackelberg game approach. A deep learning algorithm\nbased on the combination of the feedforward and LSTM neural networks is tested\non three different market models, two of which are incomplete. In contrast, the\ncomplete market Black-Scholes model serves as a benchmark for the algorithm's\nperformance. The results that indicate the algorithm's good performance are\npresented and discussed.\n  In particular, we apply our results to the special incomplete market model\nstudied by Merton and give a detailed comparison between our results based on\nthe minimal variance principle and the results obtained by Merton based on a\ndifferent pricing principle. Using deep learning, we find that the minimal\nvariance principle leads to typically higher option prices than those deduced\nfrom the Merton principle. On the other hand, the minimal variance principle\nleads to lower losses than the Merton principle.\n"
    },
    {
        "paper_id": 2407.13698,
        "authors": "Zijie Pan, Stepan Gordeev, Jiahui Zhao, Ziyi Meng, Caiwen Ding, Sandro\n  Steinbach, Dongjin Song",
        "title": "International Trade Flow Prediction with Bilateral Trade Provisions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a novel methodology for predicting international\nbilateral trade flows, emphasizing the growing importance of Preferential Trade\nAgreements (PTAs) in the global trade landscape. Acknowledging the limitations\nof traditional models like the Gravity Model of Trade, this study introduces a\ntwo-stage approach combining explainable machine learning and factorization\nmodels. The first stage employs SHAP Explainer for effective variable\nselection, identifying key provisions in PTAs, while the second stage utilizes\nFactorization Machine models to analyze the pairwise interaction effects of\nthese provisions on trade flows. By analyzing comprehensive datasets, the paper\ndemonstrates the efficacy of this approach. The findings not only enhance the\npredictive accuracy of trade flow models but also offer deeper insights into\nthe complex dynamics of international trade, influenced by specific bilateral\ntrade provisions.\n"
    },
    {
        "paper_id": 2407.13751,
        "authors": "Yoontae Hwang, Stefan Zohren, Yongjae Lee",
        "title": "Temporal Representation Learning for Stock Similarities and Its\n  Applications in Investment Management",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In the era of rapid globalization and digitalization, accurate identification\nof similar stocks has become increasingly challenging due to the non-stationary\nnature of financial markets and the ambiguity in conventional regional and\nsector classifications. To address these challenges, we examine SimStock, a\nnovel temporal self-supervised learning framework that combines techniques from\nself-supervised learning (SSL) and temporal domain generalization to learn\nrobust and informative representations of financial time series data. The\nprimary focus of our study is to understand the similarities between stocks\nfrom a broader perspective, considering the complex dynamics of the global\nfinancial landscape. We conduct extensive experiments on four real-world\ndatasets with thousands of stocks and demonstrate the effectiveness of SimStock\nin finding similar stocks, outperforming existing methods. The practical\nutility of SimStock is showcased through its application to various investment\nstrategies, such as pairs trading, index tracking, and portfolio optimization,\nwhere it leads to superior performance compared to conventional methods. Our\nfindings empirically examine the potential of data-driven approach to enhance\ninvestment decision-making and risk management practices by leveraging the\npower of temporal self-supervised learning in the face of the ever-changing\nglobal financial landscape.\n"
    },
    {
        "paper_id": 2407.13776,
        "authors": "Leon Kempen, Johan Pouwelse",
        "title": "Offline Digital Euro: a Minimum Viable CBDC using Groth-Sahai proofs",
        "comments": "13 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Current digital payment solutions are fragile and offer less privacy than\ntraditional cash.\n  Their critical dependency on an online service used to perform and validate\ntransactions makes them void if this service is unreachable.\n  Moreover, no transaction can be executed during server malfunctions or power\noutages.\n  Due to climate change, the likelihood of extreme weather increases. As\nextreme weather is a major cause of power outages, the frequency of power\noutages is expected to increase.\n  The lack of privacy is an inherent result of their account-based design or\nthe use of a public ledger.\n  The critical dependency and lack of privacy can be resolved with a Central\nBank Digital Currency that can be used offline.\n  This thesis proposes a design and a first implementation for an offline-first\ndigital euro.\n  The protocol offers complete privacy during transactions using zero-knowledge\nproofs.\n  Furthermore, transactions can be executed offline without third parties and\nretroactive double-spending detection is facilitated.\n  To protect the users' privacy, but also guard against money laundering, we\nhave added the following privacy-guarding mechanism.\n  The bank and trusted third parties for law enforcement must collaborate to\ndecrypt transactions, revealing the digital pseudonym used in the transaction.\n  Importantly, the transaction can be decrypted without decrypting prior\ntransactions attached to the digital euro.\n  The protocol has a working initial implementation showcasing its usability\nand demonstrating functionality.\n"
    },
    {
        "paper_id": 2407.1388,
        "authors": "S\\'andor Juh\\'asz, Johannes Wachs, Jermain Kaminski, C\\'esar A.\n  Hidalgo",
        "title": "The Software Complexity of Nations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Despite the growing importance of the digital sector, research on economic\ncomplexity and its implications continues to rely mostly on administrative\nrecords, e.g. data on exports, patents, and employment, that fail to capture\nthe nuances of the digital economy. In this paper we use data on the geography\nof programming languages used in open-source software projects to extend\neconomic complexity ideas to the digital economy. We estimate a country's\nsoftware economic complexity and show that it complements the ability of\nmeasures of complexity based on trade, patents, and research papers to account\nfor international differences in GDP per capita, income inequality, and\nemissions. We also show that open-source software follows the principle of\nrelatedness, meaning that a country's software entries and exits are explained\nby specialization in related programming languages. We conclude by exploring\nthe diversification and development of countries in open-source software in the\ncontext of large language models. Together, these findings help extend economic\ncomplexity methods and their policy considerations to the digital sector.\n"
    },
    {
        "paper_id": 2407.13908,
        "authors": "Maciej Wysocki, Robert \\'Slepaczuk",
        "title": "Construction and Hedging of Equity Index Options Portfolios",
        "comments": "31 pages, 27 figures, 6 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This research presents a comprehensive evaluation of systematic index\noption-writing strategies, focusing on S&P500 index options. We compare the\nperformance of hedging strategies using the Black-Scholes-Merton (BSM) model\nand the Variance-Gamma (VG) model, emphasizing varying moneyness levels and\ndifferent sizing methods based on delta and the VIX Index. The study employs\n1-minute data of S&P500 index options and index quotes spanning from 2018 to\n2023. The analysis benchmarks hedged strategies against buy-and-hold and naked\noption-writing strategies, with a focus on risk-adjusted performance metrics\nincluding transaction costs. Portfolio delta approximations are derived using\nimplied volatility for the BSM model and market-calibrated parameters for the\nVG model. Key findings reveal that systematic option-writing strategies can\npotentially yield superior returns compared to buy-and-hold benchmarks. The BSM\nmodel generally provided better hedging outcomes than the VG model, although\nthe VG model showed profitability in certain naked strategies as a tool for\nposition sizing. In terms of rehedging frequency, we found that intraday\nhedging in 130-minute intervals provided both reliable protection against\nadverse market movements and a satisfactory returns profile.\n"
    },
    {
        "paper_id": 2407.14016,
        "authors": "Joonkyo Hong and Davide Luparello",
        "title": "In Search of (Factor-Biased) Learning by Exporting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Exporting plants often undergo significant technology upgrades, becoming more\nproductive than their domestic counterparts. This process, called learning by\nexporting, is usually modeled as a Hicks-neutral TFP shifter, overlooking\nfactor-biased technical improvements. We develop a dynamic model of production,\nexporting, and capital investment that incorporates factor-augmenting\nefficiencies. We find that exporting increases TFP by 9%, skilled labor\nproductivity by 2%, and unskilled labor productivity by 8%. For new exporters,\nskilled labor productivity rises by 45%, and unskilled labor productivity\nincreases by 75% within four years of entering export markets.\n"
    },
    {
        "paper_id": 2407.14017,
        "authors": "Tomohiro Hirano, Alexis Akira Toda",
        "title": "Rational Bubbles: A Clarification",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  \"Rational bubble\", as introduced by the famous paper on money by Samuelson\n(1958), means speculation backed by nothing. The large subsequent rational\nbubble literature has identified attaching bubbles to dividend-paying assets in\na natural way as an important but challenging question. Miao and Wang (2018)\nclaim to \"provide a theory of rational stock price bubbles\". Contrary to their\nclaim, the present comment proves the nonexistence of rational bubbles in the\nmodel of Miao and Wang (2018). We also clarify the precise mathematical\ndefinition and the economic meaning of \"rational bubble\" in an accessible way\nto the general audience.\n"
    },
    {
        "paper_id": 2407.14179,
        "authors": "Max Sina Knicker, Karl Naumann-Woleske, and Michael Benzaquen",
        "title": "Bottlenecks in Occupational Transitions: A Data-driven Taxonomy",
        "comments": "19 pages, 16 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an era of rapid technological advancements and macroeconomic shifts,\nworker reallocation is necessary, yet responses to labor market shocks remain\nsluggish, making it crucial to identify bottlenecks in occupational transitions\nto understand labor market dynamics and improve mobility. In this study, we\nanalyze French occupational data to uncover patterns of worker mobility and\npinpoint specific occupations that act as bottlenecks which impede rapid\nreallocation. We introduce two metrics, transferability and accessibility, to\nquantify the diversity of occupational transitions and find that bottlenecks\ncan be explained by a condensation effect of occupations with high\naccessibility but low transferability. Transferability measures the variety of\ntransitions from an occupation to others, while accessibility assesses the\nvariety of transitions into an occupation. We provide a comprehensive framework\nfor analyzing occupational complexity and mobility patterns, offering insights\ninto potential barriers and pathways for efficient retraining programs. We\nargue that our approach can inform policymakers and stakeholders aiming to\nenhance labor market efficiency and support workforce adaptability.\n"
    },
    {
        "paper_id": 2407.14267,
        "authors": "Davide Fiaschi, Angela Parenti, Cristiano Ricci",
        "title": "The spatial evolution of economic activities: from theory to estimation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper studies the evolution of economic activities using a continuous\ntime-space aggregation-diffusion model, which encompasses competing effects of\nagglomeration and congestion. To bring the model to the real data, a novel\ndiscretization technique over time and space is introduced. This technique\neffectively disentangles spatial effects into pure topography, agglomeration,\nrepulsion, and diffusion forces, which is crucial for developing robust\neconometric methods in spatial economics. Our empirical analysis of personal\nincome across Italian municipalities from 2008 to 2019 validates the model's\nprimary predictions and demonstrates superior performance compared to the most\ncommon spatial econometric models in the literature.\n"
    },
    {
        "paper_id": 2407.14272,
        "authors": "Paolo Bartesaghi and Fernando Diaz-Diaz and Rosanna Grassi and\n  Pierpaolo Uberti",
        "title": "Global Balance and Systemic Risk in Financial Correlation Networks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show that the global balance index of financial correlation networks can\nbe used as a systemic risk measure. We define the global balance of a network\nstarting from a diffusive process that describes how the information spreads\nacross nodes in a network, providing an alternative derivation to the usual\ncombinatorial one. The steady state of this process is the solution of a linear\nsystem governed by the exponential of the replication matrix of the process. We\nprovide a bridge between the numerical stability of this linear system,\nmeasured by the condition number in an opportune norm, and the structural\npredictability of the underlying signed network. The link between the condition\nnumber and related systemic risk measures, such as the market rank indicators,\nallows the global balance index to be interpreted as a new systemic risk\nmeasure. A comprehensive empirical application to real financial data finally\nconfirms that the global balance index of the financial correlation network\nrepresents a valuable and effective systemic risk indicator.\n"
    },
    {
        "paper_id": 2407.14327,
        "authors": "Tara Merk",
        "title": "Why to DAO: a narrative analysis of the drivers of tokenized Exit to\n  Community",
        "comments": "Presented at DAWO24 conference",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper asks why startups in the blockchain industry are exiting to\nDecentralized Autonomous Organizations (DAOs), an outstanding phenomena in the\nwider digital economy which has tended to retain centralized ownership and\ngovernance rights of many platforms, products and protocols. Drawing on a\nnarrative analysis of three case studies, I find three possible drivers: (1)\nexit to DAO is motivated by both financial and stewardship goals which it\nsimultaneously promises to realize via the issuance of tokens; (2) exit to DAO\nadds an additional layer of ownership and governance rights via tokens, without\nrequiring existing rights to be relinquished, thus making it a lucrative\nstrategy; and (3) markets, laws and social norms underpinning the broader\nenvironment in which exits to DAO occur, seem to play an important role in\ndriving the decision. This paper contributes to the academic literature by\nsituating DAOs as a hybrid (and perhaps incomplete) entrepreneurial exit\nstrategy and identifying plausible drivers of the phenomenon which warrant\nfurther dedicated research.\n"
    },
    {
        "paper_id": 2407.14333,
        "authors": "Eaman Jahani, Benjamin S. Manning, Joe Zhang, Hong-Yi TuYe, Mohammed\n  Alsobay, Christos Nicolaides, Siddharth Suri, David Holtz",
        "title": "As Generative Models Improve, People Adapt Their Prompts",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In an online experiment with N = 1891 participants, we collected and analyzed\nover 18,000 prompts to explore how the importance of prompting will change as\nthe capabilities of generative AI models continue to improve. Each participant\nin our experiment was randomly and blindly assigned to use one of three\ntext-to-image diffusion models: DALL-E 2, its more advanced successor DALL-E 3,\nor a version of DALL-E 3 with automatic prompt revision. Participants were then\nasked to write prompts to reproduce a target image as closely as possible in 10\nconsecutive tries. We find that task performance was higher for participants\nusing DALL-E 3 than for those using DALL-E 2. This performance gap corresponds\nto a noticeable difference in the similarity of participants' images to their\ntarget images, and was caused in equal measure by: (1) the increased technical\ncapabilities of DALL-E 3, and (2) endogenous changes in participants' prompting\nin response to these increased capabilities. More specifically, despite being\nblind to the model they were assigned, participants assigned to DALL-E 3 wrote\nlonger prompts that were more semantically similar to each other and contained\na greater number of descriptive words. Furthermore, while participants assigned\nto DALL-E 3 with prompt revision still outperformed those assigned to DALL-E 2,\nautomatic prompt revision reduced the benefits of using DALL-E 3 by 58%. Taken\ntogether, our results suggest that as models continue to progress, people will\ncontinue to adapt their prompts to take advantage of new models' capabilities.\n"
    },
    {
        "paper_id": 2407.14335,
        "authors": "Yihang Fu, Mingwei Jing, Jiaolun Zhou, Peilin Wu, Ye Wang, Luyao\n  Zhang, Chuang Hu",
        "title": "Quantifying the Blockchain Trilemma: A Comparative Analysis of Algorand,\n  Ethereum 2.0, and Beyond",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Blockchain technology is essential for the digital economy and metaverse,\nsupporting applications from decentralized finance to virtual assets. However,\nits potential is constrained by the \"Blockchain Trilemma,\" which necessitates\nbalancing decentralization, security, and scalability. This study evaluates and\ncompares two leading proof-of-stake (PoS) systems, Algorand and Ethereum 2.0,\nagainst these critical metrics. Our research interprets existing indices to\nmeasure decentralization, evaluates scalability through transactional data, and\nassesses security by identifying potential vulnerabilities. Utilizing\nreal-world data, we analyze each platform's strategies in a structured manner\nto understand their effectiveness in addressing trilemma challenges. The\nfindings highlight each platform's strengths and propose general methodologies\nfor evaluating key blockchain characteristics applicable to other systems. This\nresearch advances the understanding of blockchain technologies and their\nimplications for the future digital economy. Data and code are available on\nGitHub as open source.\n"
    },
    {
        "paper_id": 2407.14486,
        "authors": "Alejandra de la Rica Escudero, Eduardo C. Garrido-Merchan, Maria\n  Coronado-Vaca",
        "title": "Explainable Post hoc Portfolio Management Financial Policy of a Deep\n  Reinforcement Learning agent",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Financial portfolio management investment policies computed quantitatively by\nmodern portfolio theory techniques like the Markowitz model rely on a set on\nassumptions that are not supported by data in high volatility markets. Hence,\nquantitative researchers are looking for alternative models to tackle this\nproblem. Concretely, portfolio management is a problem that has been\nsuccessfully addressed recently by Deep Reinforcement Learning (DRL)\napproaches. In particular, DRL algorithms train an agent by estimating the\ndistribution of the expected reward of every action performed by an agent given\nany financial state in a simulator. However, these methods rely on Deep Neural\nNetworks model to represent such a distribution, that although they are\nuniversal approximator models, they cannot explain its behaviour, given by a\nset of parameters that are not interpretable. Critically, financial investors\npolicies require predictions to be interpretable, so DRL agents are not suited\nto follow a particular policy or explain their actions. In this work, we\ndeveloped a novel Explainable Deep Reinforcement Learning (XDRL) approach for\nportfolio management, integrating the Proximal Policy Optimization (PPO) with\nthe model agnostic explainable techniques of feature importance, SHAP and LIME\nto enhance transparency in prediction time. By executing our methodology, we\ncan interpret in prediction time the actions of the agent to assess whether\nthey follow the requisites of an investment policy or to assess the risk of\nfollowing the agent suggestions. To the best of our knowledge, our proposed\napproach is the first explainable post hoc portfolio management financial\npolicy of a DRL agent. We empirically illustrate our methodology by\nsuccessfully identifying key features influencing investment decisions, which\ndemonstrate the ability to explain the agent actions in prediction time.\n"
    },
    {
        "paper_id": 2407.14573,
        "authors": "Orson Mengara",
        "title": "Trading Devil Final: Backdoor attack via Stock market and Bayesian\n  Optimization",
        "comments": "END :jumps-Diffusion and stock market: Better quantify uncertainty in\n  financial simulations",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Since the advent of generative artificial intelligence, every company and\nresearcher has been rushing to develop their own generative models, whether\ncommercial or not. Given the large number of users of these powerful new tools,\nthere is currently no intrinsically verifiable way to explain from the ground\nup what happens when LLMs (large language models) learn. For example, those\nbased on automatic speech recognition systems, which have to rely on huge and\nastronomical amounts of data collected from all over the web to produce fast\nand efficient results, In this article, we develop a backdoor attack called\nMarketBackFinal 2.0, based on acoustic data poisoning, MarketBackFinal 2.0 is\nmainly based on modern stock market models. In order to show the possible\nvulnerabilities of speech-based transformers that may rely on LLMs.\n"
    },
    {
        "paper_id": 2407.14642,
        "authors": "David M. Kryskowski, David Kryskowski",
        "title": "Applying the Nash Bargaining Solution for a Reasonable Royalty II",
        "comments": "12 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper expands on the concepts presented in Applying the Nash Bargaining\nSolution for a Reasonable Royalty ( arXiv:2005.10158 ). The goal is to refine\nthe process for determining a reasonable royalty using statistical methods in\ncases where there is risk and uncertainty regarding each party's disagreement\npayoffs (opportunity costs) in the Nash Bargaining Solution (NBS). This paper\nuses a Bayes Cost approach to analyze Case 1, Case 2, and the Original Nash\nmodel from the authors' previous work. By addressing risk and uncertainty in\nthe NBS, the NBS emerges as a more reliable method for estimating a reasonable\nroyalty, aligning with the criteria outlined in Georgia Pacific factor fifteen.\n"
    },
    {
        "paper_id": 2407.14728,
        "authors": "Minh-Quan Nguyen, Nhat-Tan Le, Khuong Nguyen-An, Duc-Thi Luu",
        "title": "An Integral Equation Approach for the Valuation of Finite-maturity\n  margin-call Stock Loans",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This paper examines the pricing issue of margin-call stock loans with finite\nmaturities under the Black-Scholes-Merton framework. In particular, using a\nFourier Sine transform method, we reduce the partial differential equation\ngoverning the price of a margin-call stock loan into an ordinary differential\nequation, the solution of which can be easily found (in the Fourier Sine space)\nand analytically inverted into the original space. As a result, we obtain an\nintegral representation of the value of the stock loan in terms of the unknown\noptimal exit prices, which are, in turn, governed by a Volterra integral\nequation. We thus can break the pricing problem of margin-call stock loans into\ntwo steps: 1) finding the optimal exit prices by solving numerically the\ngoverning Volterra integral equation and 2) calculating the values of\nmargin-call stock loans based on the obtained optimal exit prices. By\nvalidating and comparing with other available numerical methods, we show that\nour proposed numerical scheme offers a reliable and efficient way to calculate\nthe service fee of a margin-call stock loan contract, track the contract value\nover time, and compute the level of stock price above which it is optimal to\nexit the contract. The effects of the margin-call feature on the loan contract\nare also examined and quantified.\n"
    },
    {
        "paper_id": 2407.14734,
        "authors": "Yun Liao",
        "title": "Super-efficiency and Stock Market Valuation: Evidence from Listed Banks\n  in China (2006 to 2023)",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This study investigates the relationship between bank efficiency and stock\nmarket valuation using an unbalanced panel dataset of 42 listed banks in China\nfrom 2006 to 2023. We employ a non-radial and non-oriented slack based\nsuper-efficiency Data Envelopment Analysis (Super-SBM-UND-VRS based DEA) model,\nwhich treats Non-Performing Loans (NPLs) as an undesired output. Our results\nshow that the relationship between super-efficiency and stock market valuation\nis stronger than that between Return on Asset (ROA) and stock market\nperformance, as measured by Tobin's Q. Notably, the Super-SBM-UND-VRS model\nyields novel results compared to other efficiency methods, such as the\nStochastic Frontier Analysis (SFA) approach and traditional DEA models.\nFurthermore, our results suggest that bank evaluations benefit from decreased\nownership concentration, whereas interest rate liberalization has the opposite\neffect.\n"
    },
    {
        "paper_id": 2407.14736,
        "authors": "Pascal Fran\\c{c}ois and Genevi\\`eve Gauthier and Fr\\'ed\\'eric Godin\n  and Carlos Octavio P\\'erez Mendoza",
        "title": "Is the difference between deep hedging and delta hedging a statistical\n  arbitrage?",
        "comments": "14 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The recent work of Horikawa and Nakagawa (2024) claims that under a complete\nmarket admitting statistical arbitrage, the difference between the hedging\nposition provided by deep hedging and that of the replicating portfolio is a\nstatistical arbitrage. This raises concerns as it entails that deep hedging can\ninclude a speculative component aimed simply at exploiting the structure of the\nrisk measure guiding the hedging optimisation problem. We test whether such\nfinding remains true in a GARCH-based market model. We observe that the\ndifference between deep hedging and delta hedging can be a statistical\narbitrage if the risk measure considered does not put sufficient relative\nweight on adverse outcomes. Nevertheless, a suitable choice of risk measure can\nprevent the deep hedging agent from including a speculative overlay within its\nhedging strategy.\n"
    },
    {
        "paper_id": 2407.14773,
        "authors": "Deepal Basak, Joyee Deb, Aditya Kuvalekar",
        "title": "Similarity of Information and Collective Action",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study a canonical collective action game with incomplete information.\nIndividuals attempt to coordinate to achieve a shared goal, while also facing a\ntemptation to free-ride. Consuming more similar information about the\nfundamentals can help them coordinate, but it can also exacerbate free-riding.\nOur main result shows that more similar information facilitates (impedes)\nachieving a common goal when achieving the goal is sufficiently challenging\n(easy). We apply this insight to show why insufficiently powerful authoritarian\ngovernments may face larger protests when attempting to restrict press freedom,\nand why informational diversity in committees is beneficial when each vote\ncarries more weight.\n"
    },
    {
        "paper_id": 2407.14776,
        "authors": "Kerstin H\\\"otte, Andreina Naddeo",
        "title": "National accounting from the bottom up using large-scale financial\n  transactions data: An application to input-output tables",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Technical advances enabled real-time data collection at a large scale, but\nlacking standards hamper their economic interpretation. Here, we benchmark a\nnew monthly time series of inter-industrial flows of funds, constructed from\naggregated and anonymised real-time payments between UK businesses, covering\n5-digit SIC codes industries for the period 08/2015 to 12/2023, against\nestablished economic indicators, including GDP, input-output tables (IOTs), and\nstylised facts of granular firm- and industry-level production networks. We\nsupplement the quantitative analyses with conceptual discussions, explaining\nthe caveats of bottom-up collected payment data and their differences to\nnational account tables. The results reveal strong GDP correlations, some\nqualitative consistency with official IOTs and stylised facts. We guide on the\ninterpretation of the data and areas that require special attention for\nreliable quantitative research.\n"
    },
    {
        "paper_id": 2407.14844,
        "authors": "Hongzhou Chen, Xiaolin Duan, Abdulmotaleb El Saddik, Wei Cai",
        "title": "Political Leanings in Web3 Betting: Decoding the Interplay of Political\n  and Profitable Motives",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Harnessing the transparent blockchain user behavior data, we construct the\nPolitical Betting Leaning Score (PBLS) to measure political leanings based on\nbetting within Web3 prediction markets. Focusing on Polymarket and starting\nfrom the 2024 U.S. Presidential Election, we synthesize behaviors over 15,000\naddresses across 4,500 events and 8,500 markets, capturing the intensity and\ndirection of their political leanings by the PBLS. We validate the PBLS through\ninternal consistency checks and external comparisons. We uncover relationships\nbetween our PBLS and betting behaviors through over 800 features capturing\nvarious behavioral aspects. A case study of the 2022 U.S. Senate election\nfurther demonstrates the ability of our measurement while decoding the dynamic\ninteraction between political and profitable motives. Our findings contribute\nto understanding decision-making in decentralized markets, enhancing the\nanalysis of behaviors within Web3 prediction environments. The insights of this\nstudy reveal the potential of blockchain in enabling innovative,\nmultidisciplinary studies and could inform the development of more effective\nonline prediction markets, improve the accuracy of forecast, and help the\ndesign and optimization of platform mechanisms. The data and code for the paper\nare accessible at the following link: https://github.com/anonymous.\n"
    },
    {
        "paper_id": 2407.14955,
        "authors": "J. Lucas Reddinger",
        "title": "Temptation: Immediacy and certainty",
        "comments": "The manuscript includes 26 pages with 2 tables and 3 figures; the\n  supplement includes 20 pages with 5 tables and 15 figures. This revision is\n  minor",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Is an option especially tempting when it is both immediate and certain? I\ntest the effect of risk on the present-bias factor given quasi-hyperbolic\ndiscounting. In my experiment, workers allocate about thirty to fifty minutes\nof real-effort tasks between two weeks. I study dynamic consistency by\ncomparing choices made two days in advance of the workday with choices made\nwhen work is imminent. My novel design permits estimation of present-bias using\na decision with a consequence that is both immediate and certain. I find\ngreater present-bias when the consequence is certain. This finding has\nimplications for any economic decision involving a present-biased\ndecision-maker, including labor contracting and consumer good pricing. Finally\nI offer a methodological remedy for experimental economists.\n"
    },
    {
        "paper_id": 2407.15016,
        "authors": "Daria Gritsenko, Jon Aaen, Bent Flyvbjerg",
        "title": "Rethinking Digitalization and Climate: Don't Predict, Mitigate",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Digitalization is a core component of the green transition. Today's focus is\non quantifying and pre-dicting the climate effects of digitalization through\nvarious life-cycle assessments and baseline sce-nario methodologies. Here we\nargue that this is a mistake. Most attempts at prediction are based on three\nimplicit assumptions: (a) the digital carbon footprint can be quantified, (b)\nbusiness-as-usual with episodic change leading to a new era of stability, and\n(c) investments in digitalization will be delivered within the cost, timeframe,\nand benefits described in their business cases. We problema-tize each\nassumption within the context of digitalization and argue that the digital\ncarbon footprint is inherently unpredictable. We build on uncertainty\nliterature to show that even if you cannot predict, you can still mitigate. On\nthat basis, we propose to rethink practice on the digital carbon footprint from\nprediction to mitigation.\n"
    },
    {
        "paper_id": 2407.15038,
        "authors": "Qiqin Zhou",
        "title": "Explainable AI in Request-for-Quote",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In the contemporary financial landscape, accurately predicting the\nprobability of filling a Request-For-Quote (RFQ) is crucial for improving\nmarket efficiency for less liquid asset classes. This paper explores the\napplication of explainable AI (XAI) models to forecast the likelihood of RFQ\nfulfillment. By leveraging advanced algorithms including Logistic Regression,\nRandom Forest, XGBoost and Bayesian Neural Tree, we are able to improve the\naccuracy of RFQ fill rate predictions and generate the most efficient quote\nprice for market makers. XAI serves as a robust and transparent tool for market\nparticipants to navigate the complexities of RFQs with greater precision.\n"
    },
    {
        "paper_id": 2407.15105,
        "authors": "Hasanjan Sayit",
        "title": "Weak convergence implies convergence in mean within GGC",
        "comments": "21 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We prove that weak convergence within generalized gamma convolution (GGC)\ndistributions implies convergence in the mean value. We use this fact to show\nthe robustness of the expected utility maximizing optimal portfolio under\nexponential utility function when return vectors are modelled by hyperbolic\ndistributions.\n"
    },
    {
        "paper_id": 2407.15147,
        "authors": "Suguru Otani",
        "title": "Industry Dynamics with Cartels: The Case of the Container Shipping\n  Industry",
        "comments": "51 pages and 9 pages appendix",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  I investigate how explicit cartels, known as ``shipping conferences\", in a\nglobal container shipping market facilitated the formation of one of the\nlargest globally integrated markets through entry, exit, and shipbuilding\ninvestment of shipping firms. Using a novel data, I develop and construct a\nstructural model and find that the cartels shifted shipping prices by 20-50\\%\nand encouraged firms' entry and investment. In the counterfactual, I find that\ncartels would increase producer surplus while slightly decreasing consumer\nsurplus, then may increase social welfare by encouraging firms' entry and\nshipbuilding investment. This would validate industry policies controlling\nprices and quantities in the early stage of the new industry, which may not be\nalways harmful. Investigating hypothetical allocation rules supporting large or\nsmall firms, I find that the actual rule based on tonnage shares is the best to\nmaximize social welfare.\n"
    },
    {
        "paper_id": 2407.15339,
        "authors": "Melissa Dell",
        "title": "Deep Learning for Economists",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Deep learning provides powerful methods to impute structured information from\nlarge-scale, unstructured text and image datasets. For example, economists\nmight wish to detect the presence of economic activity in satellite images, or\nto measure the topics or entities mentioned in social media, the congressional\nrecord, or firm filings. This review introduces deep neural networks, covering\nmethods such as classifiers, regression models, generative AI, and embedding\nmodels. Applications include classification, document digitization, record\nlinkage, and methods for data exploration in massive scale text and image\ncorpora. When suitable methods are used, deep learning models can be cheap to\ntune and can scale affordably to problems involving millions or billions of\ndata points.. The review is accompanied by a companion website, EconDL, with\nuser-friendly demo notebooks, software resources, and a knowledge base that\nprovides technical details and additional applications.\n"
    },
    {
        "paper_id": 2407.15388,
        "authors": "Xiaobai Zhu, Kenneth Q. Zhou, Zijia Wang",
        "title": "A new paradigm of mortality modeling via individual vitality dynamics",
        "comments": "45 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The significance of mortality modeling extends across multiple research\nareas, including life insurance valuation, longevity risk management,\nlife-cycle hypothesis, and retirement income planning. Despite the variety of\nexisting approaches, such as mortality laws and factor-based models, they often\nlack compatibility or fail to meet specific research needs. To address these\nshortcomings, this study introduces a novel approach centered on modeling the\ndynamics of individual vitality and defining mortality as the depletion of\nvitality level to zero. More specifically, we develop a four-component\nframework to analyze the initial value, trend, diffusion, and sudden changes in\nvitality level over an individual's lifetime. We demonstrate the framework's\nestimation and analytical capabilities in various settings and discuss its\npractical implications in actuarial problems and other research areas. The\nbroad applicability and interpretability of our vitality-based modeling\napproach offer an enhanced paradigm for mortality modeling.\n"
    },
    {
        "paper_id": 2407.15509,
        "authors": "Ra\\'ul M\\'inguez and Asier Minondo",
        "title": "The increase in the number of low-value transactions in international\n  trade",
        "comments": "3 figures and an appendix",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper documents a new feature of international trade: the increase in\nthe number of low-value transactions. Using Spanish data, we show that the\nshare of low-value transactions in the total number of transactions increased\nfrom 9% to 61% in exports and from 14% to 54% in imports between 1997 and 2023.\nThe increase in the number of low-value trade transactions is related to the\nrise in e-commerce and direct-to-customer sales facilitated by online retail\nplatforms. In the case of exports, the increase in the number of low-value\ntransactions is also explained by the fast-fashion strategy followed by\nclothing firms.\n"
    },
    {
        "paper_id": 2407.15532,
        "authors": "Kamesh Korangi, Christophe Mues and Cristi\\'an Bravo",
        "title": "Large-scale Time-Varying Portfolio Optimisation using Graph Attention\n  Networks",
        "comments": "37 pages, 7 figures, v1",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Apart from assessing individual asset performance, investors in financial\nmarkets also need to consider how a set of firms performs collectively as a\nportfolio. Whereas traditional Markowitz-based mean-variance portfolios are\nwidespread, network-based optimisation techniques have built upon these\ndevelopments. However, most studies do not contain firms at risk of default and\nremove any firms that drop off indices over a certain time. This is the first\nstudy to incorporate risky firms and use all the firms in portfolio\noptimisation. We propose and empirically test a novel method that leverages\nGraph Attention networks (GATs), a subclass of Graph Neural Networks (GNNs).\nGNNs, as deep learning-based models, can exploit network data to uncover\nnonlinear relationships. Their ability to handle high-dimensional features and\naccommodate customised layers for specific purposes makes them particularly\nappealing for large-scale problems such as mid- and small-cap portfolio\noptimization. This study utilises 30 years of data on mid-cap firms, creating\ngraphs of firms using distance correlation and the Triangulated Maximally\nFiltered Graph approach. These graphs are the inputs to a GAT model that we\ntrain using custom layers which impose weight and allocation constraints and a\nloss function derived from the Sharpe ratio, thus directly maximising portfolio\nrisk-adjusted returns. This new model is benchmarked against a network\ncharacteristic-based portfolio, a mean variance-based portfolio, and an\nequal-weighted portfolio. The results show that the portfolio produced by the\nGAT-based model outperforms all benchmarks and is consistently superior to\nother strategies over a long period while also being informative of market\ndynamics.\n"
    },
    {
        "paper_id": 2407.15536,
        "authors": "Chen Zhang, Giovanni Amici, Marco Morandotti",
        "title": "Calibrating the Heston Model with Deep Differential Networks",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose a gradient-based deep learning framework to calibrate the Heston\noption pricing model (Heston, 1993). Our neural network, henceforth deep\ndifferential network (DDN), learns both the Heston pricing formula for\nplain-vanilla options and the partial derivatives with respect to the model\nparameters. The price sensitivities estimated by the DDN are not subject to the\nnumerical issues that can be encountered in computing the gradient of the\nHeston pricing function. Thus, our network is an excellent pricing engine for\nfast gradient-based calibrations. Extensive tests on selected equity markets\nshow that the DDN significantly outperforms non-differential feedforward neural\nnetworks in terms of calibration accuracy. In addition, it dramatically reduces\nthe computational time with respect to global optimizers that do not use\ngradient information.\n"
    },
    {
        "paper_id": 2407.15715,
        "authors": "Kensuke Ito",
        "title": "Cryptoeconomics and Tokenomics as Economics: A Survey with Opinions",
        "comments": "18 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper surveys products and studies on cryptoeconomics and tokenomics\nfrom an economic perspective, as these terms are still (i) ill-defined and (ii)\ndisconnected from economic disciplines. We first suggest that they can be novel\nwhen integrated; we then conduct a literature review and case study following\nconsensus-building for decentralization and token value for autonomy.\nIntegration requires simultaneous consideration of strategic behavior,\nspamming, Sybil attacks, free-riding, marginal cost, marginal utility and\nstabilizers. This survey is the first systematization of knowledge on\ncryptoeconomics and tokenomics, aiming to bridge the contexts of economics and\nblockchain.\n"
    },
    {
        "paper_id": 2407.15755,
        "authors": "Jos\\'e A. Tapia Granados and Edward L. Ionides",
        "title": "Income, health, and cointegration",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Data for many nations show a long-run increase, over many decades, of income,\nindexed by GDP per capita, and population health, indexed by mortality or life\nexpectancy at birth (LEB). However, the short-run and long-run relationships\nbetween these variables have been interpreted in different ways, and many\ncontroversies are still open. Some authors have claimed that the causal\nrelationships between population health and income can be discovered using\ncointegration models. We show, however, that empirically testing a\ncointegration relation between LEB and GDP per capita is not a sound method to\ninfer a causal link between health and income. For a given country it is easy\nto find computer-generated data or time series of real observations, related or\nunrelated to the country, that according to standard methods are also\ncointegrated with the country's LEB. More generally, given a trending time\nseries, it is easy to find other series, observational or artificial, that\nappear cointegrated with it. Thus, standard cointegration methodology cannot\ndistinguish whether cointegration relationships are spurious or causal.\n"
    },
    {
        "paper_id": 2407.15757,
        "authors": "Pouya Janghorban, Temilade Sesan, Muhammad-Kabir Salihu, Olayinka\n  Ohunakin, Narges Chinichian",
        "title": "Willingness to Pay for an Electricity Connection: A Choice Experiment\n  Among Rural Households and Enterprises in Nigeria",
        "comments": "This paper is one the outputs of the PeopleSuN project for Nigeria.\n  See here for more information on the project:\n  https://reiner-lemoine-institut.de/en/peoplesun-optimizing-off-grid-electricity-supply-nigeria-2/",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Rural electrification initiatives worldwide frequently encounter financial\nplanning challenges due to a lack of reliable market insights. This research\ndelves into the preferences and marginal willingness to pay (mWTP) for upfront\nelectricity connections in rural and peri-urban areas of Nigeria. We\ninvestigate discrete choice experiment data gathered from 3,599 households and\n1,122 Small to Medium-sized Enterprises (SMEs) across three geopolitical zones\nof Nigeria, collected during the 2021 PeopleSuN project survey phase. Employing\nconditional logit modeling, we analyze this data to explore preferences and\nmarginal willingness to pay for electricity connection. Our findings show that\nhouseholds prioritize nighttime electricity access, while SMEs place a higher\nvalue on daytime electricity. When comparing improvements in electricity\ncapacity to medium or high-capacity, SMEs exhibit a sharp increase in\nwillingness to pay for high-capacity, while households value the two options\nmore evenly. Preferences for the electricity source vary among SMEs, but\nhouseholds display a reluctance towards diesel generators and a preference for\nthe grid or solar solutions. Moreover, households with older heads express\ngreater aversion to connection fees, and male-headed households show a stronger\npreference for nighttime electricity compared to their female-headed\ncounterparts. The outcomes of this study yield pivotal insights to tailor\nelectrification strategies for rural Nigeria, emphasizing the importance of\nconsidering the diverse preferences of households and SMEs.\n"
    },
    {
        "paper_id": 2407.15766,
        "authors": "Shafique Ur Rehman, Touqeer Ahmad, Wu Dash Desheng, and Amirhossein\n  Karamoozian",
        "title": "Analyzing selected cryptocurrencies spillover effects on global\n  financial indices: Comparing risk measures using conventional and\n  eGARCH-EVT-Copula approaches",
        "comments": "29 pages, 5 figures 13",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study examines the interdependence between cryptocurrencies and\ninternational financial indices, such as MSCI World and MSCI Emerging Markets.\nWe compute the value at risk, expected shortfall (ES), and range value at risk\n(RVaR) and investigate the dynamics of risk spillover. We employ a hybrid\napproach to derive these risk measures that integrate GARCH models, extreme\nvalue models, and copula functions. This framework uses a bivariate portfolio\napproach involving cryptocurrency data and traditional financial indices. To\nestimate the above risks of these portfolio structures, we employ symmetric and\nasymmetric GARCH and both tail flexible EVT models as marginal to model the\nmarginal distribution of each return series and apply different copula\nfunctions to connect the pairs of marginal distributions into a multivariate\ndistribution. The empirical findings indicate that the eGARCH EVT-based copula\nmodel adeptly captures intricate dependencies, surpassing conventional\nmethodologies like Historical simulations and t-distributed parametric in VaR\nestimation. At the same time, the HS method proves superior for ES, and the\nt-distributed parametric method outperforms RVaR. Eventually, the\nDiebold-Yilmaz approach will be applied to compute risk spillovers between four\nsets of asset sequences. This phenomenon implies that cryptocurrencies reveal\nsubstantial spillover effects among themselves but minimal impact on other\nassets. From this, it can be concluded that cryptocurrencies propose\ndiversification benefits and do not provide hedging advantages within an\ninvestor's portfolio. Our results underline RVaR superiority over ES regarding\nregulatory arbitrage and model misspecification. The conclusions of this study\nwill benefit investors and financial market professionals who aspire to\ncomprehend digital currencies as a novel asset class and attain perspicuity in\nregulatory arbitrage.\n"
    },
    {
        "paper_id": 2407.16099,
        "authors": "Mario Ghossoub, Qinghua Ren, Ruodu Wang",
        "title": "Counter-monotonic risk allocations and distortion risk measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In risk-sharing markets with aggregate uncertainty, characterizing\nPareto-optimal allocations when agents might not be risk averse is a\nchallenging task, and the literature has only provided limited explicit results\nthus far. In particular, Pareto optima in such a setting may not necessarily be\ncomonotonic, in contrast to the case of risk-averse agents. In fact, when\nmarket participants are risk-seeking, Pareto-optimal allocations are\ncounter-monotonic. Counter-monotonicity of Pareto optima also arises in some\nsituations for quantile-optimizing agents. In this paper, we provide a\nsystematic study of efficient risk sharing in markets where allocations are\nconstrained to be counter-monotonic. The preferences of the agents are modelled\nby a common distortion risk measure, or equivalently, by a common Yaari dual\nutility. We consider three different settings: risk-averse agents, risk-seeking\nagents, and those with an inverse S-shaped distortion function. In each case,\nwe provide useful characterizations of optimal allocations, for both the\ncounter-monotonic market and the unconstrained market. To illustrate our\nresults, we consider an application to a portfolio choice problem for a\nportfolio manager tasked with managing the investments of a group of clients,\nwith varying levels of risk aversion or risk seeking. We determine explicitly\nthe optimal investment strategies in this case. Our results confirm the\nintuition that a manager investing on behalf of risk-seeking agents tends to\ninvest more in risky assets than a manager acting on behalf of risk-averse\nagents.\n"
    },
    {
        "paper_id": 2407.16103,
        "authors": "Hongshen Yang, Avinash Malik",
        "title": "Reinforcement Learning Pair Trading: A Dynamic Scaling approach",
        "comments": "31 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Cryptocurrency is a cryptography-based digital asset with extremely volatile\nprices. Around $70 billion worth of crypto-currency is traded daily on\nexchanges. Trading crypto-currency is difficult due to the inherent volatility\nof the crypto-market. In this work, we want to test the hypothesis: \"Can\ntechniques from artificial intelligence help with algorithmically trading\ncryptocurrencies?\". In order to address this question, we combine Reinforcement\nLearning (RL) with pair trading. Pair trading is a statistical arbitrage\ntrading technique which exploits the price difference between statistically\ncorrelated assets. We train reinforcement learners to determine when and how to\ntrade pairs of cryptocurrencies. We develop new reward shaping and\nobservation/action spaces for reinforcement learning. We performed experiments\nwith the developed reinforcement learner on pairs of BTC-GBP and BTC-EUR data\nseparated by 1-minute intervals (n = 263,520). The traditional non-RL pair\ntrading technique achieved an annualised profit of 8.33%, while the proposed\nRL-based pair trading technique achieved annualised profits from 9.94% -\n31.53%, depending upon the RL learner. Our results show that RL can\nsignificantly outperform manual and traditional pair trading techniques when\napplied to volatile markets such as cryptocurrencies.\n"
    },
    {
        "paper_id": 2407.16141,
        "authors": "Hie Joo Ahn and Shihan Xie",
        "title": "Stock-driven Household Attention",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the effects of stockholding on households' attention to the\nmacroeconomy. Households' attentiveness is measured by their accuracy of\ninflation expectations and perceptions. Relative to non-stockholders,\nstockholders produce more accurate inflation forecasts and backcasts, disagree\nless about future inflation, and adjust their outlook more responsively to\nnews, suggesting that stock-market participation raises households' attention.\nFrequent changes in stock prices incentivize stockholders to closely monitor\nfinancial markets for optimal trading, given the low cost of acquiring\ninformation. Consequently, paying attention to the macroeconomy helps hedge the\nrisks associated with holding stocks. Therefore, attention heterogeneity driven\nby stockholdings can be a channel through which the distributional consequences\nof monetary policy are created.\n"
    },
    {
        "paper_id": 2407.16435,
        "authors": "Joel P. Villarino and \\'Alvaro Leitao",
        "title": "On Deep Learning for computing the Dynamic Initial Margin and Margin\n  Value Adjustment",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The present work addresses the challenge of training neural networks for\nDynamic Initial Margin (DIM) computation in counterparty credit risk, a task\ntraditionally burdened by the high costs associated with generating training\ndatasets through nested Monte Carlo (MC) simulations. By condensing the initial\nmarket state variables into an input vector, determined through an interest\nrate model and a parsimonious parameterization of the current interest rate\nterm structure, we construct a training dataset where labels are noisy but\nunbiased DIM samples derived from single MC paths. A multi-output neural\nnetwork structure is employed to handle DIM as a time-dependent function,\nfacilitating training across a mesh of monitoring times. The methodology offers\nsignificant advantages: it reduces the dataset generation cost to a single MC\nexecution and parameterizes the neural network by initial market state\nvariables, obviating the need for repeated training. Experimental results\ndemonstrate the approach's convergence properties and robustness across\ndifferent interest rate models (Vasicek and Hull-White) and portfolio\ncomplexities, validating its general applicability and efficiency in more\nrealistic scenarios.\n"
    },
    {
        "paper_id": 2407.16437,
        "authors": "Maksim Papenkov",
        "title": "Multi-Industry Simplex 2.0 : Temporally-Evolving Probabilistic Industry\n  Classification",
        "comments": "15 pages, 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Accurate industry classification is critical for many areas of portfolio\nmanagement, yet the traditional single-industry framework of the Global\nIndustry Classification Standard (GICS) struggles to comprehensively represent\nrisk for highly diversified multi-sector conglomerates like Amazon. Previously,\nwe introduced the Multi-Industry Simplex (MIS), a probabilistic extension of\nGICS that utilizes topic modeling, a natural language processing approach.\nAlthough our initial version, MIS-1, was able to improve upon GICS by providing\nmulti-industry representations, it relied on an overly simple architecture that\nrequired prior knowledge about the number of industries and relied on the\nunrealistic assumption that industries are uncorrelated and independent over\ntime. We improve upon this model with MIS-2, which addresses three key\nlimitations of MIS-1 : we utilize Bayesian Non-Parametrics to automatically\ninfer the number of industries from data, we employ Markov Updating to account\nfor industries that change over time, and we adjust for correlated and\nhierarchical industries allowing for both broad and niche industries (similar\nto GICS). Further, we provide an out-of-sample test directly comparing MIS-2\nand GICS on the basis of future correlation prediction, where we find evidence\nthat MIS-2 provides a measurable improvement over GICS. MIS-2 provides\nportfolio managers with a more robust tool for industry classification,\nempowering them to more effectively identify and manage risk, particularly\naround multi-sector conglomerates in a rapidly evolving market in which new\nindustries periodically emerge.\n"
    },
    {
        "paper_id": 2407.16525,
        "authors": "Luca De Gennaro Aquino, Sascha Desmettre, Yevhen Havrylenko, Mogens\n  Steffensen",
        "title": "Equilibrium control theory for Kihlstrom-Mirman preferences in\n  continuous time",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In intertemporal settings, the multiattribute utility theory of Kihlstrom and\nMirman suggests the application of a concave transform of the lifetime utility\nindex. This construction, while allowing time and risk attitudes to be\nseparated, leads to dynamically inconsistent preferences. We address this issue\nin a game-theoretic sense by formalizing an equilibrium control theory for\ncontinuous-time Markov processes. In these terms, we describe the equilibrium\nstrategy and value function as the solution of an extended\nHamilton-Jacobi-Bellman system of partial differential equations. We verify\nthat (the solution of) this system is a sufficient condition for an equilibrium\nand examine some of its novel features. A consumption-investment problem for an\nagent with CRRA-CES utility showcases our approach.\n"
    },
    {
        "paper_id": 2407.16527,
        "authors": "Timothy DeLise",
        "title": "The Negative Drift of a Limit Order Fill",
        "comments": "27 Pages, 6 Figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Market making refers to a form of trading in financial markets characterized\nby passive orders which add liquidity to limit order books. Market makers are\nimportant for the proper functioning of financial markets worldwide. Given the\nimportance, financial mathematics has endeavored to derive optimal strategies\nfor placing limit orders in this context. This paper identifies a key\ndiscrepancy between popular model assumptions and the realities of real\nmarkets, specifically regarding the dynamics around limit order fills.\nTraditionally, market making models rely on an assumption of low-cost random\nfills, when in reality we observe a high-cost non-random fill behavior. Namely,\nlimit order fills are caused by and coincide with adverse price movements,\nwhich create a drag on the market maker's profit and loss. We refer to this\nphenomenon as \"the negative drift\" associated with limit order fills. We\ndescribe a discrete market model and prove theoretically that the negative\ndrift exists. We also provide a detailed empirical simulation using one of the\nmost traded financial instruments in the world, the 10 Year US Treasury Bond\nfutures, which also confirms its existence. To our knowledge, this is the first\npaper to describe and prove this phenomenon in such detail.\n"
    },
    {
        "paper_id": 2407.16566,
        "authors": "Chenkai Wang, Junji Ren, Peng Yang",
        "title": "Alleviating Non-identifiability: a High-fidelity Calibration Objective\n  for Financial Market Simulation with Multivariate Time Series Data",
        "comments": "13 pages, 6 figure",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The non-identifiability issue has been frequently reported in the social\nsimulation works, where different parameters of an agent-based simulation model\nyield indistinguishable simulated time series data under certain discrepancy\nmetrics. This issue largely undermines the simulation fidelity yet lacks\ndedicated investigations. This paper theoretically analyzes that incorporating\nmultiple time series data features in the model calibration phase can alleviate\nthe non-identifiability exponentially with the increasing number of features.\nTo implement this theoretical finding, a maximization-based aggregation\nfunction is applied to existing discrepancy metrics to form a new calibration\nobjective function. For verification, the financial market simulation, a\ntypical and complex social simulation task, is considered. Empirical studies on\nboth synthetic and real market data witness the significant improvements in\nalleviating the non-identifiability with much higher simulation fidelity of the\nchosen agent-based simulation model. Importantly, as a model-agnostic method,\nit achieves the first successful simulation of the high-frequency market at\nseconds level. Hence, this work is expected to provide not only a rigorous\nunderstanding of non-identifiability in social simulation, but a high-fidelity\ncalibration objective function for financial market simulations.\n"
    },
    {
        "paper_id": 2407.1678,
        "authors": "Natalia Roszyk, Robert \\'Slepaczuk",
        "title": "The Hybrid Forecast of S&P 500 Volatility ensembled from VIX, GARCH and\n  LSTM models",
        "comments": "38 pages, 18 figures, 14 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Predicting the S&P 500 index volatility is crucial for investors and\nfinancial analysts as it helps assess market risk and make informed investment\ndecisions. Volatility represents the level of uncertainty or risk related to\nthe size of changes in a security's value, making it an essential indicator for\nfinancial planning. This study explores four methods to improve the accuracy of\nvolatility forecasts for the S&P 500: the established GARCH model, known for\ncapturing historical volatility patterns; an LSTM network that utilizes past\nvolatility and log returns; a hybrid LSTM-GARCH model that combines the\nstrengths of both approaches; and an advanced version of the hybrid model that\nalso factors in the VIX index to gauge market sentiment. This analysis is based\non a daily dataset that includes S&P 500 and VIX index data, covering the\nperiod from January 3, 2000, to December 21, 2023. Through rigorous testing and\ncomparison, we found that machine learning approaches, particularly the hybrid\nLSTM models, significantly outperform the traditional GARCH model. Including\nthe VIX index in the hybrid model further enhances its forecasting ability by\nincorporating real-time market sentiment. The results of this study offer\nvaluable insights for achieving more accurate volatility predictions, enabling\nbetter risk management and strategic investment decisions in the volatile\nenvironment of the S&P 500.\n"
    },
    {
        "paper_id": 2407.16813,
        "authors": "Dan Pirjol, Xiaoyu Wang, Lingjiong Zhu",
        "title": "Short-maturity asymptotics for VIX and European options in\n  local-stochastic volatility models",
        "comments": "58 pages, 2 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We derive the short-maturity asymptotics for European and VIX option prices\nin local-stochastic volatility models where the volatility follows a\ncontinuous-path Markov process. Both out-of-the-money (OTM) and at-the-money\n(ATM) asymptotics are considered. Using large deviations theory methods, the\nasymptotics for the OTM options are expressed as a two-dimensional variational\nproblem, which is reduced to an extremal problem for a function of two real\nvariables. This extremal problem is solved explicitly in an expansion in\nlog-moneyness. We derive series expansions for the implied volatility for\nEuropean and VIX options which should be useful for model calibration. We give\nexplicit results for two classes of local-stochastic volatility models relevant\nin practice, with Heston-type and SABR-type stochastic volatility. The\nleading-order asymptotics for at-the-money options are computed in closed-form.\nThe asymptotic results reproduce known results in the literature for the Heston\nand SABR models and for the uncorrelated local-stochastic volatility model. The\nasymptotic results are tested against numerical simulations for a\nlocal-stochastic volatility model with bounded local volatility.\n"
    },
    {
        "paper_id": 2407.16838,
        "authors": "Muhammad Rofiqul Islam, Abdullah Al Mehdi",
        "title": "Bridging Climate Awareness and Sustainable Entrepreneurship: A\n  Conceptual Framework Based on the Theory of Planned Behavior",
        "comments": "10 pages, 1 figure, Published with International Research Journal of\n  Economics and Management Studies (IRJEMS)",
        "journal-ref": "Int. Research J. of Eco. and Mgt. Studies, Vol. 3, No. 7, pp.\n  266-275, 2024",
        "doi": "10.56472/25835238/IRJEMS-V3I7P129",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Many studies have examined the connection between the intention to start a\nbusiness and environmental values. However, there still needs to be more\nknowledge in the extant literature about how climate change campaigns influence\nsustainable entrepreneurial intention. This study uses the Theory of Planned\nBehavior (TPB) to develop a theoretical framework to explain how climate change\ncampaigns affect the intention to start a sustainable business. This\ninterdisciplinary conceptual research model bridges the gap between climate\nawareness, sustainable values, and entrepreneurial intentions, offering a\nrobust framework for understanding and fostering sustainable entrepreneurial\nbehaviors. Our study lays the groundwork for future empirical studies and\nreal-world interventions to advance sustainability through entrepreneurship.\n"
    },
    {
        "paper_id": 2407.16854,
        "authors": "Muhammad Rofiqul Islam, Abdullah Al Mehdi",
        "title": "Impacts of National Cultures on Managerial Decisions of Engaging in Core\n  Earnings Management",
        "comments": "12 pages, 1 figure, \"Published with European Journal of Business and\n  Management\"",
        "journal-ref": "European Journal of Business and Management, 16(4):72-83 (2024)",
        "doi": "10.7176/EJBM/16-4-07",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study investigates the impact of Hofstede's cultural dimensions on\nabnormal core earnings management in multiple national cultural contexts. We\nemploy an Ordinary Least Squares (OLS) regression model with abnormal core\nearnings as the dependent variable. The independent variables analyzed include\nHofstede's dimensions: Power Distance Index (PDI), Individualism (IDV),\nMasculinity (MAS), and Uncertainty Avoidance Index (UAI). Our findings reveal\nthat individualism is positively associated with abnormal core earnings,\nsuggesting that cultures characterized by high individualism may encourage\npractices that inflate earnings due to the prominence of personal achievement\nand rewards. In contrast, masculinity negatively correlates with abnormal core\nearnings, indicating that the risk-taking attributes associated with masculine\ncultures may deter earnings management. Interestingly, uncertainty avoidance is\npositively linked to abnormal core earnings, supporting the notion that\nmanagers tend to engage more in earnings management to minimize fluctuations in\nfinancial reports in cultures with high uncertainty avoidance. The relationship\nbetween power distance and abnormal core earnings is found to be\nnon-significant, indicating no substantial effect in this context. These\nfindings contribute to the literature on cultural influences in financial\nreporting, providing valuable insights for policymakers and multinational firms\nconcerning the cultural contexts within which financial decisions and reporting\noccur.\n"
    },
    {
        "paper_id": 2407.16878,
        "authors": "\\c{C}a\\u{g}{\\i}n Ararat, Zachary Feinstein",
        "title": "On the Separability of Vector-Valued Risk Measures",
        "comments": "13 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Risk measures for random vectors have been considered in multi-asset markets\nwith transaction costs and financial networks in the literature. While the\ntheory of set-valued risk measures provide an axiomatic framework for assigning\nto a random vector its set of all capital requirements or allocation vectors,\nthe actual decision-making process requires an additional rule to select from\nthis set. In this paper, we define vector-valued risk measures by an analogous\nlist of axioms and show that, in the convex and lower semicontinuous case, such\nfunctionals always ignore the dependence structures of the input random\nvectors. We also show that set-valued risk measures do not have this issue as\nlong as they do not reduce to a vector-valued functional. Finally, we\ndemonstrate that our results also generalize to the conditional setting. These\nresults imply that convex vector-valued risk measures are not suitable for\ndefining capital allocation rules for a wide range of financial applications\nincluding systemic risk measures.\n"
    },
    {
        "paper_id": 2407.16885,
        "authors": "Marcello Monga",
        "title": "Automated Market Making and Decentralized Finance",
        "comments": "DPhil thesis. arXiv admin note: text overlap with arXiv:2307.03499",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Automated market makers (AMMs) are a new type of trading venues which are\nrevolutionising the way market participants interact. At present, the majority\nof AMMs are constant function market makers (CFMMs) where a deterministic\ntrading function determines how markets are cleared. Within CFMMs, we focus on\nconstant product market makers (CPMMs) which implements the concentrated\nliquidity (CL) feature. In this thesis we formalise and study the trading\nmechanism of CPMMs with CL, and we develop liquidity provision and liquidity\ntaking strategies. Our models are motivated and tested with market data.\n  We derive optimal strategies for liquidity takers (LTs) who trade orders of\nlarge size and execute statistical arbitrages. First, we consider an LT who\ntrades in a CPMM with CL and uses the dynamics of prices in competing venues as\nmarket signals. We use Uniswap v3 data to study price, liquidity, and trading\ncost dynamics, and to motivate the model. Next, we consider an LT who trades a\nbasket of crypto-currencies whose constituents co-move. We use market data to\nstudy lead-lag effects, spillover effects, and causality between trading\nvenues.\n  We derive optimal strategies for strategic liquidity providers (LPs) who\nprovide liquidity in CPMM with CL. First, we use stochastic control tools to\nderive a self-financing and closed-form optimal liquidity provision strategy\nwhere the width of the LP's liquidity range is determined by the profitability\nof the pool, the dynamics of the LP's position, and concentration risk. Next,\nwe use a model-free approach to solve the problem of an LP who provides\nliquidity in multiple CPMMs with CL. We do not specify a model for the\nstochastic processes observed by LPs, and use a long short-term memory (LSTM)\nneural network to approximate the optimal liquidity provision strategy.\n"
    },
    {
        "paper_id": 2407.17014,
        "authors": "Amirreza Talebi",
        "title": "Simulation in discrete choice models evaluation: SDCM, a simulation tool\n  for performance evaluation of DCMs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Discrete choice models (DCMs) have been widely utilized in various scientific\nfields, especially economics, for many years. These models consider a\nstochastic environment influencing each decision maker's choices. Extensive\nresearch has shown that the agents' socioeconomic characteristics, the chosen\noptions' properties, and the conditions characterizing the decision-making\nenvironment all impact these models. However, the complex interactions between\nthese factors, confidentiality concerns, time constraints, and costs, have made\nreal experimentation impractical and undesirable. To address this, simulations\nhave gained significant popularity among academics, allowing the study of these\nmodels in a controlled setting using simulated data. This paper presents\nmultidisciplinary research to bridge the gap between DCMs, experimental design,\nand simulation. By reviewing related literature, the authors explore these\ninterconnected areas. We then introduce a simulation method integrated with\nexperimental design to generate synthetic data based on behavioral models of\nagents. A utility function is used to describe the developed simulation tool.\nThe paper investigates the discrepancy between simulated data and real-world\ndata.\n"
    },
    {
        "paper_id": 2407.17048,
        "authors": "Jon Danielsson and Andreas Uthemann",
        "title": "Artificial intelligence and financial crises",
        "comments": "26 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  The rapid adoption of artificial intelligence (AI) is transforming the\nfinancial industry. AI will either increase systemic financial risk or act to\nstabilise the system, depending on endogenous responses, strategic\ncomplementarities, the severity of events it faces and the objectives it is\ngiven. AI's ability to master complexity and respond rapidly to shocks means\nfuture crises will likely be more intense than those we have seen so far.\n"
    },
    {
        "paper_id": 2407.17084,
        "authors": "Robert J. Kolesar, Rok Spruk",
        "title": "Effect of Austerity Measures on Infant Mortality: Evidence from Greece",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study examines the effect of fiscal austerity measures on infant\nmortality in Greece. Austerity measures were initiated by the tripartite\ncommittee and implemented between 2010 and 2017 to counteract deep fiscal\ndeficit and large public debt. By comparing Greece with a plausible donor pool\nof OECD and Mediterranean member states in the period 1991-2020, we estimate a\nseries of missing counterfactual scenarios to evaluate the infant mortality\neffects of large-scale reduction in spending on health care. A series of hybrid\nsynthetic control and difference-in-differences estimates indicate a unique and\npervasive increase in infant mortality after the implementation of austerity\nmeasures. Compared to a plausible OECD and Mediterranean counterfactual\nscenario, pro-cyclical austerity measures are associated with derailed and\npermanently increased infant mortality up to the present day. Our estimates\nsuggest that compared to a plausible counterfactual scenario, the cumulative\ninfant mortality cost of austerity policies exceeds 10,000 infant deaths or\nslightly less than 850 deaths for each year of the austerity policies. Notably,\nmortality increases are concentrated among boys. The estimated impacts survive\na battery of rigorous robustness and placebo tests.\n"
    },
    {
        "paper_id": 2407.17151,
        "authors": "Aur\\'elien Alfonsi and Edoardo Lombardo",
        "title": "High order approximations of the log-Heston process semigroup",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present weak approximations schemes of any order for the Heston model that\nare obtained by using the method developed by Alfonsi and Bally (2021). This\nmethod consists in combining approximation schemes calculated on different\nrandom grids to increase the order of convergence. We apply this method with\neither the Ninomiya-Victoir scheme (2008) or a second-order scheme that samples\nexactly the volatility component, and we show rigorously that we can achieve\nthen any order of convergence. We give numerical illustrations on financial\nexamples that validate the theoretical order of convergence, and present also\npromising numerical results for the multifactor/rough Heston model.\n"
    },
    {
        "paper_id": 2407.17293,
        "authors": "Siyu Chen and Qing Guo",
        "title": "Fintech and MSEs Innovation: an Empirical Analysis",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Employing a comprehensive survey of micro and small enterprises (MSEs) and\nthe Digital Financial Inclusion Index in China, this study investigates the\ninfluence of fintech on MSE innovation empirically. Our findings indicate that\nfintech advancement substantially enhances the likelihood of MSEs engaging in\ninnovative endeavors and boosts both the investment and outcomes of their\ninnovation processes. The underlying mechanisms are attributed to fintech's\nrole in fostering long-term strategic incentives and investment in human\ncapital. This includes the use of promotions and stock options as rewards,\nrather than traditional perks like gifts or trips, the attraction of a greater\nnumber of university graduates, and the increase in both training expenses and\nthe remuneration of technical staff. Our heterogeneity analysis reveals that\nfintech exerts a more pronounced effect on MSEs situated in economically\ndeveloped areas, those that are five years old or younger, and businesses with\nlimited assets and workforce. Additionally, we uncover that fintech stimulates\nthe innovation of MSEs' independent research and development (R\\&D) efforts.\nThis paper contributes to the understanding of the nuanced ways in which\nfintech impacts MSE innovation and offers policy insights aimed at unleashing\nthe full potential of MSEs' innovative capabilities.\n"
    },
    {
        "paper_id": 2407.17393,
        "authors": "Robert Boyce, Martin Herdegen, Leandro S\\'anchez-Betancourt",
        "title": "Market Making with Exogenous Competition",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study liquidity provision in the presence of exogenous competition. We\nconsider a `reference market maker' who monitors her inventory and the\naggregated inventory of the competing market makers. We assume that the\ncompeting market makers use a `rule of thumb' to determine their posted depths,\ndepending linearly on their inventory. By contrast, the reference market maker\noptimises over her posted depths, and we assume that her fill probability\ndepends on the difference between her posted depths and the competition's\ndepths in an exponential way. For a linear-quadratic goal functional, we show\nthat this model admits an approximate closed-form solution. We illustrate the\nfeatures of our model and compare against alternative ways of solving the\nproblem either via an Euler scheme or state-of-the-art reinforcement learning\ntechniques.\n"
    },
    {
        "paper_id": 2407.17401,
        "authors": "Xavier Brouty, Matthieu Garcin and Hugo Roccaro",
        "title": "Estimation of bid-ask spreads in the presence of serial dependence",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  Starting from a basic model in which the dynamic of the transaction prices is\na geometric Brownian motion disrupted by a microstructure white noise,\ncorresponding to the random alternation of bids and asks, we propose\nmoment-based estimators along with their statistical properties. We then make\nthe model more realistic by considering serial dependence: we assume a\ngeometric fractional Brownian motion for the price, then an Ornstein-Uhlenbeck\nprocess for the microstructure noise. In these two cases of serial dependence,\nwe propose again consistent and asymptotically normal estimators. All our\nestimators are compared on simulated data with existing approaches, such as\nRoll, Corwin-Schultz, Abdi-Ranaldo, or Ardia-Guidotti-Kroencke estimators.\n"
    },
    {
        "paper_id": 2407.17489,
        "authors": "Josie Zvelebilova and Saiph Savage and Christoph Riedl",
        "title": "Collective Attention in Human-AI Teams",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  How does the presence of an AI assistant affect the collective attention of a\nteam? We study 20 human teams of 3-4 individuals paired with one voice-only AI\nassistant during a challenging puzzle task. Teams are randomly assigned to an\nAI assistant with a human- or robotic-sounding voice that provides either\nhelpful or misleading information about the task. Treating each individual AI\ninterjection as a treatment intervention, we identify the causal effects of the\nAI on dynamic group processes involving language use. Our findings demonstrate\nthat the AI significantly affects what teams discuss, how they discuss it, and\nthe alignment of their mental models. Teams adopt AI-introduced language for\nboth terms directly related to the task and for peripheral terms, even when\nthey (a) recognize the unhelpful nature of the AI, (b) do not consider the AI a\ngenuine team member, and (c) do not trust the AI. The process of language\nadaptation appears to be automatic, despite doubts about the AI's competence.\nThe presence of an AI assistant significantly impacts team collective attention\nby modulating various aspects of shared cognition. This study contributes to\nhuman-AI teaming research by highlighting collective attention as a central\nmechanism through which AI systems in team settings influence team performance.\nUnderstanding this mechanism will help CSCW researchers design AI systems that\nenhance team collective intelligence by optimizing collective attention.\n"
    },
    {
        "paper_id": 2407.17523,
        "authors": "Yi Zheng",
        "title": "How does the national new area impact the local economy? -- An empirical\n  analysis from Zhoushan",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  To empirically study the policy impact of a National New Area on the local\neconomy, this paper evaluates the effect of the Zhoushan Archipelago New Area\non local GDP growth rate and economic efficiency. By collecting input and\noutput data from 20 prefectural-level cities in Jiangsu, Zhejiang, and Anhui\nprovinces from 1995 to 2015, we estimate the economic efficiency of these\ncities using data envelopment analysis. Subsequently, we construct\ncounterfactuals for Zhoushan by selecting comparable cities from the dataset,\nexcluding Zhoushan, and applying a panel data approach. The difference between\nthe actual and counterfactual values for GDP growth rate and economic\nefficiency in Zhoushan is analyzed to determine the treatment effect of the\nNational New Area policy. The research reveals that in the initial four years,\nthe New Area policy enhanced Zhoushan's economic efficiency but negatively\naffected its GDP growth rate. This influence gradually disappeared after four\nyears. Further analysis suggests that the policy's effect on GDP growth rate\nvaries with the level of economic development in different regions, having a\nmore substantial impact in less developed areas. Therefore, we conclude that\nestablishing a New Area in relatively undeveloped zones is more advantageous.\n"
    },
    {
        "paper_id": 2407.17624,
        "authors": "Felix Drinkall and Janet B. Pierrehumbert and Stefan Zohren",
        "title": "Traditional Methods Outperform Generative LLMs at Forecasting Credit\n  Ratings",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Large Language Models (LLMs) have been shown to perform well for many\ndownstream tasks. Transfer learning can enable LLMs to acquire skills that were\nnot targeted during pre-training. In financial contexts, LLMs can sometimes\nbeat well-established benchmarks. This paper investigates how well LLMs perform\nin the task of forecasting corporate credit ratings. We show that while LLMs\nare very good at encoding textual information, traditional methods are still\nvery competitive when it comes to encoding numeric and multimodal data. For our\ntask, current LLMs perform worse than a more traditional XGBoost architecture\nthat combines fundamental and macroeconomic data with high-density text-based\nembedding features.\n"
    },
    {
        "paper_id": 2407.17645,
        "authors": "Carlo Nicolini, Monisha Gopalan, Jacopo Staiano, Bruno Lepri",
        "title": "Hopfield Networks for Asset Allocation",
        "comments": "12 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We present the first application of modern Hopfield networks to the problem\nof portfolio optimization. We performed an extensive study based on\ncombinatorial purged cross-validation over several datasets and compared our\nresults to both traditional and deep-learning-based methods for portfolio\nselection. Compared to state-of-the-art deep-learning methods such as\nLong-Short Term Memory networks and Transformers, we find that the proposed\napproach performs on par or better, while providing faster training times and\nbetter stability. Our results show that Modern Hopfield Networks represent a\npromising approach to portfolio optimization, allowing for an efficient,\nscalable, and robust solution for asset allocation, risk management, and\ndynamic rebalancing.\n"
    },
    {
        "paper_id": 2407.17731,
        "authors": "Zi Wang, Xingcheng Xu, Yanqing Yang, Xiaodong Zhu",
        "title": "Optimal Trade and Industrial Policies in the Global Economy: A Deep\n  Learning Framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We propose a deep learning framework, DL-opt, designed to efficiently solve\nfor optimal policies in quantifiable general equilibrium trade models. DL-opt\nintegrates (i) a nested fixed point (NFXP) formulation of the optimization\nproblem, (ii) automatic implicit differentiation to enhance gradient descent\nfor solving unilateral optimal policies, and (iii) a best-response dynamics\napproach for finding Nash equilibria. Utilizing DL-opt, we solve for\nnon-cooperative tariffs and industrial subsidies across 7 economies and 44\nsectors, incorporating sectoral external economies of scale. Our quantitative\nanalysis reveals significant sectoral heterogeneity in Nash policies: Nash\nindustrial subsidies increase with scale elasticities, whereas Nash tariffs\ndecrease with trade elasticities. Moreover, we show that global dual\ncompetition, involving both tariffs and industrial subsidies, results in lower\ntariffs and higher welfare outcomes compared to a global tariff war. These\nfindings highlight the importance of considering sectoral heterogeneity and\npolicy combinations in understanding global economic competition.\n"
    },
    {
        "paper_id": 2407.17866,
        "authors": "Alex Kim, Maximilian Muhn, Valeri Nikolaev",
        "title": "Financial Statement Analysis with Large Language Models",
        "comments": "Previously posted on SSRN (May 21, 2024). See\n  http://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  We investigate whether an LLM can successfully perform financial statement\nanalysis in a way similar to a professional human analyst. We provide\nstandardized and anonymous financial statements to GPT4 and instruct the model\nto analyze them to determine the direction of future earnings. Even without any\nnarrative or industry-specific information, the LLM outperforms financial\nanalysts in its ability to predict earnings changes. The LLM exhibits a\nrelative advantage over human analysts in situations when the analysts tend to\nstruggle. Furthermore, we find that the prediction accuracy of the LLM is on\npar with the performance of a narrowly trained state-of-the-art ML model. LLM\nprediction does not stem from its training memory. Instead, we find that the\nLLM generates useful narrative insights about a company's future performance.\nLastly, our trading strategies based on GPT's predictions yield a higher Sharpe\nratio and alphas than strategies based on other models. Taken together, our\nresults suggest that LLMs may take a central role in decision-making.\n"
    },
    {
        "paper_id": 2407.17975,
        "authors": "Gechun Liang, Wei Wei, Zhen Wu, Zhenda Xu",
        "title": "Recursive Optimal Stopping with Poisson Stopping Constraints",
        "comments": "27 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper solves a recursive optimal stopping problem with Poisson stopping\nconstraints using the penalized backward stochastic differential equation\n(PBSDE) with jumps. Stopping in this problem is only allowed at Poisson random\nintervention times, and jumps play a significant role not only through the\nstopping times but also in the recursive objective functional and model\ncoefficients. To solve the problem, we propose a decomposition method based on\nJacod-Pham that allows us to separate the problem into a series of sub-problems\nbetween each pair of consecutive Poisson stopping times. To represent the value\nfunction of the recursive optimal stopping problem when the initial time falls\nbetween two consecutive Poisson stopping times and the generator is\nconcave/convex, we leverage the comparison theorem of BSDEs with jumps. We then\napply the representation result to American option pricing in a nonlinear\nmarket with Poisson stopping constraints.\n"
    },
    {
        "paper_id": 2407.18103,
        "authors": "Tian Guo, Emmanuel Hauptmann",
        "title": "Fine-Tuning Large Language Models for Stock Return Prediction Using\n  Newsflow",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Large language models (LLMs) and their fine-tuning techniques have\ndemonstrated superior performance in various language understanding and\ngeneration tasks. This paper explores fine-tuning LLMs for stock return\nforecasting with financial newsflow. In quantitative investing, return\nforecasting is fundamental for subsequent tasks like stock picking, portfolio\noptimization, etc. We formulate the model to include text representation and\nforecasting modules. We propose to compare the encoder-only and decoder-only\nLLMs, considering they generate text representations in distinct ways. The\nimpact of these different representations on forecasting performance remains an\nopen question. Meanwhile, we compare two simple methods of integrating LLMs'\ntoken-level representations into the forecasting module. The experiments on\nreal news and investment universes reveal that: (1) aggregated representations\nfrom LLMs' token-level embeddings generally produce return predictions that\nenhance the performance of long-only and long-short portfolios; (2) in the\nrelatively large investment universe, the decoder LLMs-based prediction model\nleads to stronger portfolios, whereas in the small universes, there are no\nconsistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama),\nMistral performs more robustly across different universes; (3) return\npredictions derived from LLMs' text representations are a strong signal for\nportfolio construction, outperforming conventional sentiment scores.\n"
    },
    {
        "paper_id": 2407.18324,
        "authors": "Shengkun Wang, Taoran Ji, Jianfeng He, Mariam Almutairi, Dan Wang,\n  Linhan Wang, Min Zhang, Chang-Tien Lu",
        "title": "AMA-LSTM: Pioneering Robust and Fair Financial Audio Analysis for Stock\n  Volatility Prediction",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Stock volatility prediction is an important task in the financial industry.\nRecent advancements in multimodal methodologies, which integrate both textual\nand auditory data, have demonstrated significant improvements in this domain,\nsuch as earnings calls (Earnings calls are public available and often involve\nthe management team of a public company and interested parties to discuss the\ncompany's earnings). However, these multimodal methods have faced two\ndrawbacks. First, they often fail to yield reliable models and overfit the data\ndue to their absorption of stochastic information from the stock market.\nMoreover, using multimodal models to predict stock volatility suffers from\ngender bias and lacks an efficient way to eliminate such bias. To address these\naforementioned problems, we use adversarial training to generate perturbations\nthat simulate the inherent stochasticity and bias, by creating areas resistant\nto random information around the input space to improve model robustness and\nfairness. Our comprehensive experiments on two real-world financial audio\ndatasets reveal that this method exceeds the performance of current\nstate-of-the-art solution. This confirms the value of adversarial training in\nreducing stochasticity and bias for stock volatility prediction tasks.\n"
    },
    {
        "paper_id": 2407.18327,
        "authors": "Adria Pop, Jan Sp\\\"orer, Siegfried Handschuh",
        "title": "The Structure of Financial Equity Research Reports -- Identification of\n  the Most Frequently Asked Questions in Financial Analyst Reports to Automate\n  Equity Research Using Llama 3 and GPT-4",
        "comments": "JEL classes: C45; G11; G12; G14",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This research dissects financial equity research reports (ERRs) by mapping\ntheir content into categories. There is insufficient empirical analysis of the\nquestions answered in ERRs. In particular, it is not understood how frequently\ncertain information appears, what information is considered essential, and what\ninformation requires human judgment to distill into an ERR. The study analyzes\n72 ERRs sentence-by-sentence, classifying their 4940 sentences into 169 unique\nquestion archetypes. We did not predefine the questions but derived them solely\nfrom the statements in the ERRs. This approach provides an unbiased view of the\ncontent of the observed ERRs. Subsequently, we used public corporate reports to\nclassify the questions' potential for automation. Answers were labeled\n\"text-extractable\" if the answers to the question were accessible in corporate\nreports. 78.7% of the questions in ERRs can be automated. Those automatable\nquestion consist of 48.2% text-extractable (suited to processing by large\nlanguage models, LLMs) and 30.5% database-extractable questions. Only 21.3% of\nquestions require human judgment to answer. We empirically validate using\nLlama-3-70B and GPT-4-turbo-2024-04-09 that recent advances in language\ngeneration and information extraction enable the automation of approximately\n80% of the statements in ERRs. Surprisingly, the models complement each other's\nstrengths and weaknesses well. The research confirms that the current writing\nprocess of ERRs can likely benefit from additional automation, improving\nquality and efficiency. The research thus allows us to quantify the potential\nimpacts of introducing large language models in the ERR writing process. The\nfull question list, including the archetypes and their frequency, will be made\navailable online after peer review.\n"
    },
    {
        "paper_id": 2407.18334,
        "authors": "Abdul Jabbar and Syed Qaisar Jalil",
        "title": "A Comprehensive Analysis of Machine Learning Models for Algorithmic\n  Trading of Bitcoin",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study evaluates the performance of 41 machine learning models, including\n21 classifiers and 20 regressors, in predicting Bitcoin prices for algorithmic\ntrading. By examining these models under various market conditions, we\nhighlight their accuracy, robustness, and adaptability to the volatile\ncryptocurrency market. Our comprehensive analysis reveals the strengths and\nlimitations of each model, providing critical insights for developing effective\ntrading strategies. We employ both machine learning metrics (e.g., Mean\nAbsolute Error, Root Mean Squared Error) and trading metrics (e.g., Profit and\nLoss percentage, Sharpe Ratio) to assess model performance. Our evaluation\nincludes backtesting on historical data, forward testing on recent unseen data,\nand real-world trading scenarios, ensuring the robustness and practical\napplicability of our models. Key findings demonstrate that certain models, such\nas Random Forest and Stochastic Gradient Descent, outperform others in terms of\nprofit and risk management. These insights offer valuable guidance for traders\nand researchers aiming to leverage machine learning for cryptocurrency trading.\n"
    },
    {
        "paper_id": 2407.18504,
        "authors": "Devang Sinha, Siddhartha P. Chakrabarty",
        "title": "Multilevel Monte Carlo in Sample Average Approximation: Convergence,\n  Complexity and Application",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this paper, we examine the Sample Average Approximation (SAA) procedure\nwithin a framework where the Monte Carlo estimator of the expectation is\nbiased. We also introduce Multilevel Monte Carlo (MLMC) in the SAA setup to\nenhance the computational efficiency of solving optimization problems. In this\ncontext, we conduct a thorough analysis, exploiting Cram\\'er's large deviation\ntheory, to establish uniform convergence, quantify the convergence rate, and\ndetermine the sample complexity for both standard Monte Carlo and MLMC\nparadigms. Additionally, we perform a root-mean-squared error analysis\nutilizing tools from empirical process theory to derive sample complexity\nwithout relying on the finite moment condition typically required for uniform\nconvergence results. Finally, we validate our findings and demonstrate the\nadvantages of the MLMC estimator through numerical examples, estimating\nConditional Value-at-Risk (CVaR) in the Geometric Brownian Motion and nested\nexpectation framework.\n"
    },
    {
        "paper_id": 2407.18519,
        "authors": "Wenbo Yan, Ying Tan",
        "title": "TCGPN: Temporal-Correlation Graph Pre-trained Network for Stock\n  Forecasting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Recently, the incorporation of both temporal features and the correlation\nacross time series has become an effective approach in time series prediction.\nSpatio-Temporal Graph Neural Networks (STGNNs) demonstrate good performance on\nmany Temporal-correlation Forecasting Problem. However, when applied to tasks\nlacking periodicity, such as stock data prediction, the effectiveness and\nrobustness of STGNNs are found to be unsatisfactory. And STGNNs are limited by\nmemory savings so that cannot handle problems with a large number of nodes. In\nthis paper, we propose a novel approach called the Temporal-Correlation Graph\nPre-trained Network (TCGPN) to address these limitations. TCGPN utilize\nTemporal-correlation fusion encoder to get a mixed representation and\npre-training method with carefully designed temporal and correlation\npre-training tasks. Entire structure is independent of the number and order of\nnodes, so better results can be obtained through various data enhancements. And\nmemory consumption during training can be significantly reduced through\nmultiple sampling. Experiments are conducted on real stock market data sets\nCSI300 and CSI500 that exhibit minimal periodicity. We fine-tune a simple MLP\nin downstream tasks and achieve state-of-the-art results, validating the\ncapability to capture more robust temporal correlation patterns.\n"
    },
    {
        "paper_id": 2407.18583,
        "authors": "St\\'ephane Cr\\'epey (UFR Math\\'ematiques UPCit\\'e), Botao Li (LPSM\n  (UMR\\_8001)), Hoang Nguyen (IES, LPSM (UMR\\_8001)), Bouazza Saadeddine",
        "title": "CVA Sensitivities, Hedging and Risk",
        "comments": "This is the long, preprint version of the eponymous paper forthcoming\n  in Risk Magazine",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a unified framework for computing CVA sensitivities, hedging the\nCVA, and assessing CVA risk, using probabilistic machine learning meant as\nrefined regression tools on simulated data, validatable by low-cost companion\nMonte Carlo procedures. Various notions of sensitivities are introduced and\nbenchmarked numerically. We identify the sensitivities representing the best\npractical trade-offs in downstream tasks including CVA hedging and risk\nassessment.\n"
    },
    {
        "paper_id": 2407.18645,
        "authors": "Rian Dolphin, Barry Smyth, Ruihai Dong",
        "title": "Contrastive Learning of Asset Embeddings from Financial Time Series",
        "comments": "9 pages, 4 figures, 4 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Representation learning has emerged as a powerful paradigm for extracting\nvaluable latent features from complex, high-dimensional data. In financial\ndomains, learning informative representations for assets can be used for tasks\nlike sector classification, and risk management. However, the complex and\nstochastic nature of financial markets poses unique challenges. We propose a\nnovel contrastive learning framework to generate asset embeddings from\nfinancial time series data. Our approach leverages the similarity of asset\nreturns over many subwindows to generate informative positive and negative\nsamples, using a statistical sampling strategy based on hypothesis testing to\naddress the noisy nature of financial data. We explore various contrastive loss\nfunctions that capture the relationships between assets in different ways to\nlearn a discriminative representation space. Experiments on real-world datasets\ndemonstrate the effectiveness of the learned asset embeddings on benchmark\nindustry classification and portfolio optimization tasks. In each case our\nnovel approaches significantly outperform existing baselines highlighting the\npotential for contrastive learning to capture meaningful and actionable\nrelationships in financial data.\n"
    },
    {
        "paper_id": 2407.18687,
        "authors": "Marcelo Righi, Eduardo Horta, Marlon Moresco",
        "title": "Set risk measures",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce the concept of set risk measures (SRMs), which are real-valued\nmaps defined on the space of all non-empty, closed, and bounded sets of almost\nsurely bounded random variables. Traditional risk measures typically operate on\nspaces of random variables, but SRMs extend this framework to sets of random\nvariables. We establish an axiom scheme for SRMs, similar to classical risk\nmeasures but adapted for set operations. The main technical contribution is an\naxiomatic dual representation of convex SRMs by using regular, finitely\nadditive measures on the unit ball of the dual space of essentially bounded\nrandom variables. We explore worst-case SRMs, which evaluate risk as the\nsupremum of individual risks within a set, and provide a collection of examples\nillustrating the applicability of our framework to systemic risk, portfolio\noptimization, and decision-making under uncertainty. This work extends the\ntheory of risk measures to a more general and flexible setup, accommodating a\nbroader range of financial and mathematical applications.\n"
    },
    {
        "paper_id": 2407.18781,
        "authors": "Julio Backhoff-Veraguas, Gudmund Pammer, Walter Schachermayer",
        "title": "The Gradient Flow of the Bass Functional in Martingale Optimal Transport",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Given $\\mu$ and $\\nu$, probability measures on $\\mathbb R^d$ in convex order,\na Bass martingale is arguably the most natural martingale starting with law\n$\\mu$ and finishing with law $\\nu$. Indeed, this martingale is obtained by\nstretching a reference Brownian motion so as to meet the data $\\mu,\\nu$. Unless\n$\\mu$ is a Dirac, the existence of a Bass martingale is a delicate subject,\nsince for instance the reference Brownian motion must be allowed to have a\nnon-trivial initial distribution $\\alpha$, not known in advance. Thus the key\nto obtaining the Bass martingale, theoretically as well as practically, lies in\nfinding $\\alpha$.\n  In \\cite{BaSchTsch23} it has been shown that $\\alpha$ is determined as the\nminimizer of the so-called Bass functional. In the present paper we propose to\nminimize this functional by following its gradient flow, or more precisely, the\ngradient flow of its $L^2$-lift. In our main result we show that this gradient\nflow converges in norm to a minimizer of the Bass functional, and when $d=1$ we\nfurther establish that convergence is exponentially fast.\n"
    },
    {
        "paper_id": 2407.18957,
        "authors": "Chong Zhang, Xinyi Liu, Mingyu Jin, Zhongmou Zhang, Lingyao Li,\n  Zhenting Wang, Wenyue Hua, Dong Shu, Suiyuan Zhu, Xiaobo Jin, Sujian Li,\n  Mengnan Du, Yongfeng Zhang",
        "title": "When AI Meets Finance (StockAgent): Large Language Model-based Stock\n  Trading in Simulated Real-world Environments",
        "comments": "33 pages, 10 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Can AI Agents simulate real-world trading environments to investigate the\nimpact of external factors on stock trading activities (e.g., macroeconomics,\npolicy changes, company fundamentals, and global events)? These factors, which\nfrequently influence trading behaviors, are critical elements in the quest for\nmaximizing investors' profits. Our work attempts to solve this problem through\nlarge language model based agents. We have developed a multi-agent AI system\ncalled StockAgent, driven by LLMs, designed to simulate investors' trading\nbehaviors in response to the real stock market. The StockAgent allows users to\nevaluate the impact of different external factors on investor trading and to\nanalyze trading behavior and profitability effects. Additionally, StockAgent\navoids the test set leakage issue present in existing trading simulation\nsystems based on AI Agents. Specifically, it prevents the model from leveraging\nprior knowledge it may have acquired related to the test data. We evaluate\ndifferent LLMs under the framework of StockAgent in a stock trading environment\nthat closely resembles real-world conditions. The experimental results\ndemonstrate the impact of key external factors on stock market trading,\nincluding trading behavior and stock price fluctuation rules. This research\nexplores the study of agents' free trading gaps in the context of no prior\nknowledge related to market data. The patterns identified through StockAgent\nsimulations provide valuable insights for LLM-based investment advice and stock\nrecommendation. The code is available at\nhttps://github.com/MingyuJ666/Stockagent.\n"
    },
    {
        "paper_id": 2407.18966,
        "authors": "Tatsuru Kikuchi",
        "title": "Towards A Post-Quantum Cryptography in Blockchain I: Basic Review on\n  Theoretical Cryptography and Quantum Information Theory",
        "comments": "32 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Recently, the invention of quantum computers was so revolutionary that they\nbring transformative challenges in a variety of fields, especially for the\ntraditional cryptographic blockchain, and it may become a real thread for most\nof the cryptocurrencies in the market. That is, it becomes inevitable to\nconsider to implement a post-quantum cryptography, which is also referred to as\nquantum-resistant cryptography, for attaining quantum resistance in\nblockchains.\n"
    },
    {
        "paper_id": 2407.1919,
        "authors": "Daniele Marazzina",
        "title": "Optimal retirement in presence of stochastic labor income: a free\n  boundary approach in presence of an incomplete market",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "abstract": "  In this note, we show how to solve an optimal retirement problem in presence\nof a stochastic wage dealing with a free boundary problem. In particular, we\nshow how to deal with an incomplete market case, where the wage cannot be fully\nhedged investing in the risk-free and the risky asset describing the financial\nmarket.\n"
    },
    {
        "paper_id": 2407.19352,
        "authors": "Liyang Wang, Yu Cheng, Xingxin Gu, Zhizhong Wu",
        "title": "Design and Optimization of Big Data and Machine Learning-Based Risk\n  Monitoring System in Financial Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  With the increasing complexity of financial markets and rapid growth in data\nvolume, traditional risk monitoring methods no longer suffice for modern\nfinancial institutions. This paper designs and optimizes a risk monitoring\nsystem based on big data and machine learning. By constructing a four-layer\narchitecture, it effectively integrates large-scale financial data and advanced\nmachine learning algorithms. Key technologies employed in the system include\nLong Short-Term Memory (LSTM) networks, Random Forest, Gradient Boosting Trees,\nand real-time data processing platform Apache Flink, ensuring the real-time and\naccurate nature of risk monitoring. Research findings demonstrate that the\nsystem significantly enhances efficiency and accuracy in risk management,\nparticularly excelling in identifying and warning against market crash risks.\n"
    },
    {
        "paper_id": 2407.19367,
        "authors": "Chunhui Qiao and Xiangwei Wan",
        "title": "Enhancing Black-Scholes Delta Hedging via Deep Learning",
        "comments": "35 pages, 4 figures, 10 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper proposes a deep delta hedging framework for options, utilizing\nneural networks to learn the residuals between the hedging function and the\nimplied Black-Scholes delta. This approach leverages the smoother properties of\nthese residuals, enhancing deep learning performance. Utilizing ten years of\ndaily S&P 500 index option data, our empirical analysis demonstrates that\nlearning the residuals, using the mean squared one-step hedging error as the\nloss function, significantly improves hedging performance over directly\nlearning the hedging function, often by more than 100%. Adding input features\nwhen learning the residuals enhances hedging performance more for puts than\ncalls, with market sentiment being less crucial. Furthermore, learning the\nresiduals with three years of data matches the hedging performance of directly\nlearning with ten years of data, proving that our method demands less data.\n"
    },
    {
        "paper_id": 2407.19439,
        "authors": "Mark Fenwick, Erik P. M. Vermeulen and Marcelo Corrales Compagnucci",
        "title": "Business and Regulatory Responses to Artificial Intelligence: Dynamic\n  Regulation, Innovation Ecosystems and the Strategic Management of Disruptive\n  Technology",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Identifying and then implementing an effective response to disruptive new AI\ntechnologies is enormously challenging for any business looking to integrate AI\ninto their operations, as well as regulators looking to leverage AI-related\ninnovation as a mechanism for achieving regional economic growth. These\nbusiness and regulatory challenges are particularly significant given the broad\nreach of AI, as well as the multiple uncertainties surrounding such\ntechnologies and their future development and effects. This article identifies\ntwo promising strategies for meeting the AI challenge, focusing on the example\nof Fintech. First, dynamic regulation, in the form of regulatory sandboxes and\nother regulatory approaches that aim to provide a space for responsible\nAI-related innovation. An empirical study provides preliminary evidence to\nsuggest that jurisdictions that adopt a more proactive approach to Fintech\nregulation can attract greater investment. The second strategy relates to\nso-called innovation ecosystems. It is argued that such ecosystems are most\neffective when they afford opportunities for creative partnerships between\nwell-established corporations and AI-focused startups and that this aspect of a\nsuccessful innovation ecosystem is often overlooked in the existing discussion.\nThe article suggests that these two strategies are interconnected, in that\ngreater investment is an important element in both fostering and signaling a\nwell-functioning innovation ecosystem and that a well-functioning ecosystem\nwill, in turn, attract more funding. The resulting synergies between these\nstrategies can, therefore, provide a jurisdiction with a competitive edge in\nbecoming a regional hub for AI-related activity.\n"
    },
    {
        "paper_id": 2407.19749,
        "authors": "Elia Moretti and Michael Benzaquen",
        "title": "Mitigating Farmland Biodiversity Loss: A Bio-Economic Model of Land\n  Consolidation and Pesticide Use",
        "comments": "17 pages, 5 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Biodiversity loss driven by agricultural intensification is a pressing global\nissue, with significant implications for ecosystem stability and human\nwell-being. We design an integrated bio-economic agent-based model, informed by\nhistorical data from the French agricultural sector, to project future\nbiodiversity trends and evaluate policy interventions. Our model predicts\nfurther biodiversity decline under a business-as-usual scenario, primarily due\nto intensified land consolidation. We evaluate two policy options: reducing\npesticide use and subsidizing small farmers. While pesticide reduction rapidly\nbenefits biodiversity in the beginning, it eventually leads to increased land\nconsolidation and further biodiversity loss. In contrast, subsidizing small\nfarmers by reallocating a small fraction of existing subsidies, stabilizes farm\nsizes and enhances biodiversity in the long run. The most effective strategy\nresults from combining both policies, leveraging pesticide reduction alongside\ntargeted subsidies to balance economic pressures and consistently improve\nbiodiversity.\n"
    },
    {
        "paper_id": 2407.19762,
        "authors": "Jonghyun Kim and Donghyeon Yu and Hyoji Choi and Dongwoo Seo and\n  Bogang Jun",
        "title": "Redefining Urban Centrality: Integrating Economic Complexity Indices\n  into Central Place Theory",
        "comments": "18 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study introduces a metric designed to measure urban structures through\nthe economic complexity lens, building on the foundational theories of urban\nspatial structure, the Central Place Theory (CPT) (Christaller, 1933). Despite\nthe significant contribution in the field of urban studies and geography, CPT\nhas limited in suggesting an index that captures its key ideas. By analyzing\nvarious urban big data of Seoul, we demonstrate that PCI and ECI effectively\nidentify the key ideas of CPT, capturing the spatial structure of a city that\nassociated with the distribution of economic activities, infrastructure, and\nmarket orientation in line with the CPT. These metrics for urban centrality\noffer a modern approach to understanding the Central Place Theory and tool for\nurban planning and regional economic strategies without privacy issues.\n"
    },
    {
        "paper_id": 2407.19848,
        "authors": "Chung I Lu, Julian Sester",
        "title": "Generative model for financial time series trained with MMD using a\n  signature kernel",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Generating synthetic financial time series data that accurately reflects\nreal-world market dynamics holds tremendous potential for various applications,\nincluding portfolio optimization, risk management, and large scale machine\nlearning. We present an approach for training generative models for financial\ntime series using the maximum mean discrepancy (MMD) with a signature kernel.\nOur method leverages the expressive power of the signature transform to capture\nthe complex dependencies and temporal structures inherent in financial data. We\nemploy a moving average model to model the variance of the noise input,\nenhancing the model's ability to reproduce stylized facts such as volatility\nclustering. Through empirical experiments on S&P 500 index data, we demonstrate\nthat our model effectively captures key characteristics of financial time\nseries and outperforms a comparable GAN-based approach. In addition, we explore\nthe application of the synthetic data generated to train a reinforcement\nlearning agent for portfolio management, achieving promising results. Finally,\nwe propose a method to add robustness to the generative model by tweaking the\nnoise input so that the generated sequences can be adjusted to different market\nenvironments with minimal data.\n"
    },
    {
        "paper_id": 2407.19857,
        "authors": "Kamila Zaman and Alberto Marchisio and Muhammad Kashif and Muhammad\n  Shafique",
        "title": "PO-QA: A Framework for Portfolio Optimization using Quantum Algorithms",
        "comments": "Accepted at the 2024 IEEE International Conference on Quantum\n  Computing and Engineering (QCE24), September 2024",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Portfolio Optimization (PO) is a financial problem aiming to maximize the net\ngains while minimizing the risks in a given investment portfolio. The novelty\nof Quantum algorithms lies in their acclaimed potential and capability to solve\ncomplex problems given the underlying Quantum Computing (QC) infrastructure.\nUtilizing QC's applicable strengths to the finance industry's problems, such as\nPO, allows us to solve these problems using quantum-based algorithms such as\nVariational Quantum Eigensolver (VQE) and Quantum Approximate Optimization\nAlgorithm (QAOA). While the Quantum potential for finance is highly impactful,\nthe architecture and composition of the quantum circuits have not yet been\nproperly defined as robust financial frameworks/algorithms as state of the art\nin present literature for research and design development purposes. In this\nwork, we propose a novel scalable framework, denoted PO-QA, to systematically\ninvestigate the variation of quantum parameters (such as rotation blocks,\nrepetitions, and entanglement types) to observe their subtle effect on the\noverall performance. In our paper, the performance is measured and dictated by\nconvergence to similar ground-state energy values for resultant optimal\nsolutions by each algorithm variation set for QAOA and VQE to the exact\neigensolver (classical solution). Our results provide effective insights into\ncomprehending PO from the lens of Quantum Machine Learning in terms of\nconvergence to the classical solution, which is used as a benchmark. This study\npaves the way for identifying efficient configurations of quantum circuits for\nsolving PO and unveiling their inherent inter-relationships.\n"
    },
    {
        "paper_id": 2407.19858,
        "authors": "Tiago Monteiro",
        "title": "AI-Powered Energy Algorithmic Trading: Integrating Hidden Markov Models\n  with Neural Networks",
        "comments": "14 pages, 4 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In quantitative finance, machine learning methods are essential for alpha\ngeneration. This study introduces a new approach that combines Hidden Markov\nModels (HMM) and neural networks, integrated with Black-Litterman portfolio\noptimization. During the COVID period (2019-2022), this dual-model approach\nachieved a 83% return with a Sharpe ratio of 0.77. It incorporates two risk\nmodels to enhance risk management, showing efficiency during volatile periods.\nThe methodology was implemented on the QuantConnect platform, which was chosen\nfor its robust framework and experimental reproducibility. The system, which\npredicts future price movements, includes a three-year warm-up to ensure proper\nalgorithm function. It targets highly liquid, large-cap energy stocks to ensure\nstable and predictable performance while also considering broker payments. The\ndual-model alpha system utilizes log returns to select the optimal state based\non the historical performance. It combines state predictions with neural\nnetwork outputs, which are based on historical data, to generate trading\nsignals. This study examined the architecture of the trading system, data\npre-processing, training, and performance. The full code and backtesting data\nare available under the QuantConnect terms.\n"
    },
    {
        "paper_id": 2407.19932,
        "authors": "Abdulnasser Hatemi-J",
        "title": "Testing for the Asymmetric Optimal Hedge Ratios: With an Application to\n  Bitcoin",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Reducing financial risk is of paramount importance to investors, financial\ninstitutions, and corporations. Since the pioneering contribution of Johnson\n(1960), the optimal hedge ratio based on futures is regularly utilized. The\ncurrent paper suggests an explicit and efficient method for testing the null\nhypothesis of a symmetric optimal hedge ratio against an asymmetric alternative\none within a multivariate setting. If the null is rejected, the position\ndependent optimal hedge ratios can be estimated via the suggested model. This\napproach is expected to enhance the accuracy of the implemented hedging\nstrategies compared to the standard methods since it accounts for the fact that\nthe source of risk depends on whether the investor is a buyer or a seller of\nthe risky asset. An application is provided using spot and futures prices of\nBitcoin. The results strongly support the view that the optimal hedge ratio for\nthis cryptocurrency is position dependent. The investor that is long in Bitcoin\nhas a much higher conditional optimal hedge ratio compared to the one that is\nshort in the asset. The difference between the two conditional optimal hedge\nratios is statistically significant, which has important repercussions for\nimplementing risk management strategies.\n"
    },
    {
        "paper_id": 2407.19936,
        "authors": "Yannick Becker, Pascal Halffmann, Anita Sch\\\"obel",
        "title": "Risk management in multi-objective portfolio optimization under\n  uncertainty",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In portfolio optimization, decision makers face difficulties from\nuncertainties inherent in real-world scenarios. These uncertainties\nsignificantly influence portfolio outcomes in both classical and\nmulti-objective Markowitz models. To address these challenges, our research\nexplores the power of robust multi-objective optimization. Since portfolio\nmanagers frequently measure their solutions against benchmarks, we enhance the\nmulti-objective min-regret robustness concept by incorporating these benchmark\ncomparisons.\n  This approach bridges the gap between theoretical models and real-world\ninvestment scenarios, offering portfolio managers more reliable and adaptable\nstrategies for navigating market uncertainties. Our framework provides a more\nnuanced and practical approach to portfolio optimization under real-world\nconditions.\n"
    },
    {
        "paper_id": 2407.19995,
        "authors": "Zixin Feng, Dejian Tian and Harry Zheng",
        "title": "Consumption-investment optimization with Epstein-Zin utility in\n  unbounded non-Markovian markets",
        "comments": "25 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The paper investigates the consumption-investment problem for an investor\nwith Epstein-Zin utility in an incomplete market. A non-Markovian environment\nwith unbounded parameters is considered, which is more realistic in practical\nfinancial scenarios compared to the Markovian setting. The optimal consumption\nand investment strategies are derived using the martingale optimal principle\nand quadratic backward stochastic differential equations (BSDEs) whose\nsolutions admit some exponential moment. This integrability property plays a\ncrucial role in establishing a key martingale argument. In addition, the paper\nalso examines the associated dual problem and several models within the\nspecified parameter framework.\n"
    },
    {
        "paper_id": 2407.20136,
        "authors": "Victoria Junquera, Daniel I. Rubenstein, and Florian Knaus",
        "title": "\"How lonely are you?\" The role of social contacts and farm\n  characteristics in farmers' self-reported feelings of loneliness, and why it\n  matters",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Loneliness and social isolation among farmers are growing public health\nconcerns. The contributing factors are manifold, and some of them are linked to\nstructural change in agriculture, for instance because of higher workloads,\nrural depopulation, or reduced opportunities for collaboration. Our work\nexplores the interconnections between loneliness, social contacts, and\nstructural factors in agriculture based on a survey of 110 farm managers in the\nmountain region of Entlebuch, Switzerland combined with agricultural census\ndata. We use path analysis, in which loneliness is the main outcome, and social\ncontacts are an explanatory and explained variable. We find that 3% of\nrespondents report that they feel lonely frequently or very frequently, and the\nrest sometimes (20%), rarely (40%) or never (38%). Managers with higher\nworkloads report feeling lonely more frequently, and this relationship is\ndirect, as well as indirect because of less frequent social contacts. However,\nphysical isolation is not a significant predictor of loneliness. Moreover,\nshort food supply chains correlate with less frequent loneliness feelings. Our\nstudy sheds light on the effects that structural change can have on the social\nfabric of rural areas.\n"
    },
    {
        "paper_id": 2407.20139,
        "authors": "Muhammad Haris Saleem, S. Wajahat Ali, Sheikh Abdullah Shehzad",
        "title": "Emission Reduction in Urban Environments by Replacing Conventional City\n  Buses with Electric Bus Technology: A Case Study of Pakistan",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The global transportation industry has become one of the main contributors to\nair pollution. Consequently, electric buses and green transportation are\ngaining popularity as crucial steps to reduce emission concerns. Many developed\ncountries have already adopted the concept of Battery Electric Buses (BEBs),\nwhile the developing ones are just starting with it. However, BEB fleets have\nadvantages, such as lower fuel, higher efficiency, lower maintenance, and\nenergy security. Yet, several obstacles must be overcome to support the mass\ndeployment of BEBs. These incorporate forthright expense charges, arranging\nloads, BEB reach, and newness to BEB innovation. Stakeholders like\npolicymakers, private company owners, and government leaders have a lot to\nconsider before introducing BEBs at any level in Pakistan. As a result, to\noperate an electric bus system profitably, it is crucial to develop a proper\nelectric bus network and fleet, especially for bus operators who need to buy\nenough electric buses at the appropriate time. As a result, this paper aims to\ninvestigate if operating an electric bus could be an alternative to regular bus\noperations. The proposed methodology develops modeling software to cater to\nvarious scenarios to determine a proper-designed electric bus operating system\nin terms of the electric bus route, service frequency, and quantity. This\nresearch work simulates and financially analyses an operating Public Transport\nInfrastructure with a proposed Green Solution. The results show that regardless\nof the high upfront costs of BEB infrastructure, it becomes profitable in 6-7\nyears, resulting in a decreased Total Cost of Ownership (TCO) of approximately\n30% of its counterpart. The study also provides a clear policy pathway to help\nstakeholders make informed decisions related to the electrification of public\ntransport in Pakistan.\n"
    },
    {
        "paper_id": 2407.20301,
        "authors": "Marcelo Corrales Compagnucci, Toshiyuki Kono and Shinto Teramoto",
        "title": "Legal Aspects of Decentralized and Platform-Driven Economies",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The sharing economy is sprawling across almost every sector and activity\naround the world. About a decade ago, there were only a handful of platform\ndriven companies operating on the market. Zipcar, BlaBlaCar and Couchsurfing\namong them. Then Airbnb and Uber revolutionized the transportation and\nhospitality industries with a presence in virtually every major city. Access\nover ownership is the paradigm shift from the traditional business model that\ngrants individuals the use of products or services without the necessity of\nbuying them. Digital platforms, data and algorithm-driven companies as well as\ndecentralized blockchain technologies have tremendous potential. But they are\nalso changing the rules of the game. One of such technologies challenging the\nlegal system are AI systems that will also reshape the current legal framework\nconcerning the liability of operators, users and manufacturers. Therefore, this\nintroductory chapter deals with explaining and describing the legal issues of\nsome of these disruptive technologies. The chapter argues for a more\nforward-thinking and flexible regulatory structure.\n"
    },
    {
        "paper_id": 2407.20306,
        "authors": "Jessica Reale, Frederik Banning, Michael Roos",
        "title": "Unemployment Benefits and Job Quality: Unveiling the Complexities of\n  Labour Market Dynamics",
        "comments": "23 pages, 11 figures, 4 tables, 3 appendices",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  This study explores the impact of unemployment benefits on employment\nquality, job stability, and tenure within complex labour market dynamics. Given\nthe macroeconomic consequences of changes in unemployment benefits, including\ntheir impact on employment rates and output growth, we develop a closed\nmacroeconomic model that integrates heterogeneous households and adaptive firms\nand incorporates real-world entry-exit market mechanisms. The model considers\npersonal values, social norms, and social network formation among workers as we\nexamine the role of social contacts in mediating the effects of unemployment\nbenefits on job-matching quality and labour market outcomes. We simulate the\nmodel across various scenarios where unemployment benefit schemes differ in\nlevel and/or duration. Our results suggest that extending the duration of\nunemployment benefits does not necessarily improve job-matching quality. Longer\nbenefits may indeed reduce the effectiveness of social networks in job finding,\nindicating that social contacts play a key role in labour market dynamics.\n"
    },
    {
        "paper_id": 2407.20352,
        "authors": "Filip Stan\\v{e}k",
        "title": "Designing Time-Series Models With Hypernetworks & Adversarial Portfolios",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This article describes the methods that achieved 4th and 6th place in the\nforecasting and investment challenges, respectively, of the M6 competition,\nultimately securing the 1st place in the overall duathlon ranking. In the\nforecasting challenge, we tested a novel meta-learning model that utilizes\nhypernetworks to design a parametric model tailored to a specific family of\nforecasting tasks. This approach allowed us to leverage similarities observed\nacross individual forecasting tasks while also acknowledging potential\nheterogeneity in their data generating processes. The model's training can be\ndirectly performed with backpropagation, eliminating the need for reliance on\nhigher-order derivatives and is equivalent to a simultaneous search over the\nspace of parametric functions and their optimal parameter values. The proposed\nmodel's capabilities extend beyond M6, demonstrating superiority over\nstate-of-the-art meta-learning methods in the sinusoidal regression task and\noutperforming conventional parametric models on time-series from the M4\ncompetition. In the investment challenge, we adjusted portfolio weights to\ninduce greater or smaller correlation between our submission and that of other\nparticipants, depending on the current ranking, aiming to maximize the\nprobability of achieving a good rank.\n"
    },
    {
        "paper_id": 2407.20377,
        "authors": "C\\'esar Pedrosa Soares",
        "title": "Leveraging Natural Language and Item Response Theory Models for ESG\n  Scoring",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper explores an innovative approach to Environmental, Social, and\nGovernance (ESG) scoring by integrating Natural Language Processing (NLP)\ntechniques with Item Response Theory (IRT), specifically the Rasch model. The\nstudy utilizes a comprehensive dataset of news articles in Portuguese related\nto Petrobras, a major oil company in Brazil, collected from 2022 and 2023. The\ndata is filtered and classified for ESG-related sentiments using advanced NLP\nmethods. The Rasch model is then applied to evaluate the psychometric\nproperties of these ESG measures, providing a nuanced assessment of ESG\nsentiment trends over time. The results demonstrate the efficacy of this\nmethodology in offering a more precise and reliable measurement of ESG factors,\nhighlighting significant periods and trends. This approach may enhance the\nrobustness of ESG metrics and contribute to the broader field of sustainability\nand finance by offering a deeper understanding of the temporal dynamics in ESG\nreporting.\n"
    },
    {
        "paper_id": 2407.2038,
        "authors": "Ixandra Achitouv",
        "title": "Inferring financial stock returns correlation from complex network\n  analysis",
        "comments": "16 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Financial stock returns correlations have been studied in the prism of random\nmatrix theory, to distinguish the signal from the \"noise\". Eigenvalues of the\nmatrix that are above the rescaled Marchenko Pastur distribution can be\ninterpreted as collective modes behavior while the modes under are usually\nconsidered as noise. In this analysis we use complex network analysis to\nsimulate the \"noise\" and the \"market\" component of the return correlations, by\nintroducing some meaningful correlations in simulated geometric Brownian motion\nfor the stocks. We find that the returns correlation matrix is dominated by\nstocks with high eigenvector centrality and clustering found in the network. We\nthen use simulated \"market\" random walks to build an optimal portfolio and find\nthat the overall return performs better than using the historical mean-variance\ndata, up to 50% on short time scale.\n"
    },
    {
        "paper_id": 2407.20587,
        "authors": "Hyoji Choi and Frank Neffke and Donghyeon Yu and Bogang Jun",
        "title": "Close to Home: Analyzing Urban Consumer Behavior and Consumption Space\n  in Seoul",
        "comments": "35 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This study explores how the relatedness density of amenities influences\nconsumer buying patterns, focusing on multi-purpose shopping preferences. Using\nSeoul's credit card data from 2018 to 2023, we find a clear preference for\nshopping at amenities close to consumers' residences, particularly for trips\nwithin a 2 km radius, where relatedness density significantly influences\npurchasing decisions. The COVID-19 pandemic initially reduced this effect at\nshorter distances but rebounded in 2023, suggesting a resilient return to\npre-pandemic patterns, which vary over regions. Our findings highlight the\nresilience of local shopping preferences despite economic disruptions,\nunderscoring the importance of amenity-relatedness in urban consumer behavior.\n"
    },
    {
        "paper_id": 2407.20931,
        "authors": "Suguru Otani",
        "title": "Nonparametric Estimation of Matching Efficiency and Mismatch in Labor\n  Markets via Public Employment Security Offices in Japan, 1972-2024",
        "comments": "27 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  I examine changes in matching efficiency and elasticities in Japan's labor\nmarket via Hello Work for unemployed workers from January 1972 to April 2024\nusing a nonparametric identification approach by Lange and Papageorgiou (2020).\nI find a declining trend in matching efficiency, consistent with decreasing job\nand worker finding rates. The implied match elasticity with respect to\nunemployment is 0.5-0.9, whereas the implied match elasticity with respect to\nvacancies is 0.1-0.4. Decomposing aggregate data into full-time and part-time\nones, I find that the sharp decline of matching efficiency after 2015 shown in\nthe aggregate trend is driven by the decline of both full-time and part-time\nones. Second, I extend the mismatch index proposed by Sahin et al (2014) to the\nnonparametric version and develop the computational methodology. I find that\nthe mismatch across job categories is more severe than across prefectures and\nthe original Cobb-Douglas mismatch index is underestimated.\n"
    },
    {
        "paper_id": 2407.21025,
        "authors": "Yuheng Zheng, Zihan Ding",
        "title": "Reinforcement Learning in High-frequency Market Making",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper establishes a new and comprehensive theoretical analysis for the\napplication of reinforcement learning (RL) in high-frequency market making. We\nbridge the modern RL theory and the continuous-time statistical models in\nhigh-frequency financial economics. Different with most existing literature on\nmethodological research about developing various RL methods for market making\nproblem, our work is a pilot to provide the theoretical analysis. We target the\neffects of sampling frequency, and find an interesting tradeoff between error\nand complexity of RL algorithm when tweaking the values of the time increment\n$\\Delta$ $-$ as $\\Delta$ becomes smaller, the error will be smaller but the\ncomplexity will be larger. We also study the two-player case under the\ngeneral-sum game framework and establish the convergence of Nash equilibrium to\nthe continuous-time game equilibrium as $\\Delta\\rightarrow0$. The Nash\nQ-learning algorithm, which is an online multi-agent RL method, is applied to\nsolve the equilibrium. Our theories are not only useful for practitioners to\nchoose the sampling frequency, but also very general and applicable to other\nhigh-frequency financial decision making problems, e.g., optimal executions, as\nlong as the time-discretization of a continuous-time markov decision process is\nadopted. Monte Carlo simulation evidence support all of our theories.\n"
    },
    {
        "paper_id": 2407.21138,
        "authors": "Pascal Fran\\c{c}ois, Genevi\\`eve Gauthier, Fr\\'ed\\'eric Godin, Carlos\n  Octavio P\\'erez Mendoza",
        "title": "Enhancing Deep Hedging of Options with Implied Volatility Surface\n  Feedback Information",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We present a dynamic hedging scheme for S&P 500 options, where rebalancing\ndecisions are enhanced by integrating information about the implied volatility\nsurface dynamics. The optimal hedging strategy is obtained through a deep\npolicy gradient-type reinforcement learning algorithm, with a novel hybrid\nneural network architecture improving the training performance. The favorable\ninclusion of forward-looking information embedded in the volatility surface\nallows our procedure to outperform several conventional benchmarks such as\npractitioner and smiled-implied delta hedging procedures, both in simulation\nand backtesting experiments.\n"
    },
    {
        "paper_id": 2407.21148,
        "authors": "Katia Colaneri, Daniele Mancinelli, Immacolata Oliva",
        "title": "On the optimal design of a new class of proportional portfolio insurance\n  strategies in a jump-diffusion framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we investigate an optimal investment problem associated with\nproportional portfolio insurance (PPI) strategies in the presence of jumps in\nthe underlying dynamics. PPI strategies enable investors to mitigate downside\nrisk while still retaining the potential for upside gains. This is achieved by\nmaintaining an exposure to risky assets proportional to the difference between\nthe portfolio value and the present value of the guaranteed amount. While PPI\nstrategies are known to be free of downside risk in diffusion modeling\nframeworks with continuous trading, see e.g., Cont and Tankov (2009), real\nmarket applications exhibit a significant non-negligible risk, known as gap\nrisk, which increases with the multiplier value. The goal of this paper is to\ndetermine the optimal PPI strategy in a setting where gap risk may occur, due\nto downward jumps in the asset price dynamics. We consider a loss-averse agent\nwho aims at maximizing the expected utility of the terminal wealth exceeding a\nminimum guarantee. Technically, we model agent's preferences with an S-shaped\nutility functions to accommodate the possibility that gap risk occurs, and\naddress the optimization problem via a generalization of the martingale\napproach that turns to be valid under market incompleteness in a jump-diffusion\nframework.\n"
    },
    {
        "paper_id": 2407.21209,
        "authors": "Lingwei Cheng, Cameron Drayton, Alexandra Chouldechova, Rhema\n  Vaithianathan",
        "title": "Algorithm-Assisted Decision Making and Racial Disparities in Housing: A\n  Study of the Allegheny Housing Assessment Tool",
        "comments": "17 pages, 11 figures, AAAI/ACM AIES24",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The demand for housing assistance across the United States far exceeds the\nsupply, leaving housing providers the task of prioritizing clients for receipt\nof this limited resource. To be eligible for federal funding, local\nhomelessness systems are required to implement assessment tools as part of\ntheir prioritization processes. The Vulnerability Index Service Prioritization\nDecision Assistance Tool (VI-SPDAT) is the most commonly used assessment tool\nnationwide. Recent studies have criticized the VI-SPDAT as exhibiting racial\nbias, which may lead to unwarranted racial disparities in housing provision.\nSuch criticisms have led certain jurisdictions to develop alternative tools.\nUsing data from one such prioritization tool, called the Allegheny Housing\nAssessment (AHA), we use descriptive and quantitative analysis to assess\nwhether the replacement of the VI-SPDAT with the AHA impacts racial disparities\nin housing allocation. We find that the VI-SPDAT tended to assign higher risk\nscores to white clients and lower risk scores to Black clients, and that white\nclients were served at a higher rates pre-AHA deployment. While post-deployment\nservice decisions became better aligned with the AHA score, and the\ndistribution of AHA scores is similar across racial groups, we do not find\nevidence of a corresponding decrease in disparities in service rates. We\nattribute the persistent disparity to the use of Alt-AHA, a survey-based tool\nthat is used in cases of low data quality, as well as group differences in\neligibility-related factors, such as chronic homelessness and veteran status.\nWe discuss the implications for housing service systems seeking to reduce\nracial disparities in their service delivery.\n"
    },
    {
        "paper_id": 2407.21409,
        "authors": "Tom Brown and Fabian Neumann and Iegor Riepin",
        "title": "Price formation without fuel costs: the interaction of elastic demand\n  with storage bidding",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Studies looking at electricity market designs for very high shares of wind\nand solar often conclude that the energy-only market will break down. Without\nfuel costs, it is said that there is nothing to set prices. Symptoms of\nbreakdown include long phases of zero prices, scarcity prices too high to be\npolitically acceptable, prices that collapse under small perturbations of\ncapacities from the long-term equilibrium, cost recovery that is impossible due\nto low market values, high variability of revenue between different weather\nyears, and difficulty operating long-term storage with limited foresight. We\nargue that all these problems are an artefact of modeling with perfectly\ninelastic demand. If short-term elasticity to reflect today's flexible demand\n(-5%) is implemented in the model, these problems are significantly reduced.\nThe combined interaction of demand willingness to pay and storage opportunity\ncosts is enough to produce stable pricing. This behavior is illustrated by a\nmodel with wind, solar, batteries, and hydrogen-based storage, where a\npiecewise linear demand curve removes high price peaks and reduces the fraction\nof zero-price hours from 90% to around 30%, and entails more price stability\nfor perturbations of capacity and different weather years. Furthermore, we show\nthat with elastic demand, the long-term model exactly reproduces the prices of\nthe short-term model with the same capacities. We then use insights from the\nlong-term model to derive simple bidding strategies for storage so that we can\nalso run the short-term model with limited operational foresight. We\ndemonstrate this short-term operation in a model trained on 35 years of weather\ndata and tested on another 35 years of unseen data. We conclude that the\nenergy-only market can still play a key role in coordinating dispatch and\ninvestment in the future.\n"
    },
    {
        "paper_id": "2407.21791",
        "authors": "Wee Ling Tan, Stephen Roberts, Stefan Zohren",
        "title": "Deep Learning for Options Trading: An End-To-End Approach",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a novel approach to options trading strategies using a highly\nscalable and data-driven machine learning algorithm. In contrast to traditional\napproaches that often require specifications of underlying market dynamics or\nassumptions on an option pricing model, our models depart fundamentally from\nthe need for these prerequisites, directly learning non-trivial mappings from\nmarket data to optimal trading signals. Backtesting on more than a decade of\noption contracts for equities listed on the S&P 100, we demonstrate that deep\nlearning models trained according to our end-to-end approach exhibit\nsignificant improvements in risk-adjusted performance over existing rules-based\ntrading strategies. We find that incorporating turnover regularization into the\nmodels leads to further performance enhancements at prohibitively high levels\nof transaction costs.\n"
    },
    {
        "paper_id": "2408.00003",
        "authors": "Dhiti Osatakul, Shuanming Li, Xueyuan Wu",
        "title": "Bonus-malus Systems vs Delays in Claims Reporting and Settlement:\n  Analysis of Ruin Probabilities",
        "comments": "This paper has 39 pages and contains 4 tables and 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Our paper explores a discrete-time risk model with time-varying premiums,\ninvestigating two types of correlated claims: main claims and by-claims.\nSettlement of the by-claims can be delayed for one time period, representing\nreal-world insurance practices. We examine two premium principles based on\nreported and settled claims, using recursively computable finite-time ruin\nprobabilities to evaluate the performance of time-varying premiums. Our\nfindings suggest that, under specific assumptions, a higher probability of\nby-claim settlement delays leads to lower ruin probabilities. Moreover, a\nstronger correlation between main claims and their associated by-claims results\nin higher ruin probabilities. Lastly, the premium adjustment principles based\non settled claims experience contribute to higher ruin probabilities compared\nto those based on reported claims experience, assuming all other factors remain\nconstant. Notably, this difference becomes more pronounced when there is a high\nlikelihood of by-claim delays.\n"
    },
    {
        "paper_id": "2408.00131",
        "authors": "Patrick Kuiper, Ali Hasan, Wenhao Yang, Yuting Ng, Hoda Bidkhori, Jose\n  Blanchet, Vahid Tarokh",
        "title": "Distributionally Robust Optimization as a Scalable Framework to\n  Characterize Extreme Value Distributions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The goal of this paper is to develop distributionally robust optimization\n(DRO) estimators, specifically for multidimensional Extreme Value Theory (EVT)\nstatistics. EVT supports using semi-parametric models called max-stable\ndistributions built from spatial Poisson point processes. While powerful, these\nmodels are only asymptotically valid for large samples. However, since extreme\ndata is by definition scarce, the potential for model misspecification error is\ninherent to these applications, thus DRO estimators are natural. In order to\nmitigate over-conservative estimates while enhancing out-of-sample performance,\nwe study DRO estimators informed by semi-parametric max-stable constraints in\nthe space of point processes. We study both tractable convex formulations for\nsome problems of interest (e.g. CVaR) and more general neural network based\nestimators. Both approaches are validated using synthetically generated data,\nrecovering prescribed characteristics, and verifying the efficacy of the\nproposed techniques. Additionally, the proposed method is applied to a real\ndata set of financial returns for comparison to a previous analysis. We\nestablished the proposed model as a novel formulation in the multivariate EVT\ndomain, and innovative with respect to performance when compared to relevant\nalternate proposals.\n"
    },
    {
        "paper_id": "2408.00265",
        "authors": "Yoichi Hizen, Kazuya Kikuchi, Yukio Koriyama and Takehito Masuda",
        "title": "Jumping on the bandwagon and off the Titanic: an experimental study of\n  turnout in two-tier voting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We experimentally study voter turnout in two-tier elections when the\nelectorate consists of multiple groups, such as states. Votes are aggregated\nwithin the groups by the winner-take-all rule or the proportional rule, and the\ngroup-level decisions are combined to determine the winner. We observe that,\ncompared with the theoretical prediction, turnout is significantly lower in the\nminority camp (the Titanic effect) and significantly higher in the majority\ncamp (the behavioral bandwagon effect), and these effects are stronger under\nthe proportional rule than under the winner-take-all rule. As a result, the\ndistribution of voter welfare becomes more unequal than theoretically\npredicted, and this welfare effect is stronger under the proportional rule than\nunder the winner-take-all rule.\n"
    },
    {
        "paper_id": "2408.00507",
        "authors": "Monika Zimmermann and Florian Ziel",
        "title": "Spatial Weather, Socio-Economic and Political Risks in Probabilistic\n  Load Forecasting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Accurate forecasts of the impact of spatial weather and pan-European\nsocio-economic and political risks on hourly electricity demand for the\nmid-term horizon are crucial for strategic decision-making amidst the inherent\nuncertainty. Most importantly, these forecasts are essential for the\noperational management of power plants, ensuring supply security and grid\nstability, and in guiding energy trading and investment decisions. The primary\nchallenge for this forecasting task lies in disentangling the multifaceted\ndrivers of load, which include national deterministic (daily, weekly, annual,\nand holiday patterns) and national stochastic weather and autoregressive\neffects. Additionally, transnational stochastic socio-economic and political\neffects add further complexity, in particular, due to their non-stationarity.\nTo address this challenge, we present an interpretable probabilistic mid-term\nforecasting model for the hourly load that captures, besides all deterministic\neffects, the various uncertainties in load. This model recognizes transnational\ndependencies across 24 European countries, with multivariate modeled\nsocio-economic and political states and cross-country dependent forecasting.\nBuilt from interpretable Generalized Additive Models (GAMs), the model enables\nan analysis of the transmission of each incorporated effect to the\nhour-specific load. Our findings highlight the vulnerability of countries\nreliant on electric heating under extreme weather scenarios. This emphasizes\nthe need for high-resolution forecasting of weather effects on pan-European\nelectricity consumption especially in anticipation of widespread electric\nheating adoption.\n"
    },
    {
        "paper_id": "2408.00683",
        "authors": "Victoria Junquera, Daniel I. Rubenstein, Simon A. Levin, Jos\\'e I.\n  Hormaza, I\\~naki Vadillo P\\'erez, and Pablo Jim\\'enez Gavil\\'an",
        "title": "Hydrological collapse in southern Spain under expanding irrigated\n  agriculture: Meteorological, hydrological, and structural drought",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Spain is the largest producer of avocado and mango fruits in Europe. The\nmajority of production is concentrated in the Axarqu\\'ia region in the south,\nwhere subtropical fruit plantations and associated water demands have steadily\nincreased over the last two decades. Between 2019-2024, the region underwent an\nextreme water crisis. Reservoir reserves became nearly depleted and groundwater\nlevels dropped to sea level in several locations, where seawater intrusion is\nlikely, causing large socioeconomic impacts including short-term harvest losses\nand a long-term loss in economic centrality. We examine the causal pathway that\nled to this crisis using a mixed-methods approach, combining data from key\ninformant interviews, an exhaustive review of legal documents, and quantitative\nanalysis of time series and spatially explicit data. In particular, we analyze\ndam water use for irrigation and urban use, meteorological data, reservoir and\ngroundwater levels, and irrigation land cover maps. Our findings show that an\nunusual meteorological drought was the immediate cause for the decline in\nreservoir and groundwater reserves (hydrological drought), but the underlying\ncause was a chronic and structural long-term imbalance between water demand and\nresources resulting from several structural governance shortcomings: large\nuncertainties in water resource availability and use hampering effective\nplanning, lack of enforcement of individual water quotas, and the absence of\nregulatory mechanisms to flexibly impose resource use restrictions at both\nmicro and macro levels based on the overall resources of the system. We propose\nconcrete policy interventions aimed at sustainably enhancing the resilience of\nthe system that can be useful to efficiently manage water shortages in other\nregions with similar problems.\n"
    },
    {
        "paper_id": "2408.00784",
        "authors": "Alberto Manzano and Emanuele Nastasi and Andrea Pallavicini and Carlos\n  V\\'azquez",
        "title": "Evaluating Microscopic and Macroscopic Models for Derivative Contracts\n  on Commodity Indices",
        "comments": "28 pages, 11 tables. arXiv admin note: substantial text overlap with\n  arXiv:2208.01289",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this article, we analyze two modeling approaches for the pricing of\nderivative contracts on a commodity index. The first one is a microscopic\napproach, where the components of the index are modeled individually, and the\nindex price is derived from their combination. The second one is a macroscopic\napproach, where the index is modeled directly. While the microscopic approach\noffers greater flexibility, its calibration results to be more challenging,\nthus leading practitioners to favor the macroscopic approach. However, in the\nmacroscopic model, the lack of explicit futures curve dynamics raises questions\nabout its ability to accurately capture the behavior of the index and its\nsensitivities. In order to investigate this, we calibrate both models using\nderivatives of the S\\&P GSCI Crude Oil excess-return index and compare their\npricing and sensitivities on path-dependent options, such as autocallable\ncontracts. This research provides insights into the suitability of macroscopic\nmodels for pricing and hedging purposes in real scenarios.\n"
    },
    {
        "paper_id": "2408.00885",
        "authors": "Christian Vedel",
        "title": "A Perfect Storm: First-Nature Geography and Economic Development",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "abstract": "  Is geography destiny? What is the role of first-nature geography in\ndetermining prosperity? This paper estimates the effect of randomly removing\nand introducing favorable first-nature geography to a specific region using a\ndifference in difference design. In 1825 a storm created a new natural\nnavigable waterway, bringing trade and prosperity to the otherwise relatively\nisolated northwestern Denmark. 700 years prior, the same event happened in\nreverse, when a previous channel closed up between 1086 and 1208. The\nelasticity of geography-induced market access is estimated to be 1.6,\ncorresponding to 26.7 percent population growth within a generation of the\nevent. Demonstrated mechanisms include trade, fertility, fishing, and the rise\nof manufacturing. The central finding is replicated in reverse in a register of\ndated archaeological sites. The 1086-1208 closing caused fewer buildings and\nsites containing coins. The general insight is the same: First-nature geography\ndetermines the levels and location of prosperity.\n"
    },
    {
        "paper_id": "2408.00928",
        "authors": "Tarun Chitra and Mallesh Pai",
        "title": "How much should you pay for restaking security?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Restaking protocols have aggregated billions of dollars of security by\nutilizing token incentives and payments. A natural question to ask is: How much\nsecurity do restaked services \\emph{really} need to purchase? To answer this\nquestion, we expand a model of Durvasula and Roughgarden [DR24] that includes\nincentives and an expanded threat model consisting of strategic attackers and\nusers. Our model shows that an adversary with a strictly submodular profit\ncombined with strategic node operators who respond to incentives can avoid the\nlarge-scale cascading failures of~[DR24]. We utilize our model to construct an\napproximation algorithm for choosing token-based incentives that achieve a\ngiven security level against adversaries who are bounded in the number of\nservices they can simultaneously attack. Our results suggest that incentivized\nrestaking protocols can be secure with proper incentive management.\n"
    },
    {
        "paper_id": "2408.01185",
        "authors": "A. Agarwal and S. De Marco and E. Gobet and J. G. Lopez-Salas and F.\n  Noubiagain and A. Zhou",
        "title": "Numerical approximations of McKean Anticipative Backward Stochastic\n  Differential Equations arising in Initial Margin requirements",
        "comments": null,
        "journal-ref": "Agarwal, A. et. al., Numerical approximations of McKean\n  anticipative backward stochastic differential equations arising in initial\n  margin requirements, ESAIM: ProcS, 2019, 65, 1-26",
        "doi": "10.1051/proc/201965001",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We introduce a new class of anticipative backward stochastic differential\nequations with a dependence of McKean type on the law of the solution, that we\nname MKABSDE. We provide existence and uniqueness results in a general\nframework with relatively general regularity assumptions on the coefficients.\nWe show how such stochastic equations arise within the modern paradigm of\nderivative pricing where a central counterparty (CCP) requires the members to\ndeposit variation and initial margins to cover their exposure. In the case when\nthe initial margin is proportional to the Conditional Value-at-Risk (CVaR) of\nthe contract price, we apply our general result to define the price as a\nsolution of a MKABSDE. We provide several linear and non-linear simpler\napproximations, which we solve using different numerical (deterministic and\nMonte-Carlo) methods.\n"
    },
    {
        "paper_id": "2408.01309",
        "authors": "Kevin Riehl and Anastasios Kouvelas and Michail Makridis",
        "title": "Towards fair roads -- Why we should & how to improve the fairness in\n  traffic engineering",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Traffic engineering aims to control infrastructure and population behavior to\nachieve optimal usage of road networks. Fairness is fundamental to stimulate\ncooperation in large populations, and plays an important role in traffic\nengineering, as it increases the well-being of users, improves driving safety\nby rule-adherence, and overcomes public resistance at legislative\nimplementation. Despite the importance of fairness, only a few works have\ntranslated fairness into the transportation domain, with a focus on\ntransportation planning rather than traffic engineering. This work highlights\nthe importance of fairness when solving conflicts of large populations for\nscare, public good, road-network resources with traffic engineering, and\nestablishes a connection to the modern fairness theories. Moreover, this work\npresents a fairness framework that serves when designing traffic engineering\nsolutions, when convincing in public debates with a useful, argumentative\ntool-set to confront equity considerations, and enables systematic research and\ndesign of control systems.\n"
    },
    {
        "paper_id": "2408.01387",
        "authors": "Yuxin Liu, Jimin Lin, Achintya Gopal",
        "title": "NeuralBeta: Estimating Beta Using Deep Learning",
        "comments": "8 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Traditional approaches to estimating beta in finance often involve rigid\nassumptions and fail to adequately capture beta dynamics, limiting their\neffectiveness in use cases like hedging. To address these limitations, we have\ndeveloped a novel method using neural networks called NeuralBeta, which is\ncapable of handling both univariate and multivariate scenarios and tracking the\ndynamic behavior of beta. To address the issue of interpretability, we\nintroduce a new output layer inspired by regularized weighted linear\nregression, which provides transparency into the model's decision-making\nprocess. We conducted extensive experiments on both synthetic and market data,\ndemonstrating NeuralBeta's superior performance compared to benchmark methods\nacross various scenarios, especially instances where beta is highly\ntime-varying, e.g., during regime shifts in the market. This model not only\nrepresents an advancement in the field of beta estimation, but also shows\npotential for applications in other financial contexts that assume linear\nrelationships.\n"
    },
    {
        "paper_id": "2408.01470",
        "authors": "A. M. Ferreiro and J. A. Garc\\'ia and J. G. L\\'opez-Salas and C.\n  V\\'azquez",
        "title": "SABR/LIBOR market models: pricing and calibration for some interest rate\n  derivatives",
        "comments": null,
        "journal-ref": "Ana M. Ferreiro, Jos\\'e A. Garc\\'ia-Rodr\\'iguez, Jos\\'e G.\n  L\\'opez-Salas, Carlos V\\'azquez, SABR/LIBOR market models: Pricing and\n  calibration for some interest rate derivatives, Applied Mathematics and\n  Computation, 242, 2014",
        "doi": "10.1016/j.amc.2014.05.017",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In order to overcome the drawbacks of assuming deterministic volatility\ncoefficients in the standard LIBOR market models to capture volatility smiles\nand skews in real markets, several extensions of LIBOR models to incorporate\nstochastic volatilities have been proposed. The efficient calibration to market\ndata of these more complex models becomes a relevant target in practice. The\nmain objective of the present work is to efficiently calibrate some recent\nSABR/LIBOR market models to real market prices of caplets and swaptions. For\nthe calibration we propose a parallelized version of the simulated annealing\nalgorithm for multi-GPUs. The numerical results clearly illustrate the\nadvantages of using the proposed multi-GPUs tools when applied to real market\ndata and popular SABR/LIBOR models.\n"
    },
    {
        "paper_id": "2408.01499",
        "authors": "Achintya Gopal",
        "title": "NeuralFactors: A Novel Factor Learning Approach to Generative Modeling\n  of Equities",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The use of machine learning for statistical modeling (and thus, generative\nmodeling) has grown in popularity with the proliferation of time series models,\ntext-to-image models, and especially large language models. Fundamentally, the\ngoal of classical factor modeling is statistical modeling of stock returns, and\nin this work, we explore using deep generative modeling to enhance classical\nfactor models. Prior work has explored the use of deep generative models in\norder to model hundreds of stocks, leading to accurate risk forecasting and\nalpha portfolio construction; however, that specific model does not allow for\neasy factor modeling interpretation in that the factor exposures cannot be\ndeduced. In this work, we introduce NeuralFactors, a novel machine-learning\nbased approach to factor analysis where a neural network outputs factor\nexposures and factor returns, trained using the same methodology as variational\nautoencoders. We show that this model outperforms prior approaches both in\nterms of log-likelihood performance and computational efficiency. Further, we\nshow that this method is competitive to prior work in generating realistic\nsynthetic data, covariance estimation, risk analysis (e.g., value at risk, or\nVaR, of portfolios), and portfolio optimization. Finally, due to the connection\nto classical factor analysis, we analyze how the factors our model learns\ncluster together and show that the factor exposures could be used for embedding\nstocks.\n"
    },
    {
        "paper_id": "2408.01642",
        "authors": "Jimin Lin, Guixin Liu",
        "title": "Neural Term Structure of Additive Process for Option Pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The additive process generalizes the L\\'evy process by relaxing its\nassumption of time-homogeneous increments and hence covers a larger family of\nstochastic processes. Recent research in option pricing shows that modeling the\nunderlying log price with an additive process has advantages in easier\nconstruction of the risk-neural measure, an explicit option pricing formula and\ncharacteristic function, and more flexibility to fit the implied volatility\nsurface. Still, the challenge of calibrating an additive model arises from its\ntime-dependent parameterization, for which one has to prescribe parametric\nfunctions for the term structure. For this, we propose the neural term\nstructure model to utilize feedforward neural networks to represent the term\nstructure, which alleviates the difficulty of designing parametric functions\nand thus attenuates the misspecification risk. Numerical studies with S\\&P 500\noption data are conducted to evaluate the performance of the neural term\nstructure.\n"
    },
    {
        "paper_id": "2408.01772",
        "authors": "Michael Weba",
        "title": "Investment strategies based on forecasts are (almost) useless",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Several studies on portfolio construction reveal that sensible strategies\nessentially yield the same results as their nonsensical inverted counterparts;\nmoreover, random portfolios managed by Malkiel's dart-throwing monkey would\noutperform the cap-weighted benchmark index. Forecasting the future development\nof stock returns is an important aspect of portfolio assessment. Similar to the\nostensible arbitrariness of portfolio selection methods, it is shown that there\nis no substantial difference between the performances of ``best'' and\n``trivial'' forecasts - even under euphemistic model assumptions on the\nunderlying price dynamics. A certain significance of a predictor is found only\nin the following special case: the best linear unbiased forecast is used, the\nplanning horizon is small, and a critical relation is not satisfied.\n"
    },
    {
        "paper_id": "2408.01782",
        "authors": "Marco Due\\~nas, Antoine Mandel",
        "title": "Are EU low-carbon structural funds efficient in reducing emissions?",
        "comments": "34 pages, 3 figures and 12 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper investigates the effectiveness of the ``low-carbon economy''\nexpenditures from European Structural and Investment Funds in fostering\nreductions in greenhouse gas emissions within European regions, focusing on the\n2007-2013 and 2014-2020 programme periods. By decomposing emissions time series\ninto trend and cycle components and considering them within a panel data\nframework, our research highlights that the impacts of low-carbon economy\nexpenditures vary, qualitatively and quantitatively, with the targeted regions'\ndevelopment level. We find significant emissions reductions in developed and\ntransition regions yet less favourable outcomes in less developed areas.\nFurther analysis into specific greenhouse gas emissions types (CO$_2$, CH$_4$,\nand N$_2$O) reveals inconsistent impacts, underscoring the complexity of\nachieving emissions reductions. Our findings emphasise the need for tailored\nenvironmental strategies that accommodate the economic disparities of regions\nin the European Union.\n"
    },
    {
        "paper_id": "2408.01898",
        "authors": "Jaehyuk Choi, Lilian Hu, Yue Kuen Kwok",
        "title": "Efficient simulation of the SABR model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We propose an efficient and reliable simulation scheme for the\nstochastic-alpha-beta-rho (SABR) model. The two challenges of the SABR\nsimulation lie in sampling (i) the integrated variance conditional on terminal\nvolatility and (ii) the terminal price conditional on terminal volatility and\nintegrated variance. For the first sampling procedure, we analytically derive\nthe first four moments of the conditional average variance, and sample it from\nthe moment-matched shifted lognormal approximation. For the second sampling\nprocedure, we approximate the conditional terminal price as a\nconstant-elasticity-of-variance (CEV) distribution. Our CEV approximation\npreserves the martingale condition and precludes arbitrage, which is a key\nadvantage over Islah's approximation used in most SABR simulation schemes in\nthe literature. Then, we adopt the exact sampling method of the CEV\ndistribution based on the shifted-Poisson-mixture Gamma random variable. Our\nenhanced procedures avoid the tedious Laplace inversion algorithm for sampling\nintegrated variance and non-efficient inverse transform sampling of the forward\nprice in some of the earlier simulation schemes. Numerical results demonstrate\nour simulation scheme to be highly efficient, accurate, and reliable.\n"
    },
    {
        "paper_id": "2408.02064",
        "authors": "Mark Stedman and Luca Capriotti",
        "title": "A Path Integral Approach for Time-Dependent Hamiltonians with\n  Applications to Derivatives Pricing",
        "comments": "13 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We generalize a semi-classical path integral approach originally introduced\nby Giachetti and Tognetti [Phys. Rev. Lett. 55, 912 (1985)] and Feynman and\nKleinert [Phys. Rev. A 34, 5080 (1986)] to time-dependent Hamiltonians, thus\nextending the scope of the method to the pricing of financial derivatives. We\nillustrate the accuracy of the approach by presenting results for the\nwell-known, but analytically intractable, Black-Karasinski model for the\ndynamics of interest rates. The accuracy and computational efficiency of this\npath integral approach makes it a viable alternative to fully-numerical schemes\nfor a variety of applications in derivatives pricing.\n"
    },
    {
        "paper_id": "2408.02137",
        "authors": "Fabrice Baudoin, Oleksii Mostovyi",
        "title": "The indifference value of the weak information",
        "comments": "34 pages, preliminary version",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We propose indifference pricing to estimate the value of the weak\ninformation. Our framework allows for tractability, quantifying the amount of\nadditional information, and permits the description of the smallness and the\nstability with respect to small perturbations of the weak information. We\nprovide sharp conditions for the stability with counterexamples. The results\nrely on a theorem of independent interest on the stability of the optimal\ninvestment problem with respect to small changes in the physical probability\nmeasure. We also investigate contingent claims that are indifference price\ninvariant with respect to changes in weak information. We show that, in\nincomplete models, the class of information-invariant claims includes the\nreplicable claims, and it can be strictly bigger. In particular, in complete\nmodels, all contingent claims are information invariant. We augment the results\nwith examples and counterexamples.\n"
    },
    {
        "paper_id": "2408.02217",
        "authors": "A Samuel Pottinger, Lawson Connor, Brookie Guzder-Williams, Maya\n  Weltman-Fahs, Timothy Bowles",
        "title": "Climate-Driven Doubling of Maize Loss Probability in U.S. Crop\n  Insurance: Spatiotemporal Prediction and Possible Policy Responses",
        "comments": "24 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Climate change not only threatens agricultural producers but also strains\nfinancial institutions. These important food system actors include government\nentities tasked with both insuring grower livelihoods and supporting response\nto continued global warming. We use an artificial neural network to predict\nfuture maize yields in the U.S. Corn Belt, finding alarming changes to\ninstitutional risk exposure within the Federal Crop Insurance Program.\nSpecifically, our machine learning method anticipates more frequent and more\nsevere yield losses that would result in the annual probability of Yield\nProtection (YP) claims to more than double at mid-century relative to\nsimulations without continued climate change. Furthermore, our dual finding of\nrelatively unchanged average yields paired with decreasing yield stability\nreveals targeted opportunities to adjust coverage formulas to include\nvariability. This important structural shift may help regulators support grower\nadaptation to continued climate change by recognizing the value of\nrisk-reducing strategies such as regenerative agriculture. Altogether, paired\nwith open source interactive tools for deeper investigation, our risk profile\nsimulations fill an actionable gap in current understanding, bridging granular\nhistoric yield estimation and climate-informed prediction of future\ninsurer-relevant loss.\n"
    },
    {
        "paper_id": "2408.02273",
        "authors": "Preetha Saha, Jingrao Lyu, Dhruv Desai, Rishab Chauhan, Jerinsh\n  Jeyapaulraj, Philip Sommer, Dhagash Mehta",
        "title": "Machine Learning-based Relative Valuation of Municipal Bonds",
        "comments": "9 pages, 7 tables, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The trading ecosystem of the Municipal (muni) bond is complex and unique.\nWith nearly 2\\% of securities from over a million securities outstanding\ntrading daily, determining the value or relative value of a bond among its\npeers is challenging. Traditionally, relative value calculation has been done\nusing rule-based or heuristics-driven approaches, which may introduce human\nbiases and often fail to account for complex relationships between the bond\ncharacteristics. We propose a data-driven model to develop a supervised\nsimilarity framework for the muni bond market based on CatBoost algorithm. This\nalgorithm learns from a large-scale dataset to identify bonds that are similar\nto each other based on their risk profiles. This allows us to evaluate the\nprice of a muni bond relative to a cohort of bonds with a similar risk profile.\nWe propose and deploy a back-testing methodology to compare various benchmarks\nand the proposed methods and show that the similarity-based method outperforms\nboth rule-based and heuristic-based methods.\n"
    },
    {
        "paper_id": "2408.02289",
        "authors": "J. G. L\\'opez-Salas and S. P\\'erez-Rodr\\'iguez and C. V\\'azquez",
        "title": "PDEs for pricing interest rate derivatives under the new generalized\n  Forward Market Model (FMM)",
        "comments": null,
        "journal-ref": "Jos\\'e Germ\\'an L\\'opez-Salas, Soledad P\\'erez-Rodr\\'iguez, Carlos\n  V\\'azquez, PDEs for pricing interest rate derivatives under the new\n  generalized Forward Market Model (FMM), Computers & Mathematics with\n  Applications, 169, 2024, 88-98",
        "doi": "10.1016/j.camwa.2024.06.010",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this article we derive partial differential equations (PDEs) for pricing\ninterest rate derivatives under the generalized Forward Market Model (FMM)\nrecently presented by A. Lyashenko and F. Mercurio in\n\\cite{lyashenkoMercurio:Mar2019} to model the dynamics of the Risk Free Rates\n(RFRs) that are replacing the traditional IBOR rates in the financial industry.\nMoreover, for the numerical solution of the proposed PDEs formulation, we\ndevelop some adaptations of the finite differences methods developed in\n\\cite{LopezPerezVazquez:sisc} that are very suitable to treat the presence of\nspatial mixed derivatives. This work is the first article in the literature\nwhere PDE methods are used to value RFR derivatives. Additionally, Monte\nCarlo-based methods will be designed and the results are compared with those\nobtained by the numerical solution of PDEs.\n"
    },
    {
        "paper_id": "2408.02322",
        "authors": "Vincent Ragel and Damien Challet",
        "title": "Data time travel and consistent market making: taming reinforcement\n  learning in multi-agent systems with anonymous data",
        "comments": "11 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Reinforcement learning works best when the impact of the agent's actions on\nits environment can be perfectly simulated or fully appraised from available\ndata. Some systems are however both hard to simulate and very sensitive to\nsmall perturbations. An additional difficulty arises when an RL agent must\nlearn to be part of a multi-agent system using only anonymous data, which makes\nit impossible to infer the state of each agent, thus to use data directly.\nTypical examples are competitive systems without agent-resolved data such as\nfinancial markets. We introduce consistent data time travel for offline RL as a\nremedy for these problems: instead of using historical data in a sequential\nway, we argue that one needs to perform time travel in historical data, i.e.,\nto adjust the time index so that both the past state and the influence of the\nRL agent's action on the state coincide with real data. This both alleviates\nthe need to resort to imperfect models and consistently accounts for both the\nimmediate and long-term reactions of the system when using anonymous historical\ndata. We apply this idea to market making in limit order books, a notoriously\ndifficult task for RL; it turns out that the gain of the agent is significantly\nhigher with data time travel than with naive sequential data, which suggests\nthat the difficulty of this task for RL may have been overestimated.\n"
    },
    {
        "paper_id": "2408.02339",
        "authors": "Lionel Sopgoui",
        "title": "Modeling the impact of Climate transition on real estate prices",
        "comments": "25 pages, 10 figures, 8 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this work, we propose a model to quantify the impact of the climate\ntransition on a property in housing market. We begin by noting that property is\nan asset in an economy. That economy is organized in sectors, driven by its\nproductivity which is a multidimensional Ornstein-Uhlenbeck process, while the\nclimate transition is declined thanks to the carbon price, a continuous\ndeterministic process. We then extend the sales comparison approach and the\nincome approach to valuate an energy inefficient real estate asset. We obtain\nits value as the difference between the price of an equivalent efficient\nbuilding following an exponential Ornstein-Uhlenbeck as well as the actualized\nrenovation costs and the actualized sum of the future additional energy costs.\nThese costs are due to the inefficiency of the building, before an optimal\nrenovation date which depends on the carbon price process. Finally, we carry\nout simulations based on the French economy and the house price index of\nFrance. Our results allow to conclude that the order of magnitude of the\ndepreciation obtained by our model is the same as the empirical observations.\n"
    },
    {
        "paper_id": "2408.02355",
        "authors": "Mingshu Li, Bhaskarjit Sarmah, Dhruv Desai, Joshua Rosaler, Snigdha\n  Bhagat, Philip Sommer, Dhagash Mehta",
        "title": "Quantile Regression using Random Forest Proximities",
        "comments": "9 pages, 5 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Due to the dynamic nature of financial markets, maintaining models that\nproduce precise predictions over time is difficult. Often the goal isn't just\npoint prediction but determining uncertainty. Quantifying uncertainty,\nespecially the aleatoric uncertainty due to the unpredictable nature of market\ndrivers, helps investors understand varying risk levels. Recently, quantile\nregression forests (QRF) have emerged as a promising solution: Unlike most\nbasic quantile regression methods that need separate models for each quantile,\nquantile regression forests estimate the entire conditional distribution of the\ntarget variable with a single model, while retaining all the salient features\nof a typical random forest. We introduce a novel approach to compute quantile\nregressions from random forests that leverages the proximity (i.e., distance\nmetric) learned by the model and infers the conditional distribution of the\ntarget variable. We evaluate the proposed methodology using publicly available\ndatasets and then apply it towards the problem of forecasting the average daily\nvolume of corporate bonds. We show that using quantile regression using Random\nForest proximities demonstrates superior performance in approximating\nconditional target distributions and prediction intervals to the original\nversion of QRF. We also demonstrate that the proposed framework is\nsignificantly more computationally efficient than traditional approaches to\nquantile regressions.\n"
    },
    {
        "paper_id": "2408.02401",
        "authors": "S\\\"oren Bettels, Stefan Weber",
        "title": "An Integrated Approach to Importance Sampling and Machine Learning for\n  Efficient Monte Carlo Estimation of Distortion Risk Measures in Black Box\n  Models",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Distortion risk measures play a critical role in quantifying risks associated\nwith uncertain outcomes. Accurately estimating these risk measures in the\ncontext of computationally expensive simulation models that lack analytical\ntractability is fundamental to effective risk management and decision making.\nIn this paper, we propose an efficient important sampling method for distortion\nrisk measures in such models that reduces the computational cost through\nmachine learning. We demonstrate the applicability and efficiency of the Monte\nCarlo method in numerical experiments on various distortion risk measures and\nmodels.\n"
    },
    {
        "paper_id": "2408.02477",
        "authors": "Herv\\'e Andr\\`es (CERMICS), Benjamin Jourdain (CERMICS, MATHRISK)",
        "title": "Existence, uniqueness and positivity of solutions to the Guyon-Lekeufack\n  path-dependent volatility model with general kernels",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We show the existence and uniqueness of a continuous solution to a\npath-dependent volatility model introduced by Guyon and Lekeufack (2023) to\nmodel the price of an equity index and its spot volatility. The considered\nmodel for the trend and activity features can be written as a Stochastic\nVolterra Equation (SVE) with non-convolutional and non-bounded kernels as well\nas non-Lipschitz coefficients. We first prove the existence and uniqueness of a\nsolution to the SVE under integrability and regularity assumptions on the two\nkernels and under a condition on the second kernel weighting the past squared\nreturns which ensures that the activity feature is bounded from below by a\npositive constant. Then, assuming in addition that the kernel weighting the\npast returns is of exponential type and that an inequality relating the\nlogarithmic derivatives of the two kernels with respect to their second\nvariables is satisfied, we show the positivity of the volatility process which\nis obtained as a non-linear function of the SVE's solution. We show numerically\nthat the choice of an exponential kernel for the kernel weighting the past\nreturns has little impact on the quality of model calibration compared to other\nchoices and the inequality involving the logarithmic derivatives is satisfied\nby the calibrated kernels. These results extend those of Nutz and Valdevenito\n(2023).\n"
    },
    {
        "paper_id": "2408.02558",
        "authors": "Shiqi Fang, Zexun Chen, Jake Ansell",
        "title": "Peer-induced Fairness: A Causal Approach to Reveal Algorithmic\n  Unfairness",
        "comments": "28 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper introduces a novel framework, \"peer-induced fairness\", to\nscientifically audit algorithmic fairness. It addresses a critical but often\noverlooked issue: distinguishing between adverse outcomes due to algorithmic\ndiscrimination and those resulting from individuals' insufficient capabilities.\nBy utilizing counterfactual fairness and advanced causal inference techniques,\nsuch as the Single World Intervention Graph, this model-agnostic approach\nevaluates fairness at the individual level through peer comparisons and\nhypothesis testing. It also tackles challenges like data scarcity and\nimbalance, offering a flexible, plug-and-play self-audit tool for stakeholders\nand an external audit tool for regulators, while providing explainable feedback\nfor those affected by unfavorable decisions.\n"
    },
    {
        "paper_id": "2408.02634",
        "authors": "Robert McLaughlin, Nir Chemaya, Dingyue Liu, Dahlia Malkhi",
        "title": "CLVR Ordering of Transactions on AMMs",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "abstract": "  Trading on decentralized exchanges via an Automated Market Maker (AMM)\nmechanism has been massively adopted, with a daily trading volume reaching $1B.\nThis trading method has also received close attention from researchers, central\nbanks, and financial firms, who have the potential to adopt it to traditional\nfinancial markets such as foreign exchanges and stock markets. A critical\nchallenge of AMM-powered trading is that transaction order has high financial\nvalue, so a policy or method to order transactions in a \"good\" (optimal) manner\nis vital. We offer economic measures of both price stability (low volatility)\nand inequality that inform how a \"social planner\" should pick an optimal\nordering. We show that there is a trade-off between achieving price stability\nand reducing inequality, and that policymakers must choose which to prioritize.\nIn addition, picking the optimal order can often be costly, especially when\nperforming an exhaustive search over trade orderings (permutations). As an\nalternative we provide a simple algorithm, Clever Look-ahead Volatility\nReduction (CLVR). This algorithm constructs an ordering which approximately\nminimizes price volatility with a small computation cost. We also provide\ninsight into the strategy changes that may occur if traders are subject to this\nsequencing algorithm.\n"
    },
    {
        "paper_id": "2408.02694",
        "authors": "Tianqi Wang, Shubham Singh",
        "title": "KAN based Autoencoders for Factor Models",
        "comments": "7 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Inspired by recent advances in Kolmogorov-Arnold Networks (KANs), we\nintroduce a novel approach to latent factor conditional asset pricing models.\nWhile previous machine learning applications in asset pricing have\npredominantly used Multilayer Perceptrons with ReLU activation functions to\nmodel latent factor exposures, our method introduces a KAN-based autoencoder\nwhich surpasses MLP models in both accuracy and interpretability. Our model\noffers enhanced flexibility in approximating exposures as nonlinear functions\nof asset characteristics, while simultaneously providing users with an\nintuitive framework for interpreting latent factors. Empirical backtesting\ndemonstrates our model's superior ability to explain cross-sectional risk\nexposures. Moreover, long-short portfolios constructed using our model's\npredictions achieve higher Sharpe ratios, highlighting its practical value in\ninvestment management.\n"
    },
    {
        "paper_id": "2408.02942",
        "authors": "Shizhen Wang and Stanimira Milcheva",
        "title": "The Impossible Trinity of Human Space Usage between Home, Workplace and\n  Amenity",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We propose an impossible trinity of human space usage between home,\nworkplace, and amenity in this paper to explain mobility pattern changes and\nshifts in demand for space during COVID-19. We developed detailed time usage\nand location visit profiles for 60,131 people in England and Wales by analyzing\nabout 120 million cell phone location and timestamp records from March 2020 and\n2021. We found that both at-home time and amenity visits increased during\nCOVID-19, while workplace visits decreased. Individual visits to different\nlocations are determined by three key factors: individual preference measured\nby pre-pandemic location visit frequency, time constraints influenced by\nwork-from-home, and space accessibility. We also find that WFH improves\nequality of individual amenity usage between people of different incomes.\nLow-income and middle-income people saw an 8% and 4% increase in additional\namenity visits, respectively, compared to high-income people during the\npandemic.\n"
    },
    {
        "paper_id": "2408.02973",
        "authors": "Yaoyue Tang, Karina Arias-Calluari, Michael S. Harr\\'e",
        "title": "Comparative analysis of stationarity for Bitcoin and the S&P500",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  This paper compares and contrasts stationarity between the conventional stock\nmarket and cryptocurrency. The dataset used for the analysis is the intraday\nprice indices of the S&P500 from 1996 to 2023 and the intraday Bitcoin indices\nfrom 2019 to 2023, both in USD. We adopt the definition of `wide sense\nstationary', which constrains the time independence of the first and second\nmoments of a time series. The testing method used in this paper follows the\nWiener-Khinchin Theorem, i.e., that for a wide sense stationary process, the\npower spectral density and the autocorrelation are a Fourier transform pair. We\ndemonstrate that localized stationarity can be achieved by truncating the time\nseries into segments, and for each segment, detrending and normalizing the\nprice return are required. These results show that the S&P500 price return can\nachieve stationarity for the full 28-year period with a detrending window of 12\nmonths and a constrained normalization window of 10 minutes. With truncated\nsegments, a larger normalization window can be used to establish stationarity,\nindicating that within the segment the data is more homogeneous. For Bitcoin\nprice return, the segment with higher volatility presents stationarity with a\nnormalization window of 60 minutes, whereas stationarity cannot be established\nin other segments.\n"
    },
    {
        "paper_id": "2408.03134",
        "authors": "Christoph Czichowsky, Martin Herdegen, David Martins",
        "title": "Existence and uniqueness of quadratic and linear mean-variance\n  equilibria in general semimartingale markets",
        "comments": "32 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We revisit the classical topic of quadratic and linear mean-variance\nequilibria with both financial and real assets. The novelty of our results is\nthat they are the first allowing for equilibrium prices driven by general\nsemimartingales and hold in discrete as well as continuous time. For agents\nwith quadratic utility functions, we provide necessary and sufficient\nconditions for the existence and uniqueness of equilibria. We complement our\nanalysis by providing explicit examples showing non-uniqueness or non-existence\nof equilibria. We then study the more difficult case of linear mean-variance\npreferences. We first show that under mild assumptions, a linear mean-variance\nequilibrium corresponds to a quadratic equilibrium (for different preference\nparameters). We then use this link to study a fixed-point problem that\nestablishes existence (and uniqueness in a suitable class) of linear\nmean-variance equilibria. Our results rely on fine properties of dynamic\nmean-variance hedging in general semimartingale markets.\n"
    },
    {
        "paper_id": "2408.03137",
        "authors": "Abdulnasser Hatemi-J",
        "title": "Efficient Asymmetric Causality Tests",
        "comments": "14 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Asymmetric causality tests are increasingly gaining popularity in different\nscientific fields. This approach corresponds better to reality since logical\nreasons behind asymmetric behavior exist and need to be considered in empirical\ninvestigations. Hatemi-J (2012) introduced the asymmetric causality tests via\npartial cumulative sums for positive and negative components of the variables\noperating within the vector autoregressive (VAR) model. However, since the\nresiduals across the equations in the VAR model are not independent, the\nordinary least squares method for estimating the parameters is not efficient.\nAdditionally, asymmetric causality tests mean having different causal\nparameters (i.e., for positive or negative components), thus, it is crucial to\nassess not only if these causal parameters are individually statistically\nsignificant, but also if their difference is statistically significant.\nConsequently, tests of difference between estimated causal parameters should\nexplicitly be conducted, which are neglected in the existing literature. The\npurpose of the current paper is to deal with these issues explicitly. An\napplication is provided, and ten different hypotheses pertinent to the\nasymmetric causal interaction between two largest financial markets worldwide\nare efficiently tested within a multivariate setting.\n"
    },
    {
        "paper_id": "2408.03147",
        "authors": "Peng Liu, Andreas Tsanakas, Yunran Wei",
        "title": "Risk sharing with Lambda value at risk under heterogeneous beliefs",
        "comments": "31 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper, we study the risk sharing problem among multiple agents using\nLambda value at risk as their preferences under heterogenous beliefs, where the\nbeliefs are represented by several probability measures. We obtain\nsemi-explicit formulas for the inf-convolution of multiple Lambda value at risk\nunder heterogenous beliefs and the explicit forms of the corresponding optimal\nallocations. To show the interplay among the beliefs, we consider three cases:\nhomogeneous beliefs, conditional beliefs and absolutely continuous beliefs. For\nthose cases, we find more explicit expressions for the inf-convolution, showing\nthe influence of the relation of the beliefs on the inf-convolution. Moreover,\nwe consider the inf-convolution of one Lambda value at risk and a general risk\nmeasure, including expected utility, distortion risk measures and Lambda value\nat risk as special cases, with different beliefs. The expression of the\ninf-convolution and the form of the optimal allocation are obtained. Finally,\nwe discuss the risk sharing for another definition of Lambda value at risk.\n"
    },
    {
        "paper_id": "2408.03181",
        "authors": "Dominic Bauer, Derick Diana and Tim Gebbie",
        "title": "Correlation emergence in two coupled simulated limit order books",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We use random walks to simulate the fluid limit of two coupled diffusive\nlimit order books to model correlation emergence. The model implements the\narrival, cancellation and diffusion of orders coupled by a pairs trader\nprofiting from the mean-reversion between the two order books in the fluid\nlimit for a Lit order book with vanishing boundary conditions and order volume\nconservation. We are able to demonstrate the recovery of an Epps effect from\nthis. We discuss how various stylised facts depend on the model parameters and\nthe numerical scheme and discuss the various strengths and weaknesses of the\napproach. We demonstrate how the Epps effect depends on different choices of\ntime and price discretisation. This shows how an Epps effect can emerge without\nrecourse to market microstructure noise relative to a latent model but can\nrather be viewed as an emergent property arising from trader interactions in a\nworld of asynchronous events.\n"
    },
    {
        "paper_id": "2408.03320",
        "authors": "Siqiao Zhao, Zhikang Dong, Zeyu Cao, Raphael Douady",
        "title": "Hedge Fund Portfolio Construction Using PolyModel Theory and\n  iTransformer",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  When constructing portfolios, a key problem is that a lot of financial time\nseries data are sparse, making it challenging to apply machine learning\nmethods. Polymodel theory can solve this issue and demonstrate superiority in\nportfolio construction from various aspects. To implement the PolyModel theory\nfor constructing a hedge fund portfolio, we begin by identifying an asset pool,\nutilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory\nalso involves choosing a wide-ranging set of risk factors, which includes\nvarious financial indices, currencies, and commodity prices. This comprehensive\nselection mirrors the complexities of the real-world environment. Leveraging on\nthe PolyModel theory, we create quantitative measures such as Long-term Alpha,\nLong-term Ratio, and SVaR. We also use more classical measures like the Sharpe\nratio or Morningstar's MRAR. To enhance the performance of the constructed\nportfolio, we also employ the latest deep learning techniques (iTransformer) to\ncapture the upward trend, while efficiently controlling the downside, using all\nthe features. The iTransformer model is specifically designed to address the\nchallenges in high-dimensional time series forecasting and could largely\nimprove our strategies. More precisely, our strategies achieve better Sharpe\nratio and annualized return. The above process enables us to create multiple\nportfolio strategies aiming for high returns and low risks when compared to\nvarious benchmarks.\n"
    },
    {
        "paper_id": "2408.03328",
        "authors": "Aabid Karim, Heman Das Lohano",
        "title": "Sentiment Analysis of State Bank of Pakistan's Monetary Policy Documents\n  and its Impact on Stock Market",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "abstract": "  This research examines whether sentiments conveyed in the State Bank of\nPakistan's (SBP) communications impact financial market expectations and can\nact as a monetary policy tool. To achieve our goal, we first use sentiment\nanalysis techniques to quantify the tone of SBP monetary policy documents and\nsecond, we use short time window, high frequency methodology to approximate the\nimpact of tone on stock market returns. Our results show that positive\n(negative) change in the tone positively (negatively) impacts stock returns in\nKarachi Stock Exchange. Further extension shows that the communication of SBP\nstill has a statistically significant impact on stock returns when controlling\nfor different variables and monetary policy tool. Also, the communication of\nSBP does not have a long term constant effect on stock market.\n"
    },
    {
        "paper_id": "2408.03579",
        "authors": "Shan Huang, Yuan Yuan, Yi Ji",
        "title": "\"The Strength of Weak Ties\" Varies Across Viral Channels",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The diffusion of novel information through social networks is essential for\ndismantling echo chambers and promoting innovation. Our study examines how two\nmajor types of viral channels, specifically Direct Messaging (DM) and\nBroadcasting (BC), impact the well-known \"strength of weak ties\" in\ndisseminating novel information across social networks. We conducted a\nlarge-scale empirical analysis, examining the sharing behavior of 500,000 users\nover a two-month period on a major social media platform. Our results suggest a\ngreater capacity for DM to transmit novel information compared to BC, although\nDM typically involves stronger ties. Furthermore, the \"strength of weak ties\"\nis only evident in BC, not in DM where weaker ties do not transmit\nsignificantly more novel information. Our mechanism analysis indicates that the\ncontent selection by both senders and recipients, contingent on tie strength,\ncontributes to the observed differences between these two channels. These\nfindings expand both our understanding of contemporary weak tie theory and our\nknowledge of how to disseminate novel information in social networks.\n"
    },
    {
        "paper_id": "2408.03594",
        "authors": "Aditya Nittur Anantha and Shashi Jain",
        "title": "Forecasting High Frequency Order Flow Imbalance",
        "comments": "21 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Market information events are generated intermittently and disseminated at\nhigh speeds in real-time. Market participants consume this high-frequency data\nto build limit order books, representing the current bids and offers for a\ngiven asset. The arrival processes, or the order flow of bid and offer events,\nare asymmetric and possibly dependent on each other. The quantum and direction\nof this asymmetry are often associated with the direction of the traded price\nmovement. The Order Flow Imbalance (OFI) is an indicator commonly used to\nestimate this asymmetry. This paper uses Hawkes processes to estimate the OFI\nwhile accounting for the lagged dependence in the order flow between bids and\noffers. Secondly, we develop a method to forecast the near-term distribution of\nthe OFI, which can then be used to compare models for forecasting OFI. Thirdly,\nwe propose a method to compare the forecasts of OFI for an arbitrarily large\nnumber of models. We apply the approach developed to tick data from the\nNational Stock Exchange and observe that the Hawkes process modeled with a Sum\nof Exponential's kernel gives the best forecast among all competing models.\n"
    },
    {
        "paper_id": "2408.03655",
        "authors": "Sergiy Tkachuk, Szymon {\\L}ukasik, Anna Wr\\'oblewska",
        "title": "Consumer Transactions Simulation through Generative Adversarial Networks",
        "comments": "12 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  In the rapidly evolving domain of large-scale retail data systems,\nenvisioning and simulating future consumer transactions has become a crucial\narea of interest. It offers significant potential to fortify demand forecasting\nand fine-tune inventory management. This paper presents an innovative\napplication of Generative Adversarial Networks (GANs) to generate synthetic\nretail transaction data, specifically focusing on a novel system architecture\nthat combines consumer behavior modeling with stock-keeping unit (SKU)\navailability constraints to address real-world assortment optimization\nchallenges. We diverge from conventional methodologies by integrating SKU data\ninto our GAN architecture and using more sophisticated embedding methods (e.g.,\nhyper-graphs). This design choice enables our system to generate not only\nsimulated consumer purchase behaviors but also reflects the dynamic interplay\nbetween consumer behavior and SKU availability -- an aspect often overlooked,\namong others, because of data scarcity in legacy retail simulation models. Our\nGAN model generates transactions under stock constraints, pioneering a\nresourceful experimental system with practical implications for real-world\nretail operation and strategy. Preliminary results demonstrate enhanced realism\nin simulated transactions measured by comparing generated items with real ones\nusing methods employed earlier in related studies. This underscores the\npotential for more accurate predictive modeling.\n"
    },
    {
        "paper_id": "2408.03659",
        "authors": "Ying Liang",
        "title": "Firms' Risk Adjustments to Minimum Wage: Financial Leverage and Labor\n  Share Trade-off",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper evaluates the impact of the German minimum wage policy on firms'\nfinancial leverage. By using a comprehensive firm-establishment-employee linked\ndataset and a difference-in-differences estimation with firm-level variation in\ntreatment intensity, the analysis shows that the average minimum wage level\nreduces firms' financial leverage by about 0.5 to 0.9 percentage points,\ncorresponding to 1 to 2 percent of the mean of financial leverage. Further\ninvestigation of the mechanism shows that the minimum wage does not lead to\nsignificant capital-labor substitution; therefore, the labor share increases.\nFirms react to the increased labor share by deleveraging. The results suggest\nthat while the minimum wage benefits workers by allocating more earnings to the\nlabor force, it also introduces greater operating risks and encourages\nconservative financial behavior among firms.\n"
    },
    {
        "paper_id": "2408.03926",
        "authors": "Adam Graham-Squire, Matthew I. Jones, David McCune",
        "title": "New fairness criteria for truncated ballots in multi-winner\n  ranked-choice elections",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In real-world elections where voters cast preference ballots, voters often\nprovide only a partial ranking of the candidates. Despite this empirical\nreality, prior social choice literature frequently analyzes fairness criteria\nunder the assumption that all voters provide a complete ranking of the\ncandidates. We introduce new fairness criteria for multiwinner ranked-choice\nelections concerning truncated ballots. In particular, we define notions of the\nindependence of losing voters blocs and independence of winning voters blocs,\nwhich state that the winning committee of an election should not change when we\nremove partial ballots which rank only losing candidates, and the winning\ncommittee should change in reasonable ways when removing ballots which rank\nonly winning candidates. Of the voting methods we analyze, the\nChamberlin-Courant rule performs the best with respect to these criteria, the\nexpanding approvals rule performs the worst, and the method of single\ntransferable vote falls in between.\n"
    },
    {
        "paper_id": "2408.04508",
        "authors": "Erik-Benjamin B\\\"orschlein, Mario Bossler, Martin Popp",
        "title": "Scarce Workers, High Wages?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  Labor market tightness tremendously increased in Germany between 2012 and\n2022. We analyze the effect of tightness on wages by combining social security\ndata with unusually rich information on vacancies and job seekers. Instrumental\nvariable regressions reveal positive elasticities between 0.004 and 0.011,\nimplying that higher tightness explains between 7 and 19 percent of the real\nwage increase. We report greater elasticities for new hires, high-skilled\nworkers, the Eastern German labor market, and the service sector. In\nparticular, tightness raised wages at the bottom of the wage distribution,\ncontributing to the decline in wage inequality over the last decade.\n"
    },
    {
        "paper_id": "2408.04644",
        "authors": "Victor Olkhov",
        "title": "Lower bounds of uncertainty and upper limits on the accuracy of\n  forecasts of macroeconomic variables",
        "comments": "20 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider the randomness of values and volumes of market deals as a major\nfactor that describes lower bounds of uncertainty and upper limits on the\naccuracy of the forecasts of macroeconomic variables, prices, and returns. We\nintroduce random macroeconomic variables, whose average values coincide with\nusual macroeconomic variables, and describe their uncertainty by coefficients\nof variation that depend on the volatilities, correlations, and coefficients of\nvariation of random values or volumes of trades. The same approach describes\nbounds of uncertainty and limits on the accuracy of forecasts for growth rates,\ninflation, interest rates, etc. Limits on the accuracy of forecasts of\nmacroeconomic variables depend on the certainty of predictions of their\nprobabilities. The number of predicted statistical moments determines the\nveracity of macroeconomic probability. To quantify macroeconomic 2nd\nstatistical moments, one needs additional econometric methodologies, data, and\ncalculations of variables determined as sums of squares of values or volumes of\nmarket trades. Forecasting of macroeconomic 2nd statistical moments requires\n2nd order economic theories. All of that is absent and for many years to come,\nthe accuracy of forecasts of the probabilities of random macroeconomic\nvariables, prices, and returns will be limited by the Gaussian approximations,\nwhich are determined by the first two statistical moments.\n"
    },
    {
        "paper_id": "2408.04717",
        "authors": "Aneta Napieralska and Przemys{\\l}aw K\\k{e}pczy\\'nski",
        "title": "Redefining Accountability: Navigating Legal Challenges of Participant\n  Liability in Decentralized Autonomous Organizations",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  In the digital era, where innovative technologies like blockchain are\nrevolutionizing traditional organizational paradigms, Decentralized Autonomous\nOrganizations (DAOs) emerge as avant-garde models of collective governance.\nHowever, their unique structure challenges existing legal frameworks,\nespecially concerning the liability of participants. This study focuses on\nanalyzing the legal implications of the decentralized nature of DAOs, with a\nparticular emphasis on the aspects of participant liability. Such\nconsiderations are essential for understanding how current legal systems might\nbe adapted or reformed to effectively address these novel challenges.\n  The paper examines the specificity of DAOs, highlighting their decentralized\ngovernance structure and reliance on smart contracts, which introduce unique\nissues related to the blurring of liability boundaries. It underscores how the\nanonymity of DAO participants and the automatic execution of smart contracts\ncomplicate the traditional concept of legal liability, both within the DAO\ncontext and in interactions with external parties.\n  The analysis also includes a comparison between DAOs and traditional\norganizational forms, such as corporations and associations, to identify\npotential analogies and differences in participant liability. It explores how\nexisting regulations on partner liability might be insufficient or inapplicable\nin the DAO context, prompting the search for new, innovative legal solutions.\n"
    },
    {
        "paper_id": "2408.04758",
        "authors": "T. Choulli and S. Alsheyab",
        "title": "Linear reflected backward stochastic differential equations arising from\n  vulnerable claims in markets with random horizon",
        "comments": "arXiv admin note: substantial text overlap with arXiv:2301.09836",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "abstract": "  This paper considers the setting governed by $(\\mathbb{F},\\tau)$, where\n$\\mathbb{F}$ is the \"public\" flow of information, and $\\tau$ is a random time\nwhich might not be $\\mathbb{F}$-observable. This framework covers credit risk\ntheory and life insurance. In this setting, we assume $\\mathbb{F}$ being\ngenerated by a Brownian motion $W$ and consider a vulnerable claim $\\xi$, whose\npayment's policy depends {\\it{essentially}} on the occurrence of $\\tau$. The\nhedging problems, in many directions, for this claim led to the question of\nstudying the linear reflected-backward-stochastic differential equations (RBSDE\nhereafter), \\begin{equation*} \\begin{split}\n&dY_t=f(t)d(t\\wedge\\tau)+Z_tdW_{t\\wedge{\\tau}}+dM_t-dK_t,\\quad Y_{\\tau}=\\xi,\\\\\n& Y\\geq S\\quad\\mbox{on}\\quad \\Lbrack0,\\tau\\Lbrack,\\quad\n\\displaystyle\\int_0^{\\tau}(Y_{s-}-S_{s-})dK_s=0\\quad P\\mbox{-a.s.}.\\end{split}\n\\end{equation*} This is the objective of this paper. For this RBSDE and without\nany further assumption on $\\tau$ that might neglect any risk intrinsic to its\nstochasticity, we answer the following: a) What are the sufficient minimal\nconditions on the data $(f, \\xi, S, \\tau)$ that guarantee the existence of the\nsolution to this RBSDE? b) How can we estimate the solution in norm using $(f,\n\\xi, S)$? c) Is there an $\\mathbb F$-RBSDE that is intimately related to the\ncurrent one and how their solutions are related to each other? This latter\nquestion has practical and theoretical leitmotivs.\n"
    },
    {
        "paper_id": "2408.04781",
        "authors": "Keisuke Kokubun",
        "title": "Relationships between six cultural scales and ten ageism dimensions:\n  Correlation analysis using data from 31 countries",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  As the aging of the world accelerates, clarifying the relationship between\ncultural differences and ageism is an urgent issue. Therefore, in this study,\nwe conducted a correlation analysis between the six cultural scales of Hofstede\net al. [1] and the 10 ageism scales calculated from data on 35,232 people from\n31 countries included in the World Values Survey Wave 6 by Inglehart et al.\n[2]. The results of a partial correlation analysis controlling for economic and\ndemographic factors showed that the cultural scales were correlated with\nageism. This is the first study to show that diverse cultural scales are\nrelated to multiple dimensions of ageism.\n"
    },
    {
        "paper_id": "2408.04948",
        "authors": "Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano\n  Pasquali, Dhagash Mehta",
        "title": "HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented\n  Generation for Efficient Information Extraction",
        "comments": "9 pages, 2 figures, 5 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Extraction and interpretation of intricate information from unstructured text\ndata arising in financial applications, such as earnings call transcripts,\npresent substantial challenges to large language models (LLMs) even using the\ncurrent best practices to use Retrieval Augmented Generation (RAG) (referred to\nas VectorRAG techniques which utilize vector databases for information\nretrieval) due to challenges such as domain specific terminology and complex\nformats of the documents. We introduce a novel approach based on a combination,\ncalled HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called\nGraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for\ninformation extraction from financial documents that is shown to be capable of\ngenerating accurate and contextually relevant answers. Using experiments on a\nset of financial earning call transcripts documents which come in the form of\nQ&A format, and hence provide a natural set of pairs of ground-truth Q&As, we\nshow that HybridRAG which retrieves context from both vector database and KG\noutperforms both traditional VectorRAG and GraphRAG individually when evaluated\nat both the retrieval and generation stages in terms of retrieval accuracy and\nanswer generation. The proposed technique has applications beyond the financial\ndomain\n"
    },
    {
        "paper_id": "2408.05059",
        "authors": "Ziho Park",
        "title": "Democratic Favor Channel",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  A large body of literature in economics and political science examines the\nimpact of democracy and political freedoms on various outcomes using\ncross-country comparisons. This paper explores the possibility that any\npositive impact of democracy observed in these studies might be attributed to\npowerful democratic nations, their allies, and international organizations\ntreating democracies more favorably than nondemocracies, a concept I refer to\nas democratic favor channel. Firstly, after I control for being targeted by\nsanctions from G7 or the United Nations and having military confrontations and\ncooperation with the West, most of the positive effects of democracy on growth\nin cross-country panel regressions become insignificant or negatively\nsignificant. Secondly, using the same empirical specification as this\nliterature for demonstrating intermediating forces, I show that getting\nsanctioned, militarily attacked, and not having defense cooperation with the\nWest are plausible channels through which democracy causes growth. Lastly, in\nthe pre-Soviet-collapse period, which coincides with the time when democracy\npromotion was less often used as a justification for sanctions, the impact of\ndemocracy on GDP per capita is already weak or negative without any additional\ncontrols, and it becomes further negative once democratic favor is controlled.\nThese findings support the democratic favor channel and challenge the idea that\nthe institutional qualities of democracy per se lead to desirable outcomes. The\ncritique provided in this paper applies to the broader comparative institutions\nliterature in social sciences and political philosophy.\n"
    },
    {
        "paper_id": "2408.05194",
        "authors": "Mu Lin, Di Zhang, Ben Chen and Hang Zheng",
        "title": "The Economic Analysis of the Common Pool Method through the HARA Utility\n  Functions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Water market is a contemporary marketplace for water trading and is deemed to\none of the most efficient instruments to improve the social welfare. In modern\nwater markets, the two widely used trading systems are an improved pair-wise\ntrading, and a 'smart market' or common pool method. In comparison with the\neconomic model, this paper constructs a conceptual mathematic model through the\nHARA utility functions. Mirroring the concepts such as Nash Equilibrium, Pareto\noptimal and stable matching in economy, three significant propositions are\nacquired which illustrate the advantages of the common pool method compared\nwith the improved pair-wise trading.\n"
    },
    {
        "paper_id": "2408.05223",
        "authors": "Muhammad Hassan Bin Afzal",
        "title": "Economic Struggles and Inflation: How Does that affect voting decision?",
        "comments": "(37 Pages, 3 Tables, 5 figures)",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Economic hardships significantly affect public perception and voting\nintentions in general elections. The primary focus of my study is to capture\nthe degree of influence that individual economic hardships have on their\nvoting. I utilize the ANES 2024 Pilot Study1 Survey dataset and introduce a\nnovel composite Inflation Behavior Index (IBR) that captures individuals'\ncumulative economic and cost of living experience. To that effect, the primary\nobjectives of the current study are threefold: first, to develop a composite\neconomic behavior index from available data and variables to capture the\noverall economic experience of U.S. individuals due to ongoing inflation;\nsecond, to examine how this economic behavior impacts political engagement and\nvoting behavior utilizing appropriate and fitting mathematical models; and\nfinally which specific personal experiences and perceptions about economy and\ncost of living likely to revoke party loyalty in upcoming U.S. presidential\nelection. My study finds that increased personal economic struggles (pocketbook\nvoting) due to inflation make it more likely for individuals to express an\nintention to vote against the Incumbent even if the Incumbent is from their\nself-identified political party. Conversely, having a negative perception of\nthe national economy (sociotropic voting) is less likely to revoke party\nloyalty in the upcoming General election. In simpler terms, voters are more\nlikely to vote along party lines even if they perceive their party (the\nIncumbent) is not handling the economy and cost of living well.\n"
    },
    {
        "paper_id": "2408.05328",
        "authors": "Ning Li, Huaikang Zhou, Mingze Xu",
        "title": "From Text to Insight: Leveraging Large Language Models for Performance\n  Evaluation in Management",
        "comments": "39 pages, 8 figures, 5 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "abstract": "  This study explores the potential of Large Language Models (LLMs),\nspecifically GPT-4, to enhance objectivity in organizational task performance\nevaluations. Through comparative analyses across two studies, including various\ntask performance outputs, we demonstrate that LLMs can serve as a reliable and\neven superior alternative to human raters in evaluating knowledge-based\nperformance outputs, which are a key contribution of knowledge workers. Our\nresults suggest that GPT ratings are comparable to human ratings but exhibit\nhigher consistency and reliability. Additionally, combined multiple GPT ratings\non the same performance output show strong correlations with aggregated human\nperformance ratings, akin to the consensus principle observed in performance\nevaluation literature. However, we also find that LLMs are prone to contextual\nbiases, such as the halo effect, mirroring human evaluative biases. Our\nresearch suggests that while LLMs are capable of extracting meaningful\nconstructs from text-based data, their scope is currently limited to specific\nforms of performance evaluation. By highlighting both the potential and\nlimitations of LLMs, our study contributes to the discourse on AI role in\nmanagement studies and sets a foundation for future research to refine AI\ntheoretical and practical applications in management.\n"
    },
    {
        "paper_id": "2408.05382",
        "authors": "Ali Habibnia and Mahdi Soltanzadeh",
        "title": "Optimizing Portfolio with Two-Sided Transactions and Lending: A\n  Reinforcement Learning Framework",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This study presents a Reinforcement Learning (RL)-based portfolio management\nmodel tailored for high-risk environments, addressing the limitations of\ntraditional RL models and exploiting market opportunities through two-sided\ntransactions and lending. Our approach integrates a new environmental\nformulation with a Profit and Loss (PnL)-based reward function, enhancing the\nRL agent's ability in downside risk management and capital optimization. We\nimplemented the model using the Soft Actor-Critic (SAC) agent with a\nConvolutional Neural Network with Multi-Head Attention (CNN-MHA). This setup\neffectively manages a diversified 12-crypto asset portfolio in the Binance\nperpetual futures market, leveraging USDT for both granting and receiving loans\nand rebalancing every 4 hours, utilizing market data from the preceding 48\nhours. Tested over two 16-month periods of varying market volatility, the model\nsignificantly outperformed benchmarks, particularly in high-volatility\nscenarios, achieving higher return-to-risk ratios and demonstrating robust\nprofitability. These results confirm the model's effectiveness in leveraging\nmarket dynamics and managing risks in volatile environments like the\ncryptocurrency market.\n"
    },
    {
        "paper_id": "2408.05620",
        "authors": "Lorenc Kapllani and Long Teng",
        "title": "A forward differential deep learning-based algorithm for solving\n  high-dimensional nonlinear backward stochastic differential equations",
        "comments": "16 pages, 3 figures, 4 tables. arXiv admin note: text overlap with\n  arXiv:2404.08456",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this work, we present a novel forward differential deep learning-based\nalgorithm for solving high-dimensional nonlinear backward stochastic\ndifferential equations (BSDEs). Motivated by the fact that differential deep\nlearning can efficiently approximate the labels and their derivatives with\nrespect to inputs, we transform the BSDE problem into a differential deep\nlearning problem. This is done by leveraging Malliavin calculus, resulting in a\nsystem of BSDEs. The unknown solution of the BSDE system is a triple of\nprocesses $(Y, Z, \\Gamma)$, representing the solution, its gradient, and the\nHessian matrix. The main idea of our algorithm is to discretize the integrals\nusing the Euler-Maruyama method and approximate the unknown discrete solution\ntriple using three deep neural networks. The parameters of these networks are\nthen optimized by globally minimizing a differential learning loss function,\nwhich is novelty defined as a weighted sum of the dynamics of the discretized\nsystem of BSDEs. Through various high-dimensional examples, we demonstrate that\nour proposed scheme is more efficient in terms of accuracy and computation time\ncompared to other contemporary forward deep learning-based methodologies.\n"
    },
    {
        "paper_id": "2408.05648",
        "authors": "Yi Zheng",
        "title": "Evaluation methods and empirical research on coastal environmental\n  performance for Chinese harbor cities",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For controlling pollution of the marine environment while developing coastal\neconomy, the coastal environmental performance was proposed and measured in\nstatic and dynamic methods combined with DEA and efficiency theory in this\npaper. With the two methods, 16 harbor cities were evaluated. The results\nshowed the index designed in this paper can better reflect the effect to the\nmarine environment for economy of the coastal cities.\n"
    },
    {
        "paper_id": "2408.05652",
        "authors": "Yi Zheng",
        "title": "Evaluation to Chinese marine economy in the coastal areas",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  For promoting the development of the marine economy more sustainably, based\non the data envelopment analysis method and combined with the impact of the\nmarine environment, the environmental performance of the marine economy was\nevaluated for Chinese coastal provinces. Firstly, the classical CCR model was\nused. Then, a model that considered undesirable outputs was developed to suit\nthe Chinese marine economy. Using the two models, the economic efficiencies\nwithout environmental consideration and the environmental performance index\nwere calculated and compared. According to the results, the empirical\nrelationship between EPI and EE, per capita GDP, and the industrial structure\nwas analyzed. It is useful for guiding the coastal local economy of China to a\nhealthy way.\n"
    },
    {
        "paper_id": "2408.05653",
        "authors": "Yi Zheng",
        "title": "Measuring and Controlling Fishing Capacity for Chinese Inshore Fleets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The fishing capacity and capacity utilization for Chinese inshore fleets over\nthe latest 13 years were measured using the DEA method. Relevant models were\nthen established to analyze the relationships between capacity output, capacity\nutilization, and income, and the function of collecting taxes to control\nfishing capacity was quantitatively simulated. It was pointed out that the tax\nsystem would be effective for curtailing fishing capacity and improving the\nefficiency of the entire fishing industry in China, provided that the tax rate\nis not too low. Finally, it was suggested that collecting taxes at a proper\nrate be implemented for Chinese inshore fishing fleets.\n"
    },
    {
        "paper_id": "2408.05659",
        "authors": "Nikolas Michael, Mihai Cucuringu, Sam Howison",
        "title": "A GCN-LSTM Approach for ES-mini and VX Futures Forecasting",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We propose a novel data-driven network framework for forecasting problems\nrelated to E-mini S\\&P 500 and CBOE Volatility Index futures, in which products\nwith different expirations act as distinct nodes. We provide visual\ndemonstrations of the correlation structures of these products in terms of\ntheir returns, realized volatility, and trading volume. The resulting networks\noffer insights into the contemporaneous movements across the different\nproducts, illustrating how inherently connected the movements of the future\nproducts belonging to these two classes are. These networks are further\nutilized by a multi-channel Graph Convolutional Network to enhance the\npredictive power of a Long Short-Term Memory network, allowing for the\npropagation of forecasts of highly correlated quantities, combining the\ntemporal with the spatial aspect of the term structure.\n"
    },
    {
        "paper_id": "2408.05672",
        "authors": "Zheng Cao",
        "title": "Stochastic Calculus for Option Pricing with Convex Duality, Logistic\n  Model, and Numerical Examination",
        "comments": "65 pages, 17 figures, 6 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This thesis explores the historical progression and theoretical constructs of\nfinancial mathematics, with an in-depth exploration of Stochastic Calculus as\nshowcased in the Binomial Asset Pricing Model and the Continuous-Time Models. A\ncomprehensive survey of stochastic calculus principles applied to option\npricing is offered, highlighting insights from Peter Carr and Lorenzo\nTorricelli's ``Convex Duality in Continuous Option Pricing Models\". This\nmanuscript adopts techniques such as Monte-Carlo Simulation and machine\nlearning algorithms to examine the propositions of Carr and Torricelli, drawing\ncomparisons between the Logistic and Bachelier models. Additionally, it\nsuggests directions for potential future research on option pricing methods.\n"
    },
    {
        "paper_id": "2408.05690",
        "authors": "Matthias J. Feiler",
        "title": "Strong denoising of financial time-series",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  In this paper we introduce a method for significantly improving the signal to\nnoise ratio in financial data. The approach relies on combining a target\nvariable with different context variables and use auto-encoders (AEs) to learn\nreconstructions of the combined inputs. The objective is to obtain agreement\namong pairs of AEs which are trained on related but different inputs and for\nwhich they are forced to find common ground. The training process is set up as\na \"conversation\" where the models take turns at producing a prediction\n(speaking) and reconciling own predictions with the output of the other AE\n(listening), until an agreement is reached. This leads to a new way of\nconstraining the complexity of the data representation generated by the AE.\nUnlike standard regularization whose strength needs to be decided by the\ndesigner, the proposed mutual regularization uses the partner network to detect\nand amend the lack of generality of the learned representation of the data. The\nintegration of alternative perspectives enhances the de-noising capacity of a\nsingle AE and allows us to discover new regularities in financial time-series\nwhich can be converted into profitable trading strategies.\n"
    },
    {
        "paper_id": "2408.05701",
        "authors": "Dangxing Chen, Jingfeng Chen, Weicheng Ye",
        "title": "Why Groups Matter: Necessity of Group Structures in Attributions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Explainable machine learning methods have been accompanied by substantial\ndevelopment. Despite their success, the existing approaches focus more on the\ngeneral framework with no prior domain expertise. High-stakes financial sectors\nhave extensive domain knowledge of the features. Hence, it is expected that\nexplanations of models will be consistent with domain knowledge to ensure\nconceptual soundness.\n  In this work, we study the group structures of features that are naturally\nformed in the financial dataset. Our study shows the importance of considering\ngroup structures that conform to the regulations. When group structures are\npresent, direct applications of explainable machine learning methods, such as\nShapley values and Integrated Gradients, may not provide consistent\nexplanations; alternatively, group versions of the Shapley value can provide\nconsistent explanations. We contain detailed examples to concentrate on the\npractical perspective of our framework.\n"
    },
    {
        "paper_id": "2408.05851",
        "authors": "Jeremy Goodman and Harvey Lederman",
        "title": "Maximal Social Welfare Relations on Infinite Populations Satisfying\n  Permutation Invariance",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  We study social welfare relations (SWRs) on infinite utility streams. Our\nmain result is a new characterization of a utilitarian SWR on lotteries over\nwelfare distributions for an infinite population. We characterize this SWR as\nthe maximally complete SWR over lotteries on such distributions which satisfies\nStrong Pareto, Permutation Invariance (elsewhere called \"Relative Anonymity\"\nand \"Isomorphism Invariance\"), Dominance, Ex Ante Indifference, and an Additive\nInvariance axiom.\n"
    },
    {
        "paper_id": "2408.05856",
        "authors": "Pascal Michaillat and Emmanuel Saez",
        "title": "Has the Recession Started?",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  To answer this question, we develop a new Sahm-type recession indicator that\ncombines vacancy and unemployment data. The indicator is the minimum of the\nSahm indicator -- the difference between the 3-month trailing average of the\nunemployment rate and its minimum over the past 12 months -- and a similar\nindicator constructed with the vacancy rate -- the difference between the\n3-month trailing average of the vacancy rate and its maximum over the past 12\nmonths. We then propose a two-sided recession rule: When our indicator reaches\n0.3pp, a recession may have started; when the indicator reaches 0.8pp, a\nrecession has started for sure. This new rule is triggered earlier than the\nSahm rule: on average it detects recessions 1.4 months after they have started,\nwhile the Sahm rule detects them 2.6 months after their start. The new rule\nalso has a better historical track record: it perfectly identifies all\nrecessions since 1930, while the Sahm rule breaks down before 1960. With July\n2024 data, our indicator is at 0.5pp, so the probability that the US economy is\nnow in recession is 40%. In fact, the recession may have started as early as\nMarch 2024.\n"
    },
    {
        "paper_id": "2408.06048",
        "authors": "Katja Bergonzoli, Laurent Bieri, Dominic Rohner, Christian Zehnder",
        "title": "Hungry Professors? Decision Biases Are Less Widespread than Previously\n  Thought",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  In many situations people make sequences of similar, but unrelated decisions.\nSuch decision sequences are prevalent in many important contexts including\njudicial judgments, loan approvals, college admissions, and athletic\ncompetitions. A growing literature claims that decisions in such sequences may\nbe severely biased because decision outcomes seem to be systematically affected\nby the scheduling. In particular, it has been argued that mental depletion\nleads to harsher decisions before food breaks and that the ``law of small\nnumbers'' induces decisions to be negatively auto-correlated (i.e. favorable\ndecisions are followed by unfavorable ones and vice versa). These findings have\nattracted much academic and media attention and it has been suspected that they\nmay only represent the ``tip of the iceberg''. However, voices of caution point\nout that existing studies may suffer from serious limitations, because the\ndecision order is not randomly determined, other influencing factors are hard\nto exclude, or direct evidence for the underlying mechanisms is not available.\nWe exploit a large-scale natural experiment in a context in which the previous\nliterature would predict the presence of scheduling biases. Specifically, we\ninvestigate whether the grades of randomly scheduled oral exams in Law School\ndepend on the position of the exam in the sequence. Our rich data enables us to\nfilter-out student, professor, day, and course-specific features. Our results\ncontradict the previous findings and suggest that caution is advised when\ngeneralizing from previous studies for policy advice.\n"
    },
    {
        "paper_id": "2408.06168",
        "authors": "Aleksandar Arandjelovi\\'c and Julia Eisenberg",
        "title": "Reinsurance with neural networks",
        "comments": "18 pages with 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider an insurance company which faces financial risk in the form of\ninsurance claims and market-dependent surplus fluctuations. The company aims to\nsimultaneously control its terminal wealth (e.g. at the end of an accounting\nperiod) and the ruin probability in a finite time interval by purchasing\nreinsurance. The target functional is given by the expected utility of terminal\nwealth perturbed by a modified Gerber-Shiu penalty function. We solve the\nproblem of finding the optimal reinsurance strategy and the corresponding\nmaximal target functional via neural networks. The procedure is illustrated by\na numerical example, where the surplus process is given by a Cram\\'er-Lundberg\nmodel perturbed by a mean-reverting Ornstein-Uhlenbeck process.\n"
    },
    {
        "paper_id": "2408.06361",
        "authors": "Han Ding, Yinheng Li, Junhao Wang, Hang Chen",
        "title": "Large Language Model Agent in Financial Trading: A Survey",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Trading is a highly competitive task that requires a combination of strategy,\nknowledge, and psychological fortitude. With the recent success of large\nlanguage models(LLMs), it is appealing to apply the emerging intelligence of\nLLM agents in this competitive arena and understanding if they can outperform\nprofessional traders. In this survey, we provide a comprehensive review of the\ncurrent research on using LLMs as agents in financial trading. We summarize the\ncommon architecture used in the agent, the data inputs, and the performance of\nLLM trading agents in backtesting as well as the challenges presented in these\nresearch. This survey aims to provide insights into the current state of\nLLM-based financial trading agents and outline future research directions in\nthis field.\n"
    },
    {
        "paper_id": "2408.06433",
        "authors": "Revant Nayar, Minhajul Islam",
        "title": "Endogenous Crashes as Phase Transitions",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper explores the mechanisms behind extreme financial events,\nspecifically market crashes, by employing the theoretical framework of phase\ntransitions. We focus on endogenous crashes, driven by internal market\ndynamics, and model these events as first-order phase transitions critical,\nstochastic, and dynamic. Through a comparative analysis of early warning\nsignals associated with each type of transition, we demonstrate that dynamic\nphase transitions (DPT) offer a more accurate representation of market crashes\nthan critical (CPT) or stochastic phase transitions (SPT). Unlike existing\nmodels, such as the Log-Periodic Power Law (LPPL) model, which often suffers\nfrom overfitting and false positives, our approach grounded in DPT provides a\nmore robust prediction framework. Empirical findings, based on an analysis of\nS&P 500 stocks from 2019 to 2024, reveal significant trends in volatility and\nanomalous dimensions before crashes, supporting the superiority of the DPT\nmodel. This work contributes to a deeper understanding of the predictive\nsignals preceding market crashes and offers a novel perspective on their\nunderlying dynamics.\n"
    },
    {
        "paper_id": "2408.06497",
        "authors": "Nicola Borri, Yukun Liu, Aleh Tsyvinski, Xi Wu",
        "title": "Inefficiencies of Carbon Trading Markets",
        "comments": "17 pages, 3 figures, 2 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  The European Union Emission Trading System is a prominent market-based\nmechanism to reduce emissions. While the theory is well understood, we are the\nfirst to study the whole cap-and-trade mechanism as a financial market.\nAnalyzing the universe of transactions in 2005-2020 (more than one million\nrecords of granular transaction data), we show that this market features\nsignificant inefficiencies undermining its goals. First, about 40% of firms\nnever trade in a given year. Second, many firms only trade during surrendering\nmonths, when compliance is immediate and prices are predictably high. Third, a\nnumber of operators engage in speculative trading, exploiting private\ninformation.\n"
    },
    {
        "paper_id": "2408.06531",
        "authors": "St\\'ephane Cr\\'epey, Noufel Frikha, Azar Louzi, Jonathan Spence",
        "title": "Adaptive Multilevel Stochastic Approximation of the Value-at-Risk",
        "comments": "43 pages, 6 tables, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Cr\\'epey, Frikha, and Louzi (2023) introduced a multilevel stochastic\napproximation scheme to compute the value-at-risk of a financial loss that is\nonly simulatable by Monte Carlo. The optimal complexity of the scheme is in\n$O({\\varepsilon}^{-5/2})$, ${\\varepsilon} > 0$ being a prescribed accuracy,\nwhich is suboptimal when compared to the canonical multilevel Monte Carlo\nperformance. This suboptimality stems from the discontinuity of the Heaviside\nfunction involved in the biased stochastic gradient that is recursively\nevaluated to derive the value-at-risk. To mitigate this issue, this paper\nproposes and analyzes a multilevel stochastic approximation algorithm that\nadaptively selects the number of inner samples at each level, and proves that\nits optimal complexity is in $O({\\varepsilon}^{-2}|\\ln {\\varepsilon}|^{5/2})$.\nOur theoretical analysis is exemplified through numerical experiments.\n"
    },
    {
        "paper_id": "2408.06634",
        "authors": "Haowei Ni and Shuchen Meng and Xupeng Chen and Ziqing Zhao and Andi\n  Chen and Panfeng Li and Shiyao Zhang and Qifu Yin and Yuanqing Wang and Yuxi\n  Chan",
        "title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM\n  Approach",
        "comments": "Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.\n"
    },
    {
        "paper_id": "2408.06661",
        "authors": "Junshu Jiang, Jordan Richards, Rapha\\\"el Huser, David Bolin",
        "title": "The Efficient Tail Hypothesis: An Extreme Value Perspective on Market\n  Efficiency",
        "comments": "56 pages, 9 figures, 3 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  In econometrics, the Efficient Market Hypothesis posits that asset prices\nreflect all available information in the market. Several empirical\ninvestigations show that market efficiency drops when it undergoes extreme\nevents. Many models for multivariate extremes focus on positive dependence,\nmaking them unsuitable for studying extremal dependence in financial markets\nwhere data often exhibit both positive and negative extremal dependence. To\nthis end, we construct regular variation models on the entirety of\n$\\mathbb{R}^d$ and develop a bivariate measure for asymmetry in the strength of\nextremal dependence between adjacent orthants. Our directional tail dependence\n(DTD) measure allows us to define the Efficient Tail Hypothesis (ETH) -- an\nanalogue of the Efficient Market Hypothesis -- for the extremal behaviour of\nthe market. Asymptotic results for estimators of DTD are described, and we\ndiscuss testing of the ETH via permutation-based methods and present novel\ntools for visualization. Empirical study of China's futures market leads to a\nrejection of the ETH and we identify potential profitable investment\nopportunities. To promote the research of microstructure in China's derivatives\nmarket, we open-source our high-frequency data, which are being collected\ncontinuously from multiple derivative exchanges.\n"
    },
    {
        "paper_id": "2408.06679",
        "authors": "Gregory Yampolsky, Dhruv Desai, Mingshu Li, Stefano Pasquali, Dhagash\n  Mehta",
        "title": "Case-based Explainability for Random Forest: Prototypes, Critics,\n  Counter-factuals and Semi-factuals",
        "comments": "8 pages, 2 figures, 5 tables",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  The explainability of black-box machine learning algorithms, commonly known\nas Explainable Artificial Intelligence (XAI), has become crucial for financial\nand other regulated industrial applications due to regulatory requirements and\nthe need for transparency in business practices. Among the various paradigms of\nXAI, Explainable Case-Based Reasoning (XCBR) stands out as a pragmatic approach\nthat elucidates the output of a model by referencing actual examples from the\ndata used to train or test the model. Despite its potential, XCBR has been\nrelatively underexplored for many algorithms such as tree-based models until\nrecently. We start by observing that most XCBR methods are defined based on the\ndistance metric learned by the algorithm. By utilizing a recently proposed\ntechnique to extract the distance metric learned by Random Forests (RFs), which\nis both geometry- and accuracy-preserving, we investigate various XCBR methods.\nThese methods amount to identify special points from the training datasets,\nsuch as prototypes, critics, counter-factuals, and semi-factuals, to explain\nthe predictions for a given query of the RF. We evaluate these special points\nusing various evaluation metrics to assess their explanatory power and\neffectiveness.\n"
    },
    {
        "paper_id": "2408.07227",
        "authors": "Brian Zhu",
        "title": "Stablecoin Runs and Disclosure Policy in the Presence of Large Sales",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Stablecoins have historically depegged due from par to large sales, possibly\nof speculative nature, or poor reserve asset quality. Using a global game which\naddresses both concerns, we show that the selling pressure on stablecoin\nholders increases in the presence of a large sale. While precise public\nknowledge reduces (increases) the probability of a run when fundamentals are\nstrong (weak), interestingly, more precise private signals increase (reduce)\nthe probability of a run when fundamentals are strong (weak), potentially\nexplaining the stability of opaque stablecoins. The total run probability can\nbe decomposed into components representing risks from large sales and poor\ncollateral. By analyzing how these risk components vary with respect to\ninformation uncertainty and fundamentals, we can split the fundamental space\ninto regions based on the type of risk a stablecoin issuer is more prone to. We\nsuggest testable implications and connect our model's implications to\nreal-world applications, including depegging events and the no-questions-asked\nproperty of money.\n"
    },
    {
        "paper_id": "2408.07271",
        "authors": "Ravi Kashyap",
        "title": "The Concentration Risk Indicator: Raising the Bar for Financial\n  Stability and Portfolio Performance Measurement",
        "comments": "arXiv admin note: text overlap with arXiv:2302.06348",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We have developed a novel risk management measure called the concentration\nrisk indicator (CRI). The CRI has been created to address drawbacks with\nprevailing methodologies and to supplement existing methods. Modified and\nadapted from the Herfindahl-Hirschman (HH) index, the CRI can give a single\nnumeric score that can be helpful to evaluate the extent of risks that arise\nfrom holding concentrated portfolios. We discuss how the CRI can become an\nindicator of financial stability at any desired aggregation unit: regional,\nnational or international level. We show how the CRI can be easily applied to\ninsurance risk and to any product portfolio mix. The CRI is particularly\napplicable to the current facet of the decentralized terrain, wherein the\nmajority of the wealth is restricted to a small number of tokens. We calculate\nand report the CRI -- along with other risk metrics -- for individual assets\nand portfolios of crypto assets using a daily data sample from January 01, 2019\nuntil August 10, 2022. The CRI is an example of developing metrics that can\nuseful for sending concise yet powerful messages to the relevant audience. This\ntactic -- which can be described as marketing the benefits of any product or\nservice by using concepts from multiple disciplines -- of creating new metrics\ngoes further beyond the use of metrics to evaluate marketing efficacy. The\nsimplicity of our metric -- and the intuitive explanations we have provided for\nthe CRI -- makes it straightforward to properly articulate a strong -- clear\nand positive -- signal as part of marketing campaigns. The development -- and\nimplementation -- of new risk management metrics will have greater impact when\na wider rigorous risk management process has been established. We discuss\nseveral topics related to bringing about more improved risk management across\nall types of institutions and assets.\n"
    },
    {
        "paper_id": "2408.07405",
        "authors": "Ajay Jasra, Mohamed Maama, Aleksandar Mijatovi\\'c",
        "title": "Modeling of Measurement Error in Financial Returns Data",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  In this paper we consider the modeling of measurement error for fund returns\ndata. In particular, given access to a time-series of discretely observed\nlog-returns and the associated maximum over the observation period, we develop\na stochastic model which models the true log-returns and maximum via a L\\'evy\nprocess and the data as a measurement error there-of. The main technical\ndifficulty of trying to infer this model, for instance Bayesian parameter\nestimation, is that the joint transition density of the return and maximum is\nseldom known, nor can it be simulated exactly. Based upon the novel stick\nbreaking representation of [12] we provide an approximation of the model. We\ndevelop a Markov chain Monte Carlo (MCMC) algorithm to sample from the Bayesian\nposterior of the approximated posterior and then extend this to a multilevel\nMCMC method which can reduce the computational cost to approximate posterior\nexpectations, relative to ordinary MCMC. We implement our methodology on\nseveral applications including for real data.\n"
    },
    {
        "paper_id": "2408.07432",
        "authors": "Claudia Ceci and Katia Colaneri",
        "title": "Portfolio and reinsurance optimization under unknown market price of\n  risk",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We investigate the optimal investment-reinsurance problem for insurance\ncompany with partial information on the market price of the risk. Through the\nuse of filtering techniques we convert the original optimization problem\ninvolving different filtrations, into an equivalent stochastic control problem\nunder the observation filtration only, the so-called separated problem. The\nMarkovian structure of the separated problem allows us to apply a classical\napproach to stochastic optimization based on the Hamilton-Jacobi-Bellman\nequation, and to provide explicit formulas for the value function and the\noptimal investment-reinsurance strategy. We finally discuss some comparisons\nbetween the optimal strategies pursued by a partially informed insurer and that\nfollowed by a fully informed insurer, and we evaluate the value of information\nusing the idea of indifference pricing. These results are also supported by\nnumerical experiments.\n"
    },
    {
        "paper_id": "2408.07497",
        "authors": "Jozef Barunik and Martin Hronec and Ondrej Tobek",
        "title": "Predicting the distributions of stock returns around the globe in the\n  era of big data and learning",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  This paper presents a method for accurately predicting the full distribution\nof stock returns, given a comprehensive set of 194 stock characteristics and\nmarket variables. Such distributions, learned from rich data using a machine\nlearning algorithm, are not constrained by restrictive model assumptions and\nallow the exploration of non-Gaussian, heavy-tailed data and their non-linear\ninteractions. The method uses a two-stage quantile neural network combined with\nspline interpolation. The results show that the proposed approach outperforms\nalternative models in terms of out-of-sample losses. Furthermore, we show that\nthe moments derived from such distributions can be useful as alternative\nempirical estimates in many cases, including mean estimation and forecasting.\nFinally, we examine the relationship between cross-sectional returns and\nseveral distributional characteristics. The results are robust to a wide range\nof US and international data.\n"
    },
    {
        "paper_id": "2408.07653",
        "authors": "Wei-Ru Chen, A. Christian Silva and Shen-Ning Tung",
        "title": "Stylized facts in Web3",
        "comments": "39 pages, 30 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  This paper presents a comprehensive statistical analysis of the Web3\necosystem, comparing various Web3 tokens with traditional financial assets\nacross multiple time scales. We examine probability distributions, tail\nbehaviors, and other key stylized facts of the returns for a diverse range of\ntokens, including decentralized exchanges, liquidity pools, and centralized\nexchanges. Despite functional differences, most tokens exhibit well-established\nempirical facts, including unconditional probability density of returns with\nheavy tails gradually becoming Gaussian and volatility clustering. Furthermore,\nwe compare assets traded on centralized (CEX) and decentralized (DEX)\nexchanges, finding that DEXs exhibit similar stylized facts despite different\ntrading mechanisms and often divergent long-term performance. We propose that\nthis similarity is attributable to arbitrageurs striving to maintain similar\ncentralized and decentralized prices. Our study contributes to a better\nunderstanding of the dynamics of Web3 tokens and the relationship between CEX\nand DEX markets, with important implications for risk management, pricing\nmodels, and portfolio construction in the rapidly evolving DeFi landscape.\nThese results add to the growing body of literature on cryptocurrency markets\nand provide insights that can guide the development of more accurate models for\nDeFi markets.\n"
    },
    {
        "paper_id": "2408.07710",
        "authors": "Bent Flyvbjerg, Alexander Budzier, M. D. Christodoulou, M. Zottoli",
        "title": "Uniqueness Bias: Why It Matters, How to Curb It",
        "comments": "30 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "abstract": "  The paper explores \"uniqueness bias,\" a behavioral bias defined as the\ntendency of planners and managers to see their decisions as singular. For the\nfirst time, uniqueness bias is correlated with forecasting accuracy and\nperformance in real-world project investment decisions. We problematize the\nconventional framing of projects as unique and hypothesize that it leads to\npoor project performance. We test the thesis for a sample of 219 projects and\nfind that perceived uniqueness is indeed highly statistically significantly\nassociated with underperformance. Finally, we identify how decision makers can\nmitigate uniqueness bias in their projects through what Daniel Kahneman aptly\ncalled \"decision hygiene,\" specifically reference class forecasting,\npremortems, similarity-based forecasting, and noise audits.\n"
    },
    {
        "paper_id": "2408.07865",
        "authors": "Jian-Qiao Zhu, Joshua C. Peterson, Benjamin Enke, Thomas L. Griffiths",
        "title": "Capturing the Complexity of Human Strategic Decision-Making with Machine\n  Learning",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  Understanding how people behave in strategic settings--where they make\ndecisions based on their expectations about the behavior of others--is a\nlong-standing problem in the behavioral sciences. We conduct the largest study\nto date of strategic decision-making in the context of initial play in\ntwo-player matrix games, analyzing over 90,000 human decisions across more than\n2,400 procedurally generated games that span a much wider space than previous\ndatasets. We show that a deep neural network trained on these data predicts\npeople's choices better than leading theories of strategic behavior, indicating\nthat there is systematic variation that is not explained by those theories. We\nthen modify the network to produce a new, interpretable behavioral model,\nrevealing what the original network learned about people: their ability to\noptimally respond and their capacity to reason about others are dependent on\nthe complexity of individual games. This context-dependence is critical in\nexplaining deviations from the rational Nash equilibrium, response times, and\nuncertainty in strategic decisions. More broadly, our results demonstrate how\nmachine learning can be applied beyond prediction to further help generate\nnovel explanations of complex human behavior.\n"
    },
    {
        "paper_id": "2408.07879",
        "authors": "Chung-Han Hsieh and Jie-Ling Lu",
        "title": "On Accelerating Large-Scale Robust Portfolio Optimization",
        "comments": "Submitted to possible publication",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Solving large-scale robust portfolio optimization problems is challenging due\nto the high computational demands associated with an increasing number of\nassets, the amount of data considered, and market uncertainty. To address this\nissue, we propose an extended supporting hyperplane approximation approach for\nefficiently solving a class of distributionally robust portfolio problems for a\ngeneral class of additively separable utility functions and polyhedral\nambiguity distribution set, applied to a large-scale set of assets. Our\ntechnique is validated using a large-scale portfolio of the S&P 500 index\nconstituents, demonstrating robust out-of-sample trading performance. More\nimportantly, our empirical studies show that this approach significantly\nreduces computational time compared to traditional concave Expected Log-Growth\n(ELG) optimization, with running times decreasing from several thousand seconds\nto just a few. This method provides a scalable and practical solution to\nlarge-scale robust portfolio optimization, addressing both theoretical and\npractical challenges.\n"
    },
    {
        "paper_id": "2408.07923",
        "authors": "Zachary Wojtowicz",
        "title": "When and Why is Persuasion Hard? A Computational Complexity Result",
        "comments": "5 pages",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  As generative foundation models improve, they also tend to become more\npersuasive, raising concerns that AI automation will enable governments, firms,\nand other actors to manipulate beliefs with unprecedented scale and\neffectiveness at virtually no cost. The full economic and social ramifications\nof this trend have been difficult to foresee, however, given that we currently\nlack a complete theoretical understanding of why persuasion is costly for human\nlabor to produce in the first place. This paper places human and AI agents on a\ncommon conceptual footing by formalizing informational persuasion as a\nmathematical decision problem and characterizing its computational complexity.\nA novel proof establishes that persuasive messages are challenging to discover\n(NP-Hard) but easy to adopt if supplied by others (NP). This asymmetry helps\nexplain why people are susceptible to persuasion, even in contexts where all\nrelevant information is publicly available. The result also illuminates why\nlitigation, strategic communication, and other persuasion-oriented activities\nhave historically been so human capital intensive, and it provides a new\ntheoretical basis for studying how AI will impact various industries.\n"
    },
    {
        "paper_id": "2408.07969",
        "authors": "Yu Li, Yuhan Wu, and Shuhua Zhang",
        "title": "The mean-variance portfolio selection based on the average and current\n  profitability of the risky asset",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We study the continuous-time pre-commitment mean-variance portfolio selection\nin a time-varying financial market. By introducing two indexes which\nrespectively express the average profitability of the risky asset (AP) and the\ncurrent profitability of the risky asset (CP), the optimal portfolio selection\nis represented by AP and CP. Furthermore, instead of the traditional maximum\nlikelihood estimation (MLE) of return rate and volatility of the risky asset,\nwe estimate AP and CP with the second-order variation of an auxiliary wealth\nprocess. We prove that the estimations of AP and CP in this paper are more\naccurate than that in MLE. And, the portfolio selection is implemented in\nvarious simulated and real financial markets. Numerical studies confirm the\nsuperior performance of our portfolio selection with the estimation of AP and\nCP under various evaluation criteria.\n"
    },
    {
        "paper_id": "cond-mat/0001117",
        "authors": "Karl Strobl",
        "title": "On the Consistency of the Deterministic Local Volatility Function Model\n  ('implied tree')",
        "comments": "LaTeX, 28 pages, no figures. submitted to Intl. J. of Theor. and\n  Appl. Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We show that the frequent claim that the implied tree prices exotic options\nconsistently with the market is untrue if the local volatilities are subject to\nchange and the market is arbitrage-free. In the process, we analyse -- in the\nmost general context -- the impact of stochastic variables on the P&L of a\nhedged portfolio, and we conclude that no model can a priori be expected to\nprice all exotics in line with the vanilla options market. Calibration of an\nassumed underlying process from vanilla options alone must not be overly\nrestrictive, yet still unique, and relevant to all exotic options of interest.\nFor the implied tree we show that the calibration to real-world prices allows\nus to only price vanilla options themselves correctly. This is usually\nattributed to the incompleteness of the market under traditional stochastic\n(local) volatility models. We show that some `weakly' stochastic volatility\nmodels without quadratic variation of the volatilities avoid the incompleteness\nproblems, but they introduce arbitrage. More generally, we find that any\nstochastic tradable either has quadratic variation -- and therefore a\n$\\Ga$-like P&L on instruments with non-linear exposure to that asset -- or it\nintroduces arbitrage opportunities.\n"
    },
    {
        "paper_id": "cond-mat/0001120",
        "authors": "Enrico Scalas, Rudolf Gorenflo and Francesco Mainardi",
        "title": "Fractional calculus and continuous-time finance",
        "comments": "11 pages, no figures, LaTeX2e, submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(00)00255-7",
        "license": null,
        "abstract": "  In this paper we present a rather general phenomenological theory of\ntick-by-tick dynamics in financial markets. Many well-known aspects, such as\nthe L\\'evy scaling form, follow as particular cases of the theory. The theory\nfully takes into account the non-Markovian and non-local character of financial\ntime series. Predictions on the long-time behaviour of the waiting-time\nprobability density are presented. Finally, a general scaling form is given,\nbased on the solution of the fractional diffusion equation.\n"
    },
    {
        "paper_id": "cond-mat/0001253",
        "authors": "M. Raberto, G. Cuniberti, E. Scalas, M. Riani, F. Mainardi, G. Servizi",
        "title": "Learning short-option valuation in the presence of rare events",
        "comments": "details and related works in http://www.econophysics.org",
        "journal-ref": "International Journal of Theoretical and Applied Finance 3,\n  563-564 (2000)",
        "doi": "10.1142/S0219024900000590",
        "license": null,
        "abstract": "  We present a neural-network valuation of financial derivatives in the case of\nfat-tailed underlying asset returns. A two-layer perceptron is trained on\nsimulated prices taking into account the well-known effect of volatility smile.\nThe prices of the underlier are generated using fractional calculus algorithms,\nand option prices are computed by means of the Bouchaud-Potters formula. This\nlearning scheme is tested on market data; the results show a very good\nagreement between perceptron option prices and real market ones.\n"
    },
    {
        "paper_id": "cond-mat/0001268",
        "authors": "Giovanni Bonanno, Nicolas Vandewalle and Rosario N. Mantegna",
        "title": "Taxonomy of Stock Market Indices",
        "comments": "5 pages, 2 figures (4 panels), Revised version Aug 2000",
        "journal-ref": "Physical Review E, 62, Dec 2000, R7615-R7618",
        "doi": "10.1103/PhysRevE.62.R7615",
        "license": null,
        "abstract": "  We investigate sets of financial non-redundant and nonsynchronously recorded\ntime series. The sets are composed by a number of stock market indices located\nall over the world in five continents. By properly selecting the time horizon\nof returns and by using a reference currency we find a meaningful taxonomy. The\ndetection of such a taxonomy proves that interpretable information can be\nstored in a set of nonsynchronously recorded time series.\n"
    },
    {
        "paper_id": "cond-mat/0001293",
        "authors": "N.Vandewalle, Ph.Boveroux and F.Brisbois",
        "title": "Domino effect for world market fluctuations",
        "comments": "8 pages, 5 figures, submitted to EPJB",
        "journal-ref": null,
        "doi": "10.1007/s100510051158",
        "license": null,
        "abstract": "  In order to emphasize cross-correlations for fluctuations in major market\nplaces, series of up and down spins are built from financial data. Patterns\nfrequencies are measured, and statistical tests performed. Strong\ncross-correlations are emphasized, proving that market moves are collective\nbehaviors.\n"
    },
    {
        "paper_id": "cond-mat/0001324",
        "authors": "D. Sornette (UCLA and CNRS-University of Nice) and J.V. Andersen\n  (University of Nice)",
        "title": "Increments of Uncorrelated Time Series Can Be Predicted With a Universal\n  75% Probability of Success",
        "comments": "8 pages, 3 figures",
        "journal-ref": "Int. J. Mod. Phys. C Vol. 11 (4), 713-720 (2000)",
        "doi": "10.1142/S0129183100000626",
        "license": null,
        "abstract": "  We present a simple and general result that the sign of the variations or\nincrements of uncorrelated times series are predictable with a remarkably high\nsuccess probability of 75% for symmetric sign distributions. The origin of this\nparadoxical result is explained in details. We also present some tests on\nsynthetic, financial and global temperature time series.\n"
    },
    {
        "paper_id": "cond-mat/0001353",
        "authors": "B.M. Roehner (University Paris Jussieu) and D. Sornette (UCLA and\n  CNRS-University of Nice)",
        "title": "\"Thermometers\" of Speculative Frenzy",
        "comments": "15 pages + 10 figures",
        "journal-ref": "European Physical Journal B 16, 729-739 (2000)",
        "doi": "10.1007/s100510070190",
        "license": null,
        "abstract": "  Establishing unambiguously the existence of speculative bubbles is an\non-going controversy complicated by the need of defining a model of fundamental\nprices. Here, we present a novel empirical method which bypasses all the\ndifficulties of the previous approaches by monitoring external indicators of an\nanomalously growing interest in the public at times of bubbles. From the\ndefinition of a bubble as a self-fulfilling reinforcing price change, we\nidentify indicators of a possible self-reinforcing imitation between agents in\nthe market. We show that during the build-up phase of a bubble, there is a\ngrowing interest in the public for the commodity in question, whether it\nconsists in stocks, diamonds or coins. That interest can be estimated through\ndifferent indicators: increase in the number of books published on the topic,\nincrease in the subscriptions to specialized journals. Moreover, the well-known\nempirical rule according to which the volume of sales is growing during a bull\nmarket finds a natural interpretation in this framework: sales increases in\nfact reveal and pinpoint the progress of the bubble's diffusion throughout\nsociety. We also present a simple model of rational expectation which maps\nexactly onto the Ising model on a random graph. The indicators are then\ninterpreted as ``thermometers'', measuring the balance between idiosyncratic\ninformation (noise temperature) and imitation (coupling) strength. In this\ncontext, bubbles are interpreted as low or critical temperature phases, where\nthe imitation strength carries market prices up essentially independently of\nfundamentals. Contrary to the naive conception of a bubble and a crash as times\nof disorder, on the contrary, we show that bubbles and crashes are times where\nthe concensus is too strong.\n"
    },
    {
        "paper_id": "cond-mat/0001432",
        "authors": "Adrian Dragulescu and Victor M. Yakovenko",
        "title": "Statistical mechanics of money",
        "comments": "7 pages, 5 figures, RevTeX. V.4: final version accepted to Eur. Phys.\n  J. B: few stylistic revisions and additional references",
        "journal-ref": "Eur. Phys. J. B 17, 723 (2000)",
        "doi": "10.1007/s100510070114",
        "license": null,
        "abstract": "  In a closed economic system, money is conserved. Thus, by analogy with\nenergy, the equilibrium probability distribution of money must follow the\nexponential Gibbs law characterized by an effective temperature equal to the\naverage amount of money per economic agent. We demonstrate how the Gibbs\ndistribution emerges in computer simulations of economic models. Then we\nconsider a thermal machine, in which the difference of temperatures allows one\nto extract a monetary profit. We also discuss the role of debt, and models with\nbroken time-reversal symmetry for which the Gibbs law does not hold.\n"
    },
    {
        "paper_id": "cond-mat/0001434",
        "authors": "D. Sornette (UCLA and CNRS-University of Nice)",
        "title": "Economy of scales in R&D with block-busters",
        "comments": "10 pages",
        "journal-ref": "Quantitative Finance 2, 224--227 (2002)",
        "doi": null,
        "license": null,
        "abstract": "  Are large scale research programs that include many projects more productive\nthan smaller ones with fewer projects? This problem of economy of scale is\nparticularly relevant for understanding recent mergers in particular in the\npharmaceutical industry. We present a quantitative theory based on the\ncharacterization of distributions of discounted sales S resulting from new\nproducts. Assuming that these complementary cumulative distributions have fat\ntails with approximate power law structure S^{-a}, we demonstrate that economy\nof scales are automatically realized when the exponent a is less than one.\nEmpirical evidence suggests that the exponent a is approximately equal to 2/3\nfor the pharmaceutical industry.\n"
    },
    {
        "paper_id": "cond-mat/0002331",
        "authors": "Ricardo Mansilla",
        "title": "From naive to sophisticated behavior in multiagents based financial\n  market models",
        "comments": "16 pages, 4 figures, submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(00)00227-2",
        "license": null,
        "abstract": "  We discuss the behavior of two magnitudes, physical complexity and mutual\ninformation function of the outcome of a model of heterogeneous, inductive\nrational agents inspired in the El Farol Bar problem and the Minority Game. The\nfirst is a measure rooted in Kolmogorov-Chaitin theory and the second one a\nmeasure related with information entropy of Shannon.\n  We make extensive computer simulations, as result of which, we propose an\nansatz for physical complexity and establish the dependence of exponent of that\nansatz from the parameters of the model. We discuss the accuracy of our results\nand the relationship with the behavior of mutual information function as a\nmeasure of time correlations of agents choice.\n"
    },
    {
        "paper_id": "cond-mat/0002438",
        "authors": "Fabrizio Lillo and Rosario N. Mantegna",
        "title": "Symmetry alteration of ensemble return distribution in crash and rally\n  days of financial markets",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1007/s100510051162",
        "license": null,
        "abstract": "  We select the $n$ stocks traded in the New York Stock Exchange and we form a\nstatistical ensemble of daily stock returns for each of the $k$ trading days of\nour database from the stock price time series. We study the ensemble return\ndistribution for each trading day and we find that the symmetry properties of\nthe ensemble return distribution drastically change in crash and rally days of\nthe market. We compare these empirical results with numerical simulations based\non the single-index model and we conclude that this model is unable to explain\nthe behavior of the market in extreme days.\n"
    },
    {
        "paper_id": "cond-mat/0003025",
        "authors": "M. Bernaschi, L. Grilli, L. Marangio, S. Succi, D. Vergni",
        "title": "Statistical characterization of the fixed income market efficiency",
        "comments": "10 pages, 4 .eps figures, uses elsart.cls(sty)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present cross and time series analysis of price fluctuations in the U.S.\nTreasury fixed income market. By means of techniques borrowed from statistical\nphysics we show that the correlation among bonds depends strongly on the\nmaturity and bonds' price increments do not fulfill the random walk hyphoteses.\n"
    },
    {
        "paper_id": "cond-mat/0003357",
        "authors": "Jaume Masoliver, Miquel Montero and Josep M. Porra",
        "title": "A dynamical model describing stock market price distributions",
        "comments": "11 pages, 2 eps figures, elsart, to be published in Physica A",
        "journal-ref": "Physica A 283 (2000) 559-567",
        "doi": "10.1016/S0378-4371(00)00117-5",
        "license": null,
        "abstract": "  High frequency data in finance have led to a deeper understanding on\nprobability distributions of market prices. Several facts seem to be well\nstablished by empirical evidence. Specifically, probability distributions have\nthe following properties: (i) They are not Gaussian and their center is well\nadjusted by Levy distributions. (ii) They are long-tailed but have finite\nmoments of any order. (iii) They are self-similar on many time scales. Finally,\n(iv) at small time scales, price volatility follows a non-diffusive behavior.\nWe extend Merton's ideas on speculative price formation and present a dynamical\nmodel resulting in a characteristic function that explains in a natural way all\nof the above features. The knowledge of such distribution opens a new and\nuseful way of quantifying financial risk. The results of the model agree -with\nhigh degree of accuracy- with empirical data taken from historical records of\nthe Standard & Poor's 500 cash index.\n"
    },
    {
        "paper_id": "cond-mat/0004001",
        "authors": "D. Sornette (UCLA and CNRS-University of Nice)",
        "title": "Stock Market Speculation: Spontaneous Symmetry Breaking of Economic\n  Valuation",
        "comments": "23 pages, 10 figures",
        "journal-ref": "Physica A 284 (Nos. 104), 355-375 (2000)",
        "doi": "10.1016/S0378-4371(00)00261-2",
        "license": null,
        "abstract": "  Firm foundation theory estimates a security's firm fundamental value based on\nfour determinants: expected growth rate, expected dividend payout, the market\ninterest rate and the degree of risk. In contrast, other views of\ndecision-making in the stock market, using alternatives such as human\npsychology and behavior, bounded rationality, agent-based modeling and\nevolutionary game theory, expound that speculative and crowd behavior of\ninvestors may play a major role in shaping market prices. Here, we propose that\nthe two views refer to two classes of companies connected through a ``phase\ntransition''. Our theory is based on 1) the identification of the fundamental\nparity symmetry of prices ($p \\to -p$), which results from the relative\ndirection of payment flux compared to commodity flux and 2) the observation\nthat a company's risk-adjusted growth rate discounted by the market interest\nrate behaves as a control parameter for the observable price. We find a\ncritical value of this control parameter at which a spontaneous\nsymmetry-breaking of prices occurs, leading to a spontaneous valuation in\nabsence of earnings, similarly to the emergence of a spontaneous magnetization\nin Ising models in absence of a magnetic field. The low growth rate phase is\ndescribed by the firm foundation theory while the large growth rate phase is\nthe regime of speculation and crowd behavior. In practice, while large\n``finite-time horizon'' effects round off the predicted singularities, our\nsymmetry-breaking speculation theory accounts for the apparent over-pricing and\nthe high volatility of fast growing companies on the stock markets.\n"
    },
    {
        "paper_id": "cond-mat/0004179",
        "authors": "Wolfgang Breymann, Shoaleh Ghashghaie, and Peter Talkner",
        "title": "A Stochastic Cascade Model for FX Dynamics",
        "comments": "4 pages, 2 Postscript figures. Will be published in Int. J. Theoret.\n  Applied Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A time series model for the FX dynamics is presented which takes into account\nstructural peculiarities of the market, namely its heterogeneity and an\ninformation flow from long to short time horizons. The model emerges from an\nanalogy between FX dynamics and hydrodynamic turbulence. The heterogeneity of\nthe market is modeled in form of a multiplicative cascade of time scales\nranging from several minutes to a few months, analogous to the Kolmogorov\ncascade in turbulence.\n  The model reproduces well the important empirical characteristics of FX rates\nfor major currencies, as the heavy-tailed distribution of returns, their change\nin shape with increasing time interval, and the persistence of volatility.\n"
    },
    {
        "paper_id": "cond-mat/0004256",
        "authors": "Anirban Chakraborti and Bikas K. Chakrabarti",
        "title": "Statistical mechanics of money: How saving propensity affects its\n  distribution",
        "comments": "9 pages, 5 figures. Revised version with major changes in the text\n  and figures (to appear in Euro. Phys. Jour. B)",
        "journal-ref": "Eur. Phys. J. B 17, 167 (2000)",
        "doi": "10.1007/s100510070173",
        "license": null,
        "abstract": "  We consider a simple model of a closed economic system where the total money\nis conserved and the number of economic agents is fixed. In analogy to\nstatistical systems in equilibrium, money and the average money per economic\nagent are equivalent to energy and temperature, respectively. We investigate\nthe effect of the saving propensity of the agents on the stationary or\nequilibrium money distribution.The equilibrium probablity distribution of money\nbecomes the usual Gibb's distribution, characteristic of non-interacting\nagents, when the agents do not save. However with saving, even for local or\nindividual self-interest, the dynamics become cooperative and the resulting\nasymmetric Gaussian-like stationary distribution acquires global ordering\nproperties. Intriguing singularities are observed in the stationary money\ndistribution in the market, as function of the ``marginal saving propensity''\nof the agents.\n"
    },
    {
        "paper_id": "cond-mat/0004263",
        "authors": "Anders Johansen (UCLA) and Didier Sornette (UCLA, Univ. of Nice and\n  CNRS)",
        "title": "The Nasdaq crash of April 2000: Yet another example of log-periodicity\n  in a speculative bubble ending in a crash",
        "comments": "15 pages including 7 figures. Accepted in Eur. Phys. J. The revised\n  version contains significant parametric and non-parametric statistical tests\n  which establishes the outlier nature of the largest market events and\n  provides an objective definition of a crash",
        "journal-ref": "European Physical Journal B 17, 319-328 (2000).",
        "doi": "10.1007/s100510070147",
        "license": null,
        "abstract": "  The Nasdaq Composite fell another $\\approx 10 %$ on Friday the 14'th of April\n2000 signaling the end of a remarkable speculative high-tech bubble starting in\nspring 1997. The closing of the Nasdaq Composite at 3321 corresponds to a total\nloss of over 35% since its all-time high of 5133 on the 10'th of March 2000.\nSimilarities to the speculative bubble preceding the infamous crash of October\n1929 are quite striking: the belief in what was coined a ``New Economy'' both\nin 1929 and presently made share-prices of companies with three digits\nprice-earning ratios soar. Furthermore, we show that the largest draw downs of\nthe Nasdaq are outliers with a confidence level better than 99% and that these\ntwo speculative bubbles, as well as others, both nicely fit into the\nquantitative framework proposed by the authors in a series of recent papers.\n"
    },
    {
        "paper_id": "cond-mat/0004308",
        "authors": "D. Challet, M. Marsili and R. Zecchina",
        "title": "Comment on: Thermal model for Adaptive Competition in a Market",
        "comments": "Comment to cond-mat/9903415; PRL 83, 4429 (1999) by Cavagna et al.\n  Revised version with a modified figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We show that the dynamical equations describing the collective behavior of\nthe model introduced by Cavagna et al. i) are not their Eqs. (5,6) but rather\nii) are the same as those of the minority game (MG). As a consequence the\nanalytic solution of the MG presented in [PRL, 84, 1824 (2000)] holds also for\nthis model. Finally we show that iii) the the large temperature behavior of the\nmodel is different, due to small simulation times, from that discussed by\nCavagna et al.\n"
    },
    {
        "paper_id": "cond-mat/0004314",
        "authors": "Zhi-Feng Huang (Cologne University)",
        "title": "Self-organized model for information spread in financial markets",
        "comments": "8 pages with 7 EPS figures, LaTeX2e with EPJ class; Eur. Phys. J. B,\n  in press",
        "journal-ref": "Eur. Phys. J. B 16, 379-385 (2000)",
        "doi": "10.1007/s100510070240",
        "license": null,
        "abstract": "  A self-organized model with social percolation process is proposed to\ndescribe the propagations of information for different trading ways across a\nsocial system and the automatic formation of various groups within market\ntraders. Based on the market structure of this model, some stylized\nobservations of real market can be reproduced, including the slow decay of\nvolatility correlations, and the fat tail distribution of price returns which\nis found to cross over to an exponential-type asymptotic decay in different\ndimensional systems.\n"
    },
    {
        "paper_id": "cond-mat/0004376",
        "authors": "M. Marsili and D. Challet",
        "title": "Trading behavior and excess volatility in toy markets",
        "comments": "14 pages, 4 figures, minor changes",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the relation between the trading behavior of agents and volatility\nin toy markets of adaptive inductively rational agents. We show that excess\nvolatility, in such simplified markets, arises as a consequence of {\\em i)} the\nneglect of market impact implicit in price taking behavior and of {\\em ii)}\nexcessive reactivity of agents. These issues are dealt with in detail in the\nsimple case without public information. We also derive, for the general case,\nthe critical learning rate above which trading behavior leads to turbulent\ndynamics of the market.\n"
    },
    {
        "paper_id": "cond-mat/0005318",
        "authors": "Simon F. Norrelykke and Per Bak",
        "title": "Self-Organized Criticality in a Transient System",
        "comments": "4 pages (incl. 4 figures)",
        "journal-ref": "Phys. Rev. E 65, 036147 (2002)",
        "doi": "10.1103/PhysRevE.65.036147",
        "license": null,
        "abstract": "  A simple model economy with locally interacting producers and consumers is\nintroduced. When driven by extremal dynamics, the model self-organizes {\\em\nnot} to an attractor state, but to an asymptote, on which the economy has a\nconstant rate of deflation, is critical, and exhibits avalanches of activity\nwith power-law distributed sizes. This example demonstrates that self-organized\ncritical behavior occurs in a larger class of systems than so far considered:\nsystems not driven to an attractive fixed point, but, e.g., an asymptote, may\nalso display self-organized criticality.\n"
    },
    {
        "paper_id": "cond-mat/0005319",
        "authors": "Andrew Matacz (Science & Finance)",
        "title": "Path Dependent Option Pricing: the path integral partial averaging\n  method",
        "comments": "22 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper I develop a new computational method for pricing path dependent\noptions. Using the path integral representation of the option price, I show\nthat in general it is possible to perform analytically a partial averaging over\nthe underlying risk-neutral diffusion process. This result greatly eases the\ncomputational burden placed on the subsequent numerical evaluation. For\nshort-medium term options it leads to a general approximation formula that only\nrequires the evaluation of a one dimensional integral. I illustrate the\napplication of the method to Asian options and occupation time derivatives.\n"
    },
    {
        "paper_id": "cond-mat/0005416",
        "authors": "Sorin Solomon and Moshe Levy",
        "title": "Market Ecology, Pareto Wealth Distribution and Leptokurtic Returns in\n  Microscopic Simulation of the LLS Stock Market Model",
        "comments": "also available at:\n  http://shum.cc.huji.ac.il/~sorin/aix/aixfig.tar.gz. Proceedings of Complex\n  behavior in economics: Aix en Provence (Marseille), France, May 4-6,2000",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The LLS stock market model is a model of heterogeneous quasi-rational\ninvestors operating in a complex environment about which they have incomplete\ninformation. We review the main features of this model and several of its\nextensions. We study the effects of investor heterogeneity and show that\npredation, competition, or symbiosis may occur between different investor\npopulations. The dynamics of the LLS model lead to the empirically observed\nPareto wealth distribution. Many properties observed in actual markets appear\nas natural consequences of the LLS dynamics: truncated Levy distribution of\nshort-term returns, excess volatility, a return autocorrelation \"U-shape\"\npattern, and a positive correlation between volume and absolute returns.\n"
    },
    {
        "paper_id": "cond-mat/0005430",
        "authors": "M. Shatner, L. Muchnik, M. Leshno, S. Solomon",
        "title": "A Continuous Time Asynchronous Model of the Stock Market; Beyond the LLS\n  Model",
        "comments": "Talk at International Workshop \"Economic Dynamics from the Physics\n  Point of View\" Physikzentrum Bad Honnef, Germany, 27 - 30 March 2000; To\n  appear in Physica A",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In order to simulate the complex phenomena manifested in stock markets, we\nintroduce a continuous asynchronous model in which millions of individual\ntraders interact through a central orders matching mechanism, just as it\nhappens in real stock markets. Each trader has a unique decision function,\nwhich allows him/ her to trade at any time, to react to external news, to\nrespond to price changes (or volume, volatility, etc.), and to consider the\n\"fundamental price\". As a simple example we consider three \"generic\" decision\nfunctions, which correspond to three trader profiles: Noisy, Fundamentalist and\nChartist.\n"
    },
    {
        "paper_id": "cond-mat/0005441",
        "authors": "Ricardo Mansilla",
        "title": "Algorithmic Complexity of Real Financial Markets",
        "comments": "13 pages, 4 figures, submitted to European Physical Journal B",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00434-4",
        "license": null,
        "abstract": "  A new approach to the understanding of the complex behavior of financial\nmarkets index using tools from thermodynamics and statistical physics is\ndeveloped. Physical complexity, a magnitude rooted in the Kolmogorov-Chaitin\ntheory is applied to binary sequences built up from real time series of\nfinancial markets indices. The study is based on NASDAQ and Mexican IPC data.\nDifferent behaviors of this magnitude are shown when applied to the intervals\nof series placed before crashes and in intervals when no financial turbulence\nis observed. The connection between our results and The Efficient Market\nHypothesis is discussed.\n"
    },
    {
        "paper_id": "cond-mat/0006034",
        "authors": "Pierre Cizeau (1), Marc Potters (1) and Jean-Philippe Bouchaud (1,2)\n  ((1) Science & Finance, CFM (2) CEA Saclay)",
        "title": "Correlation structure of extreme stock returns",
        "comments": "Substantial rewriting. Added exceedance correlations, removed some\n  confusing material. To appear in Quantitative Finance",
        "journal-ref": "Quantitative Finance 1 217-222 (2001)",
        "doi": null,
        "license": null,
        "abstract": "  It is commonly believed that the correlations between stock returns increase\nin high volatility periods. We investigate how much of these correlations can\nbe explained within a simple non-Gaussian one-factor description with time\nindependent correlations. Using surrogate data with the true market return as\nthe dominant factor, we show that most of these correlations, measured by a\nvariety of different indicators, can be accounted for. In particular, this\none-factor model can explain the level and asymmetry of empirical exceedance\ncorrelations. However, more subtle effects require an extension of the one\nfactor model, where the variance and skewness of the residuals also depend on\nthe market return.\n"
    },
    {
        "paper_id": "cond-mat/0006038",
        "authors": "Hideaki Aoyama, Yuichi Nagahara, Mitsuhiro P. Okazaki, Wataru Souma,\n  Hideki Takayasu and Misako Takayasu",
        "title": "Pareto's Law for Income of Individuals and Debt of Bankrupt Companies",
        "comments": "11 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We analyze the distribution of income and income tax of individuals in Japan\nfor the fiscal year 1998. From the rank-size plots we find that the accumulated\nprobability distribution of both data obey a power law with a Pareto exponent\nvery close to -2. We also present an analysis of the distribution of the debts\nowed by bankrupt companies from 1997 to March, 2000, which is consistent with a\npower law behavior with a Pareto exponent equal to -1. This power law is the\nsame as that of the income distribution of companies. Possible implications of\nthese findings for model building are discussed.\n"
    },
    {
        "paper_id": "cond-mat/0006065",
        "authors": "Fabrizio Lillo and Rosario N. Mantegna",
        "title": "Variety and Volatility in Financial Markets",
        "comments": "10 pages, 11 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.62.6126",
        "license": null,
        "abstract": "  We study the price dynamics of stocks traded in a financial market by\nconsidering the statistical properties both of a single time series and of an\nensemble of stocks traded simultaneously. We use the $n$ stocks traded in the\nNew York Stock Exchange to form a statistical ensemble of daily stock returns.\nFor each trading day of our database, we study the ensemble return\ndistribution. We find that a typical ensemble return distribution exists in\nmost of the trading days with the exception of crash and rally days and of the\ndays subsequent to these extreme events. We analyze each ensemble return\ndistribution by extracting its first two central moments. We observe that these\nmoments are fluctuating in time and are stochastic processes themselves. We\ncharacterize the statistical properties of ensemble return distribution central\nmoments by investigating their probability density functions and temporal\ncorrelation properties. In general, time-averaged and portfolio-averaged price\nreturns have different statistical properties. We infer from these differences\ninformation about the relative strength of correlation between stocks and\nbetween different trading days. Lastly, we compare our empirical results with\nthose predicted by the single-index model and we conclude that this simple\nmodel is unable to explain the statistical properties of the second moment of\nthe ensemble return distribution.\n"
    },
    {
        "paper_id": "cond-mat/0006133",
        "authors": "Jiri Hoogland and Dimitri Neumann",
        "title": "Asians and cash dividends: Exploiting symmetries in pricing theory",
        "comments": "19 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this article we present new results for the pricing of arithmetic Asian\noptions within a Black-Scholes context. To derive these results we make\nextensive use of the local scale invariance that exists in the theory of\ncontingent claim pricing. This allows us to derive, in a natural way, a simple\nPDE for the price of arithmetic Asians options. In the case of European average\nstrike options, a proper choice of numeraire reduces the dimension of this PDE\nto one, leading to a PDE similar to the one derived by Rogers and Shi. We solve\nthis PDE, finding a Laplace-transform representation for the price of average\nstrike options, both seasoned and unseasoned. This extends the results of Geman\nand Yor, who discussed the case of average price options. Next we use symmetry\narguments to show that prices of average strike and average price options can\nbe expressed in terms of each other. Finally we show, again using symmetries,\nthat plain vanilla options on stocks paying known cash dividends are closely\nrelated to arithmetic Asians, so that all the new techniques can be directly\napplied to this case.\n"
    },
    {
        "paper_id": "cond-mat/0006145",
        "authors": "Zhi-Feng Huang (Cologne University)",
        "title": "The first 20 minutes in the Hong Kong stock market",
        "comments": "9 pages with 6 figures; Proceedings of international workshop on\n  \"Economic Dynamics from the Physics Point of View\", Physikzentrum Bad Honnef,\n  Germany, 27 - 30 March, and to appear in Physica A",
        "journal-ref": "Physica A 287, 405-411 (2000)",
        "doi": "10.1016/S0378-4371(00)00379-4",
        "license": null,
        "abstract": "  Based on the minute-by-minute data of the Hang Seng Index in Hong Kong and\nthe analysis of probability distribution and autocorrelations, we find that the\nindex fluctuations for the first few minutes of daily opening show behaviors\nvery different from those of the other times. In particular, the properties of\ntail distribution, which will show the power law scaling with exponent about -4\nor an exponential-type decay, the volatility, and its correlations depend on\nthe opening effect of each trading day.\n"
    },
    {
        "paper_id": "cond-mat/0006260",
        "authors": "Johannes Voit",
        "title": "The growth dynamics of German business firms",
        "comments": "15 pages, 12 figures, Latex, uses elsart.sty. To be published in\n  \"Discrete Dynamics in Nature and Society\", Proceedings of the WE-Heraeus\n  Workshop on Economic Dynamics from the Physics Point of View, Bad Honnef,\n  March 27-30, 2000",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We determine the distribution of size and growthrates of German business\nfirms in 1987-1997. We find a log-normal size distribution. The distribution of\ngrowth rates has fat tails. It can be fitted to an exponential in a narrow\ncentral region and is dominated by finite-sample-size effects far in its wings.\nWe study the dependence of the growth rate distribution on firm size: depending\non procedures, we find almost no dependence when the center of the distribution\nis considered or, similar to previous work, a power-law when the wings are\nweighted more strongly. Correlations in the growth of different firms are\nessentially random. We determine the annual growth of the entire economy, and\nsuccessfully correlate it with a standard economic indicator of business cycles\nin Germany. We emphasize possible problems related to the finite number of\nfirms comprised in our database and its short extension in time.\n"
    },
    {
        "paper_id": "cond-mat/0006454",
        "authors": "Francesco Mainardi (1), Marco Raberto (2), Rudolf Gorenflo (3), Enrico\n  Scalas (4) ((1) University of Bologna, (2) University of Genoa, (3) Free\n  University of Berlin, (4) University of East Piedmont)",
        "title": "Fractional calculus and continuous-time finance II: the waiting-time\n  distribution",
        "comments": "Revised version, 17 pages, 4 figures. Physica A, Vol. 287, No 3-4,\n  468--481 (2000). Proceedings of the International Workshop on \"Economic\n  Dynamics from the Physics Point of View\", Bad-Honnef (Germany), 27-30 March\n  2000",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(00)00386-1",
        "license": null,
        "abstract": "  We complement the theory of tick-by-tick dynamics of financial markets based\non a Continuous-Time Random Walk (CTRW) model recently proposed by Scalas et\nal., and we point out its consistency with the behaviour observed in the\nwaiting-time distribution for BUND future prices traded at LIFFE, London.\n"
    },
    {
        "paper_id": "cond-mat/0006463",
        "authors": "Filippo Castiglione",
        "title": "Diffusion and Aggregation in an Agent Based Model of Stock Market\n  Fluctuations",
        "comments": "17 pages, 8 figures (accepted for publication in Int. J. Mod. Phys.\n  C)",
        "journal-ref": null,
        "doi": "10.1142/S0129183100000754",
        "license": null,
        "abstract": "  We describe a new model to simulate the dynamic interactions between market\nprice and the decisions of two different kind of traders. They possess spatial\nmobility allowing to group together to form coalitions. Each coalition follows\na strategy chosen from a proportional voting ``dominated'' by a leader's\ndecision. The interplay of both kind of agents gives rise to complex price\ndynamics that is consistent with the main stylized facts of financial time\nseries.\n"
    },
    {
        "paper_id": "cond-mat/0007267",
        "authors": "Lei-Han Tang and Zhi-Feng Huang",
        "title": "Modelling High-frequency Economic Time Series",
        "comments": "To appear in Proceedings of the Dynamics Days Asia Pacific\n  Conference, 13-16 July, 1999, Hong Kong (Physica A, 2000)",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(00)00442-8",
        "license": null,
        "abstract": "  The minute-by-minute move of the Hang Seng Index (HSI) data over a four-year\nperiod is analysed and shown to possess similar statistical features as those\nof other markets. Based on a mathematical theorem [S. B. Pope and E. S. C.\nChing, Phys. Fluids A {\\bf 5}, 1529 (1993)], we derive an analytic form for the\nprobability distribution function (PDF) of index moves from fitted functional\nforms of certain conditional averages of the time series. Furthermore,\nfollowing a recent work by Stolovitzky and Ching, we show that the observed PDF\ncan be reproduced by a Langevin process with a move-dependent noise amplitude.\nThe form of the Langevin equation can be determined directly from the market\ndata.\n"
    },
    {
        "paper_id": "cond-mat/0007385",
        "authors": "Giulia Iori",
        "title": "Scaling and Multi-scaling in Financial Markets",
        "comments": "Paper presented at the Disordered and Complex Systems s conference,\n  King's College London, July 2000",
        "journal-ref": null,
        "doi": "10.1063/1.1358199",
        "license": null,
        "abstract": "  This paper reviews some of the phenomenological models which have been\nintroduced to incorporate the scaling properties of financial data. It also\nillustrates a microscopic model, based on heterogeneous interacting agents,\nwhich provides a possible explanation for the complex dynamics of markets'\nreturns. Scaling and multi-scaling analysis performed on the simulated data is\nin good quantitative agreement with the empirical results.\n"
    },
    {
        "paper_id": "cond-mat/0008026",
        "authors": "Zhi-Feng Huang, Sorin Solomon",
        "title": "Power, Levy, Exponential and Gaussian Regimes in Autocatalytic Financial\n  Systems",
        "comments": "9 pages with 5 figures; Proceedings of EPS conference \"Applications\n  of Physics in Financial Analysis 2\", 13 to 15 July 2000 Liege, Belgium (to\n  appear in Eur. Phys. J. B)",
        "journal-ref": "Eur. Phys. J. B 20 (2001) 601-607",
        "doi": "10.1007/PL00011114",
        "license": null,
        "abstract": "  We study by theoretical analysis and by direct numerical simulation the\ndynamics of a wide class of asynchronous stochastic systems composed of many\nautocatalytic degrees of freedom. We describe the generic emergence of\ntruncated power laws in the size distribution of their individual elements. The\nexponents $\\alpha$ of these power laws are time independent and depend only on\nthe way the elements with very small values are treated. These truncated power\nlaws determine the collective time evolution of the system. In particular the\nglobal stochastic fluctuations of the system differ from the normal Gaussian\nnoise according to the time and size scales at which these fluctuations are\nconsidered. We describe the ranges in which these fluctuations are\nparameterized respectively by: the Levy regime $\\alpha < 2$, the power law\ndecay with large exponent ($\\alpha > 2$), and the exponential decay. Finally we\nrelate these results to the large exponent power laws found in the actual\nbehavior of the stock markets and to the exponential cut-off detected in\ncertain recent measurement.\n"
    },
    {
        "paper_id": "cond-mat/0008057",
        "authors": "H.Takayasu, M.Takayasu, M.P.Okazaki, K.Marumo, T.Shimizu",
        "title": "Fractal Properties in Economics",
        "comments": "15 pages, 10 figures http://www.hi-ho.ne.jp/f6586719/ecph/index.html\n  in 'Paradigms of Complexity', World Scientific, ed. Miroslav M. Novak,\n  (2000)(ISBN 981-02-4292-1), pp.243-258",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Scaling properties in financial fluctuations are reviewed from the standpoint\nof statistical physics. We firstly show theoretically that the balance of\ndemand and supply enhances fluctuations due to the underlying phase transition\nmechanism. By analyzing tick data of yen-dollar exchange rates we confirm two\nfractal properties: 1 The distribution of rate change in a fixed ticks is\napproximated by a symmetric stretched exponential function for a wide range of\ntime intervals; 2 the interval time distribution of trades nearly follows a\npower law. Empirical fractal properties in companies' financial data, such as\ndistributions and fluctuations in assets and incomes are discussed with a\nsimple model. The importance of methods and theories for phase transitions is\ndiscussed.\n"
    },
    {
        "paper_id": "cond-mat/0008069",
        "authors": "J.-F. Muzy (Univ. Corte), D. Sornette (Univ. Nice/CNRS and UCLA), J.\n  Delour (CRPP) and A. Arneodo (CRPP)",
        "title": "Multifractal returns and Hierarchical Portfolio Theory",
        "comments": "31 pages, 8 figures, corrections to improve readability",
        "journal-ref": "Quantitative Finance 1 (1), 131-148 (2001)",
        "doi": null,
        "license": null,
        "abstract": "  We extend and test empirically the multifractal model of asset returns based\non a multiplicative cascade of volatilities from large to small time scales.\nThe multifractal description of asset fluctuations is generalized into a\nmultivariate framework to account simultaneously for correlations across times\nscales and between a basket of assets. The reported empirical results show that\nthis extension is pertinent for financial modelling. The second part of the\npaper applies this theory to portfolio optimisation. Our multi-scale\ndescription allows us to characterize the portfolio return distribution at all\ntime scales simultaneously. The portfolio composition is predicted to change\nwith the investment time horizon (i.e., the time scale) in a way that can be\nfully determined once an adequate measure of risk is chosen. We discuss the use\nof the fourth-order cumulant and of utility functions. While the portfolio\nvolatility can be optimized in some cases for all time horizons, the kurtosis\nand higher normalized cumulants cannot be simultaneously optimized. For a fixed\ninvestment horizon, we study in details the influence of the number of periods,\ni.e., of the number of rebalancing of the portfolio. For the large risks\nquantified by the cumulants of order larger than two, the number of periods has\na non-trivial influence, in contrast with Tobin's result valid in the\nmean-variance framework. This theory provides a fundamental framework for the\nconflicting optimization involved in the different time horizons and quantifies\nsystematically the trade-offs for an optimal inter-temporal portfolio\noptimization.\n"
    },
    {
        "paper_id": "cond-mat/0008113",
        "authors": "Parameswaran Gopikrishnan, Vasiliki Plerou, Xavier Gabaix, and H.\n  Eugene Stanley",
        "title": "Statistical Properties of Share Volume Traded in Financial Markets",
        "comments": "4 pages, two-column format, four figures",
        "journal-ref": "Phys. Rev. E. (Rapid Comm.), 62 (2000) R4493.",
        "doi": "10.1103/PhysRevE.62.R4493",
        "license": null,
        "abstract": "  We quantitatively investigate the ideas behind the often-expressed adage `it\ntakes volume to move stock prices', and study the statistical properties of the\nnumber of shares traded $Q_{\\Delta t}$ for a given stock in a fixed time\ninterval $\\Delta t$. We analyze transaction data for the largest 1000 stocks\nfor the two-year period 1994-95, using a database that records every\ntransaction for all securities in three major US stock markets. We find that\nthe distribution $P(Q_{\\Delta t})$ displays a power-law decay, and that the\ntime correlations in $Q_{\\Delta t}$ display long-range persistence. Further, we\ninvestigate the relation between $Q_{\\Delta t}$ and the number of transactions\n$N_{\\Delta t}$ in a time interval $\\Delta t$, and find that the long-range\ncorrelations in $Q_{\\Delta t}$ are largely due to those of $N_{\\Delta t}$. Our\nresults are consistent with the interpretation that the large equal-time\ncorrelation previously found between $Q_{\\Delta t}$ and the absolute value of\nprice change $| G_{\\Delta t} |$ (related to volatility) are largely due to\n$N_{\\Delta t}$.\n"
    },
    {
        "paper_id": "cond-mat/0008305",
        "authors": "Adrian Dragulescu and Victor M. Yakovenko",
        "title": "Evidence for the exponential distribution of income in the USA",
        "comments": "4 pages, including 5 figures. Uses Springer Verlag style classes for\n  Eur. Phys. J. B (included). Submitted to the proceedings of APFA2 conference.\n  V.2: minor stylistic improvements",
        "journal-ref": "The European Physical Journal B 20, 585 (2001)",
        "doi": "10.1007/PL00011112",
        "license": null,
        "abstract": "  Using tax and census data, we demonstrate that the distribution of individual\nincome in the USA is exponential. Our calculated Lorenz curve without fitting\nparameters and Gini coefficient 1/2 agree well with the data. From the\nindividual income distribution, we derive the distribution function of income\nfor families with two earners and show that it also agrees well with the data.\nThe family data for the period 1947-1994 fit the Lorenz curve and Gini\ncoefficient 3/8=0.375 calculated for two-earners families.\n"
    },
    {
        "paper_id": "cond-mat/0008466",
        "authors": "Fabio Franci (1) and Lorenzo Matassini (1) ((1) Max-Planck-Institut\n  fuer Physik komplexer Systeme Dresden)",
        "title": "Life in the Stockmarket - a Realistic Model for Trading",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a frustrated and disordered many-body model of a stockmarket in\nwhich independent adaptive traders can trade a stock subject to the economic\nlaw of supply and demand. We show that the typical scaling properties and the\ncorrelated volatility arise as a consequence of the collective behavior of\nagents: With their interaction they determine a price which in turn affects\ntheir future way of investing. We introduce only one type of investors, since\nthey all share the same hope: They simply want to maximize the profit\nminimizing the risk. The best utilization of resources occurs at a critical\npoint characterized by the transition between the excess-demand and the\nexcess-supply phases.\n"
    },
    {
        "paper_id": "cond-mat/0009042",
        "authors": "Jiri Hoogland, Dimitri Neumann (CWI)",
        "title": "Tradable Schemes",
        "comments": "13 pages, 5 tables, LaTeX 2e",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this article we present a new approach to the numerical valuation of\nderivative securities. The method is based on our previous work where we\nformulated the theory of pricing in terms of tradables. The basic idea is to\nfit a finite difference scheme to exact solutions of the pricing PDE. This can\nbe done in a very elegant way, due to the fact that in our tradable based\nformulation there appear no drift terms in the PDE. We construct a mixed scheme\nbased on this idea and apply it to price various types of arithmetic Asian\noptions, as well as plain vanilla options (both european and american style) on\nstocks paying known cash dividends. We find prices which are accurate to $\\sim\n0.1%$ in about 10ms on a Pentium 233MHz computer and to $\\sim 0.001%$ in a\nsecond. The scheme can also be used for market conform pricing, by fitting it\nto observed option prices.\n"
    },
    {
        "paper_id": "cond-mat/0009222",
        "authors": "B.M. Roehner",
        "title": "Determining bottom price-levels after a speculative peak",
        "comments": "6 pages 5 figures To appear in European Physical Journal B",
        "journal-ref": null,
        "doi": "10.1007/s100510070150",
        "license": null,
        "abstract": "  During a stock market peak the price of a given stock ($ i $) jumps from an\ninitial level $ p_1(i) $ to a peak level $ p_2(i) $ before falling back to a\nbottom level $ p_3(i) $. The ratios $ A(i) = p_2(i)/p_1(i) $ and $ B(i)=\np_3(i)/p_1(i) $ are referred to as the peak- and bottom-amplitude respectively.\nThe paper shows that for a sample of stocks there is a linear relationship\nbetween $ A(i) $ and $ B(i) $ of the form: $ B=0.4A+b $. In words, this means\nthat the higher the price of a stock climbs during a bull market the better it\nresists during the subsequent bear market. That rule, which we call the\nresilience pattern, also applies to other speculative markets. It provides a\nuseful guiding line for Monte Carlo simulations.\n"
    },
    {
        "paper_id": "cond-mat/0009260",
        "authors": "E. Bacry (1) J. Delour (2) J.F. Muzy (2,3) ((1) CMAP, Ecole\n  Polytechnique Palaiseau France (2) CRPP, Pessac France (3) Universite de\n  Corse, Corte, France)",
        "title": "A multivariate multifractal model for return fluctuations",
        "comments": "To be published in the Proceeding of the APFA2 conference (Liege,\n  Belgium, July 2000) in the journal Quantitative Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper we briefly review the recently inrtroduced Multifractal Random\nWalk (MRW) that is able to reproduce most of recent empirical findings\nconcerning financial time-series : no correlation between price variations,\nlong-range volatility correlations and multifractal statistics. We then focus\non its extension to a multivariate context in order to model portfolio\nbehavior. Empirical estimations on real data suggest that this approach can be\npertinent to account for the nature of both linear and non-linear correlation\nbetween stock returns at all time scales.\n"
    },
    {
        "paper_id": "cond-mat/0009287",
        "authors": "Per Bak, Simon F. Norrelykke and Martin Shubik",
        "title": "Money and Goldstone modes",
        "comments": "7 pages, 3 figures",
        "journal-ref": "Quantitative Finance 1, 186-190 (2001)",
        "doi": "10.1080/713665545",
        "license": null,
        "abstract": "  Why is ``worthless'' fiat money generally accepted as payment for goods and\nservices? In equilibrium theory, the value of money is generally not\ndetermined: the number of equations is one less than the number of unknowns, so\nonly relative prices are determined. In the language of mathematics, the\nequations are ``homogeneous of order one''. Using the language of physics, this\nrepresents a continuous ``Goldstone'' symmetry. However, the continuous\nsymmetry is often broken by the dynamics of the system, thus fixing the value\nof the otherwise undetermined variable. In economics, the value of money is a\nstrategic variable which each agent must determine at each transaction by\nestimating the effect of future interactions with other agents. This idea is\nillustrated by a simple network model of monopolistic vendors and buyers, with\nbounded rationality. We submit that dynamical, spontaneous symmetry breaking is\nthe fundamental principle for fixing the value of money. Perhaps the continuous\nsymmetry representing the lack of restoring force is also the fundamental\nreason for large fluctuations in stock markets.\n"
    },
    {
        "paper_id": "cond-mat/0009350",
        "authors": "Giovanni Bonanno, Fabrizio Lillo and Rosario N. Mantegna",
        "title": "High-frequency Cross-correlation in a Set of Stocks",
        "comments": "9 pages, 8 figures, 12 panels, November 2000",
        "journal-ref": "Quantitative Finance, 1,Jan 2001, 96-104",
        "doi": null,
        "license": null,
        "abstract": "  The high-frequency cross-correlation existing between pairs of stocks traded\nin a financial market are investigated in a set of 100 stocks traded in US\nequity markets. A hierarchical organization of the investigated stocks is\nobtained by determining a metric distance between stocks and by investigating\nthe properties of the subdominant ultrametric associated with it. A clear\nmodification of the hierarchical organization of the set of stocks investigated\nis detected when the time horizon used to determine stock returns is changed.\nThe hierarchical location of stocks of the energy sector is investigated as a\nfunction of the time horizon.\n"
    },
    {
        "paper_id": "cond-mat/0009401",
        "authors": "Fabrizio Lillo and Rosario N. Mantegna",
        "title": "Empirical properties of the variety of a financial portfolio and the\n  single-index model",
        "comments": "8 pages, 5 figures, 3 tables",
        "journal-ref": null,
        "doi": "10.1007/s100510170229",
        "license": null,
        "abstract": "  We investigate the variety of a portfolio of stocks in normal and extreme\ndays of market activity. We show that the variety carries information about the\nmarket activity which is not present in the single-index model and we observe\nthat the variety time evolution is not time reversal around the crash days. We\nobtain the theoretical relation between the square variety and the mean return\nof the ensemble return distribution predicted by the single-index model. The\nsingle-index model is able to mimic the average behavior of the square variety\nbut fails in describing quantitatively the relation between the square variety\nand the mean return of the ensemble distribution. The difference between\nempirical data and theoretical description is more pronounced for large\npositive values of the mean return of the ensemble distribution. Other\nsignificant deviations are also observed for extreme negative values of the\nmean return.\n"
    },
    {
        "paper_id": "cond-mat/0009437",
        "authors": "G. Caldarelli (1), M. Piccioni (1) and E. Sciubba (2) ((1)INFM and Dip\n  Fisica,\"La Sapienza\" Rome, Italy, (2) Tinbergen Institute Rotterdam, The\n  Netherlands)",
        "title": "A Numerical Study on the Evolution of Portfolio Rules: Is CAPM Fit for\n  Nasdaq?",
        "comments": "18 pages, 2 eps figures, presented at CEF2000 Barcelona, Spain",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper we test computationally the performance of CAPM in an\nevolutionary setting. In particular we study the stability of wealth\ndistribution in a financial market where some traders invest as prescribed by\nCAPM and others behave according to different portfolio rules. Our study is\nmotivated by recent analytical results that show that, whenever a logarithmic\nutility maximiser enters the market, traders who either ``believe'' in CAPM and\nuse it as a rule of thumb for their portfolio decisions, or are endowed with\ngenuine mean-variance preferences, vanish in the long run. Our analysis\nprovides further insights and extends these results. We simulate a sequence of\ntrades in a financial market and: first, we address the issue of how long is\nthe long run in different parametric settings; second, we study the effect of\nheterogeneous savings behaviour on asymptotic wealth shares. We find that CAPM\nis particularly ``unfit'' for highly risky environments.\n"
    },
    {
        "paper_id": "cond-mat/0010112",
        "authors": "D. Sornette (Univ. Nice/CNRS and UCLA)",
        "title": "\"Slimming\" of power law tails by increasing market returns",
        "comments": "13 pages + 4 figures",
        "journal-ref": "Physica A 309, 403--418 (2002)",
        "doi": "10.1016/S0378-4371(02)00614-3",
        "license": null,
        "abstract": "  We introduce a simple generalization of rational bubble models which removes\nthe fundamental problem discovered by [Lux and Sornette, 1999] that the\ndistribution of returns is a power law with exponent less than 1, in\ncontradiction with empirical data. The idea is that the price fluctuations\nassociated with bubbles must on average grow with the mean market return r.\nWhen r is larger than the discount rate r_delta, the distribution of returns of\nthe observable price, sum of the bubble component and of the fundamental price,\nexhibits an intermediate tail with an exponent which can be larger than 1. This\nregime r>r_delta corresponds to a generalization of the rational bubble model\nin which the fundamental price is no more given by the discounted value of\nfuture dividends. We explain how this is possible. Our model predicts that, the\nhigher is the market remuneration r above the discount rate, the larger is the\npower law exponent and thus the thinner is the tail of the distribution of\nprice returns.\n"
    },
    {
        "paper_id": "cond-mat/0010190",
        "authors": "Danuta Makowiec and Piotr Gnacinski",
        "title": "Fluctuations Of WIG-the index of Warsaw Stock Exchange. Preliminary\n  studies",
        "comments": "10 pages and 15 files with figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A time series that represents daily values of the WIG index (the main index\nof Warsaw Stock Exchange) over last 5 years is examined. Non-Gaussian features\nof distributions of fluctuations, namely returns, over a time scale are\nconsidered. Some general properties like exponents of the long range\ncorrelation estimated by averaged volatility and detrended fluctuations\nanalysis (DFA) as well as exponents describing a decay of tails of the\ncumulative distributions are found. Closing, the Zipf analysis for the WIG\nindex time series translated into three letter text is presented.\n"
    },
    {
        "paper_id": "cond-mat/0010211",
        "authors": "Hendrik J. Blok",
        "title": "On the nature of the stock market: Simulations and experiments",
        "comments": "227 pages, PhD thesis",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this dissertation two simple models of stock exchange are developed and\nsimulated numerically. The first is characterized by centralized trading with a\nmarket maker. Unfortunately, this model is unable to generate realistic market\ndynamics. The second model discards the requirement of centralized trading.\nUnder variation of the control parameter the model exhibits two phase\ntransitions: both a first- and a second-order (critical). The decentralized\nmodel is able to capture many of the interesting properties observed in\nempirical markets. Significantly, these properties only emerge when the\nparameters are tuned such that the model spans the critical point. This\nsuggests that real markets may operate at or near a critical point, but is\nunable to explain why this should be. One of the main points of the thesis is\nthat these empirical phenomena are not present in the stochastic driving force,\nbut emerge endogenously from interactions between agents.\n"
    },
    {
        "paper_id": "cond-mat/0010222",
        "authors": "Peter Richmond and Sorin Solomon",
        "title": "Power Laws are Boltzmann Laws in Disguise",
        "comments": "pdf file",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Using a model based on generalised Lotka Volterra dynamics together with some\nrecent results for the solution of generalised Langevin equations, we show that\nthe equilibrium solution for the probability distribution of wealth has two\ncharacteristic regimes. For large values of wealth it takes the form of a\nPareto style power law. For small values of wealth, (w less then wmin) the\ndistribution function tends sharply to zero with infinite slope. The origin of\nthis law lies in the random multiplicative process built into the model. Whilst\nsuch results have been known since the time of Gibrat, the present framework\nallows for a stable power law in an arbitrary and irregular global dynamics, so\nlong as the market is `fair', i.e., there is no net advantage to any particular\ngroup or individual. We show for our model that the relative distribution of\nwealth follows a time independent distribution of this form even thought the\ntotal wealth may follow a more complicated dynamics and vary with time in an\narbitrary manner. In developing the theory, we draw parallels with conventional\nthermodynamics and derive for the system the associated laws of `econodynamics'\ntogether with the associated econodynamic potentials. The power law that arises\nin the distribution function may then be identified with new additional\nlogarithmic terms in the familiar Boltzmann distribution function for the\nsystem. The distribution function of stock market returns for our model, it is\nargued, will follow the same qualitative laws and exhibit power law behaviour.\n"
    },
    {
        "paper_id": "cond-mat/0010263",
        "authors": "Taisei Kaizoji",
        "title": "Speculative bubbles and crashes in stock market: an interacting-agent\n  model of speculative activity",
        "comments": "11 pages, 6 figures",
        "journal-ref": "Physica A 287, 3-4, pp. 493--506",
        "doi": "10.1016/S0378-4371(00)00388-5",
        "license": null,
        "abstract": "  We present an interacting-agent model of speculative activity explaining\nbubbles and crashes in stock markets. We describe stock markets through an\ninfinite-range Ising model to formulate the tendency of traders getting\ninfluenced by the investment attitude of other traders. Bubbles and crashes are\nunderstood and described qualitatively and quantitatively in terms of the\nclassical phase transitions. The results of estimation the parameters of the\nmodel using the actual financial data (the bubble and the subsequent crash in\nthe Japanese stock market in 1987-1992) show that the good quality of the fits,\nas well as the consistency of the values of the parameters.\n"
    },
    {
        "paper_id": "cond-mat/0010455",
        "authors": "David Sherrington, Juan P. Garrahan and Esteban Moro",
        "title": "Statistical physics of adaptive correlation of agents in a market",
        "comments": "Invited talk presented at the Conference: Disordered and Complex\n  Systems, King's College London, July 2000",
        "journal-ref": null,
        "doi": "10.1063/1.1358169",
        "license": null,
        "abstract": "  Recent results and interpretations are presented for the thermal minority\ngame, concentrating on deriving and justifying the fundamental stochastic\ndifferential equation for the microdynamics.\n"
    },
    {
        "paper_id": "cond-mat/0011042",
        "authors": "D. Challet, A. Chessa, M. Marsili, Y.-C. Zhang",
        "title": "From Minority Games to real markets",
        "comments": "9 pages, 7 figures, to appear in Quantitative Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We address the question of market efficiency using the Minority Game (MG)\nmodel. First we show that removing unrealistic features of the MG leads to\nmodels which reproduce a scaling behavior close to what is observed in real\nmarkets. In particular we find that i) fat tails and clustered volatility arise\nat the phase transition point and that ii) the crossover to random walk\nbehavior of prices is a finite size effect. This, on one hand, suggests that\nmarkets operate close to criticality, where the market is marginally efficient.\nOn the other it allows one to measure the distance from criticality of real\nmarket, using cross-over times. The artificial market described by the MG is\nthen studied as an ecosystem with different_species_ of traders. This clarifies\nthe nature of the interaction and the particular role played by the various\npopulations.\n"
    },
    {
        "paper_id": "cond-mat/0011088",
        "authors": "D. Sornette (Univ. Nice/CNRS and UCLA)",
        "title": "Fokker-Planck equation of distributions of financial returns and power\n  laws",
        "comments": "11 pages, in press in Physica A",
        "journal-ref": "Physica A 290 (1-2), 211-217 (2001)",
        "doi": "10.1016/S0378-4371(00)00571-9",
        "license": null,
        "abstract": "  Our purpose is to relate the Fokker-Planck formalism proposed by [Friedrich\net al., Phys. Rev. Lett. 84, 5224 (2000)] for the distribution of stock market\nreturns to the empirically well-established power law distribution with an\nexponent in the range 3-5. We show how to use Friedrich et al.'s formalism to\npredict that the distribution of returns is indeed asymptotically a power law\nwith an exponent mu that can be determined from the Kramers-Moyal coefficients\ndetermined by Friedrich et al. However, with their values determined for the\nU.S. dollar-German mark exchange rates, the exponent mu predicted from their\ntheory is found around 12, in disagreement with the often-quoted value between\n3 and 5. This could be explained by the fact that the large asymptotic value of\n12 does not apply to real data that lie still far from the stationary state of\nthe Fokker-Planck description. Another possibility is that power laws are\ninadequate. The mechanism for the power law is based on the presence of\nmultiplicative noise across time-scales, which is different from the\nmultiplicative noise at fixed time-scales implicit in the ARCH models developed\nin the Finance literature.\n"
    },
    {
        "paper_id": "cond-mat/0011145",
        "authors": "Parameswaran Gopikrishnan, Bernd Rosenow, Vasiliki Plerou, and H.\n  Eugene Stanley",
        "title": "Identifying Business Sectors from Stock Price Fluctuations",
        "comments": "4 pages 2-column format revtex, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Firms having similar business activities are correlated. We analyze two\ndifferent cross-correlation matrices C constructed from (i) 30-min price\nfluctuations of 1000 US stocks for the 2-year period 1994-95 and (ii) 1-day\nprice fluctuations of 422 US stocks for the 35-year period 1962-96. We find\nthat the eigenvectors of C corresponding to the largest eigenvalues allow us to\npartition the set of all stocks into distinct subsets. These subsets are\nsimilar to conventionally-identified business sectors, and are stable for\nextended periods of time. Using a set of coupled stochastic differential\nequations, we argue how correlations between stocks might arise. Finally, we\ndemonstrate that the sectors we identify are useful for the practical goal of\nfinding an investment which earns a given return without exposure to\nunnecessary risk.\n"
    },
    {
        "paper_id": "cond-mat/0011149",
        "authors": "Jun-ichi Maskawa",
        "title": "Hamiltonian in Financial Markets",
        "comments": "6 pages and 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A statistical physics model for the time evolutions of stock portfolios is\nproposed. In this model the time series of price changes are coded into the\nsequences of up and down spins. The Hamiltonian of the system is introduced and\nis expressed by spin-spin interactions as in spin glass models of disordered\nmagnetic systems. The interaction coefficients between two stocks are\ndetermined by empirical data coded into up and down spin sequences using\nfluctuation-response theorem. Monte Carlo simulations are performed and the\nresultant probability densities of the system energy and magnetization show\ngood agreement with empirical data.\n"
    },
    {
        "paper_id": "cond-mat/0011280",
        "authors": "E. W. Piotrowski, J. Sladkowski",
        "title": "The thermodynamics of portfolios",
        "comments": "8 pages, LaTeX, appolb.cls is required",
        "journal-ref": "Acta Phys. Pol B32 597 (2001)",
        "doi": null,
        "license": null,
        "abstract": "  We propose a new method of valuation of portfolios and their respective\ninvesting strategies. To this end we define a canonical ensemble of portfolios\nthat allows to use the formalism thermodynamics.\n"
    },
    {
        "paper_id": "cond-mat/0011295",
        "authors": "Andreas Krause",
        "title": "Microstructure Effects on Daily Return Volatility in Financial Markets",
        "comments": "15 pages, as presented at the Complexity Workshop in Aix-en-Provence",
        "journal-ref": "International Journal of Theoretical and Applied Finance, Vol. 6,\n  No. 7 (2003) 739-765",
        "doi": "10.1142/S0219024903002171",
        "license": null,
        "abstract": "  We simulate a series of daily returns from intraday price movements initiated\nby microstructure elements. Significant evidence is found that daily returns\nand daily return volatility exhibit first order autocorrelation, but trading\nvolume and daily return volatility are not correlated, while intraday\nvolatility is. We also consider GARCH effects in daily return series and show\nthat estimates using daily returns are biased from the influence of the level\nof prices. Using daily price changes instead, we find evidence of a significant\nGARCH component. These results suggest that microstructure elements have a\nconsiderable influence on the return generating process.\n"
    },
    {
        "paper_id": "cond-mat/0011337",
        "authors": "R. Baviera, M. Pasquini, J. Raboanary, M. Serva",
        "title": "Moving averages and markets inefficiency",
        "comments": "19 pages, 4 figures, RevTex, submitted to Quantitative Finance;\n  changed sect. 3",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We introduce a stochastic price model where, together with a random\ncomponent, a moving average of logarithmic prices contributes to the price\nformation. Our model is tested against financial datasets, showing an extremely\ngood agreement with them. It suggests how to construct trading strategies which\nimply a capital growth rate larger than the growth rate of the underlying\nasset, with also the effect of reducing the fluctuations. These results are a\nclear evidence that some hidden information is not fully integrated in price\ndynamics, and therefore financial markets are partially inefficient. In simple\nterms, we give a recipe for speculators to make money as long as only few\ninvestors follow it.\n"
    },
    {
        "paper_id": "cond-mat/0011373",
        "authors": "Wataru Souma",
        "title": "Universal Structure of the Personal Income Distribution",
        "comments": "10 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate the Japanese personal income distribution in the high income\nrange over the 112 years 1887-1998, and that in the middle income range over\nthe 44 years 1955-98. It is observed that the distribution pattern of the\nlognormal with power law tail is the universal structure. However the indexes\nspecifying the distribution differ from year to year. One of the index\ncharacterizing the distribution is the mean value of the lognormal\ndistribution; the mean income in the middle income range. It is found that this\nvalue correlates linearly with the Gross Domestic Product (GDP). To clarify the\ntemporal change of the equality or inequality of the distribution, we analyze\nPareto and Gibrat indexes, which characterize the distribution in the high\nincome range and that in the middle income range respectively. It is found for\nsome years that there is no correlation between the high income and the middle\nincome. It is also shown that the mean value of Pareto index equals to 2, and\nthe change of this index is effected by the change of the asset price. From\nthese analysis we derive four constraints that must be satisfied by\nmathematical models.\n"
    },
    {
        "paper_id": "cond-mat/0011488",
        "authors": "S. Drozdz, F. Gruemmer, F. Ruf and J. Speth",
        "title": "Towards identifying the world stock market cross-correlations: DAX\n  versus Dow Jones",
        "comments": "LaTeX, 6 pages, 8 figures",
        "journal-ref": "Physica A294 (2001), 226",
        "doi": "10.1016/S0378-4371(01)00119-4",
        "license": null,
        "abstract": "  Effects connected with the world globalization affect also the financial\nmarkets. On a way towards quantifying the related characteristics we study the\nfinancial empirical correlation matrix of the 60 companies which both the\nDeutsche Aktienindex (DAX) and the Dow Jones (DJ) industrial average comprised\nduring the years 1990-1999. The time-dependence of the underlying\ncross-correlations is monitored using a time window of 60 trading days. Our\nstudy shows that if the time-zone delays are properly accounted for the two\ndistant markets largely merge into one. This effect is particularly visible\nduring the last few years. It is however the Dow Jones which dictates the\ntrend.\n"
    },
    {
        "paper_id": "cond-mat/0012045",
        "authors": "J. A. F. Heimel, A. C. C. Coolen",
        "title": "Generating Functional Analysis of the Dynamics of the Batch Minority\n  Game with Random External Information",
        "comments": "15 pages, 6 figures, uses Revtex. Replaced an old version of\n  volatility graph that. Rephrased and updated some references",
        "journal-ref": "Phys. Rev. E 63, 056121 (2001)",
        "doi": "10.1103/PhysRevE.63.056121",
        "license": null,
        "abstract": "  We study the dynamics of the batch minority game, with random external\ninformation, using generating functional techniques a la De Dominicis. The\nrelevant control parameter in this model is the ratio $\\alpha=p/N$ of the\nnumber $p$ of possible values for the external information over the number $N$\nof trading agents. In the limit $N\\to\\infty$ we calculate the location\n$\\alpha_c$ of the phase transition (signaling the onset of anomalous response),\nand solve the statics for $\\alpha>\\alpha_c$ exactly. The temporal correlations\nin global market fluctuations turn out not to decay to zero for infinitely\nwidely separated times. For $\\alpha<\\alpha_c$ the stationary state is shown to\nbe non-unique. For $\\alpha\\to 0$ we analyse our equations in leading order in\n$\\alpha$, and find asymptotic solutions with diverging volatility\n$\\sigma=\\order(\\alpha^{-{1/2}})$ (as regularly observed in simulations), but\nalso asymptotic solutions with vanishing volatility\n$\\sigma=\\order(\\alpha^{{1/2}})$. The former, however, are shown to emerge only\nif the agents' initial strategy valuations are below a specific critical value.\n"
    },
    {
        "paper_id": "cond-mat/0012405",
        "authors": "Anirban Chakraborti, Srutarshi Pradhan and Bikas K. Chakrabarti",
        "title": "A Self-organising Model of Market with Single Commodity",
        "comments": "8 pages, 3 figures (encapsulated postscript)",
        "journal-ref": "Physica A 297, 253 (2001)",
        "doi": "10.1016/S0378-4371(01)00195-9",
        "license": null,
        "abstract": "  We have studied here the self-organising features of the dynamics of a model\nmarket, where the agents `trade' for a single commodity with their money. The\nmodel market consists of fixed numbers of economic agents, money supply and\ncommodity. We demonstrate that the model, apart from showing a self-organising\nbehaviour, indicates a crucial role for the money supply in the market and also\nits self-organising behaviour is seen to be significantly affected when the\nmoney supply becomes less than the optimum. We also observed that this optimal\nmoney supply level of the market depends on the amount of `frustration' or\nscarcity in the commodity market.\n"
    },
    {
        "paper_id": "cond-mat/0012419",
        "authors": "J. Doyne Farmer and Shareen Joshi",
        "title": "The price dynamics of common trading strategies",
        "comments": "29 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A deterministic trading strategy can be regarded as a signal processing\nelement that uses external information and past prices as inputs and\nincorporates them into future prices. This paper uses a market maker based\nmethod of price formation to study the price dynamics induced by several\ncommonly used financial trading strategies, showing how they amplify noise,\ninduce structure in prices, and cause phenomena such as excess and clustered\nvolatility.\n"
    },
    {
        "paper_id": "cond-mat/0012479",
        "authors": "Sorin Solomon and Peter Richmond",
        "title": "Stability of Pareto-Zipf Law in Non-Stationary Economies",
        "comments": "HTML, 5th Workshop on Economics and Heterogeneous Interacting Agents,\n  Marseille June 15-17th; (Springer-Verlag 2001)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Generalized Lotka-Volterra (GLV) models extending the (70 year old) logistic\nequation to stochastic systems consisting of a multitude of competing\nauto-catalytic components lead to power distribution laws of the (100 year old)\nPareto-Zipf type. In particular, when applied to economic systems, GLV leads to\npower laws in the relative individual wealth distribution and in the market\nreturns. These power laws and their exponent alpha are invariant to arbitrary\nvariations in the total wealth of the system and to other endogenous and\nexogenous factors. The measured value of the exponent alpha = 1.4 is related to\nbuilt-in human social and biological constraints.\n"
    },
    {
        "paper_id": "cond-mat/0012497",
        "authors": "Marco Raberto, Enrico Scalas, Rudolf Gorenflo and Francesco Mainardi",
        "title": "The waiting-time distribution of LIFFE bond futures",
        "comments": "Submitted to Quantitative Finance, Proceedings of Application of\n  Physics in Financial Analysis II, Liege, 13-15 July 2000",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We apply the Continuous Time Random Walk (CTRW) framework, introduced in\nfinance by Scalas et al., to the analysis of the probability distribution of\ntime intervals between two consecutive trades in the case of BTP futures prices\ntraded at LIFFE in 1997. Results corroborate the validity of the CTRW approach\nfor the description of the temporal evolution of financial time series.\n"
    },
    {
        "paper_id": "cond-mat/0012514",
        "authors": "Ting Lei and Raymond J. Hawkins",
        "title": "Corporate Default Behavior: A Simple Stochastic Model",
        "comments": "6 pages, RevTex, 4 eps figures, submitted to Phys. Rev. E",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We compare observed corporate cumulative default probabilities to those\ncalculated using a stochastic model based on an extension of the work of Black\nand Cox and find that corporations default as if via diffusive dynamics. The\nmodel, based on a contingent-claims analysis of corporate capital structure, is\neasily calibrated with readily available historical default probabilities and\nfits observed default data published by Standard and Poor's. Applying this\nmodel to the Standard and Poor's default data we find that the difference in\ndefault behavior between credit ratings can be explained largely by a single\nvariable: the \"distance to default\" at the time the rating is given. The\nability to represent observed default behavior by a single analytic expression\nand to differentiate credit-rating-dependent default behavior with a single\nvariable recommends this model for a variety of risk management applications\nincluding the mapping of bank default experience to public credit ratings.\n"
    },
    {
        "paper_id": "cond-mat/0101001",
        "authors": "K. Sznajd-Weron, R. Weron",
        "title": "A simple model of price formation",
        "comments": "Version 2: 4 pages, 4 figures; added more stringent statistical\n  analysis; to appear in Int. J. Modern Physics C, Vol. 13, No. 1 (2002)",
        "journal-ref": "Int. J. Modern Physics C, Vol. 13, No. 1 (2002) 115-123",
        "doi": "10.1142/S0129183102003000",
        "license": null,
        "abstract": "  A simple Ising spin model which can describe the mechanism of price formation\nin financial markets is proposed. In contrast to other agent-based models, the\ninfluence does not flow inward from the surrounding neighbors to the center\nsite, but spreads outward from the center to the neighbors. The model thus\ndescribes the spread of opinions among traders. It is shown via standard Monte\nCarlo simulations that very simple rules lead to dynamics that duplicate those\nof asset prices.\n"
    },
    {
        "paper_id": "cond-mat/0101068",
        "authors": "Z. Burda, D. Johnston, J. Jurkiewicz, M. Kaminski, M.A. Nowak, G. Papp\n  and I. Zahed",
        "title": "Wealth Condensation in Pareto Macro-Economies",
        "comments": "4 pages, 1 figure",
        "journal-ref": "Phys.Rev.E65.026102,2002",
        "doi": "10.1103/PhysRevE.65.026102",
        "license": null,
        "abstract": "  We discuss a Pareto macro-economy (a) in a closed system with fixed total\nwealth and (b) in an open system with average mean wealth and compare our\nresults to a similar analysis in a super-open system (c) with unbounded wealth.\nWealth condensation takes place in the social phase for closed and open\neconomies, while it occurs in the liberal phase for super-open economies. In\nthe first two cases, the condensation is related to a mechanism known from the\nballs-in-boxes model, while in the last case to the non-integrable tails of the\nPareto distribution. For a closed macro-economy in the social phase, we point\nto the emergence of a ``corruption'' phenomenon: a sizeable fraction of the\ntotal wealth is always amassed by a single individual.\n"
    },
    {
        "paper_id": "cond-mat/0101143",
        "authors": "G. Cuniberti, L. Matassini",
        "title": "Liquid markets and market liquids: collective and single-asset dynamics\n  in financial markets",
        "comments": "4 pages, svjour.cls, 3 figures, to appear in The European Physical\n  Journal B",
        "journal-ref": "Eur. Phys. J. B 20, 561-564 (2001)",
        "doi": "10.1007/s100510170240",
        "license": null,
        "abstract": "  We characterize the collective phenomena of a liquid market. By interpreting\nthe behavior of a no-arbitrage N asset market in terms of a particle system\nscenario, (thermo)dynamical-like properties can be extracted from the asset\nkinetics. In this scheme the mechanisms of the particle interaction can be\nwidely investigated. We test the verisimilitude of our construction on\ntwo-decade stock market daily data (DAX30) and show the result obtained for the\ninteraction potential among asset pairs.\n"
    },
    {
        "paper_id": "cond-mat/0101175",
        "authors": "Yoshi Fujiwara and Hirokazu Fujisaka",
        "title": "Coarse-graining and Self-similarity of Price Fluctuations",
        "comments": "9 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00135-2",
        "license": null,
        "abstract": "  We propose a new approach for analyzing price fluctuations in their strongly\ncorrelated regime ranging from minutes to months. This is done by employing a\nself-similarity assumption for the magnitude of coarse-grained price\nfluctuation or volatility. The existence of a Cramer function, the\ncharacteristic function for self-similarity, is confirmed by analyzing real\nprice data from a stock market. We also discuss the close interrelation among\nour approach, the scaling-of-moments method and the multifractal approach for\nprice fluctuations.\n"
    },
    {
        "paper_id": "cond-mat/0101326",
        "authors": "Damien Challet, Matteo Marsili and Yi-Cheng Zhang",
        "title": "Stylized facts of financial markets and market crashes in Minority Games",
        "comments": "6 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00103-0",
        "license": null,
        "abstract": "  We present and study a Minority Game based model of a financial market where\nadaptive agents -- the speculators -- interact with deterministic agents --\ncalled producers. Speculators trade only if they detect predictable patterns\nwhich grant them a positive gain. Indeed the average number of active\nspeculators grows with the amount of information that producers inject into the\nmarket. Transitions between equilibrium and out of equilibrium behavior are\nobserved when the relative number of speculators to the complexity of\ninformation or to the number of producers are changed. When the system is out\nof equilibrium, stylized facts arise, such as fat tailed distribution of\nreturns and volatility clustering. Without speculators, the price follows a\nrandom walk; this implies that stylized facts arise because of the presence of\nspeculators. Furthermore, if speculators abandon price taking behavior,\nstylized facts disappear.\n"
    },
    {
        "paper_id": "cond-mat/0101351",
        "authors": "Johannes Berg, Matteo Marsili, Aldo Rustichini & Riccardo Zecchina",
        "title": "Statistical mechanics of asset markets with private information",
        "comments": "22 pages 4 figures. To appear on J.Quant.Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Traders in a market typically have widely different, private information on\nthe return of an asset. The equilibrium price of the asset may reflect this\ninformation more accurately if the number of traders is large enough compared\nto the number of the states of the world that determine the return of the\nasset. We study the transition from markets where prices do not reflect the\ninformation accurately into markets where it does. In competitive markets, this\ntransition takes place suddenly, at a critical value of the ratio between\nnumber of states and number of traders. The Nash equilibrium market behaves\nquite differently from a competitive market even in the limit of large\neconomies.\n"
    },
    {
        "paper_id": "cond-mat/0101371",
        "authors": "Y. Malevergne (Univ. Nice/CNRS) and D. Sornette (Univ. Nice/CNRS and\n  UCLA)",
        "title": "Multi-dimensional Rational Bubbles and fat tails: application of\n  stochastic regression equations to financial speculation",
        "comments": "Latex 14 pages + 1 eps figure",
        "journal-ref": "Quantitative Finance 1, 533541 (2001)",
        "doi": null,
        "license": null,
        "abstract": "  We extend the model of rational bubbles of Blanchard and of Blanchard and\nWatson to arbitrary dimensions d: a number d of market time series are made\nlinearly interdependent via d times d stochastic coupling coefficients. We\nfirst show that the no-arbitrage condition imposes that the non-diagonal\nimpacts of any asset i on any other asset j different from i has to vanish on\naverage, i.e., must exhibit random alternative regimes of reinforcement and\ncontrarian feedbacks. In contrast, the diagonal terms must be positive and\nequal on average to the inverse of the discount factor. Applying the results of\nrenewal theory for products of random matrices to stochastic recurrence\nequations (SRE), we extend the theorem of Lux and Sornette (cond-mat/9910141)\nand demonstrate that the tails of the unconditional distributions associated\nwith such d-dimensional bubble processes follow power laws (i.e., exhibit\nhyperbolic decline), with the same asymptotic tail exponent mu<1 for all\nassets. The distribution of price differences and of returns is dominated by\nthe same power-law over an extended range of large returns. This small value\nmu<1 of the tail exponent has far-reaching consequences in the non-existence of\nthe means and variances. Although power-law tails are a pervasive feature of\nempirical data, the numerical value mu<1 is in disagreement with the usual\nempirical estimates mu approximately equal to 3. It, therefore, appears that\ngeneralizing the model of rational bubbles to arbitrary dimensions does not\nallow us to reconcile the model with these stylized facts of financial data.\nThe non-stationary growth rational bubble model seems at present the only\nviable solution (see cond-mat/0010112).\n"
    },
    {
        "paper_id": "cond-mat/0102042",
        "authors": "Bertrand M. Roehner",
        "title": "To sell or not to sell? Behavior of shareholders during price collapses",
        "comments": "9 pages, 1 figure. To appear in International Journal of Modern\n  Physics C",
        "journal-ref": null,
        "doi": "10.1142/S0129183101001390",
        "license": null,
        "abstract": "  It is a common belief that the behavior of shareholders depends upon the\ndirection of price fluctuations: if prices increase they buy, if prices\ndecrease they sell. That belief, however, is more based on ``common sense''\nthan on facts. In this paper we present evidence for a specific class of\nshareholders which shows that the actual behavior of shareholders can be\nmarkedly different.\n"
    },
    {
        "paper_id": "cond-mat/0102301",
        "authors": "R. Vilela Mendes, R. Lima and T. Araujo",
        "title": "A process-reconstruction analysis of market fluctuations",
        "comments": "29 pages Latex, 16 eps-figures",
        "journal-ref": "Int. Journal of Theor. and Applied Finance 5 (2002) 797",
        "doi": null,
        "license": null,
        "abstract": "  The statistical properties of a stochastic process may be described (1)by the\nexpectation values of the observables, (2)by the probability distribution\nfunctions or (3)by probability measures on path space. Here an analysis of\nlevel (3) is carried out for market fluctuation processes. Gibbs measures and\nchains with complete connections are considered. Some other topics are also\ndiscussed, in particular the asymptotic stationarity of the processes and the\nbehavior of statistical indicators of level (1) and (2). We end up with some\nremarks concerning the nature of the market fluctuation process.\n"
    },
    {
        "paper_id": "cond-mat/0102304",
        "authors": "Carlo Acerbi, Claudio Nordio and Carlo Sirtori (Derivatives Desk,\n  Abaxbank, Milano Italy)",
        "title": "Expected Shortfall as a Tool for Financial Risk Management",
        "comments": "10 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the properties of Expected Shortfall from the point of view of\nfinancial risk management. This measure --- which emerges as a natural remedy\nin some cases where Value at Risk (VaR) is not able to distinguish portfolios\nwhich bear different levels of risk --- is indeed shown to have much better\nproperties than VaR. We show in fact that unlike VaR this variable is in\ngeneral subadditive and therefore it is a Coherent Measure of Risk in the sense\nof reference (artzner)\n"
    },
    {
        "paper_id": "cond-mat/0102305",
        "authors": "D. Sornette (Univ. Nice/CNRS and UCLA) and Y. Malevergne (Univ.\n  Nice/CNRS)",
        "title": "From Rational Bubbles to Crashes",
        "comments": "Latex 27 pages with 3 eps figure",
        "journal-ref": "Physica A 299, 40-59 (2001)",
        "doi": "10.1016/S0378-4371(01)00281-3",
        "license": null,
        "abstract": "  We study and generalize in various ways the model of rational expectation\n(RE) bubbles introduced by Blanchard and Watson in the economic literature.\nFirst, bubbles are argued to be the equivalent of Goldstone modes of the\nfundamental rational pricing equation, associated with the symmetry-breaking\nintroduced by non-vanishing dividends. Generalizing bubbles in terms of\nmultiplicative stochastic maps, we summarize the result of Lux and Sornette\nthat the no-arbitrage condition imposes that the tail of the return\ndistribution is hyperbolic with an exponent mu<1. We then extend the RE bubble\nmodel to arbitrary dimensions d and, with the renewal theory for products of\nrandom matrices applied to stochastic recurrence equations, we extend the\ntheorem of Lux and Sornette to demonstrate that the tails of the unconditional\ndistributions follow power laws, with the same asymptotic tail exponent mu<1\nfor all assets. Two extensions (the crash hazard rate model and the\nnon-stationary growth rate model) of the RE bubble model provide ways of\nreconciliation with the stylized facts of financial data. The later model\nallows for an understanding of the breakdown of the fundamental valuation\nformula as deeply associated with a spontaneous breaking of the price symmetry.\nIts implementation for multi-dimensional bubbles explains why the tail index mu\nseems to be the same for any group af assets as observed empirically. This work\nbegs for the introduction of a generalized field theory which would be able to\ncapture the spontaneous breaking of symmetry, recover the fundamental valuation\nformula in the normal economic case and extend it to the still unexplored\nregime where the economic growth rate is larger than the discount growth rate.\n"
    },
    {
        "paper_id": "cond-mat/0102369",
        "authors": "F. Schmitt, D. Schertzer, S. Lovejoy",
        "title": "Multifractal fluctuations in finance",
        "comments": "4 pages, 2 figures",
        "journal-ref": "Int. J. Theor. Appl. Fin., 3, 3 (2000), 361-364",
        "doi": null,
        "license": null,
        "abstract": "  We consider the structure functions S^(q)(T), i.e. the moments of order q of\nthe increments X(t+T)-X(t) of the Foreign Exchange rate X(t) which give clear\nevidence of scaling (S^(q)(T)~T^z(q)). We demonstrate that the nonlinearity of\nthe observed scaling exponent z(q) is incompatible with monofractal additive\nstochastic models usually introduced in finance: Brownian motion, Levy\nprocesses and their truncated versions. This nonlinearity corresponds to\nmultifractal intermittency yielded by multiplicative processes. The\nnon-analycity of z(q) corresponds to universal multifractals, which are\nfurthermore able to produce ``hyperbolic'' pdf tails with an exponent q_D >2.\nWe argue that it is necessary to introduce stochastic evolution equations which\nare compatible with this multifractal behaviour.\n"
    },
    {
        "paper_id": "cond-mat/0102402",
        "authors": "S. Drozdz, J. Kwapien, F. Gruemmer, F. Ruf, J. Speth",
        "title": "Quantifying dynamics of the financial correlations",
        "comments": "10 pages, 7 PostScript figures, talk presented by the first Author at\n  the NATO ARW on Econophysics, Prague, February 8-10, 2001; to be published in\n  proceedings (Physica A)",
        "journal-ref": "Physica A, 299 (2001) 144",
        "doi": "10.1016/S0378-4371(01)00289-8",
        "license": null,
        "abstract": "  A novel application of the correlation matrix formalism to study dynamics of\nthe financial evolution is presented. This formalism allows to quantify the\nmemory effects as well as some potential repeatable intradaily structures in\nthe financial time-series. The present study is based on the high-frequency\nDeutsche Aktienindex (DAX) data over the time-period between November 1997 and\nDecember 1999 and demonstrates a power of the method. In this way two\nsignificant new aspects of the DAX evolution are identified: (i) the memory\neffects turn out to be sizably shorter than what the standard autocorrelation\nfunction analysis seems to indicate and (ii) there exist short term repeatable\nstructures in fluctuations that are governed by a distinct dynamics. The former\nof these results may provide an argument in favour of the market efficiency\nwhile the later one may indicate origin of the difficulty in reaching a\nGaussian limit, expected from the central limit theorem, in the distribution of\nreturns on longer time-horizons.\n"
    },
    {
        "paper_id": "cond-mat/0102423",
        "authors": "Sorin Solomon and Peter Richmond",
        "title": "Power Laws of Wealth, Market Order Volumes and Market Returns",
        "comments": "April 2: modified to include clarification and minor additions to\n  section 2",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00295-3",
        "license": null,
        "abstract": "  Using the Generalised Lotka Volterra (GLV) model adapted to deal with muti\nagent systems we can investigate economic systems from a general viewpoint and\nobtain generic features common to most economies. Assuming only weak generic\nassumptions on capital dynamics, we are able to obtain very specific\npredictions for the distribution of social wealth. First, we show that in a\n'fair' market, the wealth distribution among individual investors fulfills a\npower law. We then argue that 'fair play' for capital and minimal\nsocio-biological needs of the humans traps the economy within a power law\nwealth distribution with a particular Pareto exponent $\\alpha \\sim 3/2$. In\nparticular we relate it to the average number of individuals L depending on the\naverage wealth: $\\alpha \\sim L/(L-1)$. Then we connect it to certain power\nexponents characterising the stock markets. We obtain that the distribution of\nvolumes of the individual (buy and sell) orders follows a power law with\nsimilar exponent $\\beta \\sim \\alpha \\sim 3/2$. Consequently, in a market where\ntrades take place by matching pairs of such sell and buy orders, the\ncorresponding exponent for the market returns is expected to be of order\n$\\gamma \\sim 2 \\alpha \\sim 3$. These results are consistent with recent\nexperimental measurements of these power law exponents ([Maslov 2001] for\n$\\beta$ and [Gopikrishnan et al. 1999] for $\\gamma$).\n"
    },
    {
        "paper_id": "cond-mat/0102494",
        "authors": "C. Renner (1), J. Peinke (1) and R. Friedrich (2) ((1) University of\n  Oldenburg, (2) University of Stuttgart)",
        "title": "Markov properties of high frequency exchange rate data",
        "comments": "29 pages, 19 eps figures, misprints corrected, under consideration\n  for publication in Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00269-2",
        "license": null,
        "abstract": "  We present a stochastic analysis of a data set consisiting of 10^6 quotes of\nthe US Doller - German Mark exchange rate. Evidence is given that the price\nchanges x(tau) upon different delay times tau can be described as a Markov\nprocess evolving in tau. Thus, the tau-dependence of the probability density\nfunction (pdf) p(x) on the delay time tau can be described by a Fokker-Planck\nequation, a gerneralized diffusion equation for p(x,tau). This equation is\ncompletely determined by two coefficients D_{1}(x,tau) and D_{2}(x,tau) (drift-\nand diffusion coefficient, respectively). We demonstrate how these coefficients\ncan be estimated directly from the data without using any assumptions or models\nfor the underlying stochastic process. Furthermore, it is shown that the\nsolutions of the resulting Fokker-Planck equation describe the empirical pdfs\ncorrectly, including the pronounced tails.\n"
    },
    {
        "paper_id": "cond-mat/0102518",
        "authors": "Sergei Maslov, Mark Mills",
        "title": "Price fluctuations from the order book perspective - empirical facts and\n  a simple model",
        "comments": "To appear in proceedings of the NATO Advanced Research Workshop on\n  Application of Physics in Economic Modelling, Prague 2001. 8 figures",
        "journal-ref": "Physica A 299, 234-246 (2001).",
        "doi": "10.1016/S0378-4371(01)00301-6",
        "license": null,
        "abstract": "  Statistical properties of an order book and the effect they have on price\ndynamics were studied using the high-frequency NASDAQ Level II data. It was\nobserved that the size distribution of marketable orders (transaction sizes)\nhas power law tails with an exponent 1+mu_{market}=2.4 \\pm 0.1. The\ndistribution of limit order sizes was found to be consistent with a power law\nwith an exponent close to 2. A somewhat better fit to this distribution was\nobtained by using a log-normal distribution with an effective power law\nexponent equal to 2 in the middle of the observed range. The depth of the order\nbook measured as a price impact of a hypothetical large market order was\nobserved to be a non-linear function of its size. A large imbalance in the\nnumber of limit orders placed at bid and ask sides of the book was shown to\nlead to a short term deterministic price change, which is in accord with the\nlaw of supply and demand.\n"
    },
    {
        "paper_id": "cond-mat/0103020",
        "authors": "Y. Malevergne (Univ. Nice/CNRS) and D. Sornette (Univ. Nice/CNRS and\n  UCLA)",
        "title": "General framework for a portfolio theory with non-Gaussian risks and\n  non-linear correlations",
        "comments": "Latex document of 51 pages including 18 eps figures",
        "journal-ref": "18th International Conference in Finance, Namur - Belgium, 26, 27\n  & 28 JUNE 2001",
        "doi": null,
        "license": null,
        "abstract": "  Using a family of modified Weibull distributions, encompassing both\nsub-exponentials and super-exponentials, to parameterize the marginal\ndistributions of asset returns and their natural multivariate generalizations,\nwe give exact formulas for the tails and for the moments and cumulants of the\ndistribution of returns of a portfolio make of arbitrary compositions of these\nassets. Using combinatorial and hypergeometric functions, we are in particular\nable to extend previous results to the case where the exponents of the Weibull\ndistributions are different from asset to asset and in the presence of\ndependence between assets. We treat in details the problem of risk minimization\nusing two different measures of risks (cumulants and value-at-risk) for a\nportfolio made of two assets and compare the theoretical predictions with\ndirect empirical data. While good agreement is found, the remaining discrepancy\nbetween theory and data stems from the deviations from the Weibull\nparameterization for small returns. Our extended formulas enable us to\ndetermine analytically the conditions under which it is possible to ``have your\ncake and eat it too'', i.e., to construct a portfolio with both larger return\nand smaller ``large risks''.\n"
    },
    {
        "paper_id": "cond-mat/0103024",
        "authors": "D. Challet, M. Marsili and Y.-C. Zhang",
        "title": "Minority Games and stylized facts",
        "comments": "6 pages, 2 figures. Proceedings of the NATO Advanced Research\n  Workshop on Application of Physics in Economic Modelling, Prague 2001. 2nd\n  version: small modification of the abstract",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00300-4",
        "license": null,
        "abstract": "  The Minority Game is a generic model of competing adaptive agents, which is\noften believed to be a model of financial markets. We discuss to which extend\nthis is a reasonable statement, and present minimal modifications that make\nthis model reproduce stylized facts. The resulting model shows that without\nspeculators, prices follow random walks, and that stylized facts disappear if\nenough speculators take into account their market impact.\n"
    },
    {
        "paper_id": "cond-mat/0103033",
        "authors": "K. Ivanova and M. Ausloos",
        "title": "False EUR exchange rates vs. DKK, CHF, JPY and USD. What is a strong\n  currency?",
        "comments": "10 pages, 5 figures; to be published in Empirical sciences of\n  financial fluctuations, Tokyo, Japan, Nov. 15-17, 2000 Proceedings (Springer\n  Verlag, Berlin, 2001)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Euro (EUR) has been a currency introduced by the European Community on\nJan. 01, 1999. This implies eleven countries of the European Union which have\nbeen found to meet the five requirements of the Maastricht convergence\ncriteria. In order to test EUR behavior and understand various features, we\nhave extrapolated the EUR backwards and therefore have obtained a {\\it false\neuro} (FEUR) dating back to 1993. We have derived the exchange rates of the\nFEUR with respect to several currencies of interest not belonging to the EUR,\ni.e., Danish Kroner (DKK), Swiss Franc (CHF), Japanese Yen (JPY) and U.S.\nDollar (USD). We have first observed the distribution of fluctuations of the\nexchange rates. Within the {\\it Detrended Fluctuation Analysis} (DFA)\nstatistical method, we have calculated the power law behavior describing the\nroot-mean-square deviation of these exchange rate fluctuations as a function of\ntime, displaying in particular the JPY exchange rate case. In order to estimate\nthe role of each currency making the EUR and therefore in view of identifying\nwhether some of them mostly influences its behavior, we have compared the\ntime-dependent exponent of the exchange rate fluctuations for EUR with that for\nthe currencies that form the EUR. We have found that the German Mark (DEM) has\nbeen leading the fluctuations of EUR/JPY exchange rates, and Portuguese Escudo\n(PTE) is the farthest away currency from this point of view.\n"
    },
    {
        "paper_id": "cond-mat/0103106",
        "authors": "Lorenzo Matassini and Fabio Franci",
        "title": "How Traders enter the Market through the Book",
        "comments": "6 pages, pseudo-code of the model",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Simulation of the trading activity based on the implementation of the book.\n"
    },
    {
        "paper_id": "cond-mat/0103107",
        "authors": "Szilard Pafka, Imre Kondor",
        "title": "Evaluating the RiskMetrics Methodology in Measuring Volatility and\n  Value-at-Risk in Financial Markets",
        "comments": "7 pages, 1 figure",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00310-7",
        "license": null,
        "abstract": "  We analyze the performance of RiskMetrics, a widely used methodology for\nmeasuring market risk. Based on the assumption of normally distributed returns,\nthe RiskMetrics model completely ignores the presence of fat tails in the\ndistribution function, which is an important feature of financial data.\nNevertheless, it was commonly found that RiskMetrics performs satisfactorily\nwell, and therefore the technique has become widely used in the financial\nindustry. We find, however, that the success of RiskMetrics is the artifact of\nthe choice of the risk measure. First, the outstanding performance of\nvolatility estimates is basically due to the choice of a very short (one-period\nahead) forecasting horizon. Second, the satisfactory performance in obtaining\nValue-at-Risk by simply multiplying volatility with a constant factor is mainly\ndue to the choice of the particular significance level.\n"
    },
    {
        "paper_id": "cond-mat/0103170",
        "authors": "Zhi-Feng Huang and Sorin Solomon",
        "title": "Finite market size as a source of extreme wealth inequality and market\n  instability",
        "comments": "13 pages, 6 figures, Physica A, in press",
        "journal-ref": "Physica A 294, 503-513 (2001)",
        "doi": "10.1016/S0378-4371(01)00113-3",
        "license": null,
        "abstract": "  We study the finite-size effects in some scaling systems, and show that the\nfinite number of agents N leads to a cut-off in the upper value of the Pareto\nlaw for the relative individual wealth. The exponent $\\alpha$ of the Pareto law\nobtained in stochastic multiplicative market models is crucially affected by\nthe fact that N is always finite in real systems. We show that any finite value\nof N leads to properties which can differ crucially from the naive theoretical\nresults obtained by assuming an infinite N. In particular, finite N may cause\nin the absence of an appropriate social policy extreme wealth inequality\n$\\alpha < 1$ and market instability.\n"
    },
    {
        "paper_id": "cond-mat/0103397",
        "authors": "Sergei Maslov",
        "title": "Measures of globalization based on cross-correlations of world financial\n  indices",
        "comments": "Significantly extended version with 2 new figures. Now: 4 pages, 5\n  figures, 1 table",
        "journal-ref": "Physica A 301, 397-406 (2001).",
        "doi": "10.1016/S0378-4371(01)00370-3",
        "license": null,
        "abstract": "  The cross-correlation matrix of daily returns of stock market indices in a\ndiverse set of 37 countries worldwide was analyzed. Comparison of the spectrum\nof this matrix with predictions of random matrix theory provides an empirical\nevidence of strong interactions between individual economies, as manifested by\nthree largest eigenvalues and the corresponding set of stable, non-random\neigenvectors. The observed correlation structure is robust with respect to\nchanges in the time horizon of returns ranging from 1 to 10 trading days, and\nto replacing individual returns with just their signs. This last observation\nconfirms that it is mostly correlations in signs and not absolute values of\nfluctuations, which are responsible for the observed effect. Correlations\nbetween different trading days seem to persist for up to 3 days before decaying\nto the level of the background noise.\n"
    },
    {
        "paper_id": "cond-mat/0103544",
        "authors": "Adrian Dragulescu, Victor M. Yakovenko",
        "title": "Exponential and power-law probability distributions of wealth and income\n  in the United Kingdom and the United States",
        "comments": "8 pages, 6 figures, elsart.cls. Submitted to Physica A, proceedings\n  of NATO workshop Applications of Physics in Economic Modeling, Prague,\n  February 2001. V.2: minor stylistic expansion",
        "journal-ref": "Physica A 299, 213 (2001)",
        "doi": "10.1016/S0378-4371(01)00298-9",
        "license": null,
        "abstract": "  We present the data on wealth and income distributions in the United Kingdom,\nas well as on the income distributions in the individual states of the USA. In\nall of these data, we find that the great majority of population is described\nby an exponential distribution, whereas the high-end tail follows a power law.\nThe distributions are characterized by a dimensional scale analogous to\ntemperature. The values of temperature are determined for the UK and the USA,\nas well as for the individual states of the USA.\n"
    },
    {
        "paper_id": "cond-mat/0103600",
        "authors": "Marco Raberto and Silvano Cincotti and Sergio M. Focardi and Michele\n  Marchesi",
        "title": "Agent-based simulation of a financial market",
        "comments": "11 pages, 3 EPS figures, LaTEX. To be published in Physica A\n  (Proceedings of the NATO Advanced Research Workshop on Application of Physics\n  in Economic Modelling, Prague 8-10 February 2001)",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00312-0",
        "license": null,
        "abstract": "  This paper introduces an agent-based artificial financial market in which\nheterogeneous agents trade one single asset through a realistic trading\nmechanism for price formation. Agents are initially endowed with a finite\namount of cash and a given finite portfolio of assets. There is no\nmoney-creation process; the total available cash is conserved in time. In each\nperiod, agents make random buy and sell decisions that are constrained by\navailable resources, subject to clustering, and dependent on the volatility of\nprevious periods. The model herein proposed is able to reproduce the\nleptokurtic shape of the probability density of log price returns and the\nclustering of volatility. Implemented using extreme programming and\nobject-oriented technology, the simulator is a flexible computational\nexperimental facility that can find applications in both academic and\nindustrial research projects.\n"
    },
    {
        "paper_id": "cond-mat/0103606",
        "authors": "S.Drozdz, F.Gruemmer, F.Ruf, J.Speth",
        "title": "Dynamics of correlations in the stock market",
        "comments": "10 pages, 5 figures, LaTeX2e, to appear in \"Empirical Science of\n  Financial Fluctuations\", Tokyo, Nov. 2000 (Springer Verlag 2001)",
        "journal-ref": "Empirical Science of Financial Fluctuations, H. Takayasu (Ed.),\n  Springer-Verlag Tokio 2002, p.41",
        "doi": null,
        "license": null,
        "abstract": "  Financial empirical correlation matrices of all the companies which both, the\nDeutsche Aktienindex (DAX) and the Dow Jones comprised during the time period\n1990-1999 are studied using a time window of a limited, either 30 or 60, number\nof trading days. This allows a clear identification of the resulting\ncorrelations. On both these markets the decreases turn out to be always\naccompanied by a sizable separation of one strong collective eigenstate of the\ncorrelation matrix, while increases are more competitive and thus less\ncollective. Generically, however, the remaining eigenstates of the correlation\nmatrix are, on average, consistent with predictions of the random matrix\ntheory. Effects connected with the world globalization are also discussed and a\nleading role of the Dow Jones is quantified. This effect is particularly\nspectacular during the last few years, and it turns out to be crucial to\nproperly account for the time-zone delays in order to identify it.\n"
    },
    {
        "paper_id": "cond-mat/0103621",
        "authors": "Rafal Weron",
        "title": "Measuring long-range dependence in electricity prices",
        "comments": "7 pages, 2 figures. To appear in \"Empirical Science of Financial\n  Fluctuations\", Tokyo, Nov. 2000 (Springer Verlag 2001)",
        "journal-ref": "in H. Takayasu ed., \"Empirical Science of Financial Fluctuations\"\n  (Springer-Verlag Tokyo, 2002), pp. 110-119",
        "doi": null,
        "license": null,
        "abstract": "  The price of electricity is far more volatile than that of other commodities\nnormally noted for extreme volatility. The possibility of extreme price\nmovements increases the risk of trading in electricity markets. However,\nunderlying the process of price returns is a strong mean-reverting mechanism.\nWe study this feature of electricity returns by means of Hurst R/S analysis,\nDetrended Fluctuation Analysis and periodogram regression.\n"
    },
    {
        "paper_id": "cond-mat/0104080",
        "authors": "Giulia Iori and Saqib Jafarey",
        "title": "Criticality in a model of banking crises",
        "comments": "presented at the conference Application of Physics in Economic\n  Modelling, February 8 - 10, 2001, Prague",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00297-7",
        "license": null,
        "abstract": "  An interbank market lets participants pool the risk arising from the\ncombination of illiquid investments and random withdrawals by depositors. But\nit also creates the potential for one bank's failure to trigger off avalanches\nof further failures. We simulate a model of interbank lending to study the\ninterplay of these two effects. We show that when banks are similar in size and\nexposure to risk, avalanche effects are small so that widening the interbank\nmarket leads to more stability. But as heterogeneity increases, avalanche\neffects become more important. By varying the heterogeneity and connectivity\nacross banks, the system enters a critical regime with a power law distribution\nof avalanche sizes.\n"
    },
    {
        "paper_id": "cond-mat/0104127",
        "authors": "M. Ausloos, K. Ivanova and N. Vandewalle",
        "title": "Crashes : symptoms, diagnoses and remedies",
        "comments": "15 pages, 5 figures; to appear in Empirical Science of Financial\n  Fluctuations, Tokyo, Japan, Nov. 15-17, 2000 Proceedings} (Springer Verlag,\n  Berlin, 2001) corrected misprint in Ref. 21",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A brief historical perspective is first given concerning financial crashes, -\nfrom the 17th till the 20th century. In modern times, it seems that log\nperiodic oscillations are found before crashes in several financial indices.\nThe same is found in sand pile avalanches on Sierpinski gaskets. A discussion\npertains to the after shock period with illustrations from the DAX index. The\nfactual financial observations and the laboratory ones allow us some conjecture\non symptoms and remedies for discussing financial crashes along econophysics\nlines.\n"
    },
    {
        "paper_id": "cond-mat/0104260",
        "authors": "M. Ausloos and K. Ivanova",
        "title": "Correlations Between Reconstructed EUR Exchange Rates vs. CHF, DKK, GBP,\n  JPY and USD",
        "comments": "30 pages, 8 figures; to appear in Intrn J Modern Phys",
        "journal-ref": null,
        "doi": "10.1142/S0129183101001572",
        "license": null,
        "abstract": "  On Jan. 1, 1999 the European Union introduced a common currency Euro ($EUR$),\nto become the legal currency in all eleven countries which form the $EUR$. In\norder to test the $EUR$ behavior and understand various features, the $EUR$\nexchange rate is artificially extrapolated back to 1993 by a linear\nsuperposition of the exchange rates of the 11 currencies composing $EUR$ with\nrespect to several currencies not belonging to the $EUR$, i.e. Swiss Franc\n($CHF$), Danish Kroner ($DKK$), British Pound ($GBP$), Japanese Yen ($JPY$) and\nU.S. Dollar ($USD$) of interest for reasons given in the text. The distribution\nof fluctuations of the exchange rates is shown to be Gaussian for the central\npart of the distribution, and having fat tails for the large size fluctuations.\nWithin the {\\it Detrended Fluctuation Analysis} ($DFA$) statistical method we\nhave obtained the power law behavior describing the root-mean-square deviation\nof the exchange rate fluctuations as a function of time. For the period between\nJan. 1995 and Jan. 1999 we have compared the time-dependent exponent of these\nexchange rate fluctuations for $EUR$ and that of the 11 currencies which form\nthe $EUR$. The German Mark ($DEM$) and the French Franc ($FRF$) have been the\ncurrencies primarily leading the fluctuations of the exchange rates, while\nItalian Lira ($ITL$) and ($PTE$) Portuguese Escudo are the less relevant\ncurrencies from this point of view. Technical considerations for the $EUR$\nimplementation are given as conclusions. The cases of exchange rates with $DKK$\nappear quite different from the other four major currencies.\n"
    },
    {
        "paper_id": "cond-mat/0104295",
        "authors": "Carlo Acerbi, Dirk Tasche",
        "title": "On the coherence of Expected Shortfall",
        "comments": "18 pages, LaTeX + pdfLaTeX, appendix added",
        "journal-ref": "Journal of Banking & Finance 26, 2002, pp. 1487-1503",
        "doi": null,
        "license": null,
        "abstract": "  Expected Shortfall (ES) in several variants has been proposed as remedy for\nthe defi-ciencies of Value-at-Risk (VaR) which in general is not a coherent\nrisk measure. In fact, most definitions of ES lead to the same results when\napplied to continuous loss distributions. Differences may appear when the\nunderlying loss distributions have discontinuities. In this case even the\ncoherence property of ES can get lost unless one took care of the details in\nits definition. We compare some of the definitions of Expected Shortfall,\npointing out that there is one which is robust in the sense of yielding a\ncoherent risk measure regardless of the underlying distributions. Moreover,\nthis Expected Shortfall can be estimated effectively even in cases where the\nusual estimators for VaR fail.\n  Key words: Expected Shortfall; Risk measure; worst conditional expectation;\ntail con-ditional expectation; value-at-risk (VaR); conditional value-at-risk\n(CVaR); tail mean; co-herence; quantile; sub-additivity.\n"
    },
    {
        "paper_id": "cond-mat/0104305",
        "authors": "Ingve Simonsen and Kim Sneppen",
        "title": "Profit Profiles in Correlated Markets",
        "comments": "5 pages, 4 figures",
        "journal-ref": "Physica A 316, 561 (2002)",
        "doi": "10.1016/S0378-4371(02)01024-5",
        "license": null,
        "abstract": "  We consider a financial market where the asset price follows a fractional\nBrownian motion. We introduce a family of investment strategies, and quantify\nprofit possibilities for both persistent and antipersistant markets.\n"
    },
    {
        "paper_id": "cond-mat/0104313",
        "authors": "Aki-Hiro Sato and Hideki Takayasu",
        "title": "Derivation of ARCH(1) process from market price changes based on\n  deterministic microscopic multi-agent",
        "comments": "12 pages, 5 figures; appears to Proceedings of Empirical Science of\n  Financial Fluctuations - Econophysics on the Horizon, Ed. by H.Takayasu",
        "journal-ref": "Proceedings of Empirical Science of Financial Fluctuations -\n  Econophysics on the Horizon, (2002), pp. 172--178",
        "doi": null,
        "license": null,
        "abstract": "  A model of fluctuations in the market price including many deterministic\ndealers, who predict their buying and selling prices from the latest price\nchange, is developed. We show that price changes of the model is approximated\nby ARCH(1) process. We conclude that predictions of dealers affected by the\npast price changes cause the fat tails of probability density function. We\nbelieve that this study bridges stochastic processes in econometrics with\nmulti-agent simulation approaches.\n"
    },
    {
        "paper_id": "cond-mat/0104318",
        "authors": "Aki-Hiro Sato and Hideki Takayasu",
        "title": "Market price simulator based on analog electrical circuit",
        "comments": "13 pages, 8 figures; appears to Proceedings of Empirical Science of\n  Financial Fluctuations - Econophysics on the Horizon, Ed. by H.Takayasu",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We constructed an analog electrical circuit which generates fluctuations in\nwhich probability density function has power law tails. In the circuit\nfluctuations with an arbitrary exponent of the power law can be obtained by\nadjusting the resistance. With this low cost circuit the random fluctuations\nwhich have the similar statistics to foreign exchang rates can be generated as\nfast as an expensive digital computer.\n"
    },
    {
        "paper_id": "cond-mat/0104337",
        "authors": "Andrea Capocci and Yi-Cheng Zhang",
        "title": "Market ecology of active and passive investors",
        "comments": "16 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00256-4",
        "license": null,
        "abstract": "  We study the role of active and passive investors in an investment market\nwith uncertainties. Active investors concentrate on a single or a few stocks\nwith a given probability of determining the quality of them. Passive investors\nspread their investment uniformly, resembling buying the market index. In this\ntoy market stocks are introduced as good and bad. If a stock receives\nsufficient investment it will survive, otherwise die. Active players exert a\nselective pressure since they can determine to an extent the investment\nquality. We show that the active players provide the driving force whereas the\npassive ones act as free riders. While their gains do not differ too much, we\nshow that the active players enjoy an edge. Their presence also provides better\ngains to the passive players and stocks themselves.\n"
    },
    {
        "paper_id": "cond-mat/0104341",
        "authors": "D. Sornette (Univ. Nice/CNRS and UCLA) and J.V. Andersen (Univ.\n  Nice/CNRS)",
        "title": "A Nonlinear Super-Exponential Rational Model of Speculative Financial\n  Bubbles",
        "comments": "Latex document of 24 pages including 5 eps figures",
        "journal-ref": "Int. J. Mod. Phys. C 13 (2), 171-188 (2002)",
        "doi": "10.1142/S0129183102003085",
        "license": null,
        "abstract": "  Keeping a basic tenet of economic theory, rational expectations, we model the\nnonlinear positive feedback between agents in the stock market as an interplay\nbetween nonlinearity and multiplicative noise. The derived hyperbolic\nstochastic finite-time singularity formula transforms a Gaussian white noise\ninto a rich time series possessing all the stylized facts of empirical prices,\nas well as accelerated speculative bubbles preceding crashes. We use the\nformula to invert the two years of price history prior to the recent crash on\nthe Nasdaq (april 2000) and prior to the crash in the Hong Kong market\nassociated with the Asian crisis in early 1994. These complex price dynamics\nare captured using only one exponent controlling the explosion, the variance\nand mean of the underlying random walk. This offers a new and powerful\ndetection tool of speculative bubbles and herding behavior.\n"
    },
    {
        "paper_id": "cond-mat/0104362",
        "authors": "Fabrizio Lillo, Giovanni Bonanno and Rosario N. Mantegna",
        "title": "Variety of Stock Returns in Normal and Extreme Market Days: The August\n  1998 Crisis",
        "comments": "13 pages, 7 figures. To appear in Proceedings of Empirical Science of\n  Financial Fluctuations, Econophysics on the Horizon, Ed by H. Takayasu",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate the recently introduced variety of a set of stock returns\ntraded in a financial market. This investigation is done by considering daily\nand intraday time horizons in a 15-day time period centered at the August 31st,\n1998 crash of the S&P500 index. All the stocks traded at the NYSE during that\nperiod are considered in the present analysis. We show that the statistical\nproperties of the variety observed in analyses of daily returns also hold for\nintraday returns. In particular the largest changes of the variety of the\nreturn distribution turns out to be most localized at the opening or (to a less\ndegree) at the closing of the market.\n"
    },
    {
        "paper_id": "cond-mat/0104369",
        "authors": "Giovanni Bonanno, Fabrizio Lillo, Rosario N. Mantegna",
        "title": "Levels of complexity in financial markets",
        "comments": "14 pages, 5 figures, to appear on Physica A, Proceedings of the NATO\n  Advanced Research Workshop on Application of Physics in Economic Modeling,\n  Prague February 8-10 2001",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00279-5",
        "license": null,
        "abstract": "  We consider different levels of complexity which are observed in the\nempirical investigation of financial time series. We discuss recent empirical\nand theoretical work showing that statistical properties of financial time\nseries are rather complex under several ways. Specifically, they are complex\nwith respect to their (i) temporal and (ii) ensemble properties. Moreover, the\nensemble return properties show a behavior which is specific to the nature of\nthe trading day reflecting if it is a normal or an extreme trading day.\n"
    },
    {
        "paper_id": "cond-mat/0104456",
        "authors": "Kestutis Staliunas",
        "title": "Anticorrelations, subbrownian stochastic drift, and 1/f-like spectra in\n  stable financial systems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Statistic dynamics of financial systems is investigated, basing on a model of\nrandomly coupled equation system driven by stochastic Langevin force. It is\nfound that in stable regime the noise power spectrum of the system is of\n1/f^alpha form, with the exponent alpha=3/2 in case of Hermitian coupling\nmatrices, or slightly larger (up to 5/3) in nonhermitian case. In all cases it\nleads to negative autocorrelation function of the increments of the variables\n(prices, exchange rates), and to subbrownian stochastic drift of the variables.\nThe model can be generalized to arbitrary stable, driven by noise system of\nrandomly coupled components.\n"
    },
    {
        "paper_id": "cond-mat/0104472",
        "authors": "R. Mansilla",
        "title": "Algorithmic Complexity in Real Financial Markets",
        "comments": "19 pages, 5 figures, submitted to Physica A",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A new approach to the understanding of complex behavior of financial markets\nindex using tools from thermodynamics and statistical physics is developed.\nPhysical complexity, a magnitude rooted in Kolmogorov-Chaitin theory is applied\nto binary sequences built up from real time series of financial markets\nindexes. The study is based on NASDAQ and Mexican IPC data. Different behaviors\nof this magnitude are shown when applied to the intervals of series placed\nbefore crashes and to intervals when no financial turbulence is observed. The\nconnection between our results and The Efficient Market Hypothesis is\ndiscussed.\n"
    },
    {
        "paper_id": "cond-mat/0104547",
        "authors": "Frantisek Slanina",
        "title": "Mean-field approximation for a limit order driven market model",
        "comments": "5 pages, no figures, revtex",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.64.056136",
        "license": null,
        "abstract": "  The mean-field variant of the model of limit order driven market introduced\nrecently by Maslov is formulated and solved. The agents do not have any\nstrategies and the memory of the system is kept within the order book. We show\nthat he evolution of the order book is governed by a matrix multiplicative\nprocess. The resulting stationary distribution of step-to-step price changes is\ncalculated. It exhibits a power-law tail with exponent 2. We obtain also the\nprice autocorrelation function, which agrees qualitatively with the\nexperimentally observed negative autocorrelation for short times.\n"
    },
    {
        "paper_id": "cond-mat/0105076",
        "authors": "Irene Giardina, Jean-Philippe Bouchaud and Marc M\\'ezard",
        "title": "Microscopic Models for Long Ranged Volatility Correlations",
        "comments": "12 pages, 4 figures. Proceedings of the NATO Advanced Research\n  Workshop \"Application of Physics to Economic Modelling \", Praga (8-10\n  February 2001). To be published in Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00280-1",
        "license": null,
        "abstract": "  We propose a general interpretation for long-range correlation effects in the\nactivity and volatility of financial markets. This interpretation is based on\nthe fact that the choice between `active' and `inactive' strategies is\nsubordinated to random-walk like processes. We numerically demonstrate our\nscenario in the framework of simplified market models, such as the Minority\nGame model with an inactive strategy, or a more sophisticated version that\nincludes some price dynamics. We show that real market data can be surprisingly\nwell accounted for by these simple models.\n"
    },
    {
        "paper_id": "cond-mat/0105162",
        "authors": "Gilles Zumbach, Paul Lynch",
        "title": "Heterogeneous volatility cascade in financial markets",
        "comments": "10 pages, 2 figures, To be published in Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00249-7",
        "license": null,
        "abstract": "  Using high frequency data, we have studied empirically the change of\nvolatility, also called volatility derivative, for various time horizons. In\nparticular, the correlation between the volatility derivative and the\nvolatility realized in the next time period is a measure of the response\nfunction of the market participants. This correlation shows explicitly the\nheterogeneous structure of the market according to the characteristic time\nhorizons of the differents agents. It reveals a volatility cascade from long to\nshort time horizons, with a structure different from the one observed in\nturbulence. Moreover, we have developed a new ARCH-type model which\nincorporates the different groups of agents, with their characteristic memory.\nThis model reproduces well the empirical response function, and allows us to\nquantify the importance of each group.\n"
    },
    {
        "paper_id": "cond-mat/0105191",
        "authors": "Carlo Acerbi, Dirk Tasche",
        "title": "Expected Shortfall: a natural coherent alternative to Value at Risk",
        "comments": "to be published on \"Wilmott Magazine\" (http://www.wilmott.com)",
        "journal-ref": "Economic notes, 31(2), 379-388, 2002",
        "doi": null,
        "license": null,
        "abstract": "  We discuss the coherence properties of Expected Shortfall (ES) as a financial\nrisk measure. This statistic arises in a natural way from the estimation of the\n\"average of the 100p % worst losses\" in a sample of returns to a portfolio.\nHere p is some fixed confidence level. We also compare several alternative\nrepresentations of ES which turn out to be more appropriate for certain\npurposes.\n"
    },
    {
        "paper_id": "cond-mat/0105303",
        "authors": "N. F. Johnson, D. Lamper, P. Jefferies, M. L. Hart, S. Howison",
        "title": "Application of multi-agent games to the prediction of financial\n  time-series",
        "comments": "Work presented at the NATO Workshop on Econophysics. Prague (Feb\n  2001). To appear in Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00299-0",
        "license": null,
        "abstract": "  We report on a technique based on multi-agent games which has potential use\nin the prediction of future movements of financial time-series. A third-party\ngame is trained on a black-box time-series, and is then run into the future to\nextract next-step and multi-step predictions. In addition to the possibility of\nidentifying profit opportunities, the technique may prove useful in the\ndevelopment of improved risk management strategies.\n"
    },
    {
        "paper_id": "cond-mat/0105373",
        "authors": "Yi-Cheng Zhang",
        "title": "Why Financial Markets Will Remain Marginally Inefficient?",
        "comments": "5 pages, 1 figure. based on a speech at Tokyo Econophysics Meeting,\n  Nov 14th 2000",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  I summarize the recent work on market (in)efficiency, highlighting key\nelements why financial markets will never be made efficient. My approach is not\nby adding more empirical evidence, but giving plausible reasons as to where\ninefficiency arises and why it's not rational to arbitrage it away.\n"
    },
    {
        "paper_id": "cond-mat/0105573",
        "authors": "Iksoo Chang and Dietrich Stauffer",
        "title": "Time-reversal asymmetry in Cont-Bouchaud stock market model",
        "comments": "2 pages text in TeX, two figures, all in one postscript file",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00270-9",
        "license": null,
        "abstract": "  The percolation model of stock market speculation allows an asymmetry (in the\nreturn distribution) leading to fast downward crashes and slow upward recovery.\nWe see more small upturns and more intermediate downturns.\n"
    },
    {
        "paper_id": "cond-mat/0106114",
        "authors": "Damien Challet and Robin Stinchcombe",
        "title": "Analyzing and modelling 1+1d markets",
        "comments": "17 pages, 14 figures, small typos correction",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00335-1",
        "license": null,
        "abstract": "  We report a statistical analysis of the Island ECN (NASDAQ) order book. We\ndetermine the static and dynamic properties of this system, and then analyze\nthem from a physicist's viewpoint using an equivalent particle system obtained\nby treating orders as massive particles and price as position. We identify the\nfundamental dynamical processes, test existing particles models of such markets\nagainst our findings, and introduce a new model of limit order markets.\n"
    },
    {
        "paper_id": "cond-mat/0106317",
        "authors": "Belal E. Baaquie and Srikant Marakani",
        "title": "Empirical investigation of a quantum field theory of forward rates",
        "comments": "6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A new test of a wide class of interest rate models is proposed and applied to\na recently developed quantum field theoretic model and the industry standard\nHeath-Jarrow-Morton model. This test is independent of the volatility function\nunlike other tests previously proposed in the literature. It is found that the\nHJM model is inconsistent with the data while the quantum field theoretic model\nis in significant agreement with data. We also show that a portion of the\nspread between long and short term interest rates is explicable in terms of\nthis model.\n"
    },
    {
        "paper_id": "cond-mat/0106401",
        "authors": "Ari Belenkiy",
        "title": "Inner Market as a \"Black Box\"",
        "comments": "6 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Each market has its singular characteristic. Its inner structure is directly\nresponsible for the observed distributions of returns though this fact is\nwidely overlooked. Big orders lead to doubling the tails. The behavior of a\nmarket maker with many or few ``friends'' who can reliably loan money or stock\nto him is quite different from the one without. After representing the inner\nmarket ``case'' we suggest how to analyze its structure.\n"
    },
    {
        "paper_id": "cond-mat/0106520",
        "authors": "D. Sornette (Univ. Nice/CNRS and UCLA) and A. Johansen (The Niels Bohr\n  Institute)",
        "title": "Significance of log-periodic precursors to financial crashes",
        "comments": "Latex document of 38 pages including 16 eps figures and 3 tables, in\n  press in Quantitative Finance",
        "journal-ref": "Quantitative Finance 1 (4), 452-471 (2001)",
        "doi": null,
        "license": null,
        "abstract": "  We clarify the status of log-periodicity associated with speculative bubbles\npreceding financial crashes. In particular, we address Feigenbaum's [2001]\ncriticism and show how it can be rebuked. Feigenbaum's main result is as\nfollows: ``the hypothesis that the log-periodic component is present in the\ndata cannot be rejected at the 95% confidence level when using all the data\nprior to the 1987 crash; however, it can be rejected by removing the last year\nof data.'' (e.g., by removing 15% of the data closest to the critical point).\nWe stress that it is naive to analyze a critical point phenomenon, i.e., a\npower law divergence, reliably by removing the most important part of the data\nclosest to the critical point. We also present the history of log-periodicity\nin the present context explaining its essential features and why it may be\nimportant. We offer an extension of the rational expectation bubble model for\ngeneral and arbitrary risk-aversion within the general stochastic discount\nfactor theory. We suggest guidelines for using log-periodicity and explain how\nto develop and interpret statistical tests of log-periodicity. We discuss the\nissue of prediction based on our results and the evidence of outliers in the\ndistribution of drawdowns. New statistical tests demonstrate that the 1% to 10%\nquantile of the largest events of the population of drawdowns of the Nasdaq\ncomposite index and of the Dow Jones Industrial Average index belong to a\ndistribution significantly different from the rest of the population. This\nsuggests that very large drawdowns result from an amplification mechanism that\nmay make them more predictable than smaller market moves.\n"
    },
    {
        "paper_id": "cond-mat/0106635",
        "authors": "A.C.C. Coolen, J.A.F. Heimel and D. Sherrington",
        "title": "Dynamics of the Batch Minority Game with Inhomogeneous Decision Noise",
        "comments": "14 pages LaTeX, 8 postscript figures, in PRE style (minor textual\n  changes in revision)",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.65.016126",
        "license": null,
        "abstract": "  We study the dynamics of a version of the batch minority game, with random\nexternal information and with different types of inhomogeneous decision noise\n(additive and multiplicative), using generating functional techniques \\`{a} la\nDe Dominicis. The control parameters in this model are the ratio $\\alpha=p/N$\nof the number $p$ of possible values for the external information over the\nnumber $N$ of trading agents, and the statistical properties of the agents'\ndecision noise parameters. The presence of decision noise is found to have the\ngeneral effect of damping macroscopic oscillations, which explains why in\ncertain parameter regions it can effectively reduce the market volatility, as\nobserved in earlier studies. In the limit $N\\to\\infty$ we (i) solve the first\nfew time steps of the dynamics (for any $\\alpha$), (ii) calculate the location\n$\\alpha_c$ of the phase transition (signaling the onset of anomalous response),\nand (iii) solve the statics for $\\alpha>\\alpha_c$. We find that $\\alpha_c$ is\nnot sensitive to additive decision noise, but we arrive at non-trivial phase\ndiagrams in the case of multiplicative noise. Our theoretical results find\nexcellent confirmation in numerical simulations.\n"
    },
    {
        "paper_id": "cond-mat/0106657",
        "authors": "Vasiliki Plerou, Parameswaran Gopikrishnan, Xavier Gabaix, and H.\n  Eugene Stanley",
        "title": "Quantifying Stock Price Response to Demand Fluctuations",
        "comments": "4 pages (multicol fomat, revtex)",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.66.027104",
        "license": null,
        "abstract": "  We address the question of how stock prices respond to changes in demand. We\nquantify the relations between price change $G$ over a time interval $\\Delta t$\nand two different measures of demand fluctuations: (a) $\\Phi$, defined as the\ndifference between the number of buyer-initiated and seller-initiated trades,\nand (b) $\\Omega$, defined as the difference in number of shares traded in buyer\nand seller initiated trades. We find that the conditional expectations $<G\n>_{\\Omega}$ and $<G >_{\\Phi}$ of price change for a given $\\Omega$ or $\\Phi$\nare both concave. We find that large price fluctuations occur when demand is\nvery small --- a fact which is reminiscent of large fluctuations that occur at\ncritical points in spin systems, where the divergent nature of the response\nfunction leads to large fluctuations.\n"
    },
    {
        "paper_id": "cond-mat/0107150",
        "authors": "Rui Carvalho",
        "title": "The Dynamics of the Linear Random Farmer Model",
        "comments": "35 pages, 4 figures to appear in The Proceedings of Complex Behavior\n  in Economics- Modelling, Computing and Mastering Complexity",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  On the framework of the Linear Farmer's Model, we approach the indeterminacy\nof agents' behaviour by associating with each agent an unconditional\nprobability for her to be active at each time step.\n  We show that Pareto tailed returns can appear even if value investors are the\nonly strategies on the market and give a procedure for the determination of the\ntail exponent.\n  Numerical results indicate that the returns' distribution is heavy tailed and\nvolatility is clustered if trading occurs at the zero Lyapunov (critical)\npoint.\n"
    },
    {
        "paper_id": "cond-mat/0107190",
        "authors": "Carlo Acerbi",
        "title": "Risk Aversion and Coherent Risk Measures: a Spectral Representation\n  Theorem",
        "comments": "11 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study a space of coherent risk measures M_phi obtained as certain\nexpansions of coherent elementary basis measures. In this space, the concept of\n``Risk Aversion Function'' phi naturally arises as the spectral representation\nof each risk measure in a space of functions of confidence level probabilities.\nWe give necessary and sufficient conditions on phi for M_phi to be a coherent\nmeasure. We find in this way a simple interpretation of the concept of\ncoherence and a way to map any rational investor's subjective risk aversion\nonto a coherent measure and vice--versa. We also provide for these measures\ntheir discrete versions M_phi^N acting on finite sets of N independent\nrealizations of a r.v. which are not only shown to be coherent measures for any\nfixed N, but also consistent estimators of M_phi for large N. Finally, we find\nin our results some interesting and not yet fully investigated relationships\nwith certain results known in insurance mathematical literature.\n"
    },
    {
        "paper_id": "cond-mat/0107208",
        "authors": "Fabrizio Lillo, Rosario N. Mantegna, Jean-Philippe Bouchaud and Marc\n  Potters",
        "title": "Introducing Variety in Risk Management",
        "comments": "12 pages, 5 figures, to appear in Risk",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We review the recently introduced concept of variety of a financial portfolio\nand we sketch its importance for risk control purposes. The empirical behaviour\nof variety, correlation, exceedance correlation and asymmetry of the\nprobability density function of daily returns is discussed. The results\nobtained are compared with the ones of a one-factor model showing strengths and\nlimitations of this model.\n"
    },
    {
        "paper_id": "cond-mat/0107256",
        "authors": "Fabrizio Lillo and Rosario N. Mantegna",
        "title": "Ensemble properties of securities traded in the NASDAQ market",
        "comments": "7 pages, 3 figures, to appear in the proceedings of NATO ARW on\n  Application of Physics in Economic Modelling, Prague, 8-10 February 2001",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(01)00291-6",
        "license": null,
        "abstract": "  We study the price dynamics of stocks traded in the NASDAQ market by\nconsidering the statistical properties of an ensemble of stocks traded\nsimultaneously. For each trading day of our database, we study the ensemble\nreturn distribution by extracting its first two central moments. According to\nprevious results obtained for the NYSE market, we find that the second moment\nis a long-range correlated variable. We compare time-averaged and\nensemble-averaged price returns and we show that the two averaging procedures\nlead to different statistical results.\n"
    },
    {
        "paper_id": "cond-mat/0107593",
        "authors": "Marco Airoldi (Risk Management & Research, Intesa-Bci Bank)",
        "title": "Correlation Structure and Fat Tails in Finance: a New Mechanism",
        "comments": "7 pages, 4 figures, submitted to Physical Review E on 27 July 2001",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Fat tails in financial time series and increase of stocks cross-correlations\nin high volatility periods are puzzling facts that ask for new paradigms. Both\npoints are of key importance in fundamental research as well as in Risk\nManagement (where extreme losses play a key role). In this paper we present a\nnew model for an ensemble of stocks that aims to encompass in a unitary picture\nboth these features. Equities are modelled as quasi random walk variables,\nwhere the non-Brownian components of stocks movements are leaded by the market\ntrend, according to typical trader strategies. Our model suggests that\ncollective effects may play a very important role in the characterization of\nsome significantly statistical properties of financial time series.\n"
    },
    {
        "paper_id": "cond-mat/0107600",
        "authors": "A C C Coolen and J A F Heimel",
        "title": "Dynamical Solution of the On-Line Minority Game",
        "comments": "25 pages LaTeX, no figures",
        "journal-ref": null,
        "doi": "10.1088/0305-4470/34/49/304",
        "license": null,
        "abstract": "  We solve the dynamics of the on-line minority game, with general types of\ndecision noise, using generating functional techniques a la De Dominicis and\nthe temporal regularization procedure of Bedeaux et al. The result is a\nmacroscopic dynamical theory in the form of closed equations for correlation-\nand response functions defined via an effective continuous-time single-trader\nprocess, which are exact in both the ergodic and in the non-ergodic regime of\nthe minority game. Our solution also explains why, although one cannot formally\ntruncate the Kramers-Moyal expansion of the process after the Fokker-Planck\nterm, upon doing so one still finds the correct solution, that the previously\nproposed diffusion matrices for the Fokker-Planck term are incomplete, and how\npreviously proposed approximations of the market volatility can be traced back\nto ergodicity assumptions.\n"
    },
    {
        "paper_id": "cond-mat/0108017",
        "authors": "Fredrick Michael and M.D. Johnson",
        "title": "Financial Market Dynamics",
        "comments": "8 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Distributions derived from non-extensive Tsallis statistics are closely\nconnected with dynamics described by a nonlinear Fokker-Planck equation. The\ncombination shows promise in describing stochastic processes with power-law\ndistributions and superdiffusive dynamics. We investigate intra-day price\nchanges in the S&P500 stock index within this framework by direct analysis and\nby simulation. We find that the power-law tails of the distributions, and the\nindex's anomalously diffusing dynamics, are very accurately described by this\napproach. Our results show good agreement between market data, Fokker-Planck\ndynamics, and simulation. Thus the combination of the Tsallis non-extensive\nentropy and the nonlinear Fokker-Planck equation unites in a very natural way\nthe power-law tails of the distributions and their superdiffusive dynamics.\n"
    },
    {
        "paper_id": "cond-mat/0108023",
        "authors": "V. Plerou, P. Gopikrishnan, B. Rosenow, L. A. N. Amaral, T. Guhr and\n  H. E. Stanley",
        "title": "A Random Matrix Approach to Cross-Correlations in Financial Data",
        "comments": "20 pages (2 column format, revtex)",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.65.066126",
        "license": null,
        "abstract": "  We analyze cross-correlations between price fluctuations of different stocks\nusing methods of random matrix theory (RMT). Using two large databases, we\ncalculate cross-correlation matrices C of returns constructed from (i) 30-min\nreturns of 1000 US stocks for the 2-yr period 1994--95 (ii) 30-min returns of\n881 US stocks for the 2-yr period 1996--97, and (iii) 1-day returns of 422 US\nstocks for the 35-yr period 1962--96. We test the statistics of the eigenvalues\n$\\lambda_i$ of C against a ``null hypothesis'' --- a random correlation matrix\nconstructed from mutually uncorrelated time series. We find that a majority of\nthe eigenvalues of C fall within the RMT bounds $[\\lambda_-, \\lambda_+]$ for\nthe eigenvalues of random correlation matrices. We test the eigenvalues of C\nwithin the RMT bound for universal properties of random matrices and find good\nagreement with the results for the Gaussian orthogonal ensemble of random\nmatrices --- implying a large degree of randomness in the measured\ncross-correlation coefficients. Further, we find that the distribution of\neigenvector components for the eigenvectors corresponding to the eigenvalues\noutside the RMT bound display systematic deviations from the RMT prediction. In\naddition, we find that these ``deviating eigenvectors'' are stable in time. We\nanalyze the components of the deviating eigenvectors and find that the largest\neigenvalue corresponds to an influence common to all stocks. Our analysis of\nthe remaining deviating eigenvectors shows distinct groups, whose identities\ncorrespond to conventionally-identified business sectors. Finally, we discuss\napplications to the construction of portfolios of stocks that have a stable\nratio of risk to return.\n"
    },
    {
        "paper_id": "cond-mat/0108028",
        "authors": "Kay-Yut Chen, Leslie R. Fine and Bernardo A. Huberman",
        "title": "Forecasting Uncertain Events with Small Groups",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present a novel methodology for predicting future outcomes that uses small\nnumbers of individuals participating in an imperfect information market. By\ndetermining their risk attitudes and performing a nonlinear aggregation of\ntheir predictions, we are able to assess the probability of the future outcome\nof an uncertain event and compare it to both the objective probability of its\noccurrence and the performance of the market as a whole. Experiments show that\nthis nonlinear aggregation mechanism vastly outperforms both the imperfect\nmarket and the best of the participants.\n"
    },
    {
        "paper_id": "cond-mat/0108033",
        "authors": "Ingve Simonsen",
        "title": "Measuring Anti-Correlations in the Nordic Electricity Spot Market by\n  Wavelets",
        "comments": "Latex, 11 pages including 4 figures. To appear Physica A",
        "journal-ref": "Physica A 322, 597 (2003).",
        "doi": "10.1016/S0378-4371(02)01938-6",
        "license": null,
        "abstract": "  We consider the Nordic electricity spot market from mid 1992 to the end of\nyear 2000. This market is found to be well approximated by an anti-persistent\nself-affine (mean-reverting) walk. It is characterized by a Hurst exponent of\n$H\\simeq 0.41$ over three orders of magnitude in time ranging from days to\nyears. We argue that in order to see such a good scaling behavior, and to\nlocate cross-overs, it is crucial that an analyzing technique is used that {\\em\ndecouples} scales. This is in our case achieved by utilizing a (multi-scale)\nwavelet approach. The shortcomings of methods that do not decouple scales are\nillustrated by applying, to the same dat a set, the classic $R/S$- and Fourier\ntechniques, for which scaling regimes and/or positions of cross-overs are hard\nto define.\n"
    },
    {
        "paper_id": "cond-mat/0108066",
        "authors": "J.A.F. Heimel and A. De Martino",
        "title": "Broken ergodicity and memory in the minority game",
        "comments": "6 pages, 3 figures, final version. To appear in J.Phys.A",
        "journal-ref": "J.Phys.A 34 (2001) L539-L545",
        "doi": "10.1088/0305-4470/34/40/103",
        "license": null,
        "abstract": "  We study the dynamics of the `batch' minority game with market-impact\ncorrection using generating functional techniques to carry out the quenched\ndisorder average. We find that the assumption of weak long-term memory, which\none usually makes in order to calculate ergodic stationary states, breaks down\nwhen the persistent autocorrelation becomes larger than c_c=0.772... We show\nthat this condition, remarkably, coincides with the AT-line found in an earlier\nstatic calculation. This result suggests a new scenario for ergodicity breaking\nin disordered systems.\n"
    },
    {
        "paper_id": "cond-mat/0108068",
        "authors": "J. Kwapien, S. Drozdz, F. Gruemmer, F. Ruf, and J. Speth",
        "title": "Decomposing the stock market intraday dynamics",
        "comments": "15 pages, 13 PostScript figures",
        "journal-ref": "Physica A 309 (2002) 171-182",
        "doi": "10.1016/S0378-4371(02)00613-1",
        "license": null,
        "abstract": "  The correlation matrix formalism is used to study temporal aspects of the\nstock market evolution. This formalism allows to decompose the financial\ndynamics into noise as well as into some coherent repeatable intraday\nstructures. The present study is based on the high-frequency Deutsche\nAktienindex (DAX) data over the time period between November 1997 and September\n1999, and makes use of both, the corresponding returns as well as volatility\nvariations. One principal conclusion is that a bulk of the stock market\ndynamics is governed by the uncorrelated noise-like processes. There exists\nhowever a small number of components of coherent short term repeatable\nstructures in fluctuations that may generate some memory effects seen in the\nstandard autocorrelation function analysis. Laws that govern fluctuations\nassociated with those various components are different, which indicates an\nextremely complex character of the financial fluctuations.\n"
    },
    {
        "paper_id": "cond-mat/0108452",
        "authors": "Ashok Razdan",
        "title": "Scaling in the Bombay Stock Exchange Index",
        "comments": "11 pages,3 figures",
        "journal-ref": null,
        "doi": "10.1007/s12043-002-0063-y",
        "license": null,
        "abstract": "  In this paper we study BSE Index financial time series for fractal and\nmultifractal behaviour. We show that Bombay stock Exchange (BSE)Index time\nseries is mono-fractal and can be represented by a fractional Brownian motion.\n"
    },
    {
        "paper_id": "cond-mat/0108549",
        "authors": "T. R. Hurd",
        "title": "Pricing formulas, model error and hedging derivative portfolios",
        "comments": "16 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a method for extending a given asset pricing formula to account\nfor two additional sources of risk: the risk associated with future changes in\nmarket--calibrated parameters and the remaining risk associated with\nidiosyncratic variations in the individual assets described by the formula. The\npaper makes simple and natural assumptions for how these risks behave. These\nextra risks should always be included when using the formula as a basis for\nportfolio management. We investigate an idealized typical portfolio problem,\nand argue that a rational and workable trading strategy can be based on\nminimizing the quadratic risk over the time intervals between trades. The\nexample of the variance gamma pricing formula for equity derivatives is\nexplored, and the method is seen to yield tractable decision strategies in this\ncase.\n"
    },
    {
        "paper_id": "cond-mat/0109026",
        "authors": "G. Cuniberti, M. Porto, H. E. Roman",
        "title": "Asset-asset interactions and clustering in financial markets",
        "comments": "6 pages, 3 figures",
        "journal-ref": "Physica A 299, 263-268 (2001)",
        "doi": "10.1016/S0378-4371(01)00304-1",
        "license": null,
        "abstract": "  The collective phenomena of a liquid market is characterized in terms of a\nparticle system scenario. This physical analogy enables us to disentangle\nintrinsic features from purely stochastic ones. The latter are the result of\nenvironmental changes due to a `heat bath' acting on the many-asset system,\nquantitatively described in terms of a time dependent effective temperature.\nThe remaining intrinsic properties can be widely investigated by applying\nstandard methods of classical many body systems. As an example, we consider a\nlarge set of stocks traded at the NYSE and determine the corresponding\nasset--asset `interaction' potential. In order to investigate in more detail\nthe cluster structure suggested by the short distance behavior of the\ninteraction potential, we perform a connectivity analysis of the spatial\ndistribution of the particle system. In this way, we are able to draw\nconclusions on the intrinsic cluster persistency independently of the specific\nmarket conditions.\n"
    },
    {
        "paper_id": "cond-mat/0109139",
        "authors": "Aki-Hiro Sato and Hideki Takayasu",
        "title": "Artificial market model based on deterministic agents and derivation of\n  limit of GARCH type process",
        "comments": "25 pages, 1 table and 16 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose an artificial market model based on deterministic agents. The\nagents modify their ask/bid price depending on past price changes. The temporal\ndevelopment of market price fluctuations is calculated numerically. A\nprobability density function of market price changes has power law tails.\nAutocorrelation coefficient of the changes has an anti-correlation, and\nautocorrelation coefficient of squared changes (volatility correlation\nfunction) has a long time correlation. A probability density function of\nintervals between successive trading follows a geometric distribution. GARCH\ntype stochastic process is theoretically derived from this market model in a\nlimit case. We discuss factors of the market price fluctuations and a relation\nbetween the volatility of the market prices and a demand-supply curve. We\nconclude that the power law tails and the long time volatility result from\nmechanism of the GARCH type stochastic process.\n"
    },
    {
        "paper_id": "cond-mat/0109203",
        "authors": "C. Anteneodo, C. Tsallis and A. S. Martinez",
        "title": "Risk aversion in economic transactions",
        "comments": "4 PS figures, to appear in Europhys. Lett",
        "journal-ref": "Europhys. Lett. 59, 635 (2002)",
        "doi": "10.1209/epl/i2002-00172-5",
        "license": null,
        "abstract": "  Most people are risk-averse (risk-seeking) when they expect to gain (lose).\nBased on a generalization of ``expected utility theory'' which takes this into\naccount, we introduce an automaton mimicking the dynamics of economic\noperations. Each operator is characterized by a parameter q which gauges\npeople's attitude under risky choices; this index q is in fact the entropic one\nwhich plays a central role in nonextensive statistical mechanics. Different\nlong term patterns of average asset redistribution are observed according to\nthe distribution of parameter q (chosen once for ever for each operator) and\nthe rules (e.g., the probabilities involved in the gamble and the indebtedness\nrestrictions) governing the values that are exchanged in the transactions.\nAnalytical and numerical results are discussed in terms of how the sensitivity\nto risk affects the dynamics of economic transactions.\n"
    },
    {
        "paper_id": "cond-mat/0109410",
        "authors": "A. Corcos (Univ. Picardie), J.-P. Eckmann (Univ. Geneve), A.\n  Malaspinas (Univ. Geneve), Y. Malevergne (ISFA-Lyon and Univ. Nice/CNRS) and\n  D. Sornette (Univ. Nice/CNRS and UCLA)",
        "title": "Imitation and contrarian behavior: hyperbolic bubbles, crashes and chaos",
        "comments": "Latex document of 40 pages including 21 eps figures",
        "journal-ref": "Quantitative Finance 2, 264--281 (2002)",
        "doi": null,
        "license": null,
        "abstract": "  Imitative and contrarian behaviors are the two typical opposite attitudes of\ninvestors in stock markets. We introduce a simple model to investigate their\ninterplay in a stock market where agents can take only two states, bullish or\nbearish. Each bullish (bearish) agent polls m \"friends'' and changes her\nopinion to bearish (bullish) if there is (1) either a majority of bearish\nagents or (2) too strong a majority of bullish agents. The condition (1) (resp.\n(2)) corresponds to imitative (resp. antagonistic) behavior. In the limit where\nthe number N of agents is infinite, the dynamics of the fraction of bullish\nagents is deterministic and exhibits chaotic behavior in a significant domain\nof the parameter space of the model. A typical chaotic trajectory is\ncharacterized by intermittent phases of chaos, quasi-periodic behavior and\nsuper-exponentially growing bubbles followed by crashes. A typical bubble\nstarts initially by growing at an exponential rate and then crosses over to a\nnonlinear power law growth rate leading to a finite-time singularity. The\nreinjection mechanism provided by the contrarian behavior introduces a\nfinite-size effect, rounding off these singularities and leads to chaos. We\ndocument the main stylized facts of this model in the symmetric and asymmetric\ncases. This model is one of the rare agent-based models that give rise to\ninteresting non-periodic complex dynamics in the ``thermodynamic'' limit (of an\ninfinite number N of agents). We also discuss the case of a finite number of\nagents, which introduces an endogenous source of noise superimposed on the\nchaotic dynamics.\n"
    },
    {
        "paper_id": "cond-mat/0110120",
        "authors": "Jun-ichi Maskawa",
        "title": "Ordered phase and non-equilibrium fluctuation in stock market",
        "comments": "6 pages including 10 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)00818-X",
        "license": null,
        "abstract": "  We analyze the statistics of daily price change of stock market in the\nframework of a statistical physics model for the collective fluctuation of\nstock portfolio. In this model the time series of price changes are coded into\nthe sequences of up and down spins, and the Hamiltonian of the system is\nexpressed by spin-spin interactions as in spin glass models of disordered\nmagnetic systems. Through the analysis of Dow-Jones industrial portfolio\nconsisting of 30 stock issues by this model, we find a non-equilibrium\nfluctuation mode on the point slightly below the boundary between ordered and\ndisordered phases. The remaining 29 modes are still in disordered phase and\nwell described by Gibbs distribution. The variance of the fluctuation is\noutlined by the theoretical curve and peculiarly large in the non-equilibrium\nmode compared with those in the other modes remaining in ordinary phase.\n"
    },
    {
        "paper_id": "cond-mat/0110124",
        "authors": "Ana Proykova, Lena Roussenova and Dietrich Stauffer",
        "title": "Nucleation of Market Shocks in Sornette-Ide model",
        "comments": "For APFA 3, London, Dec. 2001; four figures ; 6 pages total;corrected\n  typos",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Sornette-Ide differential equation of herding and rational trader\nbehaviour together with very small random noise is shown to lead to crashes or\nbubbles where the price change goes to infinity after an unpredictable time.\nAbout 100 time steps before this singularity, a few predictable roughly\nlog-periodic oscillations are seen.\n"
    },
    {
        "paper_id": "cond-mat/0110201",
        "authors": "Stefan Bornholdt and Friedrich Wagner",
        "title": "Stability of money: Phase transitions in an Ising economy",
        "comments": "9 pages RevTeX, 5 figures PostScript",
        "journal-ref": "Physica A 316 (2002) 453-468",
        "doi": "10.1016/S0378-4371(02)01218-9",
        "license": null,
        "abstract": "  The stability of money value is an important requisite for a functioning\neconomy, yet it critically depends on the actions of participants in the market\nthemselves. Here we model the value of money as a dynamical variable that\nresults from trading between agents. The basic trading scenario can be recast\ninto an Ising type spin model and is studied on the hierarchical network\nstructure of a Cayley tree. We solve this model analytically and observe a\nphase transition between a one state phase, always allowing for a stable money\nvalue, and a two state phase, where an unstable (inflationary) phase occurs.\nThe onset of inflation is discontinuous and follows a first order phase\ntransition. The stable phase provides a parameter region where money value is\nrobust and can be stabilized without fine tuning.\n"
    },
    {
        "paper_id": "cond-mat/0110273",
        "authors": "Zhi-Feng Huang, Sorin Solomon",
        "title": "Stochastic Multiplicative Processes for Financial Markets",
        "comments": "12 pages, 6 figures, to be published in Physica A (Proceedings of\n  Statphys21 conference)",
        "journal-ref": "Physica A 306 (2002) 412-422",
        "doi": "10.1016/S0378-4371(02)00519-8",
        "license": null,
        "abstract": "  We study a stochastic multiplicative system composed of finite asynchronous\nelements to describe the wealth evolution in financial markets. We find that\nthe wealth fluctuations or returns of this system can be described by a walk\nwith correlated step sizes obeying truncated Levy-like distribution, and the\ncross-correlation between relative updated wealths is the origin of the\nnontrivial properties of returns, including the power law distribution with\nexponent outside the stable Levy regime and the long-range persistence of\nvolatility correlations.\n"
    },
    {
        "paper_id": "cond-mat/0110285",
        "authors": "V.I. Yukalov",
        "title": "Self-similar approach to market analysis",
        "comments": "Latex file, 17 pages, no figures",
        "journal-ref": "Eur. Phys. J. B 20 (2001) 609-617",
        "doi": "10.1007/PL00011115",
        "license": null,
        "abstract": "  A novel approach to analyzing time series generated by complex systems, such\nas markets, is presented. The basic idea of the approach is the {\\it Law of\nSelf-Similar Evolution}, according to which any complex system develops\nself-similarly. There always exist some internal laws governing the evolution\nof a system, say of a market, so that each of such systems possesses its own\ncharacter regulating its behaviour. The problem is how to discover these hidden\ninternal laws defining the system character. This problem can be solved by\nemploying the {\\it Self-Similar Approximation Theory}, which supplies the\nmathematical foundation for the Law of Self-Similar Evolution. In this report,\nthe theoretical basis of the new approach to analyzing time series is\nformulated, with an accurate explanation of its principal points.\n"
    },
    {
        "paper_id": "cond-mat/0110354",
        "authors": "E. Samanidou, E. Zschischang, D. Stauffer and T. Lux",
        "title": "Microscopic Models of Financial Markets",
        "comments": "Abstract only of a long 2 Megabyte review",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Submitted to F. Schweitzer (ed.), Microscopic Models for Economic Dynamics,\n  Lecture notes in physics, Springer, Berlin-Heidelberg 2002.kiel.tex\n"
    },
    {
        "paper_id": "cond-mat/0110480",
        "authors": "Christian Schulze",
        "title": "The domino effect for markets",
        "comments": "3 pages including 1 figure for Int. J. Mod. Phys. C 13, No. 2",
        "journal-ref": null,
        "doi": "10.1142/S0129183102003061",
        "license": null,
        "abstract": "  A generalization of the Cont-Bouchaud market model to three markets agrees\nwith the correlations netween New York, Tokyo, and Frankfurt observed by\nVandewalle et al.\n"
    },
    {
        "paper_id": "cond-mat/0110506",
        "authors": "Belal E. Baaquie",
        "title": "Quantum Field Theory of Forward Rates with Stochastic Volatility",
        "comments": "7 Figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.65.056122",
        "license": null,
        "abstract": "  In a recent formulation of a quantum field theory of forward rates, the\nvolatility of the forward rates was taken to be deterministic. The field theory\nof the forward rates is generalized to the case of stochastic volatility. Two\ncases are analyzed, firstly when volatility is taken to be a function of the\nforward rates, and secondly when volatility is taken to be an independent\nquantum field. Since volatiltiy is a positive valued quantum field, the full\ntheory turns out to be an interacting nonlinear quantum field theory in two\ndimensions. The state space and Hamiltonian for the interacting theory are\nobtained, and shown to have a nontrivial structure due to the manifold moving\nwith a constant velocity. The no arbitrage condition is reformulated in terms\nof the Hamiltonian of the system, and then exactly solved for the nonlinear\ninteracting case.\n"
    },
    {
        "paper_id": "cond-mat/0111257",
        "authors": "Fabrizio Lillo, Rosario N. Mantegna",
        "title": "Power law relaxation in a complex system: Omori law after a financial\n  market crash",
        "comments": "4 pages,4 figures, accepted in PRE",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the relaxation dynamics of a financial market just after the\noccurrence of a crash by investigating the number of times the absolute value\nof an index return is exceeding a given threshold value. We show that the\nempirical observation of a power law evolution of the number of events\nexceeding the selected threshold (a behavior known as the Omori law in\ngeophysics) is consistent with the simultaneous occurrence of (i) a return\nprobability density function characterized by a power law asymptotic behavior\nand (ii) a power law relaxation decay of its typical scale. Our empirical\nobservation cannot be explained within the framework of simple and widespread\nstochastic volatility models.\n"
    },
    {
        "paper_id": "cond-mat/0111310",
        "authors": "Y. Malevergne (ISFA-Lyon and Univ. Nice/CNRS) and D. Sornette (Univ.\n  Nice/CNRS and UCLA)",
        "title": "Testing the Gaussian Copula Hypothesis for Financial Assets Dependences",
        "comments": "Latex document of 43 pages including 14 eps figures",
        "journal-ref": "Quantitative Finance, 3, 231--250 (2003)",
        "doi": "10.1088/1469-7688/3/4/301",
        "license": null,
        "abstract": "  Using one of the key property of copulas that they remain invariant under an\narbitrary monotonous change of variable, we investigate the null hypothesis\nthat the dependence between financial assets can be modeled by the Gaussian\ncopula. We find that most pairs of currencies and pairs of major stocks are\ncompatible with the Gaussian copula hypothesis, while this hypothesis can be\nrejected for the dependence between pairs of commodities (metals).\nNotwithstanding the apparent qualification of the Gaussian copula hypothesis\nfor most of the currencies and the stocks, a non-Gaussian copula, such as the\nStudent's copula, cannot be rejected if it has sufficiently many ``degrees of\nfreedom''. As a consequence, it may be very dangerous to embrace blindly the\nGaussian copula hypothesis, especially when the correlation coefficient between\nthe pair of asset is too high as the tail dependence neglected by the Gaussian\ncopula can be as large as 0.6, i.e., three out five extreme events which occur\nin unison are missed.\n"
    },
    {
        "paper_id": "cond-mat/0111349",
        "authors": "Vasiliki Plerou, Parameswaran Gopikrishnan, and H. Eugene Stanley",
        "title": "Symmetry Breaking in Stock Demand",
        "comments": "5 pages, 4 figures (two-column format, revtex)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Scale-free distributions and correlation functions found in financial data\nare reminiscent of the scale invariance of physical observables in the vicinity\nof a critical point. Here, we present empirical evidence for a transition\nphenomenon, accompanied by a symmetry breaking, in the investors' demand for\nstocks. We study the volume imbalance $\\Omega$ -- difference between the number\nof shares traded in buyer-initiated and seller-initiated trades in a time\ninterval $\\Delta t$ -- conditioned on $\\Sigma$ which is defined as the local\nfirst moment of $\\Omega$ in $\\Delta t$. We find that the conditional\ndistribution $P(\\Omega | \\Sigma)$ undergoes a qualitative change in behavior as\n$\\Sigma$ increases beyond a critical threshold $\\Sigma_c$. For $\\Sigma\n<\\Sigma_c$, $P(\\Omega|\\Sigma)$ displays a maximum at $\\Omega=0$, i.e., trades\nin $\\Delta t$ are equally likely to be buyer initiated or seller initiated. For\n$\\Sigma > \\Sigma_c$, $\\Omega=0$ becomes a local minimum and two new maxima\n$\\Omega_{+}$ and $\\Omega_{-}$ appear at non-zero values of $\\Omega$, i.e.,\ntrades in $\\Delta t$ are either predominantly buyer initiated or predominantly\nseller initiated. We interpret these results using a Langevin equation with\nmultiplicative noise.\n"
    },
    {
        "paper_id": "cond-mat/0111503",
        "authors": "Szilard Pafka, Imre Kondor",
        "title": "Noisy Covariance Matrices and Portfolio Optimization",
        "comments": "7 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1140/epjb/e20020153",
        "license": null,
        "abstract": "  According to recent findings [1,2], empirical covariance matrices deduced\nfrom financial return series contain such a high amount of noise that, apart\nfrom a few large eigenvalues and the corresponding eigenvectors, their\nstructure can essentially be regarded as random. In [1], e.g., it is reported\nthat about 94% of the spectrum of these matrices can be fitted by that of a\nrandom matrix drawn from an appropriately chosen ensemble. In view of the\nfundamental role of covariance matrices in the theory of portfolio optimization\nas well as in industry-wide risk management practices, we analyze the possible\nimplications of this effect. Simulation experiments with matrices having a\nstructure such as described in [1,2] lead us to the conclusion that in the\ncontext of the classical portfolio problem (minimizing the portfolio variance\nunder linear constraints) noise has relatively little effect. To leading order\nthe solutions are determined by the stable, large eigenvalues, and the\ndisplacement of the solution (measured in variance) due to noise is rather\nsmall: depending on the size of the portfolio and on the length of the time\nseries, it is of the order of 5 to 15%. The picture is completely different,\nhowever, if we attempt to minimize the variance under non-linear constraints,\nlike those that arise e.g. in the problem of margin accounts or in\ninternational capital adequacy regulation. In these problems the presence of\nnoise leads to a serious instability and a high degree of degeneracy of the\nsolutions.\n"
    },
    {
        "paper_id": "cond-mat/0111529",
        "authors": "Jaume Masoliver, Miquel Montero and Josep Perello",
        "title": "Return or stock price differences",
        "comments": "21 pages, 5 figures (8 plots), submitted for publication",
        "journal-ref": "Physica A 316, 220-241 (2002)",
        "doi": null,
        "license": null,
        "abstract": "  The analysis which assumes that tick by tick data is linear may lead to wrong\nconclusions if the underlying process is multiplicative. We compare data\nanalysis done with the return and stock differences and we study the limits\nwithin the two approaches are equivalent. Some illustrative examples concerning\nthese two approaches are given. Actual data is taken from S&P 500 stock cash\nindex.\n"
    },
    {
        "paper_id": "cond-mat/0111537",
        "authors": "B. Rosenow, V. Plerou, P. Gopikrishnan, and H.E. Stanley",
        "title": "Portfolio Optimization and the Random Magnet Problem",
        "comments": "12 pages, 4 figures, revtex",
        "journal-ref": null,
        "doi": "10.1209/epl/i2002-00135-4",
        "license": null,
        "abstract": "  Diversification of an investment into independently fluctuating assets\nreduces its risk. In reality, movement of assets are are mutually correlated\nand therefore knowledge of cross--correlations among asset price movements are\nof great importance. Our results support the possibility that the problem of\nfinding an investment in stocks which exposes invested funds to a minimum level\nof risk is analogous to the problem of finding the magnetization of a random\nmagnet. The interactions for this ``random magnet problem'' are given by the\ncross-correlation matrix {\\bf \\sf C} of stock returns. We find that random\nmatrix theory allows us to make an estimate for {\\bf \\sf C} which outperforms\nthe standard estimate in terms of constructing an investment which carries a\nminimum level of risk.\n"
    },
    {
        "paper_id": "cond-mat/0111563",
        "authors": "Arturo Kohatsu-Higa and Miquel Montero",
        "title": "An application of Malliavin Calculus to Finance",
        "comments": "12 pages, 3 figures, coference proceedins",
        "journal-ref": "Physica A 320 (2003) 548 -- 570",
        "doi": null,
        "license": null,
        "abstract": "  In this article, we give a brief informal introduction to Malliavin Calculus\nfor newcomers. We apply these ideas to the simulation of Greeks in Finance.\nFirst to European-type options where formulas can be computed explicitly and\ntherefore can serve as testing ground. Later we study the case of Asian options\nwhere close formulas are not available. The Greeks are computed through Monte\nCarlo simulation.\n"
    },
    {
        "paper_id": "cond-mat/0111579",
        "authors": "Hari M. Gupta and Jose R. Campanha",
        "title": "Gradually Truncated Log-normal distribution - Size distribution of firms",
        "comments": "7 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Gradually Truncated Log-normal distribution - Size distribution of firms\n  Abstract\n  Many natural and economical phenomena are described through power law or log-\nnormal distributions. In these cases, probability decreases very slowly with\nstep size compared to normal distribution. Thus it is essential to cut-off\nthese distributions for larger step size. Recently we introduce the gradually\ntruncated power law distribution to successfully describe variation of\nfinancial, educational, physical and citation index. In the present work, we\nintroduce gradually truncated log-normal distribution in which we gradually\ncut- off larger steps due to physical limitation of the system. We applied this\ndistribution successfully to size distribution of USA.\\'{}s manufactoring firms\nwhich is measured through their annual sell. The physical limitation are due to\nlimited market size or shortage of highly competent executives.\n"
    },
    {
        "paper_id": "cond-mat/0111586",
        "authors": "Agata Aleksiejuk, Janusz A. Holyst and Gueorgi Kossinets",
        "title": "Self-organized criticality in a model of collective bank bankruptcies",
        "comments": "For Int. J. Mod. Phys. C 13, No. 3, six pages including four figures",
        "journal-ref": "Int. J. Mod. Phys. C 13 (3): 333-341 MAR 2002",
        "doi": "10.1142/S0129183102003164",
        "license": null,
        "abstract": "  The question we address here is of whether phenomena of collective\nbankruptcies are related to self-organized criticality. In order to answer it\nwe propose a simple model of banking networks based on the random directed\npercolation. We study effects of one bank failure on the nucleation of\ncontagion phase in a financial market. We recognize the power law distribution\nof contagion sizes in 3d- and 4d-networks as an indicator of SOC behavior. The\nSOC dynamics was not detected in 2d-lattices. The difference between 2d- and\n3d- or 4d-systems is explained due to the percolation theory.\n"
    },
    {
        "paper_id": "cond-mat/0112045",
        "authors": "Hermann Haaf and Dirk Tasche",
        "title": "Calculating Value-at-Risk contributions in CreditRisk+",
        "comments": "11 pages, LaTeX with hyperref package",
        "journal-ref": "GARP Risk Review issue 07 Jul/Aug 2002, 43-47",
        "doi": null,
        "license": null,
        "abstract": "  Credit Suisse First Boston (CSFB) launched in 1997 the model CreditRisk+\nwhich aims at calculating the loss distribution of a credit portfolio on the\nbasis of a methodology from actuarial mathematics. Knowing the loss\ndistribution, it is possible to determine quantile-based values-at-risk (VaRs)\nfor the portfolio. An open question is how to attribute fair VaR contributions\nto the credits or loans forming the portfolio. One approach is to define the\ncontributions as certain conditional expectations. We develop an algorithm for\nthe calculations involved in this approach. This algorithm can be adapted for\ncomputing the contributions to the portfolio Expected Shortfall (ES).\n  Key words: CreditRisk+; Value-at-Risk (VaR); risk contribution; conditional\nexpectation.\n"
    },
    {
        "paper_id": "cond-mat/0112271",
        "authors": "S. Drozdz, J. Kwapien, J. Speth and M. Wojcik",
        "title": "Identifying Complexity by Means of Matrices",
        "comments": "Talk given by S. Drozdz at \"Horizons in Complex Systems\", Messina,\n  December 5-8, 2001",
        "journal-ref": "PhysicaA314:355-361,2002",
        "doi": "10.1016/S0378-4371(02)01066-X",
        "license": null,
        "abstract": "  Complexity is an interdisciplinary concept which, first of all, addresses the\nquestion of how order emerges out of randomness. For many reasons matrices\nprovide a very practical and powerful tool in approaching and quantifying the\nrelated characteristics. Based on several natural complex dynamical systems,\nlike the strongly interacting quantum many-body systems, the human brain and\nthe financial markets, by relating empirical observations to the random matrix\ntheory and quantifying deviations in term of a reduced dimensionality, we\npresent arguments in favour of the statement that complexity is a pheomenon at\nthe edge between collectivity and chaos.\n"
    },
    {
        "paper_id": "cond-mat/0112422",
        "authors": "Marcus G. Daniels, J. Doyne Farmer, Laszlo Gillemot, Giulia Iori, and\n  Eric Smith",
        "title": "A quantitative model of trading and price formation in financial markets",
        "comments": "5 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevLett.90.108102",
        "license": null,
        "abstract": "  We use standard physics techniques to model trading and price formation in a\nmarket under the assumption that order arrival and cancellations are Poisson\nrandom processes. This model makes testable predictions for the most basic\nproperties of a market, such as the diffusion rate of prices, which is the\nstandard measure of financial risk, and the spread and price impact functions,\nwhich are the main determinants of transaction cost. Guided by dimensional\nanalysis, simulation, and mean field theory, we find scaling relations in terms\nof order flow rates. We show that even under completely random order flow the\nneed to store supply and demand to facilitate trading induces anomalous\ndiffusion and temporal structure in prices.\n"
    },
    {
        "paper_id": "cond-mat/0112441",
        "authors": "Takayuki Mizuno, Misako Takayasu and Hideki Takayasu",
        "title": "The mechanism of double exponential growth in hyper-inflation",
        "comments": "9 pages, 5 figures and 2 tables, submitted to Physica A",
        "journal-ref": "Physica A 308 (2002) 411",
        "doi": "10.1016/S0378-4371(02)00598-8",
        "license": null,
        "abstract": "  Analyzing historical data of price indices we find an extraordinary growth\nphenomenon in several examples of hyper-inflation in which price changes are\napproximated nicely by double-exponential functions of time. In order to\nexplain such behavior we introduce the general coarse-graining technique in\nphysics, the Monte Carlo renormalization group method, to the price dynamics.\nStarting from a microscopic stochastic equation describing dealers' actions in\nopen markets we obtain a macroscopic noiseless equation of price consistent\nwith the observation. The effect of auto-catalytic shortening of characteristic\ntime caused by mob psychology is shown to be responsible for the\ndouble-exponential behavior.\n"
    },
    {
        "paper_id": "cond-mat/0112484",
        "authors": "G. M. Viswanathan, U. L. Fulco, M. L. Lyra and M. Serva",
        "title": "The origin of fat tailed distributions in financial time series",
        "comments": "minor corrections",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A classic problem in physics is the origin of fat tailed distributions\ngenerated by complex systems. We study the distributions of stock returns\nmeasured over different time lags $\\tau.$ We find that destroying all\ncorrelations without changing the $\\tau = 1$ d distribution, by shuffling the\norder of the daily returns, causes the fat tails almost to vanish for $\\tau>1$\nd. We argue that the fat tails are caused by known long-range volatility\ncorrelations. Indeed, destroying only sign correlations, by shuffling the order\nof only the signs (but not the absolute values) of the daily returns, allows\nthe fat tails to persist for $\\tau >1$ d.\n"
    },
    {
        "paper_id": "cond-mat/0201192",
        "authors": "Christian Schulze",
        "title": "Sornette-Ide model for markets: Trader expectations as imaginary part",
        "comments": "4 pages including two figures, for Int. J. Mod. Phys. C 14, issue 4\n  (2002)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A nonlinear differential equation of Sornette-Ide type with noise, for a\ncomplex variable, yields endogenous crashes, preceded by roughly log-periodic\noscillations in the real part, and a strong increase in the imaginary part. The\nlatter is interpreted as the trader expectation.\n"
    },
    {
        "paper_id": "cond-mat/0201195",
        "authors": "Martin Hohnisch, Sabine Pittnauer and Manisha Chakrabarty",
        "title": "Empirical Regularities in Distributions of Individual Consumption\n  Expenditure",
        "comments": "9 pages including figures; for Int. J. Mod. Phys. C 13, No. 4",
        "journal-ref": null,
        "doi": "10.1142/S0129183102003292",
        "license": null,
        "abstract": "  We empirically investigate distributions of individual consumption\nexpenditure f or four commodity categories conditional on fixed income levels.\nThe data stems from the Family Expenditure Survey carried out annually in the\nUnited Kingdom. W e use graphical techniques to test for normality and\nlognormality of these distributions. While mainstream economic theory does not\npredict any structure for these distributions, we find that in at least three\ncommodity categories individual consumption expenditure conditional on a fixed\nincome level is lognormally distributed.\n"
    },
    {
        "paper_id": "cond-mat/0201219",
        "authors": "Hari M. Gupta and Jose R. Campanha (Unesp - IGCE, Physics Dpto. Rio\n  Claro, Sao Paulo, Brazil)",
        "title": "Firms Growth Dynamics, Competition and Power Law Scaling",
        "comments": "10 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(03)00017-7",
        "license": null,
        "abstract": "  We study the growth dynamics of the size of manufacturing firms considering\ncompetition and normal distribution of competency. We start with the fact that\nall components of the system struggle with each other for growth as happened in\nreal competitive bussiness world. The detailed quantitative agreement of the\ntheory with empirical results of firms growth based on a large economic\ndatabase spanning over 20 years is good .Further we find that this basic law of\ncompetition leads approximately a power law scaling over a wide range of\nparameters. The empirical datas are in accordance with present theory rather\nthan a simple power law.\n"
    },
    {
        "paper_id": "cond-mat/0201345",
        "authors": "Emanuel Derman",
        "title": "The Perception of Time, Risk and Return During Periods of Speculation",
        "comments": "Front page plus 36",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  What return should you expect when you take on a given amount of risk? How\nshould that return depend upon other people's behavior? What principles can you\nuse to answer these questions? In this paper, we approach these topics by\nexploring the consequences of two simple hypotheses about risk.\n  The first is a common-sense invariance principle: assets with the same\nperceived risk must have the same expected return. The second hypothesis\nconcerns the perception of time. We conjecture that in times of speculative\nexcitement, short-term investors may instinctively imagine stock prices to be\nevolving in a time measure different from that of calendar time. They may\ninstead perceive and experience the risk and return of a stock in intrinsic\ntime, a dimensionless time scale that counts the number of trading\nopportunities that occur.\n  The most noteworthy result is that, in the short-term, a stock's trading\nfrequency affects its expected return. We show that short-term stock\nspeculators will expect returns proportional to the temperature of a stock,\nwhere temperature is defined as the product of the stock's traditional\nvolatility and the square root of its trading frequency. We hope that this\nmodel will have some relevance to the behavior of investors expecting\ninordinate returns in highly speculative markets.\n"
    },
    {
        "paper_id": "cond-mat/0201514",
        "authors": "Vygintas Gontis",
        "title": "Modelling share volume traded in financial markets",
        "comments": "8 pages, 3 figures, you can download article with fine figures from:\n  http://www.itpa.lt/~gontis/",
        "journal-ref": "Lithuanian Journal of Physics, 2001, v. 41, No. 4-6, 551-555",
        "doi": null,
        "license": null,
        "abstract": "  A simple analytically solvable model exhibiting a 1/f spectrum in an\narbitrarily wide frequency range was recently proposed by Kaulakys and\nMeskauskas (KM). Signals consisting of a sequence of pulses show that inherent\norigin of the 1/f noise is Brownian fluctuations of the average intervent time\nbetween subsequent pulses of the pulse sequence. We generalize the KM model to\nreproduce the variety of self-affine time series exhibiting power spectral\ndensity S(f) scaled as power of their frequency f. Numerical calculations with\nthe generalized discrete model (GDM) reproduce power spectral density S(f)\nscaled as power of frequency 1/f^b for various values of b, including b =1/2\nfor applications in financial markets. The particular applications of the model\nproposed are related with financial time series of share volume traded.\n"
    },
    {
        "paper_id": "cond-mat/0202028",
        "authors": "Kaushik Matia, Luis A. Nunes Amaral, Stephen P. Goodwin and H. Eugene\n  Stanley",
        "title": "Non-L\\'evy Distribution of Commodity Price Fluctuations",
        "comments": "4 pages 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Price fluctuations of commodities like cotton and wheat are thought to\ndisplay probability distributions of returns that follow a L\\'evy stable\ndistribution. Recent analysis of stocks and foreign exchange markets show that\nthe probability distributions are not L\\'evy stable, a plausible result since\ncommodity markets have quite different features than stock markets. We analyze\ndaily returns of 29 commodities over typically 20 years and find that the\ndistributions of returns decay as power laws with exponents $\\alpha$ which have\nvalues $\\alpha > 2$, outside the L\\'evy-stable domain. We also find that the\namplitudes of the returns display long-range time correlations, like stocks,\nwhile the returns themselves are uncorrelated for time lags $\\approx$ 2 days,\nmuch larger than for stocks ($\\approx$ 4 min).\n"
    },
    {
        "paper_id": "cond-mat/0202143",
        "authors": "G. Montagna, O. Nicrosini and N. Moreni",
        "title": "A Path Integral Way to Option Pricing",
        "comments": "20 pages, 2 figures, 3 tables",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)00796-3",
        "license": null,
        "abstract": "  An efficient computational algorithm to price financial derivatives is\npresented. It is based on a path integral formulation of the pricing problem.\nIt is shown how the path integral approach can be worked out in order to obtain\nfast and accurate predictions for the value of a large class of options,\nincluding those with path-dependent and early exercise features. As examples,\nthe application of the method to European and American options in the\nBlack-Scholes model is illustrated. A particularly simple and fast\nsemi-analytical approximation for the price of American options is derived. The\nresults of the algorithm are compared with those obtained with the standard\nprocedures known in the literature and found to be in good agreement.\n"
    },
    {
        "paper_id": "cond-mat/0202203",
        "authors": "Josep Perello and Jaume Masoliver",
        "title": "Stochastic volatility and leverage effect",
        "comments": "4 pages, 2 figures",
        "journal-ref": "Physical Review E 67, 037102 (2003)",
        "doi": "10.1103/PhysRevE.67.037102",
        "license": null,
        "abstract": "  We prove that a wide class of correlated stochastic volatility models exactly\nmeasure an empirical fact in which past returns are anticorrelated with future\nvolatilities: the so-called ``leverage effect''. This quantitative measure\nallows us to fully estimate all parameters involved and it will entail a deeper\nstudy on correlated stochastic volatility models with practical applications on\noption pricing and risk management.\n"
    },
    {
        "paper_id": "cond-mat/0202352",
        "authors": "Ingve Simonsen, Mogens H. Jensen, and Anders Johansen",
        "title": "Optimal Investment Horizons",
        "comments": "Latex, 5 pages including 4 figurs",
        "journal-ref": "Eur. Phys. J. B 27, 583, (2002).",
        "doi": "10.1140/epjb/e2002-00193-x",
        "license": null,
        "abstract": "  In stochastic finance, one traditionally considers the return as a\ncompetitive measure of an asset, {\\it i.e.}, the profit generated by that asset\nafter some fixed time span $\\Delta t$, say one week or one year. This measures\nhow well (or how bad) the asset performs over that given period of time. It has\nbeen established that the distribution of returns exhibits ``fat tails''\nindicating that large returns occur more frequently than what is expected from\nstandard Gaussian stochastic processes (Mandelbrot-1967,Stanley1,Doyne).\nInstead of estimating this ``fat tail'' distribution of returns, we propose\nhere an alternative approach, which is outlined by addressing the following\nquestion: What is the smallest time interval needed for an asset to cross a\nfixed return level of say 10%? For a particular asset, we refer to this time as\nthe {\\it investment horizon} and the corresponding distribution as the {\\it\ninvestment horizon distribution}. This latter distribution complements that of\nreturns and provides new and possibly crucial information for portfolio design\nand risk-management, as well as for pricing of more exotic options. By\nconsidering historical financial data, exemplified by the Dow Jones Industrial\nAverage, we obtain a novel set of probability distributions for the investment\nhorizons which can be used to estimate the optimal investment horizon for a\nstock or a future contract.\n"
    },
    {
        "paper_id": "cond-mat/0202356",
        "authors": "Y. Malevergne (Univ. Nice and Univ. Lyon I) and D. Sornette (CNRS and\n  Univ. Nice and UCLA)",
        "title": "Tail Dependence of Factor Models",
        "comments": "Latex document of 29 pages including 10 tables",
        "journal-ref": "The Journal of Risk 6 (3), 71-116 (2004)",
        "doi": null,
        "license": null,
        "abstract": "  Using the framework of factor models, we establish the general expression of\nthe coefficient of tail dependence between the market and a stock (i.e., the\nprobability that the stock incurs a large loss, assuming that the market has\nalso undergone a large loss) as a function of the parameters of the underlying\nfactor model and of the tail parameters of the distributions of the factor and\nof the idiosyncratic noise of each stock. Our formula holds for arbitrary\nmarginal distributions and in addition does not require any parameterization of\nthe multivariate distributions of the market and stocks. The determination of\nthe extreme parameter, which is not accessible by a direct statistical\ninference, is made possible by the measurement of parameters whose estimation\ninvolves a significant part of the data with sufficient statistics. Our\nempirical tests find a good agreement between the calibration of the tail\ndependence coefficient and the realized large losses over the period from 1962\nto 2000. Nevertheless, a bias is detected which suggests the presence of an\noutlier in the form of the crash of October 1987.\n"
    },
    {
        "paper_id": "cond-mat/0202388",
        "authors": "Wataru Souma",
        "title": "Physics of Personal Income",
        "comments": "Empirical science of financial fluctuations: the advent of\n  econophysics/ Hideki Takayasu (ed.), Proceeding of a workshop hosted by the\n  Nihon Keizai Shimbun, Inc., and held in Tokyo, Nov. 15-17, 2000",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We report empirical studies on the personal income distribution, and clarify\nthat the distribution pattern of the lognormal with power law tail is the\nuniversal structure. We analyze the temporal change of Pareto index and Gibrat\nindex to investigate the change of the inequality of the income distribution.\nIn addition some mathematical models which are proposed to explain the power\nlaw distribution are reviewed.\n"
    },
    {
        "paper_id": "cond-mat/0202391",
        "authors": "Yukihiro Aiba, Naomichi Hatano, Hideki Takayasu, Kouhei Marumo, Tokiko\n  Shimizu",
        "title": "Triangular arbitrage as an interaction among foreign exchange rates",
        "comments": "19 pages, 21 eps files embedded. Physica A, to be published",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)00799-9",
        "license": null,
        "abstract": "  We first show that there are in fact triangular arbitrage opportunities in\nthe spot foreign exchange markets, analyzing the time dependence of the\nyen-dollar rate, the dollar-euro rate and the yen-euro rate. Next, we propose a\nmodel of foreign exchange rates with an interaction. The model includes effects\nof triangular arbitrage transactions as an interaction among three rates. The\nmodel explains the actual data of the multiple foreign exchange rates well.\n"
    },
    {
        "paper_id": "cond-mat/0202479",
        "authors": "Matteo Marsili and Maurizio Piai",
        "title": "Colored minority games",
        "comments": "15 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)00800-2",
        "license": null,
        "abstract": "  We study the behavior of simple models for financial markets with widely\nspread frequency either in the trading activity of agents or in the occurrence\nof basic events. The generic picture of a phase transition between information\nefficient and inefficient markets still persists even when agents trade on\nwidely spread time-scales. We derive analytically the dependence of the\ncritical threshold on the distribution of time-scales. We also address the\nissue of market efficiency as a function of frequency. In an inefficient market\nwe find that the size of arbitrage opportunities is inversely proportional to\nthe frequency of the events on which they occur. Greatest asymmetries in market\noutcomes are concentrated on the most rare events. The practical limits of the\napplications of these ideas to real markets are discussed in a specific\nexample.\n"
    },
    {
        "paper_id": "cond-mat/0202527",
        "authors": "Salvatore Micciche`, Giovanni Bonanno, Fabrizio Lillo, Rosario N.\n  Mantegna",
        "title": "Volatility in Financial Markets: Stochastic Models and Empirical Results",
        "comments": "6 pages, 2 figures",
        "journal-ref": "Physica A, 314, 756-761, (2002)",
        "doi": "10.1016/S0378-4371(02)01187-1",
        "license": null,
        "abstract": "  We investigate the historical volatility of the 100 most capitalized stocks\ntraded in US equity markets. An empirical probability density function (pdf) of\nvolatility is obtained and compared with the theoretical predictions of a\nlognormal model and of the Hull and White model. The lognormal model well\ndescribes the pdf in the region of low values of volatility whereas the Hull\nand White model better approximates the empirical pdf for large values of\nvolatility. Both models fails in describing the empirical pdf over a moderately\nlarge volatility range.\n"
    },
    {
        "paper_id": "cond-mat/0203046",
        "authors": "Adrian A. Dragulescu, Victor M. Yakovenko",
        "title": "Probability distribution of returns in the Heston model with stochastic\n  volatility",
        "comments": "11 pages, 7 figures, RevTeX 4. V.2: substantial revision - new\n  figures, sections, and references; V.3: accepted to Quantitative Finance,\n  minor corrections",
        "journal-ref": "Quantitative Finance 2, 443 (2002)",
        "doi": null,
        "license": null,
        "abstract": "  We study the Heston model, where the stock price dynamics is governed by a\ngeometrical (multiplicative) Brownian motion with stochastic variance. We solve\nthe corresponding Fokker-Planck equation exactly and, after integrating out the\nvariance, find an analytic formula for the time-dependent probability\ndistribution of stock price changes (returns). The formula is in excellent\nagreement with the Dow-Jones index for the time lags from 1 to 250 trading\ndays. For large returns, the distribution is exponential in log-returns with a\ntime-dependent exponent, whereas for small returns it is Gaussian. For time\nlags longer than the relaxation time of variance, the probability distribution\ncan be expressed in a scaling form using a Bessel function. The Dow-Jones data\nfor 1982-2001 follow the scaling function for seven orders of magnitude.\n"
    },
    {
        "paper_id": "cond-mat/0203166",
        "authors": "Y. Malevergne (Univ. Nice and Univ. Lyon I) and D. Sornette (CNRS and\n  Univ. Nice and UCLA)",
        "title": "Investigating Extreme Dependences: Concepts and Tools",
        "comments": "46 pages including 9 figures",
        "journal-ref": "transformed and extended in the book ``Extreme Financial Risks\n  (From dependence to risk management)'' (Springer, Heidelberg, 2006)",
        "doi": null,
        "license": null,
        "abstract": "  We investigate the relative information content of six measures of dependence\nbetween two random variables $X$ and $Y$ for large or extreme events for\nseveral models of interest for financial time series. The six measures of\ndependence are respectively the linear correlation $\\rho^+_v$ and Spearman's\nrho $\\rho_s(v)$ conditioned on signed exceedance of one variable above the\nthreshold $v$, or on both variables ($\\rho_u$), the linear correlation\n$\\rho^s_v$ conditioned on absolute value exceedance (or large volatility) of\none variable, the so-called asymptotic tail-dependence $\\lambda$ and a\nprobability-weighted tail dependence coefficient ${\\bar \\lambda}$. The models\nare the bivariate Gaussian distribution, the bivariate Student's distribution,\nand the factor model for various distributions of the factor. We offer explicit\nanalytical formulas as well as numerical estimations for these six measures of\ndependence in the limit where $v$ and $u$ go to infinity. This provides a\nquantitative proof that conditioning on exceedance leads to conditional\ncorrelation coefficients that may be very different from the unconditional\ncorrelation and gives a straightforward mechanism for fluctuations or changes\nof correlations, based on fluctuations of volatility or changes of trends.\nMoreover, these various measures of dependence exhibit different and sometimes\nopposite behaviors, suggesting that, somewhat similarly to risks whose adequate\ncharacterization requires an extension beyond the restricted one-dimensional\nmeasure in terms of the variance (volatility) to include all higher order\ncumulants or more generally the knowledge of the full distribution,\ntail-dependence has also a multidimensional character.\n"
    },
    {
        "paper_id": "cond-mat/0203256",
        "authors": "L. Kullmann, J. Kertesz, K. Kaski",
        "title": "Time dependent cross correlations between different stock returns: A\n  directed network of influence",
        "comments": "7 pages, 4 figures, revtex4 style; added 5 more references",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.66.026125",
        "license": null,
        "abstract": "  We study the time dependent cross correlations of stock returns, i.e. we\nmeasure the correlation as the function of the time shift between pairs of\nstock return time series using tick-by-tick data. We find a weak but\nsignificant effect showing that in many cases the maximum correlation is at\nnonzero time shift indicating directions of influence between the companies.\nDue to the weakness of the effect and the shortness of the characteristic time\n(in the order of a few minutes) the effect is compatible with market\nefficiency. The interaction of companies defines a directed network of\ninfluence.\n"
    },
    {
        "paper_id": "cond-mat/0203304",
        "authors": "Joesph L. McCauley",
        "title": "Self-Financing, Replicating Hedging Strategies, an incomplete\n  thermodynamic analogy",
        "comments": "10 pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In the theory of riskfree hedges in continuous time finance, one can start\nwith the delta-hedge and derive the option pricing equation, or one can start\nwith the replicating, self-financing hedging strategy and derive both the\ndelta-hedge and the option pricing partial differential equation. Approximately\nreversible trading is implicitly assumed in both cases. The option pricing\nequation is not restricted to the standard Black-Scholes equation when\nnontrivial volatility is assumed, but produces option pricing in agreement with\nthe empirical distribution for the right choice of volatility in a stochastic\ndescription of fluctuations. The replicating, self-financing hedging strategy\nprovides us with an incomplete analogy with thermodynamics where liquidity\nplays the role of the heat bath, the absence of arbitrage is analgous to\nthermal equilibrium, but there is no role played by the entropy of the returns\ndistribution, which cannot reach a maximum/equilibrium. We emphasize strongly\nthat the no-arbitrage assumption is not an equilibrium assumption, as is taught\nin economics, but provides only an incomplete, very limited analogy with the\nidea of thermal equilibrium.\n"
    },
    {
        "paper_id": "cond-mat/0203399",
        "authors": "Atushi Ishikawa, Tadao Suzuki and Masashi Tomoyose",
        "title": "A New Approach to Personal Income Distribution",
        "comments": "11 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The results of R^2 dynamical random surface model (2-dimensional quantum\ngravity with a $R^2$ term) are applied to explain the personal income\ndistribution. A scale invariance exists if there is not the $R^2$ term in the\naction. The R^2 term provides a typical scale and breaks the scale invariance\nexplicitly in the low and middle income range. A new distribution, Weibull\ndistribution, is deduced from the action analytically in the low income range,\nand a consistent fitting is obtained in the whole income range. Also, we show\nthat the lognormal distribution in the middle income range can be understood in\nthis framework.\n"
    },
    {
        "paper_id": "cond-mat/0203558",
        "authors": "Dirk Tasche",
        "title": "Expected Shortfall and Beyond",
        "comments": "18 pages, LaTeX with hyperref package, Remark 3.8 and references\n  updated",
        "journal-ref": "Journal of Banking and Finance 26(7), 1519-1533, 2002",
        "doi": null,
        "license": null,
        "abstract": "  Financial institutions have to allocate so-called \"economic capital\" in order\nto guarantee solvency to their clients and counter parties. Mathematically\nspeaking, any methodology of allocating capital is a \"risk measure\", i.e. a\nfunction mapping random variables to the real numbers. Nowadays\n\"value-at-risk\", which is defined as a fixed level quantile of the random\nvariable under consideration, is the most popular risk measure. Unfortunately,\nit fails to reward diversification, as it is not \"subadditive\". In the search\nfor a suitable alternative to value-at-risk, \"Expected Shortfall\" (or\n\"conditional value-at-risk\" or \"tail value-at-risk\") has been characterized as\nthe smallest \"coherent\" and \"law invariant\" risk measure to dominate\nvalue-at-risk. We discuss these and some other properties of Expected Shortfall\nas well as its generalization to a class of coherent risk measures which can\nincorporate higher moment effects. Moreover, we suggest a general method on how\nto attribute Expected Shortfall \"risk contributions\" to portfolio components.\n  Key words: Expected Shortfall; Value-at-Risk; Spectral Risk Measure;\ncoherence; risk contribution.\n"
    },
    {
        "paper_id": "cond-mat/0203591",
        "authors": "Kestutis Staliunas",
        "title": "Anticorrelations and subdiffusion in financial systems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Statistical dynamics of financial systems is investigated, based on a model\nof a randomly coupled equation system driven by a stochastic Langevin force.\nAnticorrelations of price returns, and subdiffusion of prices is found from the\nmodel, and and compared with those calculated from historical $/EURO exchange\nrates.\n"
    },
    {
        "paper_id": "cond-mat/0203596",
        "authors": "M. Raberto, E. Scalas, F. Mainardi",
        "title": "Waiting-times and returns in high-frequency financial data: an empirical\n  study",
        "comments": "8 pages, 4 figure, presented at the International Workshop \"Horizons\n  in Complex Systems\", Messina, Italy, December 2001",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01048-8",
        "license": null,
        "abstract": "  In financial markets, not only prices and returns can be considered as random\nvariables, but also the waiting time between two transactions varies randomly.\nIn the following, we analyse the statistical properties of General Electric\nstock prices, traded at NYSE, in October 1999. These properties are critically\nrevised in the framework of theoretical predictions based on a continuous-time\nrandom walk model.\n"
    },
    {
        "paper_id": "cond-mat/0203607",
        "authors": "Acerbi Carlo and Simonetti Prospero",
        "title": "Portfolio Optimization with Spectral Measures of Risk",
        "comments": "12 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study Spectral Measures of Risk from the perspective of portfolio\noptimization. We derive exact results which extend to general Spectral Measures\nM_phi the Pflug--Rockafellar--Uryasev methodology for the minimization of\nalpha--Expected Shortfall. The minimization problem of a spectral measure is\nshown to be equivalent to the minimization of a suitable function which\ncontains additional parameters, but displays analytical properties (piecewise\nlinearity and convexity in all arguments, absence of sorting subroutines) which\nallow for efficient minimization procedures.\n  In doing so we also reveal a new picture where the classical risk--reward\nproblem a la Markowitz (minimizing risks with constrained returns or maximizing\nreturns with constrained risks) is shown to coincide to the unconstrained\noptimization of a single suitable spectral measure. In other words, minimizing\na spectral measure turns out to be already an optimization process itself,\nwhere risk minimization and returns maximization cannot be disentangled from\neach other.\n"
    },
    {
        "paper_id": "cond-mat/0204234",
        "authors": "J. Mimkes (1), Th. Fruend (1), G. Willis (2) ((1) Physics Department,\n  University of Paderborn, Paderborn, Germany, (2) South Elmsall, W. Yorkshire,\n  U.K.)",
        "title": "Lagrange statistics in systems (markets) with price constraints:\n  Analysis of property, car sales, marriage and job markets by the Boltzmann\n  function and the Pareto distribution",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Statistical models of economic distributions lead to Boltzmann distributions\nrather than a Pareto power law. This result is supported by two facts: 1. the\ndistributions of income, car sales, marriages or jobs are a matter of chances\nand luck and not of reason! 2. Data for property, automobile sales, marriages\nand job markets were analyzed by two models: the Pareto law and the Boltzmann\ndistribution of stochastic systems. In all cases the best fits to data were\nobtained by the Boltzmann function. This may indicate that the principles of\nstochastic systems like in physics, chemistry, thermodynamics may also be\napplied to economic systems.\n"
    },
    {
        "paper_id": "cond-mat/0204261",
        "authors": "Fredrick Michael, M.D. Johnson",
        "title": "Black-Scholes-Like Derivative Pricing With Tsallis Non-extensive\n  Statistics",
        "comments": "9 pages. Revised version, added derivation, deleted time homogeneous\n  process. Submitted to Physica A",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We recently showed that the S&P500 stock market index is well described by\nTsallis non-extensive statistics and nonlinear Fokker-Planck time evolution. We\nargued that these results should be applicable to a broad range of markets and\nexchanges where anomalous diffusion and `heavy' tails of the distribution are\npresent. In the present work we examine how the Black-Scholes derivative\npricing formula is modified when the underlying security obeys non-extensive\nstatistics and Fokker-Planck time evolution. We answer this by recourse to the\nunderlying microscopic Ito-Langevin stochastic differential equation of the\nnon-extensive process.\n"
    },
    {
        "paper_id": "cond-mat/0204295",
        "authors": "Hans-Christian v. Bothmer, Christian Meister",
        "title": "Predicting critical crashes? A new restriction for the free variables",
        "comments": "10 pages; 5 figures; AMSlatex. Author-supplied PDF file with high\n  quality graphics is available at http://btm8x5.mat.uni-bayreuth.de/~bothmer/",
        "journal-ref": "Physica A, 320C (2003), 539-547",
        "doi": "10.1016/S0378-4371(02)01535-2",
        "license": null,
        "abstract": "  Several authors have noticed the signature of log-periodic oscillations prior\nto large stock market crashes [cond-mat/9509033, cond-mat/9510036, Vandewalle\net al 1998]. Unfortunately good fits of the corresponding equation to stock\nmarket prices are also observed in quiet times. To refine the method several\napproaches have been suggested:\n  1) Logarithmic Divergence: Regard the limit where the critical exponent \\beta\nconverges to 0.\n  2) Universality: Define typical ranges for the free parameters, by observing\nthe best fit for historic crashes.\n  We suggest a new approach. From the observation that the hazard-rate in\ncond-mat/9510036 has to be a positive number, we get an inequality among the\nfree variables of the equation for stock-market prices.\n  Checking 88 years of Dow-Jones-Data for best fits, we find that 25% of those\nthat satisfy our inequality, occur less than one year before a crash. We\ncompare this with other methods of crash prediction, i.p. the universality\nmethod of Johansen et al., which are followed by a crash in only 9% of the\ncases.\n  Combining the two approaches we obtain a method whose predictions are\nfollowed by crashes in 54% of the cases.\n"
    },
    {
        "paper_id": "cond-mat/0204331",
        "authors": "Lisa Borland",
        "title": "Option Pricing Formulas based on a non-Gaussian Stock Price Model",
        "comments": "final version (published)",
        "journal-ref": "Phys. Rev. Lett. 89, N9, 098701, August 2002",
        "doi": "10.1103/PhysRevLett.89.098701",
        "license": null,
        "abstract": "  Options are financial instruments that depend on the underlying stock. We\nexplain their non-Gaussian fluctuations using the nonextensive thermodynamics\nparameter $q$. A generalized form of the Black-Scholes (B-S) partial\ndifferential equation, and some closed-form solutions are obtained. The\nstandard B-S equation ($q=1$) which is used by economists to calculate option\nprices requires multiple values of the stock volatility (known as the\nvolatility smile). Using $q=1.5$ which well models the empirical distribution\nof returns, we get a good description of option prices using a single\nvolatility.\n"
    },
    {
        "paper_id": "cond-mat/0204574",
        "authors": "A.G. Zawadowski, R. Karadi, J. Kertesz",
        "title": "Price Drops, Fluctuations, and Correlation in a Multi-Agent Model of\n  Stock Markets",
        "comments": "11 pages, 5 figures, 2 tables; submitted to Physica A",
        "journal-ref": "Physica A, 316 (2002), pp 403-412",
        "doi": "10.1016/S0378-4371(02)01213-X",
        "license": null,
        "abstract": "  In this paper we compare market price fluctuations with the response to\nfundamental price drops within the Lux-Marchesi model which is able to\nreproduce the most important stylized facts of real market data. Major\ndifferences can be observed between the decay of spontaneous fluctuations and\nof changes due to external perturbations reflecting the absence of detailed\nbalance, i.e., of the validity of the fluctuation-dissipation theorem. We found\nthat fundamental price drops are followed by an overshoot with a rather robust\ncharacteristic time.\n"
    },
    {
        "paper_id": "cond-mat/0204593",
        "authors": "Dirk Tasche and Luisa Tibiletti",
        "title": "A shortcut to sign Incremental Value-at-Risk for risk allocation",
        "comments": "8 pages, LaTeX with hyperref, minor corrections",
        "journal-ref": "Journal of Risk Finance 2(4) (Winter 2003), 43-46",
        "doi": null,
        "license": null,
        "abstract": "  Approximate Incremental Value-at-Risk formulae provide an easy-to-use\npreliminary guideline for risk allocation. Both the cases of risk adding and\nrisk pooling are examined and beta-based formulae achieved. Results highlight\nhow much the conditions for adding new risky positions are stronger than those\nrequired for risk pooling.\n  Key words: Incremental Value-at-Risk (IVaR); Risk pooling; Risk adding.\n"
    },
    {
        "paper_id": "cond-mat/0204626",
        "authors": "D. Sornette (CNRS, Univ. Nice and UCLA), Y. Malevergne (Univ Nice and\n  Lyon I) and J.F. Muzy (CNRS, Univ. Corsica)",
        "title": "Volatility fingerprints of large shocks: Endogeneous versus exogeneous",
        "comments": "Latex document, 12 pages, 2 figures",
        "journal-ref": "What causes crashes? Risk Volume 16 (2), 67-71 (February 2003)",
        "doi": null,
        "license": null,
        "abstract": "  Finance is about how the continuous stream of news gets incorporated into\nprices. But not all news have the same impact. Can one distinguish the effects\nof the Sept. 11, 2001 attack or of the coup against Gorbachev on Aug., 19, 1991\nfrom financial crashes such as Oct. 1987 as well as smaller volatility bursts?\nUsing a parsimonious autoregressive process with long-range memory defined on\nthe logarithm of the volatility, we predict strikingly different response\nfunctions of the price volatility to great external shocks compared to what we\nterm endogeneous shocks, i.e., which result from the cooperative accumulation\nof many small shocks. These predictions are remarkably well-confirmed\nempirically on a hierarchy of volatility shocks. Our theory allows us to\nclassify two classes of events (endogeneous and exogeneous) with specific\nsignatures and characteristic precursors for the endogeneous class. It also\nexplains the origin of endogeneous shocks as the coherent accumulations of tiny\nbad news, and thus unify all previous explanations of large crashes including\nOct. 1987.\n"
    },
    {
        "paper_id": "cond-mat/0205078",
        "authors": "Lisa Borland",
        "title": "A Theory of Non_Gaussian Option Pricing",
        "comments": "Published version, revised",
        "journal-ref": "Quantitative Finance Vol 2 (2002) 415-431",
        "doi": null,
        "license": null,
        "abstract": "  Option pricing formulas are derived from a non-Gaussian model of stock\nreturns. Fluctuations are assumed to evolve according to a nonlinear\nFokker-Planck equation which maximizes the Tsallis nonextensive entropy of\nindex $q$. A generalized form of the Black-Scholes differential equation is\nfound, and we derive a martingale measure which leads to closed form solutions\nfor European call options. The standard Black-Scholes pricing equations are\nrecovered as a special case ($q = 1$). The distribution of stock returns is\nwell-modelled with $q$ circa 1.5. Using that value of $q$ in the option pricing\nmodel we reproduce the volatility smile. The partial derivatives (or Greeks) of\nthe model are also calculated. Empirical results are demonstrated for options\non Japanese Yen futures. Using just one value of $\\sigma$ across strikes we\nclosely reproduce market prices, for expiration times ranging from weeks to\nseveral months.\n"
    },
    {
        "paper_id": "cond-mat/0205083",
        "authors": "Christian Schulze",
        "title": "Market simulation with hierarchical information flux",
        "comments": "3 pages including 2 figures; for Int. J. Mod. Phys. C 13, No. 8",
        "journal-ref": null,
        "doi": "10.1142/S0129183102003838",
        "license": null,
        "abstract": "  We assume the market price to diffuse in a hierarchical comb of barriers, the\nheights of which represent the importance of new information entering the\nmarket. We find fat tails with the desired exponent for the price change\ndistribution, and effective multifractality for intermediate times.\n"
    },
    {
        "paper_id": "cond-mat/0205119",
        "authors": "Szilard Pafka, Imre Kondor",
        "title": "Noisy Covariance Matrices and Portfolio Optimization II",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01499-1",
        "license": null,
        "abstract": "  Recent studies inspired by results from random matrix theory [1,2,3] found\nthat covariance matrices determined from empirical financial time series appear\nto contain such a high amount of noise that their structure can essentially be\nregarded as random. This seems, however, to be in contradiction with the\nfundamental role played by covariance matrices in finance, which constitute the\npillars of modern investment theory and have also gained industry-wide\napplications in risk management. Our paper is an attempt to resolve this\nembarrassing paradox. The key observation is that the effect of noise strongly\ndepends on the ratio r = n/T, where n is the size of the portfolio and T the\nlength of the available time series. On the basis of numerical experiments and\nanalytic results for some toy portfolio models we show that for relatively\nlarge values of r (e.g. 0.6) noise does, indeed, have the pronounced effect\nsuggested by [1,2,3] and illustrated later by [4,5] in a portfolio optimization\ncontext, while for smaller r (around 0.2 or below), the error due to noise\ndrops to acceptable levels. Since the length of available time series is for\nobvious reasons limited in any practical application, any bound imposed on the\nnoise-induced error translates into a bound on the size of the portfolio. In a\nrelated set of experiments we find that the effect of noise depends also on\nwhether the problem arises in asset allocation or in a risk measurement\ncontext: if covariance matrices are used simply for measuring the risk of\nportfolios with a fixed composition rather than as inputs to optimization, the\neffect of noise on the measured risk may become very small.\n"
    },
    {
        "paper_id": "cond-mat/0205262",
        "authors": "A. C. C. Coolen",
        "title": "Non-equilibrium statistical mechanics of Minority Games",
        "comments": "14 pages, short review for Cergy 2002 conference proceedings",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper I give a brief introduction to a family of simple but\nnon-trivial models designed to increase our understanding of collective\nprocesses in markets, the so-called Minority Games, and their non-equilibrium\nstatistical mathematical analysis. Since the most commonly studied members of\nthis family define disordered stochastic processes without detailed balance,\nthe canonical technique for finding exact solutions is found to be generating\nfunctional analysis a la De Dominicis, as originally developed in the\nspin-glass community.\n"
    },
    {
        "paper_id": "cond-mat/0205320",
        "authors": "Gudrun Ehrenstein",
        "title": "Cont-Bouchaud percolation model including Tobin tax",
        "comments": "Expanded for of paper to be published in Int. J. Mod. Phys. C 13\n  (2002)",
        "journal-ref": null,
        "doi": "10.1142/S0129183102003917",
        "license": null,
        "abstract": "  The Tobin tax is an often discussed method to tame speculation and get a\nsource of income. The discussion is especially heated when the financial\nmarkets are in crisis. In this article we refer to foreign exchange markets.\nThe Tobin tax should be a small international tax affecting all currency\ntransactions and thus consequently reducing the destabilizing speculations. In\nthis way this tax should take over a control function. By including Tobin tax\nin the microscopic model of Cont and Bouchaud one finds that Tobin tax could be\nthe right method to control foreign exchange operations and get a good source\nof income\n"
    },
    {
        "paper_id": "cond-mat/0205482",
        "authors": "A. Z. Gorski, S. Drozdz, J. Speth",
        "title": "Financial multifractality and its subtleties: an example of DAX",
        "comments": "LaTeX 2.09 + RevTeX 3.1, 9 EPS figures",
        "journal-ref": "Physica A316 (2002) 496-510.",
        "doi": "10.1016/S0378-4371(02)01021-X",
        "license": null,
        "abstract": "  Detailed study of multifractal characteristics of the financial time series\nof asset values and of its returns is performed using a collection of the high\nfrequency Deutsche Aktienindex data. The tail index ($\\alpha$), the Renyi\nexponents based on the box counting algorithm for the graph ($d_q$) and the\ngeneralized Hurst exponents ($H_q$) are computed in parallel for short and\ndaily return times. The results indicate a more complicated nature of the stock\nmarket dynamics than just consistent multifractal.\n"
    },
    {
        "paper_id": "cond-mat/0205520",
        "authors": "Ernesto P. Borges (Escola Politecnica, Universidade Federal da Bahia,\n  Brazil, and Centro Brasileiro de Pesquisas Fisicas, Rio de Janeiro, Brazil)",
        "title": "Empirical nonextensive laws for the county distribution of total\n  personal income and gross domestic product",
        "comments": "LaTeX using elsart, 15 pages, 5 figures (8 eps files)",
        "journal-ref": "Physica A 334 (1-2), pp. 255-266 (2004)",
        "doi": "10.1016/j.physa.2003.11.003",
        "license": null,
        "abstract": "  We analyze the cumulative distribution of total personal income of USA\ncounties, and gross domestic product of Brazilian, German and United Kingdom\ncounties, and also of world countries.\n  We verify that generalized exponential distributions, related to nonextensive\nstatistical mechanics, describe almost the whole spectrum of the distributions\n(within acceptable errors), ranging from the low region to the middle region,\nand, in some cases, up to the power-law tail.\n  The analysis over about 30 years (for USA and Brazil) shows a regular pattern\nof the parameters appearing in the present phenomenological approach,\nsuggesting a possible connection between the underlying dynamics of (at least\nsome aspects of) the economy of a country (or of the whole world) and\nnonextensive statistical mechanics.\n  We also introduce two additional examples related to geographical\ndistributions: land areas of counties and land prices, and the same kind of\nequations adjust the data in the whole range of the spectrum.\n"
    },
    {
        "paper_id": "cond-mat/0205531",
        "authors": "Wei-Xing Zhou (UCLA) and Didier Sornette (UCLA and CNRS-Univ. Nice)",
        "title": "Non-Parametric Analyses of Log-Periodic Precursors to Financial Crashes",
        "comments": "Latex document 13 pages + 58 eps figures",
        "journal-ref": "Int. J. Mod. Phys. C 14 (8), 1107-1126 (2003)",
        "doi": "10.1142/S0129183103005212",
        "license": null,
        "abstract": "  We apply two non-parametric methods to test further the hypothesis that\nlog-periodicity characterizes the detrended price trajectory of large financial\nindices prior to financial crashes or strong corrections. The analysis using\nthe so-called (H,q)-derivative is applied to seven time series ending with the\nOctober 1987 crash, the October 1997 correction and the April 2000 crash of the\nDow Jones Industrial Average (DJIA), the Standard & Poor 500 and Nasdaq\nindices. The Hilbert transform is applied to two detrended price time series in\nterms of the ln(t_c-t) variable, where t_c is the time of the crash. Taking all\nresults together, we find strong evidence for a universal fundamental\nlog-frequency $f = 1.02 \\pm 0.05$ corresponding to the scaling ratio $\\lambda =\n2.67 \\pm 0.12$. These values are in very good agreement with those obtained in\npast works with different parametric techniques.\n"
    },
    {
        "paper_id": "cond-mat/0205636",
        "authors": "Y. Malevergne (Univ. Nice and Univ. Lyon) and D. Sornette (CNRS-Univ.\n  Nice and UCLA)",
        "title": "Hedging Extreme Co-Movements",
        "comments": "11 pages including 3 figures",
        "journal-ref": "Minimizing Extremes, RISK, November issue, 129-133 (2002)\n  (www.risk.net)",
        "doi": null,
        "license": null,
        "abstract": "  Based on a recent theorem due to the authors, it is shown how the extreme\ntail dependence between an asset and a factor or index or between two assets\ncan be easily calibrated. Portfolios constructed with stocks with minimal tail\ndependence with the market exhibit a remarkable degree of decorrelation with\nthe market at no cost in terms of performance measured by the Sharpe ratio.\n"
    },
    {
        "paper_id": "cond-mat/0206047",
        "authors": "D. Sornette (UCLA and CNRS-Univ. Nice) and A. Helmstetter (Univ.\n  Grenoble)",
        "title": "Endogeneous Versus Exogeneous Shocks in Systems with Memory",
        "comments": "Latex document of 14 pages with 3 eps figures",
        "journal-ref": "Physica A 318 (3-4), 577-591 (2003)",
        "doi": "10.1016/S0378-4371(02)01371-7",
        "license": null,
        "abstract": "  Systems with long-range persistence and memory are shown to exhibit different\nprecursory as well as recovery patterns in response to shocks of exogeneous\nversus endogeneous origins. By endogeneous, we envision either fluctuations\nresulting from an underlying chaotic dynamics or from a stochastic forcing\norigin which may be external or be an effective coarse-grained description of\nthe microscopic fluctuations. In this scenario, endogeneous shocks result from\na kind of constructive interference of accumulated fluctuations whose impacts\nsurvive longer than the large shocks themselves. As a consequence, the recovery\nafter an endogeneous shock is in general slower at early times and can be at\nlong times either slower or faster than after an exogeneous perturbation. This\noffers the tantalizing possibility of distinguishing between an endogeneous\nversus exogeneous cause of a given shock, even when there is no ``smoking\ngun.'' This could help in investigating the exogeneous versus self-organized\norigins in problems such as the causes of major biological extinctions, of\nchange of weather regimes and of the climate, in tracing the source of social\nupheaval and wars, and so on. Sornette, Malevergne and Muzy have already shown\nhow this concept can be applied concretely to differentiate the effects on\nfinancial markets of the Sept. 11, 2001 attack or of the coup against Gorbachev\non Aug., 19, 1991 (exogeneous) from financial crashes such as Oct. 1987\n(endogeneous).\n"
    },
    {
        "paper_id": "cond-mat/0206446",
        "authors": "R.D. Willmann, G. M. Schuetz, D. Challet",
        "title": "Exact Hurst exponent and crossover behavior in a limit order market\n  model",
        "comments": "13 pages, 10 figures, accepted for publication in Physica A",
        "journal-ref": "Physica A 316, 430 (2002)",
        "doi": "10.1016/S0378-4371(02)01217-7",
        "license": null,
        "abstract": "  An exclusion particle model is considered as a highly simplified model of a\nlimit order market. Its price behavior reproduces the well known crossover from\nover-diffusion (Hurst exponent H>1/2) to diffusion (H=1/2) when the time\nhorizon is increased, provided that orders are allowed to be canceled. For\nearly times a mapping to the totally asymmetric exclusion process yields the\nexact result H=2/3 which is in good agreement with empirical data. The\nunderlying universality class of the exclusion process suggests some robustness\nof the exponent with respect to changes in the trading rules. In the crossover\nregime the Hurst plot has a scaling property where the bulk\ndeposition/cancellation rate is the critical parameter. Analytical results are\nfully supported by numerical simulations.\n"
    },
    {
        "paper_id": "cond-mat/0206457",
        "authors": "Belal E. Baaquie, Marakani Srikant and Mitch Warachka",
        "title": "A Quantum Field Theory Term Structure Model Applied to Hedging",
        "comments": "7 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A quantum field theory generalization, Baaquie, of the Heath, Jarrow, and\nMorton (HJM) term structure model parsimoniously describes the evolution of\nimperfectly correlated forward rates. Field theory also offers powerful\ncomputational tools to compute path integrals which naturally arise from all\nforward rate models. Specifically, incorporating field theory into the term\nstructure facilitates hedge parameters that reduce to their finite factor HJM\ncounterparts under special correlation structures. Although investors are\nunable to perfectly hedge against an infinite number of term structure\nperturbations in a field theory model, empirical evidence using market data\nreveals the effectiveness of a low dimensional hedge portfolio.\n"
    },
    {
        "paper_id": "cond-mat/0206577",
        "authors": "Thomas Guhr (1) and Bernd Kaelber (2) ((1) Mathematical Physics, LTH,\n  Lunds Universitet, Lund, Sweden, (2) MPI Kernphysik, Heidelberg, Germany)",
        "title": "A New Method to Estimate the Noise in Financial Correlation Matrices",
        "comments": "25 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1088/0305-4470/36/12/310",
        "license": null,
        "abstract": "  Financial correlation matrices measure the unsystematic correlations between\nstocks. Such information is important for risk management. The correlation\nmatrices are known to be ``noise dressed''. We develop a new and alternative\nmethod to estimate this noise. To this end, we simulate certain time series and\nrandom matrices which can model financial correlations. With our approach,\ndifferent correlation structures buried under this noise can be detected.\nMoreover, we introduce a measure for the relation between noise and\ncorrelations. Our method is based on a power mapping which efficiently\nsuppresses the noise. Neither further data processing nor additional input is\nneeded.\n"
    },
    {
        "paper_id": "cond-mat/0207156",
        "authors": "Matteo Marsili",
        "title": "Dissecting financial markets: Sectors and states",
        "comments": "6 pages 4 figures. Additional information available at\n  http://www.sissa.it/dataclustering/fin/",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  By analyzing a large data set of daily returns with data clustering\ntechnique, we identify economic sectors as clusters of assets with a similar\neconomic dynamics. The sector size distribution follows Zipf's law. Secondly,\nwe find that patterns of daily market-wide economic activity cluster into\nclasses that can be identified with market states. The distribution of\nfrequencies of market states shows scale-free properties and the memory of the\nmarket state process extends to long times ($\\sim 50$ days). Assets in the same\nsector behave similarly across states. We characterize market efficiency by\nanalyzing market's predictability and find that indeed the market is close to\nbeing efficient. We find evidence of the existence of a dynamic pattern after\nmarket's crashes.\n"
    },
    {
        "paper_id": "cond-mat/0207181",
        "authors": "Christian Schulze",
        "title": "Advertising effects in Sznajd marketing model",
        "comments": "5 pages including 3 figs., for IJMPC 14, No.1",
        "journal-ref": null,
        "doi": "10.1142/S0129183103004255",
        "license": null,
        "abstract": "  The traditional Sznajd model, as well as its Ochrombel simplification for\nopinion spreading, are applied to marketing with the help of advertising. The\nlarger the lattice is the smaller is the amount of advertising needed to\nconvince the whole market\n"
    },
    {
        "paper_id": "cond-mat/0207227",
        "authors": "Danuta Makowiec",
        "title": "Stock Market Scale by Artificial Insymmetrised Patterns",
        "comments": "14 pages(LATEX), 14 figures (JPEG)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Large and stable indices of the world wide stock markets such as NYSE and SP\n500 together with NASDAQ -- the index representing markets of new trends, and\nWIG -- the index of the local stock market of Eastern Europe, are considered.\nDue to the relation between artificial insymmetrised patterns (AIP) and time\nseries, stationary and temporary properties of stock market indices are\nidentified. By filtering extreme events it is found that fluctuations are\nself-similar. Snap-shots in time lead to estimates for a temporary state of a\nmarket with respect to its history. It appears that close to a crash the AIP\nrepresentation of a system becomes frozen.\n"
    },
    {
        "paper_id": "cond-mat/0207253",
        "authors": "Taisei Kaizoji (ICU Tokyo), Stefan Bornholdt (U Kiel), Yoshi Fujiwara\n  (KRC Kyoto)",
        "title": "Dynamics of price and trading volume in a spin model of stock markets\n  with heterogeneous agents",
        "comments": "14 pages LaTeX, 6 figures",
        "journal-ref": "Physica A 316 (2002) 441-452",
        "doi": "10.1016/S0378-4371(02)01216-5",
        "license": null,
        "abstract": "  The dynamics of a stock market with heterogeneous agents is discussed in the\nframework of a recently proposed spin model for the emergence of bubbles and\ncrashes. We relate the log returns of stock prices to magnetization in the\nmodel and find that it is closely related to trading volume as observed in real\nmarkets. The cumulative distribution of log returns exhibits scaling with\nexponents steeper than 2 and scaling is observed in the distribution of\ntransition times between bull and bear markets.\n"
    },
    {
        "paper_id": "cond-mat/0207280",
        "authors": "Friedrich Wagner",
        "title": "Volatility Cluster and Herding",
        "comments": "15 pages TeX, 6 figures PostScript",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01810-1",
        "license": null,
        "abstract": "  Stock markets can be characterized by fat tails in the volatility\ndistribution, clustering of volatilities and slow decay of their time\ncorrelations. For an explanation models with several mechanisms and\nconsequently many parameters as the Lux-Marchesi model have been used. We show\nthat a simple herding model with only four parameters leads to a quantitative\ndescription of the data. As a new type of data we describe the volatility\ncluster by the waiting time distribution, which can be used successfully to\ndistinguish between different models.\n"
    },
    {
        "paper_id": "cond-mat/0207376",
        "authors": "Fredrick Michael, John Evans, M.D. Johnson",
        "title": "Excess Demand Financial Market Model",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Recently we reported on an application of the Tsallis non-extensive\nstatistics to the S&P500 stock index. There we argued that the statistics are\napplicable to a broad range of markets and exchanges where anamolous (super)\ndiffusion and 'heavy' tails of the distribution are present, as they are in the\nS&P500. We have characterized the statistics of the underlying security as\nnon-extensive, and now we seek to generalize to the non-extensive statistics\nthe excess demand models of investors that drive the price formation in a\nmarket.\n"
    },
    {
        "paper_id": "cond-mat/0207428",
        "authors": "Fabrizio Lillo, J. Doyne Farmer, Rosario N. Mantegna",
        "title": "Single Curve Collapse of the Price Impact Function for the New York\n  Stock Exchange",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the average price impact of a single trade executed in the NYSE.\nAfter appropriate averaging and rescaling, the data for the 1000 most highly\ncapitalized stocks collapse onto a single function, giving average price shift\nas a function of trade size. This function increases as a power that is the\norder of 1/2 for small volumes, but then increases more slowly for large\nvolumes. We obtain similar results in each year from the period 1995 - 1998. We\nalso find that small volume liquidity scales as a power of the stock\ncapitalization.\n"
    },
    {
        "paper_id": "cond-mat/0207475",
        "authors": "Y. Malevergne (Univ. Nice and Univ. Lyon) and D. Sornette (CNRS-Univ.\n  Nice and UCLA)",
        "title": "Multi-Moments Method for Portfolio Management: Generalized Capital Asset\n  Pricing Model in Homogeneous and Heterogeneous markets",
        "comments": "42 pages of text + 5 tables + 21 figures",
        "journal-ref": "In ``Multi-moment Asset Allocation and Pricing Models'', B.\n  Maillet and E. Jurczenko eds., Wiley & Sons, pp. 165-193 (2006)",
        "doi": null,
        "license": null,
        "abstract": "  We introduce a new set of consistent measures of risks, in terms of the\nsemi-invariants of pdf's, such that the centered moments and the cumulants of\nthe portfolio distribution of returns that put more emphasis on the tail the\ndistributions. We derive generalized efficient frontiers, based on these novel\nmeasures of risks and present the generalized CAPM, both in the cases of\nhomogeneous and heterogeneous markets. Then, using a family of modified Weibull\ndistributions, encompassing both sub-exponentials and super-exponentials, to\nparameterize the marginal distributions of asset returns and their natural\nmultivariate generalizations, we offer exact formulas for the moments and\ncumulants of the distribution of returns of a portfolio made of an arbitrary\ncomposition of these assets. Using combinatorial and hypergeometric functions,\nwe are in particular able to extend previous results to the case where the\nexponents of the Weibull distributions are different from asset to asset and in\nthe presence of dependence between assets. In this parameterization, we treat\nin details the problem of risk minimization using the cumulants as measures of\nrisks for a portfolio made of two assets and compare the theoretical\npredictions with direct empirical data. Our extended formulas enable us to\ndetermine analytically the conditions under which it is possible to ``have your\ncake and eat it too'', i.e., to construct a portfolio with both larger return\nand smaller ``large risks''.\n"
    },
    {
        "paper_id": "cond-mat/0207523",
        "authors": "Paul Jefferies, Neil F. Johnson",
        "title": "Designing agent-based market models",
        "comments": "31 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In light of the growing interest in agent-based market models, we bring\ntogether several earlier works in which we considered the topic of\nself-consistent market modelling. Building upon the binary game structure of\nChallet and Zhang, we discuss generalizations of the strategy reward scheme\nsuch that the agents seek to maximize their wealth in a more direct way. We\nthen examine a disturbing feature whereby such reward schemes, while appearing\nmicroscopically acceptable, lead to unrealistic market dynamics (e.g.\ninstabilities). Finally, we discuss various mechanisms which are responsible\nfor re-stabilizing the market in reality. This discussion leads to a `toolbox'\nof processes from which, we believe, successful market models can be\nconstructed in the future.\n"
    },
    {
        "paper_id": "cond-mat/0207555",
        "authors": "Dirk Tasche",
        "title": "Remarks on the monotonicity of default probabilities",
        "comments": "8 pages, LaTeX with hyperref package",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The consultative papers for the Basel II Accord require rating systems to\nprovide a ranking of obligors in the sense that the rating categories indicate\nthe creditworthiness in terms of default probabilities. As a consequence, the\ndefault probabilities ought to present a monotonous function of the ordered\nrating categories. This requirement appears quite intuitive. In this paper,\nhowever, we show that the intuition can be founded on mathematical facts. We\nprove that, in the closely related context of a continuous score function,\nmonotonicity of the conditional default probabilities is equivalent to\noptimality of the corresponding decision rules in the test-theoretic sense. As\na consequence, the optimality can be checked by inspection of the ordinal\ndominance graph (also called Receiver Operating Characteristic curve) of the\nscore function: it obtains if and only if the curve is concave. We conclude the\npaper by exploring the connection between the area under the ordinal dominance\ngraph and the so-called Information Value which is used by some vendors of\nscoring systems.\n  Keywords: Conditional default probability, score function, most powerful\ntest, Information Value, Accuracy Ratio.\n"
    },
    {
        "paper_id": "cond-mat/0207750",
        "authors": "Alexandre Kurth and Dirk Tasche",
        "title": "Credit Risk Contributions to Value-at-Risk and Expected Shortfall",
        "comments": "12 pages, LaTeX with hyperref package, references updated",
        "journal-ref": "Risk 16(3) (March 2003), 84-88",
        "doi": null,
        "license": null,
        "abstract": "  This paper presents analytical solutions to the problem of how to calculate\nsensible VaR (Value-at-Risk) and ES (Expected Shortfall) contributions in the\nCreditRisk+ methodology. Via the ES contributions, ES itself can be exactly\ncomputed in finitely many steps. The methods are illustrated by numerical\nexamples.\n"
    },
    {
        "paper_id": "cond-mat/0208191",
        "authors": "Belal E. Baaquie, Claudio Coriano, Marakani Srikant",
        "title": "Quantum Mechanics, Path Integrals and Option Pricing: Reducing the\n  Complexity of Finance",
        "comments": "10 pages, 4 figures, presented by C.Coriano at the Intl. Workshop\n  \"Nonlinear Physics, THeory and Experiment II\", Gallipoli, Lecce, June 28-July\n  6, 2002",
        "journal-ref": null,
        "doi": "10.1142/9789812704467_0046",
        "license": null,
        "abstract": "  Quantum Finance represents the synthesis of the techniques of quantum theory\n(quantum mechanics and quantum field theory) to theoretical and applied\nfinance. After a brief overview of the connection between these fields, we\nillustrate some of the methods of lattice simulations of path integrals for the\npricing of options. The ideas are sketched out for simple models, such as the\nBlack-Scholes model, where analytical and numerical results are compared.\nApplication of the method to nonlinear systems is also briefly overviewed. More\ngeneral models, for exotic or path-dependent options are discussed.\n"
    },
    {
        "paper_id": "cond-mat/0208240",
        "authors": "S. Drozdz, J. Kwapien, F. Gruemmer, F. Ruf, and J. Speth",
        "title": "Are the contemporary financial fluctuations sooner converging to normal?",
        "comments": "14 pages, revised version",
        "journal-ref": "Acta Phys. Pol. B 34 (2003) 4293-4306",
        "doi": null,
        "license": null,
        "abstract": "  Based on the tick-by-tick price changes of the companies from the U.S. and\nfrom the German stock markets over the period 1998-99 we reanalyse several\ncharacteristics established by the Boston Group for the U.S. market in the\nperiod 1994-95, which serves to verify their space and time-translational\ninvariance. By increasing the time scales we find a significantly more\naccelerated crossover from the power-law (alpha approximately 3) asymptotic\nbehaviour of the distribution of returns towards a Gaussian, both for the U.S.\nas well as for the German stock markets. In the latter case the crossover is\neven faster. Consistently, the corresponding autocorrelation functions of\nreturns and of the time averaged volatility also indicate a faster loss of\nmemory with increasing time. This route towards efficiency may reflect a\nsystematic increase of the information processing when going from past to\npresent.\n"
    },
    {
        "paper_id": "cond-mat/0208310",
        "authors": "Peter Ruch, Joseph Wakeling, Yi-Cheng Zhang",
        "title": "The Interactive Minority Game: Instructions for Experts",
        "comments": "5 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Interactive Minority Game (IMG) is an online version of the traditional\nMinority Game in which human players can enter into competition with the\ntraditional computer-controlled agents. Through the rich (and, importantly,\nanalytically understood) behaviour of the MG, we can explore humans' behaviour\nin different kinds of market--crowded, efficient, critical--with a high degree\nof control. To make the game easily understandable even to those who are\nencountering it for the first time, we have presented the game with a rather\nsimplified interface; in this working paper we explain the underlying technical\naspects for those who have experience with the traditional MG.\n"
    },
    {
        "paper_id": "cond-mat/0208398",
        "authors": "Yoshi Fujiwara, Wataru Souma, Hideaki Aoyama, Taisei Kaizoji, and\n  Masanao Aoki",
        "title": "Growth and Fluctuations of Personal Income",
        "comments": "9 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01663-1",
        "license": null,
        "abstract": "  Pareto's law states that the distribution of personal income obeys a\npower-law in the high-income range, and has been supported by international\nobservations. Researchers have proposed models over a century since its\ndiscovery. However, the dynamical nature of personal income has been little\nstudied hitherto, mostly due to the lack of empirical work. Here we report the\nfirst such study, an examination of the fluctuations in personal income of\nabout 80,000 high-income taxpayers in Japan for two consecutive years, 1997 and\n1998, when the economy was relatively stable. We find that the distribution of\nthe growth rate in one year is independent of income in the previous year. This\nfact, combined with an approximate time-reversal symmetry, leads to the Pareto\nlaw, thereby explaining it as a consequence of a stable economy. We also derive\na scaling relation between positive and negative growth rates, and show good\nagreement with the data. These findings provide the direct observation of the\ndynamical process of personal income flow not yet studied as much as for\ncompanies.\n"
    },
    {
        "paper_id": "cond-mat/0208464",
        "authors": "Ofer Biham, Zhi-Feng Huang, Ofer Malcai and Sorin Solomon",
        "title": "Long-Time Fluctuations in a Dynamical Model of Stock Market Indices",
        "comments": null,
        "journal-ref": "phys. rev. E 64, 026101 (2001)",
        "doi": "10.1103/PhysRevE.64.026101",
        "license": null,
        "abstract": "  Financial time series typically exhibit strong fluctuations that cannot be\ndescribed by a Gaussian distribution. In recent empirical studies of stock\nmarket indices it was examined whether the distribution P(r) of returns r(tau)\nafter some time tau can be described by a (truncated) Levy-stable distribution\nL_{alpha}(r) with some index 0 < alpha <= 2. While the Levy distribution cannot\nbe expressed in a closed form, one can identify its parameters by testing the\ndependence of the central peak height on tau as well as the power-law decay of\nthe tails. In an earlier study [Mantegna and Stanley, Nature 376, 46 (1995)] it\nwas found that the behavior of the central peak of P(r) for the Standard & Poor\n500 index is consistent with the Levy distribution with alpha=1.4. In a more\nrecent study [Gopikrishnan et al., Phys. Rev. E 60, 5305 (1999)] it was found\nthat the tails of P(r) exhibit a power-law decay with an exponent alpha ~= 3,\nthus deviating from the Levy distribution. In this paper we study the\ndistribution of returns in a generic model that describes the dynamics of stock\nmarket indices. For the distributions P(r) generated by this model, we observe\nthat the scaling of the central peak is consistent with a Levy distribution\nwhile the tails exhibit a power-law distribution with an exponent alpha > 2,\nnamely beyond the range of Levy-stable distributions. Our results are in\nagreement with both empirical studies and reconcile the apparent disagreement\nbetween their results.\n"
    },
    {
        "paper_id": "cond-mat/0208514",
        "authors": "Ofer Malcai, Ofer Biham, Peter Richmond and Sorin Solomon",
        "title": "Theoretical Analysis and Simulations of the Generalized Lotka-Volterra\n  Model",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.66.031102",
        "license": null,
        "abstract": "  The dynamics of generalized Lotka-Volterra systems is studied by theoretical\ntechniques and computer simulations. These systems describe the time evolution\nof the wealth distribution of individuals in a society, as well as of the\nmarket values of firms in the stock market. The individual wealths or market\nvalues are given by a set of time dependent variables $w_i$, $i=1,...N$. The\nequations include a stochastic autocatalytic term (representing investments), a\ndrift term (representing social security payments) and a time dependent\nsaturation term (due to the finite size of the economy). The $w_i$'s turn out\nto exhibit a power-law distribution of the form $P(w) \\sim w^{-1-\\alpha}$. It\nis shown analytically that the exponent $\\alpha$ can be expressed as a function\nof one parameter, which is the ratio between the constant drift component\n(social security) and the fluctuating component (investments). This result\nprovides a link between the lower and upper cutoffs of this distribution,\nnamely between the resources available to the poorest and those available to\nthe richest in a given society. The value of $\\alpha$ %as well as the position\nof the lower cutoff is found to be insensitive to variations in the saturation\nterm, that represent the expansion or contraction of the economy. The results\nare of much relevance to empirical studies that show that the distribution of\nthe individual wealth in different countries during different periods in the\n20th century has followed a power-law distribution with $1 < \\alpha < 2$.\n"
    },
    {
        "paper_id": "cond-mat/0208528",
        "authors": "Belal E. Baaquie, Marakani Srikant",
        "title": "Comparison of Field Theory Models of Interest Rates with Market Data",
        "comments": "9 figures",
        "journal-ref": "Phys. Rev. E 69, 036129 (2004)",
        "doi": "10.1103/PhysRevE.69.036129",
        "license": null,
        "abstract": "  We calibrate and test various variants of field theory models of the interest\nrate with data from eurodollars futures. A model based on a simple\npsychological factor are seen to provide the best fit to the market. We make a\nmodel independent determination of the volatility function of the forward rates\nfrom market data.\n"
    },
    {
        "paper_id": "cond-mat/0208574",
        "authors": "T. Mart",
        "title": "Statistical properties of the Jakarta and Kuala Lumpur stock exchange\n  indices before and after crash",
        "comments": "10 pages, 14 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Using the tools developed for statistical physics, we simultaneously analyze\nstatistical properties of the Jakarta and Kuala Lumpur Stock Exchange indices.\nIn spite of the small number of data used in the analysis, the result shows the\nuniversal behavior of complex systems previously found in the leading stock\nindices. We also analyze their features before and after the financial crisis.\nWe found that after the crisis both stocks do not show a same statistical\nbehavior. The impact of currency controls is observed in the distribution of\nindex returns.\n"
    },
    {
        "paper_id": "cond-mat/0209065",
        "authors": "D. Sornette (CNRS-Univ. Nice and UCLA) and W.-X. Zhou (UCLA)",
        "title": "The US 2000-2002 Market Descent: How Much Longer and Deeper?",
        "comments": "15 pages + 3 tables + 13 figures",
        "journal-ref": "Quantitative Finance 2 (6), 468-481 (2002)",
        "doi": null,
        "license": null,
        "abstract": "  A remarkable similarity in the behavior of the US S&P500 index from 1996 to\nAugust 2002 and of the Japanese Nikkei index from 1985 to 1992 (11 years shift)\nis presented, with particular emphasis on the structure of the bearish phases.\nExtending a previous analysis of Johansen and Sornette [1999, 2000] on the\nNikkei index ``anti-bubble'' based on a theory of cooperative herding and\nimitation working both in bullish as well as in bearish regimes, we demonstrate\nthe existence of a clear signature of herding in the decay of the S&P500 index\nsince August 2000 with high statistical significance, in the form of strong\nlog-periodic components. We offer a detailed analysis of what could be the\nfuture evolution of the S&P500 index over the next two years, according to\nthree versions of the theory: we expect an overall continuation of the bearish\nphase, punctuated by local rallies; we predict an overall increasing market\nuntil the end of the year 2002 or at the beginning of 2003 (first quarter); we\npredict a strong following descent (with maybe one or two severe up and downs\nin the middle) which stops during the first semester of 2004. After this strong\nminimum, the market is expected to recover. Beyond, our prediction horizon is\nmade fuzzy by the possible effect of additional nonlinear collective effects\nand of a real departure from the anti-bubble regime. The similarities between\nthe two stock market indices may reflect deeper similarities between the\nfundamentals of two economies which both went through over-valuation with\nstrong speculative phases preceding the transition to bearish phases\ncharacterized by a surprising number of bad surprises (bad loans for Japan and\naccounting frauds for the US) sapping investors' confidence.\n"
    },
    {
        "paper_id": "cond-mat/0209103",
        "authors": "M. Serva, U.L. Fulco, M.L. Lyra and G.M. Viswanathan",
        "title": "Kinematics of stock prices",
        "comments": "subm. Phys. Rev. Lett",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate the general problem of how to model the kinematics of stock\nprices without considering the dynamical causes of motion. We propose a\nstochastic process with long-range correlated absolute returns. We find that\nthe model is able to reproduce the experimentally observed clustering, power\nlaw memory, fat tails and multifractality of real financial time series. We\nfind that the distribution of stock returns is approximated by a Gaussian with\nlog-normally distributed local variance and shows excellent agreement with the\nbehavior of the NYSE index for a range of time scales.\n"
    },
    {
        "paper_id": "cond-mat/0209343",
        "authors": "Belal E. Baaquie and Marakani Srikant",
        "title": "Hedging in Field Theory Models of the Term Structure",
        "comments": "18 figures, Invited Talk, International Econophysics Conference,\n  Bali, 28-31 August 2002",
        "journal-ref": "Phys. Rev. E 69, 036130 (2004)",
        "doi": "10.1103/PhysRevE.69.036130",
        "license": null,
        "abstract": "  We use path integrals to calculate hedge parameters and efficacy of hedging\nin a quantum field theory generalization of the Heath, Jarrow and Morton (HJM)\nterm structure model which parsimoniously describes the evolution of\nimperfectly correlated forward rates. We also calculate, within the model\nspecification, the effectiveness of hedging over finite periods of time. We use\nempirical estimates for the parameters of the model to show that a low\ndimensional hedge portfolio is quite effective.\n"
    },
    {
        "paper_id": "cond-mat/0209373",
        "authors": "Nicola Scafetta, Sergio Picozzi and Bruce J. West",
        "title": "Pareto's law: a model of human sharing and creativity",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A computational model for the distribution of wealth among the members of an\nideal society is presented. It is determined that a realistic distribution of\nwealth depends upon two mechanisms: an asymmetric flux of wealth in trading\ntransactions that advantages the poorer of the two traders and a non-stationary\ncreation and destruction of individual wealth. The former mechanism\nredistributes wealth by reducing the gap between the rich and poor, leading to\nthe emergence of a middle class. The latter mechanism, together with the former\none, generates a distribution of wealth having a power-law tail that is\ncompatible with Pareto's law.\n"
    },
    {
        "paper_id": "cond-mat/0209446",
        "authors": "Daniel O. Badagnani",
        "title": "Statistical Bounds on Equity",
        "comments": "6 Pages, shows how Boltzman distribution can be used i economics",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We derive the most probable distribution of resources for a simple society.\nWe find that a probabilistic analysis forbids both too much and too less\nequity, and selects instead a minimally ordered state. We give the detailed\ncalculations for a special model where the population and resources are fixed,\nand resources are owned only by individuals. We show that in general the equity\nis greater whenever the volume of the indifference manifold grows faster as a\nfunction of individual rent.\n"
    },
    {
        "paper_id": "cond-mat/0209475",
        "authors": "Gemunu H. Gunaratne and Joseph L. McCauley",
        "title": "A theory for Fluctuations in Stock Prices and Valuation of their Options",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A new theory for pricing options of a stock is presented. It is based on the\nassumption that while successive variations in return are uncorrelated, the\nfrequency with which a stock is traded depends on the value of the return. The\nsolution to the Fokker-Planck equation is shown to be an asymmetric exponential\ndistribution, similar to those observed in intra-day currency markets. The\n\"volatility smile,\" used by traders to correct the Black-Scholes pricing is\nshown to provide an alternative mechanism to implement the new options pricing\nformulae derived from our theory.\n"
    },
    {
        "paper_id": "cond-mat/0209522",
        "authors": "Daniel Faller and Francesco Petruccione",
        "title": "A master equation approach to option pricing",
        "comments": "19 pages, 6 figures, to be published in Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01530-3",
        "license": null,
        "abstract": "  A master equation approach to the numerical solution of option pricing models\nis developed. The basic idea of the approach is to consider the Black--Scholes\nequation as the macroscopic equation of an underlying mesoscopic stochastic\noption price variable. The dynamics of the latter is constructed and formulated\nin terms of a master equation. The numerical efficiency of the approach is\ndemonstrated by means of stochastic simulation of the mesoscopic process for\nboth European and American options.\n"
    },
    {
        "paper_id": "cond-mat/0209591",
        "authors": "S. Drozdz, F. Grummer, F. Ruf, J. Speth",
        "title": "Log-periodic self-similarity: an emerging financial law?",
        "comments": "Talk given by S. Drozdz at International Econophysics Conference,\n  Bali, August 28-31, 2002; typos corrected",
        "journal-ref": "Physica A 324 (2003) 174-182",
        "doi": "10.1016/S0378-4371(02)01848-4",
        "license": null,
        "abstract": "  A hypothesis that the financial log-periodicity, cascading self-similarity\nthrough various time scales, carries signatures of a law is pursued. It is\nshown that the most significant historical financial events can be classified\namazingly well using a single and unique value of the preferred scaling factor\nlambda=2, which indicates that its real value should be close to this number.\nThis applies even to a declining decelerating log-periodic phase. Crucial in\nthis connection is identification of a \"super-bubble\" (bubble on bubble)\nphenomenon. Identifying a potential \"universal\" preferred scaling factor, as\nundertaken here, may significantly improve the predictive power of the\ncorresponding methodology. Several more specific related results include\nevidence that: (i) the real end of the high technology bubble on the stock\nmarket started (with a decelerating log-periodic draw down) in the begining of\nSeptember 2000; (ii) a parallel 2000-2002 decline seen in the Standard & Poor's\n500 from the log-periodic perspective is already of the same significance as\nthe one of the early 1930s and of the late 1970s; (iii) all this points to a\nmuch more serious global crash in around 2025, of course from a level much\nhigher (at least one order of magnitude) than in 2000.\n"
    },
    {
        "paper_id": "cond-mat/0209685",
        "authors": "Fabrizio Lillo, Rosario N. Mantegna",
        "title": "Dynamics of a financial market index after a crash",
        "comments": "5 pages, 3 figures. Proceedings of the 8th conference \"Computing in\n  Economics and Finance\"",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We discuss the statistical properties of index returns in a financial market\njust after a major market crash. The observed non-stationary behavior of index\nreturns is characterized in terms of the exceedances over a given threshold.\nThis characterization is analogous to the Omori law originally observed in\ngeophysics. By performing numerical simulations and theoretical modelling, we\nshow that the nonlinear behavior observed in real market crashes cannot be\ndescribed by a GARCH(1,1) model. We also show that the time evolution of the\nValue at Risk observed just after a major crash is described by a power-law\nfunction lacking a typical scale.\n"
    },
    {
        "paper_id": "cond-mat/0210090",
        "authors": "Naoki Kozuki and Nobuko Fuchikami",
        "title": "Dynamical model of financial markets: fluctuating `temperature' causes\n  intermittent behavior of price changes",
        "comments": "9 pages including 2 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(03)00592-2",
        "license": null,
        "abstract": "  We present a model of financial markets originally proposed for a turbulent\nflow, as a dynamic basis of its intermittent behavior. Time evolution of the\nprice change is assumed to be described by Brownian motion in a power-law\npotential, where the `temperature' fluctuates slowly. The model generally\nyields a fat-tailed distribution of the price change. Specifically a Tsallis\ndistribution is obtained if the inverse temperature is $\\chi^{2}$-distributed,\nwhich qualitatively agrees with intraday data of foreign exchange market. The\nso-called `volatility', a quantity indicating the risk or activity in financial\nmarkets, corresponds to the temperature of markets and its fluctuation leads to\nintermittency.\n"
    },
    {
        "paper_id": "cond-mat/0210115",
        "authors": "Y. Malevergne (Univ. Nice and Univ. Lyon) and D. Sornette (CNRS-Univ.\n  Nice and UCLA)",
        "title": "Collective Origin of the Coexistence of Apparent RMT Noise and Factors\n  in Large Sample Correlation Matrices",
        "comments": "4 pages with 3 figure",
        "journal-ref": "Physica A 331 (3-4), 660-668 (2004)",
        "doi": "10.1016/j.physa.2003.09.004",
        "license": null,
        "abstract": "  Through simple analytical calculations and numerical simulations, we\ndemonstrate the generic existence of a self-organized macroscopic state in any\nlarge multivariate system possessing non-vanishing average correlations between\na finite fraction of all pairs of elements. The coexistence of an eigenvalue\nspectrum predicted by random matrix theory (RMT) and a few very large\neigenvalues in large empirical correlation matrices is shown to result from a\nbottom-up collective effect of the underlying time series rather than a\ntop-down impact of factors. Our results, in excellent agreement with previous\nresults obtained on large financial correlation matrices, show that there is\nrelevant information also in the bulk of the eigenvalue spectrum and\nrationalize the presence of market factors previously introduced in an ad hoc\nmanner.\n"
    },
    {
        "paper_id": "cond-mat/0210475",
        "authors": "Eric Smith, J. Doyne Farmer, Laszlo Gillemot, Supriya Krishnamurthy",
        "title": "Statistical theory of the continuous double auction",
        "comments": "36 pages, 40 figures, RevTex4, submitted to Quantitative Finance",
        "journal-ref": null,
        "doi": "10.1088/1469-7688/3/6/307",
        "license": null,
        "abstract": "  Most modern financial markets use a continuous double auction mechanism to\nstore and match orders and facilitate trading. In this paper we develop a\nmicroscopic dynamical statistical model for the continuous double auction under\nthe assumption of IID random order flow, and analyze it using simulation,\ndimensional analysis, and theoretical tools based on mean field approximations.\nThe model makes testable predictions for basic properties of markets, such as\nprice volatility, the depth of stored supply and demand vs. price, the bid-ask\nspread, the price impact function, and the time and probability of filling\norders. These predictions are based on properties of order flow and the limit\norder book, such as share volume of market and limit orders, cancellations,\ntypical order size, and tick size. Because these quantities can all be measured\ndirectly there are no free parameters. We show that the order size, which can\nbe cast as a nondimensional granularity parameter, is in most cases a more\nsignificant determinant of market behavior than tick size. We also provide an\nexplanation for the observed highly concave nature of the price impact\nfunction. On a broader level, this work suggests how stochastic models based on\nzero-intelligence agents may be useful to probe the structure of market\ninstitutions. Like the model of perfect rationality, a stochastic-zero\nintelligence model can be used to make strong predictions based on a compact\nset of assumptions, even if these assumptions are not fully believable.\n"
    },
    {
        "paper_id": "cond-mat/0210499",
        "authors": "M. Ausloos and Ph. Bronlet",
        "title": "Strategy for investments from Zipf law(s)",
        "comments": "submitted to Physica A;Proceedings ICE02, Bali, Aug.28-31, 2002",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01845-9",
        "license": null,
        "abstract": "  We have applied the Zipf method to extract the $\\zeta'$ exponent for seven\nfinancial indices (DAX, FTSE; DJIA, NASDAQ, S&P500; Hang-Seng and Nikkei 225),\nafter having translated the signals into a text based on two letters. We follow\nconsiderations based on the signal Hurst exponent and the notion of a time\ndependent Zipf law and exponent in order to implement two simple investment\nstrategies for such indices. We show the time dependence of the returns.\n"
    },
    {
        "paper_id": "cond-mat/0210509",
        "authors": "A. Johansen (Riso National Lab., Denmark) and D. Sornette (UCLA and\n  CNRS-Univ. Nice)",
        "title": "Endogenous versus Exogenous Crashes in Financial Markets",
        "comments": "Latex, 34 pages with 11 tables and 47 figures",
        "journal-ref": "Shocks, Crashes and Bubbles in Financial Markets, Brussels\n  Economic Review 53 (2), 201-253 (2010)",
        "doi": null,
        "license": null,
        "abstract": "  We perform an extended analysis of the distribution of drawdowns in the two\nleading exchange markets (US dollar against the Deutsmark and against the Yen),\nin the major world stock markets, in the U.S. and Japanese bond market and in\nthe gold market, by introducing the concept of ``coarse-grained drawdowns,''\nwhich allows for a certain degree of fuzziness in the definition of cumulative\nlosses and improves on the statistics of our previous results on the existence\nof ``outliers'' or ``kings.'' Then, for each identified outlier, we check\nwhether log-periodic power law signatures (LPPS) are present and take the\nexistence of LPPS as the qualifying signature for an endogenous crash: this is\nbecause a drawdown outlier is seen as the end of a speculative unsustainable\naccelerating bubble generated endogenously. In the absence of LPPS, we are able\nto identify what seems to have been the relevant historical event, i.e., a new\npiece of information of such magnitude and impact that it is seems reasonable\nto attribute the crash to it, in agreement with the standard view of the\nefficient market hypothesis. Such drawdown outliers are classified as having an\nexogenous origin. Globally over all the markets analyzed, we identify 49\noutliers, of which 25 are classified as endogenous, 22 as exogeneous and 2 as\nassociated with the Japanese anti-bubble. Restricting to the world market\nindices, we find 31 outliers, of which 19 are endogenous, 10 are exogenous and\n2 are associated with the Japanese anti-bubble. The combination of the two\nproposed detection techniques, one for drawdown outliers and the second for\nLPPS, provides a novel and systematic taxonomy of crashes further subtantiating\nthe importance of LPPS.\n"
    },
    {
        "paper_id": "cond-mat/0210513",
        "authors": "Jaume Masoliver, Miquel Montero and George H. Weiss",
        "title": "A continuous time random walk model for financial distributions",
        "comments": "14 pages, 5 figures, revtex4, submitted for publication",
        "journal-ref": "Physical Review E 67, 021112 (2003)",
        "doi": "10.1103/PhysRevE.67.021112",
        "license": null,
        "abstract": "  We apply the formalism of the continuous time random walk to the study of\nfinancial data. The entire distribution of prices can be obtained once two\nauxiliary densities are known. These are the probability densities for the\npausing time between successive jumps and the corresponding probability density\nfor the magnitude of a jump. We have applied the formalism to data on the US\ndollar/Deutsche Mark future exchange, finding good agreement between theory and\nthe observed data.\n"
    },
    {
        "paper_id": "cond-mat/0210549",
        "authors": "Damien Challet and Matteo Marsili",
        "title": "Criticality and finite size effects in a simple realistic model of stock\n  market",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.68.036132",
        "license": null,
        "abstract": "  We discuss a simple model based on the Minority Game which reproduces the\nmain stylized facts of anomalous fluctuations in finance. We present the\nanalytic solution of the model in the thermodynamic limit and show that\nstylized facts arise only close to a line of critical points with non-trivial\nproperties. By a simple argument, we show that, in Minority Games, the\nemergence of critical fluctuations close to the phase transition is governed by\nthe interplay between the signal to noise ratio and the system size. These\nresults provide a clear and consistent picture of financial markets as critical\nsystems.\n"
    },
    {
        "paper_id": "cond-mat/0211039",
        "authors": "Mogens H. Jensen, Anders Johansen, and Ingve Simonsen",
        "title": "Inverse Statistics in Economics : The gain-loss asymmetry",
        "comments": "Latex, 6 pages, 3 figures",
        "journal-ref": "Physica A 324, 338 (2003).",
        "doi": "10.1016/S0378-4371(02)01884-8",
        "license": null,
        "abstract": "  Inverse statistics in economics is considered. We argue that the natural\ncandidate for such statistics is the investment horizons distribution. This\ndistribution of waiting times needed to achieve a predefined level of return is\nobtained from (often detrended) historic asset prices. Such a distribution\ntypically goes through a maximum at a time called the {\\em optimal investment\nhorizon}, $\\tau^*_\\rho$, since this defines the most likely waiting time for\nobtaining a given return $\\rho$. By considering equal positive and negative\nlevels of return, we report on a quantitative gain-loss asymmetry most\npronounced for short horizons. It is argued that this asymmetry reflects the\nmarket dynamics and we speculate over the origin of this asymmetry.\n"
    },
    {
        "paper_id": "cond-mat/0211044",
        "authors": "E. Aurell, P. Muratore-Ginanneschi",
        "title": "Growth-Optimal Strategies with Quadratic Friction Over Finite-Time\n  Investment Horizons",
        "comments": "13 pages in pdf format, 2 figures",
        "journal-ref": "IJTAF Vol. 7, No. 5 (2004), 645-657",
        "doi": "10.1142/S0219024904002578",
        "license": null,
        "abstract": "  We investigate the growth optimal strategy over a finite time horizon for a\nstock and bond portfolio in an analytically solvable multiplicative Markovian\nmarket model. We show that the optimal strategy consists in holding the amount\nof capital invested in stocks within an interval around an ideal optimal\ninvestment. The size of the holding interval is determined by the intensity of\nthe transaction costs and the time horizon.\n"
    },
    {
        "paper_id": "cond-mat/0211058",
        "authors": "K. Sznajd-Weron, R. Weron",
        "title": "How effective is advertising in duopoly markets?",
        "comments": "7 pages, 6 figures; v2: cosmetic changes",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01904-0",
        "license": null,
        "abstract": "  A simple Ising spin model which can describe the mechanism of advertising in\na duopoly market is proposed. In contrast to other agent-based models, the\ninfluence does not flow inward from the surrounding neighbors to the center\nsite, but spreads outward from the center to the neighbors. The model thus\ndescribes the spread of opinions among customers. It is shown via standard\nMonte Carlo simulations that very simple rules and inclusion of an external\nfield -- an advertising campaign -- lead to phase transitions.\n"
    },
    {
        "paper_id": "cond-mat/0211082",
        "authors": "Damien Challet and Robin Stinchcombe",
        "title": "Limit order market analysis and modelling: on an universal cause for\n  over-diffusive prices",
        "comments": "6 pages, 3 figures. Contribution to the proceedings of Econophysics\n  Bali Conference 2002",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01895-2",
        "license": null,
        "abstract": "  We briefly review data analysis of the Island order book, part of NASDAQ,\nwhich suggests a framework to which all limit order markets should comply.\nUsing a simple exclusion particle model, we argue that short-time price\nover-diffusion in limit order markets is due to the non-equilibrium of order\nplacement, cancellation and execution rates, which is an inherent feature of\nreal limit order markets.\n"
    },
    {
        "paper_id": "cond-mat/0211108",
        "authors": "R. Vilela Mendes, Tanya Ara\\'ujo and Francisco Lou\\c{c}\\~a",
        "title": "Reconstructing an economic space from a market metric",
        "comments": "20 pages Latex, 9 figures",
        "journal-ref": "Physica A 323 (2003) 635",
        "doi": "10.1016/S0378-4371(03)00014-1",
        "license": null,
        "abstract": "  Using a metric related to the returns correlation, a method is proposed to\nreconstruct an economic space from the market data. A reduced subspace,\nassociated to the systematic structure of the market, is identified and its\ndimension related to the number of terms in factor models. Example were worked\nout involving sets of companies from the DJIA and S&P500 indexes. Having a\nmetric defined in the space of companies, network topology coefficients may be\nused to extract further information from the data. A notion of \"continuous\nclustering\" is defined and empirically related to the occurrence of market\nshocks.\n"
    },
    {
        "paper_id": "cond-mat/0211162",
        "authors": "Takayuki Mizuno, Shoko Kurihara, Misako Takayasu, Hideki Takayasu",
        "title": "Analysis of high-resolution foreign exchange data of USD-JPY for 13\n  years",
        "comments": "6 pages, 7 figures, submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01881-2",
        "license": null,
        "abstract": "  We analyze high-resolution foreign exchange data consisting of 20 million\ndata points of USD-JPY for 13 years to report firm statistical laws in\ndistributions and correlations of exchange rate fluctuations. A conditional\nprobability density analysis clearly shows the existence of trend-following\nmovements at time scale of 8-ticks, about 1 minute.\n"
    },
    {
        "paper_id": "cond-mat/0211175",
        "authors": "Adrian A. Dragulescu, Victor M. Yakovenko",
        "title": "Statistical Mechanics of Money, Income, and Wealth: A Short Survey",
        "comments": "4 pages, 3 figures with 6 eps files, requires AIP proceedings style\n  (enclosed). Submitted to the proceedings of the 7th Granada seminar",
        "journal-ref": "Modeling of Complex Systems: Seventh Granada Lectures, AIP\n  Conference Proceedings 661, New York, 2003, pp. 180-183",
        "doi": "10.1063/1.1571309",
        "license": null,
        "abstract": "  In this short paper, we overview and extend the results of our papers\ncond-mat/0001432, cond-mat/0008305, and cond-mat/0103544, where we use an\nanalogy with statistical physics to describe probability distributions of\nmoney, income, and wealth in society. By making a detailed quantitative\ncomparison with the available statistical data, we show that these\ndistributions are described by simple exponential and power-law functions.\n"
    },
    {
        "paper_id": "cond-mat/0211260",
        "authors": "G. Montagna, M. Morelli, O. Nicrosini, P. Amato and M. Farina",
        "title": "Pricing Derivatives by Path Integral and Neural Networks",
        "comments": "7 pages, 1 figure, 1 table. Contribution to Proceedings of\n  International Econophysics Conference, Bali, August 28-31, 2002",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01907-6",
        "license": null,
        "abstract": "  Recent progress in the development of efficient computational algorithms to\nprice financial derivatives is summarized. A first algorithm is based on a path\nintegral approach to option pricing, while a second algorithm makes use of a\nneural network parameterization of option prices. The accuracy of the two\nmethods is established from comparisons with the results of the standard\nprocedures used in quantitative finance.\n"
    },
    {
        "paper_id": "cond-mat/0211317",
        "authors": "V. Gontis",
        "title": "Multiplicative Stochastic Model of the Time Interval between Trades in\n  Financial Markets",
        "comments": "11 pages, 3 figures",
        "journal-ref": "Nonlinear Analysis: Modelling and Control, 2002, v. 7, No. 1, p.\n  43-54",
        "doi": null,
        "license": null,
        "abstract": "  Stock price change in financial market occurs through transactions in analogy\nwith diffusion in stochastic physical systems. The analysis of price changes in\nreal markets shows that long-range correlations of price fluctuations largely\ndepend on the number of transactions. We introduce the multiplicative\nstochastic model of time interval between trades and analyze spectral density\nand correlations of the number of transactions. The model reproduces spectral\nproperties of the real markets and explains the mechanism of power law\ndistribution of trading activity. Our study provides an evidence that\nstatistical properties of financial markets are enclosed in the statistics of\nthe time interval between trades. Multiplicative stochastic diffusion may serve\nas a consistent model for this statistics.\n"
    },
    {
        "paper_id": "cond-mat/0211489",
        "authors": "Belal E. Baaquie, Claudio Coriano and Marakani Srikant",
        "title": "Hamiltonian and Potentials in Derivative Pricing Models: Exact Results\n  and Lattice Simulations",
        "comments": "27 pages, 11 figures 1 subsection added (4.1). Slightly longer\n  appendix",
        "journal-ref": "PhysicaA334:531-557,2004",
        "doi": "10.1016/j.physa.2003.10.080",
        "license": null,
        "abstract": "  The pricing of options, warrants and other derivative securities is one of\nthe great success of financial economics. These financial products can be\nmodeled and simulated using quantum mechanical instruments based on a\nHamiltonian formulation. We show here some applications of these methods for\nvarious potentials, which we have simulated via lattice Langevin and Monte\nCarlo algorithms, to the pricing of options. We focus on barrier or path\ndependent options, showing in some detail the computational strategies\ninvolved.\n"
    },
    {
        "paper_id": "cond-mat/0211534",
        "authors": "M. Ebrahim Fouladvand and Amir H. Darooneh",
        "title": "Premium Forecasting of an Insurance Company: Automobile Insurance",
        "comments": "Revtex, six pages including 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present an analytical study of an insurance company. We model the\ncompany's performance on a statistical basis and evaluate the predicted annual\nincome of the company in terms of insurance parameters namely the premium,\ntotal number of the insured, average loss claims etc. We restrict ourselves to\na single insurance class the so-called automobile insurance. We show the\nexistence a crossover premium p_c below which the company is loss-making. Above\np_c, we also give detailed statistical analysis of the company's financial\nstatus and obtain the predicted profit along with the corresponding risk as\nwell as ruin probability in terms of premium. Furthermore we obtain the optimal\npremium p_{opt} which maximizes the company's profit.\n"
    },
    {
        "paper_id": "cond-mat/0212010",
        "authors": "W.-X. Zhou (UCLA/Igpp) and D. Sornette (UCLA and CNRS-Univ. Nice)",
        "title": "Evidence of a Worldwide Stock Market Log-Periodic Anti-Bubble Since\n  Mid-2000",
        "comments": "Latex file, 17 pages + 8 tables + 39 eps figures",
        "journal-ref": "Physica A 330 (2003) 543-583",
        "doi": "10.1016/j.physa.2002.12.001",
        "license": null,
        "abstract": "  Following our previous investigation of the USA Standard and Poor index\nanti-bubble that started in August 2000, we analyze thirty eight world stock\nmarket indices and identify 21 anti-bubble. An ``anti-bubble'' is defined as a\nself-fulfilling decreasing price created by positive price-to-price feedbacks\nfeeding overall pessimism and negative market sentiment further strengthened by\ninter-personal interactions. We mathematically characterize anti-bubbles by a\npower law decrease of the price (or of the logarithm of the price) as a\nfunction of time and by decelerating/expanding log-periodic oscillations. The\nmajority of European and Western stock market indices as well as other stock\nindices exhibit practically the same log-periodic power law anti-bubble\nstructure as found for the USA S&P500 index. These anti-bubbles are found to\nstart approximately at the same time, August 2000, in all these markets. This\nshows a remarkable degree of synchronization worldwide. The descent of the\nworldwide stock markets since 2000 is thus an international event, suggesting\nthe strengthening of globalization.\n"
    },
    {
        "paper_id": "cond-mat/0212186",
        "authors": "William Cook, Paul Ormerod",
        "title": "Power Law Distribution of the Frequency of Demises of U.S Firms",
        "comments": "8 pages, 2 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01955-6",
        "license": null,
        "abstract": "  Both theoretical and applied economics have a great deal to say about many\naspects of the firm, but the literature on the extinctions, or demises, of\nfirms is very sparse. We use a publicly available data base covering some 6\nmillion firms in the US and show that the underlying statistical distribution\nwhich characterises the frequency of firm demises - the disappearances of firms\nas autonomous entities - is closely approximated by a power law. The exponent\nof the power law is, intriguingly, close to that reported in the literature on\nthe extinction of biological species.\n"
    },
    {
        "paper_id": "cond-mat/0212187",
        "authors": "Morrel H. Cohen and Vincent D. Natoli",
        "title": "Risk and Utility in Portfolio Optimization",
        "comments": "10 pages, 1 figure, presented at 2002 Conference on Econophysics in\n  Bali Indonesia",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(02)01957-X",
        "license": null,
        "abstract": "  Modern portfolio theory(MPT) addresses the problem of determining the optimum\nallocation of investment resources among a set of candidate assets. In the\noriginal mean-variance approach of Markowitz, volatility is taken as a proxy\nfor risk, conflating uncertainty with risk. There have been many subsequent\nattempts to alleviate that weakness which, typically, combine utility and risk.\nWe present here a modification of MPT based on the inclusion of separate risk\nand utility criteria. We define risk as the probability of failure to meet a\npre-established investment goal. We define utility as the expectation of a\nutility function with positive and decreasing marginal value as a function of\nyield. The emphasis throughout is on long investment horizons for which\nrisk-free assets do not exist. Analytic results are presented for a Gaussian\nprobability distribution. Risk-utility relations are explored via empirical\nstock-price data, and an illustrative portfolio is optimized using the\nempirical data.\n"
    },
    {
        "paper_id": "cond-mat/0212249",
        "authors": "Sergei Levendorskii",
        "title": "Pseudo-diffusions and Quadratic term structure models",
        "comments": "39 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The non-gaussianity of processes observed in financial markets and relatively\ngood performance of gaussian models can be reconciled by replacing the Brownian\nmotion with Levy processes whose Levy densities decay as exp(-lambda|x|) or\nfaster, where lambda>0 is large. This leads to asymptotic pricing models. The\nleading term, P0, is the price in the Gaussian model with the same\ninstantaneous drift and variance. The first correction term depends on the\ninstantaneous moments of order up to three, that is, the skewness is taken into\naccount, the next term depends on moments of order four (kurtosis) as well,\netc. In empirical studies, the asymptotic formula can be applied without\nexplicit specification of the underlying process: it suffices to assume that\nthe instantaneous moments of order greater than two are small w.r.t. moments of\norder one and two, and use empirical data on moments of order up to three or\nfour. As an application, the bond pricing problem in the non-Gaussian quadratic\nterm structure model is solved. For pricing of options near expiry, a different\nset of asymptotic formulas is developed; they require more detailed\nspecification of the process, especially of its jump part. The leading terms of\nthese formulas depends on the jump part of the process only, so that they can\nbe used in empirical studies to identify the jump characteristics of the\nprocess.\n"
    },
    {
        "paper_id": "cond-mat/0212338",
        "authors": "Salvatore Miccich\\`e, Giovanni Bonanno, Fabrizio Lillo, Rosario N.\n  Mantegna",
        "title": "Degree stability of a minimum spanning tree of price return and\n  volatility",
        "comments": "9 pages, 3 figures",
        "journal-ref": "Physica A, 324, 66-73, (2003)",
        "doi": "10.1016/S0378-4371(03)00002-5",
        "license": null,
        "abstract": "  We investigate the time series of the degree of minimum spanning trees\nobtained by using a correlation based clustering procedure which is starting\nfrom (i) asset return and (ii) volatility time series. The minimum spanning\ntree is obtained at different times by computing correlation among time series\nover a time window of fixed length $T$. We find that the minimum spanning tree\nof asset return is characterized by stock degree values, which are more stable\nin time than the ones obtained by analyzing a minimum spanning tree computed\nstarting from volatility time series. Our analysis also shows that the degree\nof stocks has a very slow dynamics with a time-scale of several years in both\ncases.\n"
    },
    {
        "paper_id": "cond-mat/0212358",
        "authors": "Luis Dinis and Juan M.R.Parrondo (GISC and Dept. de Fisica Atomica,\n  Molecular y Nuclear, Universidad Complutense de Madrid, Spain.)",
        "title": "Optimal strategies in collective Parrondo games",
        "comments": "4 pages, 6 figures, revised version in published form",
        "journal-ref": "Europhys. Lett. 63 (3), 319 (2003)",
        "doi": "10.1209/epl/i2003-00461-5",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We present a modification of the so-called Parrondo's paradox where one is\nallowed to choose in each turn the game that a large number of individuals\nplay. It turns out that, by choosing the game which gives the highest average\nearnings at each step, one ends up with systematic loses, whereas a periodic or\nrandom sequence of choices yields a steadily increase of the capital. An\nexplanation of this behavior is given by noting that the short-range\nmaximization of the returns is \"killing the goose that laid the golden eggs\". A\ncontinuous model displaying similar features is analyzed using dynamic\nprogramming techniques from control theory.\n"
    },
    {
        "paper_id": "cond-mat/0212393",
        "authors": "Kyungsik Kim and Seong-Min Yoon",
        "title": "Dynamical Behavior of Continuous Tick Data in Futures Exchange Market",
        "comments": "11 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the tick dynamical behavior of the bond futures in Korean Futures\nExchange(KOFEX) market. Since the survival probability in the continuous-time\nrandom walk theory is applied to the bond futures transaction, the form of the\ndecay function in our bond futures model is discussed from two kinds of Korean\nTreasury Bond(KTB) transacted recently in KOFEX. The decay distributions for\nsurvival probability are particularly displayed stretched exponential forms\nwith novel scaling exponents $\\beta$ $=$ 0.82(KTB 203) and $\\beta$ $=$\n0.90(KTB112), respectively, for our small time intervals. We obtain the scaling\nexponents for survival probability $\\epsilon$ $=$ 17 and 18 decayed rapidly in\nlarge time limit, and our results are compared with recent numerical\ncalculations.\n"
    },
    {
        "paper_id": "cond-mat/0212641",
        "authors": "M. Ausloos and K. Ivanova",
        "title": "Generalized Technical Analysis. Effects of transaction volume and risk",
        "comments": "8 pages, 7 figures; to appear in the Proceedings of the Second Nikkei\n  Symposium: Toward control of Economic Change -- Application of Econophysics,\n  Nov 12-14, 2002, Tokyo, Japan",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We generalize the momentum indicator idea taking into account the volume of\ntransactions as a multiplicative factor. We compare returns obtained following\nstrategies based on the classical or the generalized technical analysis, taking\ninto account a sort of risk investor criterion.\n"
    },
    {
        "paper_id": "cond-mat/0301068",
        "authors": "Andrea Baldassarri, Francesca Colaiori, Claudio Castellano",
        "title": "The average shape of a fluctuation: universality in excursions of\n  stochastic processes",
        "comments": "5 pages, 5 figures, accepted for publication in Phys. Rev. Lett",
        "journal-ref": "Phys. Rev. Lett. 90, 060601 (2003)",
        "doi": "10.1103/PhysRevLett.90.060601",
        "license": null,
        "abstract": "  We study the average shape of a fluctuation of a time series x(t), that is\nthe average value <x(t)-x(0)>_T before x(t) first returns, at time T, to its\ninitial value x(0). For large classes of stochastic processes we find that a\nscaling law of the form <x(t) - x(0)>_T = T^\\alpha f(t/T) is obeyed. The\nscaling function f(s) is to a large extent independent of the details of the\nsingle increment distribution, while it encodes relevant statistical\ninformation on the presence and nature of temporal correlations in the process.\nWe discuss the relevance of these results for Barkhausen noise in magnetic\nsystems.\n"
    },
    {
        "paper_id": "cond-mat/0301268",
        "authors": "K. Ivanova, M. Ausloos and H. Takayasu",
        "title": "Deterministic and stochastic influences on Japan and US stock and\n  foreign exchange markets. A Fokker-Planck approach",
        "comments": "8 pages, 5 figures; to appear in the Proceedings of the Proceedings\n  of the Second Nikkei Symposium: Toward control of Economic Change --\n  Application of Econophysics, Nov 12-14, 2002, Tokyo, Japan",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The evolution of the probability distributions of Japan and US major market\nindices, NIKKEI 225 and NASDAQ composite index, and $JPY/DEM$ and $DEM/USD$\ncurrency exchange rates is described by means of the Fokker-Planck equation\n(FPE). In order to distinguish and quantify the deterministic and random\ninfluences on these financial time series we perform a statistical analysis of\ntheir increments $\\Delta x(\\Delta(t))$ distribution functions for different\ntime lags $\\Delta(t)$. From the probability distribution functions at various\n$\\Delta(t)$, the Fokker-Planck equation for $p(\\Delta x(t), \\Delta(t))$ is\nexplicitly derived. It is written in terms of a drift and a diffusion\ncoefficient. The Kramers-Moyal coefficients, are estimated and found to have a\nsimple analytical form, thus leading to a simple physical interpretation for\nboth drift $D^{(1)}$ and diffusion $D^{(2)}$ coefficients. The Markov nature of\nthe indices and exchange rates is shown and an apparent difference in the\nNASDAQ $D^{(2)}$ is pointed out.\n"
    },
    {
        "paper_id": "cond-mat/0301289",
        "authors": "Arnab Chatterjee, Bikas K. Chakrabarti and S. S. Manna",
        "title": "Pareto Law in a Kinetic Model of Market with Random Saving Propensity",
        "comments": "5 pages RevTeX4, 6 eps figures, to be published in Physica A (2004)",
        "journal-ref": "Physica A v.335 (2004) p.155-163",
        "doi": "10.1016/j.physa.2003.11.014",
        "license": null,
        "abstract": "  We have numerically simulated the ideal-gas models of trading markets, where\neach agent is identified with a gas molecule and each trading as an elastic or\nmoney-conserving two-body collision. Unlike in the ideal gas, we introduce\n(quenched) saving propensity of the agents, distributed widely between the\nagents ($0 \\le \\lambda < 1$). The system remarkably self-organizes to a\ncritical Pareto distribution of money $P(m) \\sim m^{-(\\nu + 1)}$ with $\\nu\n\\simeq 1$. We analyse the robustness (universality) of the distribution in the\nmodel. We also argue that although the fractional saving ingredient is a bit\nunnatural one in the context of gas models, our model is the simplest so far,\nshowing self-organized criticality, and combines two century-old distributions:\nGibbs (1901) and Pareto (1897) distributions.\n"
    },
    {
        "paper_id": "cond-mat/0301307",
        "authors": "Constantino Tsallis, Celia Anteneodo, Lisa Borland and Roberto Osorio",
        "title": "Nonextensive statistical mechanics and economics",
        "comments": "6 pages and 6 figures. Contribution to the International Econophysics\n  Conference, held in Bali, Indonesia (29-31 August 2002). To appear in Physica\n  A. It includes a partial reply to a recent criticism by D.H. Zanette and M.A.\n  Montemurro, cond-mat/0212327",
        "journal-ref": "Physica A 324, 89 (2003).",
        "doi": "10.1016/S0378-4371(03)00042-6",
        "license": null,
        "abstract": "  Ergodicity, this is to say, dynamics whose time averages coincide with\nensemble averages, naturally leads to Boltzmann-Gibbs (BG) statistical\nmechanics, hence to standard thermodynamics. This formalism has been at the\nbasis of an enormous success in describing, among others, the particular\nstationary state corresponding to thermal equilibrium. There are, however, vast\nclasses of complex systems which accomodate quite badly, or even not at all,\nwithin the BG formalism. Such dynamical systems exhibit, in one way or another,\nnonergodic aspects. In order to be able to theoretically study at least some of\nthese systems, a formalism was proposed 14 years ago, which is sometimes\nreferred to as nonextensive statistical mechanics. We briefly introduce this\nformalism, its foundations and applications. Furthermore, we provide some\nbridging to important economical phenomena, such as option pricing, return and\nvolume distributions observed in the financial markets, and the fascinating and\nubiquitous concept of risk aversion. One may summarize the whole approach by\nsaying that BG statistical mechanics is based on the entropy $S_{BG}=-k \\sum_i\np_i \\ln p_i$, and typically provides {\\it exponential laws} for describing\nstationary states and basic time-dependent phenomena, while nonextensive\nstatistical mechanics is instead based on the entropic form\n$S_q=k(1-\\sum_ip_i^q)/(q-1)$ (with $S_1=S_{BG}$), and typically provides, for\nthe same type of description, (asymptotic) {\\it power laws}.\n"
    },
    {
        "paper_id": "cond-mat/0301543",
        "authors": "D. Sornette (UCLA and CNRS-Univ. Nice)",
        "title": "Critical Market Crashes",
        "comments": "Latex 89 pages and 38 figures, in press in Physics Reports",
        "journal-ref": "Physics Reports 378 (1), 1-98 (2003)",
        "doi": "10.1016/S0370-1573(02)00634-8",
        "license": null,
        "abstract": "  This review is a partial synthesis of the book ``Why stock market crash''\n(Princeton University Press, January 2003), which presents a general theory of\nfinancial crashes and of stock market instabilities that his co-workers and the\nauthor have developed over the past seven years. The study of the frequency\ndistribution of drawdowns, or runs of successive losses shows that large\nfinancial crashes are ``outliers'': they form a class of their own as can be\nseen from their statistical signatures. If large financial crashes are\n``outliers'', they are special and thus require a special explanation, a\nspecific model, a theory of their own. In addition, their special properties\nmay perhaps be used for their prediction. The main mechanisms leading to\npositive feedbacks, i.e., self-reinforcement, such as imitative behavior and\nherding between investors are reviewed with many references provided to the\nrelevant literature outside the confine of Physics. Positive feedbacks provide\nthe fuel for the development of speculative bubbles, preparing the instability\nfor a major crash. We demonstrate several detailed mathematical models of\nspeculative bubbles and crashes. The most important message is the discovery of\nrobust and universal signatures of the approach to crashes. These precursory\npatterns have been documented for essentially all crashes on developed as well\nas emergent stock markets, on currency markets, on company stocks, and so on.\nThe concept of an ``anti-bubble'' is also summarized, with two forward\npredictions on the Japanese stock market starting in 1999 and on the USA stock\nmarket still running. We conclude by presenting our view of the organization of\nfinancial markets.\n"
    },
    {
        "paper_id": "cond-mat/0302095",
        "authors": "Josep Perello, Jaume Masoliver, and Jean-Philippe Bouchaud",
        "title": "Multiple time scales in volatility and leverage correlations: An\n  stochastic volatility model",
        "comments": "19 pages, 5 figures",
        "journal-ref": "Applied Mathematical Finance 11 (2004) 27-50",
        "doi": null,
        "license": null,
        "abstract": "  Financial time series exhibit two different type of non linear correlations:\n(i) volatility autocorrelations that have a very long range memory, on the\norder of years, and (ii) asymmetric return-volatility (or `leverage')\ncorrelations that are much shorter ranged. Different stochastic volatility\nmodels have been proposed in the past to account for both these correlations.\nHowever, in these models, the decay of the correlations is exponential, with a\nsingle time scale for both the volatility and the leverage correlations, at\nvariance with observations. We extend the linear Ornstein-Uhlenbeck stochastic\nvolatility model by assuming that the mean reverting level is itself random. We\nfind that the resulting three-dimensional diffusion process can account for\ndifferent correlation time scales. We show that the results are in good\nagreement with a century of the Dow Jones index daily returns (1900-2000), with\nthe exception of crash days.\n"
    },
    {
        "paper_id": "cond-mat/0302147",
        "authors": "Bikas K. Chakrabarti, Arnab Chatterjee",
        "title": "Ideal Gas-Like Distributions in Economics: Effects of Saving Propensity",
        "comments": "6 pages, 3 eps figures. To be published in `Application of\n  Econophysics', Ed. H. Takayasu, Springer-Verlag, Tokyo (2003): Proc. 2nd.\n  Nikkei Symposium on Econophysics, Tokyo, Nov. 2002",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider the ideal-gas models of trading markets, where each agent is\nidentified with a gas molecule and each trading as an elastic or\nmoney-conserving (two-body) collision. Unlike in the ideal gas, we introduce\nsaving propensity $\\lambda$ of agents, such that each agent saves a fraction\n$\\lambda$ of its money and trades with the rest. We show the steady-state money\nor wealth distribution in a market is Gibbs-like for $\\lambda=0$, has got a\nnon-vanishing most-probable value for $\\lambda \\ne 0$ and Pareto-like when\n$\\lambda$ is widely distributed among the agents. We compare these results with\nobservations on wealth distributions of various countries.\n"
    },
    {
        "paper_id": "cond-mat/0302270",
        "authors": "Victor M. Yakovenko",
        "title": "Research in Econophysics",
        "comments": "RevTeX 4, 4 pages, 10 figures. V.2: one reference added",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This article is written for the online newspaper \"The Photon\" published by\nthe Department of Physics, University of Maryland. The article describes\neconophysics research done in the group of Victor Yakovenko. It briefly surveys\nthe subjects \"Statistical Mechanics of Money, Income, and Wealth\" and\n\"Probability Distribution of Stock-Market Fluctuations.\"\n"
    },
    {
        "paper_id": "cond-mat/0302342",
        "authors": "R. L. Costa, G. L. Vasconcelos",
        "title": "Long-range correlations and nonstationarity in the Brazilian stock\n  market",
        "comments": "19 pages with 11 figures, submitted to Physica A",
        "journal-ref": "Physica A, Volume 329, Issues 1-2, 1 November 2003, Pages 231-248",
        "doi": "10.1016/S0378-4371(03)00607-1",
        "license": null,
        "abstract": "  We report an empirical study of the Ibovespa index of the Sao Paulo Stock\nExchange in which we detect the existence of long-range correlations. To\nanalyze our data we introduce a rescaled variant of the usual Detrended\nFluctuation Analysis that allows us to obtain the Hurst exponent through a\none-parameter fitting. We also compute a time-dependent Hurst exponent H(t)\nusing three-year moving time windows. In particular, we find that before the\nlaunch of the Collor Plan in 1990 the curve H(t) remains, in general, well\nabove 1/2, while afterwards it stays close to 1/2. We thus argue that the\nstructural reforms set off by the Collor Plan has lead to a more efficient\nstock market in Brazil. We also suggest that the time dependence of the\nIbovespa Hurst exponent could be described in terms of a multifractional\nBrownian motion.\n"
    },
    {
        "paper_id": "cond-mat/0302402",
        "authors": "Susanne Emmer and Dirk Tasche",
        "title": "Calculating credit risk capital charges with the one-factor model",
        "comments": "15 pages, LaTeX with hyperref package, final version",
        "journal-ref": "Journal of Risk 7, 2005, pp. 85-101",
        "doi": null,
        "license": null,
        "abstract": "  Even in the simple one-factor credit portfolio model that underlies the Basel\nII regulatory capital rules coming into force in 2007, the exact contributions\nto credit value-at-risk can only be calculated with Monte-Carlo simulation or\nwith approximation algorithms that often involve numerical integration. As this\nmay require a lot of computational time, there is a need for approximate\nanalytical formulae. In this note, we develop formulae according to two\ndifferent approaches: the granularity adjustment approach initiated by M. Gordy\nand T. Wilde, and a semi-asymptotic approach. The application of the formulae\nis illustrated with a numerical example.\n  Keywords: One-factor model, capital charge, granularity adjustment, quantile\nderivative.\n"
    },
    {
        "paper_id": "cond-mat/0302434",
        "authors": "T. Di Matteo, T. Aste and M. M. Dacorogna",
        "title": "Using the Scaling Analysis to Characterize Financial Markets",
        "comments": "37 pages, 10 figures, 7 tables",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We empirically analyze the scaling properties of daily Foreign Exchange\nrates, Stock Market indices and Bond futures across different financial\nmarkets. We study the scaling behaviour of the time series by using a\ngeneralized Hurst exponent approach. We verify the robustness of this approach\nand we compare the results with the scaling properties in the frequency-domain.\nWe find evidence of deviations from the pure Brownian motion behavior. We show\nthat these deviations are associated with characteristics of the specific\nmarkets and they can be, therefore, used to distinguish the different degrees\nof development of the markets.\n"
    },
    {
        "paper_id": "cond-mat/0302468",
        "authors": "Taisei Kaizoji and Masahide Nuki",
        "title": "Scaling Law for the Distribution of Fluctuations of Share Volume",
        "comments": "6pages, 3 figures",
        "journal-ref": "Fractals 12 (1) (2004) 49-54",
        "doi": "10.1142/S0218348X04002318",
        "license": null,
        "abstract": "  We show power-scaling behaviors for fluctuations in share volume, which no\nother studies have so far done. After analyzing a database of the daily\ntransactions for all securities listed on the Tokyo Stock Exchange, we selected\n1050 large companies that each had an unbroken series of daily trading activity\nfrom January 1975 to January 2002. We found that the cumulative distributions\nof daily fluctuations in share volumes can be well described by a power-law\ndecay, and that the cumulative distributions for almost all of the companies\ncan be characterized by an exponent within the stable Levy domain. Furthermore,\nmore than 35 percent of the cumulative distributions can be well approximated\nby Zipf's law, that is, the cumulative distributions have an exponent close to\nunity.\n"
    },
    {
        "paper_id": "cond-mat/0302470",
        "authors": "Taisei Kaizoji",
        "title": "Scaling behavior in land markets",
        "comments": "12 pages, 5 figures",
        "journal-ref": "Physica A326 (2003) 256-264",
        "doi": "10.1016/S0378-4371(03)00145-6",
        "license": null,
        "abstract": "  In this paper we present an analysis of power law statistics on land markets.\nThere have been no other studies that have analyzed power law statistics on\nland markets up to now. We analyzed a database of the assessed value of land,\nwhich is officially monitored and made available to the public by the Ministry\nof Land, Infrastructure, and Transport Government of Japan. This is the largest\ndatabase of Japan's land prices, and consists of approximately 30,000 points\nfor each year of a 6-year period (1995-2000). By analyzing the data on the\nassessed value of land, we were able to determine the power law distributions\nof the land prices and of the relative prices of the land. The data fits to a\nvery good degree the approximation of power law distributions. We also found\nthat the price fluctuations were amplified with the level of the price. These\nresults hold for the data for each of the 6 annual intervals. Our empirical\nfindings present the conditions that any empirically accurate theories of land\nmarket must satisfy.\n"
    },
    {
        "paper_id": "cond-mat/0302507",
        "authors": "Hans-Christian Graf v. Bothmer",
        "title": "Significance of log-periodic signatures in cumulative noise",
        "comments": "14 pages, 7 figures; AMS-Latex; introduction rewritten, some points\n  of the exposition clarified. Author-supplied PDF file with high resolution\n  graphics is available at http://btm8x5.mat.uni-bayreuth.de/~bothmer/",
        "journal-ref": "Quantitative Finance, volume 3, issue 5, pages 370-375, 2003",
        "doi": "10.1088/1469-7688/3/5/303",
        "license": null,
        "abstract": "  Using methods introduced by Scargle in 1978 we derive a cumulative version of\nthe Lomb periodogram that exhibits frequency independent statistics when\napplied to cumulative noise. We show how this cumulative Lomb periodogram\nallows us to estimate the significance of log-periodic signatures in the S&P\n500 anti-bubble that started in August 2000.\n"
    },
    {
        "paper_id": "cond-mat/0302579",
        "authors": "Raymond J. Hawkins and B. Roy Frieden",
        "title": "Financial Probabilities from Fisher Information",
        "comments": "23 pages, 3 ps figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present a novel synthesis of Fisher information and asset pricing theory\nthat yields a practical method for reconstructing the probability density\nimplicit in security prices. The Fisher information approach to these inverse\nproblems transforms the search for a probability density into the solution of a\ndifferential equation for which a substantial collection of numerical methods\nexist. We illustrate the potential of this approach by calculating the\nprobability density implicit in both bond and option prices. Comparing the\nresults of this approach with those obtained using maximum entropy we find that\nFisher information usually results in probability densities that are smoother\nthan those obtained using maximum entropy.\n"
    },
    {
        "paper_id": "cond-mat/0303089",
        "authors": "Vygintas Gontis and Bronislovas Kaulakys",
        "title": "Multiplicative point process as a model of trading activity",
        "comments": "10 pages, 3 figures",
        "journal-ref": "Gontis V., Kaulakys B., Physica A 343 (2004) 505-514",
        "doi": "10.1016/j.physa.2004.05.080",
        "license": null,
        "abstract": "  Signals consisting of a sequence of pulses show that inherent origin of the\n1/f noise is a Brownian fluctuation of the average interevent time between\nsubsequent pulses of the pulse sequence. In this paper we generalize the model\nof interevent time to reproduce a variety of self-affine time series exhibiting\npower spectral density S(f) scaling as a power of the frequency f. Furthermore,\nwe analyze the relation between the power-law correlations and the origin of\nthe power-law probability distribution of the signal intensity. We introduce a\nstochastic multiplicative model for the time intervals between point events and\nanalyze the statistical properties of the signal analytically and numerically.\nSuch model system exhibits power-law spectral density S(f)~1/f**beta for\nvarious values of beta, including beta=1/2, 1 and 3/2. Explicit expressions for\nthe power spectra in the low frequency limit and for the distribution density\nof the interevent time are obtained. The counting statistics of the events is\nanalyzed analytically and numerically, as well. The specific interest of our\nanalysis is related with the financial markets, where long-range correlations\nof price fluctuations largely depend on the number of transactions. We analyze\nthe spectral density and counting statistics of the number of transactions. The\nmodel reproduces spectral properties of the real markets and explains the\nmechanism of power-law distribution of trading activity. The study provides\nevidence that the statistical properties of the financial markets are enclosed\nin the statistics of the time interval between trades. A multiplicative point\nprocess serves as a consistent model generating this statistics.\n"
    },
    {
        "paper_id": "cond-mat/0303099",
        "authors": "Ashok Razdan",
        "title": "Wavelet Correlation Coefficient of 'strongly correlated' financial time\n  series",
        "comments": "physica A (in press)",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2003.10.042",
        "license": null,
        "abstract": "  In this paper we use wavelet concepts to show that correlation coefficient\nbetween two financial data's is not constant but varies with scale from high\ncorrelation value to strongly anti-correlation value This studies is important\nbecause correlation coefficient is used to quantify degree of independence\nbetween two variables. In econophysics correlation coefficient forms important\ninput to evolve hierarchial tree and minimum spanning tree of financial data.\n"
    },
    {
        "paper_id": "cond-mat/0303222",
        "authors": "Andrei Leonidov",
        "title": "Long Memory in Stock Trading",
        "comments": "8 pages, Latex. New material added, to appear in IJTAF",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Using a relationship between the moments of the probability distribution of\ntimes between the two consecutive trades (intertrade time distribution) and the\nmoments of the distribution of a daily number of trades we show, that the\nunderlying point process is essentially non-markovian. A detailed analysis of\nall trades in the EESR stock on the Moscow International Currency Exchange in\nthe period January 2003 - September 2003, including that of correlation between\nintertrade time intervals is presented. A power-law decay of the correlation\nprovides an additional evidence of the long-memory nature of the series of\ntimes of trades. A data set including all trades in Siemens, Commerzbank and\nKarstadt stocks traded on the Xetra electronic stock exchange of Deutsche\nBoerse in October 2002 is also considered.\n"
    },
    {
        "paper_id": "cond-mat/0303271",
        "authors": "Kestutis Staliunas",
        "title": "Bose-Einstein Condensation in Financial Systems",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We describe financial systems as condensates, similar to Bose-Einstein\ncondensates, and calculate statistical distributions following from the model.\nThe calculated distributions of investments into speculated financial assets\nare found equivalent to a Pareto distribution, and the calculated distributions\nof the price moves are found equivalent to exponentially truncated Levy\ndistributions.\n"
    },
    {
        "paper_id": "cond-mat/0303298",
        "authors": "Hideaki Shimazaki, Ernst Niebur",
        "title": "Bose-Einstein Condensation in Competitive Processes",
        "comments": "4 pages, 3 figures, submitted to PRL",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.72.011912",
        "license": null,
        "abstract": "  We introduce an irreversible discrete multiplicative process that undergoes\nBose-Einstein condensation as a generic model of competition. New players with\ndifferent abilities successively join the game and compete for limited\nresources. A player's future gain is proportional to its ability and its\ncurrent gain. The theory provides three principles for this type of\ncompetition: competitive exclusion, punctuated equilibria, and a critical\ncondition for the distribution of the players' abilities necessary for the\ndominance and the evolution. We apply this theory to genetics, ecology and\neconomy.\n"
    },
    {
        "paper_id": "cond-mat/0303304",
        "authors": "Takayuki Mizuno, Shoko Kurihara, Misako Takayasu, and Hideki Takayasu",
        "title": "Investment strategy based on a company growth model",
        "comments": "5 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We first estimate the average growth of a company's annual income and its\nvariance by using both real company data and a numerical model which we already\nintroduced a couple of years ago. Investment strategies expecting for income\ngrowth is evaluated based on the numerical model. Our numerical simulation\nsuggests the possibility that an investment strategy focusing on the\nmedium-sized companies gives the best asset growth with relatively low risk.\n"
    },
    {
        "paper_id": "cond-mat/0303306",
        "authors": "Takayuki Mizuno, Shoko Kurihara, Misako Takayasu, and Hideki Takayasu",
        "title": "Time-scale dependence of correlations among foreign currencies",
        "comments": "6 pages, 5 figures, 1 table",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  For the purpose of elucidating the correlation among currencies, we analyze\ndaily and high-resolution data of foreign exchange rates. There is strong\ncorrelation for pairs of currencies of geographically near countries. We show\nthat there is a time delay of order less than a minute between two currency\nmarkets having a strong cross-correlation. The cross-correlation between\nexchange rates is lower in shorter time scale in any case. As a corollary we\nnotice a kind of contradiction that the direct Yen-Dollar rate significantly\ndiffers from the indirect Yen-Dollar rate through Euro in short time scales.\nThis result shows the existence of arbitrage opportunity among currency\nexchange markets.\n"
    },
    {
        "paper_id": "cond-mat/0303568",
        "authors": "H.F. Coronel-Brizio (1), C.R. de la Cruz-Laso (1), A.R.\n  Hernandez-Montoya (1) ((1) Facultad de Fisica e Inteligencia Artificial.\n  Universidad Veracruzana. Mexico)",
        "title": "Fitting the Power-law Distribution to the Mexican Stock Market index\n  data",
        "comments": "4 pages, 2 Figures. Econophysics paper",
        "journal-ref": "Test of fit for the power-law distribution and some applications\n  to the Mexican Stock Market index relative changes, Advances and Applications\n  in Statistics. Volume 50, Number 2, 2017, pages 123-136 (2017)",
        "doi": "10.17654/AS050020123",
        "license": null,
        "abstract": "  In the spirit of the emergent field of econophysics, a goodness-of-fit test\nfor the Power-Law distribution, based on the Empirical Distribution Function\n(EDF) is presented, and related problems are discussed. An analysis of the tail\nbehaviour of the daily logarithmic variation of the Mexican Stock Market Index\n(IPC), showed distributional properties which are consistent with previous\nstudies.\n"
    },
    {
        "paper_id": "cond-mat/0304132",
        "authors": "Juhi-Lian Julian Ting",
        "title": "Causalities of the Taiwan Stock Market",
        "comments": "8 pages, 15 figures",
        "journal-ref": "Physica A 324, 285-295 (2003)",
        "doi": "10.1016/S0378-4371(02)01842-3",
        "license": null,
        "abstract": "  Volatility, fitting with first order Landau expansion, stationarity, and\ncausality of the Taiwan stock market (TAIEX) are investigated based on daily\nrecords. Instead of consensuses that consider stock market index change as a\nrandom time series we propose the market change as a dual time series consists\nof the index and the corresponding volume. Therefore, causalities between these\ntwo time series are investigated.\n"
    },
    {
        "paper_id": "cond-mat/0304143",
        "authors": "Kyungsik Kim, Seong-Min Yoon and Yup Kim",
        "title": "Herd Behavior of Returns in the Futures Exchange Market",
        "comments": "7 pages, 7 figures, Latex",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The herd behavior of returns is investigated in Korean futures exchange\nmarket. It is obtained that the probability distribution of returns for three\ntypes of herding parameter scales as a power law $R^{-\\beta}$ with the\nexponents $ \\beta=3.6$(KTB203) and 2.9(KTB209) in two kinds of Korean treasury\nbond. For our case since the active state of transaction exists to decrease\nlesser than the herding parameter $h=2.33$, the crash regime appears to\nincrease in the probability with high returns values. Especially, we find that\nit shows a crossover toward a Gaussian probability function near the time step\n$\\Delta t=360$ from the distribution of normalized returns. Our result will be\nalso compared with other well-known results.\n"
    },
    {
        "paper_id": "cond-mat/0304324",
        "authors": "Sitabhra Sinha",
        "title": "Stochastic Maps, Wealth Distribution in Random Asset Exchange Models and\n  the Marginal Utility of Relative Wealth",
        "comments": "7 pages, 8 figures, to appear in Phys. Scr. T (Spl. issue: Proc. Int.\n  Conf. UASP'03)",
        "journal-ref": "Physica Scripta, Vol. T 106, pp. 59-64 (2003)",
        "doi": "10.1238/Physica.Topical.106a00059",
        "license": null,
        "abstract": "  We look at how asset exchange models can be mapped to random iterated\nfunction systems (IFS) giving new insights into the dynamics of wealth\naccumulation in such models. In particular, we focus on the \"yard-sale\" (winner\ngets a random fraction of the poorer players wealth) and the \"theft-and-fraud\"\n(winner gets a random fraction of the loser's wealth) asset exchange models.\nSeveral special cases including 2-player and 3-player versions of these `games'\nallow us to connect the results with observed features in real economies, e.g.,\nlock-in (positive feedback), etc. We then implement the realistic notion that a\nricher agent is less likely to be aggressive when bargaining over a small\namount with a poorer player. When this simple feature is added to the yard-sale\nmodel, in addition to the accumulation of the total wealth by a single agent\n(\"condensation\"), we can see exponential and power-law distributions of wealth.\nSimulation results suggest that the power-law distribution occurs at the\ncross-over of the system from exponential phase to the condensate phase.\n"
    },
    {
        "paper_id": "cond-mat/0304331",
        "authors": "Kazuko Yamasaki, Kenneth J. Mackin",
        "title": "Market Simulation Displaying Multifractality",
        "comments": "6 pages,8 figures,The Nikkei Symposium on Application of Econophysics",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We proposed a market simulation model (micro model) which displays\nmultifractality and reproduces many important stylized facts of speculative\nmarkets. From this model we analytically extracted the MMAR model (Multifractal\nModel of Asset Returns) for the macroscopic limit.\n"
    },
    {
        "paper_id": "cond-mat/0304451",
        "authors": "Kyungsik Kim, Seong-Min Yoon, Yup Kim",
        "title": "Herd Behaviors in the Stock and Foreign Exchange Markets",
        "comments": "4 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.05.052",
        "license": null,
        "abstract": "  The herd behaviors of returns for the won-dollar exchange rate and the KOSPI\nare analyzed in Korean financial markets. It is shown that the probability\ndistribution $P(R)$ of price returns $R$ for three values of the herding\nparameter tends to a power-law behavior $P(R) \\simeq R^{-\\beta}$ with the\nexponents $ \\beta=2.2$(the won-dollar exchange rate) and 2.4(the KOSPI). The\nfinancial crashes are found to occur at $h >2.33$ when the relative increase in\nthe probability distribution of exteremely high price returns is observed.\nEspecially, the distribution of normalized returns shows a crossover to a\nGaussian distribution for the time step $\\Delta t=252$. Our results will be\nalso compared to the other well-known analyses.\n"
    },
    {
        "paper_id": "cond-mat/0304469",
        "authors": "V.V.Kondratenko and Yu. A Kuperin",
        "title": "Using Recurrent Neural Networks To Forecasting of Forex",
        "comments": "23 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper reports empirical evidence that a neural networks model is\napplicable to the statistically reliable prediction of foreign exchange rates.\nTime series data and technical indicators such as moving average, are fed to\nneural nets to capture the underlying \"rules\" of the movement in currency\nexchange rates. The trained recurrent neural networks forecast the exchange\nrates between American Dollar and four other major currencies, Japanese Yen,\nSwiss Frank, British Pound and EURO. Various statistical estimates of forecast\nquality have been carried out. Obtained results show, that neural networks are\nable to give forecast with coefficient of multiple determination not worse then\n0.65. Linear and nonlinear statistical data preprocessing, such as\nKolmogorov-Smirnov test and Hurst exponents for each currency were calculated\nand analyzed.\n"
    },
    {
        "paper_id": "cond-mat/0304601",
        "authors": "D. Sornette (CNRS-Univ. Nice and UCLA), W.-X. Zhou (UCLA)",
        "title": "Predictability of large future changes in major financial indices",
        "comments": "28 Latex pages including 8 eps figures",
        "journal-ref": "International Journal of Forecasting 22 (2006) 153-168",
        "doi": "10.1016/j.ijforecast.2005.02.004",
        "license": null,
        "abstract": "  We present a systematic algorithm testing for the existence of collective\nself-organization in the behavior of agents in social systems, with a concrete\nempirical implementation on the Dow Jones Industrial Average index (DJIA) over\nthe 20th century and on Hong Kong Hang Seng composite index (HSI) since 1969.\nThe algorithm combines ideas from critical phenomena, the impact of agents'\nexpectation, multi-scale analysis and the mathematical method of pattern\nrecognition of sparse data. Trained on the three major crashes in DJIA of the\ncentury, our algorithm exhibits a remarkable ability for generalization and\ndetects in advance 8 other significant drops or changes of regimes. An\napplication to HSI gives promising results as well. The results are robust with\nrespect to the variations of the recognition algorithm. We quantify the\nprediction procedure with error diagrams.\n"
    },
    {
        "paper_id": "cond-mat/0304685",
        "authors": "Arnab Das and Sudhakar Yarlagadda",
        "title": "Analytic treatment of a trading market model",
        "comments": "2 pages, RevTeX4, 1 ps figure, to be published in Physica Scripta T:\n  Proc. Vol. `Unconventional Applications of Statistical Physics', March, 2003",
        "journal-ref": null,
        "doi": "10.1238/Physica.Topical.106a00039",
        "license": null,
        "abstract": "  We mathematically analyze a simple market model where trading at each point\nin time involves only two agents with the sum of their money being conserved\nand with neither parties resulting with negative money after the interaction\nprocess. The exchange involves random re-distribution among the two players of\na fixed fraction of their total money. We obtain a simple integral nonlinear\nequation for the money distribution. We find that the zero savings and finite\nsavings cases belong to different universality classes. While the zero savings\ncase can be solved analytically, the finite savings solution is obtained by\nnumerically solving the integral equation. We find remarkable agreement with\nresults obtained by other researchers using sophisticated numerical techniques.\n"
    },
    {
        "paper_id": "cond-mat/0305004",
        "authors": "D. Sornette (CNRS-Univ. Nice and UCLA), W.-X. Zhou (UCLA)",
        "title": "The US 2000-2003 Market Descent: Clarifications",
        "comments": "6 Latex pages, a shorter version will appear soon in Quantitative\n  Finance",
        "journal-ref": "Quantitative Finance 3 (3), C39-C41 (2003)",
        "doi": null,
        "license": null,
        "abstract": "  In a recent comment (Johansen A 2003 An alternative view, Quant. Finance 3:\nC6-C7, cond-mat/0302141), Anders Johansen has criticized our methodology and\nhas questioned several of our results published in [Sornette D and Zhou W-X\n2002 The US 2000-2002 market descent: how much longer and deeper? Quant.\nFinance 2: 468-81, cond-mat/0209065] and in our two consequent preprints\n[cond-mat/0212010, physics/0301023]. In the present reply, we clarify the\nissues on (i) the analogy between rupture and crash, (ii) the Landau expansion,\n``double cosine'' and Weierstrass-type solutions, (iii) the symmetry between\nbubbles and anti-bubbles and universality, (iv) the condition of criticality,\n(v) the meaning of ``bullish anti-bubbles'', (vi) the absolute value of t_c-t,\n(vii) the fractal log-periodic power law patterns, (viii) the similarity\nbetween the Nikkei index in 1990-2000 and the S&P500 in 2000-2002 and (ix) the\npresent status of our prediction.\n"
    },
    {
        "paper_id": "cond-mat/0305038",
        "authors": "Dirk Tasche",
        "title": "A traffic lights approach to PD validation",
        "comments": "7 pages, LaTeX with hyperref package",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  As a consequence of the dependence experienced in loan portfolios, the\nstandard binomial test which is based on the assumption of independence does\nnot appear appropriate for validating probabilities of default (PDs). The model\nunderlying the new rules for minimum capital requirements (Basle II) is taken\nas a point of departure for deriving two parametric test procedures that\nincorporate dependence effects. The first one makes use of the so-called\ngranularity adjustment approach while the the second one is based on moment\nmatching.\n"
    },
    {
        "paper_id": "cond-mat/0305062",
        "authors": "Amir H. Darooneh",
        "title": "Non-Life Insurance Pricing : Statistical Mechanics Viewpoint",
        "comments": "10 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider the insurance company as a physical system which is immersed in\nits environment (the financial market). The insurer company interacts with the\nmarket by exchanging the money through the payments for loss claims and\nreceiving the premium. Here in the equilibrium state we obtain the premium by\nusing the canonical ensemble theory, and compare it with the {\\it Esscher}\nprinciple, the actuaristic well known formula for premium calculation. We\nsimulate the case of automobile insurance for quantitative comparison.\n"
    },
    {
        "paper_id": "cond-mat/0305270",
        "authors": "Kyungsik Kim and Seong-Min Yoon",
        "title": "Multifractal Features in the Foreign Exchange and Stock Markets",
        "comments": "9 pages, 5 figures, 2 Tables, Latex",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The multifractal behavior for tick data of prices is investigated in Korean\nfinancial market. Using the rescaled range analysis(R/S analysis), we show the\nmultifractal nature of returns for the won-dollar exchange rate and the KOSPI.\nWe also estimate the Hurst exponent and the generalized $q$th-order Hurst\nexponent in the unversal multifractal framework. Particularly, our financial\nmarket is a persistent process with long-run memory effects, and the\nstatistical value of the Hurst exponents occurs the crossovers at charateristic\ntime scales. It is found that the probability distribution of returns is well\nconsistent with a Lorentz distribution, significantly different from fat-tailed\nproperties.\n"
    },
    {
        "paper_id": "cond-mat/0305417",
        "authors": "Rene' Carmona and Dario Villani",
        "title": "Weak vs. Strong Correlations: Bid-Ask Spreads for Weather-Contingent\n  Options",
        "comments": "5 pages, 2 figures. Key words: Monte Carlo Methods, Weather\n  Derivatives, Commodity Markets",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We price weather-contingent options by use of Monte Carlo simulations. After\ncalibrating the models to fit quoted prices, we analyze bid-ask spreads in\nterms of correlations across markets. Results are presented for a\ndouble-trigger Weather vs. Natural Gas call option.\n"
    },
    {
        "paper_id": "cond-mat/0305475",
        "authors": "Szilard Pafka, Imre Kondor",
        "title": "Estimated Correlation Matrices and Portfolio Optimization",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.05.079",
        "license": null,
        "abstract": "  Financial correlations play a central role in financial theory and also in\nmany practical applications. From theoretical point of view, the key interest\nis in a proper description of the structure and dynamics of correlations. From\npractical point of view, the emphasis is on the ability of the developed models\nto provide the adequate input for the numerous portfolio and risk management\nprocedures used in the financial industry. This is crucial, since it has been\nlong argued that correlation matrices determined from financial series contain\na relatively large amount of noise and, in addition, most of the portfolio and\nrisk management techniques used in practice can be quite sensitive to the\ninputs. In this paper we introduce a model (simulation)-based approach which\ncan be used for a systematic investigation of the effect of the different\nsources of noise in financial correlations in the portfolio and risk management\ncontext. To illustrate the usefulness of this framework, we develop several toy\nmodels for the structure of correlations and, by considering the finiteness of\nthe time series as the only source of noise, we compare the performance of\nseveral correlation matrix estimators introduced in the academic literature and\nwhich have since gained also a wide practical use. Based on this experience, we\nbelieve that our simulation-based approach can also be useful for the\nsystematic investigation of several other problems of much interest in finance.\n"
    },
    {
        "paper_id": "cond-mat/0306322",
        "authors": "Juan C. Ferrero",
        "title": "The statistical distribution of money and the rate of money transference",
        "comments": "15 pages plus 1 table plus 3 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.05.029",
        "license": null,
        "abstract": "  The distribution of money is analysed in connection with the Boltzmann\ndistribution of energy in the degenerate states of molecules. Plots of the\npopulation density of income distribution for various countries are well\nreproduced by a Gamma function, confirming the validity of the statistical\ndistribution at equilibrium. The equilibrium state is reached through pair wise\nmoney transference processes, independently of the shape of the initial\ndistribution and also of the detailed nature of the money transactions between\nthe economic agents.\n"
    },
    {
        "paper_id": "cond-mat/0306496",
        "authors": "D. Sornette (CNRS-Univ. Nice and UCLA), W.-X. Zhou (UCLA)",
        "title": "Evidence of Fueling of the 2000 New Economy Bubble by Foreign Capital\n  Inflow: Implications for the Future of the US Economy and its Stock Market",
        "comments": "41 Latex pages including 14 eps figures",
        "journal-ref": "Physica A 332 (2004) 412-440",
        "doi": "10.1016/j.physa.2003.10.010",
        "license": null,
        "abstract": "  Previous analyses of a large ensemble of stock markets have demonstrated that\na log-periodic power law (LPPL) behavior of the prices constitutes a qualifying\nsignature of speculative bubbles that often land with a crash. We detect such a\nLPPL signature in the foreign capital inflow during the bubble on the US\nmarkets culminating in March 2000. We detect a weak synchronization and lag\nwith the NASDAQ 100 LPPL pattern. We propose to rationalize these observations\nby the existence of positive feedback loops between market-appreciation /\nincreased-spending / increased-deficit-of-balance-of-payment /\nlarger-foreign-surplus / increased-foreign-capital-inflows and so on. Our\nanalysis suggests that foreign capital inflow have been following rather than\ncausing the bubble. We then combine a macroeconomic analysis of feedback\nprocesses occurring between the economy and the stock market with a technical\nanalysis of more than two hundred years of the DJIA to investigate possible\nscenarios for the future, three years after the end of the bubble and deep into\na bearish regime. We also detect a LPPL accelerating bubble on the EURO against\nthe US dollar and the Japanese Yen. In sum, our analyses is in line with our\nprevious work on the LPPL ``anti-bubble'' representing the bearish market that\nstarted in 2000.\n"
    },
    {
        "paper_id": "cond-mat/0306507",
        "authors": "Andrea De Martino (INFM-SMC, Roma 1)",
        "title": "Dynamics of multi-frequency minority games",
        "comments": "9 pages, 5 figures",
        "journal-ref": "Eur. Phys. J. B 35 143 (2003)",
        "doi": "10.1140/epjb/e2003-00265-5",
        "license": null,
        "abstract": "  The dynamics of minority games with agents trading on different time scales\nis studied via dynamical mean-field theory. We analyze the case where the\nagents' decision-making process is deterministic and its stochastic\ngeneralization with finite heterogeneous learning rates. In each case, we\ncharacterize the macroscopic properties of the steady states resulting from\ndifferent frequency and learning rate distributions and calculate the\ncorresponding phase diagrams. Finally, the different roles played by regular\nand occasional traders, as well as their impact on the system's global\nefficiency, are discussed.\n"
    },
    {
        "paper_id": "cond-mat/0306579",
        "authors": "Nicola Scafetta, Bruce J. West and Sergio Picozzi",
        "title": "A Trade-Investment Model for Distribution of Wealth",
        "comments": "23 pages, 8 figures, 2 tables- in press on a special issue of Physica\n  D to be entitled \"Anomalous Distributions, Nonlinear Dynamics, and\n  Nonextensivity\" (2003). This paper is part of a conference proceedings for\n  the international Workshop on Anomalous Distributions, Nonlinear Dynamics and\n  Nonextensivity, Nov 6-9 2002, Santa Fe (NM). The work was presented by N.\n  Scafetta",
        "journal-ref": null,
        "doi": "10.1016/j.physd.2004.01.031",
        "license": null,
        "abstract": "  Econophysics provides a strategy for understanding the potential mechanisms\nunderlying the anomalous distribution of wealth found in real societies. We\npresent a computational nonlinear stochastic model for the distribution of\nwealth that depends upon three parameters and two mechanisms: trade and\ninvestment. To avoid economic paradoxes, the trade mechanism is assumed to be\nrelated to the poorer trader's wealth and to statistically advantage the poorer\nof the two traders. The two mechanisms together are shown to generate a\ndistribution that reproduces the full range of the empirical wealth\ndistribution, and not only the inverse power-law tail that Pareto found in\nwestern societies at the end of the 19th century.\n"
    },
    {
        "paper_id": "cond-mat/0306605",
        "authors": "Celia Anteneodo and Constantino Tsallis",
        "title": "Risk aversion in financial decisions: A nonextensive approach",
        "comments": "Based on an invited conference given by one of us (C.T.) at the\n  \"International Public Seminar of the Year\", 27 August 2002, Jakarta,\n  Indonesia. To appear in the Proceedings of the meeting, Editor Y. Surya. 10\n  pages and 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The sensitivity to risk that most people (hence, financial operators) feel\naffects the dynamics of financial transactions. Here we present an approach to\nthis problem based on a current generalization of Boltzmann-Gibbs statistical\nmechanics.\n"
    },
    {
        "paper_id": "cond-mat/0306608",
        "authors": "J. Kwapien, S. Drozdz and J. Speth",
        "title": "Alternation of different fluctuation regimes in the stock market\n  dynamics",
        "comments": "19 pages",
        "journal-ref": "Physica A 330 (2003) 605-621",
        "doi": "10.1016/j.physa.2003.09.012",
        "license": null,
        "abstract": "  Based on the tick-by-tick stock prices from the German and American stock\nmarkets, we study the statistical properties of the distribution of the\nindividual stocks and the index returns in highly collective and noisy\nintervals of trading, separately. We show that periods characterized by the\nstrong inter-stock couplings can be associated with the distributions of index\nfluctuations which reveal more pronounced tails than in the case of weaker\ncouplings in the market. During periods of strong correlations in the German\nmarket these distributions can even reveal an apparent L\\'evy-stable component.\n"
    },
    {
        "paper_id": "cond-mat/0307170",
        "authors": "Guennadi Saiko",
        "title": "On Simple Mean-Field Stochastic Model of Market Dynamics",
        "comments": "LaTeX, 5 pages with 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a simple stochastic model of market behavior. Dividing market\nparticipants into two groups: trend-followers and fundamentalists, we derive\nthe general form of a stochastic equation of market dynamics. The model has two\ncharacteristic time scales: the time of changes of market environment and the\ncharacteristic time of news flow. Price behavior in the most general case is\ndriven by three stochastic processes, attributed to trend-followers,\nfundamentalists, and news flow, respectively. The model demonstrates the wide\nrange of peculiarities which are typical in real markets: multiscale behavior,\nclustered volatility, weak correlations between the price changes on successive\ntrading days, etc.\n"
    },
    {
        "paper_id": "cond-mat/0307226",
        "authors": "M. Acharyya (Krishnanagar Govt. College) and A. B. Acharyya (Hooghly\n  Mohsin College)",
        "title": "Modelling and computer simulation of an insurance policy: A search for\n  maximum profit",
        "comments": "This paper is dedicated to Prof. D. Stauffer on the occassion of his\n  60th birthday. Int. J. Mod. Phys. C (2003) (in press)",
        "journal-ref": "International Journal of Modern Physics C 14 (2003) 1041",
        "doi": "10.1142/S0129183103005170",
        "license": null,
        "abstract": "  We have developed a model for a life insurance policy. In this model the net\ngain is calculated by computer simulation for a particular type of lifetime\ndistribution function. We observed that the net gain becomes maximum for a\nparticular value of upper age of last premium. This paper is dedicated to\nProfessor Dietrich Stauffer on the occassion of his 60-th birthday.\n"
    },
    {
        "paper_id": "cond-mat/0307244",
        "authors": "Imre Kondor, Andras Szepessy, and Tunde Ujvarosi",
        "title": "Concave risk measures in international capital regulation",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We show that some specific market risk measures implied by current\ninternational capital regulation (the Basel Accords and the Capital Adequacy\nDirective of the European Union) violate the obvious requirement of convexity\nin some regions in the space of portfolio weights.\n"
    },
    {
        "paper_id": "cond-mat/0307270",
        "authors": "Takayuki Mizuno, Misako Takayasu, and Hideki Takayasu",
        "title": "The mean-field approximation model of company's income growth",
        "comments": "10 pages, 7 figures, submitted to Physics A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2003.10.006",
        "license": null,
        "abstract": "  We introduce a mean-field type approximation for description of company's\nincome statistics. Utilizing huge company data we show that a discrete version\nof Langevin equation with additive and multiplicative noises can appropriately\ndescribe the time evolution of a company's income fluctuation in statistical\nsense. The Zipf's law of income distribution is shown to be hold in a\nsteady-sate widely, and country-dependence of income distribution can also be\nnicely implemented in our numerical simulation.\n"
    },
    {
        "paper_id": "cond-mat/0307323",
        "authors": "Piotr Gnacinski and Danuta Makowiec",
        "title": "Another type of log-periodic oscillations on Polish stock market?",
        "comments": "10 pages (6 figures): conference APFA4 (Warsaw, November 2003)",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.06.143",
        "license": null,
        "abstract": "  Log-periodic oscillations have been used to predict price trends and crashes\non financial markets. So far two types of log-periodic oscillations have been\nassociated with the real markets. The first type are oscillations which\naccompany a rising market and which ends in a crash. The second type\noscillations, called \"anti-bubbles\" appear after a crash, when the prices\ndecreases. Here, we propose the third type of log-periodic oscillations, where\na exogenous crash initializes a log-periodic behavior of market, and the market\nis growing up. Such behavior has been identified on Polish stock market index\nbetween the \"Russian crisis\" (August 1998) and the \"New Economy crash\" in April\n2000.\n"
    },
    {
        "paper_id": "cond-mat/0307332",
        "authors": "Jean-Philippe Bouchaud (CEA, CFM), Yuval Gefen (Weizmann), Marc\n  Potters (CFM), Matthieu Wyart (CEA)",
        "title": "Fluctuations and response in financial markets: the subtle nature of\n  `random' price changes",
        "comments": null,
        "journal-ref": "Quantitative Finance 4 (April 2004) 176-190",
        "doi": "10.1088/1469-7688/4/2/007",
        "license": null,
        "abstract": "  Using Trades and Quotes data from the Paris stock market, we show that the\nrandom walk nature of traded prices results from a very delicate interplay\nbetween two opposite tendencies: long-range correlated market orders that lead\nto super-diffusion (or persistence), and mean reverting limit orders that lead\nto sub-diffusion (or anti-persistence). We define and study a model where the\nprice, at any instant, is the result of the impact of all past trades, mediated\nby a non constant `propagator' in time that describes the response of the\nmarket to a single trade. Within this model, the market is shown to be, in a\nprecise sense, at a critical point, where the price is purely diffusive and the\naverage response function almost constant. We find empirically, and discuss\ntheoretically, a fluctuation-response relation. We also discuss the fraction of\ntruly informed market orders, that correctly anticipate short term moves, and\nfind that it is quite small.\n"
    },
    {
        "paper_id": "cond-mat/0307341",
        "authors": "Adrian A. Dragulescu",
        "title": "Applications of physics to economics and finance: Money, income, wealth,\n  and the stock market",
        "comments": "30 pages, 30 figures. Ph.D. thesis in physics defended on May 15,\n  2002 at the University of Maryland. Covers cond-mat/0001432,\n  cond-mat/0008305, cond-mat/0103544, cond-mat/0203046, cond-mat/0211175, and\n  contains extra material. v.2: spelling of a name is corrected",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Several problems arising in Economics and Finance are analyzed using concepts\nand quantitative methods from Physics. Here is the abridged abstact:\n  Chapter 1: By analogy with energy, the equilibrium probability distribution\nof money must follow the exponential Boltzmann-Gibbs law characterized by an\neffective temperature equal to the average amount of money per economic agent.\nA thermal machine which extracts a monetary profit can be constructed between\ntwo economic systems with different temperatures.\n  Chapter 2: Using data from several sources, it is found that the distribution\nof income is described for the great majority of population by an exponential\ndistribution, whereas the high-end tail follows a power law. The Lorenz curve\nand Gini coefficient were calculated and are shown to be in good agreement with\nboth income and wealth data sets.\n  Chapter 3: The Heston model where stock-price dynamics is governed by a\ngeometrical (multiplicative) Brownian motion with stochastic variance is\nstudied. The corresponding Fokker-Planck equation is solved exactly.\nIntegrating out the variance, an analytic formula for the time-dependent\nprobability distribution of stock price changes (returns) is found. The formula\nis in excellent agreement with the Dow-Jones index for the time lags from 1 to\n250 trading days.\n"
    },
    {
        "paper_id": "cond-mat/0307759",
        "authors": "Miquel Montero",
        "title": "Partial Derivative Approach for Option Pricing in a Simple Stochastic\n  Volatility Model",
        "comments": "21 pages, 3 figures, submitted for publication",
        "journal-ref": "Eur. Phys. J. B 42, 141--153 (2004)",
        "doi": "10.1140/epjb/e2004-00366-7",
        "license": null,
        "abstract": "  We study a market model in which the volatility of the stock may jump at a\nrandom time from a fixed value to another fixed value. This model was already\ndescribed in the literature. We present a new approach to the problem, based on\npartial derivative equations, which gives a different perspective to the\nproblem. Within our framework we can easily consider several prescriptions for\nthe market price of volatility risk, and interpret their financial meaning.\nThus, we recover solutions previously cited in the literature as well as obtain\nnew ones.\n"
    },
    {
        "paper_id": "cond-mat/0308012",
        "authors": "Kaushik Matia, Yosef Ashkenazy and H. Eugene Stanley",
        "title": "Multifractal Properties of Price Fluctuations of Stocks and Commodities",
        "comments": "Published in Euro Physics Letters (14 pages, 5 figures)",
        "journal-ref": null,
        "doi": "10.1209/epl/i2003-00194-y",
        "license": null,
        "abstract": "  We analyze daily prices of 29 commodities and 2449 stocks, each over a period\nof $\\approx 15$ years. We find that the price fluctuations for commodities have\na significantly broader multifractal spectrum than for stocks. We also propose\nthat multifractal properties of both stocks and commodities can be attributed\nmainly to the broad probability distribution of price fluctuations and\nsecondarily to their temporal organization. Furthermore, we propose that, for\ncommodities, stronger higher order correlations in price fluctuations result in\nbroader multifractal spectra.\n"
    },
    {
        "paper_id": "cond-mat/0308013",
        "authors": "Kaushik Matia, Mukul Pal, H. Eugene Stanley, H. Salunkay",
        "title": "Scale-Dependent Price Fluctuations for the Indian Stock Market",
        "comments": "7 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1209/epl/i2003-10267-y",
        "license": null,
        "abstract": "  Classic studies of the probability density of price fluctuations $g$ for\nstocks and foreign exchanges of several highly developed economies have been\ninterpreted using a {\\it power-law} probability density function $P(g) \\sim\ng^{-(\\alpha+1)}$ with exponent values $\\alpha > 2$, which are outside the\nL\\'evy-stable regime $0 < \\alpha < 2$. To test the universality of this\nrelationship for less highly developed economies, we analyze daily returns for\nthe period Nov. 1994--June 2002 for the 49 largest stocks of the National Stock\nExchange which has the highest volume of trade in India. We find that $P(g)$\ndecays as an {\\it exponential} function $P(g) \\sim \\exp(-\\beta g)$ with a\ncharacteristic decay scales $\\beta = 1.51 \\pm 0.05$ for the negative tail and\n$\\beta = 1.34 \\pm 0.04$ for the positive tail, which is significantly different\nfrom that observed for developed economies. Thus we conclude that the Indian\nstock market may belong to a universality class that differs from those of\ndeveloped countries analyzed previously.\n"
    },
    {
        "paper_id": "cond-mat/0308017",
        "authors": "Jaume Masoliver, Miquel Montero, Josep Perello and George H. Weiss",
        "title": "The CTRW in finance: Direct and inverse problems with some\n  generalizations and extensions",
        "comments": "25 pages, 3 figures, Elsart, submitted for publication",
        "journal-ref": "Physica A 379 (2007) 151-167",
        "doi": "10.1016/j.physa.2007.01.001",
        "license": null,
        "abstract": "  We study financial distributions within the framework of the continuous time\nrandom walk (CTRW). We review earlier approaches and present new results\nrelated to overnight effects as well as the generalization of the formalism\nwhich embodies a non-Markovian formulation of the CTRW aimed to account for\ncorrelated increments of the return.\n"
    },
    {
        "paper_id": "cond-mat/0308358",
        "authors": "Martin Hohnisch, Sabine Pittnauer and Dietrich Stauffer",
        "title": "Percolation-Based Model of New-Product Diffusion with Macroscopic\n  Feedback Effects",
        "comments": "Econophysics, 11 pages including figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper proposes a percolation-based model of new-product diffusion in the\nspirit of Solomon et al. (2000) and Goldenberg et al. (2000). A consumer buys\nthe new product if she has formed her individual valuation of the product\n(reservation price) and if this valuation is greater or equal than the price of\nthe product announced by the firm in a given period. Our model differs from\nprevious percolation-based models of new-product diffusion in two respects.\nFirst, we consider macroscopic feedback effects affecting the supply or the\ndemand side of the market (or both). Second, a consumer who did not buy the\nproduct in the period in which her valuation was formed remains a potential\nbuyer and buys in some later period if and when her individual valuation equals\nor exceeds the price of the product. Unlike most previous models of new-product\ndiffusion, our framework accounts for the empirical finding of long tails\ncharacteristic for early stages of innovation diffusion.\n"
    },
    {
        "paper_id": "cond-mat/0308365",
        "authors": "Takayuki Mizuno, Makoto Katori, Hideki Takayasu, Misako Takayasu",
        "title": "Statistical Laws in the Income of Japanese Companies",
        "comments": "Empirical science of financial fluctuations: the advent of\n  econophysics/ Hideki Takayasu (ed.), Proceeding of a workshop hosted by the\n  Nihon Keizai Shimbun, Inc., and held in Tokyo, Nov. 15-17, 2000",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Following the work of Okuyama, Takayasu and Takayasu [Okuyama, Takayasu and\nTakayasu 1999] we analyze huge databases of Japanese companies' financial\nfigures and confirm that the Zipf's law, a power law distribution with the\nexponent -1, has been maintained over 30 years in the income distribution of\nJapanese companies with very high precision. Similar power laws are found not\nonly in income distribution of company's income, but also in the distributions\nof capital, sales and number of employees. From the data we find an important\ntime evolutionary property that the growth rate of income is approximately\nindependent of the value of income, namely, small companies and large ones have\nsimilar statistical chances of growth. This observational fact suggests the\napplicability of the theory of multiplicative stochastic processes developed in\nstatistical physics. We introduce a discrete version of Langevin equation with\nadditive and multiplicative noises as a simple time evolution model of\ncompany's income. We test the validity of the Takayasu-Sato-Takayasu condition\n[Takayasu, Sato and Takayasu 1997] for having an asymptotic power law\ndistribution as a unique statistically steady solution. Directly estimated\npower law exponents and theoretically evaluated ones are compared resulting a\nreasonable fit by introducing a normalization to reduce the effect of gross\neconomic change.\n"
    },
    {
        "paper_id": "cond-mat/0308548",
        "authors": "Jorgen Vitting Andersen",
        "title": "Could short selling make financial markets tumble?",
        "comments": "Revtex, 7 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  It is suggested to consider long term trends of financial markets as a growth\nphenomenon. The question that is asked is what conditions are needed for a long\nterm sustainable growth or contraction in a financial market? The paper discuss\nthe role of traditional market players of long only mutual funds versus hedge\nfunds which take both short and long positions. It will be argued that\nfinancial markets since their very origin and only till very recently, have\nbeen in a state of ``broken symmetry'' which favored long term growth instead\nof contraction. The reason for this ``broken symmetry'' into a long term ``bull\nphase'' is the historical almost complete dominance by long only players in\nfinancial markets. Dangers connected to short trading are illustrated by the\nappearence of long term bearish trends seen in analytical results and by\nsimulation results of an agent based market model. Recent short trade data of\nthe Nasdaq Composite index show an increase in the short activity prior to or\nat the same time as dips in the market, and reveal an steadily increase in the\nshort trading activity, reaching levels never seen before.\n"
    },
    {
        "paper_id": "cond-mat/0309003",
        "authors": "Dirk Tasche and Ursula Theiler",
        "title": "Calculating Concentration-Sensitive Capital Charges with Conditional\n  Value-at-Risk",
        "comments": "8 pages, 1 figure, minor corrections",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  By mid 2004, the Basel Committee on Banking Supervision (BCBS) is epected to\nlaunch its final recommendations on minimum capital requirements in the banking\nindustry. Although there is the intention to arrive at capital charges which\nconcur with economic intuition, the risk weight formulas proposed by the\ncommittee will lack an adequate treatment of concentration risks in credit\nportfolios. The question arises whether this problem can be solved without\nrecourse to fully-fledged portfolio models. Since recent practical experience\nshows that the risk measure Conditional Value-at-Risk (CVaR) is particularly\nwell suited for detecting concentrations, we develop the semi-asymptotic\napproach by Emmer and Tasche in the CVaR context and compare it with the\ncapital charges recently suggested by the Basel Committee. Both approaches are\nbased on the same Vasicek one-factor model.\n"
    },
    {
        "paper_id": "cond-mat/0309233",
        "authors": "J. Doyne Farmer, Paolo Patelli, Ilija I. Zovko",
        "title": "The Predictive Power of Zero Intelligence in Financial Markets",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Standard models in economics stress the role of intelligent agents who\nmaximize utility. However, there may be situations where, for some purposes,\nconstraints imposed by market institutions dominate intelligent agent behavior.\nWe use data from the London Stock Exchange to test a simple model in which zero\nintelligence agents place orders to trade at random. The model treats the\nstatistical mechanics of order placement, price formation, and the accumulation\nof revealed supply and demand within the context of the continuous double\nauction, and yields simple laws relating order arrival rates to statistical\nproperties of the market. We test the validity of these laws in explaining the\ncross-sectional variation for eleven stocks. The model explains 96% of the\nvariance of the bid-ask spread, and 76% of the variance of the price diffusion\nrate, with only one free parameter. We also study the market impact function,\ndescribing the response of quoted prices to the arrival of new orders. The\nnon-dimensional coordinates dictated by the model approximately collapse data\nfrom different stocks onto a single curve. This work is important from a\npractical point of view because it demonstrates the existence of simple laws\nrelating prices to order flows, and in a broader context, because it suggests\nthat there are circumstances where institutions are more important than\nstrategic considerations.\n"
    },
    {
        "paper_id": "cond-mat/0309404",
        "authors": "Peter Richmond and Lorenzo Sabatelli",
        "title": "Langevin processes, agent models and socio-economic systems",
        "comments": "1 figure",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.01.007",
        "license": null,
        "abstract": "  We review some approaches to the understanding of fluctuations in some models\nused to describe socio and economic systems. Our approach builds on the\ndevelopment of a simple Langevin equation that characterises stochastic\nprocesses. This provides a unifying approach that allows first a\nstraightforward description of the early approaches of Bachelier. We generalise\nthe approach to stochastic equations that model interacting agents. Using a\nsimple change of variable, we show that the peer pressure model of Marsilli and\nthe wealth dynamics model of Solomon are closely related. The methods are\nfurther shown to be consistent with a global free energy functional that\ninvokes an entropy term based on the Boltzmann formula. A more recent approach\nby Michael and Johnson maximised a Tsallis entropy function subject to simple\nconstraints. We show how this approach can be developed from an agent model\nwhere the simple Langevin process is now conditioned by local rather than\nglobal noise. The approach yields a BBGKY type hierarchy of equations for the\nsystem correlation functions. Of especial interest is that the results can be\nobtained from a new free energy functional similar to that mentioned above\nexcept that a Tsallis like entropy term replaces the Boltzmann entropy term. A\nmean field approximation yields the results of Michael and Johnson. We show how\npersonal income data for Brazil, the US, Germany and the UK, analysed recently\nby Borgas can be qualitatively understood by this approach.\n"
    },
    {
        "paper_id": "cond-mat/0309416",
        "authors": "J. Doyne Farmer and Fabrizio Lillo",
        "title": "On the origin of power law tails in price fluctuations",
        "comments": "5 pages; replacement clarifies a few points (e.g. clearer description\n  of data set) that were unclear in the earlier version",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In a recent Nature paper, Gabaix et al. \\cite{Gabaix03} presented a theory to\nexplain the power law tail of price fluctuations. The main points of their\ntheory are that volume fluctuations, which have a power law tail with exponent\nroughly -1.5, are modulated by the average market impact function, which\ndescribes the response of prices to transactions. They argue that the average\nmarket impact function follows a square root law, which gives power law tails\nfor prices with exponent roughly -3. We demonstrate that the long-memory nature\nof order flow invalidates their statistical analysis of market impact, and\npresent a more careful analysis that properly takes this into account. This\nmakes it clear that the functional form of the average market impact function\nvaries from market to market, and in some cases from stock to stock. In fact,\nfor both the London Stock Exchange and the New York Stock Exchange the average\nmarket impact function grows much slower than a square root law; this implies\nthat the exponent for price fluctuations predicted by modulations of volume\nfluctuations is much too big. We find that for LSE stocks the distribution of\ntransaction volumes does not even have a power law tail. This makes it clear\nthat volume fluctuations do not determine the power law tail of price returns.\n"
    },
    {
        "paper_id": "cond-mat/0309533",
        "authors": "A. De Martino, M. Marsili and I. P\\'erez Castillo",
        "title": "Typical properties of large random economies with linear activities",
        "comments": "19 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the competitive equilibrium of large random economies with linear\nactivities using methods of statistical mechanics. We focus on economies with\n$C$ commodities, $N$ firms, each running a randomly drawn linear technology,\nand one consumer. We derive, in the limit $N,C\\to\\infty$ with $n=N/C$ fixed, a\ncomplete description of the statistical properties of typical equilibria. We\nfind two regimes, which in the limit of efficient technologies are separated by\na phase transition, and argue that endogenous technological change drives the\neconomy close to the critical point.\n"
    },
    {
        "paper_id": "cond-mat/0309549",
        "authors": "R. Donangelo and K. Sneppen",
        "title": "Cooperativity in a trading model with memory and production",
        "comments": "12 pages, 7 figures",
        "journal-ref": "Physica A 316 (2002) 581-591",
        "doi": "10.1016/S0378-4371(02)01016-6",
        "license": null,
        "abstract": "  We consider in a market model the cooperative emergence of value due to a\npositive feedback between perception of needs and demand. Here we consider also\na negative feedback from production of the traded products, and find that this\ncooperativity is robust, provided that the production rate is slow.\nCooperativity is found to be critically linked to the ability to minimize the\noverall need, and thus disappears when the agents are poor, when the production\nrate is large or when there is little trade. We further observe that a\ncooperative economy may self-organize to compensate for an eventual slow\nproduction rate of certain products, so that these products are found in\nsizeable stocks. This differs qualitatively from an economy where cooperativity\ndid not develop, in which case no product has a stock larger than what its bare\nproduction rate justifies. We also find that these results are robust in\nrelation to the spatial restriction of the agents.\n"
    },
    {
        "paper_id": "cond-mat/0310061",
        "authors": "Yoshi Fujiwara, Corrado Di Guilmi, Hideaki Aoyama, Mauro Gallegati,\n  Wataru Souma",
        "title": "Do Pareto-Zipf and Gibrat laws hold true? An analysis with European\n  Firms",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2003.12.015",
        "license": null,
        "abstract": "  By employing exhaustive lists of large firms in European countries, we show\nthat the upper-tail of the distribution of firm size can be fitted with a\npower-law (Pareto-Zipf law), and that in this region the growth rate of each\nfirm is independent of the firm's size (Gibrat's law of proportionate effect).\nWe also find that detailed balance holds in the large-size region for periods\nwe investigated; the empirical probability for a firm to change its size from a\nvalue to another is statistically the same as that for its reverse process. We\nprove several relationships among Pareto-Zipf's law, Gibrat's law and the\ncondition of detailed balance. As a consequence, we show that the distribution\nof growth rate possesses a non-trivial relation between the positive side of\nthe distribution and the negative side, through the value of Pareto index, as\nis confirmed empirically.\n"
    },
    {
        "paper_id": "cond-mat/0310062",
        "authors": "Yoshi Fujiwara",
        "title": "Zipf Law in Firms Bankruptcy",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.01.037",
        "license": null,
        "abstract": "  Using an exhaustive list of Japanese bankruptcy in 1997, we discover a Zipf\nlaw for the distribution of total liabilities of bankrupted firms in high debt\nrange. The life-time of these bankrupted firms has exponential distribution in\ncorrelation with entry rate of new firms. We also show that the debt and size\nare highly correlated, so the Zipf law holds consistently with that for size\ndistribution. In attempt to understand ``physics'' of bankruptcy, we show that\na model of debtor-creditor dynamics of firms and a bank, recently proposed by\neconomists, can reproduce these phenomenological findings.\n"
    },
    {
        "paper_id": "cond-mat/0310092",
        "authors": "W.-X. Zhou (ECUST and Ucla), D. Sornette (UCLA and CNRS-Univ. Nice)",
        "title": "Testing the Stability of the 2000-2003 US Stock Market \"Antibubble\"",
        "comments": "17 Elsevier Latex (elsart.sty) text pages + 3 tables + 17 eps figures",
        "journal-ref": "Physica A 348 (2005) 428-452",
        "doi": "10.1016/j.physa.2004.09.032",
        "license": null,
        "abstract": "  Since August 2000, the stock market in the USA as well as most other western\nmarkets have depreciated almost in synchrony according to complex patterns of\ndrops and local rebounds. In \\cite{SZ02QF}, we have proposed to describe this\nphenomenon using the concept of a log-periodic power law (LPPL) antibubble,\ncharacterizing behavioral herding between investors leading to a competition\nbetween positive and negative feedbacks in the pricing process. A monthly\nprediction for the future evolution of the US S&P 500 index has been issued,\nmonitored and updated in \\cite{urlprediction}, which is still running. Here, we\ntest the possible existence of a regime switching in the US S&P 500 antibubble.\nFirst, we find some evidence that the antibubble has exhibited a transition in\nlog-periodicity described by a so-called second-order log-periodicity. Second,\n>...\n"
    },
    {
        "paper_id": "cond-mat/0310305",
        "authors": "Enrico Scalas, Rudolf Gorenflo, Francesco Mainardi, Maurizio Mantelli,\n  Marco Raberto",
        "title": "Anomalous waiting times in high-frequency financial data",
        "comments": "8 pages, 1 figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In high-frequency financial data not only returns, but also waiting times\nbetween consecutive trades are random variables. Therefore, it is possible to\napply continuous-time random walks (CTRWs) as phenomenological models of the\nhigh-frequency price dynamics. An empirical analysis performed on the 30 DJIA\nstocks shows that the waiting-time survival probability for high-frequency data\nis non-exponential. This fact sets limits for agent-based models of financial\nmarkets.\n"
    },
    {
        "paper_id": "cond-mat/0310343",
        "authors": "Arnab Das and Sudhakar Yarlagadda",
        "title": "A distribution function analysis of wealth distribution",
        "comments": "6 pages and 5 PS figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We develop a general framework to analyze the distribution functions of\nwealth and income. Within this framework we study wealth distribution in a\nsociety by using a model which turns on two-party trading for poor people while\nfor rich people interaction with wealthy entities (huge reservoir) is relevant.\nAt equilibrium, the interaction with wealthy entities gives a power law\n(Pareto-like) behavior in the wealth distribution while the two party\ninteraction gives a distribution similar to that reported earlier.\n"
    },
    {
        "paper_id": "cond-mat/0310351",
        "authors": "Przemyslaw Repetowicz and Peter Richmond",
        "title": "Modeling of waiting times and price changes in currency exchange data",
        "comments": "22 pages, 5 postscript figures, LaTeX2e using elsart.cls",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.06.162",
        "license": null,
        "abstract": "  A theory which describes the share price evolution at financial markets as a\ncontinuous-time random walk has been generalized in order to take into account\nthe dependence of waiting times t on price returns x. A joint probability\ndensity function (pdf) which uses the concept of a L\\'{e}vy stable distribution\nis worked out. The theory is fitted to high-frequency US$/Japanese Yen exchange\nrate and low-frequency 19th century Irish stock data. The theory has been\nfitted both to price return and to waiting time data and the adherence to data,\nin terms of the chi-squared test statistic, has been improved when compared to\nthe old theory.\n"
    },
    {
        "paper_id": "cond-mat/0310503",
        "authors": "Diego Garlaschelli, Stefano Battiston, Maurizio Castri, Vito D. P.\n  Servedio and Guido Caldarelli",
        "title": "The scale-free topology of market investments",
        "comments": "Final version accepted for publication on Physica A",
        "journal-ref": "Physica A 350 (2-4), 491-499 (2005)",
        "doi": "10.1016/j.physa.2004.11.040",
        "license": null,
        "abstract": "  We propose a network description of large market investments, where both\nstocks and shareholders are represented as vertices connected by weighted links\ncorresponding to shareholdings. In this framework, the in-degree ($k_{in}$) and\nthe sum of incoming link weights ($v$) of an investor correspond to the number\nof assets held (\\emph{portfolio diversification}) and to the invested wealth\n(\\emph{portfolio volume}) respectively. An empirical analysis of three\ndifferent real markets reveals that the distributions of both $k_{in}$ and $v$\ndisplay power-law tails with exponents $\\gamma$ and $\\alpha$. Moreover, we find\nthat $k_{in}$ scales as a power-law function of $v$ with an exponent $\\beta$.\nRemarkably, despite the values of $\\alpha$, $\\beta$ and $\\gamma$ differ across\nthe three markets, they are always governed by the scaling relation\n$\\beta=(1-\\alpha)/(1-\\gamma)$. We show that these empirical findings can be\nreproduced by a recent model relating the emergence of scale-free networks to\nan underlying Paretian distribution of `hidden' vertex properties.\n"
    },
    {
        "paper_id": "cond-mat/0310544",
        "authors": "T. Di Matteo, T. Aste and S. T. Hyde",
        "title": "Exchanges in complex networks: income and wealth distributions",
        "comments": "8 pages, 11 figures",
        "journal-ref": "in \"The Physics of Complex Systems (New Advances and\n  Perspectives)\", Eds. F. Mallamace and H. E. Stanley, (IOS Press, Amsterdam\n  2004) 435.",
        "doi": null,
        "license": null,
        "abstract": "  We investigate the wealth evolution in a system of agents that exchange\nwealth through a disordered network in presence of an additive stochastic\nGaussian noise. We show that the resulting wealth distribution is shaped by the\ndegree distribution of the underlying network and in particular we verify that\nscale free networks generate distributions with power-law tails in the\nhigh-income region. Numerical simulations of wealth exchanges performed on two\ndifferent kind of networks show the inner relation between the wealth\ndistribution and the network properties and confirm the agreement with a\nself-consistent solution. We show that empirical data for the income\ndistribution in Australia are qualitatively well described by our theoretical\npredictions.\n"
    },
    {
        "paper_id": "cond-mat/0311053",
        "authors": "Fabrizio Lillo and J. Doyne Farmer",
        "title": "The long memory of the efficient market",
        "comments": "19 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  For the London Stock Exchange we demonstrate that the signs of orders obey a\nlong-memory process. The autocorrelation function decays roughly as\n$\\tau^{-\\alpha}$ with $\\alpha \\approx 0.6$, corresponding to a Hurst exponent\n$H \\approx 0.7$. This implies that the signs of future orders are quite\npredictable from the signs of past orders; all else being equal, this would\nsuggest a very strong market inefficiency. We demonstrate, however, that\nfluctuations in order signs are compensated for by anti-correlated fluctuations\nin transaction size and liquidity, which are also long-memory processes. This\ntends to make the returns whiter. We show that some institutions display\nlong-range memory and others don't.\n"
    },
    {
        "paper_id": "cond-mat/0311089",
        "authors": "J. V. Andersen (CNRS, Univ. Nice and Univ. X-Nanterre) and D Sornette\n  (CNRS-Univ. Nice and UCLA)",
        "title": "Fearless versus Fearful Speculative Financial Bubbles",
        "comments": "12 pages + 9 figures + 9 tables",
        "journal-ref": "Physica A 337 (3-4), 565-585 (2004)",
        "doi": "10.1016/j.physa.2004.01.054",
        "license": null,
        "abstract": "  Using a recently introduced rational expectation model of bubbles, based on\nthe interplay between stochasticity and positive feedbacks of prices on returns\nand volatility, we develop a new methodology to test how this model classifies\n9 time series that have been previously considered as bubbles ending in\ncrashes. The model predicts the existence of two anomalous behaviors occurring\nsimultaneously: (i) super-exponential price growth and (ii) volatility growth,\nthat we refer to as the ``fearful singular bubble'' regime. Out of the 9 time\nseries, we find that 5 pass our tests and can be characterized as ``fearful\nsingular bubbles.'' The 4 other cases are the information technology Nasdaq\nbubble and three bubbles of the Hang Seng index ending in crashes in 1987, 1994\nand 1997. According to our analysis, these four bubbles have developed with\nessentially no significant increase of their volatility. This paper thus\nproposes that speculative bubbles ending in crashes form two groups hitherto\nunrecognized, namely those accompanied by increasing volatility (reflecting\nincreasing risk perception) and those without change of volatility (reflecting\nan absence of risk perception).\n"
    },
    {
        "paper_id": "cond-mat/0311096",
        "authors": "Jean-Pierre Nadal (1), Denis Phan (2), Mirta B. Gordon (3) and Jean\n  Vannimenus (1) ((1) LPS, Ecole Normale Sup\\'erieure, Paris, France, (2) ENST\n  Bretagne and ICI-UBO, Brest, France, (3) Leibniz, Grenoble, France)",
        "title": "Monopoly Market with Externality: an Analysis with Statistical Physics\n  and Agent Based Computational Economics",
        "comments": "20 pages, LaTeX2e, 5 figures. Presented at the 8th Annual Workshop on\n  Economics with Heterogeneous Interacting Agents (WEHIA 2003, May 29-31,\n  Kiel); extended version of the paper submitted for publication in the\n  conference proceedings",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We explore the effects of social influence in a simple market model in which\na large number of agents face a binary choice: 'to buy/not to buy' a single\nunit of a product at a price posted by a single seller (the monopoly case). We\nconsider the case of 'positive externalities': an agent is more willing to buy\nif the other agents with whom he/she interacts make the same decision.\n  We compare two special cases known in the economics literature as the\nThurstone and the McFadden approaches. We show that they correspond to modeling\nthe heterogenity in individual decision rules with, respectively, annealed and\nquenched disorder. More precisely the first case leads to a standard Ising\nmodel at finite temperature in a uniform external field, and the second case to\na random field Ising model (RFIM) at zero temperature.\n  Considering the optimisation of profit by the seller within the McFadden/RFIM\nmodel in the mean field limit, we exhibit a new first order phase transition:\nif the social influence is strong enough, there is a regime where, if the mean\nwillingness to pay increases, or if the production costs decrease, the optimal\nsolution for the seller jumps from one with a high price and a small number of\nbuyers, to another one with a low price and a large number of buyers.\n"
    },
    {
        "paper_id": "cond-mat/0311103",
        "authors": "J. Kwapien, S. Drozdz and J. Speth",
        "title": "Time scales involved in market emergence",
        "comments": "13 pages",
        "journal-ref": "Physica A 337 (2004) 231-242",
        "doi": "10.1016/j.physa.2004.01.050",
        "license": null,
        "abstract": "  In addressing the question of the time scales characteristic for the market\nformation, we analyze high frequency tick-by-tick data from the NYSE and from\nthe German market. By using returns on various time scales ranging from seconds\nor minutes up to two days, we compare magnitude of the largest eigenvalue of\nthe correlation matrix for the same set of securities but for different time\nscales. For various sets of stocks of different capitalization (and the average\ntrading frequency), we observe a significant elevation of the largest\neigenvalue with increasing time scale. Our results from the correlation matrix\nstudy go in parallel with the so-called Epps effect. There is no unique\nexplanation of this effect and it seems that many different factors play a role\nhere. One of such factors is randomness in transaction moments for different\nstocks. Another interesting conclusion to be drawn from our results is that in\nthe contemporary markets the emergence of significant correlations occurs on\ntime scales much smaller than in the more distant history.\n"
    },
    {
        "paper_id": "cond-mat/0311113",
        "authors": "S. Pianegonda and J.R. Iglesias",
        "title": "Inequalities of wealth distribution in a conservative economy",
        "comments": "7 pages, 4 figures, submitted to Physica A, Proceedings of the VIII\n  LAWNP, Salvador, Brazil, 2003",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.04.078",
        "license": null,
        "abstract": "  We analyze a conservative market model for the competition among economic\nagents in a close society. A minimum dynamics ensures that the poorest agent\nhas a chance to improve its economic welfare. After a transient, the system\nself-organizes into a critical state where the wealth distribution have a\nminimum threshold, with almost no agent below this poverty line, also, very few\nextremely rich agents are stable in time. Above the poverty line the\ndistribution follows an exponential behavior. The local solution exhibits a low\nGini index, while the mean field solution of the model generates a wealth\ndistribution similar to welfare states like Sweden.\n"
    },
    {
        "paper_id": "cond-mat/0311127",
        "authors": "J.R. Iglesias, S. Goncalves, G. Abramson, J.L. Vega",
        "title": "Correlation between Risk Aversion and Wealth distribution",
        "comments": "8 pages, 7 figures, submitted to Physica A, Proceedings of the VIII\n  LAWNP, Salvador, Brazil, 2003",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.04.077",
        "license": null,
        "abstract": "  Different models of capital exchange among economic agents have been proposed\nrecently trying to explain the emergence of Pareto's wealth power law\ndistribution. One important factor to be considered is the existence of risk\naversion. In this paper we study a model where agents posses different levels\nof risk aversion, going from uniform to a random distribution. In all cases the\nrisk aversion level for a given agent is constant during the simulation. While\nfor a uniform and constant risk aversion the system self-organizes in a\ndistribution that goes from an unfair ``one takes all'' distribution to a\nGaussian one, a random risk aversion can produce distributions going from\nexponential to log-normal and power-law. Besides, interesting correlations\nbetween wealth and risk aversion are found.\n"
    },
    {
        "paper_id": "cond-mat/0311155",
        "authors": "Kyungsik Kim, Seong-Min Yoon and Jum Soo Choi",
        "title": "Volatility and Returns in Korean Futures Exchange Markets",
        "comments": "13 Pages, 6 Figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We apply the formalism of the continuous time random walk (CTRW) theory to\nfinancial tick data of the bond futures transacted in Korean Futures Exchange\n(KOFEX) market. For our case, the tick dynamical behaviors of the returns and\nvolatility for bond futures are treated particularly at the long-time limit.\nThe volatility for the price of our bond futures shows a power-law with\nanomalous scaling exponent, similar to other options. Our result presented will\nbe compared with that of recent numerical calculations.\n"
    },
    {
        "paper_id": "cond-mat/0311227",
        "authors": "Arnab Chatterjee, Bikas K. Chakrabarti and S. S. Manna",
        "title": "Money in Gas-Like Markets: Gibbs and Pareto Laws",
        "comments": "4 pages, 2 eps figures, in Conference Procedings of International\n  Conference on \"Unconventional Applications of Statistical Physics\", Kolkata,\n  India, March 2003; paper published in Physica Scripta T106 (2003) 36",
        "journal-ref": "Physica Scripta T106 (2003) 36-38",
        "doi": "10.1238/Physica.Topical.106a00036",
        "license": null,
        "abstract": "  We consider the ideal-gas models of trading markets, where each agent is\nidentified with a gas molecule and each trading as an elastic or\nmoney-conserving (two-body) collision. Unlike in the ideal gas, we introduce\nsaving propensity $\\lambda$ of agents, such that each agent saves a fraction\n$\\lambda$ of its money and trades with the rest. We show the steady-state money\nor wealth distribution in a market is Gibbs-like for $\\lambda=0$, has got a\nnon-vanishing most-probable value for $\\lambda \\ne 0$ and Pareto-like when\n$\\lambda$ is widely distributed among the agents. We compare these results with\nobservations on wealth distributions of various countries.\n"
    },
    {
        "paper_id": "cond-mat/0311235",
        "authors": "Frantisek Slanina",
        "title": "Inelastically scattering particles and wealth distribution in an open\n  economy",
        "comments": "8 pages 5 figures",
        "journal-ref": "Phys. Rev. E 69, 046102 (2004)",
        "doi": "10.1103/PhysRevE.69.046102",
        "license": null,
        "abstract": "  Using the analogy with inelastic granular gasses we introduce a model for\nwealth exchange in society. The dynamics is governed by a kinetic equation,\nwhich allows for self-similar solutions. The scaling function has a power-law\ntail, the exponent being given by a transcendental equation. In the limit of\ncontinuous trading, closed form of the wealth distribution is calculated\nanalytically.\n"
    },
    {
        "paper_id": "cond-mat/0311257",
        "authors": "F.F. Ferreira and M. Marsili",
        "title": "Real payoffs and virtual trading in agent based market models",
        "comments": "20pages and 15 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The \\$-Game was recently introduced as an extension of the Minority Game. In\nthis paper we compare this model with the well know Minority Game and the\nMajority Game models. Due to the inter-temporal nature of the market payoff, we\nintroduce a two step transaction with single and mixed group of interacting\ntraders. When the population is composed of two different group of \\$-traders,\nthey show an anti-imitative behavior. However, when they interact with minority\nor majority players the \\$-population imitates the usual behavior of these\nplayers. Finally we discuss how these models contribute to clarify the market\nmechanism.\n"
    },
    {
        "paper_id": "cond-mat/0311372",
        "authors": "M. Bartolozzi and A. W. Thomas",
        "title": "Stochastic Cellular Automata Model for Stock Market Dynamics",
        "comments": "17 pages and 7 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.69.046112",
        "license": null,
        "abstract": "  In the present work we introduce a stochastic cellular automata model in\norder to simulate the dynamics of the stock market. A direct percolation method\nis used to create a hierarchy of clusters of active traders on a two\ndimensional grid. Active traders are characterised by the decision to buy,\n(+1), or sell, (-1), a stock at a certain discrete time step. The remaining\ncells are inactive,(0). The trading dynamics is then determined by the\nstochastic interaction between traders belonging to the same cluster. Most of\nthe stylized aspects of the financial market time series are reproduced by the\nmodel.\n"
    },
    {
        "paper_id": "cond-mat/0311581",
        "authors": "G. Ehrenstein, F. Westerhoff and D. Stauffer",
        "title": "Tobin tax and market depth",
        "comments": "16 pages econophysics, including figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper investigates - on the basis of the Cont-Bouchaud model - whether a\nTobin tax can stabilize foreign exchange markets. Compared to earlier studies,\nthis paper explicitly recognizes that a transaction tax-induced reduction in\nmarket depth may increase the price responsiveness of a given order. We find\nthat the imposition of a transaction tax may still achieve a triple dividend:\n(1) exchange rate fluctuations decrease, (2) currencies are less mispriced, and\n(3) central authorities raise substantial tax revenues. However, if the price\nimpact function is too sensitive with respect to market depth, stabilization\nmay turn into destabilization.\n"
    },
    {
        "paper_id": "cond-mat/0311585",
        "authors": "Ian Wright",
        "title": "The duration of recessions follows an exponential not a power law",
        "comments": "3 pages, 2 figures. Submitted to Physica A",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, 345, 3-4,\n  pp. 608-610, 2005",
        "doi": "10.1016/j.physa.2004.07.035",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  Ormerod and Mounfield analysed GDP data of 17 leading capitalist economies\nfrom 1870 to 1994 and concluded that the frequency of the duration of\nrecessions is consistent with a power-law. But in fact the data is consistent\nwith an exponential (Boltzmann-Gibbs) law.\n"
    },
    {
        "paper_id": "cond-mat/0311594",
        "authors": "Hisanao Takahashi",
        "title": "Ehrenfest Model with Large Jumps in Finance",
        "comments": "15 pages, 5 figures",
        "journal-ref": "Physica D 189 (2004) 61-69",
        "doi": "10.1016/j.physd.2003.07.005",
        "license": null,
        "abstract": "  Changes (returns) in stock index prices and exchange rates for currencies are\nargued, based on empirical data, to obey a stable distribution with\ncharacteristic exponent $ \\alpha < 2 $ for short sampling intervals and a\nGaussian distribution for long sampling intervals. In order to explain this\nphenomenon, an Ehrenfest model with large jumps (ELJ) is introduced to explain\nthe empirical density function of price changes for both short and long\nsampling intervals.\n"
    },
    {
        "paper_id": "cond-mat/0311627",
        "authors": "D. Grech (Inst. Ther. Phys. Wroclaw Univ.) and Z. Mazur (Inst.\n  Exper.Phys. Wroclaw Univ.)",
        "title": "Can One Make Any Crash Prediction in Finance Using the Local Hurst\n  Exponent Idea?",
        "comments": "LaTeX 2e, 7 figures (included), 17 pages",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.01.018",
        "license": null,
        "abstract": "  We apply the Hurst exponent idea for investigation of DJIA index time-series\ndata. The behavior of the local Hurst exponent prior to drastic changes in\nfinancial series signal is analyzed. The optimal length of the time-window over\nwhich this exponent can be calculated in order to make some meaningful\npredictions is discussed. Our prediction hypothesis is verified with examples\nof '29 and '87 crashes, as well as with more recent phenomena in stock market\nfrom the period 1995-2003.Some interesting agreements are found.\n"
    },
    {
        "paper_id": "cond-mat/0311646",
        "authors": "James P. Gleeson",
        "title": "Motion in random fields - an application to stock market data",
        "comments": "28 pages, 10 figures",
        "journal-ref": null,
        "doi": "10.1117/12.556444",
        "license": null,
        "abstract": "  A new model for stock price fluctuations is proposed, based upon an analogy\nwith the motion of tracers in Gaussian random fields, as used in turbulent\ndispersion models and in studies of transport in dynamically disordered media.\nAnalytical and numerical results for this model in a special limiting case of a\nsingle-scale field show characteristics similar to those found in empirical\nstudies of stock market data. Specifically, short-term returns have a\nnon-Gaussian distribution, with super-diffusive volatility, and a fast-decaying\ncorrelation function. The correlation function of the absolute value of returns\ndecays as a power-law, and the returns distribution converges towards Gaussian\nover long times. Some important characteristics of empirical data are not,\nhowever, reproduced by the model, notably the scaling of tails of the\ncumulative distribution function of returns.\n"
    },
    {
        "paper_id": "cond-mat/0312121",
        "authors": "Josep Perello, Jaume Masoliver, and Napoleon Anento",
        "title": "A comparison between several correlated stochastic volatility models",
        "comments": "4 pages, 2 figures, APFA 4 conferences contribution (13-15 november,\n  2003, Warsaw)",
        "journal-ref": "Physica A 344 (2004) 134-137",
        "doi": "10.1016/j.physa.2004.06.103",
        "license": null,
        "abstract": "  We compare the most common SV models such as the Ornstein-Uhlenbeck (OU), the\nHeston and the exponential OU (expOU) models. We try to decide which is the\nmost appropriate one by studying their volatility autocorrelation and leverage\neffect, and thus outline the limitations of each model. We add empirical\nresearch on market indices confirming the universality of the leverage and\nvolatility correlations.\n"
    },
    {
        "paper_id": "cond-mat/0312149",
        "authors": "W.-X. Zhou (UCLA), D. Sornette (UCLA and CNRS-Univ. Nice)",
        "title": "Antibubble and Prediction of China's stock market and Real-Estate",
        "comments": "29 Elsevier Latex pages including 12 eps figures",
        "journal-ref": "Physica A 337 (2004) 243-268",
        "doi": "10.1016/j.physa.2004.01.051",
        "license": null,
        "abstract": "  We document a well-developed log-periodic power-law antibubble in China's\nstock market, which started in August 2001. We argue that the current stock\nmarket antibubble is sustained by a contemporary active unsustainable\nreal-estate bubble in China. The characteristic parameters of the antibubble\nhave exhibited remarkable stability over one year (Oct. 2002-Oct. 2003). Many\ntests, including predictability over different horizons and time periods,\nconfirm the high significance of the antibubble detection. We predict that the\nChinese stock market will stop its negative trend around the end of 2003 and\nstart going up, appreciating by at least 25% in the following 6 months.\nNotwithstanding the immature nature of the Chinese equity market and the strong\ninfluence of government policy, we have found maybe even stronger imprints of\nherding than in other mature markets. This is maybe due indeed to the\nimmaturity of the Chinese market which seems to attract short-term investors\nmore interested in fast gains than in long-term investments, thus promoting\nspeculative herding.\n"
    },
    {
        "paper_id": "cond-mat/0312167",
        "authors": "Marco Patriarca, Anirban Chakraborti and Kimmo Kaski",
        "title": "Gibbs versus non-Gibbs distributions in money dynamics",
        "comments": "6 pages including 3 figures. Elsevier style. Submitted for Conference\n  Proceedings of the International Conference \"News and Expectations in\n  Thermostatistics\", 2003 in Cagliari (Italy)",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.04.024",
        "license": null,
        "abstract": "  We review a simple model of closed economy, where the economic agents make\nmoney transactions and a saving criterion is present. We observe the Gibbs\ndistribution for zero saving propensity, and non-Gibbs distributions otherwise.\nWhile the exact solution in the case of zero saving propensity is already known\nto be given by the Gibbs distribution, here we provide the explicit analytical\nform of the equilibrium distribution for the general case of nonzero saving\npropensity. We verify it through comparison with numerical data and show that\nit can be cast in the form of a Poisson distribution.\n"
    },
    {
        "paper_id": "cond-mat/0312357",
        "authors": "Toshiya Ohtsuki, Akihiro Fujihara and Hiroshi Yamamoto",
        "title": "Effects of Randomness on Power Law Tails in Multiplicatively Interacting\n  Stochastic Processes",
        "comments": "7pages",
        "journal-ref": null,
        "doi": "10.1016/j.physleta.2004.03.013",
        "license": null,
        "abstract": "  Effects of randomness on non-integer power law tails in multiplicatively\ninteracting stochastic processes are investigated theoretically. Generally,\nrandomness causes decrease of the exponent of tails and the growth rate of\nprocesses. Explicit calculations are performed for two examples: uniformly\ndistributed and two peaked systems. Significant influence is demonstrated when\na bare growth rate is low and coupling is weak. It should be emphasized that\neven the sign of the growth rate can be changed from positive to negative\ngrowth.\n"
    },
    {
        "paper_id": "cond-mat/0312404",
        "authors": "Taisei Kaizoji and Michiyo Kaizoji",
        "title": "A mechanism leading bubbles to crashes: the case of Japan's land markets",
        "comments": "4 pages, 1 figure",
        "journal-ref": "Physica A344 (2004) pp.138-141",
        "doi": "10.1016/j.physa.2004.06.104",
        "license": null,
        "abstract": "  In this paper we investigate quantitatively statistical properties of\nensemble of {\\it land prices} in Japan in the period from 1981 to 2002,\ncorresponding to the period of bubbles and crashes. We find that the tail of\nthe distributions of ensembles of the land prices in the high price range is\nwell described by a power law distribution, $ P(S>x) \\sim x^{-\\alpha} $, and\nfurthermore that as the power-law exponents $ \\alpha $ approached to unity, the\ncrashes of bubbles occurred.\n"
    },
    {
        "paper_id": "cond-mat/0312406",
        "authors": "Taisei Kaizoji and Michiyo Kaizoji",
        "title": "Power law for ensembles of stock prices",
        "comments": "4 pages, 1 figure",
        "journal-ref": "Physica A344 (2004) pp. 240-243",
        "doi": "10.1016/j.physa.2004.06.125",
        "license": null,
        "abstract": "  In this paper we quantitatively investigate the statistical properties of an\nensemble of {\\it stock prices}. We selected 1200 stocks traded in the Tokyo\nStock Exchange and formed a statistical ensemble of daily stock prices for each\ntrading day in the 5 year period from January 4, 1988 to December 30, 1992. We\nfound that the tail of the complementary cumulative distribution function of\nthe ensembles is accurately described by a power-law distribution with an\nexponent that moves in the range of $ 1.7 < \\alpha < 2.2 $.\n"
    },
    {
        "paper_id": "cond-mat/0312413",
        "authors": "H. F. Coronel-Brizio and A. R. Hernandez-Montoya (Facultad de Fisica e\n  Inteligencia Artificial.Universidad Veracruzana. Xalapa Veracruz. Mexico.)",
        "title": "Asymptotic behavior of the Daily Increment Distribution of the IPC, the\n  Mexican Stock Market Index",
        "comments": "Econophysics paper. 5 pages 4 figures. Rev.Mex.Fis (in press).\n  Updated version: Corrected typos, added references and footnotes",
        "journal-ref": "Revista Mexicana de Fisica 51 (1) 27-31 (2005)",
        "doi": null,
        "license": null,
        "abstract": "  In this work, a statistical analysis of the distribution of daily\nfluctuations of the IPC, the Mexican Stock Market Index is presented. A sample\nof the IPC covering the 13-year period 04/19/1990 - 08/21/2003 was analyzed and\nthe cumulative probability distribution of its daily logarithmic variations\nstudied. Results showed that the cumulative distribution function for extreme\nvariations, can be described by a Pareto-Levy model with shape parameters\nalpha=3.634 +- 0.272 and alpha=3.540 +- 0.278 for its positive and negative\ntails respectively. This result is consistent with previous studies, where it\nhas been found that 2.5< alpha <4 for other financial markets worldwide.\n"
    },
    {
        "paper_id": "cond-mat/0312489",
        "authors": "Luigi Palatella, Josep Perello, Miquel Montero and Jaume Masoliver",
        "title": "Activity autocorrelation in financial markets. A comparative study\n  between several models",
        "comments": "15 pages, 4 figures",
        "journal-ref": "European Physical Journal B 38 (2004) 671-677",
        "doi": "10.1140/epjb/e2004-00161-6",
        "license": null,
        "abstract": "  We study the activity, i.e., the number of transactions per unit time, of\nfinancial markets. Using the diffusion entropy technique we show that the\nautocorrelation of the activity is caused by the presence of peaks whose time\ndistances are distributed following an asymptotic power law which ultimately\nrecovers the Poissonian behavior. We discuss these results in comparison with\nARCH models, stochastic volatility models and multi-agent models showing that\nARCH and stochastic volatility models better describe the observed experimental\nevidences.\n"
    },
    {
        "paper_id": "cond-mat/0312496",
        "authors": "Zdzislaw Burda, Jerzy Jurkiewicz",
        "title": "Signal and Noise in Financial Correlation Matrices",
        "comments": "6 pages + 2 figures, corrected references, Talk at Conference:\n  Applications of Physics in Financial Analysis 4, Warsaw, 13-15 November 2003",
        "journal-ref": "Physica A 344, 67 (2004)",
        "doi": "10.1016/j.physa.2004.06.089",
        "license": null,
        "abstract": "  Using Random Matrix Theory one can derive exact relations between the\neigenvalue spectrum of the covariance matrix and the eigenvalue spectrum of its\nestimator (experimentally measured correlation matrix). These relations will be\nused to analyze a particular case of the correlations in financial series and\nto show that contrary to earlier claims, correlations can be measured also in\nthe ``random'' part of the spectrum. Implications for the portfolio\noptimization are briefly discussed.\n"
    },
    {
        "paper_id": "cond-mat/0312547",
        "authors": "Takayuki Mizuno, Tohur Nakano, Misako Takayasu, Hideki Takayasu",
        "title": "Traders' strategy with price feedbacks in financial market",
        "comments": "4 pages, 5 figures, submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.06.145",
        "license": null,
        "abstract": "  We introduce an autoregressive-type model of prices in financial market\ntaking into account the self-modulation effect. We find that traders are mainly\nusing strategies with weighted feedbacks of past prices. These feedbacks are\nresponsible for the slow diffusion in short times, apparent trends and power\nlaw distribution of price changes.\n"
    },
    {
        "paper_id": "cond-mat/0312560",
        "authors": "Taisei Kaizoji and Michiyo Kaizoji",
        "title": "Power law for the calm-time interval of price changes",
        "comments": "14 pages, 7 figures",
        "journal-ref": "Physica A 336 (2004) 563-570",
        "doi": "10.1016/j.physa.2003.12.054",
        "license": null,
        "abstract": "  In this paper, we describe a newly discovered statistical property of time\nseries data for daily price changes. We conducted quantitative investigation of\nthe {\\it calm-time intervals} of price changes for 800 companies listed in the\nTokyo Stock Exchange, and for the Nikkei 225 index over a 27-year period from\nJanuary 4, 1975 to December 28, 2001. A calm-time interval is defined as the\ninterval between two successive price changes above a fixed threshold. We found\nthat the calm-time interval distribution of price changes obeys a power law\ndecay. Furthermore, we show that the power-law exponent decreases monotonically\nwith respect to the threshold.\n  Keyword: econophysics, stock price changes, calm time interval, power-laws;\nPACS: 89.90.+n; 05.40.Df;\n"
    },
    {
        "paper_id": "cond-mat/0312568",
        "authors": "Yoshikazu Ohtaki, Hiroshi H. Hasegawa",
        "title": "Superstatistics in Econophysics",
        "comments": "10 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider an ideal closed stock market, in which 100 traders have economic\nactivities. The assets of the traders change through buying and selling stocks.\nWe simulate the assets under conservation of both total currency and total\nnumber of stocks. If the traders are identical, then the assets are distributed\nas a stationary Gaussian. When variety among the traders makes winners and\nlosers, the asset distribution displays power law scaling such as the Pareto\nlaw. We discuss this power law scaling from the point of view of\nsuperstatistics. It is given as a superposition of scaled distributions for\neach hierarchical level. The various traders have the same growth rate\ndistribution to keep the scaling.\n"
    },
    {
        "paper_id": "cond-mat/0312643",
        "authors": "Akihiko Utsugi, Kazusumi Ino, Masaki Oshikawa",
        "title": "Random Matrix Theory Analysis of Cross Correlations in Financial Markets",
        "comments": "RevTex, 17 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.70.026110",
        "license": null,
        "abstract": "  We confirm universal behaviors such as eigenvalue distribution and spacings\npredicted by Random Matrix Theory (RMT) for the cross correlation matrix of the\ndaily stock prices of Tokyo Stock Exchange from 1993 to 2001, which have been\nreported for New York Stock Exchange in previous studies. It is shown that the\nrandom part of the eigenvalue distribution of the cross correlation matrix is\nstable even when deterministic correlations are present. Some deviations in the\nsmall eigenvalue statistics outside the bounds of the universality class of RMT\nare not completely explained with the deterministic correlations as proposed in\nprevious studies. We study the effect of randomness on deterministic\ncorrelations and find that randomness causes a repulsion between deterministic\neigenvalues and the random eigenvalues. This is interpreted as a reminiscent of\n``level repulsion'' in RMT and explains some deviations from the previous\nstudies observed in the market data. We also study correlated groups of issues\nin these markets and propose a refined method to identify correlated groups\nbased on RMT. Some characteristic differences between properties of Tokyo Stock\nExchange and New York Stock Exchange are found.\n"
    },
    {
        "paper_id": "cond-mat/0312658",
        "authors": "W.-X. Zhou (UCLA), D. Sornette (UCLA and CNRS-Univ. Nice)",
        "title": "Causal Slaving of the U.S. Treasury Bond Yield Antibubble by the Stock\n  Market Antibubble of August 2000",
        "comments": "26 Elsevier Latex pages including 11 eps figures (color online)",
        "journal-ref": "Physica A 337, 586-608 (2004).",
        "doi": "10.1016/j.physa.2004.02.009",
        "license": null,
        "abstract": "  Using the descriptive method of log-periodic power laws (LPPL) based on a\ntheory of behavioral herding, we use a battery of parametric and non-parametric\ntests to demonstrate the existence of an antibubble in the yields with\nmaturities larger than 1 year since October 2000. The concept of ``antibubble''\ndescribes the existence of a specific LPPL pattern that is thought to reflect\ncollective herding effects. From the dependence of the parameters of the LPPL\nformula as a function of yield maturities and using lagged cross-correlation\ncalculations between the S&P 500 and bond yields, we find strong evidence for\nthe following causality: Stock Market $\\to$ Fed Reserve (Federal funds rate)\n$\\to$ short-term yields $\\to$ long-term yields (as well as a direct and\ninstantaneous influence of the stock market on the long-term yields). Our\ninterpretation is that the FRB is ``causally slaved'' to the stock market (at\nleast for the studied period), because the later is (taken as) a proxy for the\npresent and future health of the economy.\n"
    },
    {
        "paper_id": "cond-mat/0312703",
        "authors": "J. Doyne Farmer, Laszlo Gillemot, Fabrizio Lillo, Szabolcs Mike,\n  Anindya Sen",
        "title": "What really causes large price changes?",
        "comments": "14 pages, 12 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the cause of large fluctuations in prices in the London Stock\nExchange. This is done at the microscopic level of individual events, where an\nevent is the placement or cancellation of an order to buy or sell. We show that\nprice fluctuations caused by individual market orders are essentially\nindependent of the volume of orders. Instead, large price fluctuations are\ndriven by liquidity fluctuations, variations in the market's ability to absorb\nnew orders. Even for the most liquid stocks there can be substantial gaps in\nthe order book, corresponding to a block of adjacent price levels containing no\nquotes. When such a gap exists next to the best price, a new order can remove\nthe best quote, triggering a large midpoint price change. Thus, the\ndistribution of large price changes merely reflects the distribution of gaps in\nthe limit order book. This is a finite size effect, caused by the granularity\nof order flow: In a market where participants placed many small orders\nuniformly across prices, such large price fluctuations would not happen. We\nshow that this explains price fluctuations on longer timescales. In addition,\nwe present results suggesting that the risk profile varies from stock to stock,\nand is not universal: lightly traded stocks tend to have more extreme risks.\n"
    },
    {
        "paper_id": "cond-mat/0401009",
        "authors": "M. I. Krivoruchenko, E. Alessio, V. Frappietro and L. J. Streckert",
        "title": "Modeling stylized facts for financial time series",
        "comments": "Contribution to Proceedings of the Conference \"Applications of\n  Physics in Financial Analysis 4\", Warsaw, 13-15 November, 2003. Four pages\n  Elsevier LaTeX. Transparencies of the talk given by M.I.K. are attached,\n  PostScript 32 pages. PDF file of the published contribution to the APFA4\n  Proceedings with removed misprints, introduced by a typesetter of physica A,\n  is attached",
        "journal-ref": "Physica A 344, 263-266 (2004)",
        "doi": "10.1016/j.physa.2004.06.129",
        "license": null,
        "abstract": "  Multivariate probability density functions of returns are constructed in\norder to model the empirical behavior of returns in a financial time series.\nThey describe the well-established deviations from the Gaussian random walk,\nsuch as an approximate scaling and heavy tails of the return distributions,\nlong-ranged volatility-volatility correlations (volatility clustering) and\nreturn-volatility correlations (leverage effect). The model is tested\nsuccessfully to fit joint distributions of the 100+ years of daily price\nreturns of the Dow Jones 30 Industrial Average.\n"
    },
    {
        "paper_id": "cond-mat/0401053",
        "authors": "Ian Wright",
        "title": "The Social Architecture of Capitalism",
        "comments": "36 pages, 12 figures",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, 346, pp.\n  589-622, 2005",
        "doi": "10.1016/j.physa.2004.08.006",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A dynamic model of the social relations between workers and capitalists is\nintroduced. The model is deduced from the assumption that the law of value is\nan organising principle of modern economies. The model self-organises into a\ndynamic equilibrium with statistical properties that are in close qualitative\nand in many cases quantitative agreement with a broad range of known empirical\ndistributions of developed capitalism, including the power-law distribution of\nfirm size, the Laplace distribution of firm and GDP growth, the lognormal\ndistribution of firm demises, the exponential distribution of the duration of\nrecessions, the lognormal-Pareto distribution of income, and the gamma-like\ndistribution of the rate-of-profit of firms. Normally these distributions are\nstudied in isolation, but this model unifies and connects them within a single\ncausal framework. In addition, the model generates business cycle phenomena,\nincluding fluctuating wage and profit shares in national income about values\nconsistent with empirical studies. A testable consequence of the model is a\nconjecture that the rate-of-profit distribution is consistent with a\nparameter-mix of a ratio of normal variates with means and variances that\ndepend on a firm size parameter that is distributed according to a power-law.\n"
    },
    {
        "paper_id": "cond-mat/0401055",
        "authors": "A. G. Zawadowski, J. Kertesz, and G. Andor",
        "title": "Large price changes on small scales",
        "comments": "6 pages, 2 figures, APFA4 conference proceedings, to be published in\n  Physica A, references updated",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.06.121",
        "license": null,
        "abstract": "  In this study we examine the evolution of price, volume, and the bid-ask\nspread after extreme 15 minute intraday price changes on the NYSE and the\nNASDAQ. We find that due to strong behavioral trading there is an overreaction.\nFurthermore we find that volatility which increases sharply at the event decays\naccording to a power law with an exponent of approximately 0.4, i.e., much\nfaster than the autocorrelation function of volatility.\n"
    },
    {
        "paper_id": "cond-mat/0401140",
        "authors": "Taisei Kaizoji",
        "title": "Inflation and deflation in stock markets",
        "comments": "8 pages, 3 igures",
        "journal-ref": "Physica A343 (2004) 662-668",
        "doi": "10.1016/j.physa.2004.06.137",
        "license": null,
        "abstract": "  The aim of this paper is to compare statistical properties of a bubble period\nwith those of the anti-bubble period in stock markets. We investigate the\nstatistical properties of daily data for the Nikkei 225 index in the 28-year\nperiod from January 1975 to April 2003, corresponded to the periods of bubbles\nand anti-bubbles. We divide the time series into two parts, the period of {\\it\ninflation (or bubbles)} from January 1975 to December 2002 and the period of\n{\\it deflation (or anti-bubbles)} from January 1990 to December 2002. We find\nthat the volatility in the inflationary period is approximated by the\n$q$-exponential distribution with $ q = 1.14 $ while the volatility\ndistribution in the deflationary period is accurately described by an {\\it\nexponential} distribution, that is, the $q$-exponential distribution with $ q\n\\to 1 $. Our empirical findings suggest that the momentous structural changes\nhave occurred at the beginning of 1990 when the speculative bubble was\ncollapsed in the Japan's stock markets.\n  Keywords: econophysics, inflationary period, deflationary period, power law,\nexponential (Bolztmann-Gibbs) law; PACS 89.90.+n; 05.40.-a;\n"
    },
    {
        "paper_id": "cond-mat/0401181",
        "authors": "Silvio M. Duarte Queiros and Constantino Tsallis",
        "title": "Bridging the ARCH model for finance and nonextensive entropy",
        "comments": "4 pages, 5 figures.Figure 4 fixed",
        "journal-ref": "Europhys. Lett. 69, 893-899 (2005)",
        "doi": "10.1209/epl/i2004-10436-6",
        "license": null,
        "abstract": "  Engle's ARCH algorithm is a generator of stochastic time series for financial\nreturns (and similar quantities) characterized by a time-dependent variance. It\ninvolves a memory parameter $b$ ($b=0$ corresponds to {\\it no memory}), and the\nnoise is currently chosen to be Gaussian. We assume here a generalized noise,\nnamely $q_n$-Gaussian, characterized by an index $q_{n} \\in {\\cal R}$\n($q_{n}=1$ recovers the Gaussian case, and $q_n>1$ corresponds to tailed\ndistributions). We then match the second and fourth momenta of the ARCH return\ndistribution with those associated with the $q$-Gaussian distribution obtained\nthrough optimization of the entropy $S_{q}=\\frac{% 1-\\sum_{i} {p_i}^q}{q-1}$,\nbasis of nonextensive statistical mechanics. The outcome is an {\\it analytic}\ndistribution for the returns, where an unique $q\\ge q_n$ corresponds to each\npair $(b,q_n)$ ($q=q_n$ if $ b=0$). This distribution is compared with\nnumerical results and appears to be remarkably precise. This system constitutes\na simple, low-dimensional, dynamical mechanism which accommodates well within\nthe current nonextensive framework.\n"
    },
    {
        "paper_id": "cond-mat/0401210",
        "authors": "Anders Johansen",
        "title": "Origin of Crashes in 3 US stock markets: Shocks and Bubbles",
        "comments": "7 pages including 3 tables and 3 figures. Subm. for Proceeding of\n  Frontier Science 2003",
        "journal-ref": "Physica A vol 338, pp. 135-142 (2004)",
        "doi": "10.1016/j.physa.2004.02.035",
        "license": null,
        "abstract": "  This paper presents an exclusive classification of the largest crashes in Dow\nJones Industrial Average (DJIA), SP500 and NASDAQ in the past century. Crashes\nare objectively defined as the top-rank filtered drawdowns (loss from the last\nlocal maximum to the next local minimum disregarding noise fluctuations), where\nthe size of the filter is determined by the historical volatility of the index.\nIt is shown that {\\it all} crashes can be linked to either an external shock,\n{\\it e.g.}, outbreak of war, {\\it or} a log-periodic power law (LPPL) bubble\nwith an empirically well-defined complex value of the exponent. Conversely,\nwith one sole exception {\\it all} previously identified LPPL bubbles are\nfollowed by a top-rank drawdown. As a consequence, the analysis presented\nsuggest a one-to-one correspondence between market crashes defined as top-rank\nfiltered drawdowns on one hand and surprising news and LPPL bubbles on the\nother. We attribute this correspondence to the Efficient Market Hypothesis\neffective on two quite different time scales depending on whether the market\ninstability the crash represent is internally or externally generated.\n"
    },
    {
        "paper_id": "cond-mat/0401225",
        "authors": "A. Christian Silva, Richard E. Prange, Victor M. Yakovenko",
        "title": "Exponential distribution of financial returns at mesoscopic time lags: a\n  new stylized fact",
        "comments": "7 pages, 12 plots, elsart.cls, submitted to the Proceedings of\n  APFA-4. V.2: updated references",
        "journal-ref": "Physica A 344, 227-235 (2004)",
        "doi": "10.1016/j.physa.2004.06.122",
        "license": null,
        "abstract": "  We study the probability distribution of stock returns at mesoscopic time\nlags (return horizons) ranging from about an hour to about a month. While at\nshorter microscopic time lags the distribution has power-law tails, for\nmesoscopic times the bulk of the distribution (more than 99% of the\nprobability) follows an exponential law. The slope of the exponential function\nis determined by the variance of returns, which increases proportionally to the\ntime lag. At longer times, the exponential law continuously evolves into\nGaussian distribution. The exponential-to-Gaussian crossover is well described\nby the analytical solution of the Heston model with stochastic volatility.\n"
    },
    {
        "paper_id": "cond-mat/0401300",
        "authors": "G. Bonanno, G. Caldarelli, F. Lillo, S. Micciche`, N. Vandewalle, R.\n  N. Mantegna",
        "title": "Networks of equities in financial markets",
        "comments": "9 pages, 8 figures. Accepted for publication in EPJ B",
        "journal-ref": "Eur Phys J B, 38, 363-371, (2004)",
        "doi": "10.1140/epjb/e2004-00129-6",
        "license": null,
        "abstract": "  We review the recent approach of correlation based networks of financial\nequities. We investigate portfolio of stocks at different time horizons,\nfinancial indices and volatility time series and we show that meaningful\neconomic information can be extracted from noise dressed correlation matrices.\nWe show that the method can be used to falsify widespread market models by\ndirectly comparing the topological properties of networks of real and\nartificial markets.\n"
    },
    {
        "paper_id": "cond-mat/0401308",
        "authors": "Amir H. Darooneh",
        "title": "Premium Calculation Based on Physical Principles",
        "comments": "9 pages, 3 figures, revtex4",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider the concept of equilibrium in economic systems from statistical\nmechanics viewpoint. A new method is suggested for computing the premium on\nthis basis. The B\\\"{u}hlmann economic premium principle is derived as a special\ncase of our method.\n"
    },
    {
        "paper_id": "cond-mat/0401329",
        "authors": "Bernd Rosenow, Rafael Weissbach, and Frank Altrock",
        "title": "Modelling Correlations in Portfolio Credit Risk",
        "comments": "5 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The risk of a credit portfolio depends crucially on correlations between the\nprobability of default (PD) in different economic sectors. Often, PD\ncorrelations have to be estimated from relatively short time series of default\nrates, and the resulting estimation error hinders the detection of a signal. We\npresent statistical evidence that PD correlations are well described by a\n(one-)factorial model. We suggest a method of parameter estimation which avoids\nin a controlled way the underestimation of correlation risk. Empirical evidence\nis presented that, in the framework of the CreditRisk+ model with integrated\ncorrelations, this method leads to an increased reliability of the economic\ncapital estimate.\n"
    },
    {
        "paper_id": "cond-mat/0401360",
        "authors": "M. I. Krivoruchenko",
        "title": "Best linear forecast of volatility in financial time series",
        "comments": "8 pages, REVTeX, one Postscript figure. Maple source code for\n  calculation of the predictor function is attached in a separate .txt file",
        "journal-ref": "Phys.Rev. E70 (2004) 036102",
        "doi": "10.1103/PhysRevE.70.036102",
        "license": null,
        "abstract": "  The autocorrelation function of volatility in financial time series is fitted\nwell by a superposition of several exponents. Such a case admits an explicit\nanalytical solution of the problem of constructing the best linear forecast of\na stationary stochastic process. We describe and apply the proposed analytical\nmethod for forecasting volatility. The leverage effect and volatility\nclustering are taken into account. Parameters of the predictor function are\ndetermined numerically for the Dow Jones 30 Industrial Average. Connection of\nthe proposed method to the popular ARCH models is discussed.\n"
    },
    {
        "paper_id": "cond-mat/0401378",
        "authors": "Jordi Molins, Eduard Vives",
        "title": "Long range Ising model for credit risk modeling in homogeneous\n  portfolios",
        "comments": "4 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Within the framework of maximum entropy principle we show that the\nfinite-size long-range Ising model is the adequate model for the description of\nhomogeneous credit portfolios and the computation of credit risk when default\ncorrelations between the borrowers are included. The exact analysis of the\nmodel suggest that when the correlation increases a first-order-like transition\nmay occur inducing a sudden risk increase. Such a feature is not reproduced by\nthe standard models used in credit risk modeling.\n"
    },
    {
        "paper_id": "cond-mat/0401422",
        "authors": "Anton Bovier, Jiri Cerny, Ostap Hryniv",
        "title": "The Opinion Game: Stock price evolution from microscopic market\n  modelling",
        "comments": "14 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a class of Markovian agent based models for the time evolution of\na share price in an interactive market. The models rely on a microscopic\ndescription of a market of buyers and sellers who change their opinion about\nthe stock value in a stochastic way. The actual price is determined in\nrealistic way by matching (clearing) offers until no further transactions can\nbe performed. Some analytic results for a non-interacting model are presented.\nWe also propose basic interaction mechanisms and show in simulations that these\nalready reproduce certain particular features of prices in real stock markets.\n"
    },
    {
        "paper_id": "cond-mat/0401443",
        "authors": "T. Di Matteo, T. Aste and R. N. Mantegna",
        "title": "An interest rates cluster analysis",
        "comments": "7 pages, 7 figures",
        "journal-ref": "Physica A 339 (2004) 181-188",
        "doi": "10.1016/j.physa.2004.03.041",
        "license": null,
        "abstract": "  An empirical analysis of interest rates in money and capital markets is\nperformed. We investigate a set of 34 different weekly interest rate time\nseries during a time period of 16 years between 1982 and 1997. Our study is\nfocused on the collective behavior of the stochastic fluctuations of these\ntime-series which is investigated by using a clustering linkage procedure.\nWithout any a priori assumption, we individuate a meaningful separation in 6\nmain clusters organized in a hierarchical structure.\n"
    },
    {
        "paper_id": "cond-mat/0401445",
        "authors": "T. Di Matteo, M. Airoldi, E. Scalas",
        "title": "On pricing of interest rate derivatives",
        "comments": "9 pages, 13 figures",
        "journal-ref": "Physica A 339 (2004) 189-196",
        "doi": "10.1016/j.physa.2004.03.042",
        "license": null,
        "abstract": "  At present, there is an explosion of practical interest in the pricing of\ninterest rate (IR) derivatives. Textbook pricing methods do not take into\naccount the leptokurticity of the underlying IR process. In this paper, such a\nleptokurtic behaviour is illustrated using LIBOR data, and a possible\nmartingale pricing scheme is discussed.\n"
    },
    {
        "paper_id": "cond-mat/0401495",
        "authors": "Corrado Di Guilmi, Edoardo Gaffeo, Mauro Gallegati and Antonio\n  Palestrini",
        "title": "International evidence on business cycle magnitude dependence",
        "comments": "14 pages, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Are expansions and recessions more likely to end as their magnitude\nincreases? In this paper we apply parametric hazard models to investigate this\nissue in a sample of 16 countries from 1881 to 2000. For the total sample we\nfind evidence of positive magnitude dependence for recessions, while for\nexpansions we are not able to reject the null of magnitude independence. This\nlast result is likely due to a structural change in the mechanism guiding\nexpansions before and after the second World War. In particular, upturns show\nnegative magnitude dependence in the post-World War II sub-sample, meaning that\nin this period expansions become less likely to end as their magnitude\nincreases.\n"
    },
    {
        "paper_id": "cond-mat/0401503",
        "authors": "Marco Airoldi",
        "title": "A perturbative moment approach to option pricing",
        "comments": "28 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper we present a new methodology for option pricing. The main idea\nconsists to represent a generic probability distribution function (PDF) via a\nperturbative expansion around a given, simpler, PDF (typically a gaussian\nfunction) by matching moments of increasing order. Because, as shown in\nliterature, the pricing of path dependent European options can be often reduced\nto recursive (or nested) one-dimensional integral calculations, the above\nperturbative moment expansion (PME) leads very quickly to excellent numerical\nsolutions. In this paper, we present the basic ideas of the method and the\nrelative applications to a variety of contracts, mainly: asian, reverse cliquet\nand barrier options. A comparison with other numerical techniques is also\npresented.\n"
    },
    {
        "paper_id": "cond-mat/0402049",
        "authors": "A. De Martino, M. Marsili, I. Perez Castillo (SMC-Roma 1, ICTP Trieste\n  and KU Leuven)",
        "title": "Statistical mechanics analysis of the equilibria of linear economies",
        "comments": "16 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The optimal (`equilibrium') macroscopic properties of an economy with $N$\nindustries endowed with different technologies, $P$ commodities and one\nconsumer are derived in the limit $N\\to\\infty$ with $n=N/P$ fixed using the\nreplica method. When technologies are strictly inefficient, a phase transition\noccurs upon increasing $n$. For low $n$, the system is in an expanding phase\ncharacterized by the existence of many profitable opportunities for new\ntechnologies. For high $n$, technologies roughly saturate the possible\nproductions and the economy becomes strongly selective with respect to\ninnovations. The phase transition and other significant features of the model\nare discussed in detail. When the inefficiency assumption is relaxed, the\neconomy becomes unstable at high $n$.\n"
    },
    {
        "paper_id": "cond-mat/0402075",
        "authors": "Marcel Ausloos, Paulette Clippe, Janusz Mi\\'skiewicz, Andrzej Pekalski",
        "title": "A (reactive) lattice-gas approach to economic cycles",
        "comments": "The paper has been presented on APFA4 conference and submitted to\n  Physics A",
        "journal-ref": "Physica A 344 (2004) 1-7",
        "doi": "10.1016/j.physa.2004.06.078",
        "license": null,
        "abstract": "  A microscopic approach to macroeconomic features is intended. A model for\nmacroeconomic behavior under heterogeneous spatial economic conditions is\nreviewed. A birth-death lattice gas model taking into account the influence of\nan economic environment on the fitness and concentration evolution of economic\nentities is numerically and analytically examined. The reaction-diffusion model\ncan be also mapped onto a high order logistic map. The role of the selection\npressure along various dynamics with entity diffusion on a square symmetry\nlattice has been studied by Monte-Carlo simulation. The model leads to a sort\nof phase transition for the fitness gap as a function of the selection pressure\nand to cycles. The control parameter is a (scalar) ''business plan''. The\nbusiness plan(s) allows for spin-offs or merging and enterprise survival\nevolution law(s), whence bifurcations, cycles and chaotic behavior.\n"
    },
    {
        "paper_id": "cond-mat/0402185",
        "authors": "Renato Vicente, Charles M. de Toledo, Vitor B. P. Leite and Nestor\n  Caticha",
        "title": "Common Underlying Dynamics in an Emerging Market: From Minutes to Months",
        "comments": "11 pages, 8 figures, subimitted",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We analyse a period spanning 35 years of activity in the Sao Paulo Stock\nExchange Index (IBOVESPA) and show that the Heston model with stochastic\nvolatility is capable of explaining price fluctuations for time scales ranging\nfrom 5 minutes to 100 days with a single set of parameters. We also show that\nthe Heston model is inconsistent with the observed behavior of the volatility\nautocorrelation function. We deal with the latter inconsistency by introducing\na slow time scale to the model. The fact that the price dynamics in a period of\n35 years of macroeconomical unrest may be modeled by the same stochastic\nprocess is evidence for a general underlying microscopic market dynamics.\n"
    },
    {
        "paper_id": "cond-mat/0402239",
        "authors": "Amir H. Darooneh",
        "title": "Non-Life Insurance Pricing: Multi Agents Model",
        "comments": "6 pages, revtex4",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2004-00363-x",
        "license": null,
        "abstract": "  We use the maximum entropy principle for pricing the non-life insurance and\nrecover the B\\\"{u}hlmann results for the economic premium principle. The\nconcept of economic equilibrium is revised in this respect.\n"
    },
    {
        "paper_id": "cond-mat/0402240",
        "authors": "Amir H. Darooneh",
        "title": "Utility Function from Maximum Entropy Principle",
        "comments": "6 pages, revtex4",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We apply the maximum entropy principle to economic systems in equilibrium and\nfind the density function for the market's wealth. This is the same as price\ndensity which is used for insurance pricing. The risk aversion parameter of the\nagent then it's utility function with respect to this density is derived.\n"
    },
    {
        "paper_id": "cond-mat/0402389",
        "authors": "Diane Wilcox, Tim Gebbie",
        "title": "An analysis of Cross-correlations in South African Market data",
        "comments": "19 pages, 15 figures, additional figures, discussion and references",
        "journal-ref": "Physica A 375 (2007) 584-598",
        "doi": "10.1016/j.physa.2006.10.030",
        "license": null,
        "abstract": "  We apply random matrix theory to compare correlation matrix estimators C\nobtained from emerging market data. The correlation matrices are constructed\nfrom 10 years of daily data for stocks listed on the Johannesburg Stock\nExchange (JSE) from January 1993 to December 2002. We test the spectral\nproperties of C against random matrix predictions and find some agreement\nbetween the distributions of eigenvalues, nearest neighbour spacings,\ndistributions of eigenvector components and the inverse participation ratios\nfor eigenvectors. We show that interpolating both missing data and illiquid\ntrading days with a zero-order hold increases agreement with RMT predictions.\nFor the more realistic estimation of correlations in an emerging market, we\nsuggest a pairwise measured-data correlation matrix. For the data set used,\nthis approach suggests greater temporal stability for the leading eigenvectors.\nAn interpretation of eigenvectors in terms of trading strategies is given in\nlieu of classification by economic sectors.\n"
    },
    {
        "paper_id": "cond-mat/0402390",
        "authors": "Dirk Tasche",
        "title": "The single risk factor approach to capital charges in case of correlated\n  loss given default rates",
        "comments": "9 pages, LaTeX",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A new methodology for incorporating LGD correlation effects into the Basel II\nrisk weight functions is introduced. This methodology is based on modelling of\nLGD and default event with a single loss variable. The resulting formulas for\ncapital charges are numerically compared to the current proposals by the Basel\nCommittee on Banking Supervision.\n  Keywords: Regulatory capital charge, loss given default (LGD).\n"
    },
    {
        "paper_id": "cond-mat/0402466",
        "authors": "D. Garlaschelli, M. I. Loffredo",
        "title": "Wealth Dynamics on Complex Networks",
        "comments": "6 pages, 2(x2) figures",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, Volume 338,\n  Issues 1-2, 1 July 2004, Pages 113-118. Proceedings of the conference A\n  Nonlinear World: the Real World, 2nd International Conference on Frontier\n  Science, Pavia (Italy)",
        "doi": "10.1016/j.physa.2004.02.032",
        "license": null,
        "abstract": "  We study a model of wealth dynamics [Bouchaud and M\\'ezard 2000,\n\\emph{Physica A} \\textbf{282}, 536] which mimics transactions among economic\nagents. The outcomes of the model are shown to depend strongly on the\ntopological properties of the underlying transaction network. The extreme cases\nof a fully connected and a fully disconnected network yield power-law and\nlog-normal forms of the wealth distribution respectively. We perform numerical\nsimulations in order to test the model on more complex network topologies. We\nshow that the mixed form of most empirical distributions (displaying a\nnon-smooth transition from a log-normal to a power-law form) can be traced back\nto a heterogeneous topology with varying link density, which on the other hand\nis a recently observed property of real networks.\n"
    },
    {
        "paper_id": "cond-mat/0402511",
        "authors": "Takeshi Inagaki",
        "title": "Critical Ising Model and Financial Market",
        "comments": "5 pages, no figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate Ising model description of dynamics of stock price. The model\nis defined in near 2 dimensions, one dimension is time and another represents\nensemble of stocks, and strength of response of investors to price change\ncorresponds to inverse temperature of the system. At critical temperature,\ninfinitely long correlation among number of trades along time is observed and\npower-law tail in distribution of price fluctuation appears.\n"
    },
    {
        "paper_id": "cond-mat/0402573",
        "authors": "Szilard Pafka, Marc Potters and Imre Kondor",
        "title": "Exponential Weighting and Random-Matrix-Theory-Based Filtering of\n  Financial Covariance Matrices for Portfolio Optimization",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We introduce a covariance matrix estimator that both takes into account the\nheteroskedasticity of financial returns (by using an exponentially weighted\nmoving average) and reduces the effective dimensionality of the estimation (and\nhence measurement noise) via techniques borrowed from random matrix theory. We\ncalculate the spectrum of large exponentially weighted random matrices (whose\nupper band edge needs to be known for the implementation of the estimation)\nanalytically, by a procedure analogous to that used for standard random\nmatrices. Finally, we illustrate, on empirical data, the superiority of the\nnewly introduced estimator in a portfolio optimization context over both the\nmethod of exponentially weighted moving averages and the uniformly-weighted\nrandom-matrix-theory-based filtering.\n"
    },
    {
        "paper_id": "cond-mat/0402591",
        "authors": "M.H.Jensen (Niels Bohr Institute, Denmark) A. Johansen (My house,\n  Humlebaek, Denmark) F. Petroni (Dipartimento di Matematica and I.N.F.M.\n  Universita dell'Aquila,, Italy) I. Simonsen (Department of Physics, NTNU,\n  Trondheim, Norway)",
        "title": "Inverse Statistics in the Foreign Exchange Market",
        "comments": "8 pages. Accepted Physica A",
        "journal-ref": "Physica A 340, 678 (2004)",
        "doi": "10.1016/j.physa.2004.05.024",
        "license": null,
        "abstract": "  We investigate intra-day foreign exchange (FX) time series using the inverse\nstatistic analysis developed in [1,2]. Specifically, we study the time-averaged\ndistributions of waiting times needed to obtain a certain increase (decrease)\n$\\rho$ in the price of an investment. The analysis is performed for the Deutsch\nmark (DM) against the $US for the full year of 1998, but similar results are\nobtained for the Japanese Yen against the $US. With high statistical\nsignificance, the presence of \"resonance peaks\" in the waiting time\ndistributions is established. Such peaks are a consequence of the trading\nhabits of the markets participants as they are not present in the corresponding\ntick (business) waiting time distributions. Furthermore, a new {\\em stylized\nfact}, is observed for the waiting time distribution in the form of a power law\nPdf. This result is achieved by rescaling of the physical waiting time by the\ncorresponding tick time thereby partially removing scale dependent features of\nthe market activity.\n"
    },
    {
        "paper_id": "cond-mat/0402648",
        "authors": "Paul Ormerod",
        "title": "Information cascades and the distribution of economic recessions in the\n  United States",
        "comments": "10 pages 2 figures, submitted to Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.04.109",
        "license": null,
        "abstract": "  The American economy can be thought of as a highly connected random network\nin terms of both its technological and informational connections. The\ncumulative size of economic recessions, the fall in output from peak to trough,\nis analysed for the US economy 1900-2002. A least squares fit of an exponential\nrelationship between size and the rank of size gives a good description of most\nof the data. But the observation for the Great Depression of the 1930s stands\nout as a very distinct outlier. In other words, we observe a bimodal\nrelationship of the type predicted by theory.\n"
    },
    {
        "paper_id": "cond-mat/0402654",
        "authors": "Adriana P. Mattedi, Fernando M. Ramos, Reinaldo R. Rosa, Rosario N.\n  Mantegna",
        "title": "Value-at-Risk and Tsallis statistics: risk analysis of the aerospace\n  sector",
        "comments": "10 pages, 4 figures, 1 table, to appear in Physica A",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this study, we analyze the aerospace stocks prices in order to\ncharacterize the sector behavior. The data analyzed cover the period from\nJanuary 1987 to April 1999. We present a new index for the aerospace sector and\nwe investigate the statistical characteristics of this index. Our results show\nthat this index is well described by Tsallis distribution. We explore this\nresult and modify the standard Value-at-Risk (VaR), financial risk assessment\nmethodology in order to reflect an asset which obeys Tsallis non-extensive\nstatistics.\n"
    },
    {
        "paper_id": "cond-mat/0403022",
        "authors": "L. Borland (Evnine-Vaughan Associates), J.P. Bouchaud (Science &\n  Finance/Capital Fund Management)",
        "title": "A Non-Gaussian Option Pricing Model with Skew",
        "comments": "37 pages, 11 ps figures, minor changes, typos corrected, to appear in\n  Quantitative Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Closed form option pricing formulae explaining skew and smile are obtained\nwithin a parsimonious non-Gaussian framework. We extend the non-Gaussian option\npricing model of L. Borland (Quantitative Finance, {\\bf 2}, 415-431, 2002) to\ninclude volatility-stock correlations consistent with the leverage effect. A\ngeneralized Black-Scholes partial differential equation for this model is\nobtained, together with closed-form approximate solutions for the fair price of\na European call option. In certain limits, the standard Black-Scholes model is\nrecovered, as is the Constant Elasticity of Variance (CEV) model of Cox and\nRoss. Alternative methods of solution to that model are thereby also discussed.\nThe model parameters are partially fit from empirical observations of the\ndistribution of the underlying. The option pricing model then predicts European\ncall prices which fit well to empirical market data over several maturities.\n"
    },
    {
        "paper_id": "cond-mat/0403045",
        "authors": "Nicola Scafetta, Sergio Picozzi, and Bruce J. West",
        "title": "An out-of-equilibrium model of the distributions of wealth",
        "comments": "11 pages + 7 figures. in press on Quantitavive Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The distribution of wealth among the members of a society is herein assumed\nto result from two fundamental mechanisms, trade and investment. An empirical\ndistribution of wealth shows an abrupt change between the low-medium range,\nthat may be fitted by a non-monotonic function with an exponential-like tail\nsuch as a Gamma distribution, and the high wealth range, that is well fitted by\na Pareto or inverse power-law function. We demonstrate that an appropriate\ntrade-investment model, depending on three adjustable parameters associated\nwith the total wealth of a society, a social differentiation among agents, and\neconomic volatility referred to as investment can successfully reproduce the\ndistribution of empirical wealth data in the low, medium and high ranges.\nFinally, we provide an economic interpretation of the mechanisms in the model\nand, in particular, we discuss the difference between Classical and\nNeoclassical theories regarding the concepts of {\\it value} and {\\it price}. We\nconsider the importance that out-of-equilibrium trade transactions, where the\nprices differ from values, have in real economic societies.\n"
    },
    {
        "paper_id": "cond-mat/0403051",
        "authors": "D. Garlaschelli and M. I. Loffredo",
        "title": "Fitness-dependent topological properties of the World Trade Web",
        "comments": "4 Pages, 4 Figures. Final version accepted for publication on\n  Physical Review Letters",
        "journal-ref": "Phys. Rev. Lett. 93, 188701 (2004).",
        "doi": "10.1103/PhysRevLett.93.188701",
        "license": null,
        "abstract": "  Among the proposed network models, the hidden variable (or good get richer)\none is particularly interesting, even if an explicit empirical test of its\nhypotheses has not yet been performed on a real network. Here we provide the\nfirst empirical test of this mechanism on the world trade web, the network\ndefined by the trade relationships between world countries. We find that the\npower-law distributed gross domestic product can be successfully identified\nwith the hidden variable (or fitness) determining the topology of the world\ntrade web: all previously studied properties up to third-order correlation\nstructure (degree distribution, degree correlations and hierarchy) are found to\nbe in excellent agreement with the predictions of the model. The choice of the\nconnection probability is such that all realizations of the network with the\nsame degree sequence are equiprobable.\n"
    },
    {
        "paper_id": "cond-mat/0403067",
        "authors": "Vasiliki Plerou, Parameswaran Gopikrishnan, Xavier Gabaix, and H.\n  Eugene Stanley",
        "title": "On the Origin of Power-Law Fluctuations in Stock Prices",
        "comments": "6 pages 2 column format",
        "journal-ref": "Quantitative Finance 4 (February 2004) C11-C15",
        "doi": null,
        "license": null,
        "abstract": "  We respond to the issues discussed by Farmer and Lillo (FL) related to our\nproposed approach to understanding the origin of power-law distributions in\nstock price fluctuations. First, we extend our previous analysis to 1000 US\nstocks and perform a new estimation of market impact that accounts for\nsplitting of large orders and potential autocorrelations in the trade flow. Our\nnew analysis shows clearly that price impact and volume are related by a\nsquare-root functional form of market impact for large volumes, in contrast to\nthe claim of FL that this relationship increases as a power law with a smaller\nexponent. Since large orders are usually executed by splitting into smaller\nsize trades, procedures used by FL give a downward bias for this power law\nexponent. Second, FL analyze 3 stocks traded on the London Stock Exchange, and\nsolely on this basis they claim that the distribution of transaction volumes do\nnot have a power-law tail for the London Stock Exchange. We perform new\nempirical analysis on transaction data for the 262 largest stocks listed in the\nLondon Stock Exchange, and find that the distribution of volume decays as a\npower-law with an exponent $\\approx 3/2$ -- in sharp contrast to FL's claim\nthat the distribution of transaction volume does not have a power-law tail. Our\nexponent estimate of $\\approx 3/2$ is consistent with our previous results from\nthe New York and Paris Stock Exchanges. We conclude that the available\nempirical evidence is consistent with our hypothesis on the origin of power-law\nfluctuations in stock prices.\n"
    },
    {
        "paper_id": "cond-mat/0403070",
        "authors": "Atushi Ishikawa, Tadao Suzuki",
        "title": "Relations between a typical scale and averages in the breaking of\n  fractal distribution",
        "comments": "17 pages, latex, 13 eps figures",
        "journal-ref": "PhysicaA343:376-392,2004",
        "doi": "10.1016/j.physa.2004.06.060",
        "license": null,
        "abstract": "  We study distributions which have both fractal and non-fractal scale regions\nby introducing a typical scale into a scale invariant system. As one of models\nin which distributions follow power law in the large scale region and deviate\nfurther from the power law in the smaller scale region, we employ 2-dim quantum\ngravity modified by the $R^2$ term. As examples of distributions in the real\nworld which have similar property to this model, we consider those of personal\nincome in Japan over latest twenty fiscal years. We find relations between the\ntypical scale and several kinds of averages in this model, and observe that\nthese relations are also valid in recent personal income distributions in Japan\nwith sufficient accuracy. We show the existence of the fiscal years so called\nbubble term in which the gap has arisen in power law, by observing that the\ndata are away from one of these relations. We confirm, therefore, that the\ndistribution of this model has close similarity to those of personal income. In\naddition, we can estimate the value of Pareto index and whether a big gap\nexists in power law by using only these relations. As a result, we point out\nthat the typical scale is an useful concept different from average value and\nthat the distribution function derived in this model is an effective tool to\ninvestigate these kinds of distributions.\n"
    },
    {
        "paper_id": "cond-mat/0403143",
        "authors": "Marcel Ausloos, Janusz Miskiewicz, Michele Sanglier",
        "title": "The durations of recession and prosperity: does their distribution\n  follow a power or an exponential law?",
        "comments": "8 pages, 9 figures, submitted to Physica A",
        "journal-ref": "Physica A 339 (2004) 548-558",
        "doi": "10.1016/j.physa.2004.03.005",
        "license": null,
        "abstract": "  Following findings by Ormerod and Mounfield, Wright rises the problem whether\na power or an exponential law describes the distribution of occurrences of\neconomic recession periods. In order to clarify the controversy a different set\nof GDP data is hereby examined. The conclusion about a power law distribution\nof recession periods seems better though the matter is not entirely settled.\nThe case of prosperity duration is also studied and is found to follow a power\nlaw. Universal but also non universal features between recession and prosperity\ncases are emphasized. Considering that the economy is basically a bistable\n(recession/prosperity) system we may derive a characteristic (de)stabilisation\ntime.\n"
    },
    {
        "paper_id": "cond-mat/0403161",
        "authors": "Kyungsik Kim, Seong-Min Yoon (Pukyong National University)",
        "title": "Power Law Distributions in Korean Household Incomes",
        "comments": "12 pages, 7 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate the distribution function and the cumulative probability for\nKorean household incomes, i.e., the current, labor, and property incomes. For\nour case, the distribution functions are consistent with a power law. It is\nalso showed that the probability density of income growth rates almost has the\nform of a exponential function. Our obtained results are compared with those of\nother numerical calculations.\n"
    },
    {
        "paper_id": "cond-mat/0403167",
        "authors": "Michael Boss, Martin Summer, Stefan Thurner",
        "title": "Contagion Flow Through Banking Networks",
        "comments": "8 pages, 2 figures, contribution to iccs 2004",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Based on an empirical analysis of the network structure of the Austrian\ninter-bank market, we study the flow of funds through the banking network\nfollowing exogenous shocks to the system. These shocks are implemented by\nstochastic changes in variables like interest rates, exchange rates, etc. We\ndemonstrate that the system is relatively stable in the sence that defaults of\nindividual banks are unlikely to spread over the entire network. We study the\ncontagion impact of all individual banks, meaning the number of banks which are\ndriven into insolvency as a result of a single bank's default. We show that the\nvertex betweenness of individual banks is linearly related to their contagion\nimpact.\n"
    },
    {
        "paper_id": "cond-mat/0403177",
        "authors": "Przemyslaw Repetowicz and Peter Richmond",
        "title": "Removing noise from correlations in multivariate stock price data",
        "comments": "19 pages, 18 postscript figures, submitted to Physica A in March 2004",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper examines the applicability of Random Matrix Theory to portfolio\nmanagement in finance. Starting from a group of normally distributed stochastic\nprocesses with given correlations we devise an algorithm for removing noise\nfrom the estimator of correlations constructed from measured time series. We\nthen apply this algorithm to historical time series for the Standard and Poor's\n500 index. We discuss to what extent the noise can be removed and whether the\nresulting underlying correlations are sufficiently accurate for portfolio\nmanagement purposes.\n"
    },
    {
        "paper_id": "cond-mat/0403333",
        "authors": "Tanya Ara\\'ujo and Francisco Lou\\c{c}\\~a",
        "title": "Complex Behavior of Stock Markets: Processes of Synchronization and\n  Desynchronization during Crises",
        "comments": "15 pages, 11 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper investigates the dynamics of in the S&P500 index from daily\nreturns for the last 30 years. Using a stochastic geometry technique, each\nS&P500 yearly batch of data is embedded in a subspace that can be accurately\ndescribed by a reduced number of dimensions. Such feature is understood as\nempirical evidence for the presence of a certain amount of structure in the\nmarket. As part of the inquiry into the structure of the market we investigate\nchanges in its volume and shape, and we define new measures for that purpose.\nHaving these measures defined in the space of stocks we analyze the effects of\nsome extreme phenomena on the geometry of the market. We discuss the hypothesis\nthat collective behavior in period of crises reinforces the structure of\ncorrelations between stocks, but that it also may have an opposite effect on\nclustering by similar economic sectors. Comparing the crises of 1987 and 2001,\nwe discuss why the expansion of the ellipsoid describing the geometry of the\ndistances in the market, which occurs in the latter period, is not homogeneous\nthrough sectors. The conclusions from this research identify some of the\nchanges in the structure of the market over the last 30 years.\n"
    },
    {
        "paper_id": "cond-mat/0403465",
        "authors": "Hokky Situngkir, Yohanes Surya",
        "title": "Stylized Statistical Facts of Indonesian Financial Data: Empirical Study\n  of Several Stock Indexes in Indonesia",
        "comments": "11 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper is trying to unveil general statistical characteristic of\nfinancial; time series data that is subjected to several financial time series\ndata present in Indonesia, e.g. individual index such as stock price of PT.\nTELKOM, stock price of PT HM SAMPOERNA, and compiled stock price index (Jakarta\nStock Exchange Index). Characteristics that we try to analyze are volatility\nclustering, truncated Levy distribution, and multifractality feature. This\nanalysis is directed for further works of research in making Indonesian\nartificial stock exchange that gives representation of micro structure of stock\nexchange in Indonesia. This paper is a resume of statistic behavior analyzed in\ntop-down to become the ground in starting a more bottom-up analysis.\n"
    },
    {
        "paper_id": "cond-mat/0403469",
        "authors": "Andrei Leonidov",
        "title": "On non-markovian nature of stock trading",
        "comments": "Presented at \"Applications of Physics in Financial Analysis\", Warsaw,\n  November 13-15 2004; International Journal of Theoretical and Applied\n  Finance, to appear",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Using a relationship between the moments of the probability distribution of\ntimes between the two consecutive trades (intertrade time distribution) and the\nmoments of the distribution of a daily number of trades we show, that the\nunderlying point process generating times of the trades is an essentially\nnon-markovian long-range memory one. Further evidence for the long-range memory\nnature of this point process is provided by the powerlike correlation between\nthe intertrade time intervals. The data set includes all trades in EESR stock\non the Moscow International Currency Exchange in January 2003 - September 2003\nand in Siemens, Commerzbank and Karstadt stocks traded on the Xetra electronic\nstock exchange of Deutsche Boerse in October 2002.\n"
    },
    {
        "paper_id": "cond-mat/0403563",
        "authors": "G. Broekstra (Nyenrode Univ.), D. Sornette (CNRS-Univ. Nice and UCLA),\n  W.-X. Zhou (UCLA)",
        "title": "Bubble, Critical Zone and the Crash of Royal Ahold",
        "comments": "37 pages including 13 figures",
        "journal-ref": "Physica A 346 (2005) 529-560",
        "doi": "10.1016/j.physa.2004.08.021",
        "license": null,
        "abstract": "  Our analysis of financial data, in terms of super-exponential growth,\nsuggests that the seed of the 2002/03 crisis of the Dutch supermarket giant\nAHOLD was planted in 1996. It became quite visible in 1999 when the post-bubble\ndestabilization regime was well-developed and acted as the precursor of an\ninevitable collapse fueled by raising expectations of investors to maintain\nstrong herding pressures. We have adapted Weidlich's theory of opinion\nformation to describe the formation of buy or sell decisions among investors,\nbased on a competition between the mechanisms of herding and of personal\nopinion opposing the herd. Among four typical patterns of stock price\nevolution, we have identified a ``critical zone'' in the model characterized by\na strong sensitivity of the price trajectory on the herding and personal\ninclination parameters. The critical zone describes the maturation of a\nsystemic instability forewarning of an inevitable crash. Classification and\nrecognition of the spontaneous emergence of patterns of stock market evolution\nbased on Weidlich's theory of complex systems, and in particular our discovery\nof the post-bubble destabilization regime which acts as a precursor to a\nsubsequent crash or antibubble, not only presents the possibility of developing\nearly warning signals but also suggests to top management ways of dealing with\nthe coming crisis.\n"
    },
    {
        "paper_id": "cond-mat/0403621",
        "authors": "R. Rothenstein and K. Pawelzik",
        "title": "Limited profit in predictable stock markets",
        "comments": "4 pages, 4 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.09.010",
        "license": null,
        "abstract": "  It has been assumed that arbitrage profits are not possible in efficient\nmarkets, because future prices are not predictable. Here we show that\npredictability alone is not a sufficient measure of market efficiency. We\ninstead propose to measure inefficiencies of markets in terms of the maximal\nprofit an ideal trader can take out from a market. In a stock market model with\nan evolutionary selection of agents this method reveals that the mean relative\namount of realizable profits $P$ is very limited and we find that it decays\nwith rising number of agents in the markets. Our results show that markets may\nself-organize their collective dynamics such that it becomes very sensitive to\nprofit attacks which demonstrates that a high degree of market efficiency can\ncoexist with predictability.\n"
    },
    {
        "paper_id": "cond-mat/0403624",
        "authors": "Silvio M. Duarte Queiros",
        "title": "On anomalous distributions in intra-day financial time series and\n  Non-extensive Statistical Mechanics",
        "comments": "To appear in Physica A - \"Proceedings of Applications of Physics to\n  Financial Analysis 4\", 5 pages, 1 figures",
        "journal-ref": "Physica A 344, 279 - 283 (2004)",
        "doi": null,
        "license": null,
        "abstract": "  In this paper one studies the distribution of log-returns (tick-by-tick) in\nthe Lisbon stock market and shows that it is well adjusted by the solution of\nthe equation, {$\\frac{dp_{x}}{d| x|}=-\\beta_{q^{\\prime\n}}p_{x}^{q^{\\prime}}-(\\beta_{q}-\\beta_{q^{\\prime}}) p_{x}^{q}$}, which\ncorresponds to a generalization of the differential equation which has as\nsolution the power-laws that optimise the entropic form $S_{q}=-k \\frac{1-\\int\np_{x}^{q} dx}{1-q}$, base of present non-extensive statistical mechanics.\n"
    },
    {
        "paper_id": "cond-mat/0403649",
        "authors": "A. De Martino, I. Giardina, M. Marsili and A. Tedeschi",
        "title": "Generalized minority games with adaptive trend-followers and contrarians",
        "comments": "4 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.70.025104",
        "license": null,
        "abstract": "  We introduce a simple extension of the minority game in which the market\nrewards contrarian (resp. trend-following) strategies when it is far from\n(resp. close to) efficiency. The model displays a smooth crossover from a\nregime where contrarians dominate to one where trend-followers dominate. In the\nintermediate phase, the stationary state is characterized by non-Gaussian\nfeatures as well as by the formation of sustained trends and bubbles.\n"
    },
    {
        "paper_id": "cond-mat/0403662",
        "authors": "Plamen Ch. Ivanov (Boston University), Ainslie Yuen (Cambridge\n  University), Boris Podobnik (University of Rijeka, Croatia), Youngki Lee\n  (Yanbian University, China)",
        "title": "Common Scaling Patterns in Intertrade Times of U. S. Stocks",
        "comments": "8 pages, 5 figures. Presented at The Second Nikkei Econophysics\n  Workshop, Tokyo, 11-14 Nov. 2002. A subset appears in \"The Application of\n  Econophysics: Proceedings of the Second Nikkei Econophysics Symposium\",\n  editor H. Takayasu (Springer-Verlag, Tokyo, 2003) pp.51-57. Submitted to\n  Phys. Rev. E on 25 June 2003",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.69.056107",
        "license": null,
        "abstract": "  We analyze the sequence of time intervals between consecutive stock trades of\nthirty companies representing eight sectors of the U. S. economy over a period\nof four years. For all companies we find that: (i) the probability density\nfunction of intertrade times may be fit by a Weibull distribution; (ii) when\nappropriately rescaled the probability densities of all companies collapse onto\na single curve implying a universal functional form; (iii) the intertrade times\nexhibit power-law correlated behavior within a trading day and a consistently\ngreater degree of correlation over larger time scales, in agreement with the\ncorrelation behavior of the absolute price returns for the corresponding\ncompany, and (iv) the magnitude series of intertrade time increments is\ncharacterized by long-range power-law correlations suggesting the presence of\nnonlinear features in the trading dynamics, while the sign series is\nanti-correlated at small scales. Our results suggest that independent of\nindustry sector, market capitalization and average level of trading activity,\nthe series of intertrade times exhibit possibly universal scaling patterns,\nwhich may relate to a common mechanism underlying the trading dynamics of\ndiverse companies. Further, our observation of long-range power-law\ncorrelations and a parallel with the crossover in the scaling of absolute price\nreturns for each individual stock, support the hypothesis that the dynamics of\ntransaction times may play a role in the process of price formation.\n"
    },
    {
        "paper_id": "cond-mat/0403681",
        "authors": "T. Di Matteo, T. Aste, M. M. Dacorogna",
        "title": "Long term memories of developed and emerging markets: using the scaling\n  analysis to characterize their stage of development",
        "comments": "46 pages, 7 figures, accepted for publication in Journal of Banking &\n  Finance",
        "journal-ref": "Journal of Banking & Finance 29/4 (2005) 827-851",
        "doi": null,
        "license": null,
        "abstract": "  The scaling properties encompass in a simple analysis many of the volatility\ncharacteristics of financial markets. That is why we use them to probe the\ndifferent degree of markets development. We empirically study the scaling\nproperties of daily Foreign Exchange rates, Stock Market indices and fixed\nincome instruments by using the generalized Hurst approach. We show that the\nscaling exponents are associated with characteristics of the specific markets\nand can be used to differentiate markets in their stage of development. The\nrobustness of the results is tested by both Monte-Carlo studies and a\ncomputation of the scaling in the frequency-domain.\n"
    },
    {
        "paper_id": "cond-mat/0403713",
        "authors": "Belal Baaquie (Singapore) and Jean-Philippe Bouchaud (Science &\n  Finance/CFM)",
        "title": "\"Stiff\" Field Theory of Interest Rates and Psychological Future Time",
        "comments": "10 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The simplest field theory description of the multivariate statistics of\nforward rate variations over time and maturities, involves a quadratic action\ncontaining a gradient squared rigidity term. However, this choice leads to a\nspurious kink (infinite curvature) of the normalized correlation function for\ncoinciding maturities. Motivated by empirical results, we consider an extended\naction that contains a squared Laplacian term, which describes the bending\nstiffness of the FRC. With the extra ingredient of a `psychological' future\ntime, describing how the perceived time between events depends on the time in\nthe future, our theory accounts extremely well for the phenomenology of\ninterest rate dynamics.\n"
    },
    {
        "paper_id": "cond-mat/0403723",
        "authors": "Frank Westerhoff",
        "title": "Market depth and price dynamics: A note",
        "comments": "9 pages from economist, including 4 figs, for Int. J. Mod. Phys. C\n  15, issue 7",
        "journal-ref": null,
        "doi": "10.1142/S0129183104006455",
        "license": null,
        "abstract": "  This note explores the consequences of nonlinear price impact functions on\nprice dynamics within the chartist-fundamentalist framework. Price impact\nfunctions may be nonlinear with respect to trading volume. As indicated by\nrecent empirical studies, a given transaction may cause a large (small) price\nchange if market depth is low (high). Simulations reveal that such a\nrelationship may create endogenous complex price fluctuations even if the\ntrading behavior of chartists and fundamentalists is linear.\n"
    },
    {
        "paper_id": "cond-mat/0403761",
        "authors": "Sergei Fedotov and Abby Tan",
        "title": "Long memory stochastic volatility in option pricing",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The aim of this paper is to present a simple stochastic model that accounts\nfor the effects of a long-memory in volatility on option pricing. The starting\npoint is the stochastic Black-Scholes equation involving volatility with\nlong-range dependence. We consider the option price as a sum of classical\nBlack-Scholes price and random deviation describing the risk from the random\nvolatility. By using the fact the option price and random volatility change on\ndifferent time scales, we find the asymptotic equation for the derivation\ninvolving fractional Brownian motion. The solution to this equation allows us\nto find the pricing bands for options.\n"
    },
    {
        "paper_id": "cond-mat/0403767",
        "authors": "Zoltan Eisler, Janos Kertesz",
        "title": "Multifractal model of asset returns with leverage effect",
        "comments": "23 pages, 8 figures, updated some figures and references, fixed two\n  typos, accepted to Physica A",
        "journal-ref": "Physica A 343, 603-622 (2004)",
        "doi": "10.1016/j.physa.2004.05.061",
        "license": null,
        "abstract": "  Multifractal processes are a relatively new tool of stock market analysis.\nTheir power lies in the ability to take multiple orders of autocorrelations\ninto account explicitly. In the first part of the paper we discuss the\nframework of the Lux model and refine the underlying phenomenological picture.\nWe also give a procedure of fitting all parameters to empirical data. We\npresent a new approach to account for the effective length of power-law memory\nin volatility. The second part of the paper deals with the consequences of\nasymmetry in returns. We incorporate two related stylized facts, skewness and\nleverage autocorrelations into the model. Then from Monte Carlo measurements we\nshow, that this asymmetry significantly increases the mean squared error of\nvolatility forecasts. Based on a filtering method we give evidence on similar\nbehavior in empirical data.\n"
    },
    {
        "paper_id": "cond-mat/0404103",
        "authors": "Sergei Levendorskii",
        "title": "The American put and European options near expiry, under Levy processes",
        "comments": "29 pages, 6 figures, submitted to ``Stochastic Porcesses and their\n  Applications\"",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We derive explicit formulas for time decay, for the European call and put\noptions at expiry, and use them to calculate analytical approximations to the\nprice of the American put and early exercise boundary near expiry. We show that\nfor many families of non-Gaussian processes used in empirical studies of\nfinancial markets, the early exercise boundary for the American put without\ndividends is separated from the strike price by a non-vanishing margin on the\ninterval [0,T). As the riskless rate vanishes and the drift decreases\naccordingly so that the stock remains a martingale, the optimal exercise price\ngoes to zero uniformly over the interval [0, T). The implications for\nparameters' fitting are discussed.\n"
    },
    {
        "paper_id": "cond-mat/0404106",
        "authors": "Svetlana Boyarchenko and Sergei Levendorskii",
        "title": "Practical guide to real options in discrete time",
        "comments": "28 pages, 1 figure, submitted to the \"Journal of economic Theory\"",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Continuous time models in the theory of real options give explicit formulas\nfor optimal exercise strategies when options are simple and the price of an\nunderlying asset follows a geometric Brownian motion. This paper suggests a\ngeneral, computationally simple approach to real options in discrete time.\nExplicit formulas are derived even for embedded options. Discrete time\nprocesses reflect the scarcity of observations in the data, and may account for\nfat tails and skewness of probability distributions of commodity prices. The\nmethod of the paper is based on the use of the expected present value\noperators.\n"
    },
    {
        "paper_id": "cond-mat/0404107",
        "authors": "Sergei Levendorskii",
        "title": "Consistency conditions for affine term structure models",
        "comments": "39 pages",
        "journal-ref": "\"Stochastic Processes and their Applications\", 109, 2004, pp.\n  225-261",
        "doi": null,
        "license": null,
        "abstract": "  ATSM are widely applied for pricing of bonds and interest rate derivatives\nbut the consistency of ATSM when the short rate, r, is unbounded from below\nremains essentially an open question. First, the standard approach to ATSM uses\nthe Feynman-Kac theorem which is easily applicable only when r is bounded from\nbelow. Second, if the tuple of state variables belongs to the region where r is\npositive, the bond price should decrease in any state variable for which the\ncorresponding coefficient in the formula for r is positive; the bond price\nshould also decrease as the time to maturity increases. In the paper,\nsufficient conditions for the application of the Feynman-Kac formula, and\nmonotonicity of the bond price are derived, for wide classes of affine term\nstructure models in the pure diffusion case. Necessary conditions for the\nmonotonicity are obtained as well. The results can be generalized for\njump-diffusion processes.\n"
    },
    {
        "paper_id": "cond-mat/0404108",
        "authors": "Svetlana Boyarchenko and Sergei Levendorskii",
        "title": "Universal bad news principle and pricing of options on dividend-paying\n  assets",
        "comments": "24 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We solve the pricing problem for perpetual American puts and calls on\ndividend-paying assets. The dependence of a dividend process on the underlying\nstochastic factor is fairly general: any non-decreasing function is admissible.\nThe stochastic factor follows a Levy process. This specification allows us to\nconsider assets that pay no dividends at all when the level of the underlying\nfactor (say, the assets of the firm) is too low, and assets that pay dividends\nat a fixed rate when the underlying stochastic process remains in some range.\nCertain dividend processes exhibiting mean-reverting features can be modelled\nas appropriate increasing functions of Levy processes. The payoffs of both the\nAmerican put and call options can be represented as the expected present value\n(EPV) of a certain stream of dividends, and we show that the option must be\nexercised the first time the EPV of this stream with the original process being\nreplaced by the infimum process starting from the current level, becomes\npositive. Thus, the exercise threshold depends only on the record setting bad\nnews. The results can be applied to the theory of real options as well; as one\nof possible applications, we consider the problem of incremental capital\nexpansion.\n"
    },
    {
        "paper_id": "cond-mat/0404264",
        "authors": "Damien Challet, Tobias Galla",
        "title": "Price return auto-correlation and predictability in agent-based models\n  of financial markets",
        "comments": "7 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We demonstrate that minority mechanisms arise in the dynamics of markets\nbecause of effects of price impact; accordingly the relative importance of\nminority and delayed majority mechanisms depends on the frequency of trading.\nWe then use minority games to illustrate that a vanishing price return\nauto-correlation function does not necessarily imply market efficiency. On the\ncontrary, we stress the difference between correlations measured conditionally\nand unconditionally on external patterns.\n"
    },
    {
        "paper_id": "cond-mat/0404416",
        "authors": "Diane Wilcox, Tim Gebbie",
        "title": "Serial Correlation, Periodicity and Scaling of Eigenmodes in an Emerging\n  Market",
        "comments": "16 pages, 11 figures. Added section on Variance Ratios, extended\n  discussion with added reference",
        "journal-ref": "International Journal of Theoretical and Applied Finance, 11, 7\n  (November 2008), pp. 739-760",
        "doi": "10.1142/S0219024908005020",
        "license": null,
        "abstract": "  We investigate serial correlation, periodic, aperiodic and scaling behaviour\nof eigenmodes, i.e. daily price fluctuation time-series derived from\neigenvectors, of correlation matrices of shares listed on the Johannesburg\nStock Exchange (JSE) from January 1993 to December 2002. Periodic, or calendar,\ncomponents are detected by spectral analysis. We find that calendar effects are\nlimited to eigenmodes which correspond to eigenvalues outside the Wishart\nrange. Using a variance ratio test, we uncover serial correlation in the first\neigenmodes and find slight negative serial correlation for eigenmodes within\nthe Wishart range. Our spectral analysis and variance ratio investigations\nsuggest that interpolating missing data or illiquid trading days with\nzero-order hold introduces high frequency noise and spurious serial\ncorrelation.\n  Aperiodic and scaling behaviour of the eigenmodes are investigated by using\nrescaled-range (R/S) methods and detrended fluctuation analysis (DFA). We find\nthat DFA and classic and modified R/S exponents suggest the presence of\nlong-term memory effects in the first five eigenmodes.\n"
    },
    {
        "paper_id": "cond-mat/0404497",
        "authors": "N. Basalto, R. Bellotti, F. De Carlo, P. Facchi, S. Pascazio",
        "title": "Clustering stock market companies via chaotic map synchronization",
        "comments": "12 pages, 3 figures",
        "journal-ref": "Physica A 345 (2005) 196",
        "doi": "10.1016/j.physa.2004.07.034",
        "license": null,
        "abstract": "  A pairwise clustering approach is applied to the analysis of the Dow Jones\nindex companies, in order to identify similar temporal behavior of the traded\nstock prices. To this end, the chaotic map clustering algorithm is used, where\na map is associated to each company and the correlation coefficients of the\nfinancial time series are associated to the coupling strengths between maps.\nThe simulation of a chaotic map dynamics gives rise to a natural partition of\nthe data, as companies belonging to the same industrial branch are often\ngrouped together. The identification of clusters of companies of a given stock\nmarket index can be exploited in the portfolio optimization strategies.\n"
    },
    {
        "paper_id": "cond-mat/0404520",
        "authors": "Pierre Henry-Labordere",
        "title": "The Feedback Effect of Hedging in Portfolio Optimization",
        "comments": "10 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this short note, we will show how to optimize the portfolio of a large\ntrader whose hedging strategy affects the price of his assets.\n"
    },
    {
        "paper_id": "cond-mat/0404680",
        "authors": "Amir Hossein Darooneh",
        "title": "Physical Picture of the Insurance Market",
        "comments": "3 page",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We find the wealth distribution for an economic agent in the financial\nmarket, in analogy with standard derivation of generaliz Boltzman (Tsallis)\nfactor in statistical mechanics. In this respect, Tsallis entropic index\nseparates two different regimes, the large and small size market. The Pareto\nlike wealth distribution is obtained in the case of small size market. A method\nfor computing the premium is suggested based on the surplus average vanishing.\n"
    },
    {
        "paper_id": "cond-mat/0404684",
        "authors": "Rui Vilela Mendes and Maria Joao Oliveira",
        "title": "Option pricing with fractional volatility",
        "comments": "17 pages Latex, 2 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Based on empirical market data, a stochastic volatility model is proposed\nwith volatility driven by fractional noise. The model is used to obtain a\nrisk-neutrality option pricing formula and an option pricing equation.\n"
    },
    {
        "paper_id": "cond-mat/0405172",
        "authors": "Kyungsik Kim, Seong-Min Yoon, J. S. Choi, Hideki Takayasu",
        "title": "Herd Behaviors in Financial Markets",
        "comments": "15 pages, 6 figures",
        "journal-ref": "J. Korean Phys. Soc. 44, 647 (2004)",
        "doi": "10.3938/jkps.44.647",
        "license": null,
        "abstract": "  We investigate the herd behavior of returns for the yen-dollar exchange rate\nin the Japanese financial market. It is obtained that the probability\ndistribution $P(R)$ of returns $R$ satisfies the power-law behavior $P(R)\n\\simeq R^{-\\beta}$ with the exponents $ \\beta=3.11$(the time interval $\\tau=$\none minute) and 3.36($\\tau=$ one day). The informational cascade regime appears\nin the herding parameter $H\\ge 2.33$ at $\\tau=$ one minute, while it occurs no\nherding at $\\tau=$ one day. Especially, we find that the distribution of\nnormalized returns shows a crossover to a Gaussian distribution at one time\nstep $\\Delta t=1$ day.\n"
    },
    {
        "paper_id": "cond-mat/0405173",
        "authors": "Kyungsik Kim, Seong-Min Yoon and Jum-Soo Choi",
        "title": "Multifractal Measures for the Yen-Dollar Exchange Rate",
        "comments": "14 pages, 5 figures",
        "journal-ref": "J. Korean Phys. Soc. 44, 643 (2004)",
        "doi": "10.3938/jkps.44.643",
        "license": null,
        "abstract": "  We study the tick dynamical behavior of the yen-dollar exchange rate using\nthe rescaled range analysis in financial market. It is found that the\nmultifractal Hurst exponents with the short and long-run memory effects can be\nobtained from the yen-dollar exchange rate. This exists one crossover for the\nHurst exponents at charateristic time scales, while the bond futures exists no\ncrossover. Particularly, it is shown that the probability distribution of the\nyen-dollar exchange rate has one form of the Lorentz distribution rather than\nfat-tailed properties, which is similar to that of for the won-dollar exchange\nrate.\n"
    },
    {
        "paper_id": "cond-mat/0405257",
        "authors": "M. Bartolozzi, D. B. Leinweber, A. W. Thomas",
        "title": "Self-Organized Criticality and Stock Market Dynamics: an Empirical Study",
        "comments": "16 pages, 13 figures. In press: Physica A",
        "journal-ref": "Physica A350:451-465,2005",
        "doi": "10.1016/j.physa.2004.11.061",
        "license": null,
        "abstract": "  The Stock Market is a complex self-interacting system, characterized by an\nintermittent behaviour. Periods of high activity alternate with periods of\nrelative calm. In the present work we investigate empirically about the\npossibility that the market is in a self-organized critical state (SOC). A\nwavelet transform method is used in order to separate high activity periods,\nrelated to the avalanches of sandpile models, from quiescent.\n  A statistical analysis of the filtered data show a power law behaviour in the\navalanche size, duration and laminar times. The memory process, implied by the\npower law distribution, of the laminar times is not consistent with classical\nconservative models for self-organized criticality. We argue that a\n``near-SOC'' state or a time dependence in the driver, which may be chaotic,\ncan explain this behaviour.\n"
    },
    {
        "paper_id": "cond-mat/0405390",
        "authors": "Kyungsik Kim, S.-M. Yoon, C. Christopher Lee, K. H. Chang",
        "title": "Zipf's Law Distributions for Korean Stock Prices",
        "comments": "9 pages, 3 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper investigates the rank distribution, cumulative probability, and\nprobability density of price returns for the stocks traded in the KSE and the\nKOSDAQ market. This research demonstrates that the rank distribution is\nconsistent approximately with the Zipf's law with exponent $\\alpha = -1.00$\n(KSE) and -1.31 (KOSDAQ), similar that of stock prices traded on the TSE. In\naddition, the cumulative probability distribution follows a power law with\nscaling exponent $\\beta = -1.23$ (KSE) and -1.45 (KOSDAQ). In particular, the\nevidence displays that the probability density of normalized price returns for\ntwo kinds of assets almost has the form of an exponential function, similar to\nthe result in the TSE and the NYSE.\n"
    },
    {
        "paper_id": "cond-mat/0405646",
        "authors": "Sergei Fedotov and Stephanos Panayides",
        "title": "Volatility smile and stochastic arbitrage returns",
        "comments": "15 pages, 3 figures. The paper was accepted for publication in\n  Physica A",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The purpose of this work is to explore the role that random arbitrage\nopportunities play in pricing financial derivatives. We use a non-equilibrium\nmodel to set up a stochastic portfolio, and for the random arbitrage return, we\nchoose a stationary ergodic random process rapidly varying in time. We exploit\nthe fact that option price and random arbitrage returns change on different\ntime scales which allows us to develop an asymptotic pricing theory involving\nthe central limit theorem for random processes. We restrict ourselves to\nfinding pricing bands for options rather than exact prices. The resulting\npricing bands are shown to be independent of the detailed statistical\ncharacteristics of the arbitrage return. We find that the volatility ``smile''\ncan also be explained in terms of random arbitrage opportunities.\n"
    },
    {
        "paper_id": "cond-mat/0406168",
        "authors": "Chun-Xia Yang, Tao Zhou, Pei-Ling Zhou, Jun Liu and Zi-Nan Tang",
        "title": "Study on Evolvement Complexity in an Artificial Stock Market",
        "comments": "4 pages and 4 figures",
        "journal-ref": "Chin. Phys. Lett. 22, 1014(2005)",
        "doi": "10.1088/0256-307X/22/4/065",
        "license": null,
        "abstract": "  An artificial stock market is established based on multi-agent . Each agent\nhas a limit memory of the history of stock price, and will choose an action\naccording to his memory and trading strategy. The trading strategy of each\nagent evolves ceaselessly as a result of self-teaching mechanism. Simulation\nresults exhibit that large events are frequent in the fluctuation of the stock\nprice generated by the present model when compared with a normal process, and\nthe price returns distribution is L\\'{e}vy distribution in the central part\nfollowed by an approximately exponential truncation. In addition, by defining a\nvariable to gauge the \"evolvement complexity\" of this system, we have found a\nphase cross-over from simple-phase to complex-phase along with the increase of\nthe number of individuals, which may be a ubiquitous phenomenon in multifarious\nreal-life systems.\n"
    },
    {
        "paper_id": "cond-mat/0406224",
        "authors": "J.-P. Bouchaud, J. Kockelkoren, M. Potters",
        "title": "Random walks, liquidity molasses and critical response in financial\n  markets",
        "comments": "18 Pages, 11 Figures, 2 Tables, 3 spurious figures removed",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Stock prices are observed to be random walks in time despite a strong, long\nterm memory in the signs of trades (buys or sells). Lillo and Farmer have\nrecently suggested that these correlations are compensated by opposite long\nranged fluctuations in liquidity, with an otherwise permanent market impact,\nchallenging the scenario proposed in Quantitative Finance 4, 176 (2004), where\nthe impact is *transient*, with a power-law decay in time. The exponent of this\ndecay is precisely tuned to a critical value, ensuring simultaneously that\nprices are diffusive on long time scales and that the response function is\nnearly constant. We provide new analysis of empirical data that confirm and\nmake more precise our previous claims. We show that the power-law decay of the\nbare impact function comes both from an excess flow of limit order opposite to\nthe market order flow, and to a systematic anti-correlation of the bid-ask\nmotion between trades, two effects that create a `liquidity molasses' which\ndampens market volatility.\n"
    },
    {
        "paper_id": "cond-mat/0406225",
        "authors": "R. Kitt, J. Kalda",
        "title": "Properties of low variability periods in financial time series",
        "comments": "14 pages, 5 figures, 3 tables, Submitted to Physica A",
        "journal-ref": "Physica A, 345, 2005, 622",
        "doi": "10.1016/j.physa.2004.07.015",
        "license": null,
        "abstract": "  Properties of low-variability periods in the time series are analysed. The\ntheoretical approach is used to show the relationship between the multi-scaling\nof low-variability periods and multi-affinity of the time series. It is shown\nthat this technically simple method is capable of reveling more details about\ntime-series than the traditional multi-affine analysis. We have applied this\nscaling analysis to financial time series: a number of daily currency and stock\nindex time series. The results show a good scaling behaviour for different\nmodel parameters. The analysis of high-frequency USD-EUR exchange rate data\nconfirmed the theoretical expectations.\n"
    },
    {
        "paper_id": "cond-mat/0406310",
        "authors": "Tomer Kalisky, Yosef Ashkenazy, Shlomo Havlin",
        "title": "Volatility of Linear and Nonlinear Time Series",
        "comments": "7 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.72.011913",
        "license": null,
        "abstract": "  Previous studies indicate that nonlinear properties of Gaussian time series\nwith long-range correlations, $u_i$, can be detected and quantified by studying\nthe correlations in the magnitude series $|u_i|$, i.e., the ``volatility''.\nHowever, the origin for this empirical observation still remains unclear, and\nthe exact relation between the correlations in $u_i$ and the correlations in\n$|u_i|$ is still unknown. Here we find analytical relations between the scaling\nexponent of linear series $u_i$ and its magnitude series $|u_i|$. Moreover, we\nfind that nonlinear time series exhibit stronger (or the same) correlations in\nthe magnitude time series compared to linear time series with the same\ntwo-point correlations. Based on these results we propose a simple model that\ngenerates multifractal time series by explicitly inserting long range\ncorrelations in the magnitude series; the nonlinear multifractal time series is\ngenerated by multiplying a long-range correlated time series (that represents\nthe magnitude series) with uncorrelated time series [that represents the sign\nseries $sgn(u_i)$]. Our results of magnitude series correlations may help to\nidentify linear and nonlinear processes in experimental records.\n"
    },
    {
        "paper_id": "cond-mat/0406326",
        "authors": "Yan-Bo Xie, Bing-Hong Wang, Chin-Kun Hu and Tao Zhou",
        "title": "Global Optimization of Minority Game by Smart Agents",
        "comments": "5 pages, 5 figures",
        "journal-ref": "Eur. Phys. J. B 47, 587-593 (2005)",
        "doi": "10.1140/epjb/e2005-00350-9",
        "license": null,
        "abstract": "  We propose a new model of minority game with so-called smart agents such that\nthe standard deviation and the total loss in this model reach the theoretical\nminimum values in the limit of long time. The smart agents use trail and error\nmethod to make a choice but bring global optimization to the system, which\nsuggests that the economic systems may have the ability to self-organize into a\nhighly optimized state by agents who are forced to make decisions based on\ninductive thinking for their limited knowledge and capabilities. When other\nkinds of agents are also present, the experimental results and analyses show\nthat the smart agent can gain profits from producers and are much more\ncompetent than the noise traders and conventional agents in original minority\ngame.\n"
    },
    {
        "paper_id": "cond-mat/0406365",
        "authors": "Pei-Ling Zhou, Zi-Nan Tang, Tao Zhou, Jing-Ting Wang, and Chun-Xia\n  Yang",
        "title": "Mathew Effect in Artificial Stock Market",
        "comments": "5 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this article, we established a stock market model based on agents'\ninvesting mentality. The agents decide whether to purchase the shares at the\nprobability, according to their anticipation of the market's behaviors. The\nexpectation of the amount of shares they want to buy is directly proportional\nto the value of asset they hold. The agents sell their shares because of the\ngaining-profit psychology, stopping-loss psychology, or dissatisfaction with\nthe long-time congealing of the assets. We studied how the distribution of\nagent's assets varies along with systemic evolution. The experiments show us\nobvious Mathew effect on asset distribution in the artificial stock market, and\nwe have found that the Mathew effect on asset distribution was more and more\nsalient along with the increasing of system running time, stock market size and\nagents' activity extent.\n"
    },
    {
        "paper_id": "cond-mat/0406385",
        "authors": "A. Christian Silva, Victor M. Yakovenko",
        "title": "Temporal evolution of the \"thermal\" and \"superthermal\" income classes in\n  the USA during 1983-2001",
        "comments": "v.3: 7 pages, 5 figures, EPL style, more references added",
        "journal-ref": "Europhys. Lett., 69 (2), pp. 304-310 (2005)",
        "doi": "10.1209/epl/i2004-10330-3",
        "license": null,
        "abstract": "  Personal income distribution in the USA has a well-defined two-class\nstructure. The majority of population (97-99%) belongs to the lower class\ncharacterized by the exponential Boltzmann-Gibbs (\"thermal\") distribution,\nwhereas the upper class (1-3% of population) has a Pareto power-law\n(\"superthermal\") distribution. By analyzing income data for 1983-2001, we show\nthat the \"thermal\" part is stationary in time, save for a gradual increase of\nthe effective temperature, whereas the \"superthermal\" tail swells and shrinks\nfollowing the stock market. We discuss the concept of equilibrium inequality in\na society, based on the principle of maximal entropy, and quantitatively show\nthat it applies to the majority of population.\n"
    },
    {
        "paper_id": "cond-mat/0406556",
        "authors": "Jaume Masoliver, Miquel Montero and Josep Perello",
        "title": "Extreme times in financial markets",
        "comments": "6 pages, 3 figures",
        "journal-ref": "PHYSICAL REVIEW E 71, 056130 (2005)",
        "doi": "10.1103/PhysRevE.71.056130",
        "license": null,
        "abstract": "  We apply the theory of continuous time random walks to study some aspects of\nthe extreme value problem applied to financial time series. We focus our\nattention on extreme times, specifically the mean exit time and the mean\nfirst-passage time. We set the general equations for these extremes and\nevaluate the mean exit time for actual data.\n"
    },
    {
        "paper_id": "cond-mat/0406694",
        "authors": "G. Willis and J. Mimkes",
        "title": "Evidence for the Independence of Waged and Unwaged Income, Evidence for\n  Boltzmann Distributions in Waged Income, and the Outlines of a Coherent\n  Theory of Income Distribution",
        "comments": "28 pages,31 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Two sets of high quality income data are analysed in detail, one set from the\nUK, one from the USA. It is firstly demonstrated that both a log-normal\ndistribution and a Boltzmann distribution can give very accurate fits to both\nthese data sets. The absence of a power tail in the US data set is then\ndiscussed. Taken in conjunction with detailed evidence from the UK and Japanese\nincome data, a strong case is made for the mathematically separate treatment of\nwaged and unwaged income. The authors present a case for preferring the use of\nthe Boltzmann distribution over the log-normal function, this leads to a brief\nreview of the work of a number of researchers, which shows that a coherent\ntheory for the distribution of all income can be postulated.\n"
    },
    {
        "paper_id": "cond-mat/0406696",
        "authors": "Adam G. Zawadowski, Gyorgy Andor, and Janos Kertesz",
        "title": "Short-term market reaction after extreme price changes of liquid stocks",
        "comments": "27 pages, 9 tables, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In our empirical study, we examine the price of liquid stocks after\nexperiencing a large intraday price change using data from the NYSE and the\nNASDAQ. We find significant reversal for both intraday price decreases and\nincreases. The results are stable against varying parameters. While on the NYSE\nthe large widening of the bid-ask spread eliminates most of the profits that\ncan be achieved by a contrarian strategy, on the NASDAQ the bid-ask spread\nstays almost constant yielding significant short-term abnormal profits.\nFurthermore, volatility, volume, and in case of the NYSE the bid-ask spread,\nwhich increase sharply at the event, decay according to a power-law and stay\nsignificantly high over days afterwards.\n"
    },
    {
        "paper_id": "cond-mat/0406704",
        "authors": "Bertrand M. Roehner",
        "title": "Stock markets are not what we think they are: the key roles of\n  cross-ownership and corporate treasury stock",
        "comments": "9 pages, 3 figures, 1 table",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.09.020",
        "license": null,
        "abstract": "  We describe and document three mechanisms by which corporations can influence\nor even control stock prices. (i) Parent and holding companies wield control\nover other publicly traded companies. (ii) Through clever management of\ntreasury stock based on buyback programs and stock issuance, stock price\nfluctuations can be amplified or curbed. (iii) Finally, history shows a close\ninterdependance between the level of stock prices on the one hand and merger\nand acquisition activity on the other hand. This perspective in which Boards of\nDirectors of major companies shepherd the market offers a natural\ninterpretation of the so-called \"herd behavior\" observed in stock markets. The\ntraditional view holds that by driving profit expectations, corporations have\nan indirect role in shaping the market. In this paper, we suggest that over the\nlast decades they became more and more the direct moving force of stock\nmarkets.\n"
    },
    {
        "paper_id": "cond-mat/0407321",
        "authors": "G. Bormetti, G. Montagna, N. Moreni and O. Nicrosini",
        "title": "Pricing Exotic Options in a Path Integral Approach",
        "comments": "21 pages, LaTeX, 3 figures, 6 tables",
        "journal-ref": "Quantitative Finance 6 (2006) 55 - 66",
        "doi": null,
        "license": null,
        "abstract": "  In the framework of Black-Scholes-Merton model of financial derivatives, a\npath integral approach to option pricing is presented. A general formula to\nprice European path dependent options on multidimensional assets is obtained\nand implemented by means of various flexible and efficient algorithms. As an\nexample, we detail the cases of Asian, barrier knock out, reverse cliquet and\nbasket call options, evaluating prices and Greeks. The numerical results are\ncompared with those obtained with other procedures used in quantitative finance\nand found to be in good agreement. In particular, when pricing at-the-money and\nout-of-the-money options, the path integral approach exhibits competitive\nperformances.\n"
    },
    {
        "paper_id": "cond-mat/0407383",
        "authors": "Ying Fan, Menghui Li, Zengru Di",
        "title": "Increasing Returns to Scale, Dynamics of Industrial Structure and Size\n  Distribution of Firms",
        "comments": "28 pages, 8 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A model is presented of the market dynamics to emphasis the effects of\nincreasing returns to scale, including the description of the born and death of\nthe adaptive producers. The evolution of market structure and its behavior with\nthe technological shocks are discussed. Its dynamics is in good agreement with\nsome empirical stylized facts of industrial evolution. Together with the\ndiversities of demand and adaptive growth strategies of firms, the generalized\nmodel has reproduced the power-law distribution of firm size. Three factors\nmainly determine the competitive dynamics and the skewed size distributions of\nfirms: 1. Self-reinforcing mechanism; 2. Adaptive firm grows strategies; 3.\nDemand diversities or widespread heterogeneity in the technological\ncapabilities of different firms. Key words: Econophysics, Increasing returns,\nIndustry dynamics, Size distribution of firms\n"
    },
    {
        "paper_id": "cond-mat/0407418",
        "authors": "Kyuong Eun Lee and Jae Woo Lee",
        "title": "Scaling Properites of Price Changes for Korean Stock Indices",
        "comments": null,
        "journal-ref": "J. Korean Phys. Soc. 44, 668(2004)",
        "doi": null,
        "license": null,
        "abstract": "  We consider returns of two Korean stock market indices, KOSPI and KOSDAQ\nindex. Central parts of the probability distribution function of returns are\nwell fitted by the Lorentzian distribution function. However, tail parts of the\nprobability distribution function follow a power law behavior well. We found\nthat the probability distribution function of returns for both KOSPI and\nKOSDAQ, is outside the L\\'{e}vy stable distribution.\n"
    },
    {
        "paper_id": "cond-mat/0407471",
        "authors": "Antonios Antoniou and Constantinos E. Vorlow",
        "title": "Price Clustering and Discreteness: Is there Chaos behind the Noise?",
        "comments": "18 pages, 3 tables, 3 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.09.006",
        "license": null,
        "abstract": "  We investigate the \"compass rose\" (Crack, T.F. and Ledoit, O. (1996), Journal\nof Finance, 51(2), pg. 751-762) patterns revealed in phase portraits (delay\nplots) of stock returns. The structures observed in these diagrams have been\nattributed mainly to price clustering and discreteness. Using wavelet based\ndenoising, we examine the noise-free versions of a set of FTSE100 stock returns\ntime series. We reveal evidence of non-periodic cyclical dynamics. As a second\nstage we apply Surrogate Data Analysis on the original and denoised stock\nreturns. Our results suggest that there is a strong nonlinear and possibly\ndeterministic signature in the data generating processes of the stock returns\nsequences.\n"
    },
    {
        "paper_id": "cond-mat/0407603",
        "authors": "I. A. Agaev, Yu. A. Kuperin",
        "title": "Multifractal Analysis and Local Hoelder Exponents Approach to Detecting\n  Stock Markets Crashes",
        "comments": "8 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper is devoted to problem of detecting critical events at finiacial\nmarkets using methods of multifractal analysis. Namely, the local regularity of\ntime-series is studied. As a result, one can find out a special behavior or\nsignal of regularity before crashes. This spesial behaviour of local Hoelder\nexponents inherent in financial time series can be used in detecting critcal\nevents or crashes at financial markets.\n"
    },
    {
        "paper_id": "cond-mat/0407687",
        "authors": "Ian Wright",
        "title": "A conjecture on the distribution of firm profit",
        "comments": "8 pages, 2 figures; Econom\\'ia: Teor\\'ia y Pr\\'actica, 20, 2004",
        "journal-ref": null,
        "doi": null,
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  A common assumption of political economy is that profit rates across firms or\nsectors tend to uniformity, and often models are formulated in which this\ntendency is assumed to have been realised. But in reality this tendency is\nnever realised and the distribution of firm profits is not degenerate but\nskewed to the right. The mode is less than the mean and super-profits are\npresent. To understand the distribution of firm profits a general probabilistic\nargument is sketched that yields a candidate functional form. The overall\nproperties of the derived distribution are qualitatively consistent with\nempirical measures, although there is more work to be done.\n"
    },
    {
        "paper_id": "cond-mat/0407769",
        "authors": "Gilles Zumbach",
        "title": "How the trading activity scales with the company sizes in the FTSE 100",
        "comments": "20 pages, 13 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper investigates the scaling dependencies between measures of\n\"activity\" and of \"size\" for companies included in the FTSE 100. The \"size\" of\ncompanies is measured by the total market capitalization. The \"activity\" is\nmeasured with several quantities related to trades (transaction value per\ntrade, transaction value per hour, tick rate), to the order queue (total number\nof orders, total value), and to the price dynamic (spread, volatility). The\noutcome is that systematic scaling relations are observed: 1) the value\nexchanged by hour and value in the order queue have exponents lower than 1\nrespectively 0.90 and 0.75; 2) the tick rate and the value per transaction\nscale with the exponents 0.39 and 0.44; 3) the annualized volatility is\nindependent of the size, and the tick-by-tick volatility decreases with the\nmarket capitalization with an exponent -0.23; 4) the spread increases with the\nvolatility with an exponent 0.94. A theoretical random walk argument is given\nthat relates the volatility exponents with the exponents in points 1 and 2.\n"
    },
    {
        "paper_id": "cond-mat/0407770",
        "authors": "Przemyslaw Repetowicz, Stefan Hutzler, Peter Richmond",
        "title": "Dynamics of Money and Income Distributions",
        "comments": "Sixteen pages, Seven figures, Elsevier style file. Submitted to\n  Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2005.04.010",
        "license": null,
        "abstract": "  We study the model of interacting agents proposed by Chatterjee et al that\nallows agents to both save and exchange wealth. Closed equations for the wealth\ndistribution are developed using a mean field approximation. We show that when\nall agents have the same fixed savings propensity, subject to certain well\ndefined approximations defined in the text, these equations yield the\nconjecture proposed by Chatterjee for the form of the stationary agent wealth\ndistribution. If the savings propensity for the equations is chosen according\nto some random distribution we show further that the wealth distribution for\nlarge values of wealth displays a Pareto like power law tail, ie P(w)\\sim\nw^{1+a}. However the value of $a$ for the model is exactly 1. Exact numerical\nsimulations for the model illustrate how, as the savings distribution function\nnarrows to zero, the wealth distribution changes from a Pareto form to to an\nexponential function. Intermediate regions of wealth may be approximately\ndescribed by a power law with $a>1$. However the value never reaches values of\n\\~ 1.6-1.7 that characterise empirical wealth data. This conclusion is not\nchanged if three body agent exchange processes are allowed. We conclude that\nother mechanisms are required if the model is to agree with empirical wealth\ndata.\n"
    },
    {
        "paper_id": "cond-mat/0408013",
        "authors": "Constantinos E. Vorlow",
        "title": "Stock Price Clustering and Discreteness: The \"Compass Rose\" and\n  Predictability",
        "comments": "13 Pages, 2 Figures, 2 Tables",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this letter we investigate the information provided by the \"compass rose\"\n(Crack, T.F. and Ledoit, O. (1996), Journal of Finance, 51(2), pg. 751-762)\npatterns revealed in phase portraits of daily stock returns. It has been\ninitially suggested that the compass rose is just a manifestation of price\nclustering and discreteness and the tick size, factors that can affect the\nunbiasedness of an array of statistical tests based on stock returns. We show\nthat this may not entirely be the case.\n"
    },
    {
        "paper_id": "cond-mat/0408067",
        "authors": "F. Clementi, M. Gallegati",
        "title": "Power Law Tails in the Italian Personal Income Distribution",
        "comments": "Latex2e v1.6; 14 pages with 10 figures; preprint submitted to Physica\n  A",
        "journal-ref": "Physica A: Statistical Mechanics and its Applications, Vol: 350,\n  Issue: 2-4, May 15, 2005, pp. 427-438",
        "doi": "10.1016/j.physa.2004.11.038",
        "license": null,
        "abstract": "  We investigate the shape of the Italian personal income distribution using\nmicrodata from the Survey on Household Income and Wealth, made publicly\navailable by the Bank of Italy for the years 1977--2002. We find that the upper\ntail of the distribution is consistent with a Pareto-power law type\ndistribution, while the rest follows a two-parameter lognormal distribution.\nThe results of our analysis show a shift of the distribution and a change of\nthe indexes specifying it over time. As regards the first issue, we test the\nhypothesis that the evolution of both gross domestic product and personal\nincome is governed by similar mechanisms, pointing to the existence of\ncorrelation between these quantities. The fluctuations of the shape of income\ndistribution are instead quantified by establishing some links with the\nbusiness cycle phases experienced by the Italian economy over the years covered\nby our dataset.\n"
    },
    {
        "paper_id": "cond-mat/0408143",
        "authors": "Giovani L. Vasconcelos",
        "title": "A Guided Walk Down Wall Street: an Introduction to Econophysics",
        "comments": "27 pages, 12 figures, lecture notes to appear in the Brazilian\n  Journal of Physics",
        "journal-ref": "Braz. J. Phys. 34, 1039-1065 (2004). Available online at\n  http://pcsbf1.sbfisica.org.br/bjp/Vol34/Num3b",
        "doi": "10.1590/S0103-97332004000600002",
        "license": null,
        "abstract": "  This article contains the lecture notes for the short course ``Introduction\nto Econophysics,'' delivered at the II Brazilian School on Statistical\nMechanics, held in Sao Carlos, Brazil, in February 2004. The main goal of the\npresent notes is twofold: i) to provide a brief introduction to the problem of\npricing financial derivatives in continuous time; and ii) to review some of the\nrelated problems to which physicists have made relevant contributions in recent\nyears.\n"
    },
    {
        "paper_id": "cond-mat/0408166",
        "authors": "D. Sornette (CNRS-Univ. Nice and Ucla), W.-X. Zhou (UCLA and Ecust)",
        "title": "Non-parametric Determination of Real-Time Lag Structure between Two Time\n  Series: the \"Optimal Thermal Causal Path\" Method",
        "comments": "37 Elsevier pages including 13 eps figures",
        "journal-ref": "Quantitative Finance 5, 577-591 (2005). See also Journal of\n  Macroeconomics 28, 195-224 (2006) for more details on the methodology.",
        "doi": "10.1080/14697680500383763",
        "license": null,
        "abstract": "  We introduce a novel non-parametric methodology to test for the dynamical\ntime evolution of the lag-lead structure between two arbitrary time series. The\nmethod consists in constructing a distance matrix based on the matching of all\nsample data pairs between the two time series. Then, the lag-lead structure is\nsearched as the optimal path in the distance matrix landscape that minimizes\nthe total mismatch between the two time series, and that obeys a one-to-one\ncausal matching condition. To make the solution robust to the presence of large\nnoise that may lead to spurious structures in the distance matrix landscape, we\nthen generalize this optimal search by introducing a fuzzy search by sampling\nover all possible paths, each path being weighted according to a multinomial\nlogit or equivalently Boltzmann factor proportional to the exponential of the\nglobal mismatch of this path. We present the efficient transfer matrix method\nthat solves the problem and test it on simple synthetic examples to demonstrate\nits properties and usefulness compared with the standard running-time\ncross-correlation method. We then apply our `Optimal Thermal Causal Path''\nmethod to the question of the causality between ......\n"
    },
    {
        "paper_id": "cond-mat/0408227",
        "authors": "G. Willis",
        "title": "Laser Welfare: First Steps in Econodynamic Engineering",
        "comments": "26 pages, 7 Figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The paper starts with a brief review of present understanding of income\ndistributions; especially with regard to recent work in the field of\neconophysics that draws parallels between income, wealth and energy\ndistributions. Examples of alternative energy distributions found in physical\nsystems are discussed, and how they could be used to construct economic models\nthat might allow alternative overall distributions of wealth and income in\nsociety. These ideas are further expanded and a more detailed scheme for\nwelfare assistance is proposed that might be used to improve the incomes of the\npoorest in a more efficient way than traditional welfare schemes. Finally, and\nunusually for a paper on economics; an experiment is proposed that could be\nused to either support or disprove the ideas discussed in the rest of the\npaper.\n"
    },
    {
        "paper_id": "cond-mat/0408277",
        "authors": "P.Oswiecimka, J.Kwapien and S.Drozdz",
        "title": "Multifractality in the stock market: price increments versus waiting\n  times",
        "comments": "Physica A, in print",
        "journal-ref": "Physica A 347 (2005) 626-638",
        "doi": "10.1016/j.physa.2004.08.025",
        "license": null,
        "abstract": "  By applying the multifractal detrended fluctuation analysis to the\nhigh-frequency tick-by-tick data from Deutsche B\\\"orse both in the price and in\nthe time domains, we investigate multifractal properties of the time series of\nlogarithmic price increments and inter-trade intervals of time. We show that\nboth quantities reveal multiscaling and that this result holds across different\nstocks. The origin of the multifractal character of the corresponding dynamics\nis, among others, the long-range correlations in price increments and in\ninter-trade time intervals as well as the non-Gaussian distributions of the\nfluctuations. Since the transaction-to-transaction price increments do not\nstrongly depend on or are almost independent of the inter-trade waiting times,\nboth can be sources of the observed multifractal behaviour of the fixed-delay\nreturns and volatility. The results presented also allow one to evaluate the\napplicability of the Multifractal Model of Asset Returns in the case of\ntick-by-tick data.\n"
    },
    {
        "paper_id": "cond-mat/0408292",
        "authors": "Przemyslaw Repetowicz, Brian Lucey, Peter Richmond",
        "title": "Modelling the term structure of interest rates \\'{a} la\n  Heath-Jarrow-Morton but with non Gaussian fluctuations",
        "comments": "Elsevier style file, 22 pages, one postscript figure, revised on\n  07/09/2004",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider a generalization of the Heath Jarrow Morton model for the term\nstructure of interest rates where the forward rate is driven by Paretian\nfluctuations. We derive a generalization of It\\^{o}'s lemma for the calculation\nof a differential of a Paretian stochastic variable and use it to derive a\nStochastic Differential Equation for the discounted bond price. We show that it\nis not possible to choose the parameters of the model to ensure absence of\ndrift of the discounted bond price. Then we consider a Continuous Time Random\nWalk with jumps driven by Paretian random variables and we derive the large\ntime scaling limit of the jump probability distribution function (pdf). We show\nthat under certain conditions defined in text the large time scaling limit of\nthe jump pdf in the Fourier domain is \\tilde{omega}_t(k,t) \\sim \\exp{-K/(\\ln(k\nt))^2} and is different from the case of a random walk with Gaussian\nfluctuations. We also derive the master equation for the jump pdf and discuss\nthe relation of the master equation to Distributed Order Fractional Diffusion\nEquations.\n"
    },
    {
        "paper_id": "cond-mat/0408358",
        "authors": "Hokky Situngkir, Yohanes Surya",
        "title": "Statistical Facts of Artificial Stock Market",
        "comments": "10 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The paper reports the construction of artificial stock market that emerges\nthe similar statistical facts with real data in Indonesian stock market. We use\nthe individual but dominant data, i.e.: PT TELKOM in hourly interval. The\nartificial stock market shows standard statistical facts, e.g.: volatility\nclustering, the excess kurtosis of the distribution of return, and the scaling\nproperties with its breakdown in the crossover of Levy distribution to the\nGaussian one. From this point, the artificial stock market will always be\nevaluated in order to have comprehension about market process in Indonesian\nstock market generally.\n"
    },
    {
        "paper_id": "cond-mat/0408409",
        "authors": "Zoltan Eisler, Janos Kertesz, Soon-Hyung Yook, Albert-Laszlo Barabasi",
        "title": "Multiscaling and non-universality in fluctuations of driven complex\n  systems",
        "comments": "7 pages, 5 figures, submitted to Europhyisics Letters (extended text)",
        "journal-ref": "Europhys. Lett., 69 (4), pp. 664-670 (2005)",
        "doi": "10.1209/epl/i2004-10384-1",
        "license": null,
        "abstract": "  For many externally driven complex systems neither the noisy driving force,\nnor the internal dynamics are a priori known. Here we focus on systems for\nwhich the time dependent activity of a large number of components can be\nmonitored, allowing us to separate each signal into a component attributed to\nthe external driving force and one to the internal dynamics. We propose a\nformalism to capture the potential multiscaling in the fluctuations and apply\nit to the high frequency trading records of the New York Stock Exchange. We\nfind that on the time scale of minutes the dynamics is governed by internal\nprocesses, while on a daily or longer scale the external factors dominate. This\ntransition from internal to external dynamics induces systematic changes in the\nscaling exponents, offering direct evidence of non-universality in the system.\n"
    },
    {
        "paper_id": "cond-mat/0408531",
        "authors": "R. Donangelo, A. Hansen, K. Sneppen, S.R. Souza",
        "title": "Need, Greed and Noise: Competing Strategies in a Trading Model",
        "comments": "10 pages, 6 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.09.046",
        "license": null,
        "abstract": "  We study an economic model where agents trade a variety of products by using\none of three competing rules: \"need\", \"greed\" and \"noise\". We find that the\noptimal strategy for any agent depends on both product composition in the\noverall market and composition of strategies in the market. In particular, a\nstrategy that does best on pairwise competition may easily do much worse when\nall are present, leading, in some cases, to a \"paper, stone, scissors\" circular\nhierarchy.\n"
    },
    {
        "paper_id": "cond-mat/0408560",
        "authors": "Andrei Khrennikov",
        "title": "Financial heat machine",
        "comments": null,
        "journal-ref": "Physica A, 350, 487-490 (2005)",
        "doi": "10.1016/j.physa.2004.11.046",
        "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "abstract": "  We consider dynamics of financial markets as dynamics of expectations and\ndiscuss such a dynamics from the point of view of phenomenological\nthermodynamics. We describe a financial Carnot cycle and the financial analogue\nof a heat machine. We see, that while in physics a perpetuum mobile is\nabsolutely impossible, in economics such mobile may exist under some\nconditions. Our thermodynamical model for the financial market induces a rather\nunusual interpretation of the role of financial crises. In contrast to the\ncommon point of view, in our model financial crises play a crucial role in\nfunctioning of the modern financial market. This is an important (concluding)\nstage of any financial cycle that is analogous to the stage of cooling in the\nordinary Carnot cycle. A financial cycle could not be completed without such a\nstage as well as the ordinary Carnot cycle. Thus, in spite its destructive (at\nthe first sight) consequences the stage or financial crises is as well\nimportant as the stage of \"boiling of the financial market\" (\"heating of\nexpectations\")\n"
    },
    {
        "paper_id": "cond-mat/0408625",
        "authors": "Kyungsik Kim and Seong-Min Yoon",
        "title": "Phase Transition of Dynamical Herd Behaviors in Financial Markets",
        "comments": "9 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the phase transition of dynamical herd behaviors for the yen-dollar\nexchange rate in the Japanese financial market. It is obtained that the\nprobability distribution of returns satisfies the power-law behavior with three\ndifferent values of the scaling exponent 3.11 (one time lag $\\tau$ = 1 minute),\n2.81 (30 minutes), and 2.29 (1 hour). The crash regime in which the probabilty\ndensity increases with the increasing return appears in the case of $\\tau$ < 30\nminutes, while it occurs no financial crash at $\\tau$ > 30 minutes. it is\nespecially obtained that our dynamical herd behavior exhibits the phase\ntransition at one time lag $\\tau$ = 30 minutes.\n"
    },
    {
        "paper_id": "cond-mat/0409097",
        "authors": "Kyungsik Kim, Seong-Min Yoon, C. Christopher Lee and Myung-Kul Yum",
        "title": "Dynamical Volatilities for Yen-Dollar Exchange Rates",
        "comments": "8 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the continuous time random walk theory from financial tick data of\nthe yen-dollar exchange rate transacted at the Japanese financial market. The\ndynamical behavior of returns and volatilities in this case is particularly\ntreated at the long-time limit. We find that the volatility for prices shows a\npower-law with anomalous scaling exponent k = 0.96 (one minute) and 0.86 (ten\nminutes), and that our behavior occurs in the subdiffusive process. Our result\npresented will be compared with that of recent numerical calculations.\n"
    },
    {
        "paper_id": "cond-mat/0409145",
        "authors": "Atushi Ishikawa",
        "title": "Pareto law and Pareto index in the income distribution of Japanese\n  companies",
        "comments": "12 pages, 8 figures",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.10.023",
        "license": null,
        "abstract": "  In order to study the phenomenon in detail that income distribution follows\nPareto law, we analyze the database of high income companies in Japan. We find\na quantitative relation between the average capital of the companies and the\nPareto index. The larger the average capital becomes, the smaller the Pareto\nindex becomes. From this relation, we can possibly explain that the Pareto\nindex of company income distribution hardly changes, while the Pareto index of\npersonal income distribution changes sharply, from a viewpoint of capital (or\nmeans). We also find a quantitative relation between the lower bound of capital\nand the typical scale at which Pareto law breaks. The larger the lower bound of\ncapital becomes, the larger the typical scale becomes. From this result, the\nreason there is a (no) typical scale at which Pareto law breaks in the income\ndistribution can be understood through (no) constraint, such as the lower bound\nof capital or means of companies, in the financial system.\n"
    },
    {
        "paper_id": "cond-mat/0409179",
        "authors": "I.M. Dremin, A.V. Leonidov",
        "title": "On distribution of number of trades in different time windows in the\n  stock market",
        "comments": "LaTeX, 6 figures",
        "journal-ref": "PhysicaA353:388-402,2005",
        "doi": "10.1016/j.physa.2004.12.048",
        "license": null,
        "abstract": "  Properties of distributions of the number of trades in different intraday\ntime intervals for five stocks traded in MICEX are studied. The dependence of\nthe mean number of trades on the capital turnover is analyzed. Correlation\nanalysis using factorial and $H_q$ moments demonstrates the multifractal nature\nof these distributions as well as some peculiar changes in the correlation\npattern. Guided by the analogy with the analysis of particle multiplicity\ndistributions in multiparticle production at high energies, an evolution\nequation relating changes in capital turnover and a number of trades is\nproposed. We argue that such equation can describe the observed features of the\ndistribution of the number of trades in the stock market.\n"
    },
    {
        "paper_id": "cond-mat/0409319",
        "authors": "Hans-Peter Bermin, Arturo Kohatsu-Higa, Josep Perello",
        "title": "Hints for an extension of the early exercise premium formula for\n  American options",
        "comments": "First Bonzenfreies Colloquium on Market Dynamics and Quantitative\n  Economics. Alessandria, 9-10 September 2004. 7 pages, 4 figures",
        "journal-ref": "Physica A 355 (2005) 152-157.",
        "doi": "10.1016/j.physa.2005.02.077",
        "license": null,
        "abstract": "  Characterization of the American put option price is still an open issue.\n  From the beginning of the nineties there exists a non-closed formula for this\nprice but nontrivial numerical computations are required to solve it. Strong\nefforts have been done to propose methods more and more computationally\nefficient but most of them have few mathematical ground as to ascertain why\nthese methods work well and how important is to consider a good approximation\nto the boundary or to the smooth pasting condition. We perform an extension of\nthe American put price aiming to catch weaknesses of the numerical methods\ngiven in the literature.\n"
    },
    {
        "paper_id": "cond-mat/0409329",
        "authors": "Arnab Das and Sudhakar Yarlagadda",
        "title": "An analytic treatment of the Gibbs-Pareto behavior in wealth\n  distribution",
        "comments": "5 pages, 3 figures, accepted in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2005.02.018",
        "license": null,
        "abstract": "  We develop a general framework, based on Boltzmann transport theory, to\nanalyze the distribution of wealth in societies. Within this framework we\nderive the distribution function of wealth by using a two-party trading model\nfor the poor people while for the rich people a new model is proposed where\ninteraction with wealthy entities (huge reservoir) is relevant. At equilibrium,\nthe interaction with wealthy entities gives a power-law (Pareto-like) behavior\nin the wealth distribution while the two-party interaction gives a\nBoltzmann-Gibbs distribution.\n"
    },
    {
        "paper_id": "cond-mat/0409375",
        "authors": "A.L. Alejandro-Quinones, K.E. Bassler, M. Field, J.L. McCauley, M.\n  Nicol, I. Timofeyef, A. Torok, G.H. Gunaratne",
        "title": "A Theory of Fluctuations in Stock Prices",
        "comments": "16 pages, 9 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The distribution of price returns for a class of uncorrelated diffusive\ndynamics is considered. The basic assumptions are (1) that there is a\n\"consensus\" value associated with a stock, and (2) that the rate of diffusion\ndepends on the deviation of the stock price from the consensus value. We find\nan analytical expression for the distribution of returns in terms of the\ndiffusion rate, when the consensus value is assumed to be fixed in time. The\nanalytical solution is shown to match computed histograms in two simple cases.\nDifferences that result when the consensus value is allowed to change with time\nare presented qualitative explanations.\n"
    },
    {
        "paper_id": "cond-mat/0410079",
        "authors": "Olivier Guedj, Jean-Philippe Bouchaud",
        "title": "Experts' earning forecasts: bias, herding and gossamer information",
        "comments": "15 latex pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the statistics of earning forecasts of US, EU, UK and JP stocks\nduring the period 1987-2004. We confirm, on this large data set, that financial\nanalysts are on average over-optimistic and show a pronounced herding behavior.\nThese effects are time dependent, and were particularly strong in the early\nnineties and during the Internet bubble. We furthermore find that their\nforecast ability is, in relative terms, quite poor and comparable in quality, a\nyear ahead, to the simplest `no change' forecast. As a result of herding,\nanalysts agree with each other five to ten times more than with the actual\nresult. We have shown that significant differences exist between US stocks and\nEU stocks, that may partly be explained as a company size effect.\nInterestingly, herding effects appear to be stronger in the US than in the\nEurozone. Finally, we study the correlation of errors across stocks and show\nthat significant sectorization occurs, some sectors being easier to predict\nthan others. These results add to the list of arguments suggesting that the\ntenets of Efficient Market Theory are untenable.\n"
    },
    {
        "paper_id": "cond-mat/0410225",
        "authors": "Wei-Xing Zhou (ECUST), Wei-Kang Yuan (ECUST)",
        "title": "Inverse statistics in stock markets: Universality and idiosyncracy",
        "comments": "Elsevier style Latex file with BibTex, 13 pages including 9 eps\n  figures (Several misprints corrected, reference updated)",
        "journal-ref": "Physica A 353 (2005) 433-444",
        "doi": "10.1016/j.physa.2005.02.011",
        "license": null,
        "abstract": "  Investigations of inverse statistics (a concept borrowed from turbulence) in\nstock markets, exemplified with filtered Dow Jones Industrial Average, S&P 500,\nand NASDAQ, have uncovered a novel stylized fact that the distribution of exit\ntime follows a power law $p(\\tau_\\rho) \\sim \\tau\\rho^{-\\alpha}$ with $\\alpha\n\\approx 1.5$ at large $\\tau_\\rho$ and the optimal investment horizon\n$\\tau_\\rho^*$ scales as $\\rho^\\gamma$ [1-3]. We have performed an extensive\nanalysis based on unfiltered daily indices and stock prices and high-frequency\n(5-min) records as well in the markets all over the world. Our analysis\nconfirms that the power-law distribution of the exit time with an exponent of\nabout $\\alpha=1.5$ is universal for all the data sets analyzed. In addition,\nall data sets show that the power-law scaling in the optimal investment horizon\nholds, but with idiosyncratic exponent. Specifically, $\\gamma \\approx 1.5$ for\nthe daily data in most of the developed stock markets and the five-minute\nhigh-frequency data, while the $\\gamma$ values of the daily indexes and stock\nprices in emerging markets are significantly less than 1.5. We show that there\nis of little chance that this discrepancy in $\\gamma$ stems from the difference\nof record sizes in the two kinds of stock markets.\n"
    },
    {
        "paper_id": "cond-mat/0410289",
        "authors": "A. Rasoolizadeh, R. Solgi",
        "title": "Statistical analysis of the price index of Tehran Stock Exchange",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper presents a statistical analysis of Tehran Price Index (TePIx) for\nthe period of 1992 to 2004. The results present asymmetric property of the\nreturn distribution which tends to the right hand of the mean. Also the return\ndistribution can be fitted by a stable Levy distribution and the tails are very\nfatter than the gaussian distribution. We estimate the tail index of the TePIx\nreturns with two different methods and the results are consistent with the\nprevious studies on the stock markets. A strong autocorrelation has been\ndetected in the TePIx time series representing a long memory of several trading\ndays. We have also applied a Zipf analysis on the TePIx data presenting strong\ncorrelations between the TePIx daily fluctuations. We hope that this paper be\nable to give a brief description about the statistical behavior of financial\ndata in Iran stock market.\n"
    },
    {
        "paper_id": "cond-mat/0410294",
        "authors": "Sergei Fedotov and Stephanos Panayides",
        "title": "An Adaptive Method for Valuing an Option on Assets with Uncertainty in\n  Volatility",
        "comments": "15 pages, 3 fiqures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present an adaptive approach for valuing the European call option on\nassets with stochastic volatility. The essential feature of the method is a\nreduction of uncertainty in latent volatility due to a Bayesian learning\nprocedure. Starting from a discrete-time stochastic volatility model, we derive\na recurrence equation for the variance of the innovation term in latent\nvolatility equation. This equation describes a reduction of uncertainty in\nvolatility which is crucial for option pricing. To implement the idea of\nadaptive control, we use the risk-minimization procedure involving random\nvolatility with uncertainty. By using stochastic dynamic programming and a\nBayesian approach, we derive a recurrence equation for the risk inherent in\nwriting the option. This equation allows us to find the fair price of the\nEuropean call option. We illustrate numerically that the adaptive procedure\nleads to a decrease in option price.\n"
    },
    {
        "paper_id": "cond-mat/0410335",
        "authors": "A. C. C. Coolen",
        "title": "Generating functional analysis of Minority Games with real market\n  histories",
        "comments": "39 pages, 5 postscript figures, iop style",
        "journal-ref": null,
        "doi": "10.1088/0305-4470/38/11/002",
        "license": null,
        "abstract": "  It is shown how the generating functional method of De Dominicis can be used\nto solve the dynamics of the original version of the minority game (MG), in\nwhich agents observe real as opposed to fake market histories. Here one again\nfinds exact closed equations for correlation and response functions, but now\nthese are defined in terms of two connected effective non-Markovian stochastic\nprocesses: a single effective agent equation similar to that of the `fake'\nhistory models, and a second effective equation for the overall market bid\nitself (the latter is absent in `fake' history models). The result is an exact\ntheory, from which one can calculate from first principles both the persistent\nobservables in the MG and the distribution of history frequencies.\n"
    },
    {
        "paper_id": "cond-mat/0410414",
        "authors": "A.Y. Abul-Magd",
        "title": "Wealth distribution in an ancient Egyptian society",
        "comments": null,
        "journal-ref": "Phys. Rev. E 66 (2002) 057104",
        "doi": "10.1103/PhysRevE.66.057104",
        "license": null,
        "abstract": "  Modern excavations yielded a distribution of the house areas in the ancient\nEgyptian city Akhetaten, which was populated for a short period during the 14th\ncentury BC. Assuming that the house area is a measure of the wealth of its\ninhabitants allows us to make a comparison of the wealth distributions in\nancient and modern societies.\n"
    },
    {
        "paper_id": "cond-mat/0410691",
        "authors": "Robert D. Groot and Pieter A. D. Musters",
        "title": "Minority Game of price promotions in fast moving consumer goods markets",
        "comments": "19 pages, 10 figures, accepted for publication in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.11.010",
        "license": null,
        "abstract": "  A variation of the Minority Game has been applied to study the timing of\npromotional actions at retailers in the fast moving consumer goods market. The\nunderlying hypotheses for this work are that price promotions are more\neffective when fewer than average competitors do a promotion, and that a\npromotion strategy can be based on past sales data. The first assumption has\nbeen checked by analysing 1467 promotional actions for three products on the\nDutch market (ketchup, mayonnaise and curry sauce) over a 120-week period, both\non an aggregated level and on retailer chain level.\n  The second assumption was tested by analysing past sales data with the\nMinority Game. This revealed that high or low competitor promotional pressure\nfor actual ketchup, mayonnaise, curry sauce and barbecue sauce markets is to\nsome extent predictable up to a forecast of some 10 weeks. Whereas a random\nguess would be right 50% of the time, a single-agent game can predict the\nmarket with a success rate of 56% for a 6 to 9 week forecast. This number is\nthe same for all four mentioned fast moving consumer markets. For a multi-agent\ngame a larger variability in the success rate is obtained, but predictability\ncan be as high as 65%.\n  Contrary to expectation, the actual market does the opposite of what game\ntheory would predict. This points at a systematic oscillation in the market.\nEven though this result is not fully understood, merely observing that this\ntrend is present in the data could lead to exploitable trading benefits. As a\ncheck, random history strings were generated from which the statistical\nvariation in the game prediction was studied. This shows that the odds are\n1:1,000,000 that the observed pattern in the market is based on coincidence.\n"
    },
    {
        "paper_id": "cond-mat/0410762",
        "authors": "Jorgen Vitting Andersen and Didier Sornette",
        "title": "A Mechanism for Pockets of Predictability in Complex Adaptive Systems",
        "comments": "5 pages, 3 figures, error corrected",
        "journal-ref": "Europhys. Lett., 70 (5), 697-703 (2005)",
        "doi": null,
        "license": null,
        "abstract": "  We document a mechanism operating in complex adaptive systems leading to\ndynamical pockets of predictability (``prediction days''), in which agents\ncollectively take predetermined courses of action, transiently decoupled from\npast history. We demonstrate and test it out-of-sample on synthetic minority\nand majority games as well as on real financial time series. The surprising\nlarge frequency of these prediction days implies a collective organization of\nagents and of their strategies which condense into transitional herding\nregimes.\n"
    },
    {
        "paper_id": "cond-mat/0410768",
        "authors": "Rosario Bartiromo",
        "title": "Non linear behaviour of stock market volatility",
        "comments": "9 pages, 6 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We exploit a continuous time random walk description of stock prices to\nobtain a fast and accurate evaluation of their volatility from intraday data.\nWe show that financial markets are usefully described as open physical systems.\nIndeed we find that the process determining market volatility is not stationary\nwhile the market response to external volatility shocks stays constant over the\ntime period of more than two years covered by our experimental data.\nFurthermore the autocorrelation function of volatility increments yields a\nvalue of about -0.4 at one-day time lag that is nearly equal for all stocks we\nanalyze. Conditioning the evaluation of the autocorrelation function, we show\nthat the market response is non-linear and strongly stabilizing when external\nshocks push for higher volatility. This market behavior can be explained by the\naction of participants with different time horizon.\n"
    },
    {
        "paper_id": "cond-mat/0411112",
        "authors": "J.Kwapien, P.Oswiecimka and S.Drozdz",
        "title": "Components of multifractality in high-frequency stock returns",
        "comments": "to appear in Physica A",
        "journal-ref": "Physica A 350 (2005) 466-474",
        "doi": "10.1016/j.physa.2004.11.019",
        "license": null,
        "abstract": "  We analyzed multifractal properties of 5-minute stock returns from a period\nof over two years for 100 highly capitalized American companies. The two\nsources: fat-tailed probability distributions and nonlinear temporal\ncorrelations, vitally contribute to the observed multifractal dynamics of the\nreturns. For majority of the companies the temporal correlations constitute a\nmuch more significant related factor, however.\n"
    },
    {
        "paper_id": "cond-mat/0411161",
        "authors": "H.F. Coronel-Brizio, A.R. Hernandez-Montoya (Facultad de Fisica e\n  Inteligencia Artificial, Universidad Veracruzana, Xalapa Veracruz, Mexico.)",
        "title": "On fitting the Pareto-Levy distribution to stock market index data:\n  selecting a suitable cutoff value",
        "comments": "Econophysics paper. 5 pages 9 figures",
        "journal-ref": "Physica A 354 (2005) 437-449 (updated version)",
        "doi": "10.1016/j.physa.2005.03.001",
        "license": null,
        "abstract": "  The so-called Pareto-Levy or power-law distribution has been successfully\nused as a model to describe probabilities associated to extreme variations of\nworldwide stock markets indexes data and it has the form $Pr(X>x) ~ x**(-alpha)\nfor gamma< x <infinity. The selection of the threshold parameter gamma$ from\nempirical data and consequently, the determination of the exponent alpha, is\noften is done by using a simple graphical method based on a log-log scale,\nwhere a power-law probability plot shows a straight line with slope equal to\nthe exponent of the power-law distribution. This procedure can be considered\nsubjective, particularly with regard to the choice of the threshold or cutoff\nparameter gamma. In this work is presented a more objective procedure, based on\na statistical measure of discrepancy between the empirical and the Pareto-Levy\ndistribution. The technique is illustrated for data sets from the New York\nStock Exchange Index and the Mexican Stock Market Index (IPC).\n"
    },
    {
        "paper_id": "cond-mat/0411699",
        "authors": "Katja Pluto and Dirk Tasche",
        "title": "Estimating Probabilities of Default for Low Default Portfolios",
        "comments": "24 pages, LaTeX; sections on scaling and the multi-period case added",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  For credit risk management purposes in general, and for allocation of\nregulatory capital by banks in particular (Basel II), numerical assessments of\nthe credit-worthiness of borrowers are indispensable. These assessments are\nexpressed in terms of probabilities of default (PD) that should incorporate a\ncertain degree of conservatism in order to reflect the prudential risk\nmanagement style banks are required to apply. In case of credit portfolios that\ndid not at all suffer defaults, or very few defaults only over years, the\nresulting naive zero or close to zero estimates would clearly not involve such\na sufficient conservatism. As an attempt to overcome this issue, we suggest the\n\"most prudent estimation\" principle. This means to estimate the PDs by upper\nconfidence bounds while guaranteeing at the same time a PD ordering that\nrespects the differences in credit quality indicated by the rating grades. The\nmethodology is most easily applied under an assumption of independent default\nevents but can be adapted to the case of correlated defaults.\n"
    },
    {
        "paper_id": "cond-mat/0412014",
        "authors": "Kyungsik Kim, S.-M. Yoon, K. H. Chang",
        "title": "Power Law Distributions for Stock Prices in Financial Markets",
        "comments": "7 pages, 12 figures, latex",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the rank distribution, the cumulative probability, and the\nprobability density of returns of stock prices of listed firms traded in four\nstock markets. We find that the rank distribution and the cumulative\nprobability of stock prices traded in are consistent approximately with the\nZipf's law or a power law. It is also obtained that the probability density of\nnormalized returns for listed stocks almost has the form of the exponential\nfunction. Our results are compared with those of other numerical calculations.\n"
    },
    {
        "paper_id": "cond-mat/0412163",
        "authors": "R. D. Groot",
        "title": "Levy distribution and long correlation times in supermarket sales",
        "comments": "19 pages, 7 figures, accepted for publication in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2004.12.064",
        "license": null,
        "abstract": "  Sales data in a commodity market (supermarket sales to consumers) has been\nanalysed by studying the fluctuation spectrum and noise correlations. Three\nrelated products (ketchup, mayonnaise and curry sauce) have been analysed. Most\nnoise in sales is caused by promotions, but here we focus on the fluctuations\nin baseline sales. These characterise the dynamics of the market. Four hitherto\nunnoticed effects have been found that are difficult to explain from simple\neconometric models. These effects are: (1) the noise level in baseline sales is\nmuch higher than can be expected for uncorrelated sales events; (2) weekly\nbaseline sales differences are distributed according to a broad non-Gaussian\nfunction with fat tails; (3) these fluctuations follow a Levy distribution of\nexponent alpha = 1.4, similar to financial exchange markets and in stock\nmarkets; and (4) this noise is correlated over a period of 10 to 11 weeks, or\nshows an apparent power law spectrum. The similarity to stock markets suggests\nthat models developed to describe these markets may be applied to describe the\ncollective behaviour of consumers.\n"
    },
    {
        "paper_id": "cond-mat/0412411",
        "authors": "Mark McDonald, Omer Suleman, Stacy Williams, Sam Howison and Neil F.\n  Johnson (Oxford University and HSBC Bank)",
        "title": "Detecting a Currency's Dominance or Dependence using Foreign Exchange\n  Network Trees",
        "comments": null,
        "journal-ref": "Physical Review E, Vol. 72, No. 4: 046106 (2005)",
        "doi": "10.1103/PhysRevE.72.046106",
        "license": null,
        "abstract": "  In a system containing a large number of interacting stochastic processes,\nthere will typically be many non-zero correlation coefficients. This makes it\ndifficult to either visualize the system's inter-dependencies, or identify its\ndominant elements. Such a situation arises in Foreign Exchange (FX) which is\nthe world's biggest market. Here we develop a network analysis of these\ncorrelations using Minimum Spanning Trees (MSTs). We show that not only do the\nMSTs provide a meaningful representation of the global FX dynamics, but they\nalso enable one to determine momentarily dominant and dependent currencies. We\nfind that information about a country's geographical ties emerges from the raw\nexchange-rate data. Most importantly from a trading perspective, we discuss how\nto infer which currencies are `in play' during a particular period of time.\n"
    },
    {
        "paper_id": "cond-mat/0412526",
        "authors": "Lisa Borland",
        "title": "A multi-time scale non-Gaussian model of stock returns",
        "comments": "Comment added pertaining to volatility autocorrelation, clarifying\n  approximation used in calculation",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a stochastic process for stock movements that, with just one\nsource of Brownian noise, has an instantaneous volatility that rises from a\ntype of statistical feedback across many time scales. This results in a\nstationary non-Gaussian process which captures many features observed in time\nseries of real stock returns. These include volatility clustering, a kurtosis\nwhich decreases slowly over time together with a close to log-normal\ndistribution of instantaneous volatility. We calculate the rate of decay of\nvolatility-volatility correlations, which depends on the strength of the memory\nin the system and fits well to empirical observations.\n"
    },
    {
        "paper_id": "cond-mat/0412708",
        "authors": "F. Lillo, Szabolcs Mike, and J. Doyne Farmer",
        "title": "A theory for long-memory in supply and demand",
        "comments": "12 pages, 7 figures",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.71.066122",
        "license": null,
        "abstract": "  Recent empirical studies have demonstrated long-memory in the signs of orders\nto buy or sell in financial markets [2, 19]. We show how this can be caused by\ndelays in market clearing. Under the common practice of order splitting, large\norders are broken up into pieces and executed incrementally. If the size of\nsuch large orders is power law distributed, this gives rise to power law\ndecaying autocorrelations in the signs of executed orders. More specifically,\nwe show that if the cumulative distribution of large orders of volume v is\nproportional to v to the power -alpha and the size of executed orders is\nconstant, the autocorrelation of order signs as a function of the lag tau is\nasymptotically proportional to tau to the power -(alpha - 1). This is a\nlong-memory process when alpha < 2. With a few caveats, this gives a good match\nto the data. A version of the model also shows long-memory fluctuations in\norder execution rates, which may be relevant for explaining the long-memory of\nprice diffusion rates.\n"
    },
    {
        "paper_id": "cond-mat/0412723",
        "authors": "Vygintas Gontis, Bronislovas Kaulakys",
        "title": "Modelling financial markets by the multiplicative sequence of trades",
        "comments": "6 pages, 2 figures",
        "journal-ref": "Gontis V., Kaulakys B., Physica A 344 (2004) 128-133",
        "doi": "10.1016/j.physa.2004.06.153",
        "license": null,
        "abstract": "  We introduce the stochastic multiplicative point process modelling trading\nactivity of financial markets. Such a model system exhibits power-law spectral\ndensity S(f) ~ 1/f**beta, scaled as power of frequency for various values of\nbeta between 0.5 and 2. Furthermore, we analyze the relation between the\npower-law autocorrelations and the origin of the power-law probability\ndistribution of the trading activity. The model reproduces the spectral\nproperties of trading activity and explains the mechanism of power-law\ndistribution in real markets.\n"
    },
    {
        "paper_id": "cond-mat/0412754",
        "authors": "Krzysztof Urbanowicz and Janusz A. Holyst",
        "title": "Investment strategy due to the minimization of portfolio noise level by\n  observations of coarse-grained entropy",
        "comments": "6 pages, 1 figure, 1 table, Proceedings of the conference APFA4. See\n  http://www.chaosandnoise.org",
        "journal-ref": "Physica A 344, 284-288 (2004)",
        "doi": "10.1016/j.physa.2004.06.133",
        "license": null,
        "abstract": "  Using a recently developed method of noise level estimation that makes use of\nproperties of the coarse grained-entropy we have analyzed the noise level for\nthe Dow Jones index and a few stocks from the New York Stock Exchange. We have\nfound that the noise level ranges from 40 to 80 percent of the signal variance.\nThe condition of a minimal noise level has been applied to construct optimal\nportfolios from selected shares. We show that implementation of a corresponding\nthreshold investment strategy leads to positive returns for historical data.\n"
    },
    {
        "paper_id": "cond-mat/0501002",
        "authors": "Ondrej Hudak and Jana Tothova",
        "title": "Topology and Behaviour of Agents: Capital Markets",
        "comments": "14 pages, Latex, sociophysics, revised version (corrected\n  typographical errors, extended discussion). In this version contribution of\n  the author Jana Tothova was taken into account. arXiv admin note: substantial\n  text overlap with arXiv:physics/0505086",
        "journal-ref": null,
        "doi": null,
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "abstract": "  On a capital market the social group is formed from traders. Individual\nbehaviour of agents is influenced by the need to associate with other agents\nand to obtain the approval of other agents in the group. Making decisions an\nindividual equates own needs with those of the other agents. Any two agents\nfrom the group may interact. The interaction consists of the exchange of\ninformation and it costs some money. We assume that agents give reference to\nthe origin of the information if asked by other agents. Thus the agent may\nverify obtained private information. Hudak recently used methods described by\nRivier to study social behaviour of such agents. He characterized the quantity\nwhich corresponds to verification of information. Quantity which characterizes\nverification of information contributes to an aversion of an agent with respect\nto a risk. The mix of investments of an agent in a given cell with an average\nmeasure A of risk aversion in the cell is found from minimum of the average per\ncell aim function $<FM>$. Absolute minimum corresponds to such a state in which\nthere is an optimal mix of the exchange of information for a given expectations\nabout the capital market. The crowd and personal /$\\approx <f>$/ contributions\nto the risk aversion of an agent are present in the aversion constant A. We\nhave discussed a stable and metastable states of the market for different\nvalues of E, an expected return for a given investment period, of EV, an\nexpected risk for a given investment period, and of b, a constant which\ncharacterizes contribution of the quantity $<f>$ to the risk aversion. Variance\nof n for the distribution of nonreducibile subgroups is found. Our model\ndescribes intermediary process effects.\n"
    },
    {
        "paper_id": "cond-mat/0501057",
        "authors": "Franco Busetti",
        "title": "Metaheuristic Approaches to Realistic Portfolio Optimization",
        "comments": "93 pages, 17 tables, 26 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We investigate the application of two heuristic methods, genetic algorithms\nand tabu/scatter search, to the optimisation of realistic portfolios. The model\nis based on the classical mean-variance approach, but enhanced with floor and\nceiling constraints, cardinality constraints and nonlinear transaction costs\nwhich include a substantial illiquidity premium.\n  It is shown that genetic algorithms can optimise such portfolios effectively\nand within reasonable times. This approach also copes easily with extensive\nmodifications such as the addition of more intricate constraints, discontinuous\nvariables and more complex objective functions.\n  The results indicate that that both floor and ceiling constraints have a\nsubstantial negative impact on portfolio performance and should be examined\ncritically. Another insight is that nonlinear transaction costs which are\ncomparable in magnitude to forecast returns will tend to diversify portfolios;\nthe effect of these costs on portfolio risk is, however, ambiguous, depending\non the degree of diversification required for cost reduction. The number of\nassets in a portfolio invariably increases as a result of constraints, costs\nand their combination.\n  The implementation of cardinality constraints is essential for finding the\nbest-performing portfolio. The ability of the heuristic method to deal with\ncardinality constraints is one of its most powerful features.\n"
    },
    {
        "paper_id": "cond-mat/0501261",
        "authors": "Enrico Scalas",
        "title": "Five Years of Continuous-time Random Walks in Econophysics",
        "comments": "14 pages. Paper presented at WEHIA 2004, Kyoto, Japan",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper is a short review on the application of continuos-time random\nwalks to Econophysics in the last five years.\n"
    },
    {
        "paper_id": "cond-mat/0501292",
        "authors": "Lisa Borland, Jean-Philippe Bouchaud, Jean-Francois Muzy, Gilles\n  Zumbach",
        "title": "The Dynamics of Financial Markets -- Mandelbrot's multifractal cascades,\n  and beyond",
        "comments": "24 pages, to appear in Wilmott Magazine special issue for Mandelbrot",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This is a short review in honor of B. Mandelbrot's 80st birthday, to appear\nin W ilmott magazine. We discuss how multiplicative cascades and related\nmultifractal ideas might be relevant to model the main statistical features of\nfinancial time series, in particular the intermittent, long-memory nature of\nthe volatility. We describe in details the Bacry-Muzy-Delour multifractal\nrandom walk. We point out some inadequacies of the current models, in\nparticular concerning time reversal symmetry, and propose an alternative family\nof multi-timescale models, intermediate between GARCH models and multifractal\nmodels, that seem quite promising.\n"
    },
    {
        "paper_id": "cond-mat/0501320",
        "authors": "Enrico Scalas",
        "title": "Basel II for Physicists: A Discussion Paper",
        "comments": "9 pages. This is a discussion paper reporting the opinions of the\n  author on the future role of physicists in the banking sector",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  On June 26th, 2004, Central bank governors and the heads of bank supervisory\nauthorities in the Group of Ten (G10) countries issued a press release and\nendorsed the publication of \"International Convergence of Capital Measurement\nand Capital Standards: a Revised Framework\", the new capital adequacy framework\ncommonly known as Basel II. According to Jean Claude Trichet, Chairman of the\nG10 group of central bank governors and heads of bank supervisory authorities\nand President of the European Central Bank: ``Basel II embraces a comprehensive\napproach to risk management and bank supervision. It will enhance banks' safety\nand soundness, strengthen the stability of the financial system as a whole, and\nimprove the financial sector's ability to serve as a source for sustainable\ngrowth for the broader economy.'' The negotial process is likely to lead to the\nadoption of the new rules within 2007. In 1996, after the \"Amendment to the\ncapital accord to incorporate market risks\", a new wave of physicists entered\nrisk management offices of large banks, that had to develop internal models of\nmarket risk. Which will be the challenges and opportunities for physicists in\nthe financial sector in the years to come? This paper is a first modest\ncontribution for starting a debate within the Econophysics community.\n"
    },
    {
        "paper_id": "cond-mat/0501325",
        "authors": "Robert Kitt and Jaan Kalda",
        "title": "Scaling analysis of multivariate intermittent time series",
        "comments": "16 pages, 5 figures, accepted for publication in Physica A",
        "journal-ref": "Physica A, 353, 2005, 480",
        "doi": "10.1016/j.physa.2005.01.038",
        "license": null,
        "abstract": "  The scaling properties of the time series of asset prices and trading volumes\nof stock markets are analysed. It is shown that similarly to the asset prices,\nthe trading volume data obey multi-scaling length-distribution of\nlow-variability periods. In the case of asset prices, such scaling behaviour\ncan be used for risk forecasts: the probability of observing next day a large\nprice movement is (super-universally) inversely proportional to the length of\nthe ongoing low-variability period. Finally, a method is devised for a\nmulti-factor scaling analysis. We apply the simplest, two-factor model to\nequity index and trading volume time series.\n"
    },
    {
        "paper_id": "cond-mat/0501395",
        "authors": "Lisa Borland, Jeremy Evnine and Benoit Pochart",
        "title": "A Merton-Like Approach to Pricing Debt based on a non-Gaussian Asset\n  Model",
        "comments": "Contribution to the Workshop on Complexity, Metastability and\n  Nonextensivity, Erice 2004",
        "journal-ref": null,
        "doi": "10.1142/9789812701558_0035",
        "license": null,
        "abstract": "  This paper is a contribution to the Proceedings of the Workshop\n  Complexity, Metastability and Nonextensivity held in Erice 20-26 July 2004,\nto be published by World Scientific. We propose a generalization to Merton's\nmodel for evaluating credit spreads. In his original work, a company's assets\nwere assumed to follow a log-normal process. We introduce fat tails and skew\ninto this model, along the same lines as in the option pricing model of Borland\nand Bouchaud (2004, Quantitative Finance 4) and illustrate the effects of each\ncomponent. Preliminary empirical results indicate that this model fits well to\nempirically observed credit spreads with a parameterization that also matched\nobserved stock return distributions and option prices.\n"
    },
    {
        "paper_id": "cond-mat/0501413",
        "authors": "Arnab Chatterjee, Bikas K. Chakrabarti and Robin B. Stinchcombe",
        "title": "Master equation for a kinetic model of trading market and its analytic\n  solution",
        "comments": "6 pages, 2 eps figures, RevTeX4, corrected final version",
        "journal-ref": "Phys. Rev. E 72 (2005) 026126",
        "doi": "10.1103/PhysRevE.72.026126",
        "license": null,
        "abstract": "  We analyze an ideal gas like model of a trading market with quenched random\nsaving factors for its agents and show that the steady state income ($m$)\ndistribution $P(m)$ in the model has a power law tail with Pareto index $\\nu$\nexactly equal to unity, confirming the earlier numerical studies on this model.\nThe analysis starts with the development of a master equation for the time\ndevelopment of $P(m)$. Precise solutions are then obtained in some special\ncases.\n"
    },
    {
        "paper_id": "cond-mat/0501513",
        "authors": "M. Bartolozzi, S. Drozdz, D.B. Leinweber, J. Speth, A. W. Thomas",
        "title": "Self-Similar Log-Periodic Structures in Western Stock Markets from 2000",
        "comments": "17 pages, 14 figures. International Journal of Modern Physics C, in\n  press",
        "journal-ref": null,
        "doi": "10.1142/S0129183105007972",
        "license": null,
        "abstract": "  The presence of log-periodic structures before and after stock market crashes\nis considered to be an imprint of an intrinsic discrete scale invariance (DSI)\nin this complex system. The fractal framework of the theory leaves open the\npossibility of observing self-similar log-periodic structures at different time\nscales. In the present work we analyze the daily closures of three of the most\nimportant indices worldwide since 2000: the DAX for Germany and the Nasdaq100\nand the S&P500 for the United States. The qualitative behaviour of these\ndifferent markets is similar during the temporal frame studied. Evidence is\nfound for decelerating log-periodic oscillations of duration about two years\nand starting in September 2000. Moreover, a nested sub-structure starting in\nMay 2002 is revealed, bringing more evidence to support the hypothesis of\nself-similar, log-periodic behavior. Ongoing log-periodic oscillations are also\nrevealed. A Lomb analysis over the aforementioned periods indicates a\npreferential scaling factor $\\lambda \\sim 2$. Higher order harmonics are also\npresent. The spectral pattern of the data has been found to be similar to that\nof a Weierstrass-type function, used as a prototype of a log-periodic fractal\nfunction.\n"
    },
    {
        "paper_id": "cond-mat/0501639",
        "authors": "Jaume Masoliver and Josep Perello",
        "title": "Multiple time scales and the exponential Ornstein-Uhlenbeck stochastic\n  volatility model",
        "comments": "24 pages, 9 colored figures, Workshop Volatility of Financial Markets\n  (Leiden 18-29 October 2004)",
        "journal-ref": "Quantitative Finance 6, 423-433 (2006)",
        "doi": "10.1080/14697680600727547",
        "license": null,
        "abstract": "  We study the exponential Ornstein-Uhlenbeck stochastic volatility model and\nobserve that the model shows a multiscale behavior in the volatility\nautocorrelation. It also exhibits a leverage correlation and a probability\nprofile for the stationary volatility which are consistent with market\nobservations. All these features make the model quite appealing since it\nappears to be more complete than other stochastic volatility models also based\non a two-dimensional diffusion. We finally present an approximate solution for\nthe return probability density designed to capture the kurtosis and skewness\neffects.\n"
    },
    {
        "paper_id": "cond-mat/0501699",
        "authors": "Gilles Zumbach",
        "title": "Volatility conditional on price trends",
        "comments": "19 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The influence of the past price behaviour on the realized volatility is\ninvestigated in the present article. The results show that trending (drifting)\nprices lead to increased (decreased) realized volatility. This ``volatility\ninduced by trend'' constitutes a new stylized fact. The past price behaviour is\nmeasured by a product of 2 non overlapping returns, of the form r L[r] where L\nis the lag operator. The effect is studied empirically using USD/CHF foreign\nexchange data, in a large range of time horizons. A set of ARCH based processes\nare modified in order to include the trend effect, and their forecasting\nperformances are compared. For a better forecast, it is shown that the main\nfactor is the shape of the memory kernel (i.e. power law), and the following\nfactor is the inclusion of the trend effect.\n"
    },
    {
        "paper_id": "cond-mat/0502029",
        "authors": "Stephanos Panayides",
        "title": "Arbitrage Opportunities and their Implications to Derivative Hedging",
        "comments": "10 pages, 2 figures added references, corrected typos",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2005.06.077",
        "license": null,
        "abstract": "  We explore the role that random arbitrage opportunities play in hedging\nfinancial derivatives. We extend the asymptotic pricing theory presented by\nFedotov and Panayides [Stochastic arbitrage return and its implication for\noption pricing, Physica A 345 (2005), 207-217] for the case of hedging a\nderivative when arbitrage opportunities are present in the market. We restrict\nourselves to finding hedging confidence intervals that can be adapted to the\namount of arbitrage risk an investor will permit to be exposed to. The\nresulting hedging bands are independent of the detailed statistical\ncharacteristics of the arbitrage opportunities.\n"
    },
    {
        "paper_id": "cond-mat/0502151",
        "authors": "Silvio M. Duarte Queiros and Constantino Tsallis",
        "title": "On the connection between financial processes with stochastic volatility\n  and nonextensive statistical mechanics",
        "comments": null,
        "journal-ref": "Eur. Phys. J. B 48, 139--148 (2005)",
        "doi": "10.1140/epjb/e2005-00366-1",
        "license": null,
        "abstract": "  The $GARCH$ algorithm is the most renowned generalisation of Engle's original\nproposal for modelising {\\it returns}, the $ARCH$ process. Both cases are\ncharacterised by presenting a time dependent and correlated variance or {\\it\nvolatility}. Besides a memory parameter, $b$, (present in $ARCH$) and an\nindependent and identically distributed noise, $\\omega $, $GARCH$ involves\nanother parameter, $c$, such that, for $c=0$, the standard $ARCH$ process is\nreproduced. In this manuscript we use a generalised noise following a\ndistribution characterised by an index $q_{n}$, such that $q_{n}=1$ recovers\nthe Gaussian distribution. Matching low statistical moments of $GARCH$\ndistribution for returns with a $q$-Gaussian distribution obtained through\nmaximising the entropy $S_{q}=\\frac{1-\\sum_{i}p_{i}^{q}}{q-1}$, basis of\nnonextensive statistical mechanics, we obtain a sole analytical connection\nbetween $q$ and $(b,c,q_{n}) $ which turns out to be remarkably good when\ncompared with computational simulations. With this result we also derive an\nanalytical approximation for the stationary distribution for the (squared)\nvolatility. Using a generalised Kullback-Leibler relative entropy form based on\n$S_{q}$, we also analyse the degree of dependence between successive returns,\n$z_{t}$ and $z_{t+1}$, of GARCH(1,1) processes. This degree of dependence is\nquantified by an entropic index, $q^{op}$. Our analysis points the existence of\na unique relation between the three entropic indexes $q^{op}$, $q$ and $q_{n}$\nof the problem, independent of the value of $(b,c)$.\n"
    },
    {
        "paper_id": "cond-mat/0502166",
        "authors": "Sitabhra Sinha",
        "title": "Evidence for Power-law tail of the Wealth Distribution in India",
        "comments": "8 pages, 3 figures",
        "journal-ref": "Physica A, Vol 359, pp 555-562 (2006)",
        "doi": "10.1016/j.physa.2005.02.092",
        "license": null,
        "abstract": "  The higher-end tail of the wealth distribution in India is studied using\nrecently published lists of the wealth of richest Indians between the years\n2002-4. The resulting rank distribution seems to imply a power-law tail for the\nwealth distribution, with a Pareto exponent between 0.81 and 0.92 (depending on\nthe year under analysis). This provides a comparison with previous studies of\nwealth distribution, which have all been confined to Western advanced\ncapitalist economies. We conclude with a discussion on the appropriateness of\nmultiplicative stochastic process as a model for asset accumulation, the\nrelation between the wealth and income distributions (we estimate the Pareto\nexponent for the latter to be around 1.5 for India), as well as possible\nsources of error in measuring the Pareto exponent for wealth.\n"
    },
    {
        "paper_id": "cond-mat/0502337",
        "authors": "Silvio M. Duarte Queiros",
        "title": "On the distribution of high-frequency stock market traded volume: a\n  dynamical scenario",
        "comments": null,
        "journal-ref": "Europhys. Lett., 71 (3), 339--345 (2005)",
        "doi": "10.1209/epl/i2005-10109-0",
        "license": null,
        "abstract": "  This manuscript reports a stochastic dynamical scenario whose associated\nstationary probability density function is exactly a previously proposed one to\nadjust high-frequency traded volume distributions. This dynamical conjecture,\nphysically connected to superstatiscs, which is intimately related with the\ncurrent nonextensive statistical mechanics framework, is based on the idea of\nlocal fluctuations in the mean traded volume associated to financial markets\nagents herding behaviour. The corroboration of this mesoscopic model is done by\nmodelising NASDAQ 1 and 2 minute stock market traded volume.\n"
    },
    {
        "paper_id": "cond-mat/0502662",
        "authors": "Andrea De Martino and Matteo Marsili",
        "title": "On the interplay between fluctuations and efficiency in a model economy\n  with heterogeneous adaptive consumers",
        "comments": "prepared for the proceedings of Fluctuations and Noise 2005",
        "journal-ref": null,
        "doi": "10.1117/12.618904",
        "license": null,
        "abstract": "  We discuss the stationary states of a model economy in which $N$\nheterogeneous adaptive consumers purchase commodity bundles repeatedly from $P$\nsellers. The system undergoes a transition from an inefficient to an efficient\nstate as the number of consumers increases. In the latter phase, however, price\nfluctuations may be much larger than in the inefficient regime. Results from\ndynamical mean-field theory obtained for $N\\to\\infty$ compare fairly well with\ncomputer simulations.\n"
    },
    {
        "paper_id": "cond-mat/0503156",
        "authors": "Tetsuya Takaishi",
        "title": "Simulations of financial markets in a Potts-like model",
        "comments": "8 pages, 5 figures",
        "journal-ref": "Int. J. Mod. Phys. C 16, 1311 (2005)",
        "doi": "10.1142/S0129183105007923",
        "license": null,
        "abstract": "  A three-state model based on the Potts model is proposed to simulate\nfinancial markets. The three states are assigned to \"buy\", \"sell\" and\n\"inactive\" states. The model shows the main stylized facts observed in the\nfinancial market: fat-tailed distributions of returns and long time\ncorrelations in the absolute returns. At low inactivity rate, the model\neffectively reduces to the two-state model of Bornholdt and shows similar\nresults to the Bornholdt model. As the inactivity increases, we observe the\nexponential distributions of returns.\n"
    },
    {
        "paper_id": "cond-mat/0503532",
        "authors": "A.C.C. Coolen",
        "title": "Reply to cond-mat/0503325: Comment on `Generating functional analysis of\n  Minority Games with real merket histories' by KH Ho, WC Man, FK Chow and HF\n  Chau",
        "comments": "1 page of LaTeX",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Comment cond-mat/0503325 is built around two core statements, both of\nwhich are plainly incorrect.\n"
    },
    {
        "paper_id": "cond-mat/0503607",
        "authors": "Didier Sornette (CNRS-Univ. Nice and UCLA), Wei-Xing Zhou (ECUST)",
        "title": "Importance of Positive Feedbacks and Over-confidence in a\n  Self-Fulfilling Ising Model of Financial Markets",
        "comments": "44 Elsart Latex Pages including 15 figures",
        "journal-ref": "Physica A 370, 704-726 (2006)",
        "doi": "10.1016/j.physa.2006.02.022",
        "license": null,
        "abstract": "  Following a long tradition of physicists who have noticed that the Ising\nmodel provides a general background to build realistic models of social\ninteractions, we study a model of financial price dynamics resulting from the\ncollective aggregate decisions of agents. This model incorporates imitation,\nthe impact of external news and private information. It has the structure of a\ndynamical Ising model in which agents have two opinions (buy or sell) with\ncoupling coefficients which evolve in time with a memory of how past news have\nexplained realized market returns. We study two versions of the model, which\ndiffer on how the agents interpret the predictive power of news. We show that\nthe stylized facts of financial markets are reproduced only when agents are\nover-confident and mis-attribute the success of news to predict return to\nherding effects, thereby providing positive feedbacks leading to the model\nfunctioning close to the critical point. Our model exhibits a rich multifractal\nstructure characterized by a continuous spectrum of exponents of the power law\nrelaxation of endogenous bursts of volatility, in good agreement with previous\nanalytical predictions obtained with the multifractal random walk model and\nwith empirical facts.\n"
    },
    {
        "paper_id": "cond-mat/0503762",
        "authors": "A. Tedeschi, A. De Martino, I. Giardina",
        "title": "Coordination, intermittency and trends in generalized Minority Games",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/j.physa.2005.04.020",
        "license": null,
        "abstract": "  The Minority Game framework was recently generalized to account for the\npossibility that agents adapt not only through strategy selection but also by\ndiversifying their response according to the kind of dynamical regime, or the\nrisk, they perceive. Here we study the effects of this mechanism in different\ninformation structures. We show that both the stationary macroscopic properties\nand the dynamical features depend strongly on whether the information supplied\nto the system is exogenous (`random') or endogenous (`real'). In particular, in\nthe latter case one observes that a small amount of herding tendency suffices\nto alter the collective behavior dramatically. In such cases, the dynamics is\ncharacterized by the creation and destruction of trends, accompanied by\nintermittent features like volatility clustering.\n"
    },
    {
        "paper_id": "cond-mat/0508122",
        "authors": "C. Coronnello, M. Tumminello, F. Lillo, S. Miccich\\`e and R.N.\n  Mantegna",
        "title": "Sector identification in a set of stock return time series traded at the\n  London Stock Exchange",
        "comments": "28 pages, 13 figures, 3 Tables. Proceedings of the conference on\n  \"Applications of Random Matrices to Economy and other Complex Systems\",\n  Krakow (Poland), May 25-28 2005. Submitted for pubblication to Acta Phys. Pol",
        "journal-ref": "Acta Phys. Pol. B 36 (2005) 2653-2679",
        "doi": null,
        "license": null,
        "abstract": "  We compare some methods recently used in the literature to detect the\nexistence of a certain degree of common behavior of stock returns belonging to\nthe same economic sector. Specifically, we discuss methods based on random\nmatrix theory and hierarchical clustering techniques. We apply these methods to\na portfolio of stocks traded at the London Stock Exchange. The investigated\ntime series are recorded both at a daily time horizon and at a 5-minute time\nhorizon. The correlation coefficient matrix is very different at different time\nhorizons confirming that more structured correlation coefficient matrices are\nobserved for long time horizons. All the considered methods are able to detect\neconomic information and the presence of clusters characterized by the economic\nsector of stocks. However different methods present a different degree of\nsensitivity with respect to different sectors. Our comparative analysis\nsuggests that the application of just a single method could not be able to\nextract all the economic information present in the correlation coefficient\nmatrix of a stock portfolio.\n"
    },
    {
        "paper_id": "cond-mat/0508413",
        "authors": "Tobias Galla, David Sherrington",
        "title": "Stationary states of a spherical Minority Game with ergodicity breaking",
        "comments": "26 pages, 8 figures; typo corrected",
        "journal-ref": "J. Stat. Mech. (2005) P10009",
        "doi": "10.1088/1742-5468/2005/10/P10009",
        "license": null,
        "abstract": "  Using generating functional and replica techniques, respectively, we study\nthe dynamics and statics of a spherical Minority Game (MG), which in contrast\nwith a spherical MG previously presented in J.Phys A: Math. Gen. 36 11159\n(2003) displays a phase with broken ergodicity and dependence of the\nmacroscopic stationary state on initial conditions. The model thus bears more\nsimilarity with the original MG. Still, all order parameters including the\nvolatility can computed in the ergodic phases without making any\napproximations. We also study the effects of market impact correction on the\nphase diagram. Finally we discuss a continuous-time version of the model as\nwell as the differences between on-line and batch update rules. Our analytical\nresults are confirmed convincingly by comparison with numerical simulations. In\nan appendix we extend the analysis of the earlier spherical MG to a model with\ngeneral time-step, and compare the dynamics and statics of the two spherical\nmodels.\n"
    },
    {
        "paper_id": "cond-mat/0508451",
        "authors": "Z. Burda, J. Jurkiewicz, B. Waclaw",
        "title": "Eigenvalue density of empirical covariance matrix for correlated samples",
        "comments": "12 pages, 5 figures, to appear in Acta Phys. Pol. B (Proceedings of\n  the conference on `Applications of Random Matrix Theory to Economy and Other\n  Complex Systems', May 25-28, 2005, Cracow, Poland",
        "journal-ref": "Acta Phys. Pol. B36, 2641 (2005)",
        "doi": null,
        "license": null,
        "abstract": "  We describe a method to determine the eigenvalue density of empirical\ncovariance matrix in the presence of correlations between samples. This is a\nstraightforward generalization of the method developed earlier by the authors\nfor uncorrelated samples. The method allows for exact determination of the\nexperimental spectrum for a given covariance matrix and given correlations\nbetween samples in the limit of large N and N/T=r=const with N being the number\nof degrees of freedom and T being the number of samples. We discuss the effect\nof correlations on several examples.\n"
    },
    {
        "paper_id": "cond-mat/0510154",
        "authors": "G. Bonanno, D. Valenti, B. Spagnolo",
        "title": "Role of Noise in a Market Model with Stochastic Volatility",
        "comments": "13 pages, 6 figures, Eur. Phys. J. B, in press",
        "journal-ref": null,
        "doi": "10.1140/epjb/e2006-00388-1",
        "license": null,
        "abstract": "  We study a generalization of the Heston model, which consists of two coupled\nstochastic differential equations, one for the stock price and the other one\nfor the volatility. We consider a cubic nonlinearity in the first equation and\na correlation between the two Wiener processes, which model the two white noise\nsources. This model can be useful to describe the market dynamics characterized\nby different regimes corresponding to normal and extreme days. We analyze the\neffect of the noise on the statistical properties of the escape time with\nreference to the noise enhanced stability (NES) phenomenon, that is the noise\ninduced enhancement of the lifetime of a metastable state. We observe NES\neffect in our model with stochastic volatility. We investigate the role of the\ncorrelation between the two noise sources on the NES effect.\n"
    },
    {
        "paper_id": "cond-mat/0510693",
        "authors": "Hiroshi Yamamoto, Toshiya Ohtsuki, Akihiro Fujihara, Satoshi Tanimoto,\n  Keizo Yamamoto and Sasuke Miyazima",
        "title": "Asymptotic analysis of the model for distribution of high-tax payers",
        "comments": "5pages, 3figures",
        "journal-ref": "Japan J. Indust. Appl. Math. 24, 211-218 (2007).",
        "doi": "10.1088/1742-6596/31/1/009",
        "license": null,
        "abstract": "  The z-transform technique is used to investigate the model for distribution\nof high-tax payers, which is proposed by two of the authors (K. Y and S. M) and\nothers. Our analysis shows an asymptotic power-law of this model with the\nexponent -5/2 when a total ``mass'' has a certain critical value. Below the\ncritical value, the system exhibits an ordinary critical behavior, and scaling\nrelations hold. Above the threshold, numerical simulations show that a\npower-law distribution coexists with a huge ``monopolized'' member. It is\nargued that these behaviors are observed universally in conserved aggregation\nprocesses, by analizing an extended model.\n"
    },
    {
        "paper_id": "cond-mat/0512308",
        "authors": "David Sherrington",
        "title": "The Minority Game: a statistical physics perspective",
        "comments": "6 pages, 2 figures. Submitted for publication in the proceedings of\n  the Econophysics Colloquium, Canberra, Australia (November 2005)",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2006.04.039",
        "license": null,
        "abstract": "  A brief review is given of the minority game, an idealized model stimulated\nby a market of speculative agents, and its complex many-body behaviour.\nParticular consideration is given to analytic results for the model rather than\ndiscussions of its relevance in real-world situations.\n"
    },
    {
        "paper_id": "cond-mat/0601279",
        "authors": "K. B. K. Mayya and R. E. Amritkar",
        "title": "Analysis of delay correlation matrices",
        "comments": "4 pages, 5 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We construct and analyze symmetrized delay correlation matrices for empirical\ndata sets for atmopheric and financial data to derive information about\ncorrelation between different entities of the time series over time. The\ninformation about correlations is obtained by comparing the results for the\neigenvalue distribution with the analytical results for the independent,\nidentically distributed random data sets. For the atmospheric case we find long\nterm correlations between different entities of the multivariable time series.\nFor the financial time series we find little correlations between different\nentities over a time delay beyond about two days. Most of the eigenvalues for\nthe symmetrized delay correlation matrices for the financial data are\nsymmetrically distributed about zero. The delay correlation results for the\nfinancial data are similar to the analytical results for the random data sets.\nHowever there are considerable deviations for the atmospheric data from the\nrandom case.\n"
    },
    {
        "paper_id": "cond-mat/0602316",
        "authors": "Kevin E. Bassler, Gemunu H. Gunaratne, Joseph L. McCauley",
        "title": "Markov Processes, Hurst Exponents, and Nonlinear Diffusion Equations\n  with application to finance",
        "comments": "to appear in Physica A",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2006.01.081",
        "license": null,
        "abstract": "  We show by explicit closed form calculations that a Hurst exponent H that is\nnot 1/2 does not necessarily imply long time correlations like those found in\nfractional Brownian motion. We construct a large set of scaling solutions of\nFokker-Planck partial differential equations where H is not 1/2. Thus Markov\nprocesses, which by construction have no long time correlations, can have H not\nequal to 1/2. If a Markov process scales with Hurst exponent H then it simply\nmeans that the process has nonstationary increments. For the scaling solutions,\nwe show how to reduce the calculation of the probability density to a single\nintegration once the diffusion coefficient D(x,t) is specified. As an example,\nwe generate a class of student-t-like densities from the class of quadratic\ndiffusion coefficients. Notably, the Tsallis density is one member of that\nlarge class. The Tsallis density is usually thought to result from a nonlinear\ndiffusion equation, but instead we explicitly show that it follows from a\nMarkov process generated by a linear Fokker-Planck equation, and therefore from\na corresponding Langevin equation. Having a Tsallis density with H not equal to\n1/2 therefore does not imply dynamics with correlated signals, e.g., like those\nof fractional Brownian motion. A short review of the requirements for\nfractional Brownian motion is given for clarity, and we explain why the usual\nsimple argument that H unequal to 1/2 implies correlations fails for Markov\nprocesses with scaling solutions. Finally, we discuss the question of scaling\nof the full Green function g(x,t;x',t') of the Fokker-Planck pde.\n"
    },
    {
        "paper_id": "cond-mat/0603134",
        "authors": "Ginestra Bianconi, Tobias Galla and Matteo Marsili",
        "title": "Effects of Tobin Taxes in Minority Game markets",
        "comments": "(9 pages,6 figures)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We show that the introduction of Tobin taxes in agent-based models of\ncurrency markets can lead to a reduction of speculative trading and reduce the\nmagnitude of exchange rate fluctuations at intermediate tax rates. In this\nregime revenues for the market maker obtained from speculators are maximal. We\nhere focus on Minority Game models of markets, which are accessible by exact\ntechniques from statistical mechanics. Results are supported by computer\nsimulations. Our findings suggest that at finite systems sizes the effect is\nmost pronounced in a critical region around the phase transition of the\ninfinite system, but much weaker if the market is operating far from\ncriticality and does not exhibit anomalous fluctuations.\n"
    },
    {
        "paper_id": "cond-mat/0605623",
        "authors": "Tobias Galla, Michele Leone, Matteo Marsili, Mauro Sellitto, Martin\n  Weigt, Riccardo Zecchina",
        "title": "Statistical mechanics of combinatorial auctions",
        "comments": "4 pages, 4 figures, minor changes, references added. To appear on PRL",
        "journal-ref": "Phys. Rev. Lett. 97, 128701 (2006)",
        "doi": "10.1103/PhysRevLett.97.128701",
        "license": null,
        "abstract": "  Combinatorial auctions are formulated as frustrated lattice gases on sparse\nrandom graphs, allowing the determination of the optimal revenue by methods of\nstatistical physics. Transitions between computationally easy and hard regimes\nare found and interpreted in terms of the geometric structure of the space of\nsolutions. We introduce an iterative algorithm to solve intermediate and large\ninstances, and discuss competing states of optimal revenue and maximal number\nof satisfied bidders. The algorithm can be generalized to the hard phase and to\nmore sophisticated auction protocols.\n"
    },
    {
        "paper_id": "cond-mat/0607478",
        "authors": "Andreia Dionisio, Rui Menezes and Diana A. Mendes",
        "title": "On the integrated behaviour of non-stationary volatility in stock\n  markets",
        "comments": "10 pages, 3 figures. Paper presented in the APFA 5 conference",
        "journal-ref": null,
        "doi": "10.1016/j.physa.2007.02.008",
        "license": null,
        "abstract": "  This paper analyses the behaviour of volatility for several international\nstock market indexes, namely the SP 500 (USA), the Nikkei (Japan), the PSI 20\n(Portugal), the CAC 40 (France), the DAX 30 (Germany), the FTSE 100 (UK), the\nIBEX 35 (Spain) and the MIB 30 (Italy), in the context of non-stationarity. Our\nempirical results point to the evidence of the existence of integrated\nbehaviour among several of those stock market indexes of different dimensions.\nIt seems, therefore, that the behaviour of these markets tends to some\nuniformity, which can be interpreted as the existence of a similar behaviour\nfacing to shocks that may affect the worldwide economy. Whether this is a cause\nor a consequence of market globalization is an issue that may be stressed in\nfuture work.\n"
    },
    {
        "paper_id": "cond-mat/0610022",
        "authors": "Simone Bianco",
        "title": "Detecting long and short memory via spectral methods",
        "comments": "8 pages, 2 fiures. Submitted to Physica A",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the properties of memory of a financial time series adopting two\ndifferent methods of analysis, the detrended fluctuation analysis (DFA) and the\nanalysis of the power spectrum (PSA). The methods are applied on three time\nseries: one of high-frequency returns, one of shuffled returns and one of\nabsolute values of returns. We prove that both DFA and PSA give results in line\nwith those obtained with standard econometrics measures of correlation.\n"
    },
    {
        "paper_id": "cond-mat/0612077",
        "authors": "Giovanni Bonanno, Davide Valenti and Bernardo Spagnolo",
        "title": "Mean Escape Time in a System with Stochastic Volatility",
        "comments": "9 pages, 9 figures, to be published in Phys. Rev. E",
        "journal-ref": null,
        "doi": "10.1103/PhysRevE.75.016106",
        "license": null,
        "abstract": "  We study the mean escape time in a market model with stochastic volatility.\nThe process followed by the volatility is the Cox Ingersoll and Ross process\nwhich is widely used to model stock price fluctuations. The market model can be\nconsidered as a generalization of the Heston model, where the geometric\nBrownian motion is replaced by a random walk in the presence of a cubic\nnonlinearity. We investigate the statistical properties of the escape time of\nthe returns, from a given interval, as a function of the three parameters of\nthe model. We find that the noise can have a stabilizing effect on the system,\nas long as the global noise is not too high with respect to the effective\npotential barrier experienced by a fictitious Brownian particle. We compare the\nprobability density function of the return escape times of the model with those\nobtained from real market data. We find that they fit very well.\n"
    },
    {
        "paper_id": "cond-mat/0702517",
        "authors": "Joseph L. McCauley",
        "title": "Fokker-Planck and Chapman-Kolmogorov equations for Ito processes with\n  finite memory",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1007/978-1-4020-8761-5_8",
        "license": null,
        "abstract": "  The usual derivation of the Fokker-Planck partial differential eqn. assumes\nthe Chapman-Kolmogorov equation for a Markov process. Starting instead with an\nIto stochastic differential equation we argue that finitely many states of\nmemory are allowed in Kolmogorov's two pdes, K1 (the backward time pde) and K2\n(the Fokker-Planck pde), and show that a Chapman-Kolmogorov eqn. follows as\nwell. We adapt Friedman's derivation to emphasize that finite memory is not\nexcluded. We then give an example of a Gaussian transition density with 1 state\nmemory satisfying both K1, K2, and the Chapman-Kolmogorov eqns. We begin the\npaper by explaining the meaning of backward diffusion, and end by using our\ninterpretation to produce a new, short proof that the Green function for the\nBlack-Scholes pde describes a Martingale in the risk neutral discounted stock\nprice.\n"
    },
    {
        "paper_id": "cond-mat/0702607",
        "authors": "Ryszard Zygad{\\l}o",
        "title": "Geometrical Brownian Motion Driven by Color Noise",
        "comments": "presented at FENS, 2006, Cracow, April 22",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The evolution of prices on ideal market is given by geometrical Brownian\nmotion, where Gaussian white noise describes fluctuations. We study the effect\nof correlations introduced by a color noise.\n"
    },
    {
        "paper_id": "cond-mat/9702082",
        "authors": "L.A.N. Amaral, S.V. Buldyrev, S. Havlin, H. Leschhorn, P. Maass, M.A.\n  Salinger, H.E. Stanley, and M.H.R. Stanley",
        "title": "Scaling behavior in economics: I. Empirical results for company growth",
        "comments": "16 pages LateX, RevTeX 3, 10 figures, to appear J. Phys. I France\n  (April 1997)",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We address the question of the growth of firm size. To this end, we analyze\nthe Compustat data base comprising all publicly-traded United States\nmanufacturing firms within the years 1974-1993. We find that the distribution\nof firm sizes remains stable for the 20 years we study, i.e., the mean value\nand standard deviation remain approximately constant. We study the distribution\nof sizes of the ``new'' companies in each year and find it to be well\napproximated by a log-normal. We find (i) the distribution of the logarithm of\nthe growth rates, for a fixed growth period of one year, and for companies with\napproximately the same size $S$ displays an exponential form, and (ii) the\nfluctuations in the growth rates -- measured by the width of this distribution\n$\\sigma_1$ -- scale as a power law with $S$, $\\sigma_1\\sim S^{-\\beta}$. We find\nthat the exponent $\\beta$ takes the same value, within the error bars, for\nseveral measures of the size of a company. In particular, we obtain:\n$\\beta=0.20\\pm0.03$ for sales, $\\beta=0.18\\pm0.03$ for number of employees,\n$\\beta=0.18\\pm0.03$ for assets, $\\beta=0.18\\pm0.03$ for cost of goods sold, and\n$\\beta=0.20\\pm0.03$ for property, plant, & equipment.\n"
    },
    {
        "paper_id": "cond-mat/9702085",
        "authors": "S.V. Buldyrev, L.A.N. Amaral, S. Havlin, H. Leschhorn, P. Maass, M.A.\n  Salinger, H.E. Stanley, and M.H.R. Stanley",
        "title": "Scaling behavior in economics: II. Modeling of company growth",
        "comments": "19 pages LateX, RevTeX 3, 6 figures, to appear J. Phys. I France\n  (April 1997)",
        "journal-ref": null,
        "doi": "10.1051/jp1:1997181",
        "license": null,
        "abstract": "  In the preceding paper we presented empirical results describing the growth\nof publicly-traded United States manufacturing firms within the years\n1974--1993. Our results suggest that the data can be described by a scaling\napproach. Here, we propose models that may lead to some insight into these\nphenomena. First, we study a model in which the growth rate of a company is\naffected by a tendency to retain an ``optimal'' size. That model leads to an\nexponential distribution of the logarithm of the growth rate in agreement with\nthe empirical results. Then, we study a hierarchical tree-like model of a\ncompany that enables us to relate the two parameters of the model to the\nexponent $\\beta$, which describes the dependence of the standard deviation of\nthe distribution of growth rates on size. We find that $\\beta = -\\ln \\Pi / \\ln\nz$, where $z$ defines the mean branching ratio of the hierarchical tree and\n$\\Pi$ is the probability that the lower levels follow the policy of higher\nlevels in the hierarchy. We also study the distribution of growth rates of this\nhierarchical model. We find that the distribution is consistent with the\nexponential form found empirically.\n"
    },
    {
        "paper_id": "cond-mat/9705075",
        "authors": "Rama Cont (CEA Saclay & CNRS Nice)",
        "title": "Scaling and correlation in financial data",
        "comments": "LATEX file + 8 postscript figures.",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The statistical properties of the increments x(t+T) - x(t) of a financial\ntime series depend on the time resolution T on which the increments are\nconsidered. A non-parametric approach is used to study the scale dependence of\nthe empirical distribution of the price increments x(t+T) - x(t) of S&P Index\nfutures, for time scales T, ranging from a few minutes to a few days using\nhigh-frequency price data. We show that while the variance increases linearly\nwith the timescale, the kurtosis exhibits anomalous scaling properties,\nindicating a departure from the iid hypothesis. Study of the dependence\nstructure of the increments shows that although the autocorrelation function\ndecays rapidly to zero in a few minutes, the correlation of their squares\nexhibits a slow power law decay with exponent 0.37, indicating persistence in\nthe scale of fluctuations. We establish a link between the scaling behavior and\nthe dependence structure of the increments : in particular, the anomalous\nscaling of kurtosis may be explained by \"long memory\" properties of the square\nof the increments.\n"
    },
    {
        "paper_id": "cond-mat/9705087",
        "authors": "Rama Cont (1,2,3) Marc Potters (2) Jean-Philippe Bouchaud (1,2) ((1)\n  CEA Saclay (2) Science & Finance (3) CNRS Nice)",
        "title": "Scaling in stock market data: stable laws and beyond",
        "comments": "Lecture given at Les Houches Workshop on Scale Invariance (March\n  1997). Plain TEX file, macros included. 11 pages, including 7 postscript\n  figures",
        "journal-ref": "Scale Invariance and Beyond (proceedings of the CNRS Workshop on\n  Scale Invariance, Les Houches, March 1997)",
        "doi": null,
        "license": null,
        "abstract": "  The concepts of scale invariance, self-similarity and scaling have been\nfruitfully applied to the study of price fluctuations in financial markets.\nAfter a brief review of the properties of stable Levy distributions and their\napplications to market data we indicate the shortcomings of such models and\ndescribe the truncated Levy flight as an alternative model for price movements.\nFurthermore, studying the dependence structure of the price increments shows\nthat while their autocorrelation function decreases rapidly to zero, the\ncorrelation of their squares and absolute values shows a slow power law decay,\nindicating persistence in the scale of fluctuations, a property which can be\nrelated to the anomalous scaling of the kurtosis. In the last section we\nreview, in the light of these empirical facts, recent attempts to draw\nanalogies between scaling in financial markets and in turbulent flows.\n"
    },
    {
        "paper_id": "cond-mat/9706021",
        "authors": "Yanhui Liu, Pierre Cizeau, Martin Meyer, Chung-Kang Peng, and H.\n  Eugene Stanley",
        "title": "Correlations in Economic Time Series",
        "comments": "6 pages, 2 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(97)00368-3",
        "license": null,
        "abstract": "  The correlation function of a financial index of the New York stock exchange,\nthe S&P 500, is analyzed at 1 min intervals over the 13-year period, Jan 84 --\nDec 96. We quantify the correlations of the absolute values of the index\nincrement. We find that these correlations can be described by two different\npower laws with a crossover time t_\\times\\approx 600 min. Detrended fluctuation\nanalysis gives exponents $\\alpha_1=0.66$ and $\\alpha_2=0.93$ for $t<t_\\times$\nand $t>t_\\times$ respectively. Power spectrum analysis gives corresponding\nexponents $\\beta_1=0.31$ and $\\beta_2=0.90$ for $f>f_\\times$ and $f< f_\\times$\nrespectively.\n"
    },
    {
        "paper_id": "cond-mat/9707042",
        "authors": "Jean-Philippe Bouchaud (1,2), Marc Potters (2), Jean-Pierre Aguilar\n  (2) ((1) CEA Saclay (2) Science & Finance)",
        "title": "Missing Information and Asset Allocation",
        "comments": "LaTeX 5 pages + 1 eps figure",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  When the available statistical information is imperfect, it is dangerous to\nfollow standard optimisation procedures to construct an optimal portfolio,\nwhich usually leads to a strong concentration of the weights on very few\nassets. We propose a new way, based on generalised entropies, to ensure a\nminimal degree of diversification.\n"
    },
    {
        "paper_id": "cond-mat/9708012",
        "authors": "A. Arneodo, J.-F. Muzy and D. Sornette",
        "title": "Causal cascade in the stock market from the ``infrared'' to the\n  ``ultraviolet''",
        "comments": "9 pages, 3 figures",
        "journal-ref": "European Physical Journal B 2, 277-282 (1998)",
        "doi": "10.1007/s100510050250",
        "license": null,
        "abstract": "  Modelling accurately financial price variations is an essential step\nunderlying portfolio allocation optimization, derivative pricing and hedging,\nfund management and trading. The observed complex price fluctuations guide and\nconstraint our theoretical understanding of agent interactions and of the\norganization of the market. The gaussian paradigm of independent normally\ndistributed price increments has long been known to be incorrect with many\nattempts to improve it. Econometric nonlinear autoregressive models with\nconditional heteroskedasticity (ARCH) and their generalizations capture only\nimperfectly the volatility correlations and the fat tails of the probability\ndistribution function (pdf) of price variations. Moreover, as far as changes in\ntime scales are concerned, the so-called ``aggregation'' properties of these\nmodels are not easy to control. More recently, the leptokurticity of the full\npdf was described by a truncated ``additive'' L\\'evy flight model (TLF).\nAlternatively, Ghashghaie et al. proposed an analogy between price dynamics and\nhydrodynamic turbulence. In this letter, we use wavelets to decompose the\nvolatility of intraday (S&P500) return data across scales. We show that when\ninvestigating two-points correlation functions of the volatility logarithms\nacross different time scales, one reveals the existence of a causal information\ncascade from large scales (i.e. small frequencies, hence to vocable\n``infrared'') to fine scales (``ultraviolet''). We quantify and visualize the\ninformation flux across scales. We provide a possible interpretation of our\nfindings in terms of market dynamics.\n"
    },
    {
        "paper_id": "cond-mat/9708018",
        "authors": "S. Ispolatov, P. L. Krapivsky, S. Redner (Boston University)",
        "title": "Wealth Distributions in Models of Capital Exchange",
        "comments": "10 pages, RevTeX, 4 figures, to be submitted to PRE",
        "journal-ref": "Eur. Phys. J. B 2, 267-76 (1998)",
        "doi": "10.1007/s100510050249",
        "license": null,
        "abstract": "  A dynamical model of capital exchange is introduced in which a specified\namount of capital is exchanged between two individuals when they meet. The\nresulting time dependent wealth distributions are determined for a variety of\nexchange rules. For ``greedy'' exchange, an interaction between a rich and a\npoor individual results in the rich taking a specified amount of capital from\nthe poor. When this amount is independent of the capitals of the two traders, a\nmean-field analysis yields a Fermi-like scaled wealth distribution in the\nlong-time limit. This same distribution also arises in greedier exchange\nprocesses, where the interaction rate is an increasing function of the capital\ndifference of the two traders. The wealth distribution in multiplicative\nprocesses, where the amount of capital exchanged is a finite fraction of the\ncapital of one of the traders, are also discussed. For random multiplicative\nexchange, a steady state wealth distribution is reached, while in greedy\nmultiplicative exchange a non-steady power law wealth distribution arises, in\nwhich the support of the distribution continuously increases. Finally,\nextensions of our results to arbitrary spatial dimension and to growth\nprocesses, where capital is created in an interaction, are presented.\n"
    },
    {
        "paper_id": "cond-mat/9708143",
        "authors": "Pierre Cizeau, Yanhui Liu, Martin Meyer, C.-K. Peng, H. Eugene Stanley",
        "title": "Volatility distribution in the S&P500 Stock Index",
        "comments": "6 pages, 5 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(97)00417-2",
        "license": null,
        "abstract": "  We study the volatility of the S&P500 stock index from 1984 to 1996 and find\nthat the volatility distribution can be very well described by a log-normal\nfunction. Further, using detrended fluctuation analysis we show that the\nvolatility is power-law correlated with Hurst exponent $\\alpha\\cong0.9$.\n"
    },
    {
        "paper_id": "cond-mat/9709118",
        "authors": "G. Caldarelli, M. Marsili, Y.-C. Zhang",
        "title": "A Prototype Model of Stock Exchange",
        "comments": "LaTex, 4 pages, 4 Encapsulated Postscript figures, uses psfig",
        "journal-ref": null,
        "doi": "10.1209/epl/i1997-00491-5",
        "license": null,
        "abstract": "  A prototype model of stock market is introduced and studied numerically. In\nthis self-organized system, we consider only the interaction among traders\nwithout external influences. Agents trade according to their own strategy, to\naccumulate his assets by speculating on the price's fluctuations which are\nproduced by themselves. The model reproduced rather realistic price histories\nwhose statistical properties are also similar to those observed in real\nmarkets.\n"
    },
    {
        "paper_id": "cond-mat/9709141",
        "authors": "B. Holdom",
        "title": "From turbulence to financial time series",
        "comments": "10 pages, 1 figure, LaTeX, version to appear in Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(98)00078-8",
        "license": null,
        "abstract": "  We develop a framework especially suited to the autocorrelation properties\nobserved in financial times series, by borrowing from the physical picture of\nturbulence. The success of our approach as applied to high frequency foreign\nexchange data is demonstrated by the overlap of the curves in Figure (1), since\nwe are able to provide an analytical derivation of the relative sizes of the\nquantities depicted. These quantities include departures from Gaussian\nprobability density functions and various two and three-point autocorrelation\nfunctions.\n"
    },
    {
        "paper_id": "cond-mat/9710197",
        "authors": "Andrew Matacz (University of Sydney, Australia)",
        "title": "Financial Modeling and Option Theory with the Truncated Levy Process",
        "comments": "21 pages in Latex, 6 eps figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In recent studies the truncated Levy process (TLP) has been shown to be very\npromising for the modeling of financial dynamics. In contrast to the Levy\nprocess, the TLP has finite moments and can account for both the previously\nobserved excess kurtosis at short timescales, along with the slow convergence\nto Gaussian at longer timescales. I further test the truncated Levy paradigm\nusing high frequency data from the Australian All Ordinaries share market\nindex. I then consider, for the early Levy dominated regime, the issue of\noption hedging for two different hedging strategies that are in some sense\noptimal. These are compared with the usual delta hedging approach and found to\ndiffer significantly. I also derive the natural generalization of the\nBlack-Scholes option pricing formula when the underlying security is modeled by\na geometric TLP. This generalization would not be possible without the\ntruncation.\n"
    },
    {
        "paper_id": "cond-mat/9710290",
        "authors": "S. Gluzman and V. I. Yukalov",
        "title": "Resummation Methods for Analyzing Time Series",
        "comments": "Corrections are made to match the published version",
        "journal-ref": "Mod. Phys. Lett. B 12, 61-74 (1998)",
        "doi": "10.1142/S021798499800010X",
        "license": null,
        "abstract": "  An approach is suggested for analyzing time series by means of resummation\ntechniques of theoretical physics. A particular form of such an analysis, based\non the algebraic self-similar renormalization, is developed and illustrated by\nseveral examples from the stock market time series.\n"
    },
    {
        "paper_id": "cond-mat/9710336",
        "authors": "S. Gluzman and V. I. Yukalov",
        "title": "Renormalization Group Analysis of October Market Crashes",
        "comments": "Corrections are made to match the published version",
        "journal-ref": "Mod. Phys. Lett. B 12, 75-84 (1998)",
        "doi": "10.1142/S0217984998000111",
        "license": null,
        "abstract": "  The self-similar analysis of time series, suggested earlier by the authors,\nis applied to the description of market crises. The main attention is payed to\nthe October 1929, 1987 and 1997 stock market crises, which can be successfully\ntreated by the suggested approach. The analogy between market crashes and\ncritical phenomena is emphasized.\n"
    },
    {
        "paper_id": "cond-mat/9711008",
        "authors": "J. Rotyis and G. Vattay (E\\\"otv\\\"os University Budapest,Hungary)",
        "title": "Statistical Analysis of the Stock Index of the Budapest Stock Exchange",
        "comments": "4 pages Revtex",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Scaling properties of the BUX index are similar to those observed in other\nparts of the world. The main difference is that the traditional quantities like\nvolatility, growth and autocorrelation of returns follows more closely the\nassumptions of the traditional stock market theory developed by Bachelier and\nby Black and Scholes.\n"
    },
    {
        "paper_id": "cond-mat/9712005",
        "authors": "A. Johansen and D. Sornette",
        "title": "Stock market crashes are outliers",
        "comments": "8 pages, 3 figures (accepted in European Physical Journal B)",
        "journal-ref": "European Physical Journal B 1, 141-143 (1998)",
        "doi": "10.1007/s100510050163",
        "license": null,
        "abstract": "  We call attention against what seems to a widely held misconception according\nto which large crashes are the largest events of distributions of price\nvariations with fat tails. We demonstrate on the Dow Jones Industrial index\nthat with high probability the three largest crashes in this century are\noutliers. This result supports suggestion that large crashes result from\nspecific amplification processes that might lead to observable pre-cursory\nsignatures.\n"
    },
    {
        "paper_id": "cond-mat/9712164",
        "authors": "J.-P. Bouchaud, N. Sagna, R. Cont, N. El-Karoui, M. Potters\n  (SPEC-Saclay, Science & Finance, Ecole Polytechnique)",
        "title": "Phenomenology of the Interest Rate Curve",
        "comments": "34 LaTeX pages and 11 .ps figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  This paper contains a phenomenological description of the whole U.S. forward\nrate curve (FRC), based on an data in the period 1990-1996. We find that the\naverage FRC (measured from the spot rate) grows as the square-root of the\nmaturity, with a prefactor which is comparable to the spot rate volatility.\nThis suggests that forward rate market prices include a risk premium,\ncomparable to the probable changes of the spot rate between now and maturity,\nwhich can be understood as a `Value-at-Risk' type of pricing. The instantaneous\nFRC however departs form a simple square-root law. The distortion is maximum\naround one year, and reflects the market anticipation of a local trend on the\nspot rate. This anticipated trend is shown to be calibrated on the past\nbehaviour of the spot itself. We show that this is consistent with the\nvolatility `hump' around one year found by several authors (and which we\nconfirm). Finally, the number of independent components needed to interpret\nmost of the FRC fluctuations is found to be small. We rationalize this by\nshowing that the dynamical evolution of the FRC contains a stabilizing second\nderivative (line tension) term, which tends to suppress short scale distortions\nof the FRC. This shape dependent term could lead, in principle, to arbitrage.\nHowever, this arbitrage cannot be implemented in practice because of\ntransaction costs. We suggest that the presence of transaction costs (or other\nmarket `imperfections') is crucial for model building, for a much wider class\nof models becomes eligible to represent reality.\n"
    },
    {
        "paper_id": "cond-mat/9712318",
        "authors": "Rama Cont and Jean-Philippe Bouchaud (CEA Saclay and Science & Finance\n  Research Group)",
        "title": "Herd behavior and aggregate fluctuations in financial markets",
        "comments": "Minor modifications in text, references added. 29 pages, typesetted\n  using LATEX",
        "journal-ref": "Macroeconomic Dynamics, 2000, Volume 4, No 2, 170-196",
        "doi": "10.1017/s1365100500015029",
        "license": null,
        "abstract": "  We present a simple model of a stock market where a random communication\nstructure between agents gives rise to a heavy tails in the distribution of\nstock price variations in the form of an exponentially truncated power-law,\nsimilar to distributions observed in recent empirical studies of high frequency\nmarket data. Our model provides a link between two well-known market phenomena:\nthe heavy tails observed in the distribution of stock market returns on one\nhand and 'herding' behavior in financial markets on the other hand. In\nparticular, our study suggests a relation between the excess kurtosis observed\nin asset returns, the market order flow and the tendency of market participants\nto imitate each other.\n"
    },
    {
        "paper_id": "cond-mat/9801209",
        "authors": "Stefano Galluccio, Jean-Philippe Bouchaud and Marc Potters (CEA-Saclay\n  and Science et Finance)",
        "title": "Rational Decisions, Random Matrices and Spin Glasses",
        "comments": null,
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(98)00332-X",
        "license": null,
        "abstract": "  We consider the problem of rational decision making in the presence of\nnonlinear constraints. By using tools borrowed from spin glass and random\nmatrix theory, we focus on the portfolio optimisation problem. We show that the\nnumber of ``optimal'' solutions is generically exponentially large: rationality\nis thus de facto of limited use. In addition, this problem is related to spin\nglasses with L\\'evy-like (long-ranged) couplings, for which we show that the\nground state is not exponentially degenerate.\n"
    },
    {
        "paper_id": "cond-mat/9801239",
        "authors": "Matteo Marsili, Sergei Maslov, and Yi-Cheng Zhang",
        "title": "Dynamical Optimization Theory of a Diversified Portfolio",
        "comments": "9 pages, 2 figures, accepted for publication in Physica A; Figure\n  captions and PS-files of two figues are added",
        "journal-ref": "Physica A 253, 403-418 (1998).",
        "doi": "10.1016/S0378-4371(98)00075-2",
        "license": null,
        "abstract": "  We propose and study a simple model of dynamical redistribution of capital in\na diversified portfolio. We consider a hypothetical situation of a portfolio\ncomposed of N uncorrelated stocks. Each stock price follows a multiplicative\nrandom walk with identical drift and dispersion. The rules of our model\nnaturally give rise to power law tails in the distribution of capital fractions\ninvested in different stocks. The exponent of this scale free distribution is\ncalculated in both discrete and continuous time formalism. It is demonstrated\nthat the dynamical redistribution strategy results in a larger typical growth\nrate of the capital than a static ``buy-and-hold'' strategy. In the large N\nlimit the typical growth rate is shown to asymptotically approach that of the\nexpectation value of the stock price. The finite dimensional variant of the\nmodel is shown to describe the partition function of directed polymers in\nrandom media.\n"
    },
    {
        "paper_id": "cond-mat/9801240",
        "authors": "Sergei Maslov and Yi-Cheng Zhang",
        "title": "Optimal Investment Strategy for Risky Assets",
        "comments": "11 pages, 1 figure, submitted to International Journal of Theoretical\n  and Applied Finance",
        "journal-ref": "International Journal of Theoretical and Applied Finance 1,377\n  (1998).",
        "doi": null,
        "license": null,
        "abstract": "  We design an optimal strategy for investment in a portfolio of assets subject\nto a multiplicative Brownian motion. The strategy provides the maximal typical\nlong-term growth rate of investor's capital. We determine the optimal fraction\nof capital that an investor should keep in risky assets as well as weights of\ndifferent assets in an optimal portfolio. In this approach both average return\nand volatility of an asset are relevant indicators determining its optimal\nweight. Our results are particularly relevant for very risky assets when\ntraditional continuous-time Gaussian portfolio theories are no longer\napplicable.\n"
    },
    {
        "paper_id": "cond-mat/9801321",
        "authors": "P. Santa-Clara and D. Sornette",
        "title": "The Dynamics of the Forward Interest Rate Curve with Stochastic String\n  Shocks",
        "comments": "29 pages, 3 figures, submitted to Review of Financial Studies",
        "journal-ref": "The Review of Financial Studies 14(1), 149-185 (January 2001)",
        "doi": null,
        "license": null,
        "abstract": "  This paper offers a new class of models of the term structure of interest\nrates. We allow each instantaneous forward rate to be driven by a different\nstochastic shock, constrained in such a way as to keep the forward rate curve\ncontinuous. We term the process followed by the shocks to the forward curve\n``stochastic strings'', and construct them as the solution to stochastic\npartial differential equations, that allow us to offer a variety of interesting\nparametrizations. The models can produce, with parsimony, any sort of\ncorrelation pattern among forward rates of different maturities. This feature\nmakes the models consistent with any panel dataset of bond prices, not\nrequiring the addition of error terms in econometric models. Interest rate\noptions can easily be priced by simulation. However, options can only be\nperfectly hedged by trading in bonds of all maturities available.\n"
    },
    {
        "paper_id": "cond-mat/9802059",
        "authors": "Didier Sornette",
        "title": "Large deviations and portfolio optimization",
        "comments": "40 pages, 6 figures, corrections of a few formulas and misprints in\n  press in Physica A",
        "journal-ref": "Physica A 256, 251-283 (1998)",
        "doi": "10.1016/S0378-4371(98)00114-9",
        "license": null,
        "abstract": "  Risk control and optimal diversification constitute a major focus in the\nfinance and insurance industries as well as, more or less consciously, in our\neveryday life. We present a discussion of the characterization of risks and of\nthe optimization of portfolios that starts from a simple illustrative model and\nends by a general functional integral formulation. A major theme is that risk,\nusually thought one-dimensional in the conventional mean-variance approach, has\nto be addressed by the full distribution of losses. Furthermore, the\ntime-horizon of the investment is shown to play a major role. We show the\nimportance of accounting for large fluctuations and use the theory of Cram\\'er\nfor large deviations in this context. We first treat a simple model with a\nsingle risky asset that examplifies the distinction between the average return\nand the typical return, the role of large deviations in multiplicative\nprocesses, and the different optimal strategies for the investors depending on\ntheir size. We then analyze the case of assets whose price variations are\ndistributed according to exponential laws, a situation that is found to\ndescribe reasonably well daily price variations. Several portfolio optimization\nstrategies are presented that aim at controlling large risks. We end by\nextending the standard mean-variance portfolio optimization theory, first\nwithin the quasi-Gaussian approximation and then using a general formulation\nfor non-Gaussian correlated assets in terms of the formalism of functional\nintegrals developed in the field theory of critical phenomena.\n"
    },
    {
        "paper_id": "cond-mat/9802136",
        "authors": "D. Sornette",
        "title": "``String'' formulation of the Dynamics of the Forward Interest Rate\n  Curve",
        "comments": "24 pages, European Physical Journal B (in press)",
        "journal-ref": "European Physical Journal B 3, 125-137 (1998)",
        "doi": "10.1007/s100510050291",
        "license": null,
        "abstract": "  We propose a formulation of the term structure of interest rates in which the\nforward curve is seen as the deformation of a string. We derive the general\ncondition that the partial differential equations governing the motion of such\nstring must obey in order to account for the condition of absence of arbitrage\nopportunities. This condition takes a form similar to a fluctuation-dissipation\ntheorem, albeit on the same quantity (the forward rate), linking the bias to\nthe covariance of variation fluctuations. We provide the general structure of\nthe models that obey this constraint in the framework of stochastic partial\n(possibly non-linear) differential equations. We derive the general solution\nfor the pricing and hedging of interest rate derivatives within this framework,\nalbeit for the linear case (we also provide in the appendix a simple and\nintuitive derivation of the standard European option problem). We also show how\nthe ``string'' formulation simplifies into a standard N-factor model under a\nGalerkin approximation.\n"
    },
    {
        "paper_id": "cond-mat/9802234",
        "authors": "B. M. Roehner and D. Sornette",
        "title": "The sharp peak-flat trough pattern and critical speculation",
        "comments": "20 pages, 6 figures (only fig.4 and 6 available in ps format), 3\n  tables, European Physical Journal B (in press)",
        "journal-ref": "European Physical Journal B 4, 387-399 (1998)",
        "doi": "10.1007/s100510050394",
        "license": null,
        "abstract": "  We find empirically a characteristic sharp peak-flat trough pattern in a\nlarge set of commodity prices. We argue that the sharp peak structure reflects\nan endogenous inter-market organization, and that peaks may be seen as local\n``singularities'' resulting from imitation and herding. These findings impose a\nnovel stringent constraint on the construction of models. Intermittent\namplification is not sufficient and nonlinear effects seem necessary to account\nfor the observations.\n"
    },
    {
        "paper_id": "cond-mat/9802256",
        "authors": "Rosario N. Mantegna",
        "title": "Hierarchical Structure in Financial Markets",
        "comments": "11 pages, 3 figures with 7 panels",
        "journal-ref": null,
        "doi": "10.1007/s100510050929",
        "license": null,
        "abstract": "  I find a topological arrangement of stocks traded in a financial market which\nhas associated a meaningful economic taxonomy. The topological space is a graph\nconnecting the stocks of the portfolio analyzed. The graph is obtained starting\nfrom the matrix of correlation coefficient computed between all pairs of stocks\nof the portfolio by considering the synchronous time evolution of the\ndifference of the logarithm of daily stock price. The hierarchical tree of the\nsubdominant ultrametric space associated with the graph provides information\nuseful to investigate the number and nature of the common economic factors\naffecting the time evolution of logarithm of price of well defined groups of\nstocks.\n"
    },
    {
        "paper_id": "cond-mat/9803059",
        "authors": "S. Gluzman and V. I. Yukalov",
        "title": "Fixed Points in Self-Similar Analysis of Time Series",
        "comments": "1 file, 6 pages, LaTex",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Two possible definitions of fixed points in the self-similar analysis of time\nseries are considered. One definition is based on the minimal-difference\ncondition and another, on a simple averaging. From studying stock market time\nseries, one may conclude that these two definitions are practically equivalent.\nA forecast is made for the stock market indices for the end of March 1998.\n"
    },
    {
        "paper_id": "cond-mat/9803238",
        "authors": "Erik Aurell, Karol \\.Zyczkowski",
        "title": "Risk-return arguments applied to options with trading costs",
        "comments": "10 pages, in LaTeX, no figures, Paper to be published in the\n  Proceedings of the conference \"Disorder and Chaos\", in memory of Giovanni\n  Paladin, Rome, Italy, 22-24 September 1997",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We study the problem of option pricing and hedging strategies within the\nframe-work of risk-return arguments. An economic agent is described by a\nutility function that depends on profit (an expected value) and risk (a\nvariance). In the ideal case without transaction costs the optimal strategy for\nany given agent is found as the explicit solution of a constrained optimization\nproblem. Transaction costs are taken into account on a perturbative way. A\nrational option price, in a world with only these agents, is then determined by\nconsidering the points of view of the buyer and the writer of the option. Price\nand strategy are determined to first order in the transaction costs.\n"
    },
    {
        "paper_id": "cond-mat/9803367",
        "authors": "Sorin Solomon (Hebrew University)",
        "title": "Stochastic Lotka-Volterra Systems of Competing Auto-Catalytic Agents\n  Lead Generically to Truncated Pareto Power Wealth Distribution, Truncated\n  Levy Distribution of Market Returns, Clustered Volatility, Booms and Craches",
        "comments": "13 Pages, no figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We give a microscopic representation of the stock-market in which the\nmicroscopic agents are the individual traders and their capital. Their basic\ndynamics consists in the auto-catalysis of the individual capital and in the\nglobal competition/cooperation between the agents mediated by the total wealth\ninvested in the stock (which we identify with the stock-index). We show that\nsuch systems lead generically to (truncated) Pareto power-law distribution of\nthe individual wealth. This, in turn, leads to intermittent market (short time)\nreturns parametrized by a (truncated) Levy distribution. We relate the\ntruncation in the Levy distribution to the (truncation in the Pareto Power Law\ni.e. to the) fact that at each moment no trader can own more than the current\ntotal wealth invested in the stock. In the cases where the system is dominated\nby the largest traders, the dynamics looks similar to noisy low-dimensional\nchaos. By introducing traders memory and/or feedback between individual and\ncollective wealth fluctuations (the later identified with the stock returns),\none obtains clustered \"volatility\" as well as market booms and crashes. The\nbasic feedback loop consists in: - computing the market price of the stock as\nthe sum of the individual wealths invested in the stock by the traders and -\ndetermining the time variation of the individual trader wealth as his/her\nprevious wealth multiplied by the stock return (i.e. the variation of the stock\nprice).\n"
    },
    {
        "paper_id": "cond-mat/9803374",
        "authors": "Parameswaran Gopikrishnan, Martin Meyer, Luis A Nunes Amaral and H\n  Eugene Stanley",
        "title": "Inverse Cubic Law for the Probability Distribution of Stock Price\n  Variations",
        "comments": "5 pages, 4 figures, RevTex 2 figures added",
        "journal-ref": "Eur. Phys. J. B (Rapid Note), 3 (1998) 139",
        "doi": "10.1007/s100510050292",
        "license": null,
        "abstract": "  The probability distribution of stock price changes is studied by analyzing a\ndatabase (the Trades and Quotes Database) documenting every trade for all\nstocks in three major US stock markets, for the two year period Jan 1994 -- Dec\n1995. A sample of 40 million data points is extracted, which is substantially\nlarger than studied hitherto. We find an asymptotic power-law behavior for the\ncumulative distribution with an exponent alpha approximately 3, well outside\nthe Levy regime 0< alpha <2.\n"
    },
    {
        "paper_id": "cond-mat/9804045",
        "authors": "D. Sornette",
        "title": "Gauge theory of Finance?",
        "comments": "4 pages",
        "journal-ref": "Int. J. Mod. Phys. 9 (3), 505-508 (1998)",
        "doi": "10.1142/S0129183198000406",
        "license": null,
        "abstract": "  Some problems with the recent stimulating proposal of a ``Gauge Theory of\nFinance'' by Ilinski and collaborators are outlined. First, the derivation of\nthe log-normal distribution is shown equivalent both in information and\nmathematical content to the simpler and well-known derivation, dating back from\nBachelier and Samuelson. Similarly, the re-derivation of Black-Scholes equation\nis shown equivalent to the standard one because the limit of no uncertainty is\nequivalent to the standard risk-free replication argument. Both re-derivations\nof the log-normality and Black-Scholes result do not provide a test of the\ntheory because it is degenerate in the limits where these results apply. Third,\nthe choice of the exponential form a la Boltzmann, of the weight of a given\nmarket configuration, is a key postulate that requires justification. In\naddition, the ``Gauge Theory of Finance'' seems to lead to ``virtual''\narbitrage opportunities for pure Markov random walk market when there should be\nnone. These remarks are offered in the hope to improve the formulation of the\n``Gauge Theory of Finance'' into a coherent and useful framework.\n"
    },
    {
        "paper_id": "cond-mat/9804100",
        "authors": "Youngki Lee (BU), Luis A. N. Amaral (MIT), David Canning (HIID),\n  Martin Meyer (BU), and H. Eugene Stanley (BU)",
        "title": "Universal features in the growth dynamics of complex organizations",
        "comments": "4 pages, 7 ps figures, using Latex2e with epsf rotate and multicol\n  style files. Submitted to PRL",
        "journal-ref": null,
        "doi": "10.1103/PhysRevLett.81.3275",
        "license": null,
        "abstract": "  We analyze the fluctuations in the gross domestic product (GDP) of 152\ncountries for the period 1950--1992. We find that (i) the distribution of\nannual growth rates for countries of a given GDP decays with ``fatter'' tails\nthan for a Gaussian, and (ii) the width of the distribution scales as a power\nlaw of GDP with a scaling exponent $\\beta \\approx 0.15$. Both findings are in\nsurprising agreement with results on firm growth. These results are consistent\nwith the hypothesis that the evolution of organizations with complex structure\nis governed by similar growth mechanisms.\n"
    },
    {
        "paper_id": "cond-mat/9804111",
        "authors": "Laurent Laloux (1), Marc Potters (1), Rama Cont (1,2), Jean-Pierre\n  Aguilar (1,3) and Jean-Philippe Bouchaud (1,4) ((1) Science & Finance (2)\n  Polytechnique Lausanne (3) Capital Futures Management (4) CEA Saclay)",
        "title": "Are Financial Crashes Predictable?",
        "comments": "LaTeX, 5 pages + 1 postscript figure",
        "journal-ref": null,
        "doi": "10.1209/epl/i1999-00122-9",
        "license": null,
        "abstract": "  We critically review recent claims that financial crashes can be predicted\nusing the idea of log-periodic oscillations or by other methods inspired by the\nphysics of critical phenomena. In particular, the October 1997 `correction'\ndoes not appear to be the accumulation point of a geometric series of local\nminima.\n"
    },
    {
        "paper_id": "cond-mat/9804126",
        "authors": "Rosario N. Mantegna and H. Eugene Stanley",
        "title": "Modeling of Financial Data: Comparison of the Truncated L\\'evy Flight\n  and the ARCH(1) and GARCH(1,1) processes",
        "comments": "13 pages, no figures, to appear in Physica A",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(98)00020-X",
        "license": null,
        "abstract": "  We compare our results on empirical analysis of financial data with\nsimulations of two stochastic models of the dynamics of stock market prices.\nThe two models are (i) the truncated L\\'evy flight recently introduced by us\nand (ii) the ARCH(1) and GARCH(1,1) processes. We find that the TLF well\ndescribes the scaling and its breakdown observed in empirical data, while it is\nnot able to properly describe the fluctuations of volatility empirically\ndetected. The ARCH(1) and GARCH(1,1) models are able to describe the\nprobability density function of price changes at a given time horizon, but both\nfail to describe the scaling properties of the PDFs for short time horizons.\n"
    },
    {
        "paper_id": "cond-mat/9804297",
        "authors": "R. Baviera, M. Pasquini, M. Serva, A. Vulpiani (Universit\\`a\n  dell'Aquila and Roma \"La Sapienza\", Italy)",
        "title": "Optimal Strategies for Prudent Investors",
        "comments": "14 pages, LaTeX, epsfig.sty, 7 eps figures, minor changes; accepted\n  for International J. of Theoretical and Applied Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We consider a stochastic model of investment on an asset of a stock market\nfor a prudent investor. She decides to buy permanent goods with a fraction $\\a$\nof the maximum amount of money owned in her life in order that her economic\nlevel never decreases. The optimal strategy is obtained by maximizing the\nexponential growth rate for a fixed $\\a$. We derive analytical expressions for\nthe typical exponential growth rate of the capital and its fluctuations by\nsolving an one-dimensional random walk with drift.\n"
    },
    {
        "paper_id": "cond-mat/9805115",
        "authors": "D. F. Wang (Univ.of Waterloo and TD Bank)",
        "title": "Revisiting the Black-Scholes equation",
        "comments": "12 pages, Revtex style",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In common finance literature, Black-Scholes partial differential equation of\noption pricing is usually derived with no-arbitrage principle. Considering an\nasset market, Merton applied the Hamilton-Jacobi-Bellman techniques of his\ncontinuous-time consumption-portfolio problem, deriving general equilibrium\nrelationships among the securities in the asset market. In special case where\nthe interest rate is constant, he rederived the Black-Scholes partial\ndifferential equation from the general equilibrium asset market. In this work,\nI follow Cox-Ingersoll-Ross formulation to consider an economy which includes\n(1) uncertain production processes, and (2) the random technology change.\nAssuming a random production stochastic process of constant drift and variance,\nand assuming a random technology change to follow a log normal process, the\nequilibrium point of this economy will lead to the Black-Scholes partial\ndifferential equation for option pricing.\n"
    },
    {
        "paper_id": "cond-mat/9806138",
        "authors": "Kirill N. Ilinski, Alexander S. Stepanenko",
        "title": "Electrodynamical model of quasi-efficient financial market",
        "comments": "9 pages, 2 figures, LaTeX",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The modelling of financial markets presents a problem which is both\ntheoretically challenging and practically important. The theoretical aspects\nconcern the issue of market efficiency which may even have political\nimplications \\cite{Cuthbertson}, whilst the practical side of the problem has\nclear relevance to portfolio management \\cite{Elton} and derivative pricing\n\\cite{Hull}. Up till now all market models contain \"smart money\" traders and\n\"noise\" traders whose joint activity constitutes the market \\cite{DeLong,Bak}.\nOn a short time scale this traditional separation does not seem to be\nrealistic, and is hardly acceptable since all high-frequency market\nparticipants are professional traders and cannot be separated into \"smart\" and\n\"noisy\". In this paper we present a \"microscopic\" model with homogenuous\nquasi-rational behaviour of traders, aiming to describe short time market\nbehaviour. To construct the model we use an analogy between \"screening\" in\nquantum electrodynamics and an equilibration process in a market with temporal\nmispricing \\cite{Ilinski,Dunbar}. As a result, we obtain the time-dependent\ndistribution function of the returns which is in quantitative agreement with\nreal market data and obeys the anomalous scaling relations recently reported\nfor both high-frequency exchange rates \\cite{Breymann}, S&P500 \\cite{Stanley}\nand other stock market indices \\cite{Bouchaud,Australia}.\n"
    },
    {
        "paper_id": "cond-mat/9807066",
        "authors": "D. F. Wang (TD Bank and Univ. of Waterloo)",
        "title": "Hedging The Risk In The Continuous Time Option Pricing Model With\n  Stochastic Stock Volatility",
        "comments": "8 pages, Revtex style",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this work, I address the issue of forming riskless hedge in the continuous\ntime option pricing model with stochastic stock volatility. I show that it is\nessential to verify whether the replicating portfolio is self-financing, in\norder for the theory to be self-consistent. The replicating methods in existing\nfinance literature are shown to violate the self-financing constraint when the\nunderlying asset has stochastic volatility. Correct self-financing hedge is\nformed in this article.\n"
    },
    {
        "paper_id": "cond-mat/9807397",
        "authors": "Sergei Fedotov and Sergei Mikhailov",
        "title": "Option Pricing Model for Incomplete Market",
        "comments": null,
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The problem of determining the European-style option price in the incomplete\nmarket has been examined within the framework of stochastic optimization. An\nanalytic method based on the discrete dynamic programming equation (Bellman\nequation) has been developed that gives the general formalism for determining\nthe option price and the optimal trading strategy (optimal control policy) that\nreduces total risk inherent in writing the option.\n  The basic purpose of paper is to present an effective algorithm that can be\nused in practice.\n  Keywords: option pricing, incomplete market, transaction costs, stochastic\noptimization, Bellman equation.\n"
    },
    {
        "paper_id": "cond-mat/9808168",
        "authors": "D. F. Wang (TD Bank and Univ. of Waterloo)",
        "title": "Pricing defaultable debt: some exact results",
        "comments": "Revtex, 8 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this letter, I consider the issue of pricing risky debt by following\nMerton's approach. I generalize Merton's results to the case where the interest\nrate is modeled by the CIR term structure. Exact closed forms are provided for\nthe risky debt's price.\n"
    },
    {
        "paper_id": "cond-mat/9808240",
        "authors": "David Eliezer, Ian I. Kogan",
        "title": "Scaling Laws for the Market Microstructure of the Interdealer Broker\n  Markets",
        "comments": "58 pages, 3 figures, introduction modified, references added",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We propose a series of simple models for the microstructure of a double\nauction market without intermediaries. We specialize to those markets, such\ninterdealer broker markets, which are dominated by professional traders, who\ntrade mainly through limit orders, watch markets closely, and move their limit\norder prices frequently. We model these markets as a set of buyers and a set of\nsellers diffusing in price space and interacting through an annihilation\ninteraction. We seek to compute the purely statistical effects of the presence\nof large numbers of traders, as scaling laws on various measures of liquidity,\nand to this end we allow our model very few parameters. We find that the\nbid-offer spread scales as $\\sqrt{1/{\\rm Deal Rate}}$.In addition we\ninvestigate the scaling of other intuitive relationships, such as the relation\nbetween fluctuations of the best bid/offer and the density of buyers/sellers.\nWe then study this model and its scaling laws under the influence of random\ndisturbances to trader drift, trader volatility, and entrance rate. We also\nstudy possible extensions to the model, such as the addition of market order\ntraders, and an interaction that models momentum-type trading. Finally, we\ndiscuss how detailed simulations may be carried out to study scaling in all of\nthese settings, and how the models may be tested inactual markets.\n"
    },
    {
        "paper_id": "cond-mat/9808295",
        "authors": "Sergei Maslov and Yi-Cheng Zhang",
        "title": "Probability distribution of drawdowns in risky investments",
        "comments": "5 pages, 4 figures (included)",
        "journal-ref": "Physica A 262, 232-241 (1999).",
        "doi": "10.1016/S0378-4371(98)00416-6",
        "license": null,
        "abstract": "  We study the risk criterion for investments based on the drawdown from the\nmaximal value of the capital in the past. Depending on investor's risk\nattitude, thus his risk exposure, we find that the distribution of these\ndrawdowns follows a general power law. In particular, if the risk exposure is\nKelly-optimal, the exponent of this power law has the borderline value of 2,\ni.e. the average drawdown is just about to diverge\n"
    },
    {
        "paper_id": "cond-mat/9808305",
        "authors": "L. Pietronero, E.Tosatti, V.Tosatti and A. Vespignani",
        "title": "The Uneven Distribution of Numbers in Nature",
        "comments": "9 pages, 2 figures; improved version with added references",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Suppose you look at today's stock prices and bet on the value of the first\ndigit. One could guess that a fair bet should correspond to the frequency of\n$1/9 = 11.11%$ for each digit from 1 to 9. This is by no means the case, and\none can easily observe a strong prevalence of the small values over the large\nones. The first three integers 1,2 and 3 alone have globally a frequency of 60%\nwhile the other six values 4, 5, 6, 7, 8 and 9 appear only in 40% of the cases.\nThis situation is actually much more general than the stock market and it\noccurs in a variety of number catalogs related to natural phenomena. The first\nobservation of this property traces back to S. Newcomb in 1881 but a more\nprecise account was given by F. Benford in 1938. In this note we illustrate\nthese observations with the enlightening specific example of the stock market.\nWe also identify the general mechanism for the origin of this uneven\ndistribution in the multiplicative nature of fluctuations in economics and in\nmany natural phenomena. This provides a natural explanation for the ubiquitous\npresence of the Benford's law in many different phenomena with the common\nelement that their fluctuations refer to a fraction of their values. This\nbrings us close to the problem of the spontaneous origin of scale invariant\nproperties in various phenomena which is a debated question at the frontier of\ndifferent fields.\n"
    },
    {
        "paper_id": "cond-mat/9809045",
        "authors": "D. F. Wang",
        "title": "Generalizing Merton's approach of pricing risky debt: some closed form\n  results",
        "comments": "7 pages, Revtex style",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(98)00545-7",
        "license": null,
        "abstract": "  In this work, I generalize Merton's approach of pricing risky debt to the\ncase where the interest rate risk is modeled by the CIR term structure. Closed\nform result for pricing the debt is given for the case where the firm value has\nnon-zero correlation with the interest rate. This extends previous closed form\npricing formular of zero-correlation case to the generic one of non-zero\ncorrelation between the firm value and the interest rate.\n"
    },
    {
        "paper_id": "cond-mat/9809199",
        "authors": "Belal E. Baaquie",
        "title": "Quantum Field Theory of Treasury Bonds",
        "comments": "29 pages, 4 figures",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  The Heath-Jarrow-Morton (HJM) formulation of treasury bonds in terms of\nforward rates is recast as a problem in path integration. The HJM-model is\ngeneralized to the case where all the forward rates are allowed to fluctuate\nindependently. The resulting theory is shown to be a two-dimensional Gaussian\nquantum field theory. The no arbitrage condition is obtained and a functional\nintegral derivation is given for the price of a futures and an options\ncontract.\n"
    },
    {
        "paper_id": "cond-mat/9809366",
        "authors": "Didier Sornette (CNRS-University of Nice and UCLA) and Daniel\n  Zajdenweber (Universite de Parix X - Nanterre)",
        "title": "Economic returns of research: the Pareto law and its implications",
        "comments": "18 pages, 7 figures",
        "journal-ref": "European Physical Journal B, 8 (4), 653-664 (1999)",
        "doi": "10.1007/s100510050733",
        "license": null,
        "abstract": "  At what level should government or companies support research? This complex\nmulti-faceted question encompasses such qualitative bonus as satisfying natural\nhuman curiosity, the quest for knowledge and the impact on education and\nculture, but one of its most scrutinized component reduces to the assessment of\neconomic performance and wealth creation derived from research. In certain\nareas such as biotechnology, semi-conductor physics, optical communications,\nthe impact of basic research is direct while, in other disciplines, the path\nfrom discovery to applications is full of surprises. As a consequence, there\nare persistent uncertainties in the quantification of the exact economic\nreturns of public expenditure on basic research. Here, we suggest that these\nuncertainties have a fundamental origin to be found in the interplay between\nthe intrinsic ``fat tail'' power law nature of the distribution of economic\nreturns, characterized by a mathematically diverging variance, and the\nstochastic character of discovery rates. In the regime where the cumulative\neconomic wealth derived from research is expected to exhibit a long-term\npositive trend, we show that strong fluctuations blur out significantly the\nshort-time scales: a few major unpredictable innovations may provide a finite\nfraction of the total creation of wealth. In such a scenario, any attempt to\nassess the economic impact of research over a finite time horizon encompassing\nonly a small number of major discoveries is bound to be highly unreliable. New\ntools, developed in the theory of self-similar and complex systems to tackle\nsimilar extreme fluctuations in Nature can be adapted to measure the economic\nbenefits of research, which is intimately associated to this large variability.\n"
    },
    {
        "paper_id": "cond-mat/9810091",
        "authors": "M. Serva (Dip. di Matematica and I.N.F.M., Universit\\`a dell'Aquila,\n  Italy)",
        "title": "Optimal lag in dynamical investments",
        "comments": "13 pages, LaTeX, uses epsfig.sty, 5 ps figures, submitted to Int. J.\n  of Theoretical and Applied Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A portfolio of different stocks and a risk-less security whose composition is\ndynamically maintained stable by trading shares at any time step leads to a\ngrowth of the capital with a nonrandom rate. This is the key for the theory of\noptimal-growth investment formulated by Kelly. In presence of transaction\ncosts, the optimal composition changes and, more important, it turns out that\nthe frequency of transactions must be reduced. This simple observation leads to\nthe definition of an optimal lag between two rearrangement of the portfolio.\nThis idea is tested against an investment in a risky asset and a risk-less one.\nThe price of the first is proportional to NYSE composite index while the price\nof the second grows according to the American Discount Rate. An application to\na portfolio of many stochastically equivalent securities is also provided.\n"
    },
    {
        "paper_id": "cond-mat/9810092",
        "authors": "S. Gluzman and V. I. Yukalov",
        "title": "Booms and Crashes in Self-Similar Markets",
        "comments": "1 file, 10 pages, RevTex",
        "journal-ref": "Mod. Phys. Lett. B 12 (1998) 575-587",
        "doi": "10.1142/S0217984998000688",
        "license": null,
        "abstract": "  Sharp changes in time series representing market dynamics are studied by\nmeans of the self--similar analysis suggested earlier by the authors. These\nsharp changes are market booms and crashes. Such crises phenomena in markets\nare analogous to critical phenomena in physics. A simple classification of the\nmarket crisis phenomena is given.\n"
    },
    {
        "paper_id": "cond-mat/9810162",
        "authors": "Debashish Chowdhury and Dietrich Stauffer (Cologne)",
        "title": "A generalized spin model of financial markets",
        "comments": "11 pages LATEX, 7 postscript figures; longer text with theoretical\n  analysis, more accurate numerical data, better terminology, additional\n  references. Accepted for publication in European Physical Journal B",
        "journal-ref": "European Physical Journal B, 8 (1999) 477",
        "doi": "10.1007/s100510050714",
        "license": null,
        "abstract": "  We reformulate the Cont-Bouchaud model of financial markets in terms of\nclassical \"super-spins\" where the spin value is a measure of the number of\nindividual traders represented by a portfolio manager of an investment agency.\nWe then extend this simplified model by switching on interactions among the\nsuper-spins to model the tendency of agencies getting influenced by the opinion\nof other managers. We also introduce a fictitious temperature (to model other\nrandom influences), and time-dependent local fields to model slowly changing\noptimistic or pessimistic bias of traders. We point out close similarities\nbetween the price variations in our model with $N$ super-spins and total\ndisplacements in an $N$-step Levy flight. We demonstrate the phenomena of\nnatural and artificially created bubbles and subsequent crashes as well as the\noccurrence of \"fat tails\" in the distributions of stock price variations.\n"
    },
    {
        "paper_id": "cond-mat/9810232",
        "authors": "Michele Pasquini, Maurizio Serva (Dip. di Matematica and I.N.F.M.,\n  Universit\\`a dell'Aquila, Italy)",
        "title": "Multiscale behaviour of volatility autocorrelations in a financial\n  market",
        "comments": "2 pages, RevTeX, 3 eps figures, submitted to Economics Letters",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We perform a scaling analysis on NYSE daily returns. We show that volatility\ncorrelations are power-laws on a time range from one day to one year and, more\nimportant, that they exhibit a multiscale behaviour.\n"
    },
    {
        "paper_id": "cond-mat/9810257",
        "authors": "E. Aurell, R. Baviera, O. Hammarlid, M. Serva, A. Vulpiani",
        "title": "A general methodology to price and hedge derivatives in incomplete\n  markets",
        "comments": "24 pages, LaTeX, epsfig.sty, 5 eps figures, changes in the\n  presentation of the method, submitted to International J. of Theoretical and\n  Applied Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We introduce and discuss a general criterion for the derivative pricing in\nthe general situation of incomplete markets, we refer to it as the No Almost\nSure Arbitrage Principle. This approach is based on the theory of optimal\nstrategy in repeated multiplicative games originally introduced by Kelly. As\nparticular cases we obtain the Cox-Ross-Rubinstein and Black-Scholes in the\ncomplete markets case and the Schweizer and Bouchaud-Sornette as a quadratic\napproximation of our prescription. Technical and numerical aspects for the\npractical option pricing, as large deviation theory approximation and Monte\nCarlo computation are discussed in detail.\n"
    },
    {
        "paper_id": "cond-mat/9811094",
        "authors": "Per Bak, Simon F. Norrelykke and Martin Shubik",
        "title": "The Dynamics of Money",
        "comments": "5 pages, 2 figures, to be published in Phys.Rev.E",
        "journal-ref": "Phys. Rev. E 60, 2528-2532 (1999)",
        "doi": "10.1103/PhysRevE.60.2528",
        "license": null,
        "abstract": "  We present a dynamical many-body theory of money in which the value of money\nis a time dependent ``strategic variable'' that is chosen by the individual\nagents. The value of money in equilibrium is not fixed by the equations, and\nthus represents a continuous symmetry. The dynamics breaks this continuous\nsymmetry by fixating the value of money at a level which depends on initial\nconditions. The fluctuations around the equilibrium, for instance in the\npresence of noise, are governed by the ``Goldstone modes'' associated with the\nbroken symmetry. The idea is illustrated by a simple network model of\nmonopolistic vendors and buyers.\n"
    },
    {
        "paper_id": "cond-mat/9811114",
        "authors": "Lei-Han Tang and Guang-Shan Tian",
        "title": "Reaction-Diffusion-Branching Models of Stock Price Fluctuations",
        "comments": "4 pages, 3 figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(98)00549-4",
        "license": null,
        "abstract": "  Several models of stock trading [P. Bak et al, Physica A {\\bf 246}, 430\n(1997)] are analyzed in analogy with one-dimensional, two-species\nreaction-diffusion-branching processes. Using heuristic and scaling arguments,\nwe show that the short-time market price variation is subdiffusive with a Hurst\nexponent $H=1/4$. Biased diffusion towards the market price and blind-eyed\ncopying lead to crossovers to the empirically observed random-walk behavior\n($H=1/2$) at long times. The calculated crossover forms and diffusion constants\nare shown to agree well with simulation data.\n"
    },
    {
        "paper_id": "cond-mat/9811197",
        "authors": "Kirill N Ilinski",
        "title": "Gauge Physics of Finance: simple introduction",
        "comments": "16 pages, 2 figures, written for MoneyWeb",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper we state the fundamental principles of the gauge approach to\nfinancial economics and demonstrate the ways of its application. In particular,\nmodelling of realistic price processes is considered for an example of S&P500\nmarket index. Derivative pricing and portfolio theory are also briefly\ndiscussed.\n"
    },
    {
        "paper_id": "cond-mat/9811292",
        "authors": "D. Sornette (CNRS-University of Nice and UCLA), J. V. Andersen\n  (Nordita, Copenhagen) and P. Simonetti (USC)",
        "title": "Minimizing volatility increases large risks",
        "comments": "13 pages, 6 figures",
        "journal-ref": "International Journal of Theoretical and Applied Finance 3 (3),\n  523-535 (2000)",
        "doi": null,
        "license": null,
        "abstract": "  We introduce a faithful representation of the heavy tail multivariate\ndistribution of asset returns, as parsimonous as the Gaussian framework. Using\ncalculation techniques of functional integration and Feynman diagrams borrowed\nfrom particle physics, we characterize precisely, through its cumulants of high\norder, the distribution of wealth variations of a portfolio composed of an\narbitrary mixture of assets. The portfolio which minimizes the variance, i.e.\nthe relatively small risks, often increases larger risks as measured by higher\nnormalized cumulants and by the Value-at-risk.\n"
    },
    {
        "paper_id": "cond-mat/9812318",
        "authors": "Matthias Otto (Institute of Theoretical Physics, University of\n  Goettingen, Germany)",
        "title": "Using path integrals to price interest rate derivatives",
        "comments": "15 pages, no figures, typos corrected, references added",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We present a new approach for the pricing of interest rate derivatives which\nallows a direct computation of option premiums without deriving a\n(Black-Scholes type) partial differential equation and without explicitly\nsolving the stochastic process for the underlying variable. The approach is\ntested by rederiving the prices of a zero bond and a zero bond option for a\nshort rate environment which is governed by Vasicek dynamics. Furthermore, a\ngeneralization of the method to general short rate models is outlined. In the\ncase, where analytical solutions are not accessible, numerical implementations\nof the path integral method in terms of lattice calculations as well as path\nintegral Monte Carlo simulations are possible.\n"
    },
    {
        "paper_id": "cond-mat/9901035",
        "authors": "Anders Johansen (IGPP, UCLA) and Didier Sornette (CNRS-University of\n  Nice and UCLA)",
        "title": "Critical Crashes",
        "comments": "7 pages, 5 figures",
        "journal-ref": "Risk, Vol 12, No. 1, p.91-94 (1999)",
        "doi": null,
        "license": null,
        "abstract": "  We argue that the word ``critical'' in the title is not purely literary.\nBased on our and other previous work on nonlinear complex dynamical systems, we\nsummarize present evidence, on the Oct. 1929, Oct. 1987, Oct. 1987 Hong-Kong,\nAug. 1998 global market events and on the 1985 Forex event, for the hypothesis\nadvanced four years ago that stock market crashes are caused by the slow\nbuildup of long-range correlations between traders leading to a collapse of the\nstock market in one critical instant. We qualify the log-periodic oscillations\nusing a novel non-parametric method that does not rely on any fit: the\ncorresponding log-periodogram exhibits a strong statistically significant peak\nfor all six crashes examined, pointing at approximately the same prefered\nscaling ratio around 2.\n"
    },
    {
        "paper_id": "cond-mat/9901225",
        "authors": "R. Baviera, M. Pasquini, M. Serva, D. Vergni, A. Vulpiani (Universita'\n  di L'Aquila and Roma \"La Sapienza\", Italy)",
        "title": "Efficiency in foreign exchange markets",
        "comments": "22 pages, LaTeX, 6 eps figures, submitted to European Financial\n  Management journal",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  A quantitative check of weak efficiency in US dollar/German mark exchange\nrates is developed using high frequency data. We show the existence of long\nterm return anomalies. We introduce a technique to measure the available\ninformation and show it can be profitable following a particular trading rule.\n"
    },
    {
        "paper_id": "cond-mat/9901243",
        "authors": "Yi-Cheng Zhang",
        "title": "Toward a Theory of Marginally Efficient Markets",
        "comments": "9 pages, 3 ps figures",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(99)00077-1",
        "license": null,
        "abstract": "  Empirical evidence suggests that even the most competitive markets are not\nstrictly efficient. Price histories can be used to predict near future returns\nwith a probability better than random chance. Many markets can be considered as\n{\\it favorable games}, in the sense that there is a small probabilistic edge\nthat smart speculators can exploit. We propose to identify this probability\nusing conditional entropy concept. A perfect random walk has this entropy\nmaximized, and departure from the maximal value represents a price history's\npredictability. We propose that market participants should be divided into two\ncategories: producers and speculators. The former provides the negative entropy\ninto the price, upon which the latter feed. We show that the residual negative\nentropy can never be arbitraged away: infinite arbitrage capital is needed to\nmake the price a perfect random walk.\n"
    },
    {
        "paper_id": "cond-mat/9901268",
        "authors": "A. Johansen (IGPP, UCLA) and D. Sornette (CNRS-University of Nice and\n  UCLA)",
        "title": "Financial ``Anti-Bubbles'': Log-Periodicity in Gold and Nikkei collapses",
        "comments": "14 pages with 4 figures",
        "journal-ref": "International Journal of Modern Physics C, Vol. 10, No. 4 (1999)\n  563-575",
        "doi": "10.1142/S0129183199000437",
        "license": null,
        "abstract": "  We propose that imitation between traders and their herding behaviour not\nonly lead to speculative bubbles with accelerating over-valuations of financial\nmarkets possibly followed by crashes, but also to ``anti-bubbles'' with\ndecelerating market devaluations following all-time highs. For this, we propose\na simple market dynamics model in which the demand decreases slowly with\nbarriers that progressively quench in, leading to a power law decay of the\nmarket price decorated by decelerating log-periodic oscillations. We document\nthis behaviour on the Japanese Nikkei stock index from 1990 to present and on\nthe Gold future prices after 1980, both after their all-time highs. We perform\nsimultaneously a parametric and non-parametric analysis that are fully\nconsistent with each other. We extend the parametric approach to the next order\nof perturbation, comparing the log-periodic fits with one, two and three\nlog-frequencies, the latter one providing a prediction for the general trend in\nthe coming years. The non-parametric power spectrum analysis shows the\nexistence of log-periodicity with high statistical significance, with a\nprefered scale ratio of $\\lambda \\approx 3.5$ for the Nikkei index $\\lambda\n\\approx 1.9$ for the Gold future prices, comparable to the values obtained for\nspeculative bubbles leading to crashes.\n"
    },
    {
        "paper_id": "cond-mat/9901277",
        "authors": "Marco Rosa-Clot and Stefano Taddei",
        "title": "A Path Integral Approach to Derivative Security Pricing: I. Formalism\n  and Analytical Results",
        "comments": "20 pages, no figures, to be published in International Journal of\n  Theoretical and Applied Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We use a path integral approach for solving the stochastic equations\nunderlying the financial markets, and we show the equivalence between the path\nintegral and the usual SDE and PDE methods. We analyze both the one-dimensional\nand the multi-dimensional cases, with point dependent drift and volatility, and\ndescribe a covariant formulation which allows general changes of variables.\nFinally we apply the method to some economic models with analytical solutions.\nIn particular, we evaluate the expectation value of functionals which\ncorrespond to quantities of financial interest.\n"
    },
    {
        "paper_id": "cond-mat/9901279",
        "authors": "Marco Rosa-Clot and Stefano Taddei",
        "title": "A Path Integral Approach to Derivative Security Pricing: II. Numerical\n  Methods",
        "comments": "25 pages, 1 figure, submitted to International Journal of Theoretical\n  and Applied Finance",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We discuss two numerical methods, based on a path integral approach described\nin a previous paper (I), for solving the stochastic equations underlying the\nfinancial markets: the Monte Carlo approach, and the Green function\ndeterministic numerical method. Then, we apply the latter to some specific\nfinancial problems. In particular, we consider the pricing of a European\noption, a zero-coupon bond, a caplet, an American option, and a Bermudan\nswaption.\n"
    },
    {
        "paper_id": "cond-mat/9902018",
        "authors": "Rama Cont (CMAP - Ecole Polytechnique)",
        "title": "Modeling interest rate dynamics: an infinite-dimensional approach",
        "comments": "Keywords: interest rates, stochastic PDE, term structure models,\n  stochastic processes in Hilbert space. Other related works may be retrieved\n  on http://www.eleves.ens.fr:8080/home/cont/papers.html",
        "journal-ref": "International Journal of Theoretical and Applied Finance Vol. 8,\n  No. 3 (2005) 357--380",
        "doi": "10.1142/S0219024905003049",
        "license": null,
        "abstract": "  We present a family of models for the term structure of interest rates which\ndescribe the interest rate curve as a stochastic process in a Hilbert space. We\nstart by decomposing the deformations of the term structure into the variations\nof the short rate, the long rate and the fluctuations of the curve around its\naverage shape. This fluctuation is then described as a solution of a stochastic\nevolution equation in an infinite dimensional space. In the case where\ndeformations are local in maturity, this equation reduces to a stochastic PDE,\nof which we give the simplest example. We discuss the properties of the\nsolutions and show that they capture in a parsimonious manner the essential\nfeatures of yield curve dynamics: imperfect correlation between maturities,\nmean reversion of interest rates and the structure of principal components of\nterm structure deformations. Finally, we discuss calibration issues and show\nthat the model parameters have a natural interpretation in terms of empirically\nobserved quantities.\n"
    },
    {
        "paper_id": "cond-mat/9902044",
        "authors": "Alexandra Ilinskaia and Kirill Ilinski",
        "title": "How to reconcile Market Efficiency and Technical Analysis",
        "comments": "Latex, 15 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  Weak form of the Efficiency Market Hypothesis (EMH) excludes predictions of\nfuture market movements from historical data and makes the technical analysis\n(TA) out of law. However the technical analysis is widely used by traders and\nspeculators who steadely refuse to consider the market as a \"fair game\" and\nsurvive with such believe. In the paper we make a conjecture that TA and EMH\ncorrespond to different time regimes and show how both technical analysis\npredictions for short times and realistic statistical data for larger times can\nbe obtained in a simple single stock model of Gauge Theory of Arbitrage.\n"
    },
    {
        "paper_id": "cond-mat/9902045",
        "authors": "Kirill Ilinski",
        "title": "Virtual Arbitrage Pricing Theory",
        "comments": "Latex, 12 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  We generalize the Arbitrage Pricing Theory (APT) to include the contribution\nof virtual arbitrage opportunities. We model the arbitrage return by a\nstochastic process. The latter is incorporated in the APT framework to\ncalculate the correction to the APT due to the virtual arbitrage opportunities.\nThe resulting relations reduce to the APT for an infinitely fast market\nreaction or in the case where the virtual arbitrage is absent. Corrections to\nthe Capital Asset Pricing Model (CAPM) are also derived.\n"
    },
    {
        "paper_id": "cond-mat/9902046",
        "authors": "Kirill Ilinski and Alexander Stepanenko",
        "title": "Derivative pricing with virtual arbitrage",
        "comments": "Latex, 10 pages",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this paper we derive an effective equation for derivative pricing which\naccounts for the presence of virtual arbitrage opportunities and their\nelimination by the market. We model the arbitrage return by a stochastic\nprocess and find an equation for the average derivative price. This is an\nintegro-differential equation which, in the absence of the virtual arbitrage or\nfor an infinitely fast market reaction, reduces to the Black-Scholes equation.\nExplicit formulas are obtained for European call and put vanilla options.\n"
    },
    {
        "paper_id": "cond-mat/9902047",
        "authors": "Kirill Ilinski",
        "title": "How to account for virtual arbitrage in the standard derivative pricing",
        "comments": "Latex, 6 pages, Proschal'nii poklon",
        "journal-ref": null,
        "doi": null,
        "license": null,
        "abstract": "  In this short note we show how virtual arbitrage opportunities can be\nmodelled and included in the standard derivative pricing without changing the\ngeneral framework.\n"
    },
    {
        "paper_id": "cond-mat/9902283",
        "authors": "Vasiliki Plerou, Parameswaran Gopikrishnan, Bernd Rosenow, Luis A.\n  Nunes Amaral, and H. Eugene Stanley",
        "title": "Universal and non-universal properties of cross-correlations in\n  financial time series",
        "comments": "14 pages, 3 figures, Revtex",
        "journal-ref": "Phys. Rev. Lett., 83 (1999) 1471",
        "doi": "10.1103/PhysRevLett.83.1471",
        "license": null,
        "abstract": "  We use methods of random matrix theory to analyze the cross-correlation\nmatrix C of price changes of the largest 1000 US stocks for the 2-year period\n1994-95. We find that the statistics of most of the eigenvalues in the spectrum\nof C agree with the predictions of random matrix theory, but there are\ndeviations for a few of the largest eigenvalues. We find that C has the\nuniversal properties of the Gaussian orthogonal ensemble of random matrices.\nFurthermore, we analyze the eigenvectors of C through their inverse\nparticipation ratio and find eigenvectors with large inverse participation\nratios at both edges of the eigenvalue spectrum--a situation reminiscent of\nresults in localization theory.\n"
    },
    {
        "paper_id": "cond-mat/9903079",
        "authors": "C. Busshaus and H. Rieger",
        "title": "A prognosis oriented microscopic stock market model",
        "comments": "14 pages RevTeX, 5 eps-figures included",
        "journal-ref": "Physica A 267, 443 (1999)",
        "doi": "10.1016/S0378-4371(99)00060-6",
        "license": null,
        "abstract": "  We present a new microscopic stochastic model for an ensemble of interacting\ninvestors that buy and sell stocks in discrete time steps via limit orders\nbased on individual forecasts about the price of the stock. These orders\ndetermine the supply and demand fixing after each round (time step) the new\nprice of the stock according to which the limited buy and sell orders are then\nexecuted and new forecasts are made. We show via numerical simulation of this\nmodel that the distribution of price differences obeys an exponentially\ntruncated Levy-distribution with a self similarity exponent mu~5.\n"
    },
    {
        "paper_id": "cond-mat/9903142",
        "authors": "Kirill Ilinski (University of Birmingham)",
        "title": "Critical Crashes?",
        "comments": "6 pages, Latex, to appear in Int.J.Mod.Phys.C",
        "journal-ref": null,
        "doi": "10.1142/S0129183199000553",
        "license": null,
        "abstract": "  In this short note we discuss recent attempts to describe pre-crash market\ndynamics with analogies from theory of critical phenomena.\n"
    },
    {
        "paper_id": "cond-mat/9903144",
        "authors": "R. Baviera (Dip. di Fisica and I.N.F.M., Universita' dell'Aquila,\n  Italy), D. Vergni and A. Vulpiani (Dip. di Fisica and I.N.F.M., Universita'\n  dell'Aquila, Italy)",
        "title": "Markovian approximation in foreign exchange markets",
        "comments": "19 pages, LaTeX, uses elsart.cls and JournalOfFinance.sty, 7 eps\n  figures, submitted to J. of Int. Money and Finance",
        "journal-ref": null,
        "doi": "10.1016/S0378-4371(00)00094-7",
        "license": null,
        "abstract": "  In this paper we test the random walk hypothesis on the high frequency\ndataset of the bid--ask Deutschemark/US dollar exchange rate quotes registered\nby the inter-bank Reuters network over the period October 1, 1992 to September\n30, 1993. Then we propose a stochastic model for price variation which is able\nto describe some important features of the exchange market behavior. Besides\nthe usual correlation analysis we have verified the validity of this model by\nmeans of other approaches inspired by information theory . These techniques are\nnot only severe tests of the approximation but also evidence some aspects of\nthe data series which have a clear financial relevance.\n"
    }
]